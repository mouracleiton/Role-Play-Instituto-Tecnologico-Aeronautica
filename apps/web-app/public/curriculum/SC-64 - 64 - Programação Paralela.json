{
  "formatVersion": "1.0",
  "exportDate": "2025-12-04T21:38:27.223Z",
  "appVersion": "1.0",
  "curriculumData": {
    "metadata": {
      "baseOn": "Catálogo dos Cursos de Graduação 2025 - SC-64",
      "lastUpdated": "2025-12-04",
      "totalAtomicSkills": 283
    },
    "areas": [
      {
        "id": "10",
        "name": "Software e Sistemas de Informação",
        "description": "Departamento de Software e Sistemas de Informação (IEC-I)",
        "disciplines": [
          {
            "id": "10.1",
            "name": "Programação Paralela",
            "description": "Taxonomia de Flynn e modelos de memória. Principais modelos de programação paralela para memória distribuída e compartilhada: troca de mensagens, decomposição de domínio e exclusão mútua. Linguagens de programação paralela em plataformas multicores, heterogêneas e na nuvem. Avaliação de desempenho de programas paralelos. Aplicações (estudo de casos).",
            "mainTopics": [
              {
                "id": "10.1.1",
                "name": "Taxonomia de Flynn e Modelos de Memória",
                "description": "Apresenta a taxonomia de Flynn e os principais modelos de memória em computação paralela.",
                "totalSkills": 51,
                "atomicTopics": [
                  {
                    "id": "10.1.1.1",
                    "name": "Taxonomia de Flynn",
                    "description": "Classificação de arquiteturas de computadores paralelos em SISD, SIMD, MISD e MIMD.",
                    "specificSkills": [
                      {
                        "id": "10.1.1.1.1",
                        "name": "Definir a Taxonomia de Flynn",
                        "description": "Explicar a Taxonomia de Flynn, proposta por Michael J. Flynn em 1966, como um sistema de classificação de arquiteturas de computadores paralelos baseado em dois eixos: o número de fluxos de instruções (único - single ou múltiplo - multiple) e o número de fluxos de dados (único - single ou múltiplo - multiple), gerando as categorias SISD, SIMD, MISD e MIMD.",
                        "atomicExpansion": {
                          "steps": [
                            {
                              "stepNumber": 1,
                              "title": "Compreender o Contexto Histórico e Propósito da Taxonomia de Flynn",
                              "subSteps": [
                                "Pesquise a origem da taxonomia, proposta por Michael J. Flynn em 1966.",
                                "Identifique o problema que ela resolve: classificar arquiteturas de computadores paralelos.",
                                "Leia a definição básica: classificação baseada em fluxos de instruções e fluxos de dados.",
                                "Anote o objetivo principal: ajudar no design e análise de sistemas paralelos.",
                                "Visualize um diagrama simples dos dois eixos de classificação."
                              ],
                              "verification": "Escreva um parágrafo resumindo o histórico e propósito, citando Flynn e o ano.",
                              "estimatedTime": "20-30 minutos",
                              "materials": [
                                "Notebook ou papel para anotações",
                                "Acesso à internet para artigo original de Flynn ou resumo"
                              ],
                              "tips": "Comece com fontes confiáveis como Wikipedia ou livros de arquitetura de computadores para contexto rápido.",
                              "learningObjective": "Entender o background histórico e o propósito da taxonomia para contextualizar sua importância.",
                              "commonMistakes": [
                                "Confundir com outras taxonomias como a de Brooks",
                                "Ignorar o foco em paralelismo",
                                "Achar que é só teórica sem aplicações práticas"
                              ]
                            },
                            {
                              "stepNumber": 2,
                              "title": "Dominar os Dois Eixos de Classificação",
                              "subSteps": [
                                "Defina 'fluxo de instruções': único (SI) ou múltiplo (MI). Explique SI como uma sequência comum, MI como instruções independentes.",
                                "Defina 'fluxo de dados': único (SD) ou múltiplo (MD). Explique SD como dados sequenciais, MD como dados paralelos.",
                                "Crie uma tabela 2x2 combinando os eixos: SI/SD, SI/MD, MI/SD, MI/MD.",
                                "Desenhe setas ou diagramas ilustrando como os fluxos interagem em hardware.",
                                "Compare com programação sequencial para fixar diferenças."
                              ],
                              "verification": "Construa e explique uma tabela 2x2 correta dos eixos em voz alta ou por escrito.",
                              "estimatedTime": "25-35 minutos",
                              "materials": [
                                "Papel e caneta para tabela e diagramas",
                                "Ferramenta de desenho como Draw.io ou PowerPoint"
                              ],
                              "tips": "Use mnemônicos: 'Instruções' para o que o processador faz, 'Dados' para o que ele processa.",
                              "learningObjective": "Saber diferenciar e combinar os eixos de instruções e dados precisamente.",
                              "commonMistakes": [
                                "Trocar instruções por dados",
                                "Pensar que MI sempre significa multi-core",
                                "Ignorar que fluxos são streams lógicos, não físicos"
                              ]
                            },
                            {
                              "stepNumber": 3,
                              "title": "Memorizar e Detalhar as Quatro Categorias",
                              "subSteps": [
                                "Estude SISD: Single Instruction Single Data – computadores sequenciais clássicos como CPU von Neumann.",
                                "Estude SIMD: Single Instruction Multiple Data – processadores vetoriais como GPUs ou SSE instructions.",
                                "Estude MISD: Multiple Instruction Single Data – raro, usado em sistemas tolerantes a falhas como SPACE shuttle.",
                                "Estude MIMD: Multiple Instruction Multiple Data – maioria dos sistemas paralelos modernos como clusters.",
                                "Repita as siglas com exemplos até fixar: SISD (PC antigo), SIMD (GPU), MISD (fault-tolerant), MIMD (supercomputador)."
                              ],
                              "verification": "Liste as 4 categorias com definições e um exemplo cada, sem consultar materiais.",
                              "estimatedTime": "30-40 minutos",
                              "materials": [
                                "Flashcards com siglas e exemplos",
                                "Vídeos curtos sobre cada categoria no YouTube"
                              ],
                              "tips": "Associe cada categoria a hardware real: SISD=CPU desktop, SIMD=gráficos, MIMD=cloud computing.",
                              "learningObjective": "Identificar e descrever cada uma das quatro categorias com precisão.",
                              "commonMistakes": [
                                "Confundir SIMD com MIMD",
                                "Achar MISD inexistente ou irrelevante",
                                "Esquecer exemplos concretos"
                              ]
                            },
                            {
                              "stepNumber": 4,
                              "title": "Aplicar a Taxonomia a Exemplos e Cenários",
                              "subSteps": [
                                "Classifique arquiteturas conhecidas: Intel CPU (SISD), NVIDIA GPU (SIMD), Hadoop cluster (MIMD).",
                                "Discuta limitações da taxonomia: não cobre memória ou comunicação.",
                                "Crie um fluxograma de decisão para classificar uma arquitetura desconhecida.",
                                "Pesquise um processador moderno e aplique a classificação.",
                                "Debata evoluções: como GPUs misturam SIMD e MIMD."
                              ],
                              "verification": "Classifique 3 hardware reais corretamente em um relatório curto.",
                              "estimatedTime": "25-35 minutos",
                              "materials": [
                                "Lista de processadores: CPU, GPU, FPGA",
                                "Internet para specs de hardware"
                              ],
                              "tips": "Pratique com hardware que você usa diariamente para tornar concreto.",
                              "learningObjective": "Aplicar a taxonomia na prática para análise de sistemas reais.",
                              "commonMistakes": [
                                "Forçar classificações híbridas sem justificativa",
                                "Ignorar que sistemas modernos são híbridos",
                                "Não considerar o nível lógico vs. físico"
                              ]
                            }
                          ],
                          "practicalExample": "Classifique a arquitetura de uma GPU NVIDIA moderna: ela executa uma única instrução (como um shader) sobre múltiplos dados (pixels ou vetores), encaixando-se em SIMD. Em contraste, um cluster de servidores AWS roda instruções independentes em cada máquina sobre dados distribuídos, sendo MIMD.",
                          "finalVerifications": [
                            "Pode recitar as 4 categorias e seus significados sem erros.",
                            "Explica corretamente os dois eixos com exemplos.",
                            "Classifica pelo menos 3 arquiteturas reais usando a taxonomia.",
                            "Identifica limitações da taxonomia de Flynn.",
                            "Desenha um diagrama 2x2 preciso.",
                            "Discute uma aplicação real como GPUs em IA."
                          ],
                          "assessmentCriteria": [
                            "Precisão nas definições dos eixos e categorias (90%+ correto).",
                            "Uso de exemplos relevantes e atuais para cada categoria.",
                            "Capacidade de aplicação prática em cenários reais.",
                            "Clareza na explicação oral ou escrita da taxonomia.",
                            "Identificação de limitações e evoluções.",
                            "Profundidade nos sub-passos com verificações completas."
                          ],
                          "crossCurricularConnections": [
                            "História da Computação: Evolução de von Neumann para paralelos.",
                            "Programação Paralela: Mapeamento para OpenMP (SIMD) e MPI (MIMD).",
                            "Engenharia de Hardware: Design de processadores e GPUs.",
                            "Inteligência Artificial: Uso de SIMD em vectorização para ML.",
                            "Sistemas Distribuídos: MIMD em cloud computing."
                          ],
                          "realWorldApplication": "A Taxonomia de Flynn guia o design de processadores como GPUs (SIMD para gráficos e IA) e supercomputadores (MIMD para simulações científicas), otimizando paralelismo em smartphones, data centers e veículos autônomos."
                        },
                        "estimatedTime": "0.5 horas",
                        "difficulty": "beginner",
                        "status": "not_started",
                        "prerequisites": []
                      },
                      {
                        "id": "10.1.1.1.2",
                        "name": "Caracterizar a arquitetura SISD",
                        "description": "Descrever a classe Single Instruction Single Data (SISD) como o modelo sequencial clássico de computadores von Neumann, onde uma única instrução é processada em um único fluxo de dados por ciclo, representando arquiteturas uniprocessadoras sem paralelismo inerente.",
                        "atomicExpansion": {
                          "steps": [
                            {
                              "stepNumber": 1,
                              "title": "Compreender o contexto da Taxonomia de Flynn",
                              "subSteps": [
                                "Pesquisar a origem da Taxonomia de Flynn, proposta por Michael J. Flynn em 1966.",
                                "Identificar as quatro classes principais: SISD, SIMD, MISD e MIMD.",
                                "Explicar os eixos de classificação: número de instruções (single/multiple) e fluxos de dados (single/multiple).",
                                "Estudar diagramas básicos da taxonomia para visualizar as diferenças.",
                                "Anotar definições chave de cada classe para referência futura."
                              ],
                              "verification": "Criar um mapa mental ou tabela resumindo as 4 classes da Taxonomia de Flynn com exemplos breves.",
                              "estimatedTime": "20 minutos",
                              "materials": [
                                "Acesso à internet para artigos sobre Taxonomia de Flynn",
                                "Papel e caneta ou ferramenta digital como Draw.io",
                                "Livro-texto de Arquitetura de Computadores"
                              ],
                              "tips": "Comece pelo contexto histórico para fixar melhor os conceitos; use cores diferentes para instruções e dados nos diagramas.",
                              "learningObjective": "Entender a classificação geral de arquiteturas paralelas e sequenciais na Taxonomia de Flynn.",
                              "commonMistakes": [
                                "Confundir fluxos de instruções com fluxos de dados",
                                "Ignorar o ano e autor da taxonomia",
                                "Omitir alguma das quatro classes"
                              ]
                            },
                            {
                              "stepNumber": 2,
                              "title": "Definir e caracterizar a arquitetura SISD",
                              "subSteps": [
                                "Definir SISD como Single Instruction Single Data: uma única instrução aplicada a um único fluxo de dados por ciclo.",
                                "Associar SISD ao modelo von Neumann clássico, com CPU, memória compartilhada, unidade de controle e ALU.",
                                "Descrever o processamento sequencial: fetch-decode-execute em ciclos clock.",
                                "Explicar ausência de paralelismo inerente: processador uniprocessador.",
                                "Listar componentes chave: barramento de endereços, dados e controle."
                              ],
                              "verification": "Escrever uma definição formal de SISD em 3-5 frases, incluindo termos como 'von Neumann' e 'sequencial'.",
                              "estimatedTime": "25 minutos",
                              "materials": [
                                "Diagramas de arquitetura von Neumann (impressos ou online)",
                                "Notas do Step 1",
                                "Editor de texto simples"
                              ],
                              "tips": "Use analogias como 'uma pessoa lendo e executando uma receita passo a passo' para visualizar o fluxo único.",
                              "learningObjective": "Dominar a definição precisa e os termos fundamentais da SISD.",
                              "commonMistakes": [
                                "Confundir SISD com SIMD (múltiplos dados)",
                                "Omitir menção ao modelo von Neumann",
                                "Descrever como paralelismo"
                              ]
                            },
                            {
                              "stepNumber": 3,
                              "title": "Analisar características e limitações da SISD",
                              "subSteps": [
                                "Descrever o gargalo de von Neumann: contenção no barramento de memória.",
                                "Explicar execução sequencial: instruções processadas uma de cada vez.",
                                "Comparar brevemente com SIMD: SISD não vetoriza dados.",
                                "Identificar vantagens: simplicidade, baixo custo, fácil programação.",
                                "Listar limitações: incapacidade de explorar paralelismo de dados."
                              ],
                              "verification": "Criar uma tabela de prós, contras e comparação com SIMD (2-3 linhas cada).",
                              "estimatedTime": "20 minutos",
                              "materials": [
                                "Planilha ou tabela em Google Sheets/Excel",
                                "Referências online sobre gargalo de von Neumann"
                              ],
                              "tips": "Priorize o gargalo como característica definidora; teste compreensão verbalizando para si mesmo.",
                              "learningObjective": "Identificar forças, fraquezas e diferenças contextuais da SISD.",
                              "commonMistakes": [
                                "Exagerar paralelismo na SISD",
                                "Confundir gargalo com pipeline",
                                "Ignorar simplicidade como vantagem"
                              ]
                            },
                            {
                              "stepNumber": 4,
                              "title": "Ilustrar SISD com exemplo prático e diagrama",
                              "subSteps": [
                                "Desenhar um diagrama simples da SISD: CPU conectada a memória via barramentos.",
                                "Simular fluxo: mostrar fetch de uma instrução e aplicação a um dado único.",
                                "Executar um pseudocódigo sequencial: soma de array elemento por elemento.",
                                "Relacionar a hardware real: processadores Intel x86 pré-multicore.",
                                "Documentar observações sobre ausência de paralelismo."
                              ],
                              "verification": "Produzir um diagrama rotulado e pseudocódigo comentado demonstrando ciclo SISD.",
                              "estimatedTime": "30 minutos",
                              "materials": [
                                "Ferramenta de desenho como Lucidchart ou papel",
                                "Editor de código para pseudocódigo"
                              ],
                              "tips": "Mantenha o diagrama minimalista: foque em 1 instrução e 1 dado; anote setas para fluxo.",
                              "learningObjective": "Visualizar e simular o funcionamento prático da SISD.",
                              "commonMistakes": [
                                "Incluir múltiplos processadores no diagrama",
                                "Usar loops vetorizados no exemplo",
                                "Esquecer labels nos barramentos"
                              ]
                            }
                          ],
                          "practicalExample": "Implemente um programa C sequencial para somar elementos de um array de 100 números inteiros, processando um elemento por iteração em um loop for simples. Observe que uma única instrução de soma é aplicada sequencialmente a cada dado individual, sem vetorização SIMD, simulando o fluxo SISD em um processador uniprocessador.",
                          "finalVerifications": [
                            "Descrever SISD em próprias palavras, mencionando von Neumann e fluxos single.",
                            "Diferenciar corretamente SISD de SIMD e MIMD com exemplos.",
                            "Explicar o gargalo de von Neumann e seu impacto.",
                            "Desenhar um diagrama básico de SISD reconhecível.",
                            "Identificar 3 exemplos de hardware SISD clássico (ex: Intel 8086).",
                            "Simular verbalmente um ciclo fetch-decode-execute."
                          ],
                          "assessmentCriteria": [
                            "Precisão na definição e terminologia técnica (von Neumann, single instruction/data).",
                            "Completude: cobertura de contexto Flynn, características, limitações e ilustração.",
                            "Clareza na explicação e uso de analogias ou diagramas.",
                            "Capacidade de diferenciação com outras classes de Flynn.",
                            "Profundidade nas verificações: ausência de erros comuns como confusão com paralelismo.",
                            "Relevância do exemplo prático ao conceito SISD."
                          ],
                          "crossCurricularConnections": [
                            "História da Computação: Evolução do modelo von Neumann desde 1945.",
                            "Arquitetura de Computadores: Estudo de barramentos e ciclo de instrução.",
                            "Programação: Desenvolvimento de algoritmos sequenciais em linguagens imperativas.",
                            "Engenharia de Software: Limitações em sistemas legados uniprocessadores.",
                            "Física/Engenharia Elétrica: Clock cycles e sinalização em hardware."
                          ],
                          "realWorldApplication": "Arquiteturas SISD formam a base de computadores pessoais tradicionais (ex: PCs com single-core pré-2005), servidores uniprocessadores e microcontroladores em dispositivos embarcados como Arduino, onde simplicidade e custo baixo superam a necessidade de paralelismo, processando tarefas sequenciais como controle de sensores ou cálculos básicos em tempo real."
                        },
                        "estimatedTime": "0.5 horas",
                        "difficulty": "beginner",
                        "status": "not_started",
                        "prerequisites": []
                      },
                      {
                        "id": "10.1.1.1.3",
                        "name": "Caracterizar a arquitetura SIMD",
                        "description": "Explicar a classe Single Instruction Multiple Data (SIMD), na qual uma única instrução é executada simultaneamente em múltiplos fluxos de dados independentes, comum em processadores vetoriais, arrays de processadores e GPUs modernas para aceleração de computação paralela em dados.",
                        "atomicExpansion": {
                          "steps": [
                            {
                              "stepNumber": 1,
                              "title": "Revisar a Taxonomia de Flynn",
                              "subSteps": [
                                "Estude a definição da Taxonomia de Flynn proposta por Michael J. Flynn em 1966.",
                                "Identifique as quatro classes principais: SISD, SIMD, MISD e MIMD.",
                                "Analise os eixos de classificação: fluxo de instruções (único ou múltiplo) e fluxo de dados (único ou múltiplo).",
                                "Crie um diagrama simples ilustrando as diferenças entre as classes.",
                                "Compare brevemente SISD (arquitetura sequencial tradicional) com as paralelas."
                              ],
                              "verification": "Desenhe ou liste corretamente as quatro classes da Taxonomia de Flynn com suas características principais.",
                              "estimatedTime": "25 minutos",
                              "materials": [
                                "Artigo original de Flynn ou resumo online",
                                "Diagrama da Taxonomia de Flynn (impresso ou digital)"
                              ],
                              "tips": "Use mnemônicos como 'Single Instruction Single Data' para memorizar SISD e assim por diante.",
                              "learningObjective": "Compreender o contexto classificatório da arquitetura SIMD dentro da Taxonomia de Flynn.",
                              "commonMistakes": [
                                "Confundir fluxo de instruções com fluxo de dados",
                                "Ignorar MISD como classe válida embora rara"
                              ]
                            },
                            {
                              "stepNumber": 2,
                              "title": "Definir e caracterizar SIMD",
                              "subSteps": [
                                "Defina SIMD como Single Instruction Multiple Data: uma instrução única aplicada simultaneamente a múltiplos dados independentes.",
                                "Explique que opera em fluxos paralelos de dados com sincronização implícita.",
                                "Descreva componentes chave: unidade de controle única e múltiplas unidades de processamento de dados (PEs).",
                                "Diferencie de SISD (sequencial) e antecipe comparação com MIMD (instruções independentes).",
                                "Registre a definição em suas próprias palavras."
                              ],
                              "verification": "Escreva uma definição precisa de SIMD em uma frase, citando os elementos 'Single Instruction' e 'Multiple Data'.",
                              "estimatedTime": "20 minutos",
                              "materials": [
                                "Notas de aula sobre Taxonomia de Flynn",
                                "Vídeo curto explicando SIMD (ex: YouTube Khan Academy ou similar)"
                              ],
                              "tips": "Pense em SIMD como 'uma ordem para um pelotão inteiro' onde todos executam a mesma ação em dados diferentes.",
                              "learningObjective": "Dominar a definição precisa e os princípios fundamentais da arquitetura SIMD.",
                              "commonMistakes": [
                                "Achar que dados em SIMD precisam ser dependentes",
                                "Confundir com paralelismo de threads em MIMD"
                              ]
                            },
                            {
                              "stepNumber": 3,
                              "title": "Explicar o funcionamento da arquitetura SIMD",
                              "subSteps": [
                                "Descreva o ciclo de execução: broadcast da instrução para todas as PEs, processamento paralelo nos dados.",
                                "Ilustre com um exemplo simples: soma de vetores [a1+a2, b1+b2] usando uma instrução de adição.",
                                "Discuta mascaramento (masking) para lidar com comprimentos irregulares de dados.",
                                "Explique sincronização: todas as PEs executam em lock-step.",
                                "Simule manualmente um exemplo com 4 elementos de dados."
                              ],
                              "verification": "Simule em papel a execução de uma operação aritmética SIMD em um vetor de 4 elementos.",
                              "estimatedTime": "30 minutos",
                              "materials": [
                                "Papel e caneta para simulação",
                                "Ferramenta online como SIMD simulator ou pseudocódigo"
                              ],
                              "tips": "Visualize as PEs como soldados em fila recebendo a mesma ordem ao mesmo tempo.",
                              "learningObjective": "Entender o mecanismo operacional de execução paralela em SIMD.",
                              "commonMistakes": [
                                "Esquecer o broadcast da instrução única",
                                "Assumir independência total como em MIMD"
                              ]
                            },
                            {
                              "stepNumber": 4,
                              "title": "Identificar implementações e aplicações de SIMD",
                              "subSteps": [
                                "Liste exemplos: processadores vetoriais (Cray), arrays de processadores (Illiac IV), extensões modernas (Intel SSE/AVX, ARM NEON).",
                                "Descreva uso em GPUs modernas para computação paralela massiva (ex: CUDA shaders).",
                                "Discuta vantagens: alta eficiência em dados regulares, bom para multimídia.",
                                "Mencione limitações: inadequado para dados irregulares ou dependentes.",
                                "Pesquise um exemplo real de código vetorizado."
                              ],
                              "verification": "Cite pelo menos três implementações históricas ou modernas de SIMD com uma breve descrição.",
                              "estimatedTime": "25 minutos",
                              "materials": [
                                "Documentação Intel AVX ou NVIDIA CUDA",
                                "Lista de processadores SIMD online"
                              ],
                              "tips": "Procure benchmarks comparando código escalar vs. vetorizado para ver ganhos reais.",
                              "learningObjective": "Conectar a teoria SIMD a hardware e software reais.",
                              "commonMistakes": [
                                "Limitar SIMD apenas a supercomputadores antigos",
                                "Ignorar extensões SIMD em CPUs desktop modernas"
                              ]
                            }
                          ],
                          "practicalExample": "Usando NumPy em Python para simular SIMD: importe numpy as np; a = np.array([1,2,3,4]); b = np.array([5,6,7,8]); c = a + b; print(c) # Resultado: [6 8 10 12] executado em uma única instrução vetorizada, acelerando processamento de imagens ou ML.",
                          "finalVerifications": [
                            "Defina corretamente SIMD em termos da Taxonomia de Flynn.",
                            "Diferencie SIMD de MIMD e SISD com exemplos.",
                            "Simule uma operação SIMD simples em papel ou código.",
                            "Cite pelo menos dois exemplos de hardware SIMD moderno.",
                            "Explique uma vantagem e uma limitação de SIMD.",
                            "Descreva mascaramento em SIMD."
                          ],
                          "assessmentCriteria": [
                            "Precisão na definição e classificação de SIMD (30%)",
                            "Clareza na explicação do funcionamento e ciclo de execução (25%)",
                            "Correta identificação de exemplos históricos e modernos (20%)",
                            "Uso de analogias ou diagramas para ilustrar conceitos (15%)",
                            "Análise de vantagens, limitações e comparações (10%)"
                          ],
                          "crossCurricularConnections": [
                            "Hardware e Arquitetura de Computadores: Estudo de extensões como SSE/AVX em CPUs.",
                            "Programação Paralela: Vetorização em linguagens como C++ com intrinsics ou OpenMP.",
                            "Inteligência Artificial: Aceleração de tensores em frameworks como TensorFlow/PyTorch.",
                            "Matemática Computacional: Operações em vetores e álgebra linear paralela.",
                            "Engenharia de Software: Otimização de performance em aplicações multimídia."
                          ],
                          "realWorldApplication": "SIMD é essencial em GPUs para renderização 3D em jogos (ex: shaders processando pixels paralelos), processamento de vídeo em smartphones (filtros em frames), aceleração de machine learning (operações matriciais em CPUs Intel com AVX-512) e simulações científicas (clima, física de partículas), reduzindo tempo de computação em ordens de magnitude para dados massivamente paralelos."
                        },
                        "estimatedTime": "1 hora",
                        "difficulty": "intermediate",
                        "status": "not_started",
                        "prerequisites": [
                          "10.1.1.1.1"
                        ]
                      },
                      {
                        "id": "10.1.1.1.4",
                        "name": "Caracterizar a arquitetura MISD",
                        "description": "Descrever a classe Multiple Instruction Single Data (MISD), considerada rara, onde múltiplas instruções independentes operam sobre um único fluxo de dados compartilhado, com exemplos em sistemas de pipeline com redundância para detecção de falhas ou processamento tolerante a erros.",
                        "atomicExpansion": {
                          "steps": [
                            {
                              "stepNumber": 1,
                              "title": "Revisar os fundamentos da Taxonomia de Flynn",
                              "subSteps": [
                                "Estude as quatro classes principais: SISD, SIMD, MISD e MIMD.",
                                "Identifique os eixos de classificação: número de instruções e fluxos de dados.",
                                "Anote as características gerais de cada classe com diagramas simples.",
                                "Pesquise a origem histórica da taxonomia criada por Michael J. Flynn em 1966.",
                                "Crie um quadro comparativo básico das classes."
                              ],
                              "verification": "Construa um diagrama ou tabela resumindo as quatro classes da Taxonomia de Flynn.",
                              "estimatedTime": "20 minutos",
                              "materials": [
                                "Artigo original de Flynn (1966) ou resumo online",
                                "Papel e caneta para diagramas",
                                "Vídeo introdutório sobre arquiteturas paralelas"
                              ],
                              "tips": "Use cores diferentes para instruções e dados nos diagramas para facilitar a visualização.",
                              "learningObjective": "Compreender o contexto da Taxonomia de Flynn como base para classificar MISD.",
                              "commonMistakes": "Confundir instruções com dados; sempre diferencie os fluxos."
                            },
                            {
                              "stepNumber": 2,
                              "title": "Definir e descrever a arquitetura MISD",
                              "subSteps": [
                                "Defina MISD como Multiple Instruction Single Data: múltiplas instruções independentes sobre um único fluxo de dados.",
                                "Explique que é rara e não comum em arquiteturas modernas.",
                                "Descreva o fluxo: um dado compartilhado processado por várias unidades de instrução paralelas.",
                                "Destaque independência das instruções: cada uma opera sem sincronização direta.",
                                "Registre a sigla em inglês e sua tradução."
                              ],
                              "verification": "Escreva uma definição precisa de MISD em suas próprias palavras, com no máximo 50 palavras.",
                              "estimatedTime": "15 minutos",
                              "materials": [
                                "Notas da Taxonomia de Flynn",
                                "Documentação de arquiteturas paralelas (Wikipedia ou livros-texto)"
                              ],
                              "tips": "Pense em 'múltiplas cabeças processando o mesmo corpo' para visualizar.",
                              "learningObjective": "Dominar a definição técnica e conceitual de MISD.",
                              "commonMistakes": "Confundir com SIMD (um comando para múltiplos dados); MISD é o oposto."
                            },
                            {
                              "stepNumber": 3,
                              "title": "Explorar características e exemplos de MISD",
                              "subSteps": [
                                "Liste características: redundância para detecção de falhas, processamento tolerante a erros.",
                                "Estude exemplos: pipelines com duplicação de processamento para verificação.",
                                "Analise sistemas de pipeline fault-tolerant, como em aviônica ou espaço.",
                                "Desenhe um diagrama de um pipeline MISD simples com redundância.",
                                "Pesquise aplicações raras, como em supercomputadores experimentais."
                              ],
                              "verification": "Crie um diagrama esquemático de um sistema MISD com pelo menos duas unidades de instrução.",
                              "estimatedTime": "25 minutos",
                              "materials": [
                                "Ferramenta de desenho (Draw.io ou papel)",
                                "Exemplos de papers sobre fault-tolerance em pipelines"
                              ],
                              "tips": "Foque em como o dado único flui através de múltiplos processadores independentes.",
                              "learningObjective": "Identificar traços únicos e exemplos práticos de MISD.",
                              "commonMistakes": "Achar que MISD é comum; enfatize sua raridade comparado a MIMD."
                            },
                            {
                              "stepNumber": 4,
                              "title": "Comparar MISD com outras classes e sintetizar",
                              "subSteps": [
                                "Compare MISD vs. SISD (sequencial), SIMD (vetorizado), MIMD (multitarefa).",
                                "Discuta por que MISD é rara: complexidade e pouca utilidade prática.",
                                "Sintetize vantagens: tolerância a falhas via redundância.",
                                "Liste desvantagens: overhead de sincronização implícita.",
                                "Resuma em um parágrafo a caracterização completa de MISD."
                              ],
                              "verification": "Elabore uma tabela comparativa das 4 classes, destacando MISD.",
                              "estimatedTime": "20 minutos",
                              "materials": [
                                "Tabela anterior do Step 1",
                                "Livro de arquitetura de computadores (ex: Tanenbaum)"
                              ],
                              "tips": "Use setas para mostrar fluxos de dados/instruções na tabela.",
                              "learningObjective": "Capacitar a caracterização de MISD no contexto da taxonomia.",
                              "commonMistakes": "Ignorar a independência das instruções; elas não compartilham controle."
                            }
                          ],
                          "practicalExample": "Em um sistema de controle de voo de satélite, um único fluxo de dados de sensores (ex: temperatura) é processado por duas unidades MISD independentes: uma calcula média com algoritmo A, outra com B; resultados são comparados para detectar falhas sem interromper o fluxo.",
                          "finalVerifications": [
                            "Explique MISD em 1 minuto sem consultar notas.",
                            "Desenhe corretamente um diagrama MISD.",
                            "Diferencie MISD de SIMD e MIMD com exemplos.",
                            "Cite pelo menos um exemplo real ou hipotético de MISD.",
                            "Identifique por que MISD é considerada rara na taxonomia."
                          ],
                          "assessmentCriteria": [
                            "Definição precisa e completa de MISD (20%)",
                            "Descrição clara de características e fluxos (25%)",
                            "Exemplos relevantes e diagramas corretos (20%)",
                            "Comparação adequada com outras classes (20%)",
                            "Síntese coesa e compreensão de raridade (15%)"
                          ],
                          "crossCurricularConnections": [
                            "Engenharia de Software: Tolerância a falhas em sistemas distribuídos.",
                            "Sistemas Embarcados: Pipelines redundantes em dispositivos críticos.",
                            "Matemática: Teoria de conjuntos para fluxos de dados únicos.",
                            "Física/Engenharia: Aplicações em controle de processos industriais."
                          ],
                          "realWorldApplication": "Sistemas aeroespaciais como o Space Shuttle usavam conceitos MISD em pipelines de redundância para detecção de erros em tempo real, garantindo segurança onde falhas são inaceitáveis."
                        },
                        "estimatedTime": "0.5 horas",
                        "difficulty": "intermediate",
                        "status": "not_started",
                        "prerequisites": [
                          "10.1.1.1.1"
                        ]
                      },
                      {
                        "id": "10.1.1.1.5",
                        "name": "Caracterizar a arquitetura MIMD",
                        "description": "Detalhar a classe Multiple Instruction Multiple Data (MIMD), a mais versátil e comum em sistemas paralelos modernos, onde múltiplos processadores executam instruções independentes em fluxos de dados independentes, abrangendo multicore, multiprocessadores e clusters distribuídos.",
                        "atomicExpansion": {
                          "steps": [
                            {
                              "stepNumber": 1,
                              "title": "Revisar a Taxonomia de Flynn e posicionar MIMD",
                              "subSteps": [
                                "Estude as quatro classes principais da Taxonomia de Flynn: SISD, SIMD, MISD e MIMD.",
                                "Identifique os eixos de classificação: fluxo de instruções (único ou múltiplo) e fluxo de dados (único ou múltiplo).",
                                "Explique por que MIMD é Multiple Instruction Multiple Data.",
                                "Compare brevemente MIMD com SISD (sequencial) e SIMD (vetorial).",
                                "Anote as características gerais de arquiteturas paralelas."
                              ],
                              "verification": "Crie um diagrama ou tabela comparativa das classes de Flynn, destacando MIMD.",
                              "estimatedTime": "20-30 minutos",
                              "materials": [
                                "Livro de Arquitetura de Computadores (ex: Hennessy & Patterson)",
                                "Artigo da Wikipedia sobre Taxonomia de Flynn",
                                "Papel e caneta para diagrama"
                              ],
                              "tips": "Use mnemônicos como 'MIMD = Muitos Instrutores, Muitos Dados' para memorizar.",
                              "learningObjective": "Compreender o contexto da Taxonomia de Flynn e a posição única do MIMD como a mais flexível.",
                              "commonMistakes": [
                                "Confundir MIMD com SIMD (MIMD permite instruções diferentes por processador)",
                                "Ignorar que Flynn classifica fluxos, não necessariamente hardware moderno"
                              ]
                            },
                            {
                              "stepNumber": 2,
                              "title": "Definir características principais da arquitetura MIMD",
                              "subSteps": [
                                "Defina MIMD: múltiplos processadores executam instruções independentes em fluxos de dados independentes.",
                                "Descreva independência: cada processador tem seu próprio PC (Program Counter) e dados.",
                                "Explique sincronização: comunicação via memória compartilhada ou mensagens.",
                                "Discuta modelos de memória: UMA (Uniform Memory Access), NUMA, COMA.",
                                "Liste propriedades: versatilidade, escalabilidade, suporte a cargas gerais."
                              ],
                              "verification": "Escreva uma definição precisa de MIMD em suas próprias palavras e liste 5 características chave.",
                              "estimatedTime": "25-35 minutos",
                              "materials": [
                                "Slides ou vídeo sobre Taxonomia de Flynn (YouTube: MIT OpenCourseWare)",
                                "Notas de aula sobre paralelismo"
                              ],
                              "tips": "Pense em MIMD como 'computadores independentes cooperando', não lockstep.",
                              "learningObjective": "Dominar a definição e as propriedades fundamentais que tornam MIMD versátil para computação paralela moderna.",
                              "commonMistakes": [
                                "Achar que MIMD requer memória compartilhada (pode ser distribuída)",
                                "Confundir com multiprogramação sequencial"
                              ]
                            },
                            {
                              "stepNumber": 3,
                              "title": "Classificar subtipos e modelos de MIMD",
                              "subSteps": [
                                "Diferencie MIMD acoplado apertado (SMP - Symmetric Multiprocessing) de acoplado frouxo (clusters).",
                                "Estude modelos de memória: UMA vs NUMA vs distribuída.",
                                "Analise consistência de cache e protocolos de sincronização (barreiras, locks).",
                                "Descreva desafios: overhead de comunicação, escalabilidade de Amdahl.",
                                "Compare MIMD com arquiteturas híbridas modernas (GPU + CPU)."
                              ],
                              "verification": "Monte uma tabela com subtipos de MIMD, modelos de memória e exemplos.",
                              "estimatedTime": "30-40 minutos",
                              "materials": [
                                "Documentação MPI/OpenMP",
                                "Artigo sobre NUMA",
                                "Ferramenta de desenho como Draw.io"
                              ],
                              "tips": "Visualize com diagramas: setas independentes para instruções e dados em MIMD.",
                              "learningObjective": "Identificar variações de MIMD e entender impactos em performance e programação.",
                              "commonMistakes": [
                                "Ignorar diferenças NUMA vs UMA em latência",
                                "Achar todos MIMD são SMP (clusters são MIMD distribuídos)"
                              ]
                            },
                            {
                              "stepNumber": 4,
                              "title": "Explorar exemplos e aplicações de MIMD",
                              "subSteps": [
                                "Liste hardware MIMD: CPUs multicore (Intel Xeon), clusters (Beowulf), supercomputadores (TOP500).",
                                "Descreva software: threads (pthreads), processos (MPI para distribuído).",
                                "Analise vantagens: general-purpose, fault-tolerance; desvantagens: complexidade de programação.",
                                "Simule conceitualmente um programa MIMD com tarefas independentes.",
                                "Pesquise um caso real, como Hadoop em clusters MIMD."
                              ],
                              "verification": "Desenhe um diagrama de um sistema MIMD real (ex: cluster com 4 nós) e explique fluxos.",
                              "estimatedTime": "25-35 minutos",
                              "materials": [
                                "Lista TOP500 supercomputers",
                                "Exemplos de código multiprocessing Python",
                                "Browser para pesquisa"
                              ],
                              "tips": "Relacione com seu PC: seu processador multicore é MIMD em ação.",
                              "learningObjective": "Conectar teoria MIMD a implementações reais e preparar para programação paralela.",
                              "commonMistakes": [
                                "Limitar MIMD a supercomputadores (smartphones multicore são MIMD)",
                                "Confundir GPU (SIMD-like) com MIMD puro"
                              ]
                            }
                          ],
                          "practicalExample": "Implemente um programa Python usando o módulo multiprocessing: um processo analisa dados de imagem A com filtro de bordas, outro processa imagem B com detecção de objetos, demonstrando instruções independentes em dados independentes, com comunicação via Queue para resultados finais.",
                          "finalVerifications": [
                            "Explique a diferença fundamental entre MIMD e SIMD com um exemplo.",
                            "Liste 3 exemplos de hardware MIMD moderno e classifique-os como SMP ou cluster.",
                            "Descreva como sincronizar processadores MIMD em memória compartilhada vs distribuída.",
                            "Identifique limitações de MIMD pela Lei de Amdahl.",
                            "Crie um diagrama de fluxos de instruções/dados para MIMD.",
                            "Compare performance esperada de MIMD vs SISD em uma tarefa paralelizável."
                          ],
                          "assessmentCriteria": [
                            "Precisão na definição e posicionamento na Taxonomia de Flynn (20%)",
                            "Compreensão de independência de instruções e dados (25%)",
                            "Correta classificação de subtipos e modelos de memória (20%)",
                            "Uso de exemplos reais e diagramas claros (15%)",
                            "Análise de vantagens/desvantagens e aplicações (10%)",
                            "Capacidade de verificação prática via simulação conceitual (10%)"
                          ],
                          "crossCurricularConnections": [
                            "Programação Paralela: Uso de MPI/OpenMP em MIMD.",
                            "Sistemas Operacionais: Gerenciamento de multiprocessadores SMP.",
                            "Redes de Computadores: Clusters MIMD distribuídos.",
                            "Inteligência Artificial: Clusters para treinamento distribuído de modelos.",
                            "Engenharia de Software: Design de aplicações escaláveis em MIMD."
                          ],
                          "realWorldApplication": "Arquiteturas MIMD dominam computação moderna, como processadores multicore em smartphones (ex: Snapdragon com 8 núcleos independentes), servidores cloud (AWS EC2 com NUMA), e supercomputadores como Frontier (TOP500 #1), permitindo paralelismo geral para IA, big data e simulações científicas."
                        },
                        "estimatedTime": "1 hora",
                        "difficulty": "intermediate",
                        "status": "not_started",
                        "prerequisites": [
                          "10.1.1.1.1"
                        ]
                      },
                      {
                        "id": "10.1.1.1.6",
                        "name": "Comparar as classes da Taxonomia de Flynn",
                        "description": "Analisar e comparar as quatro classes (SISD, SIMD, MISD, MIMD) em termos de paralelismo de instruções e dados, exemplos de hardware, aplicações típicas, vantagens, limitações e relevância para programação paralela contemporânea.",
                        "atomicExpansion": {
                          "steps": [
                            {
                              "stepNumber": 1,
                              "title": "Revisar as Definições Básicas das Quatro Classes da Taxonomia de Flynn",
                              "subSteps": [
                                "Estude a definição de SISD (Single Instruction, Single Data): execução sequencial com uma instrução processando um dado por vez.",
                                "Analise SIMD (Single Instruction, Multiple Data): uma instrução aplicada a múltiplos dados simultaneamente.",
                                "Examine MISD (Multiple Instruction, Single Data): múltiplas instruções processando o mesmo dado de formas diferentes.",
                                "Descreva MIMD (Multiple Instruction, Multiple Data): múltiplas instruções em múltiplos dados independentemente.",
                                "Crie um quadro comparativo inicial com as definições."
                              ],
                              "verification": "Confirme entendendo cada acrônimo e explicando verbalmente ou por escrito para um colega.",
                              "estimatedTime": "1 hora",
                              "materials": [
                                "Documentação da Taxonomia de Flynn (Wikipedia ou livro-texto como 'Computer Architecture: A Quantitative Approach')",
                                "Papel e caneta ou ferramenta de quadro como Draw.io"
                              ],
                              "tips": "Use mnemônicos como 'SISD é sequencial clássico' para memorizar.",
                              "learningObjective": "Compreender as diferenças fundamentais em instruções e dados para cada classe.",
                              "commonMistakes": [
                                "Confundir SIMD com MIMD; lembrar que SIMD é vetorizado, MIMD é geral."
                              ]
                            },
                            {
                              "stepNumber": 2,
                              "title": "Comparar Paralelismo de Instruções e Dados",
                              "subSteps": [
                                "Classifique cada classe quanto ao paralelismo de instruções: único (SISD, SIMD) vs. múltiplo (MISD, MIMD).",
                                "Classifique paralelismo de dados: único (SISD, MISD) vs. múltiplo (SIMD, MIMD).",
                                "Crie uma tabela 2x2 destacando os quadrantes: SISD (nenhum), SIMD (dados), MISD (instruções), MIMD (ambos).",
                                "Discuta implicações: como isso afeta eficiência em tarefas paralelas.",
                                "Desenhe fluxogramas simples para ilustrar o fluxo em cada classe."
                              ],
                              "verification": "Gere uma tabela preenchida corretamente e explique as diferenças para si mesmo em voz alta.",
                              "estimatedTime": "1.5 horas",
                              "materials": [
                                "Planilha Excel ou Google Sheets",
                                "Artigos acadêmicos sobre paralelismo (ex: IEEE papers iniciais de Flynn)"
                              ],
                              "tips": "Pense em uma grade: linhas para instruções (1 ou M), colunas para dados (1 ou M).",
                              "learningObjective": "Identificar e contrastar níveis de paralelismo como base para comparações.",
                              "commonMistakes": [
                                "Ignorar MISD como 'raro'; é teórico mas importante para pipelining."
                              ]
                            },
                            {
                              "stepNumber": 3,
                              "title": "Examinar Exemplos de Hardware e Aplicações Típicas",
                              "subSteps": [
                                "Liste hardware para SISD: processadores von Neumann como Intel x86 single-core.",
                                "Identifique SIMD: GPUs (NVIDIA CUDA), vetores SSE/AVX em CPUs.",
                                "Pesquise MISD: pipelines como em alguns processadores de sinal digital ou fault-tolerant systems.",
                                "Exemplos MIMD: multicore CPUs, clusters de supercomputadores (ex: TOP500).",
                                "Mapeie aplicações: SISD (apps desktop), SIMD (gráficos/imagens), MISD (redundância), MIMD (HPC, servidores)."
                              ],
                              "verification": "Compile uma lista de 2-3 exemplos por classe com fontes citadas.",
                              "estimatedTime": "2 horas",
                              "materials": [
                                "Site TOP500.org",
                                "Documentação NVIDIA/Intel",
                                "Livro 'Parallel Computer Architecture' de Culler"
                              ],
                              "tips": "Busque vídeos no YouTube sobre 'Flynn's Taxonomy examples' para visualização.",
                              "learningObjective": "Associar classes a tecnologias reais para contextualizar.",
                              "commonMistakes": [
                                "Atribuir GPUs só a MIMD; elas são primariamente SIMD com MIMD em nível superior."
                              ]
                            },
                            {
                              "stepNumber": 4,
                              "title": "Analisar Vantagens e Limitações de Cada Classe",
                              "subSteps": [
                                "Para SISD: vantagens (simples, debug fácil), limitações (sem paralelismo).",
                                "SIMD: vantagens (eficiente para dados regulares), limitações (dados irregulares).",
                                "MISD: vantagens (tolerância a falhas), limitações (raro, overhead alto).",
                                "MIMD: vantagens (flexível, escalável), limitações (sincronização complexa).",
                                "Compare em uma matriz de prós/contras."
                              ],
                              "verification": "Preencha matriz e debata trade-offs em um resumo escrito.",
                              "estimatedTime": "1.5 horas",
                              "materials": [
                                "Ferramenta de tabela Markdown ou Word",
                                "Papers comparativos sobre arquiteturas"
                              ],
                              "tips": "Use escalas qualitativas como 'alta/baixa eficiência' para comparações.",
                              "learningObjective": "Avaliar forças e fraquezas para escolhas arquiteturais.",
                              "commonMistakes": [
                                "Superestimar MISD; enfatize sua raridade prática."
                              ]
                            },
                            {
                              "stepNumber": 5,
                              "title": "Discutir Relevância para Programação Paralela Contemporânea",
                              "subSteps": [
                                "Relacione com OpenMP/MPI: MIMD dominante.",
                                "SIMD em shaders e ML (Tensor cores).",
                                "SISD como baseline em single-thread.",
                                "Debata hibridismo moderno (ex: CPUs com SIMD + MIMD).",
                                "Preveja tendências: mais MIMD/SIMD em edge computing."
                              ],
                              "verification": "Escreva um parágrafo conectando cada classe a uma ferramenta moderna.",
                              "estimatedTime": "1 hora",
                              "materials": [
                                "Documentação OpenMP, MPI",
                                "Artigos sobre programação paralela atual"
                              ],
                              "tips": "Pense em como CUDA usa SIMD dentro de MIMD.",
                              "learningObjective": "Aplicar taxonomia a contextos atuais de programação.",
                              "commonMistakes": [
                                "Desconsiderar evoluções; taxonomia ainda guia designs híbridos."
                              ]
                            }
                          ],
                          "practicalExample": "Compare SISD (execução single-thread em um app Python sequencial) vs. SIMD (vetorização NumPy para processamento de imagem) vs. MIMD (multi-threading com multiprocessing para simulação paralela), medindo speedup em um benchmark simples de multiplicação de matrizes.",
                          "finalVerifications": [
                            "Crie e explique uma tabela comparativa completa das 4 classes.",
                            "Identifique corretamente hardware/aplicações para cada classe.",
                            "Liste 2 vantagens e 2 limitações por classe sem erros.",
                            "Discuta como MIMD domina HPC moderno.",
                            "Resolva um quiz com 10 perguntas sobre diferenças.",
                            "Explique taxonomia para um 'não-especialista' em 5 minutos."
                          ],
                          "assessmentCriteria": [
                            "Precisão nas definições e classificações de paralelismo (30%)",
                            "Profundidade em exemplos hardware/aplicações (25%)",
                            "Análise equilibrada de vantagens/limitações (20%)",
                            "Conexões relevantes à programação paralela atual (15%)",
                            "Clareza e organização na tabela/comparação final (10%)"
                          ],
                          "crossCurricularConnections": [
                            "Arquitetura de Computadores: Mapeamento direto a designs de CPU/GPU.",
                            "Programação: Uso em OpenMP, CUDA, MPI.",
                            "Inteligência Artificial: SIMD em processamento de tensores para ML.",
                            "Engenharia de Software: Escolha de modelos para escalabilidade.",
                            "Sistemas Distribuídos: MIMD em cloud computing."
                          ],
                          "realWorldApplication": "No design de supercomputadores como Frontier (MIMD com SIMD subunits), programadores usam essa comparação para otimizar workloads HPC em simulações climáticas ou drug discovery, escolhendo arquiteturas que maximizam throughput enquanto gerenciam overhead de sincronização."
                        },
                        "estimatedTime": "1 hora",
                        "difficulty": "intermediate",
                        "status": "not_started",
                        "prerequisites": [
                          "10.1.1.1.1",
                          "10.1.1.1.2",
                          "10.1.1.1.3",
                          "10.1.1.1.4",
                          "10.1.1.1.5"
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.2",
                    "name": "Modelos de Memória Compartilhada",
                    "description": "Características e princípios de programação em sistemas com memória acessível por todos os processadores.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.2.1",
                        "name": "Características dos Sistemas de Memória Compartilhada",
                        "description": "Entender as propriedades fundamentais dos sistemas onde todos os processadores acessam uma memória global comum, incluindo modelos UMA (Uniform Memory Access) e NUMA (Non-Uniform Memory Access).",
                        "specificSkills": [
                          {
                            "id": "10.1.1.2.1.1",
                            "name": "Identificar modelos UMA e NUMA",
                            "description": "Diferenciar entre arquiteturas UMA, onde o acesso à memória é uniforme para todos os processadores, e NUMA, onde o tempo de acesso varia com a proximidade do processador à memória local.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos básicos de memória compartilhada",
                                  "subSteps": [
                                    "Estude a definição de sistemas de memória compartilhada em programação paralela.",
                                    "Identifique os desafios de acesso à memória em arquiteturas multi-processador.",
                                    "Revise a taxonomia de Flynn para contextualizar modelos de memória.",
                                    "Analise diagramas genéricos de memória compartilhada.",
                                    "Anote as diferenças entre memória local e remota."
                                  ],
                                  "verification": "Resuma em 3 frases os conceitos básicos e compartilhe com um colega para feedback.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Diagrama da Taxonomia de Flynn (impresso ou online)",
                                    "Artigo introdutório sobre memória compartilhada"
                                  ],
                                  "tips": "Use analogias como 'trânsito em uma cidade' para visualizar acessos concorrentes à memória.",
                                  "learningObjective": "Entender o papel da memória compartilhada em sistemas paralelos.",
                                  "commonMistakes": [
                                    "Confundir memória compartilhada com distribuída",
                                    "Ignorar o impacto da latência no desempenho"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o modelo UMA (Uniform Memory Access)",
                                  "subSteps": [
                                    "Defina UMA: acesso uniforme a toda memória por todos os processadores.",
                                    "Descreva hardware típico: barramento compartilhado ou crossbar.",
                                    "Simule tempos de acesso idênticos em um diagrama simples.",
                                    "Liste vantagens: simplicidade de programação e escalabilidade limitada.",
                                    "Identifique limitações: gargalos em barramentos compartilhados."
                                  ],
                                  "verification": "Desenhe um diagrama de UMA e rotule os componentes principais.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramenta de desenho como Draw.io",
                                    "Vídeo explicativo sobre UMA (YouTube ou Khan Academy)"
                                  ],
                                  "tips": "Pense em UMA como uma 'sala de aula com quadro único acessível por todos igualmente'.",
                                  "learningObjective": "Descrever características e hardware do modelo UMA.",
                                  "commonMistakes": [
                                    "Achar que UMA escala indefinidamente",
                                    "Confundir com cache coherence"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar o modelo NUMA (Non-Uniform Memory Access)",
                                  "subSteps": [
                                    "Defina NUMA: memória local rápida e remota mais lenta.",
                                    "Descreva topologias: nós com processadores e memória local interconectados.",
                                    "Calcule tempos de acesso aproximados (local vs remoto).",
                                    "Liste otimizações: alocação de afinidade de memória.",
                                    "Compare escalabilidade com UMA."
                                  ],
                                  "verification": "Crie uma tabela comparando tempos de acesso em NUMA.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Simulador NUMA online (ex: gem5 simulator demo)",
                                    "Diagrama NUMA de supercomputadores"
                                  ],
                                  "tips": "Visualize NUMA como 'cidades conectadas por estradas': local é rápido, interestadual é lento.",
                                  "learningObjective": "Explicar variações de latência e otimizações no modelo NUMA.",
                                  "commonMistakes": [
                                    "Ignorar o impacto da topologia na performance",
                                    "Confundir NUMA com COMA"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Diferenciar e identificar UMA e NUMA",
                                  "subSteps": [
                                    "Crie uma tabela de comparação: hardware, latência, escalabilidade, programação.",
                                    "Analise diagramas mistos e classifique como UMA ou NUMA.",
                                    "Discuta cenários reais: quando usar cada um.",
                                    "Pratique com perguntas: 'Qual modelo em um servidor dual-socket?'",
                                    "Resolva exercícios de identificação."
                                  ],
                                  "verification": "Responda corretamente a 5 perguntas de identificação em um quiz.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Tabela comparativa em Excel/Google Sheets",
                                    "Quiz online sobre modelos de memória"
                                  ],
                                  "tips": "Foquem em 'uniforme vs não-uniforme' como critério chave de diferenciação.",
                                  "learningObjective": "Diferenciar UMA e NUMA com base em características observáveis.",
                                  "commonMistakes": [
                                    "Generalizar UMA como obsoleto",
                                    "Não considerar híbridos modernos"
                                  ]
                                }
                              ],
                              "practicalExample": "Examine o diagrama de um servidor Intel Xeon multi-socket: identifique nós NUMA pela memória local de cada CPU e compare com um sistema UMA antigo como SGI Origin, simulando acessos locais (10ns) vs remotos (100ns).",
                              "finalVerifications": [
                                "Explicar verbalmente a diferença principal entre UMA e NUMA.",
                                "Identificar corretamente UMA/NUMA em 3 diagramas fornecidos.",
                                "Calcular impacto de latência NUMA em um exemplo simples.",
                                "Listar 2 vantagens e 2 desvantagens de cada modelo.",
                                "Aplicar conceito a um hardware real (ex: seu PC).",
                                "Criar um fluxograma de identificação."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de UMA e NUMA (80% correto).",
                                "Capacidade de diagramar ambos os modelos.",
                                "Compreensão de implicações em performance paralela.",
                                "Identificação correta em cenários variados.",
                                "Uso correto de terminologia técnica.",
                                "Demonstração de otimizações NUMA."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Estudo de barramentos e interconexões.",
                                "Sistemas Operacionais: Gerenciamento de memória e scheduling NUMA-aware.",
                                "Programação Paralela: OpenMP com afinidade de threads.",
                                "Redes de Computadores: Latência em topologias de nós.",
                                "Engenharia de Software: Design de aplicações escaláveis."
                              ],
                              "realWorldApplication": "Em supercomputadores como o Fugaku (NUMA para escalar milhares de núcleos) ou servidores cloud AWS (otimizações NUMA para reduzir latência em bancos de dados paralelos), permitindo alta performance em big data e IA."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.1.2",
                            "name": "Explicar princípios de consistência de memória",
                            "description": "Descrever os modelos de consistência sequencial, forte e fraca, e suas implicações para a programação paralela em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos de Consistência de Memória",
                                  "subSteps": [
                                    "Defina consistência de memória como a propriedade que garante que atualizações em uma localização de memória sejam visíveis para todas as threads de forma previsível.",
                                    "Explique a importância em sistemas de memória compartilhada para evitar condições de corrida e comportamentos indefinidos.",
                                    "Discuta o trade-off entre consistência forte (mais segura, mas lenta) e fraca (mais rápida, mas complexa).",
                                    "Identifique cenários onde violações de consistência causam bugs em programação paralela.",
                                    "Revise o modelo sequencial de execução como base para comparações."
                                  ],
                                  "verification": "Escreva uma definição clara de consistência de memória e liste 2 exemplos de problemas causados por sua ausência.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro 'Programming Massively Parallel Processors' de Kirk e Hwu (Capítulo 5)",
                                    "Artigo 'Memory Consistency Models' da Intel Developer Zone"
                                  ],
                                  "tips": "Use analogias como 'tráfego de dados' para visualizar visibilidade entre threads.",
                                  "learningObjective": "Entender o conceito básico e sua relevância em programação paralela.",
                                  "commonMistakes": "Confundir consistência de memória com atomicidade de operações."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Modelo de Consistência Sequencial",
                                  "subSteps": [
                                    "Descreva consistência sequencial como uma execução que parece uma permutação serial total das operações de todas as threads.",
                                    "Ilustre com um diagrama de operações de leitura/escrita em múltiplas threads.",
                                    "Explique que preserva a ordem intra-thread, mas permite reordenação inter-thread.",
                                    "Compare com execução serial para destacar semelhanças e diferenças.",
                                    "Implemente um exemplo simples em pseudocódigo para demonstrar conformidade."
                                  ],
                                  "verification": "Crie um diagrama mostrando uma execução sequencial válida para 2 threads.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Documentação OpenMP sobre memória",
                                    "Ferramenta online como Memory Consistency Visualizer"
                                  ],
                                  "tips": "Pense em consistência sequencial como 'embaralhamento de baralho onde cada jogador mantém sua ordem'.",
                                  "learningObjective": "Dominar a definição e características da consistência sequencial.",
                                  "commonMistakes": "Assumir que ordem global é preservada; ela só é intra-thread."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Consistência Forte (Linearizabilidade)",
                                  "subSteps": [
                                    "Defina consistência forte como uma execução onde existe uma ordem total linear que respeita todas as operações reais.",
                                    "Diferencie de sequencial: forte requer um ponto linearizável único por operação.",
                                    "Discuta hardware support como fences e barriers.",
                                    "Exemplo: Como locks mutex fornecem consistência forte.",
                                    "Liste vantagens (simplicidade) e desvantagens (overhead de performance)."
                                  ],
                                  "verification": "Explique em 3 frases como uma operação de lock garante consistência forte.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Paper 'Linearizability: A Correctness Condition for Concurrent Objects' de Herlihy e Wing",
                                    "Código exemplo em C++ com std::mutex"
                                  ],
                                  "tips": "Visualize como uma 'fila única' onde cada operação tem um timestamp global.",
                                  "learningObjective": "Compreender consistência forte e seu uso em sincronização.",
                                  "commonMistakes": "Confundir com consistência sequencial; forte é mais restritiva."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Investigar Consistência Fraca e Relaxada",
                                  "subSteps": [
                                    "Descreva consistência fraca como visibilidade eventual ou por ordem de programa.",
                                    "Explique modelos como Total Store Order (TSO) e variantes (PC, PSO).",
                                    "Compare com forte/sequencial em termos de performance e complexidade.",
                                    "Exemplo: Cache coherence protocols como MESI implementando relaxações.",
                                    "Discuta quando usar: em aplicações de alto throughput como big data."
                                  ],
                                  "verification": "Liste 3 diferenças chave entre consistência fraca e forte, com exemplos.",
                                  "estimatedTime": "55 minutos",
                                  "materials": [
                                    "ARM Architecture Reference Manual (seção de memória)",
                                    "Vídeo 'Weak Memory Models' no YouTube por Jeff Preshing"
                                  ],
                                  "tips": "Lembre: fraca otimiza performance sacrificando intuição programador.",
                                  "learningObjective": "Diferenciar modelos fracos e suas trade-offs.",
                                  "commonMistakes": "Ignorar necessidade de fences em modelos fracos."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar Implicações na Programação Paralela",
                                  "subSteps": [
                                    "Analise como escolher modelo baseado em hardware (x86 vs ARM).",
                                    "Discuta ferramentas de debugging como ThreadSanitizer para detectar violações.",
                                    "Implemente código paralelo corrigindo inconsistências.",
                                    "Compare performance em benchmarks simples.",
                                    "Resuma guidelines para programação segura em memória compartilhada."
                                  ],
                                  "verification": "Escreva um snippet de código paralelo que exija fence para consistência correta.",
                                  "estimatedTime": "70 minutos",
                                  "materials": [
                                    "Compilador GCC com -fopenmp",
                                    "Exemplos de código no GitHub: 'memory-models-examples'"
                                  ],
                                  "tips": "Sempre teste em múltiplas arquiteturas para expor diferenças.",
                                  "learningObjective": "Integrar conhecimentos para programação prática.",
                                  "commonMistakes": "Assumir portabilidade sem considerar modelo de memória do hardware."
                                }
                              ],
                              "practicalExample": "Em um programa OpenMP com 4 threads atualizando um array compartilhado: Thread 1 escreve em índice 0, Thread 2 lê. Sem consistência sequencial, Thread 2 pode ver valor antigo apesar de sincronização aparente. Adicione #pragma omp barrier para forçar visibilidade.",
                              "finalVerifications": [
                                "Defina corretamente os três modelos de consistência com exemplos.",
                                "Desenhe um diagrama de execução inválida para consistência forte.",
                                "Explique trade-offs de performance entre modelos fraco e forte.",
                                "Identifique necessidade de sincronização em um código dado.",
                                "Compare implicações em x86 vs ARM.",
                                "Liste 3 ferramentas para depuração de inconsistências."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições (90% correto).",
                                "Uso correto de terminologia técnica.",
                                "Capacidade de ilustrar com diagramas ou código.",
                                "Análise clara de trade-offs e implicações.",
                                "Exemplos práticos relevantes e acionáveis.",
                                "Compreensão de diferenças hardware-dependentes.",
                                "Estrutura lógica na explicação."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Cache coherence e protocolos MESI/MOESI.",
                                "Sistemas Operacionais: Sincronização de threads e mutexes.",
                                "Bancos de Dados: Consistência em transações distribuídas (ACID vs BASE).",
                                "Inteligência Artificial: Paralelismo em treinamento de modelos de ML.",
                                "Engenharia de Software: Design de APIs thread-safe."
                              ],
                              "realWorldApplication": "Em servidores web como Apache ou Nginx com worker threads compartilhando cache de sessões; uso de consistência sequencial garante que atualizações de usuário sejam visíveis imediatamente, evitando erros em e-commerces de alto tráfego."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.1.3",
                            "name": "Comparar com memória distribuída",
                            "description": "Contrastar os modelos de memória compartilhada com memória distribuída, destacando vantagens como simplicidade de programação e desafios como contenção.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar características da memória compartilhada",
                                  "subSteps": [
                                    "Identifique as principais características: acesso unificado à memória por todos os processadores.",
                                    "Liste modelos como UMA (Uniform Memory Access) e NUMA (Non-Uniform Memory Access).",
                                    "Descreva vantagens iniciais: simplicidade de programação com threads compartilhando dados.",
                                    "Anote desafios: contenção de cache, sincronização (mutex, semáforos).",
                                    "Registre exemplos de APIs: OpenMP, Pthreads."
                                  ],
                                  "verification": "Crie um mapa mental ou tabela resumindo 4 características chave com exemplos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Slides ou notas sobre Taxonomia de Flynn e Memória Compartilhada",
                                    "Documentação OpenMP"
                                  ],
                                  "tips": "Use diagramas para visualizar o barramento de memória compartilhado.",
                                  "learningObjective": "Compreender os fundamentos da memória compartilhada para basear a comparação.",
                                  "commonMistakes": [
                                    "Confundir com memória distribuída prematuramente",
                                    "Ignorar diferenças UMA/NUMA"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Revisar características da memória distribuída",
                                  "subSteps": [
                                    "Defina memória distribuída: cada processador tem sua própria memória local, sem compartilhamento direto.",
                                    "Descreva comunicação via mensagens (MPI: send/receive).",
                                    "Liste vantagens: escalabilidade horizontal, ausência de contenção centralizada.",
                                    "Anote desafios: latência de rede, complexidade de programação (gerenciar dados remotos).",
                                    "Exemplifique com clusters e APIs como MPI."
                                  ],
                                  "verification": "Elabore uma tabela comparativa inicial com 3 características de cada modelo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI",
                                    "Vídeos sobre programação distribuída"
                                  ],
                                  "tips": "Pense em nós de rede para visualizar a ausência de memória global.",
                                  "learningObjective": "Dominar os pilares da memória distribuída como contraponto.",
                                  "commonMistakes": [
                                    "Subestimar overhead de comunicação",
                                    "Confundir com memória hierárquica"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Contrastar vantagens e desvantagens",
                                  "subSteps": [
                                    "Compare simplicidade: compartilhada é mais intuitiva para tarefas pequenas (ex: loops paralelos).",
                                    "Analise contenção na compartilhada vs. latência na distribuída.",
                                    "Discuta escalabilidade: distribuída para milhares de nós, compartilhada limitada por hardware.",
                                    "Avalie custo: compartilhada requer hardware caro (SMP), distribuída usa commodities.",
                                    "Sintetize em prós/contras: simplicidade vs. performance em larga escala."
                                  ],
                                  "verification": "Redija um parágrafo contrastando uma vantagem e um desafio de cada modelo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Artigos comparativos Flynn/Memória",
                                    "Ferramenta de tabela (Excel/Google Sheets)"
                                  ],
                                  "tips": "Use balança de prós/contras para equilibrar a análise.",
                                  "learningObjective": "Identificar trade-offs claros entre os modelos.",
                                  "commonMistakes": [
                                    "Generalizar sem contexto de escala",
                                    "Omitir sincronização na compartilhada"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar comparação em cenários práticos",
                                  "subSteps": [
                                    "Selecione um problema (ex: soma de matriz) e esboce soluções em cada modelo.",
                                    "Avalie quando escolher compartilhada (pequenos dados, baixa latência).",
                                    "Avalie distribuída (big data, clusters).",
                                    "Crie tabela final de decisão baseada em critérios: tamanho, custo, performance.",
                                    "Reflita sobre híbridos (ex: Spark com memória distribuída)."
                                  ],
                                  "verification": "Desenvolva um fluxograma de decisão para escolher modelo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Exemplos de código OpenMP/MPI",
                                    "Ferramenta de diagrama (Draw.io)"
                                  ],
                                  "tips": "Teste mentalmente com dados reais para validar.",
                                  "learningObjective": "Aplicar a comparação de forma decisória.",
                                  "commonMistakes": [
                                    "Ignorar overheads reais",
                                    "Não considerar hibridizações modernas"
                                  ]
                                }
                              ],
                              "practicalExample": "Compare um programa OpenMP para soma paralela de vetor (memória compartilhada: threads acessam array global com #pragma omp parallel for) versus MPI (memória distribuída: cada processo soma parte local e usa MPI_Reduce para agregar resultados via rede). Note simplicidade no OpenMP mas contenção em cache vs. escalabilidade MPI mas complexidade de scatter/gather.",
                              "finalVerifications": [
                                "Liste 3 vantagens da memória compartilhada sobre distribuída.",
                                "Explique contenção e como mitigá-la.",
                                "Descreva 2 cenários onde distribuída é superior.",
                                "Crie tabela com 4 trade-offs chave.",
                                "Compare APIs: OpenMP vs. MPI em 3 aspectos.",
                                "Identifique limitações de escalabilidade na compartilhada."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas diferenças arquiteturais (acesso memória/comunicação).",
                                "Profundidade nos trade-offs (simplicidade vs. escalabilidade).",
                                "Uso de exemplos concretos e APIs.",
                                "Clareza na identificação de vantagens/desafios.",
                                "Capacidade de aplicação em cenários reais.",
                                "Ausência de confusões conceituais (ex: UMA vs. mensagens)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: latência e protocolos de mensagem (TCP/IP).",
                                "Arquitetura de Computadores: caches e barramentos em SMP.",
                                "Sistemas Operacionais: sincronização e escalonamento de threads/processos.",
                                "Big Data: frameworks como Hadoop/Spark (distribuída).",
                                "Engenharia de Software: padrões de design paralelo/distribuído."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, memória compartilhada é usada em nós SMP para eficiência local, enquanto distribuída conecta nós via InfiniBand para escalar a petaflops; em cloud como AWS, clusters EC2 usam MPI para simulações científicas, evitando contenção de hardware caro."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.2.2",
                        "name": "Decomposição de Domínio em Memória Compartilhada",
                        "description": "Técnica de divisão do problema em subdomínios independentes que compartilham dados via memória global, comum em simulações numéricas.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.2.2.1",
                            "name": "Aplicar decomposição de domínio",
                            "description": "Dividir um problema computacional em domínios espaciais ou funcionais para distribuição entre threads, minimizando comunicações implícitas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar o Problema e Identificar o Domínio",
                                  "subSteps": [
                                    "Examine o problema computacional para entender suas componentes espaciais ou funcionais.",
                                    "Identifique barreiras naturais ou regiões independentes no domínio do problema.",
                                    "Mapeie dependências de dados entre partes do problema.",
                                    "Documente o domínio total (ex.: grade 2D, grafo funcional)."
                                  ],
                                  "verification": "Crie um diagrama do domínio original com dependências marcadas e valide com um colega ou auto-revisão.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Papel e caneta ou ferramenta de diagramação como Draw.io",
                                    "Descrição do problema de exemplo (ex.: multiplicação de matrizes ou simulação N-body)"
                                  ],
                                  "tips": "Comece com problemas familiares para praticar identificação rápida de domínios.",
                                  "learningObjective": "Compreender a estrutura do problema para isolar regiões paralelinizáveis.",
                                  "commonMistakes": "Ignorar dependências sutis que causam races conditions futuras."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Selecionar Estratégia de Decomposição",
                                  "subSteps": [
                                    "Avalie se decomposição espacial (ex.: partição de grade) ou funcional (ex.: pipeline de tarefas) é mais adequada.",
                                    "Considere o modelo de memória compartilhada e custo de sincronização.",
                                    "Calcule granularidade ideal baseada no número de threads disponíveis.",
                                    "Justifique a escolha com análise de balanceamento de carga."
                                  ],
                                  "verification": "Escreva um relatório curto justificando a estratégia escolhida, incluindo prós e contras.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Documentação de OpenMP ou Pthreads",
                                    "Calculadora ou planilha para estimar overheads"
                                  ],
                                  "tips": "Prefira decomposição espacial para problemas regulares como grids; funcional para fluxos irregulares.",
                                  "learningObjective": "Escolher a decomposição ótima minimizando overhead de comunicação.",
                                  "commonMistakes": "Escolher granularidade fina demais, levando a excesso de comunicações."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar a Decomposição em Subdomínios",
                                  "subSteps": [
                                    "Divida o domínio em subdomínios independentes ou com dependências mínimas.",
                                    "Defina fronteiras e pontos de comunicação explícita.",
                                    "Garanta balanceamento de carga entre subdomínios.",
                                    "Ajuste tamanhos para minimizar comunicações implícitas via memória compartilhada."
                                  ],
                                  "verification": "Gere um pseudocódigo ou diagrama mostrando subdomínios e suas interações.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Editor de código (VS Code)",
                                    "Exemplos de código de decomposição em repositórios GitHub"
                                  ],
                                  "tips": "Use halos ou ghost cells em decomposições espaciais para lidar com dependências de vizinhança.",
                                  "learningObjective": "Criar partições que maximizem independência e minimizem sincronizações.",
                                  "commonMistakes": "Criar subdomínios desbalanceados, causando starvation de threads."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Mapear para Threads e Validar Minimização de Comunicações",
                                  "subSteps": [
                                    "Atribua subdomínios a threads usando schedules dinâmicos ou estáticos.",
                                    "Implemente barreiras ou locks apenas onde necessário.",
                                    "Simule ou execute testes para medir comunicações implícitas.",
                                    "Otimize iterativamente reduzindo acessos concorrentes a dados compartilhados."
                                  ],
                                  "verification": "Execute o código com profiler (ex.: gprof) e confirme baixa taxa de comunicações.",
                                  "estimatedTime": "2.5 hours",
                                  "materials": [
                                    "Compilador com suporte a OpenMP (gcc)",
                                    "Profiler de performance (Intel VTune ou gprof)",
                                    "Máquina multi-core"
                                  ],
                                  "tips": "Use private clauses em OpenMP para evitar acessos compartilhados desnecessários.",
                                  "learningObjective": "Implementar mapeamento eficiente que preserve escalabilidade.",
                                  "commonMistakes": "Esquecer de alinhar dados para cache locality, aumentando comunicações cache."
                                }
                              ],
                              "practicalExample": "Em uma simulação de multiplicação de matrizes densas (NxN), decompõe a saída C em blocos espaciais de linhas/colunas atribuídos a threads, usando redução apenas nas bordas para minimizar locks.",
                              "finalVerifications": [
                                "Diagrama da decomposição mostra subdomínios balanceados e dependências mínimas.",
                                "Pseudocódigo implementa distribuição sem comunicações implícitas excessivas.",
                                "Teste em 4 threads mostra speedup linear próximo de ideal.",
                                "Análise de profiler confirma <10% do tempo em sincronizações.",
                                "Explicação verbal cobre trade-offs de granularidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de domínios independentes (80% cobertura).",
                                "Efetividade na minimização de comunicações (medida por profiler).",
                                "Balanceamento de carga entre threads (<20% variação).",
                                "Escalabilidade demonstrada em diferentes números de threads.",
                                "Documentação clara de justificativas e otimizações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Teoria de grafos para modelar dependências.",
                                "Física: Decomposição em simulações numéricas de PDEs.",
                                "Engenharia de Software: Princípios de design modular e paralelismo.",
                                "Análise de Dados: Particionamento em big data frameworks como Spark."
                              ],
                              "realWorldApplication": "Aplicado em simulações CFD (Computational Fluid Dynamics) para dividir malhas 3D entre núcleos de supercomputadores, acelerando previsões meteorológicas e design automotivo."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.2.2",
                            "name": "Gerenciar dependências de dados",
                            "description": "Identificar e resolver dependências entre subdomínios em memória compartilhada, usando regiões fantasma ou overlap para atualizações.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar Dependências de Dados entre Subdomínios",
                                  "subSteps": [
                                    "Analise o algoritmo sequencial para mapear acessos de memória e padrões de vizinhança (stencil).",
                                    "Divida o domínio em subdomínios paralelos e identifique bordas adjacentes.",
                                    "Classifique dependências como leitura-leitura, leitura-escrita ou escrita-escrita nas interfaces.",
                                    "Desenhe um diagrama de dependência destacando regiões de overlap necessárias.",
                                    "Documente o raio de dependência (ex: 1 para 5-point stencil em 2D)."
                                  ],
                                  "verification": "Criar e validar um diagrama de stencil mostrando dependências para uma grade 2D de 10x10.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código fonte sequencial (ex: Jacobi iteration em C)",
                                    "Papel e lápis ou ferramenta de diagrama como Draw.io"
                                  ],
                                  "tips": "Sempre considere o pior caso de stencil para definir o overlap mínimo.",
                                  "learningObjective": "Compreender origens e tipos de dependências de dados em decomposições de domínio.",
                                  "commonMistakes": "Subestimar dependências diagonais ou em stencils assimétricos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Projetar Regiões Fantasma ou Overlap",
                                  "subSteps": [
                                    "Determine a largura do overlap baseada no raio máximo do stencil (ex: raio 1 = overlap 1).",
                                    "Defina o layout de memória para arrays expandidos em cada subdomínio (interior + ghosts).",
                                    "Calcule tamanhos de buffers de comunicação para cada direção (norte, sul, leste, oeste).",
                                    "Planeje topologia de vizinhos para trocas não-bloqueantes.",
                                    "Esboce pseudocódigo para alocação dinâmica de arrays com ghosts."
                                  ],
                                  "verification": "Implementar alocação de array 2D expandido e imprimir dimensões para confirmação.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador C/C++ com OpenMP ou MPI",
                                    "Editor de código (VS Code)",
                                    "Grade de teste 20x20"
                                  ],
                                  "tips": "Use índices offset para ghosts (ex: array[0..N+2] onde 1 a N é interior).",
                                  "learningObjective": "Projetar estruturas de dados que eliminam dependências remotas via overlap local.",
                                  "commonMistakes": "Definir overlap insuficiente levando a acessos inválidos fora do subdomínio."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Troca de Dados nas Regiões Fantasma (Halo Exchange)",
                                  "subSteps": [
                                    "Implemente cópias de bordas de destino para buffers de envio.",
                                    "Execute trocas síncronas ou assíncronas com vizinhos (MPI_Sendrecv ou OpenMP barriers).",
                                    "Atualize regiões fantasma com dados recebidos de vizinhos.",
                                    "Adicione verificações de fronteira para evitar overflows.",
                                    "Teste troca em uma grade pequena com valores conhecidos."
                                  ],
                                  "verification": "Executar halo exchange e verificar que ghosts correspondem a vizinhos via inspeção de dump de memória.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Biblioteca MPI ou OpenMP",
                                    "Código base do step 2",
                                    "Debugger (GDB)"
                                  ],
                                  "tips": "Prefira trocas não-bloqueantes em clusters para overlap com computação.",
                                  "learningObjective": "Implementar comunicação eficiente para resolver dependências de dados.",
                                  "commonMistakes": "Ordem errada de cópia/atualização causando dados obsoletos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar Atualizações e Validar Correção",
                                  "subSteps": [
                                    "Atualize apenas o interior do subdomínio usando stencil sobre ghosts atualizados.",
                                    "Implemente múltiplas iterações e compare com versão sequencial.",
                                    "Meça speedup e verifique convergência idêntica.",
                                    "Otimize reduzindo overlap onde possível ou usando packing de mensagens.",
                                    "Profile comunicação vs computação para gargalos."
                                  ],
                                  "verification": "Rodar 100 iterações e assertar erro <1e-10 vs sequencial.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código integrado dos steps anteriores",
                                    "Ferramenta de profiling (gprof ou TAU)",
                                    "Grade 100x100"
                                  ],
                                  "tips": "Use redução de precisão em ghosts se aplicável para economizar banda.",
                                  "learningObjective": "Garantir corretude e performance em gerenciamento de dependências paralelas.",
                                  "commonMistakes": "Race conditions em atualizações simultâneas sem sincronização adequada."
                                }
                              ],
                              "practicalExample": "Em uma simulação Jacobi 2D para equação de calor em grade 128x128 dividida em 4x4 subdomínios (32x32 cada), use overlap de 1 célula. Cada subdomínio troca halos 32x2 células com 4 vizinhos antes de atualizar interior, alcançando speedup de 12x em 16 cores.",
                              "finalVerifications": [
                                "Diagrama de dependências cobre todos acessos do stencil.",
                                "Arrays ghosts são corretamente populados pós-troca.",
                                "Atualizações paralelas produzem resultados idênticos ao sequencial (erro L2 < 1e-12).",
                                "Tempo de comunicação < 20% do total em grade moderada.",
                                "Nenhuma violação de bounds ou race condition detectada via Valgrind."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de raio de dependência (100%).",
                                "Eficiência do halo exchange (overhead < 25%).",
                                "Correção numérica comprovada por testes unitários.",
                                "Escalabilidade demonstrada em 2-16 threads/processos.",
                                "Documentação clara de design e otimizações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Numérica: Estabilidade de métodos em grade com condições de contorno.",
                                "Algoritmos Paralelos: Balanceamento de carga e minimização de comunicação.",
                                "Engenharia de Software: Abstrações para decompositores de domínio.",
                                "Física Computacional: Modelos PDE em malhas distribuídas.",
                                "Análise de Performance: Modelos de custo em arquiteturas NUMA."
                              ],
                              "realWorldApplication": "Em simulações CFD como NAS Parallel Benchmarks ou modelagem climática (ex: CESM), onde domínios globais são decompostos em milhares de subdomínios com halos para resolver equações Navier-Stokes em supercomputadores."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.2.3",
                            "name": "Implementar em pseudocódigo",
                            "description": "Escrever pseudocódigo para um exemplo de decomposição de domínio em um problema como multiplicação de matrizes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender a Multiplicação de Matrizes Sequencial e Identificar Dependências",
                                  "subSteps": [
                                    "Revise o algoritmo sequencial para multiplicação de matrizes A (N x N) e B (N x N) resultando em C (N x N), onde c[i][j] = soma de a[i][k] * b[k][j] para k=0 a N-1.",
                                    "Identifique dependências de dados: cada elemento c[i][j] depende apenas da linha i de A e coluna j de B, sem dependências entre elementos de C.",
                                    "Anote oportunidades de paralelismo: linhas de C podem ser computadas independentemente.",
                                    "Desenhe um diagrama simples das matrizes destacando divisões potenciais por threads.",
                                    "Calcule o tempo sequencial aproximado: O(N^3) operações."
                                  ],
                                  "verification": "Confirme que você pode escrever o pseudocódigo sequencial corretamente e listar pelo menos 3 dependências/ independências.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Papel e caneta ou editor de texto para pseudocódigo sequencial; matrizes de exemplo 4x4.",
                                  "tips": "Use índices explícitos para visualizar dependências; teste com matrizes pequenas manualmente.",
                                  "learningObjective": "Compreender o problema base para identificar pontos de paralelismo em decomposição de domínio.",
                                  "commonMistakes": "Confundir dependências de linha/coluna; ignorar que soma interna é sequencial mas externa pode paralelizar."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Escrever Pseudocódigo para o Programa Principal",
                                  "subSteps": [
                                    "Inclua declaração de matrizes A, B, C como compartilhadas (memória compartilhada).",
                                    "Inicialize A e B com dados de exemplo.",
                                    "Crie P threads, passando thread_id t, start_row e end_row como parâmetros.",
                                    "Inclua barreira ou join para sincronizar threads após computação.",
                                    "Escreva loop principal: for t=0 to P-1 { start_row = t*(N/P); end_row = (t+1)*(N/P); create_thread(worker, t, start_row, end_row) }.",
                                    "Após join, imprima C para verificação."
                                  ],
                                  "verification": "Simule execução mental para P=2, N=4; confirme que todas linhas são cobertas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Editor de texto para pseudocódigo; conhecimento de sintaxe de threads (ex: pthread_create).",
                                  "tips": "Use pseudocódigo genérico, não linguagem específica; destaque seções compartilhadas.",
                                  "learningObjective": "Estruturar o orquestrador que aloca tarefas em memória compartilhada.",
                                  "commonMistakes": "Esquecer join/barreira; calcular índices errados (off-by-one)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Escrever Pseudocódigo para a Função Worker/Thread",
                                  "subSteps": [
                                    "Defina função worker(thread_id, start_row, end_row, N, A, B, C).",
                                    "Para i = start_row to end_row-1: para j=0 to N-1: c[i][j] = 0; para k=0 to N-1: c[i][j] += a[i][k] * b[k][j].",
                                    "Garanta acesso seguro: sem locks necessários pois cada thread escreve linhas exclusivas de C.",
                                    "Adicione debug: imprima 'Thread t computou linhas i_start a i_end'.",
                                    "Retorne após computação."
                                  ],
                                  "verification": "Verifique se worker cobre exatamente suas linhas atribuídas e usa dados compartilhados corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Editor de texto; matrizes de teste.",
                                  "tips": "Inicialize c[i][j]=0 dentro do loop de i para evitar lixo.",
                                  "learningObjective": "Implementar lógica paralela independente em cada thread.",
                                  "commonMistakes": "Acessar linhas erradas; adicionar locks desnecessários (overhead)."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Refinar o Pseudocódigo Completo",
                                  "subSteps": [
                                    "Combine principal e worker em um pseudocódigo unificado.",
                                    "Simule com N=2, P=2: calcule C manualmente e compare com saída simulada.",
                                    "Adicione comentários sobre escalabilidade: speedup ideal ~P.",
                                    "Discuta limitações: overhead de threads, cache locality em memória compartilhada.",
                                    "Otimize se possível: block tiling para melhor locality (opcional)."
                                  ],
                                  "verification": "Pseudocódigo roda sem erros lógicos em simulação manual; C correto.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Calculadora ou planilha para multiplicação manual.",
                                  "tips": "Teste edge cases: P=1 (sequencial), P=N.",
                                  "learningObjective": "Garantir corretude e completude da implementação paralela.",
                                  "commonMistakes": "Índices off-by-one em end_row; não inicializar C."
                                }
                              ],
                              "practicalExample": "Pseudocódigo para multiplicar A[4x4] e B[4x4] com P=2 threads: Thread 0 computa linhas 0-1 de C; Thread 1 computa linhas 2-3. Exemplo: A=[[1,2],[3,4]] (N=2), B similar, C calculado em paralelo sem conflitos.",
                              "finalVerifications": [
                                "Pseudocódigo cobre todas linhas de C sem sobreposição ou lacunas.",
                                "Cada thread acessa apenas suas linhas de escrita em C.",
                                "Leitura de A e B é compartilhada e thread-safe.",
                                "Sincronização via join garante completude antes de output.",
                                "Simulação manual com N=4 produz C correto.",
                                "Comentários explicam decomposição de domínio claramente."
                              ],
                              "assessmentCriteria": [
                                "Corretude: Decomposição cobre domínio inteiro sem race conditions.",
                                "Clareza: Títulos de steps, substeps e pseudocódigo legíveis.",
                                "Detalhamento: Substeps acionáveis com 3-5 itens por step.",
                                "Eficiência: Paralelismo aproveita independência de linhas.",
                                "Completude: Inclui inicialização, worker, principal e verificação.",
                                "Realismo: Considera modelo de memória compartilhada."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e propriedades de multiplicação de matrizes.",
                                "Algoritmos: Análise de complexidade O(N^3/P) vs sequencial.",
                                "Sistemas Operacionais: Gerenciamento de threads e sincronização.",
                                "Engenharia de Software: Modularidade em funções worker."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática com grandes matrizes), processamento de imagens (filtros convolucionais paralelizáveis) ou machine learning (multiplicações em redes neurais) usando bibliotecas como OpenMP ou pthread para aceleração em multi-core."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.2.3",
                        "name": "Exclusão Mútua e Sincronização",
                        "description": "Mecanismos para coordenar acesso concorrente a recursos compartilhados, evitando condições de corrida e garantindo atomicidade.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.2.3.1",
                            "name": "Implementar locks para exclusão mútua",
                            "description": "Usar primitivas como mutex (mutual exclusion) para proteger seções críticas em código paralelo, demonstrando com exemplos em threads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Exclusão Mútua e Seções Críticas",
                                  "subSteps": [
                                    "Estude o que é uma seção crítica: código que acessa recursos compartilhados.",
                                    "Identifique race conditions em exemplos simples de threads sem sincronização.",
                                    "Aprenda primitivas de sincronização: foco em mutex (lock e unlock).",
                                    "Analise requisitos de locks: mutual exclusion, progress e bounded waiting.",
                                    "Revise modelo de memória compartilhada em programação paralela."
                                  ],
                                  "verification": "Explique em suas palavras os 3 requisitos de um bom lock e dê um exemplo de race condition.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação de pthreads (man pthread_mutex_init)",
                                    "Exemplos de código sem sincronização (GitHub ou livros como 'Programming with POSIX Threads')"
                                  ],
                                  "tips": "Use diagramas de execução de threads para visualizar race conditions.",
                                  "learningObjective": "Dominar fundamentos teóricos para justificar o uso de mutex.",
                                  "commonMistakes": [
                                    "Confundir mutex com semáforos",
                                    "Ignorar bounded waiting",
                                    "Achar que sleep resolve race conditions"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente e Inicializar Mutex",
                                  "subSteps": [
                                    "Instale bibliotecas de threads (ex: pthreads no Linux com gcc -pthread).",
                                    "Crie um programa base com múltiplas threads (pthread_create).",
                                    "Inicialize mutex: pthread_mutex_init(&mutex, NULL).",
                                    "Compile e execute programa básico para verificar threads rodando em paralelo.",
                                    "Teste destruição: pthread_mutex_destroy no final."
                                  ],
                                  "verification": "Programa compila e roda threads sem erros de segmentação; mutex é inicializado e destruído.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador GCC com pthread",
                                    "Código template de threads múltiplas"
                                  ],
                                  "tips": "Sempre verifique retornos de pthread_* com errno para erros.",
                                  "learningObjective": "Configurar corretamente primitivas de mutex em código real.",
                                  "commonMistakes": [
                                    "Esquecer -pthread no link",
                                    "Inicializar mutex estático sem PTHREAD_MUTEX_INITIALIZER",
                                    "Não destruir mutex levando a leaks"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Proteção de Seção Crítica com Lock/Unlock",
                                  "subSteps": [
                                    "Crie um recurso compartilhado (ex: contador global).",
                                    "Adicione pthread_mutex_lock(&mutex) antes da seção crítica.",
                                    "Implemente a operação crítica (ex: contador++).",
                                    "Adicione pthread_mutex_unlock(&mutex) imediatamente após.",
                                    "Execute com muitas iterações e threads para testar atomicidade."
                                  ],
                                  "verification": "Contador final é correto (ex: 10000 para 10 threads x 1000 iterações) em múltiplas runs.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código do Step 2",
                                    "Debugger como gdb para threads"
                                  ],
                                  "tips": "Use variáveis atômicas como benchmark, mas foque em mutex para seções longas.",
                                  "learningObjective": "Proteger corretamente seções críticas garantindo exclusão mútua.",
                                  "commonMistakes": [
                                    "Unlock sem lock pareado",
                                    "Lock/unlock fora da seção crítica",
                                    "Variáveis locais em vez de compartilhadas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, Depurar e Analisar Problemas Comuns",
                                  "subSteps": [
                                    "Introduza intencionalmente erros: esqueça unlock para simular deadlock.",
                                    "Use ferramentas como helgrind (Valgrind) para detectar issues de race/lock.",
                                    "Teste starvation: priorize threads e verifique fairness.",
                                    "Otimize com mutex trylock para non-blocking.",
                                    "Documente métricas: tempo de execução com vs sem mutex."
                                  ],
                                  "verification": "Sem deadlocks ou races detectados por ferramentas; código roda consistentemente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Valgrind/Helgrind",
                                    "Timers para performance (gettimeofday)"
                                  ],
                                  "tips": "Rode com strace para ver chamadas de sistema de locks.",
                                  "learningObjective": "Identificar e corrigir falhas em implementações de locks.",
                                  "commonMistakes": [
                                    "Deadlock por locks aninhados sem hierarquia",
                                    "Busy-waiting em vez de unlock",
                                    "Ignorar performance overhead de locks"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um contador global incrementado por 10 threads, cada uma executando 1000 incrementos. Sem mutex, resultado varia (ex: 5432 em vez de 10000). Com mutex: pthread_mutex_lock antes de counter++, unlock após. Compile: gcc -o test -pthread test.c; ./test.",
                              "finalVerifications": [
                                "Código compila e executa sem warnings ou erros de runtime.",
                                "Resultado do contador é sempre exato após múltiplas execuções.",
                                "Nenhuma race condition ou deadlock detectado por Valgrind.",
                                "Mutex é inicializado, usado e destruído corretamente.",
                                "Tempo de execução é mensurável e overhead do lock é observado.",
                                "Explicação escrita de por que o mutex resolve o problema."
                              ],
                              "assessmentCriteria": [
                                "Uso correto e pareado de lock/unlock em todas seções críticas.",
                                "Tratamento de erros em chamadas pthread (checagem de retorno).",
                                "Eficiência: locks só onde necessário, sem nesting desnecessário.",
                                "Testes abrangentes: múltiplas threads e iterações altas.",
                                "Comentários no código explicando escolhas de sincronização.",
                                "Análise de performance e problemas potenciais."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Estudo de primitivas kernel como futex.",
                                "Algoritmos: Comparação com locks não-bloqueantes (CAS).",
                                "Segurança da Informação: Locks em contextos de criptografia multi-thread.",
                                "Engenharia de Software: Padrões de design para thread-safety."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx, locks protegem estruturas de dados compartilhadas (ex: contadores de requests ou caches) acessadas por worker threads, evitando corrupção de dados em alta concorrência."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.3.2",
                            "name": "Aplicar barreiras de sincronização",
                            "description": "Coordenar threads para aguardar conclusão de fases computacionais usando barreiras, explicando overhead e escalabilidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de barreiras de sincronização",
                                  "subSteps": [
                                    "Estude a definição de barreira: ponto onde threads aguardam até que todas cheguem para prosseguir.",
                                    "Analise o funcionamento: contador de chegadas, liberação coletiva ao atingir o número de participantes.",
                                    "Compare com outros mecanismos: diferença para mutex e semáforos (barreiras são para sincronização coletiva).",
                                    "Revise overhead: custo de busy-waiting ou sleeping em implementações.",
                                    "Estude escalabilidade: impacto com número crescente de threads."
                                  ],
                                  "verification": "Resuma em um diagrama ou parágrafo os componentes de uma barreira e suas diferenças com locks.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação de CyclicBarrier (Java) ou pthread_barrier (C)",
                                    "Artigos sobre sincronização paralela"
                                  ],
                                  "tips": "Desenhe um fluxograma com 4 threads chegando à barreira para visualizar.",
                                  "learningObjective": "Explicar o mecanismo de barreiras e seu overhead introdutório.",
                                  "commonMistakes": [
                                    "Confundir com locks (barreiras não protegem seções críticas)",
                                    "Ignorar que barreiras são reutilizáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente e implementar estrutura básica de threads",
                                  "subSteps": [
                                    "Crie um projeto Java com múltiplas threads (ex: 4 threads).",
                                    "Defina fases computacionais simuladas (ex: incremento de contador por thread).",
                                    "Instancie uma CyclicBarrier com número de parties igual ao de threads.",
                                    "Adicione ações de barreira (Runnable) para log de sincronização.",
                                    "Compile e execute sem barreira para observar execução assíncrona."
                                  ],
                                  "verification": "Execute o código sem barreira e confirme que threads terminam em tempos diferentes.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "JDK 8+ ou superior",
                                    "IDE como IntelliJ ou Eclipse",
                                    "Exemplo de código base de threads"
                                  ],
                                  "tips": "Use Thread.sleep() para simular trabalho e destacar assincronia.",
                                  "learningObjective": "Preparar código base para inserção de barreira.",
                                  "commonMistakes": [
                                    "Número de parties incorreto na barreira",
                                    "Threads não chamando await()"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e testar a barreira de sincronização",
                                  "subSteps": [
                                    "Insira barrier.await() no final de cada fase computacional nas threads.",
                                    "Execute com 2-3 fases para observar sincronização múltipla.",
                                    "Adicione logs com timestamps para verificar chegada simultânea pós-barreira.",
                                    "Teste reset() da barreira para reutilização em múltiplas rodadas.",
                                    "Verifique comportamento com uma thread 'lenta' (sleep extra)."
                                  ],
                                  "verification": "Logs mostram que todas threads passam a barreira juntas, independentemente de velocidades individuais.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Código do passo anterior",
                                    "Ferramenta de profiling como VisualVM"
                                  ],
                                  "tips": "Use System.nanoTime() para medir tempo de chegada à barreira.",
                                  "learningObjective": "Aplicar barreira corretamente em código multithread.",
                                  "commonMistakes": [
                                    "Deadlock por número de parties errado",
                                    "Não resetar barreira entre usos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar overhead e escalabilidade",
                                  "subSteps": [
                                    "Meça tempo total com e sem barreira usando nanoTime().",
                                    "Varie número de threads (4, 8, 16) e repita medições (média de 10 runs).",
                                    "Calcule overhead: (tempo_com_barreira - tempo_sem_barreira) / tempo_sem_barreira.",
                                    "Plote gráfico de overhead vs. número de threads.",
                                    "Discuta limitações: busy-waiting em implementações sense-reversing."
                                  ],
                                  "verification": "Gere relatório com tabela de tempos e gráfico mostrando overhead crescente.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Ferramentas de plotagem como Excel ou Python Matplotlib",
                                    "Código otimizado"
                                  ],
                                  "tips": "Aqueça JVM com runs iniciais para medições precisas.",
                                  "learningObjective": "Quantificar e explicar impactos de performance das barreiras.",
                                  "commonMistakes": [
                                    "Medições sem aquecimento ou com GC interferindo",
                                    "Ignorar variância em runs únicas"
                                  ]
                                }
                              ],
                              "practicalExample": "Desenvolva um programa onde 8 threads processam fatias de uma matriz de 1000x1000, aplicando uma iteração de Jacobi (método iterativo). Use barreira para sincronizar após cada iteração global, garantindo que todas threads completem antes da próxima.",
                              "finalVerifications": [
                                "Todas threads chegam à barreira simultaneamente (logs confirmam).",
                                "Programa executa múltiplas rodadas sem deadlocks ou race conditions.",
                                "Overhead medido é <10% para 8 threads e reportado corretamente.",
                                "Escalabilidade testada com variação de threads sem crashes.",
                                "Reset da barreira funciona para reutilização.",
                                "Explicação escrita cobre busy-waiting e alternativas como barriers condicionais."
                              ],
                              "assessmentCriteria": [
                                "Código compila, executa e sincroniza corretamente (sem erros de thread).",
                                "Explicação precisa de mecanismo, overhead e escalabilidade.",
                                "Medições de performance precisas com múltiplas runs e análise estatística.",
                                "Uso correto de await() e reset() em contextos reutilizáveis.",
                                "Identificação de erros comuns como mismatch de parties.",
                                "Diagrama ou gráfico ilustrando sincronização e performance."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos Paralelos: Integração com iterações em métodos como Gauss-Seidel.",
                                "Sistemas Operacionais: Comparação com primitivas kernel como futex.",
                                "Análise de Complexidade: Avaliação de O(n) overhead em barreiras.",
                                "Computação de Alto Desempenho: Uso em MPI_Barrier para clusters.",
                                "Engenharia de Software: Padrões de design para sincronização thread-safe."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (ex: CESM), onde milhares de threads sincronizam fases de computação distribuída em supercomputadores, evitando deriva temporal e garantindo precisão coletiva."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.3.3",
                            "name": "Evitar deadlocks e livelocks",
                            "description": "Detectar e prevenir deadlocks em protocolos de sincronização, usando técnicas como hierarquia de locks ou timeouts.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Deadlock e Livelock",
                                  "subSteps": [
                                    "Defina deadlock como uma situação em que dois ou mais threads estão bloqueados indefinidamente, cada um esperando por um recurso mantido pelo outro, formando um ciclo.",
                                    "Defina livelock como uma condição onde threads respondem ativamente umas às outras, mudando estados repetidamente, mas sem progresso.",
                                    "Diferencie deadlock (congelado) de livelock (ativo mas improdutivo) e starvation (um thread é indefinidamente adiado).",
                                    "Analise exemplos clássicos, como o problema dos filósofos jantando para deadlock.",
                                    "Crie diagramas de dependência para visualizar cenários de deadlock e livelock."
                                  ],
                                  "verification": "Explique em suas palavras, com um diagrama, a diferença entre deadlock e livelock, identificando-os em um exemplo simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Modern Operating Systems' de Tanenbaum (capítulo de sincronização)",
                                    "Vídeos Khan Academy ou YouTube sobre deadlocks",
                                    "Ferramenta de desenho como Draw.io"
                                  ],
                                  "tips": [
                                    "Use analogias cotidianas, como dois carros em uma rua estreita (deadlock).",
                                    "Desenhe sempre fluxogramas para cenários multi-thread."
                                  ],
                                  "learningObjective": "Identificar e diferenciar deadlocks, livelocks e condições relacionadas em contextos de programação paralela.",
                                  "commonMistakes": [
                                    "Confundir livelock com busy-waiting simples.",
                                    "Ignorar que livelocks não envolvem bloqueio, mas atividade contínua."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Condições Necessárias para Deadlock",
                                  "subSteps": [
                                    "Estude as quatro condições de Coffman: exclusão mútua, retenção e espera, não-preempção e espera circular.",
                                    "Para cada condição, crie um exemplo de código em Java ou C++ usando mutexes.",
                                    "Simule como quebrar uma condição previne deadlock.",
                                    "Identifique essas condições em códigos existentes fornecidos.",
                                    "Pratique detectando potenciais deadlocks analisando grafos de recursos."
                                  ],
                                  "verification": "Liste as 4 condições de Coffman e forneça código que viole uma delas intencionalmente, explicando o impacto.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Artigo 'Deadlock Detection' de Silberschatz (Operating System Concepts)",
                                    "Compilador Java/C++ com threads (Eclipse ou VS Code)",
                                    "Ferramenta de visualização de threads como jvisualvm"
                                  ],
                                  "tips": [
                                    "Sempre verifique espera circular primeiro, pois é a mais comum.",
                                    "Use pseudocódigo antes de implementar em linguagem real."
                                  ],
                                  "learningObjective": "Detectar potenciais deadlocks analisando as condições de Coffman em código fonte.",
                                  "commonMistakes": [
                                    "Achar que exclusão mútua é sempre ruim (é necessária para sincronização).",
                                    "Esquecer que todas as 4 condições devem ocorrer simultaneamente."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Prevenção via Hierarquia de Locks",
                                  "subSteps": [
                                    "Aprenda a impor uma ordem global nos locks (ex: por ID de recurso).",
                                    "Refatore código propenso a deadlock para adquirir locks sempre na mesma ordem.",
                                    "Teste com múltiplas threads simulando acessos concorrentes.",
                                    "Implemente em um exemplo de transferências bancárias entre contas.",
                                    "Valide usando ferramentas de detecção de deadlock."
                                  ],
                                  "verification": "Forneça código refatorado que usa hierarquia de locks e rode testes com 10+ threads sem deadlock.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Exemplos de código Java Thread/Mutex (GitHub repos de concurrency)",
                                    "IDE com debugger multi-thread (IntelliJ IDEA)",
                                    "JUnit para testes automatizados"
                                  ],
                                  "tips": [
                                    "Atribua IDs numéricos únicos a todos os recursos lockáveis.",
                                    "Evite locks aninhados desnecessários."
                                  ],
                                  "learningObjective": "Aplicar hierarquia de locks para prevenir esperas circulares em aplicações multi-threaded.",
                                  "commonMistakes": [
                                    "Adquirir locks em ordem inconsistente em diferentes caminhos de código.",
                                    "Ignorar locks recursivos que quebram a hierarquia."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Timeouts e Técnicas de Detecção/Recuperação",
                                  "subSteps": [
                                    "Implemente timeouts em locks (ex: Lock.tryLock com tempo limite em Java).",
                                    "Estude detecção de deadlock via grafo de espera e algoritmos como Banker's.",
                                    "Adicione recuperação: abortar threads em deadlock detectado.",
                                    "Compare livelocks e use yield() ou backoff randômico para resolvê-los.",
                                    "Teste cenários com timeouts para evitar livelocks em busy-waiting."
                                  ],
                                  "verification": "Implemente um sistema com timeouts que detecta e recupera de deadlock simulado, registrando logs.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação Java ReentrantLock (com tryLock)",
                                    "Ferramentas como ThreadMXBean para monitoramento",
                                    "Simulador de deadlocks online (ex: University of Washington tools)"
                                  ],
                                  "tips": [
                                    "Timeouts curtos para livelocks, longos para deadlocks.",
                                    "Log sempre tentativas de lock para depuração."
                                  ],
                                  "learningObjective": "Usar timeouts e detecção dinâmica para lidar com deadlocks e livelocks não preveníveis estaticamente.",
                                  "commonMistakes": [
                                    "Timeouts muito curtos causando falhas prematuras.",
                                    "Não tratar livelocks com randomização em retries."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar e Validar Implementações",
                                  "subSteps": [
                                    "Crie testes de stress com múltiplas threads aleatórias.",
                                    "Use ferramentas como ThreadSanitizer ou Helgrind para detectar races/deadlocks.",
                                    "Analise logs para confirmar ausência de deadlocks/livelocks.",
                                    "Otimize código com métricas de performance (throughput, latência).",
                                    "Documente o design choices em um relatório."
                                  ],
                                  "verification": "Execute testes que passem 1000 iterações sem deadlocks, com relatório de cobertura.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Google Thread Sanitizer (para C++) ou AddressSanitizer",
                                    "JMH para benchmarks Java",
                                    "Scripts de teste em Python (concurrent.futures)"
                                  ],
                                  "tips": [
                                    "Teste cenários edge: alta contenda, falhas de hardware simuladas.",
                                    "Monitore CPU usage para detectar livelocks."
                                  ],
                                  "learningObjective": "Validar robustez de sincronizações contra deadlocks e livelocks em produção-like cenários.",
                                  "commonMistakes": [
                                    "Testes insuficientes (só cenários felizes).",
                                    "Confiar só em debugger manual."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema bancário multi-threaded, Thread1 trava Conta1 e tenta travar Conta2 para transferir $100; Thread2 trava Conta2 e tenta Conta1. Deadlock ocorre. Solução: hierarquia por ID da conta (sempre menor ID primeiro) + timeout de 500ms. Para livelock, threads retry infinitamente em contenda; adicione backoff exponencial.",
                              "finalVerifications": [
                                "Implemente e rode código com 20 threads concorrentes sem deadlocks por 10 minutos.",
                                "Detecte e explique um deadlock induzido em código fornecido.",
                                "Aplique timeout para resolver livelock em busy-wait loop.",
                                "Gere grafo de recursos mostrando ausência de ciclo.",
                                "Documente 3 técnicas usadas e seu impacto em performance.",
                                "Passe testes automatizados de cobertura de 90% em cenários de sincronização."
                              ],
                              "assessmentCriteria": [
                                "Explicação precisa das condições de Coffman (100% corretas).",
                                "Código implementado sem deadlocks detectáveis por ferramentas.",
                                "Uso correto de hierarquia e timeouts com exemplos funcionais.",
                                "Análise de performance pré/pós- implementação (melhoria mensurável).",
                                "Identificação e mitigação de livelocks em cenários ativos.",
                                "Relatório claro com diagramas e logs de testes."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de deadlocks no kernel (ex: Linux futex).",
                                "Bancos de Dados: Deadlock detection em transações SQL (InnoDB).",
                                "Redes: Prevenção de livelocks em protocolos de roteamento (OSPF).",
                                "Engenharia de Software: Design patterns para concurrency (Producer-Consumer).",
                                "Inteligência Artificial: Evitar deadlocks em agentes multi-agentes."
                              ],
                              "realWorldApplication": "Em servidores de alta carga como Apache Tomcat ou bancos de dados PostgreSQL, essas técnicas previnem perdas financeiras por transações travadas, garantindo escalabilidade em aplicações cloud multi-tenant com milhares de requisições/segundo."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.3.4",
                            "name": "Usar semáforos e condvars",
                            "description": "Implementar sincronização avançada com semáforos para contagem de recursos e variáveis de condição para sinalização entre threads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender e Inicializar Semáforos para Contagem de Recursos",
                                  "subSteps": [
                                    "Estude o conceito de semáforo como contador de recursos disponíveis (P para produzir, V para liberar).",
                                    "Aprenda as operações sem_wait() (decrementa e bloqueia se zero) e sem_post() (incrementa e acorda thread).",
                                    "Implemente inicialização de semáforo com sem_init() em C/POSIX com valor inicial representando recursos.",
                                    "Teste um exemplo simples de múltiplas threads acessando um recurso limitado.",
                                    "Analise deadlocks potenciais em cenários de contagem."
                                  ],
                                  "verification": "Compilar e executar código que simula acesso controlado a 3 recursos por 5 threads sem overflow/underflow.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação POSIX semaphores (man sem_init)",
                                    "Compilador GCC com -pthread",
                                    "Exemplo de código base em GitHub para semáforos"
                                  ],
                                  "tips": "Sempre inicialize semáforos antes de usar threads e destrua com sem_destroy() no final.",
                                  "learningObjective": "Compreender semáforos como mecanismo de contagem para limitar acesso concorrente a recursos.",
                                  "commonMistakes": [
                                    "Esquecer de inicializar o semáforo (SIGSEGV)",
                                    "Usar valor inicial zero sem produção prévia",
                                    "Não incluir mutex para proteger variáveis compartilhadas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Sincronização com Semáforos em Produtor-Consumidor Básico",
                                  "subSteps": [
                                    "Crie um buffer compartilhado com semáforos para slots vazios (empty) e cheios (full).",
                                    "Use mutex para proteger o buffer durante inserção/remoção.",
                                    "Implemente produtor: wait(empty), wait(mutex), insere, post(mutex), post(full).",
                                    "Implemente consumidor: wait(full), wait(mutex), remove, post(mutex), post(empty).",
                                    "Execute com múltiplos produtores/consumidores e observe o comportamento."
                                  ],
                                  "verification": "Rodar programa por 30s sem buffer overflow/underflow ou starvation de threads.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código template de producer-consumer",
                                    "GDB para debug de threads",
                                    "Valgrind para detectar races"
                                  ],
                                  "tips": "Defina empty inicial como tamanho do buffer e full como 0 para evitar condições inválidas iniciais.",
                                  "learningObjective": "Aplicar semáforos para coordenar produção e consumo em buffers limitados.",
                                  "commonMistakes": [
                                    "Ordem errada de wait/post causando deadlock",
                                    "Esquecer mutex levando a races no buffer",
                                    "Não sinalizar corretamente full/empty"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir Variáveis de Condição (condvars) para Sinalização Eficiente",
                                  "subSteps": [
                                    "Estude pthread_cond_t: init com pthread_cond_init(), wait/signal/broadcast.",
                                    "Aprenda que condvars requerem mutex: pthread_cond_wait() libera mutex atomically.",
                                    "Implemente um exemplo simples onde threads esperam uma condição (ex: buffer não vazio).",
                                    "Diferencie signal() (acorda uma thread) de broadcast() (todas).",
                                    "Teste com cenário onde produtor sinaliza consumidores após produzir."
                                  ],
                                  "verification": "Código compila e threads acordam corretamente sem busy-waiting (use strace para verificar).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Man pages: pthread_cond_wait, pthread_cond_signal",
                                    "Exemplos em Beej's Guide to Pthreads"
                                  ],
                                  "tips": "Sempre use pthread_mutex_lock/unlock ao redor de cond_wait para atomicidade.",
                                  "learningObjective": "Dominar condvars para sinalização condicional sem polling ineficiente.",
                                  "commonMistakes": [
                                    "Chamar cond_wait sem mutex locked",
                                    "Não destravar mutex após signal",
                                    "Broadcast desnecessário causando thrashing"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Combinar Semáforos e Condvars em Sincronização Avançada",
                                  "subSteps": [
                                    "Integre condvars no produtor-consumidor: use cond para notificar 'buffer tem item' ou 'buffer tem espaço'.",
                                    "Mantenha semáforos para contagem, mas use cond para sinalização precisa.",
                                    "Implemente leitor-escritor com condvars para priorizar leitores.",
                                    "Adicione timeouts com pthread_cond_timedwait() para evitar bloqueios indefinidos.",
                                    "Debug e otimize para performance com ferramentas como perf."
                                  ],
                                  "verification": "Programa roda com 10 produtores/10 consumidores sem deadlocks ou ineficiências (CPU <50%).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código avançado de tanenbaum ou LKD book",
                                    "Helgrind (Valgrind) para detectar erros de sincronização"
                                  ],
                                  "tips": "Verifique a condição novamente após cond_wait (spurious wakeups são possíveis).",
                                  "learningObjective": "Integrar semáforos e condvars para soluções robustas de sincronização multi-thread.",
                                  "commonMistakes": [
                                    "Spurious wakeups não checados",
                                    "Deadlock por ordem errada de locks",
                                    "Overuse de broadcast reduzindo escalabilidade"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar e Otimizar Implementação Completa",
                                  "subSteps": [
                                    "Crie testes unitários para cenários edge: buffer cheio/vazio, sinalizações perdidas.",
                                    "Meça performance com diferentes tamanhos de buffer e número de threads.",
                                    "Use ferramentas para detectar data races e leaks.",
                                    "Refatore código para legibilidade e adicione comentários.",
                                    "Documente limitações e quando usar alternativas (ex: locks finos)."
                                  ],
                                  "verification": "Todos testes passam; relatório de performance gerado sem erros detectados por ferramentas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Google Test para C++ ou unity para C",
                                    "ThreadSanitizer",
                                    "Exemplos de benchmarks"
                                  ],
                                  "tips": "Aumente gradualmente o número de threads para estressar o sistema.",
                                  "learningObjective": "Validar e refinar implementações de sincronização para produção.",
                                  "commonMistakes": [
                                    "Ignorar edge cases como zero threads",
                                    "Não limpar recursos (memory leaks)",
                                    "Falsos positivos em ferramentas mal configuradas"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um buffer circular de tamanho 10 para produtores enviando mensagens e consumidores processando-as, usando dois semáforos (empty/full), um mutex e duas condvars (not_empty/not_full). Produtores esperam not_full se buffer cheio; consumidores esperam not_empty se vazio. Rode com 4 produtores e 4 consumidores por 1 minuto sem perda de mensagens.",
                              "finalVerifications": [
                                "Compilação sem warnings com -Wall -pthread -std=c11.",
                                "Execução sem segfaults ou deadlocks em runs múltiplos.",
                                "Valgrind relata zero leaks e races.",
                                "Throughput estável sem starvation (todas threads produzem/consomem igualmente).",
                                "Adaptação correta a mudanças no tamanho do buffer.",
                                "Timeouts evitam hangs em cenários de falha."
                              ],
                              "assessmentCriteria": [
                                "Inicialização correta de semáforos e condvars com valores apropriados.",
                                "Sequência exata de wait/post/signal sem violações lógicas.",
                                "Proteção adequada de seções críticas com mutex.",
                                "Tratamento de spurious wakeups com while(condition).",
                                "Eficiência: ausência de busy-waiting ou spins desnecessários.",
                                "Limpeza de recursos no final do programa."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Mecanismos de kernel como futexes.",
                                "Redes de Computadores: Sincronização em protocolos como TCP handshakes.",
                                "Banco de Dados: Locks e MVCC em transações concorrentes.",
                                "Engenharia de Software: Padrões de design para concurrency (ex: thread pools).",
                                "Inteligência Artificial: Sincronização em frameworks multi-thread como TensorFlow."
                              ],
                              "realWorldApplication": "Em servidores web como Nginx ou Apache para gerenciar pools de conexões worker threads limitadas; em sistemas de filas de mensagens (RabbitMQ) para coordenar produtores/consumidores; em bancos de dados como PostgreSQL para controle de acessos concorrentes a tabelas compartilhadas, evitando bottlenecks e garantindo escalabilidade."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.3",
                    "name": "Modelos de Memória Distribuída",
                    "description": "Características e princípios de programação em sistemas com memória local a cada processador.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.3.1",
                        "name": "Características dos Sistemas de Memória Distribuída",
                        "description": "Definição e principais atributos dos sistemas onde cada processador possui memória local exclusiva, sem acesso direto à memória de outros processadores, exigindo comunicação explícita.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.1.1",
                            "name": "Identificar diferenças entre memória distribuída e compartilhada",
                            "description": "Comparar modelos de memória distribuída (memória local por processador) com compartilhada (acesso global), destacando ausência de coerência de cache e necessidade de comunicação por mensagens.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Memória Compartilhada",
                                  "subSteps": [
                                    "Defina memória compartilhada como um modelo onde todos os processadores acessam uma única memória global.",
                                    "Explique o conceito de coerência de cache: caches locais mantêm consistência via protocolos como MESI.",
                                    "Descreva o hardware típico: barramento compartilhado ou redes de interconexão em SMP (Symmetric Multi-Processing).",
                                    "Identifique vantagens: transparência de acesso e simplicidade em programação.",
                                    "Liste desvantagens iniciais: contenção de barramento e escalabilidade limitada."
                                  ],
                                  "verification": "Desenhe um diagrama simples de um sistema SMP com memória compartilhada e rotule os componentes chave.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Diagrama em branco e caneta",
                                    "Artigo sobre modelos SMP (ex: Wikipedia 'Shared Memory')",
                                    "Vídeo introdutório sobre multi-core processors"
                                  ],
                                  "tips": "Use analogias como uma cozinha compartilhada onde todos acessam os mesmos armários simultaneamente.",
                                  "learningObjective": "Explicar os princípios básicos e mecanismos de suporte da memória compartilhada.",
                                  "commonMistakes": [
                                    "Confundir com memória distribuída achando que não há caches locais",
                                    "Ignorar a necessidade de protocolos de coerência"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender os Fundamentos da Memória Distribuída",
                                  "subSteps": [
                                    "Defina memória distribuída como cada processador ter sua própria memória local privada.",
                                    "Explique a ausência de coerência de cache: cada nó gerencia seu cache independentemente.",
                                    "Descreva comunicação via mensagens: uso de MPI ou sockets para troca de dados.",
                                    "Identifique hardware típico: clusters de computadores conectados por rede Ethernet ou InfiniBand.",
                                    "Liste vantagens: escalabilidade alta e tolerância a falhas."
                                  ],
                                  "verification": "Crie um esboço de um cluster com 4 nós, mostrando memórias locais e setas para mensagens.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel para diagrama",
                                    "Documentação MPI básica",
                                    "Vídeo sobre Beowulf clusters"
                                  ],
                                  "tips": "Pense em computadores separados em uma rede LAN, como PCs em um laboratório.",
                                  "learningObjective": "Descrever a arquitetura e mecanismos de comunicação em sistemas de memória distribuída.",
                                  "commonMistakes": [
                                    "Achar que há acesso direto à memória remota sem mensagens",
                                    "Subestimar latência de rede"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar e Comparar as Diferenças Chave",
                                  "subSteps": [
                                    "Compare acesso à memória: global e transparente (compartilhada) vs. local com mensagens (distribuída).",
                                    "Discuta coerência: automática via hardware (compartilhada) vs. manual via software (distribuída).",
                                    "Analise performance: baixa latência local (compartilhada) vs. alta latência de rede (distribuída).",
                                    "Avalie escalabilidade: limitada por barramento (compartilhada) vs. alta com mais nós (distribuída).",
                                    "Considere programação: threads/OpenMP (compartilhada) vs. processos/MPI (distribuída)."
                                  ],
                                  "verification": "Preencha uma tabela de comparação com pelo menos 5 diferenças em colunas lado a lado.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Tabela em Excel ou papel",
                                    "Tabela comparativa de artigos acadêmicos",
                                    "Ferramenta como Draw.io para tabelas visuais"
                                  ],
                                  "tips": "Use uma tabela markdown para organizar: linha para cada diferença, colunas para compartilhada/distribuída.",
                                  "learningObjective": "Listar e justificar pelo menos 5 diferenças principais entre os dois modelos.",
                                  "commonMistakes": [
                                    "Ignorar impacto na programação",
                                    "Confundir NUMA (híbrido) com puramente compartilhada"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Implicações Práticas e Exemplos",
                                  "subSteps": [
                                    "Discuta quando usar cada: compartilhada para workloads pequenos/altas frequências, distribuída para grandes escalas.",
                                    "Analise overheads: sincronização em compartilhada vs. serialização de mensagens em distribuída.",
                                    "Examine híbridos como NUMA e sua relação com os modelos puros.",
                                    "Revise casos de falha: crash de nó em distribuída vs. falha total em compartilhada.",
                                    "Pratique identificando em sistemas reais: Intel multi-core vs. AWS cluster."
                                  ],
                                  "verification": "Escreva um parágrafo resumindo uma diferença chave com um exemplo real.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Lista de sistemas reais (ex: TOP500 supercomputers)",
                                    "Notas dos steps anteriores"
                                  ],
                                  "tips": "Relacione com experiências pessoais, como rodar código em laptop multi-core vs. Google Colab cluster.",
                                  "learningObjective": "Aplicar o conhecimento para escolher modelos em cenários reais.",
                                  "commonMistakes": [
                                    "Generalizar demais sem considerar tamanhos de escala",
                                    "Esquecer trade-offs de custo"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de análise de imagem: Na memória compartilhada (multi-core CPU), threads acessam o mesmo array de pixels via OpenMP sem copiar dados. Na distribuída (cluster), cada nó processa uma porção da imagem e envia resultados parciais via MPI, evitando cópias massivas mas adicionando latência de rede.",
                              "finalVerifications": [
                                "Explicar verbalmente 3 diferenças chave sem consultar notas.",
                                "Desenhar diagramas precisos de ambos os modelos.",
                                "Preencher corretamente uma tabela de comparação cegamente.",
                                "Identificar modelo correto em 3 cenários reais (ex: smartphone vs. supercomputador).",
                                "Discutir uma implicação de programação para cada modelo.",
                                "Listar prós e contras de cada sem erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de conceitos fundamentais (30%).",
                                "Clareza e completude na comparação de diferenças (25%).",
                                "Uso correto de terminologia técnica (20%).",
                                "Capacidade de fornecer exemplos práticos relevantes (15%).",
                                "Demonstração de compreensão de implicações (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação como TCP/IP em distribuída.",
                                "Sistemas Operacionais: Gerenciamento de memória e scheduling em multi-processadores.",
                                "Programação: Diferenças entre threads (pthreads) e mensagens (MPI).",
                                "Arquitetura de Computadores: Hierarquia de memória e interconexões.",
                                "Engenharia de Software: Design de sistemas escaláveis e tolerantes a falhas."
                              ],
                              "realWorldApplication": "Em computação de alto desempenho (HPC), supercomputadores como Frontier usam memória distribuída para simulações climáticas massivas, enquanto servidores web multi-core exploram compartilhada para baixa latência em requests simultâneos; entender isso guia escolhas em cloud computing como AWS EC2 vs. HPC clusters."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.1.2",
                            "name": "Reconhecer princípios de escalabilidade em memória distribuída",
                            "description": "Explicar como a ausência de gargalos de memória compartilhada permite escalabilidade linear em clusters de processadores independentes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Modelos de Memória Compartilhada vs Distribuída",
                                  "subSteps": [
                                    "Defina memória compartilhada: todos os processadores acessam uma memória central comum.",
                                    "Defina memória distribuída: cada processador possui memória local privada, comunicando via mensagens.",
                                    "Compare arquiteturas: UMA (Uniform Memory Access) vs NUMA em compartilhada, e clusters independentes em distribuída.",
                                    "Identifique diferenças chave: latência de acesso e contenção em compartilhada.",
                                    "Estude diagramas de Flynn's Taxonomy relacionados a SISD, SIMD, MISD, MIMD."
                                  ],
                                  "verification": "Crie um diagrama comparativo e explique verbalmente as diferenças para um colega.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de Programação Paralela (Tanenbaum), diagramas online de modelos de memória, ferramenta de desenho como Draw.io.",
                                  "tips": "Use analogias: compartilhada como uma biblioteca central lotada, distribuída como bibliotecas locais.",
                                  "learningObjective": "Diferenciar modelos de memória e suas implicações arquiteturais.",
                                  "commonMistakes": "Confundir NUMA com distribuída; assumir que distribuída não tem comunicação."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Gargalos em Sistemas de Memória Compartilhada",
                                  "subSteps": [
                                    "Explique contenção de memória: múltiplos processadores competindo por acesso ao barramento.",
                                    "Discuta latência crescente com mais processadores devido a cache coherence protocols (MESI, etc.).",
                                    "Calcule impacto: Lei de Amdahl aplicada a overhead de sincronização.",
                                    "Simule com exemplo: 4 processadores acessando 1GB compartilhado vs locais.",
                                    "Analise métricas: throughput cai de linear para sub-linear."
                                  ],
                                  "verification": "Resolva um problema simples calculando throughput teórico para N processadores.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Calculadora ou Python para simulações, artigos sobre cache coherence, whiteboard.",
                                  "tips": "Foquem em 'bus contention' como gargalo primário; ignore I/O por agora.",
                                  "learningObjective": "Reconhecer como compartilhamento cria não-escalabilidade.",
                                  "commonMistakes": "Ignorar overhead de coherence; superestimar velocidade de barramentos modernos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Ausência de Gargalos na Memória Distribuída",
                                  "subSteps": [
                                    "Descreva independência: cada nó gerencia sua memória sem interferência central.",
                                    "Explique comunicação via MPI ou sockets: mensagens explícitas evitam contenção implícita.",
                                    "Compare performance: adicionar nó = adicionar memória + CPU sem divisão.",
                                    "Estude partição de dados: dados locais reduzem tráfego de rede.",
                                    "Discuta trade-offs: latência de rede vs ausência de contenção."
                                  ],
                                  "verification": "Desenhe fluxo de dados em um cluster de 8 nós e destaque ausência de gargalos.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Documentação MPI, vídeos de clusters Beowulf, software como ns-3 para simulação de rede.",
                                  "tips": "Pense em 'scale-out' vs 'scale-up': distribuída é scale-out natural.",
                                  "learningObjective": "Explicar como design distribuído elimina gargalos compartilhados.",
                                  "commonMistakes": "Confundir com memória compartilhada remota (DSM); ignorar custos de rede."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Demonstrar Escalabilidade Linear em Clusters",
                                  "subSteps": [
                                    "Defina escalabilidade linear: performance ∝ número de processadores.",
                                    "Use gráfico: speedup vs processadores em benchmarks distribuídos (NAS Parallel Benchmarks).",
                                    "Implemente mini-exemplo: programa MPI 'hello world' escalando de 1 a 16 processos.",
                                    "Meça tempo de execução e plote eficiência: eficiência = speedup / N.",
                                    "Conclua: ausência de gargalos permite ~100% eficiência em workloads balanceados."
                                  ],
                                  "verification": "Execute simulação e produza gráfico mostrando escalabilidade linear.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Ambiente MPI (OpenMPI instalado), Jupyter Notebook para plots, cluster simulado ou cloud (AWS EC2).",
                                  "tips": "Use workloads embarassingly parallel como pi calculation para demonstrar linearidade.",
                                  "learningObjective": "Validar princípios teóricos com evidências empíricas de escalabilidade.",
                                  "commonMistakes": "Workloads não balanceados; medir wall-time sem considerar comunicação."
                                }
                              ],
                              "practicalExample": "Em um cluster Hadoop para processamento de big data, adicionar mais nós DataNode aumenta capacidade de armazenamento e processamento linearmente, sem gargalo central, processando terabytes de logs em tempo proporcional ao hardware adicionado.",
                              "finalVerifications": [
                                "Explicar verbalmente como memória distribuída evita bus contention.",
                                "Desenhar diagrama de cluster mostrando independência de memória.",
                                "Calcular speedup esperado para 10x processadores em cenário distribuído.",
                                "Identificar quando escalabilidade linear falha (e.g., comunicação pesada).",
                                "Comparar com SMP (Symmetric Multi-Processing) em termos de escala.",
                                "Executar mini-benchmark MPI confirmando eficiência >90%."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: distinção clara entre modelos de memória (90%).",
                                "Profundidade de análise: identificação correta de gargalos e soluções (85%).",
                                "Evidências empíricas: uso de exemplos/simulações válidas (80%).",
                                "Clareza de comunicação: diagramas e explicações concisas (75%).",
                                "Compreensão de trade-offs: menção a latência de rede (70%).",
                                "Aplicação prática: ligação a clusters reais (65%)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: protocolos de comunicação como TCP/IP em clusters.",
                                "Bancos de Dados: sharding em NoSQL (Cassandra) para escalabilidade distribuída.",
                                "Cloud Computing: auto-scaling em Kubernetes pods independentes.",
                                "Algoritmos Paralelos: MapReduce como exemplo de workloads distribuídos."
                              ],
                              "realWorldApplication": "Desenvolvimento de sistemas como Google Search ou Netflix recommendation engines, onde clusters de milhares de nós processam queries em paralelo sem gargalos de memória, permitindo servir bilhões de usuários com latência baixa via escalabilidade linear."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.1.3",
                            "name": "Descrever desafios de latência e topologia de rede",
                            "description": "Analisar impactos da latência de comunicação em redes (ex.: Ethernet, InfiniBand) e topologias (mesh, torus) nos sistemas distribuídos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de latência em redes de comunicação",
                                  "subSteps": [
                                    "Definir latência como o tempo total para uma mensagem viajar de uma origem a um destino, incluindo componentes como latência de propagação, transmissão e processamento.",
                                    "Explicar os fatores que influenciam a latência: distância física, velocidade da luz no meio, overhead de protocolos e congestionamento.",
                                    "Diferenciar latência de throughput e bandwidth, com exemplos numéricos simples (ex.: 1ms de latência vs 10Gbps de banda).",
                                    "Analisar como a latência afeta a sincronização em sistemas distribuídos.",
                                    "Estudar métricas de latência: média, pior caso (tail latency) e jitter."
                                  ],
                                  "verification": "Resumir em um diagrama os componentes da latência e calcular um exemplo simples de latência total.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Vídeos introdutórios sobre redes (Khan Academy ou YouTube), calculadora, papel para diagramas.",
                                  "tips": "Use analogias cotidianas, como tempo de viagem de uma carta, para fixar o conceito.",
                                  "learningObjective": "Ao final, o aluno definirá latência e seus componentes com precisão, diferenciando-a de outras métricas de rede.",
                                  "commonMistakes": "Confundir latência com perda de pacotes ou assumir que maior banda reduz latência automaticamente."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar redes específicas: Ethernet e InfiniBand",
                                  "subSteps": [
                                    "Descrever Ethernet: características (latência típica 100-500µs, CSMA/CD legado, switches modernos), usos em LANs e clusters.",
                                    "Estudar InfiniBand: RDMA, latência baixa (1-5µs), alta taxa de transferência (100-400Gbps), foco em HPC.",
                                    "Comparar métricas: latência, custo, escalabilidade e protocolos (TCP/IP vs RDMA).",
                                    "Simular cenários: impacto de Ethernet em workloads distribuídos vs InfiniBand em supercomputadores.",
                                    "Pesquisar benchmarks reais (ex.: SPEC ou HPL)."
                                  ],
                                  "verification": "Criar uma tabela comparativa com latências, prós e contras de cada rede.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Documentação oficial (Ethernet IEEE 802.3, Mellanox InfiniBand guides), ferramentas online como iperf para simulações básicas.",
                                  "tips": "Foque em números reais de datasheets para ancorar o aprendizado em dados concretos.",
                                  "learningObjective": "O aluno comparará Ethernet e InfiniBand, identificando quando cada uma é ideal para sistemas distribuídos.",
                                  "commonMistakes": "Ignorar overhead de software em Ethernet ou superestimar InfiniBand para aplicações não-HPC."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estudar topologias de rede: Mesh e Torus",
                                  "subSteps": [
                                    "Definir topologia Mesh: conexões diretas entre todos os nós (full mesh) ou parcial, vantagens em latência baixa, desvantagens em escalabilidade.",
                                    "Explicar topologia Torus: grade 3D/2D com wrap-around, usada em HPC (ex.: IBM Blue Gene), reduzindo diâmetro de rede.",
                                    "Calcular diâmetro e hops médios: Mesh (1 hop direto) vs Torus (até k/2 em k-dimensões).",
                                    "Analisar trade-offs: custo de cabos, consumo de energia e impacto na latência coletiva.",
                                    "Visualizar com diagramas: desenhar redes de 8-64 nós."
                                  ],
                                  "verification": "Desenhar diagramas de Mesh e Torus para 16 nós e calcular hops para pares distantes.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Ferramentas de desenho (Draw.io ou papel), artigos sobre topologias HPC (ex.: Cray ou IBM docs).",
                                  "tips": "Comece com 2D torus para simplicidade antes de 3D.",
                                  "learningObjective": "O aluno descreverá Mesh e Torus, calculando métricas de latência baseadas em topologia.",
                                  "commonMistakes": "Confundir torus com grid simples (ignorar wrap-around) ou assumir mesh sempre superior."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar impactos da latência e topologia em sistemas distribuídos",
                                  "subSteps": [
                                    "Analisar efeitos em algoritmos distribuídos: MPI AllReduce mais lento com alta latência.",
                                    "Estudar mitigações: pipelining, overlap de comunicação/computação, topologias otimizadas.",
                                    "Simular cenários: impacto de torus em machine learning distribuído vs mesh em small clusters.",
                                    "Discutir escalabilidade: como latência cresce com N nós em diferentes topologias.",
                                    "Relacionar com modelos de memória distribuída: consistência eventual vs forte afetada por latência."
                                  ],
                                  "verification": "Escrever um relatório curto (200 palavras) descrevendo um desafio real e solução.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Simuladores como ns-3 ou OMNeT++, papers de HPC (SC conferences).",
                                  "tips": "Use equações simples como tempo_total = computacao + N * latencia para ilustrar.",
                                  "learningObjective": "O aluno analisará impactos qualitativos e quantitativos, propondo otimizações.",
                                  "commonMistakes": "Subestimar latência de software ou ignorar gargalos além da rede."
                                }
                              ],
                              "practicalExample": "Em um cluster de 64 nós com Ethernet e topologia mesh parcial, um job MPI All-to-All demora 10x mais devido a latência de 200µs vs InfiniBand torus com 2µs, permitindo overlap eficiente em treinamento de redes neurais distribuídas.",
                              "finalVerifications": [
                                "Explicar e calcular latência total em um caminho Ethernet de 100m.",
                                "Comparar hops médios em mesh vs torus para 100 nós.",
                                "Identificar quando usar InfiniBand sobre Ethernet em HPC.",
                                "Descrever 3 impactos de alta latência em MPI.",
                                "Propor uma topologia para minimizar latência em data center.",
                                "Diferenciar tail latency de latência média com exemplo."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas de latência e topologias).",
                                "Uso de exemplos quantitativos e benchmarks reais.",
                                "Análise de trade-offs (custo vs performance).",
                                "Profundidade na integração com sistemas distribuídos.",
                                "Clareza em diagramas e cálculos.",
                                "Criatividade em mitigações propostas."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos e métricas avançadas.",
                                "Programação Paralela: Otimização de comunicação em MPI/OpenMP.",
                                "Arquitetura de Computadores: Interconexões em multiprocessadores.",
                                "Matemática: Grafos e diâmetro de redes.",
                                "Engenharia de Software: Design de sistemas escaláveis."
                              ],
                              "realWorldApplication": "No design de supercomputadores como Frontier (usando Slingshot, similar a torus otimizado) ou data centers AWS, onde minimizar latência reduz custos de energia e acelera IA distribuída, evitando gargalos em workloads como simulações climáticas ou genômica."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.3.2",
                        "name": "Programação por Troca de Mensagens",
                        "description": "Modelo fundamental de programação paralela em memória distribuída, baseado em envio e recepção explícita de dados entre processadores.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.2.1",
                            "name": "Implementar operações básicas de envio e recepção",
                            "description": "Utilizar primitivas como send/receive em bibliotecas como MPI para trocar dados entre processos em memória distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente MPI e inicializar comunicadores",
                                  "subSteps": [
                                    "Instalar biblioteca MPI (ex: OpenMPI ou MPICH) se não estiver disponível no sistema.",
                                    "Incluir o cabeçalho #include <mpi.h> no código C.",
                                    "Chamar MPI_Init(&argc, &argv); no início da main para inicializar o ambiente MPI.",
                                    "Obter o número de processos com MPI_Comm_size(MPI_COMM_WORLD, &size);.",
                                    "Obter o rank do processo atual com MPI_Comm_rank(MPI_COMM_WORLD, &rank);."
                                  ],
                                  "verification": "Compilar um programa 'Hello World' MPI simples com mpicc e executar com mpirun -np 2 ./programa, verificando se todos os ranks imprimem suas identificações.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador C com suporte MPI (mpicc)",
                                    "Terminal/Linux ou ambiente com MPI instalado",
                                    "Editor de código (VS Code, Vim)"
                                  ],
                                  "tips": "Sempre inicialize MPI antes de qualquer chamada MPI e use MPI_COMM_WORLD como comunicador padrão para programas simples.",
                                  "learningObjective": "Compreender a inicialização do ambiente de programação paralela com MPI e identificação de processos.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes de outras funções MPI",
                                    "Usar MPI sem compilar com mpicc",
                                    "Não verificar erros de inicialização com MPI_SUCCESS"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a operação básica de envio de dados (MPI_Send)",
                                  "subSteps": [
                                    "Definir um buffer de envio (ex: char mensagem[100] = \"Olá do processo 0\";).",
                                    "No processo sender (rank 0), especificar parâmetros: buffer, count (tamanho), MPI_CHAR, destino (rank 1), tag (0), MPI_COMM_WORLD.",
                                    "Chamar MPI_Send(&buffer, count, datatype, dest, tag, comm); de forma bloqueante.",
                                    "Adicionar printf para depuração, mostrando o que foi enviado.",
                                    "Garantir que o sender aguarde a conclusão do envio."
                                  ],
                                  "verification": "Executar o programa e verificar via saída no terminal se a mensagem foi preparada corretamente no sender (mesmo sem recepção ainda).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código base do Step 1",
                                    "Documentação MPI para MPI_Send (man mpi_send ou mpi.org)"
                                  ],
                                  "tips": "Use tags únicas para diferenciar mensagens; comece com count pequeno para testes.",
                                  "learningObjective": "Dominar a sintaxe e semântica da primitiva MPI_Send para transferência síncrona de dados.",
                                  "commonMistakes": [
                                    "Parâmetros incorretos em count ou datatype levando a envios truncados",
                                    "Enviar para rank inválido causando deadlock",
                                    "Buffer não inicializado"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a operação básica de recepção de dados (MPI_Recv)",
                                  "subSteps": [
                                    "Definir um buffer de recepção no receptor (ex: char mensagem_recebida[100];).",
                                    "No processo receptor (rank 1), especificar: buffer, count (MPI_MAX para wildcard), MPI_CHAR, source (MPI_ANY_SOURCE), tag (MPI_ANY_TAG), MPI_COMM_WORLD, &status.",
                                    "Chamar MPI_Recv(buffer, count, datatype, source, tag, comm, &status); bloqueante.",
                                    "Imprimir o conteúdo recebido e detalhes do status (source e tag via MPI_Get_count).",
                                    "Testar com mpirun -np 2 para sincronização sender-receptor."
                                  ],
                                  "verification": "Observar na saída do terminal se o receptor imprime a mensagem enviada corretamente sem erros ou truncamentos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código dos Steps anteriores",
                                    "Documentação MPI para MPI_Recv"
                                  ],
                                  "tips": "Use MPI_ANY_SOURCE e MPI_ANY_TAG para flexibilidade em testes iniciais; sempre use MPI_Status para inspecionar a recepção.",
                                  "learningObjective": "Entender a primitiva MPI_Recv e seu papel em completar a troca de mensagens bloqueante.",
                                  "commonMistakes": [
                                    "Buffer de recepção pequeno demais causando overflow",
                                    "Não usar MPI_Status levando a perda de metadados",
                                    "Deadlock por falta de matching send/recv"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar o programa, compilar, executar e validar a troca completa",
                                  "subSteps": [
                                    "Chamar MPI_Finalize(); no final de todos os processos após a comunicação.",
                                    "Compilar com mpicc -o programa programa.c -Wall para detectar warnings.",
                                    "Executar com mpirun -np 2 -host localhost ./programa para testar em 2 processos.",
                                    "Verificar saídas em diferentes ranks e testar com np=4 ajustando lógica.",
                                    "Adicionar tratamento de erros com if(erro != MPI_SUCCESS) para robustez."
                                  ],
                                  "verification": "Programa termina sem deadlocks, todos ranks imprimem mensagens trocadas corretamente, e MPI_Finalize é chamado.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "mpirun ou mpiexec",
                                    "Scripts de teste para múltiplos np"
                                  ],
                                  "tips": "Use -host localhost para testes locais; aumente np gradualmente para escalabilidade.",
                                  "learningObjective": "Integrar send/receive em um programa completo MPI e validar execução paralela.",
                                  "commonMistakes": [
                                    "Chamar MPI_Finalize antes de todas comunicações",
                                    "Executar sem mpirun causando falha silenciosa",
                                    "Ignorar erros de MPI"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa simples com 2 processos: rank 0 envia \"Olá do processo 0!\" para rank 1 usando MPI_Send; rank 1 recebe com MPI_Recv e imprime \"Recebido: Olá do processo 0!\". Execute com mpirun -np 2 para ver a troca síncrona.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros ou deadlocks com mpirun -np 2.",
                                "Mensagem é enviada e recebida corretamente, impressa no receptor.",
                                "Todos os processos (ranks) chamam MPI_Finalize e terminam graciosamente.",
                                "MPI_Status revela source e tag corretos na recepção.",
                                "Teste com np=4 mostra escalabilidade sem falhas.",
                                "Nenhum vazamento de buffer ou truncamento de dados."
                              ],
                              "assessmentCriteria": [
                                "Uso correto de parâmetros em MPI_Send (buffer, count, datatype, dest, tag, comm).",
                                "Implementação precisa de MPI_Recv com MPI_Status e wildcards apropriados.",
                                "Inicialização/finalização MPI em todos os processos.",
                                "Tratamento básico de erros MPI e depuração via printf.",
                                "Sincronização implícita via bloqueio send/recv funciona sem busy-wait.",
                                "Código limpo, comentado e compilável com warnings zero."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Analogia com sockets TCP para comunicação ponto-a-ponto.",
                                "Algoritmos e Estruturas de Dados: Buffers como arrays e gerenciamento de memória distribuída.",
                                "Sistemas Operacionais: Processos paralelos e primitivas de sincronização.",
                                "Engenharia de Software: Modularidade em códigos paralelos e depuração distribuída."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (ex: trocas de dados de fronteiras entre subdomínios em supercomputadores) ou processamento distribuído de big data em clusters Hadoop/Spark com MPI subjacente."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.2.2",
                            "name": "Aplicar comunicação coletiva",
                            "description": "Implementar operações como broadcast, scatter, gather e reduce para sincronização e distribuição de dados em grupos de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Comunicação Coletiva",
                                  "subSteps": [
                                    "Estude as definições de broadcast (um processo envia dados para todos), scatter (distribui dados de um para cada), gather (coleta dados de todos para um) e reduce (agrega dados com operação como soma).",
                                    "Compare com comunicação point-to-point: coletiva envolve todos os processos no grupo, garantindo sincronização.",
                                    "Analise o modelo de memória distribuída: cada processo tem seu buffer local, sem compartilhamento direto.",
                                    "Revise hierarquia MPI: MPI_COMM_WORLD como grupo padrão.",
                                    "Desenhe diagramas de fluxo para cada operação com 4 processos."
                                  ],
                                  "verification": "Crie um diagrama ou resumo escrito explicando cada operação e suas diferenças.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação MPI oficial (mpi-forum.org)",
                                    "Editor de texto ou papel para diagramas",
                                    "Tutoriais online sobre MPI collectives"
                                  ],
                                  "tips": "Use animações interativas como as do MPI Tutorial para visualizar fluxos.",
                                  "learningObjective": "Diferenciar e explicar o propósito de cada operação coletiva em programação paralela.",
                                  "commonMistakes": "Confundir scatter com broadcast (scatter distribui porções únicas); ignorar sincronização implícita."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Broadcast e Scatter/Gather",
                                  "subSteps": [
                                    "Inclua headers MPI e inicialize MPI com MPI_Init e obtenha rank/tamanho com MPI_Comm_rank/size.",
                                    "Implemente broadcast: root envia array para todos via MPI_Bcast.",
                                    "Implemente scatter: root distribui array em porções via MPI_Scatter; cada processo recebe e processa localmente.",
                                    "Implemente gather: processos enviam porções via MPI_Gather para root coletar.",
                                    "Compile com mpicc e execute com mpirun -np 4."
                                  ],
                                  "verification": "Execute e verifique se todos processos recebem os mesmos dados no broadcast e distribuições corretas no scatter/gather via printf.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "OpenMPI ou MPICH instalado",
                                    "Compilador mpicc",
                                    "Código base MPI simples"
                                  ],
                                  "tips": "Garanta tamanhos de buffer múltiplos do número de processos para scatter/gather.",
                                  "learningObjective": "Codificar corretamente broadcast, scatter e gather para distribuição e coleta de dados.",
                                  "commonMistakes": "Buffers não alocados corretamente (use MPI_INT); esquecer MPI_Barrier se necessário."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Operações de Reduce",
                                  "subSteps": [
                                    "Estude operações de redução: MPI_SUM, MPI_MAX, etc., em MPI_Reduce (para root) e MPI_Allreduce (para todos).",
                                    "Implemente reduce: cada processo computa parcial (ex: soma local), envia para root via MPI_Reduce.",
                                    "Teste com array de números aleatórios: cada processo gera dados, reduz soma total.",
                                    "Adicione MPI_Allreduce para todos receberem o resultado.",
                                    "Valide resultados comparando com execução serial."
                                  ],
                                  "verification": "Compare soma reduzida com soma conhecida; todos processos imprimem o mesmo valor em Allreduce.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Mesmo ambiente MPI do step anterior",
                                    "Gerador de números rand() em C"
                                  ],
                                  "tips": "Use contadores de tipo MPI (MPI_INT) e operação MPI_Op como MPI_SUM.",
                                  "learningObjective": "Aplicar reduções para agregar dados distribuídos de forma eficiente.",
                                  "commonMistakes": "Enviar buffers de saída errados; não inicializar dados locais."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar em Programa Completo e Otimizar",
                                  "subSteps": [
                                    "Combine todas: scatter dados, processe local (ex: multiplicar), gather resultados, reduce soma final.",
                                    "Adicione tratamento de erros com MPI_SUCCESS e finalize com MPI_Finalize.",
                                    "Teste escalabilidade: execute com 2, 4, 8 processos e meça tempo com MPI_Wtime.",
                                    "Otimize: use MPI_IN_PLACE onde possível para reduzir cópias.",
                                    "Debug com mpirun -np 4 --hostfile hosts programa."
                                  ],
                                  "verification": "Programa produz resultado correto independente do número de processos; tempo escala linearmente.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Ambiente MPI completo",
                                    "Script para múltiplas execuções"
                                  ],
                                  "tips": "Sempre chame MPI_Init primeiro e MPI_Finalize por último.",
                                  "learningObjective": "Desenvolver programa paralelo funcional usando múltiplas collectives.",
                                  "commonMistakes": "Não sincronizar com MPI_Barrier após collectives; vazamentos de memória em buffers."
                                }
                              ],
                              "practicalExample": "Programa que distribui uma matriz 4x4 via scatter para 4 processos (cada processa uma linha somando elementos), gather somas parciais e reduce para total geral, simulando computação distribuída de soma de matriz.",
                              "finalVerifications": [
                                "Código compila e executa sem erros com mpirun -np N para N=2-8.",
                                "Todos processos imprimem dados corretos após broadcast e recebem porções únicas em scatter.",
                                "Gather reconstrói array original no root; reduce produz soma exata comparável a serial.",
                                "Tempo de execução diminui com mais processos para problema escalável.",
                                "Nenhum deadlock ou crash em execuções repetidas.",
                                "Uso de MPI_Allreduce propaga resultado para todos corretamente."
                              ],
                              "assessmentCriteria": [
                                "Correção das chamadas MPI: parâmetros de buffer, count, datatype, root, comm.",
                                "Gerenciamento eficiente de memória: alocações dinâmicas baseadas em tamanho do grupo.",
                                "Sincronização implícita das collectives usada corretamente sem barriers extras desnecessários.",
                                "Escalabilidade demonstrada em testes com múltiplos processos.",
                                "Código limpo, comentado e modular com funções separadas por operação.",
                                "Tratamento de erros e validação de retornos MPI."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados: operações vetoriais e prefix sums.",
                                "Redes de Computadores: conceitos de multicast e agregação em topologias.",
                                "Matemática Computacional: reduções paralelas em álgebra linear.",
                                "Engenharia de Software: design modular e reutilização de primitives paralelas."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (distribuir grids de dados para nós, agregar estatísticas) ou treinamento distribuído de machine learning (broadcast parâmetros, reduce gradientes em frameworks como Horovod sobre MPI)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.1.3.2.3",
                            "name": "Gerenciar topologias de comunicadores",
                            "description": "Configurar e utilizar comunicadores personalizados em MPI para definir subgrupos de processos e padrões de comunicação.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos básicos e criar comunicadores derivados com MPI_Comm_split",
                                  "subSteps": [
                                    "Estude a documentação oficial do MPI sobre MPI_COMM_WORLD e comunicadores derivados.",
                                    "Instale e configure um ambiente MPI (como OpenMPI ou MPICH) em sua máquina.",
                                    "Escreva um programa simples que usa MPI_Comm_split para dividir processos por cor (ex: pares e ímpares).",
                                    "Compile e execute o programa com pelo menos 4 processos usando mpirun.",
                                    "Analise a saída para verificar a criação correta dos subgrupos."
                                  ],
                                  "verification": "Verifique se os processos em cada subgrupo imprimem mensagens corretas e isoladas do outro grupo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação MPI (mpi-forum.org)",
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Use MPI_Comm_rank e MPI_Comm_size nos novos comunicadores para depurar.",
                                  "learningObjective": "Explicar a diferença entre comunicadores globais e derivados, e criar subgrupos baseados em chaves.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Comm_free no final",
                                    "Usar ranks globais em vez de locais no subgrupo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar topologias cartesianas com MPI_Cart_create",
                                  "subSteps": [
                                    "Revise conceitos de grade cartesiana (dims e periods).",
                                    "Crie um comunicador cartesiano a partir de COMM_WORLD especificando dimensões (ex: 2x2 para 4 processos).",
                                    "Use MPI_Cart_rank e MPI_Cart_coords para mapear ranks a coordenadas.",
                                    "Implemente uma troca de vizinhos (MPI_Cart_shift para comunicação com vizinhos).",
                                    "Execute e valide a topologia com impressões de coordenadas."
                                  ],
                                  "verification": "Confirme que cada processo conhece corretamente as coordenadas de seus vizinhos e que a comunicação ocorre apenas entre eles.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Documentação MPI sobre topologias",
                                    "mpirun para execução paralela"
                                  ],
                                  "tips": "Comece com grids pequenos (2D 2x2) para visualização fácil.",
                                  "learningObjective": "Criar e utilizar topologias cartesianas para padrões de comunicação regulares como grades.",
                                  "commonMistakes": [
                                    "Definir dims incorretas que não dividem o número total de processos",
                                    "Ignorar o parâmetro 'reorder'"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir topologias de grafo com MPI_Graph_create",
                                  "subSteps": [
                                    "Estude representações de grafos em MPI (index e edges arrays).",
                                    "Defina um grafo simples (ex: anel ou estrela) para 6 processos.",
                                    "Crie o comunicador gráfico usando MPI_Graph_create.",
                                    "Use MPI_Graph_neighbors para obter vizinhos e implemente broadcast ou allreduce no grafo.",
                                    "Teste com diferentes tamanhos de execução."
                                  ],
                                  "verification": "Verifique que a comunicação ocorre apenas entre processos conectados no grafo, sem erros de rank inválido.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Exemplos de código MPI Graph",
                                    "Ferramentas de debug como TotalView ou printf"
                                  ],
                                  "tips": "Desenhe o grafo no papel antes de codificar os arrays.",
                                  "learningObjective": "Modelar comunicações irregulares usando grafos e acessar vizinhos eficientemente.",
                                  "commonMistakes": [
                                    "Índices incorretos no array de edges",
                                    "Não replicar o grafo em todos os processos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Gerenciar comunicadores em aplicações e boas práticas",
                                  "subSteps": [
                                    "Integre múltiplos tipos de topologias em um programa único (split + cart).",
                                    "Implemente comunicação intra-topologia (ex: alltoall em cart).",
                                    "Adicione tratamento de erros com MPI_Error_string.",
                                    "Libere todos os comunicadores com MPI_Comm_free.",
                                    "Otimize e profile com ferramentas como mpiP ou Vampir."
                                  ],
                                  "verification": "Execute o programa completo sem vazamentos de memória e com comunicações corretas em subgrupos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Profiler MPI (mpiP)",
                                    "Código dos steps anteriores"
                                  ],
                                  "tips": "Sempre verifique o status de MPI após criações de comunicadores.",
                                  "learningObjective": "Aplicar topologias em fluxos de programa reais e gerenciar recursos adequadamente.",
                                  "commonMistakes": [
                                    "Não liberar comunicadores, causando vazamentos",
                                    "Misturar contextos de comunicação entre grupos"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa MPI com 8 processos, use MPI_Comm_split para criar dois grupos de 4 processos (por rank par/ímpar). No grupo par, crie uma topologia cartesiana 2x2 e implemente uma difusão de calor simples trocando valores com vizinhos. Imprima o estado final de cada grade para verificar convergência.",
                              "finalVerifications": [
                                "Explicar verbalmente ou por escrito como MPI_Comm_split difere de MPI_Cart_create.",
                                "Executar código com topologias variadas sem erros de MPI.",
                                "Identificar vizinhos corretos em uma topologia dada.",
                                "Liberar todos os comunicadores sem warnings de valgrind.",
                                "Adaptar código para diferentes números de processos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na criação de subgrupos (100% dos processos alocados corretamente).",
                                "Correção das comunicações topológicas (sem deadlocks ou dados errados).",
                                "Eficiência: tempo de execução escalável com mais processos.",
                                "Código limpo com comentários e tratamento de erros.",
                                "Compreensão demonstrada em verificações finais.",
                                "Uso apropriado de funções topológicas vs. genéricas."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: Modelagem de estruturas não regulares.",
                                "Redes de Computadores: Topologias de rede física mapeadas em MPI.",
                                "Algoritmos Paralelos: Otimização de padrões de comunicação.",
                                "Estruturas de Dados: Representação de adjacências em arrays."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC como modelagem climática (grades cartesianas para domínios espaciais) ou análise de redes sociais (grafos para propagação de informações), onde processos são organizados em subgrupos eficientes para reduzir latência de comunicação."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.3.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.3.3",
                        "name": "Decomposição de Domínio em Memória Distribuída",
                        "description": "Técnica de divisão do problema em subdomínios locais para cada processador, minimizando comunicações.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.3.1",
                            "name": "Aplicar decomposição de domínio 1D e 2D",
                            "description": "Dividir domínios computacionais (ex.: grades em simulações numéricas) em blocos lineares ou bidimensionais atribuídos a processadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de Decomposição de Domínio 1D e 2D",
                                  "subSteps": [
                                    "Estude a definição de domínio computacional em simulações numéricas, como grades 1D (linhas) e 2D (matrizes).",
                                    "Analise exemplos de decomposição 1D: divisão linear de um vetor em segmentos iguais para múltiplos processadores.",
                                    "Explore decomposição 2D: divisão de uma matriz em blocos retangulares ou em tiras horizontais/verticais.",
                                    "Compare vantagens e desvantagens: 1D é simples mas pode causar overhead de comunicação; 2D equilibra carga melhor em grades quadradas.",
                                    "Identifique cenários de uso: 1D para problemas lineares, 2D para imagens ou simulações de campo."
                                  ],
                                  "verification": "Resuma em um diagrama simples as diferenças entre 1D e 2D, mostrando uma grade de 8x8 dividida em 4 processadores.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de MPI ou OpenMP",
                                    "Papel e caneta para diagramas",
                                    "Vídeos tutoriais sobre decomposição de domínio"
                                  ],
                                  "tips": "Use desenhos manuais para visualizar melhor as divisões antes de codificar.",
                                  "learningObjective": "Dominar os princípios teóricos da decomposição 1D e 2D para preparar a aplicação prática.",
                                  "commonMistakes": [
                                    "Confundir 1D com divisão sequencial sem paralelismo",
                                    "Ignorar o impacto do formato da grade no balanceamento"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Decomposição de Domínio 1D",
                                  "subSteps": [
                                    "Crie um array 1D de tamanho N (ex.: N=1000) representando uma grade linear.",
                                    "Calcule o tamanho do bloco por processador: block_size = N / num_procs; ajuste para resto.",
                                    "Atribua índices iniciais e finais para cada processador usando rank e num_procs.",
                                    "Implemente em código (MPI_Send/Recv ou MPI_Scatter) para distribuir dados.",
                                    "Teste com print de índices locais para verificar divisão correta."
                                  ],
                                  "verification": "Execute o código com 4 processadores e confirme que cada um recebe blocos consecutivos sem sobreposição ou lacunas.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador C/Fortran com MPI",
                                    "Ambiente MPI como MPICH ou OpenMPI",
                                    "Editor de código (VSCode)"
                                  ],
                                  "tips": "Use MPI_Comm_rank e MPI_Comm_size para obter rank e número de processadores dinamicamente.",
                                  "learningObjective": "Aplicar decomposição 1D em código para distribuição linear de dados.",
                                  "commonMistakes": [
                                    "Divisão inteira sem tratar resto (N % num_procs)",
                                    "Índices off-by-one em cálculos de start/end"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Decomposição de Domínio 2D",
                                  "subSteps": [
                                    "Defina uma matriz 2D MxN (ex.: 512x512) e número de processadores PxQ (ex.: 4x4=16).",
                                    "Calcule dimensões locais: local_rows = M / P; local_cols = N / Q; gerencie restos.",
                                    "Mapeie coordenadas globais (i,j) para locais usando fórmulas: proc_row = i / local_rows.",
                                    "Use MPI_Cart_create para topologia 2D ou calcule manualmente ranks.",
                                    "Distribua a matriz usando MPI_Scatterv ou loops personalizados e verifique submatrizes."
                                  ],
                                  "verification": "Imprima submatrizes locais e confirme que cobrem toda a matriz global sem duplicatas.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Biblioteca MPI",
                                    "Ferramentas de visualização como Paraview para matrizes",
                                    "Scripts de teste"
                                  ],
                                  "tips": "Prefira decomposição em blocos para minimizar comunicações em simulações stencil.",
                                  "learningObjective": "Executar decomposição 2D em grades bidimensionais com mapeamento correto para processadores.",
                                  "commonMistakes": [
                                    "Assumir grade quadrada sem ajustar para retangular",
                                    "Erro em mapeamento de coordenadas globais-locais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar Balanceamento de Carga e Comunicar Fronteiras",
                                  "subSteps": [
                                    "Meça tamanhos de blocos e calcule desbalanceamento (max_size - min_size).",
                                    "Implemente trocas de halo (fronteiras) para decomposição 1D (MPI_Sendrecv adjacentes) e 2D (quatro vizinhos).",
                                    "Execute benchmarks medindo tempo de computação vs. comunicação.",
                                    "Otimize redistribuindo restos para balancear melhor.",
                                    "Documente métricas de performance para ambos os métodos."
                                  ],
                                  "verification": "Confirme que halos são atualizados corretamente comparando com versão sequencial.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "MPI_Wtime para timing",
                                    "Profiler como TAU ou Vampir"
                                  ],
                                  "tips": "Monitore overhead de comunicação; 2D reduz ghosts em grades grandes.",
                                  "learningObjective": "Garantir eficiência prática com balanceamento e comunicação mínima.",
                                  "commonMistakes": [
                                    "Esquecer trocas de halo levando a resultados incorretos",
                                    "Balanceamento pobre em num_procs não divisível"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão de calor em uma grade 2D de 1000x1000, decomponha em 16 processadores (4x4): cada um recebe uma subgrade 250x250, com trocas de halo nas bordas para atualizar temperaturas vizinhas.",
                              "finalVerifications": [
                                "A soma de todos os blocos locais reconstrói exatamente o domínio global.",
                                "Tamanhos de blocos variam no máximo em 1 unidade para balanceamento ótimo.",
                                "Atualizações de halo propagam valores corretamente em iterações de teste.",
                                "Tempo de execução escala linearmente com número de processadores.",
                                "Resultados coincidem com versão sequencial em precisão (erro < 1e-6).",
                                "Diagrama final mostra mapeamento proc-domínio sem ambiguidades."
                              ],
                              "assessmentCriteria": [
                                "Correção na divisão: blocos cobrem domínio sem lacunas/sobreposições (100%).",
                                "Balanceamento de carga: desvio padrão de tamanhos < 5%.",
                                "Eficiência de comunicação: overhead < 20% do tempo total.",
                                "Robustez: funciona para qualquer num_procs divisível ou com resto.",
                                "Clareza do código: comentários e funções modulares.",
                                "Escalabilidade demonstrada: speedup > 80% para 8+ processadores."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear (matrizes e vetores) e divisão de intervalos.",
                                "Física: Simulações numéricas de PDEs como equação de Laplace/Poisson.",
                                "Engenharia de Computação: Arquitetura de clusters e redes de interconexão.",
                                "Análise de Algoritmos: Complexidade espacial e análise de custo em HPC."
                              ],
                              "realWorldApplication": "Usado em supercomputadores para modelagem climática (divisão de grades globais), simulações CFD em aviação (domínios fluidodinâmicos) e processamento de imagens médicas (segmentação paralela de volumes 3D estendida de 2D)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.3.2",
                            "name": "Realizar balanceamento de carga",
                            "description": "Distribuir subdomínios de forma equitativa considerando tamanhos irregulares e heterogeneidades de processadores para otimizar tempo de execução.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Análise da decomposição inicial e identificação de heterogeneidades",
                                  "subSteps": [
                                    "Examinar a decomposição de domínio atual e medir o tamanho computacional de cada subdomínio (número de elementos ou iterações estimadas).",
                                    "Coletar informações sobre as características dos processadores: velocidade de clock, número de núcleos e overhead de comunicação.",
                                    "Calcular a carga de trabalho estimada para cada subdomínio em cada processador usando métricas como flops ou tempo de execução projetado.",
                                    "Visualizar a distribuição de carga atual com gráficos de barras ou heatmaps para identificar desbalanceamentos.",
                                    "Registrar métricas baseline como makespan (tempo total de execução) e utilização média de CPU."
                                  ],
                                  "verification": "Gerar um relatório com cargas calculadas e gráfico mostrando desbalanceamento >20% entre processadores.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código fonte da aplicação paralela",
                                    "Ferramentas de profiling (ex: MPI profiling tools como TAU ou Vampir)",
                                    "Bibliotecas de visualização (ex: Matplotlib ou Paraview)"
                                  ],
                                  "tips": "Priorize medições empíricas em vez de estimativas teóricas para maior precisão.",
                                  "learningObjective": "Identificar e quantificar irregularidades na distribuição de carga em sistemas distribuídos.",
                                  "commonMistakes": [
                                    "Ignorar overhead de comunicação entre subdomínios",
                                    "Assumir homogeneidade de processadores sem verificação",
                                    "Usar tamanhos geométricos sem considerar custo computacional"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Seleção e planejamento do método de balanceamento",
                                  "subSteps": [
                                    "Estudar métodos adequados: diffusion-based, recursive coordinate bisection ou graph partitioning (ex: METIS).",
                                    "Escolher método baseado no contexto: estático para cargas previsíveis ou dinâmico para irregulares.",
                                    "Definir critérios de partição: minimizar makespan considerando pesos de subdomínios e velocidades de processadores.",
                                    "Planejar migração de subdomínios: calcular volumes de dados a transferir e impacto na comunicação.",
                                    "Simular o balanceamento em pequena escala para validar a escolha."
                                  ],
                                  "verification": "Documentar justificativa do método escolhido com simulação mostrando redução projetada no makespan.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de bibliotecas de partitioning (METIS, Scotch)",
                                    "Simulador simples (ex: script Python com NumPy)"
                                  ],
                                  "tips": "Para heterogeneidades altas, prefira métodos que incorporam pesos de processadores explicitamente.",
                                  "learningObjective": "Selecionar e justificar estratégias de balanceamento otimizadas para cenários específicos.",
                                  "commonMistakes": [
                                    "Escolher método dinâmico desnecessário aumentando overhead",
                                    "Não considerar custo de migração de dados",
                                    "Ignorar topologia de rede"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementação do balanceamento de carga",
                                  "subSteps": [
                                    "Integrar a biblioteca ou algoritmo de partitioning ao código (ex: chamar METIS no MPI_Init).",
                                    "Ajustar mapeamento de subdomínios para processadores considerando velocidades normalizadas.",
                                    "Implementar migração de workloads: usar MPI_Send/Recv para transferir dados e estados.",
                                    "Adicionar checkpoints para balanceamento periódico em métodos dinâmicos.",
                                    "Compilar e testar em ambiente distribuído pequeno (2-4 nodes)."
                                  ],
                                  "verification": "Executar teste unitário confirmando que subdomínios foram redistribuídos corretamente sem perda de dados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ambiente MPI (OpenMPI ou MPICH)",
                                    "Biblioteca METIS ou Zoltan",
                                    "Código fonte editável"
                                  ],
                                  "tips": "Use normalização de cargas: carga_efetiva = tamanho_subdominio / velocidade_processador.",
                                  "learningObjective": "Implementar algoritmos de balanceamento em aplicações de memória distribuída.",
                                  "commonMistakes": [
                                    "Erros em MPI collective calls durante migração",
                                    "Não sincronizar estados após balanceamento",
                                    "Sobrecarga excessiva por balanceamentos frequentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliação e otimização iterativa",
                                  "subSteps": [
                                    "Executar a aplicação balanceada e medir novas métricas: makespan, balanceamento (std dev de cargas) e speedup.",
                                    "Comparar com baseline usando profiling tools para validar otimização.",
                                    "Identificar gargalos residuais e iterar no balanceamento se redução <30%.",
                                    "Documentar lições aprendidas e parametrizações ótimas.",
                                    "Testar escalabilidade em mais processadores."
                                  ],
                                  "verification": "Relatório final com gráficos comparativos mostrando melhoria no makespan e utilização de CPU.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Cluster de teste ou cloud (AWS EC2 com MPI)",
                                    "Ferramentas de benchmark (ex: mpiBLAST ou HPL)"
                                  ],
                                  "tips": "Monitore não só CPU mas também rede para balanceamentos reais.",
                                  "learningObjective": "Avaliar eficácia de balanceamentos e realizar otimizações iterativas.",
                                  "commonMistakes": [
                                    "Atribuir melhorias a ruído em vez de balanceamento",
                                    "Testar apenas em escala pequena",
                                    "Ignorar variabilidade em runs múltiplos"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de propagação de fraturas em rocha (carga irregular devido a geometria), usando um cluster com 8 nodes (4 CPUs rápidas e 4 lentas), aplicar METIS para redistribuir subdomínios, reduzindo makespan de 120s para 70s.",
                              "finalVerifications": [
                                "Desvio padrão das cargas entre processadores <10%.",
                                "Makespan reduzido em pelo menos 25% comparado ao baseline.",
                                "Utilização média de CPU >85% em todos os processadores.",
                                "Volume total de dados migrados <5% do dataset total.",
                                "Execução estável sem deadlocks ou perdas de precisão.",
                                "Speedup linear ou superlinear em testes de escalabilidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na quantificação de heterogeneidades (erro <5%).",
                                "Eficiência do método escolhido (redução makespan >20%).",
                                "Corretude da implementação (sem erros de MPI ou perda de dados).",
                                "Qualidade da documentação e visualizações.",
                                "Capacidade de iterar e otimizar baseado em métricas.",
                                "Consideração de custos reais (comunicação e overhead)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Otimização combinatorial e grafos (partitioning).",
                                "Redes de Computadores: Topologias e latência de comunicação.",
                                "Algoritmos e Estruturas de Dados: Heurísticas de balanceamento.",
                                "Engenharia de Software: Profiling e tuning de performance.",
                                "Física Computacional: Modelos de simulação distribuída."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas ou CFD (ex: NASA ou ECMWF), onde heterogeneidades de hardware e cargas irregulares de malhas adaptativas demandam balanceamento dinâmico para maximizar throughput em petascale computing."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.3.3.1"
                            ]
                          },
                          {
                            "id": "10.1.1.3.3.3",
                            "name": "Gerenciar fronteiras e trocas de dados",
                            "description": "Implementar atualizações de halo ou ghost cells nas fronteiras de subdomínios para manter consistência em iterações paralelas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Decomposição de Domínio e Conceito de Halo/Ghost Cells",
                                  "subSteps": [
                                    "Estude a decomposição de domínio em blocos ou tiras para memória distribuída.",
                                    "Identifique fronteiras compartilhadas entre subdomínios adjacentes.",
                                    "Aprenda que halo/ghost cells são camadas extras de células copiadas das fronteiras vizinhas para computação local.",
                                    "Analise exemplos em grades 1D e 2D para visualizar trocas.",
                                    "Desenhe um diagrama manual de uma grade 2D dividida em 4 subdomínios com halos."
                                  ],
                                  "verification": "Crie um diagrama anotado mostrando subdomínios e halos; confirme com um colega ou tutor.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação MPI, papel e caneta ou ferramenta de desenho como Draw.io, tutoriais sobre decomposição de domínio.",
                                  "tips": "Comece com 1D para simplicidade antes de 2D.",
                                  "learningObjective": "Explicar o papel de halo cells na manutenção de consistência em computações paralelas distribuídas.",
                                  "commonMistakes": "Confundir halo cells com padding desnecessário; ignorar direções de fronteiras (esquerda/direita, cima/baixo)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Subdomínios e Inicializar Halo Cells",
                                  "subSteps": [
                                    "Implemente divisão do domínio global em subdomínios locais usando MPI_Comm_rank e MPI_Comm_size.",
                                    " Aloque arrays locais com tamanho extra para halo cells (ex: +2 em cada dimensão).",
                                    "Inicialize valores internos do subdomínio com dados do domínio global.",
                                    "Marque regiões de halo como inválidas inicialmente (ex: valor sentinela).",
                                    "Escreva uma função para calcular coordenadas locais vs globais."
                                  ],
                                  "verification": "Execute código serializado para imprimir array local com halos vazios; verifique dimensões e inicialização.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Compilador MPI (OpenMPI/MPICH), editor de código (VSCode), grade de teste 2D simples.",
                                  "tips": "Use macros para dimensões de halo (ex: #define HALO_WIDTH 1) para facilitar mudanças.",
                                  "learningObjective": "Configurar estruturas de dados locais que suportem atualizações de fronteiras.",
                                  "commonMistakes": "Erro no cálculo de offsets para subdomínios; alocação insuficiente para halos em bordas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Troca de Dados nas Fronteiras com MPI",
                                  "subSteps": [
                                    "Identifique vizinhos: cima, baixo, esquerda, direita usando ranks MPI.",
                                    "Use MPI_Send e MPI_Recv para trocar dados de halo em pares (envie recebe simultâneo).",
                                    "Implemente MPI_Sendrecv para trocas não-bloqueantes eficientes em grades 2D.",
                                    "Copie dados recebidos para as regiões de halo correspondentes.",
                                    "Adicione suporte para cantos (trocas diagonais se necessário)."
                                  ],
                                  "verification": "Rode com 4 processos; imprima halos após troca e confirme que coincidem com vizinhos esperados.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Cluster ou mpirun local, debugger como TotalView ou gdb, script de grade de teste com padrões conhecidos.",
                                  "tips": "Sempre troque em ordem consistente (ex: envia para direita/baixo primeiro) para evitar deadlocks.",
                                  "learningObjective": "Executar comunicações ponto-a-ponto seguras para sincronizar fronteiras.",
                                  "commonMistakes": "Deadlocks por ordem errada de Send/Recv; tamanhos de buffer incorretos em MPI_Type_vector."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar em Loop de Iteração Paralela e Testar Consistência",
                                  "subSteps": [
                                    "Coloque troca de halos dentro de um loop de iterações (ex: método de Jacobi).",
                                    "Atualize células internas usando halos atualizados.",
                                    "Implemente redução global (MPI_Allreduce) para métricas de convergência.",
                                    "Execute múltiplas iterações e compare resultados com versão serial.",
                                    "Meça tempo de comunicação vs computação com MPI_Wtime."
                                  ],
                                  "verification": "Compare solução paralela com serial (erro < 1e-6); verifique escalabilidade com 2-8 processos.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Benchmark de grade maior (ex: 1024x1024), ferramentas de profiling como TAU ou Vampir.",
                                  "tips": "Use MPI_Barrier apenas para medições; evite em produção.",
                                  "learningObjective": "Manter consistência de dados ao longo de iterações paralelas distribuídas.",
                                  "commonMistakes": "Atualizar halos fora do loop; esquecer sincronização em iterações assíncronas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimizar e Depurar Troca de Fronteiras",
                                  "subSteps": [
                                    "Otimize com MPI_Isend/Irecv não-bloqueantes e MPI_Waitall.",
                                    "Adicione tratamento de bordas do domínio global (MPI_PROC_NULL).",
                                    "Implemente logging de comunicações para depuração.",
                                    "Teste com falhas simuladas (ex: rank falhando).",
                                    "Profile para identificar gargalos de comunicação."
                                  ],
                                  "verification": "Reduza tempo total em 20% com otimizações; passe em testes de robustez.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Profiler MPI (Scalasca), casos de teste edge-case.",
                                  "tips": "Persistência de buffers para MPI persiste se suportado.",
                                  "learningObjective": "Otimizar e tornar robusta a gestão de fronteiras em cenários reais.",
                                  "commonMistakes": "Overhead de não-bloqueante sem overlap correto; ignorar topologias cartesianas (MPI_Cart)."
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão de calor em uma grade 2D de 1000x1000, divida em 4 subdomínios. Cada processo atualiza sua porção usando Jacobi, trocando halos de 1 célula via MPI_Sendrecv após cada iteração. Inicialize com hotspot no centro; verifique convergência uniforme.",
                              "finalVerifications": [
                                "Halos de todos processos coincidem com dados vizinhos após troca.",
                                "Solução paralela idêntica à serial (L2 norm < 1e-10).",
                                "Execução sem deadlocks ou crashes em 2-16 processos.",
                                "Tempo de comunicação < 20% do total em grades grandes.",
                                "Tratamento correto de bordas do domínio global.",
                                "Convergência detectada corretamente via redução global."
                              ],
                              "assessmentCriteria": [
                                "Código compila e roda corretamente em múltiplos ranks sem erros MPI.",
                                "Halos atualizados precisamente sem sobreposição ou lacunas.",
                                "Eficiência: overlap de comunicação/computação demonstrado.",
                                "Robustez: lida com domínios não-divisíveis uniformemente.",
                                "Documentação clara de funções de troca e uso.",
                                "Escalabilidade comprovada com speedup linear até 8 processos."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de troca de mensagens semelhantes a TCP/IP.",
                                "Algoritmos e Estruturas de Dados: Grafos para modelar topologia de subdomínios.",
                                "Matemática Numérica: Métodos iterativos como Jacobi/Gauss-Seidel em PDES.",
                                "Engenharia de Software: Design de APIs para abstrair comunicações paralelas."
                              ],
                              "realWorldApplication": "Em simulações CFD (ex: OpenFOAM) ou modelagem climática (ex: CESM), gerencia fronteiras em malhas distribuídas para precisão em bilhões de células, permitindo escalabilidade em supercomputadores como Frontier."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.3.3.1",
                              "10.1.1.3.2.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.4",
                    "name": "Troca de Mensagens",
                    "description": "Modelo de programação paralela para memória distribuída, incluindo paradigmas como MPI.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.4.1",
                        "name": "Fundamentos da Troca de Mensagens em Memória Distribuída",
                        "description": "Conceitos básicos do modelo de programação paralela baseado em troca de mensagens, onde cada processador possui memória privada e a comunicação ocorre explicitamente via envio e recepção de mensagens, contrastando com modelos de memória compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.1.1",
                            "name": "Identificar características da memória distribuída",
                            "description": "Diferenciar memória distribuída de compartilhada, explicando ausência de espaço de endereçamento global e necessidade de comunicação explícita via mensagens, com exemplos de taxonomia de Flynn (MIMD).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Diferenciar memória compartilhada de memória distribuída",
                                  "subSteps": [
                                    "Revise a definição de memória compartilhada: um único espaço de endereçamento acessível por todos os processadores.",
                                    "Revise a definição de memória distribuída: cada processador tem sua própria memória privada, sem acesso direto à memória de outros.",
                                    "Compare os dois modelos usando diagramas simples.",
                                    "Identifique vantagens e desvantagens iniciais de cada modelo.",
                                    "Discuta cenários onde cada um é preferível."
                                  ],
                                  "verification": "Crie um diagrama comparativo e explique verbalmente as diferenças principais.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Diagramas de memória compartilhada e distribuída",
                                    "Vídeo introdutório sobre modelos de memória (ex: YouTube ou Khan Academy)"
                                  ],
                                  "tips": [
                                    "Use analogias como 'apartamento compartilhado' vs 'casas separadas' para fixar conceitos.",
                                    "Foque em hardware físico primeiro, antes de software."
                                  ],
                                  "learningObjective": "Compreender as diferenças fundamentais entre memória compartilhada e distribuída.",
                                  "commonMistakes": [
                                    "Confundir memória distribuída com cache distribuído.",
                                    "Ignorar o impacto na latência de acesso à memória."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explicar a ausência de espaço de endereçamento global",
                                  "subSteps": [
                                    "Defina espaço de endereçamento global: mecanismo que permite a qualquer processador acessar qualquer localização de memória.",
                                    "Explique por que não existe na memória distribuída: memórias locais isoladas fisicamente.",
                                    "Descreva implicações: necessidade de mapeamento explícito para acessar dados remotos.",
                                    "Compare com memória compartilhada, onde endereços são globais.",
                                    "Ilustre com um exemplo de tentativa de acesso inválido em sistema distribuído."
                                  ],
                                  "verification": "Escreva um parágrafo explicando por que um ponteiro global falha em memória distribuída.",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Pseudocódigo de acesso a memória em ambos os modelos",
                                    "Artigo sobre modelos de memória em sistemas paralelos"
                                  ],
                                  "tips": [
                                    "Pense em redes locais (LAN): cada máquina tem IP próprio, sem endereçamento unificado.",
                                    "Desenhe setas entre nós para visualizar isolamento."
                                  ],
                                  "learningObjective": "Entender as consequências da falta de um espaço de endereçamento unificado.",
                                  "commonMistakes": [
                                    "Assumir que RPC ou chamadas remotas criam um espaço global – elas não.",
                                    "Confundir com virtualização de memória."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Entender a necessidade de comunicação explícita via mensagens",
                                  "subSteps": [
                                    "Descreva comunicação explícita: envio e recebimento de mensagens entre processos.",
                                    "Explique por quê é necessária: única forma de trocar dados em memória distribuída.",
                                    "Discuta primitivas básicas: send/receive, broadcast.",
                                    "Compare com comunicação implícita em memória compartilhada (leitura/escrita direta).",
                                    "Simule uma troca simples de dados via mensagens."
                                  ],
                                  "verification": "Implemente um pseudocódigo simples de send/receive entre dois nós.",
                                  "estimatedTime": "30-40 minutos",
                                  "materials": [
                                    "Documentação básica de MPI ou similar",
                                    "Ferramenta online para simular mensagens (ex: MPI simulator)"
                                  ],
                                  "tips": [
                                    "Comece com mensagens ponto-a-ponto antes de coletivas.",
                                    "Monitore overhead de comunicação vs cópia de dados."
                                  ],
                                  "learningObjective": "Dominar o conceito e a razão da comunicação explícita por mensagens.",
                                  "commonMistakes": [
                                    "Subestimar latência de rede em simulações locais.",
                                    "Misturar com compartilhamento via sockets sem abstrações."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com taxonomia de Flynn, focando em MIMD",
                                  "subSteps": [
                                    "Revise taxonomia de Flynn: SISD, SIMD, MISD, MIMD.",
                                    "Identifique onde memória distribuída se encaixa: tipicamente MIMD (múltiplos processadores independentes, instruções e dados).",
                                    "Dê exemplos: clusters com MPI (MIMD distribuído).",
                                    "Compare MIMD distribuído vs MIMD compartilhado (ex: multicore com OpenMP).",
                                    "Discuta escalabilidade em MIMD distribuído."
                                  ],
                                  "verification": "Classifique 3 arquiteturas reais (ex: GPU, cluster Hadoop) na taxonomia e justifique modelo de memória.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Tabela da taxonomia de Flynn",
                                    "Exemplos de sistemas MIMD (Wikipedia ou slides acadêmicos)"
                                  ],
                                  "tips": [
                                    "MIMD é 'Multiple Instruction Multiple Data' – perfeito para cargas heterogêneas.",
                                    "Ligue de volta às mensagens como enabler para MIMD distribuído."
                                  ],
                                  "learningObjective": "Conectar memória distribuída à taxonomia de Flynn, especialmente MIMD.",
                                  "commonMistakes": [
                                    "Confundir MIMD com SIMD (vetorização).",
                                    "Ignorar que MIMD pode ser compartilhado ou distribuído."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 4 nós rodando MPI (MIMD distribuído), cada nó calcula soma parcial de um vetor local e envia via MPI_Send para o nó raiz, que agrega com MPI_Reduce – sem espaço global, toda troca é explícita por mensagens.",
                              "finalVerifications": [
                                "Diferencie corretamente memória compartilhada de distribuída em um diagrama.",
                                "Explique ausência de espaço de endereçamento global com um exemplo de falha.",
                                "Descreva primitivas de comunicação explícita e sua necessidade.",
                                "Classifique um sistema real (ex: cluster AWS) como MIMD distribuído.",
                                "Simule uma troca de mensagens em pseudocódigo.",
                                "Identifique 2 vantagens da memória distribuída em MIMD."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção entre modelos de memória (90%+ correto).",
                                "Clareza na explicação da ausência de endereçamento global.",
                                "Correta identificação de comunicação explícita como essencial.",
                                "Integração precisa com taxonomia de Flynn e MIMD.",
                                "Uso de exemplos concretos e diagramas.",
                                "Ausência de confusões comuns (ex: MIMD vs SIMD)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de mensagens como TCP/IP.",
                                "Sistemas Operacionais: Gerenciamento de processos distribuídos.",
                                "Banco de Dados: Sistemas distribuídos como Cassandra.",
                                "Big Data: Frameworks como Hadoop/Spark em clusters MIMD."
                              ],
                              "realWorldApplication": "Em computação em nuvem (ex: Google Cloud clusters), memória distribuída com MPI permite escalar análises de big data, como machine learning distribuído no TensorFlow, onde nós trocam gradientes via mensagens sem compartilhar memória global."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.1.2",
                            "name": "Explicar paradigmas de troca de mensagens",
                            "description": "Descrever os paradigmas fundamentais como envio ponto-a-ponto e operações coletivas, relacionando com decomposição de domínio e destacando desafios como latência e sincronização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de Troca de Mensagens",
                                  "subSteps": [
                                    "Definir troca de mensagens como mecanismo principal em sistemas de memória distribuída.",
                                    "Diferenciar paradigmas de comunicação: ponto-a-ponto (individuais) versus coletivas (grupais).",
                                    "Explicar o papel da troca de mensagens na programação paralela distribuída.",
                                    "Relacionar brevemente com modelos de memória e Taxonomia de Flynn.",
                                    "Identificar bibliotecas comuns como MPI para implementação."
                                  ],
                                  "verification": "Escrever um parágrafo resumindo os dois paradigmas principais e suas diferenças.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação oficial do MPI (mpi-forum.org)",
                                    "Slides ou vídeo introdutório sobre programação paralela distribuída"
                                  ],
                                  "tips": "Use analogia de 'carta entre duas pessoas' para ponto-a-ponto e 'reunião em grupo' para coletivas.",
                                  "learningObjective": "Dominar a distinção conceitual entre paradigmas de troca de mensagens.",
                                  "commonMistakes": "Confundir troca de mensagens com compartilhamento de memória (ex: OpenMP)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Paradigma de Envio Ponto-a-Ponto",
                                  "subSteps": [
                                    "Descrever operações básicas: MPI_Send e MPI_Recv (ou equivalentes).",
                                    "Explicar modos de envio: síncrono, assíncrono, buffered.",
                                    "Discutir conceitos de buffer, tags e comunicadores.",
                                    "Analisar fluxos de controle e possíveis bloqueios.",
                                    "Simular um exemplo simples de troca entre dois processos."
                                  ],
                                  "verification": "Desenhar um diagrama de fluxo mostrando comunicação ponto-a-ponto entre processos A e B.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Instalação de MPI (OpenMPI ou MPICH)",
                                    "Editor de código como VS Code com suporte MPI"
                                  ],
                                  "tips": "Sempre especifique tags para evitar mensagens perdidas em comunicações complexas.",
                                  "learningObjective": "Capacitar-se a descrever e ilustrar comunicações ponto-a-ponto.",
                                  "commonMistakes": "Ignorar mismatches de buffer size, causando erros de segmentação."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Operações Coletivas",
                                  "subSteps": [
                                    "Listar e descrever operações comuns: Broadcast, Scatter, Gather, Reduce, Allreduce.",
                                    "Explicar a topologia implícita (ex: árvore binomial para reduce).",
                                    "Comparar eficiência com ponto-a-ponto equivalente.",
                                    "Demonstrar uso em cenários de agregação de dados.",
                                    "Explorar variações in-place para otimização de memória."
                                  ],
                                  "verification": "Implementar um código simples de MPI_Allreduce e executar em múltiplos processos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Exemplos de código de repositórios GitHub sobre MPI collectives"
                                  ],
                                  "tips": "Prefira collectives para padrões regulares de comunicação para melhor performance.",
                                  "learningObjective": "Entender o funcionamento e benefícios das operações coletivas.",
                                  "commonMistakes": "Usar ponto-a-ponto para collectives, levando a overhead desnecessário."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com Decomposição de Domínio e Destacar Desafios",
                                  "subSteps": [
                                    "Explicar como decomposição de domínio (1D, 2D) gera padrões de comunicação.",
                                    "Analisar desafios: latência (tempo de mensagem), bandwidth, sincronização.",
                                    "Discutir problemas como deadlocks e starvation em trocas.",
                                    "Propor soluções: non-blocking calls, profiling tools como TAU.",
                                    "Avaliar impacto na escalabilidade geral do programa."
                                  ],
                                  "verification": "Redigir um relatório curto ligando decomposição a desafios de comunicação com exemplos.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Artigo 'MPI: The Complete Reference'",
                                    "Ferramentas de profiling como Vampir ou Score-P"
                                  ],
                                  "tips": "Monitore latência com ferramentas de profiling desde o início do desenvolvimento.",
                                  "learningObjective": "Integrar paradigmas de mensagens com design de algoritmos paralelos.",
                                  "commonMistakes": "Subestimar latência em decomposições finas, causando gargalos."
                                }
                              ],
                              "practicalExample": "Em uma simulação de Monte Carlo distribuída: processos decompõem o domínio de amostras aleatórias; usam MPI_Send/MPI_Recv ponto-a-ponto para trocar estatísticas parciais entre vizinhos e MPI_Allreduce coletivamente para computar a média global final, lidando com sincronização via barriers.",
                              "finalVerifications": [
                                "Descrever com precisão envio ponto-a-ponto versus operações coletivas.",
                                "Explicar como decomposição de domínio influencia padrões de mensagens.",
                                "Identificar pelo menos três desafios (latência, sincronização, deadlocks) com soluções.",
                                "Implementar e executar um exemplo híbrido ponto-a-ponto/coletivo sem erros.",
                                "Analisar overhead de comunicação em um diagrama de performance."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual dos paradigmas descritos (clareza e correção).",
                                "Profundidade na relação com decomposição de domínio.",
                                "Identificação completa de desafios e propostas de mitigação.",
                                "Qualidade de exemplos práticos e diagramas fornecidos.",
                                "Capacidade de codificação e depuração de cenários MPI.",
                                "Análise crítica de escalabilidade e performance."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação e latência de rede.",
                                "Algoritmos e Estruturas de Dados: Decomposição e agregação paralela.",
                                "Sistemas Operacionais: Gerenciamento de processos e sincronização distribuída.",
                                "Engenharia de Software: Design de APIs como MPI para paralelismo."
                              ],
                              "realWorldApplication": "Em supercomputação para simulações científicas (ex: modelagem climática no Cray ou IBM Blue Gene), onde milhares de nós usam MPI para trocar mensagens em decomposições de malha 3D, otimizando latência para resultados em tempo real."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.1.3",
                            "name": "Comparar com outros modelos de memória compartilhada",
                            "description": "Comparar troca de mensagens com exclusão mútua e decomposição de domínio em memória compartilhada, identificando vantagens em escalabilidade para clusters e nuvens.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos da Troca de Mensagens (Message Passing)",
                                  "subSteps": [
                                    "Estude os princípios básicos do modelo de troca de mensagens, incluindo envio e recebimento explícito de dados entre processos.",
                                    "Analise exemplos de bibliotecas como MPI (Message Passing Interface) e suas primitivas como MPI_Send e MPI_Recv.",
                                    "Identifique cenários onde a troca de mensagens é preferida, como em sistemas distribuídos sem memória compartilhada.",
                                    "Discuta independência de processos e ausência de estado compartilhado.",
                                    "Revise overheads associados, como latência de rede e sincronização explícita."
                                  ],
                                  "verification": "Resuma em um diagrama ou tabela os componentes chave da troca de mensagens e liste 3 primitivas principais.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação MPI oficial, slides de aula sobre programação paralela, ferramenta de desenho como Draw.io.",
                                  "tips": "Use analogias como 'carta pelo correio' para visualizar envio/recebimento assíncrono.",
                                  "learningObjective": "Compreender os mecanismos e vantagens básicas do modelo de troca de mensagens.",
                                  "commonMistakes": "Confundir troca de mensagens com chamadas remotas de procedimento (RPC); ignorar deadlocks em padrões de comunicação."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Memória Compartilhada com Exclusão Mútua e Decomposição de Domínio",
                                  "subSteps": [
                                    "Defina memória compartilhada e descreva acesso direto a regiões comuns de memória por múltiplos threads/processos.",
                                    "Estude exclusão mútua (mutual exclusion) usando primitivas como mutexes, semáforos e barreiras para evitar race conditions.",
                                    "Analise decomposição de domínio: dividir o problema em partes independentes mapeadas para threads compartilhando dados.",
                                    "Examine bibliotecas como OpenMP ou Pthreads para exemplos de diretivas de paralelismo e sincronização.",
                                    "Identifique desafios como falsos compartilhamentos e overhead de cache coherence."
                                  ],
                                  "verification": "Implemente um código simples em pseudocódigo com mutex para uma seção crítica e explique a decomposição usada.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Tutoriais OpenMP/Pthreads, compilador C++ com suporte OpenMP, exemplos de código de race conditions.",
                                  "tips": "Teste códigos com múltiplas threads para observar race conditions antes de adicionar sincronização.",
                                  "learningObjective": "Dominar técnicas de sincronização e decomposição em memória compartilhada.",
                                  "commonMistakes": "Subestimar o custo de sincronização em memória compartilhada; confundir decomposição de domínio com decomposição funcional."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar os Dois Modelos em Dimensões Chave",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: independência de processos vs. sincronização implícita/explícita.",
                                    "Compare overheads: latência de mensagens vs. cache coherence e locks em memória compartilhada.",
                                    "Avalie portabilidade: mensagem passing em clusters heterogêneos vs. shared memory limitada a máquinas SMP.",
                                    "Discuta padrões de comunicação: point-to-point e coletivas em MPI vs. redução/barreiras em OpenMP.",
                                    "Identifique trade-offs em performance para workloads balanceados vs. irregulares."
                                  ],
                                  "verification": "Preencha uma tabela de comparação com pelo menos 5 dimensões e justifique cada entrada.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Planilha Google Sheets ou LaTeX para tabelas, artigos comparativos como 'MPI vs. OpenMP'.",
                                  "tips": "Classifique comparações em categorias: programabilidade, performance, escalabilidade.",
                                  "learningObjective": "Desenvolver habilidades para análise comparativa sistemática dos modelos.",
                                  "commonMistakes": "Ignorar contexto de hardware; generalizar vantagens sem considerar workload específico."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Vantagens de Escalabilidade em Clusters e Nuvens",
                                  "subSteps": [
                                    "Explique por que troca de mensagens escala melhor em clusters (múltiplos nós sem memória compartilhada física).",
                                    "Compare decomposição em domínios distribuídos vs. centralizados em shared memory.",
                                    "Discuta casos de nuvens: elasticidade com containers (e.g., Kubernetes + MPI) vs. limitações de shared memory.",
                                    "Analise métricas: speedup linear em milhares de nós com message passing vs. limites em centenas com shared memory.",
                                    "Revise estudos de caso como TOP500 supercomputadores usando MPI."
                                  ],
                                  "verification": "Escreva um parágrafo identificando 3 vantagens específicas de escalabilidade da troca de mensagens.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Lista TOP500, papers sobre escalabilidade MPI em clouds (e.g., AWS ParallelCluster).",
                                  "tips": "Pense em 'escala horizontal' (mais nós) vs. 'vertical' (mais cores por nó).",
                                  "learningObjective": "Identificar contextos onde um modelo supera o outro em ambientes distribuídos.",
                                  "commonMistakes": "Confundir escalabilidade com performance absoluta; ignorar custos de rede em nuvens."
                                }
                              ],
                              "practicalExample": "Em um cluster de 100 nós simulando computação climática: use MPI para decompor o globo em grids por nó (troca de mensagens nas bordas), contrastando com OpenMP limitado a multi-core por nó, destacando como MPI permite escalar para milhares de processadores sem gargalos de memória compartilhada.",
                              "finalVerifications": [
                                "Pode listar e explicar 4 diferenças chave entre message passing e shared memory.",
                                "Identifica corretamente overheads de exclusão mútua em shared memory vs. latência de mensagens.",
                                "Descreve decomposição de domínio em ambos os contextos com exemplos.",
                                "Explica vantagens de escalabilidade de message passing para >1000 nós em clusters.",
                                "Cria uma tabela comparativa precisa com dimensões de programabilidade e performance.",
                                "Aplica conceitos a um cenário real de nuvem ou cluster."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições e comparações sem erros (30%)",
                                "Profundidade na análise de escalabilidade: identificação clara de vantagens (25%)",
                                "Uso de exemplos e evidências: inclusão de primitivas/bibliotecas (20%)",
                                "Estrutura lógica: tabela/diagrama bem organizada (15%)",
                                "Clareza e completude: cobertura de todos os aspectos solicitados (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: protocolos de comunicação e latência de rede em message passing.",
                                "Sistemas Operacionais: primitivas de sincronização como mutexes em shared memory.",
                                "Cloud Computing: orquestração em Kubernetes para workloads paralelos distribuídos.",
                                "Engenharia de Software: padrões de design para decomposição de domínios paralelos."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier (TOP500 #1), MPI é usado para simulações científicas em milhões de cores, escalando melhor que shared memory para análise de dados genômicos em clusters de nuvem AWS, evitando gargalos de sincronização em aplicações de IA distribuída."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.4.2",
                        "name": "Message Passing Interface (MPI)",
                        "description": "Biblioteca padrão para programação paralela em memória distribuída, fornecendo primitivas portáteis para troca de mensagens em plataformas multicores, heterogêneas e na nuvem.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.2.1",
                            "name": "Inicializar e finalizar programas MPI",
                            "description": "Implementar MPI_Init(), MPI_Comm_rank(), MPI_Comm_size() e MPI_Finalize() para configurar processos paralelos e obter identificadores e número de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento para MPI",
                                  "subSteps": [
                                    "Instalar o OpenMPI ou MPICH usando gerenciador de pacotes (ex: sudo apt install openmpi-bin libopenmpi-dev no Ubuntu).",
                                    "Verificar a instalação executando 'mpicc --version' ou 'mpirun --version' no terminal.",
                                    "Criar um diretório para o projeto e um arquivo fonte em C (ex: mpi_hello.c).",
                                    "Escrever um esqueleto básico de programa main() sem MPI para testar compilação.",
                                    "Compilar com 'mpicc mpi_hello.c -o mpi_hello' e executar './mpi_hello'."
                                  ],
                                  "verification": "O comando 'mpicc --version' retorna informações da versão e o programa esqueleto compila e executa sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Computador com Linux/Mac/Windows com WSL",
                                    "Acesso root/sudo para instalação",
                                    "Editor de texto (VS Code ou vim)"
                                  ],
                                  "tips": "Prefira OpenMPI para iniciantes; teste em máquina virtual se necessário.",
                                  "learningObjective": "Preparar o ambiente para compilar e executar programas MPI corretamente.",
                                  "commonMistakes": [
                                    "Instalar apenas binários sem bibliotecas de desenvolvimento (libopenmpi-dev)",
                                    "Usar 'gcc' em vez de 'mpicc'",
                                    "Esquecer de recarregar o shell após instalação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a inicialização com MPI_Init()",
                                  "subSteps": [
                                    "Incluir a biblioteca no topo do arquivo: #include <mpi.h>.",
                                    "Declarar argc e argv na main: int main(int argc, char** argv).",
                                    "Chamar MPI_Init(&argc, &argv); logo após o início da main.",
                                    "Verificar o retorno: int ierr = MPI_Init(&argc, &argv); if(ierr != MPI_SUCCESS) { erro handling }.",
                                    "Adicionar printf(\"MPI inicializado\\n\"); para teste."
                                  ],
                                  "verification": "Programa compila com mpicc e executa com mpirun -np 1 sem crashes ou erros de inicialização.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Arquivo mpi_hello.c",
                                    "Compilador mpicc",
                                    "Terminal"
                                  ],
                                  "tips": "Sempre passe &argc e &argv para MPI_Init permitir argumentos do mpirun.",
                                  "learningObjective": "Inicializar corretamente o ambiente MPI para processos paralelos.",
                                  "commonMistakes": [
                                    "Chamar MPI_Init múltiplas vezes",
                                    "Não incluir <mpi.h>",
                                    "Esquecer de passar ponteiros para argc/argv"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Obter rank e size com MPI_Comm_rank() e MPI_Comm_size()",
                                  "subSteps": [
                                    "Declarar variáveis: int rank, size;.",
                                    "Chamar MPI_Comm_rank(MPI_COMM_WORLD, &rank); para obter o ID do processo.",
                                    "Chamar MPI_Comm_size(MPI_COMM_WORLD, &size); para obter o número total de processos.",
                                    "Adicionar printf(\"Processo %d de %d: Olá!\\n\", rank, size);.",
                                    "Verificar erros nos retornos das funções MPI."
                                  ],
                                  "verification": "Ao executar mpirun -np 4, cada processo imprime rank único de 0 a 3 e size=4 corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código com MPI_Init já implementado",
                                    "mpicc e mpirun"
                                  ],
                                  "tips": "MPI_COMM_WORLD é o comunicador padrão para todos os processos.",
                                  "learningObjective": "Identificar e acessar informações básicas do processo no contexto paralelo.",
                                  "commonMistakes": [
                                    "Usar MPI_COMM_WORLD sem inicializar",
                                    "Não usar ponteiro em &rank",
                                    "Executar sem mpirun -np N"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar o programa com MPI_Finalize() e executar em paralelo",
                                  "subSteps": [
                                    "Chamar MPI_Finalize(); imediatamente antes do return 0;.",
                                    "Garantir que não haja chamadas MPI após Finalize.",
                                    "Compilar: mpicc mpi_hello.c -o mpi_hello.",
                                    "Executar: mpirun -np 4 ./mpi_hello (testar com diferentes np).",
                                    "Verificar saída ordenada ou usar barramento se necessário para sincronia."
                                  ],
                                  "verification": "Programa executa sem warnings de processos zumbis e MPI_Finalize é chamado em todos os processos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código completo",
                                    "mpirun"
                                  ],
                                  "tips": "Finalize deve ser o último chamado MPI; use -hostfile para multi-máquina.",
                                  "learningObjective": "Encerrar corretamente o ambiente MPI evitando vazamentos.",
                                  "commonMistakes": [
                                    "Chamar Finalize antes de outras chamadas MPI",
                                    "Executar sem mpirun",
                                    "Ignorar código de retorno do Finalize"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa completo 'mpi_hello.c':\n#include <mpi.h>\n#include <stdio.h>\nint main(int argc, char** argv) {\n  MPI_Init(&argc, &argv);\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  printf(\"Olá do processo %d de %d\\n\", rank, size);\n  MPI_Finalize();\n  return 0;\n}\nCompilar e rodar: mpicc mpi_hello.c -o hello; mpirun -np 4 ./hello",
                              "finalVerifications": [
                                "Programa compila sem erros com mpicc.",
                                "Execução com mpirun -np N imprime N linhas únicas com ranks corretos.",
                                "Nenhum erro ou warning de MPI no output.",
                                "Processos terminam limpos sem zumbis (verificar com ps aux | grep mpirun).",
                                "Funciona com diferentes valores de N (1 a 8).",
                                "Código trata potenciais erros de chamadas MPI."
                              ],
                              "assessmentCriteria": [
                                "Todas as funções MPI_Init, MPI_Comm_rank, MPI_Comm_size e MPI_Finalize são usadas corretamente.",
                                "Ordem de chamadas é respeitada (Init primeiro, Finalize último).",
                                "Variáveis rank e size são declaradas e usadas adequadamente.",
                                "Programa é compilável e executável em ambiente MPI padrão.",
                                "Saída demonstra paralelismo correto.",
                                "Código é limpo, comentado e sem vazamentos óbvios."
                              ],
                              "crossCurricularConnections": [
                                "Programação em C: Uso de ponteiros e argumentos de main.",
                                "Sistemas Operacionais: Gerenciamento de processos e execução paralela.",
                                "Computação de Alto Desempenho: Introdução a modelos de memória distribuída.",
                                "Algoritmos Paralelos: Base para troca de mensagens.",
                                "Engenharia de Software: Configuração de ambientes de desenvolvimento."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (ex: ECMWF usa MPI para distribuir cálculos em milhares de processos em supercomputadores), processamento de big data em clusters Hadoop/Spark ou machine learning distribuído em TensorFlow/PyTorch com backends MPI."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.4.1.1"
                            ]
                          },
                          {
                            "id": "10.1.1.4.2.2",
                            "name": "Realizar envio e recepção de mensagens",
                            "description": "Utilizar MPI_Send(), MPI_Recv(), MPI_Bsend() e MPI_Isend() para comunicação síncrona e assíncrona ponto-a-ponto, especificando buffers, contadores, tipos de dados e comunicadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e implementar comunicação síncrona básica com MPI_Send e MPI_Recv",
                                  "subSteps": [
                                    "Instalar e verificar MPI (ex: OpenMPI ou MPICH) com 'mpirun --version'.",
                                    "Escrever código C/MPI inicializando MPI_Init, obtendo rank e size com MPI_Comm_rank e MPI_Comm_size.",
                                    "Implementar MPI_Send no processo 0 para enviar dados (buffer, count, datatype, dest rank, tag, communicator) para processo 1.",
                                    "Implementar MPI_Recv no processo 1 para receber os dados (buffer, count, datatype, source rank, tag, communicator, status).",
                                    "Finalizar com MPI_Finalize e imprimir dados recebidos para verificação."
                                  ],
                                  "verification": "Compilar com 'mpicc programa.c -o programa' e executar 'mpirun -np 2 ./programa'; verificar se processo 1 recebe e imprime dados corretos do processo 0.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Compilador MPI (mpicc), editor de código (VSCode ou similar), terminal.",
                                  "tips": "Sempre use MPI_COMM_WORLD como comunicador inicial e tag=0 para simplicidade.",
                                  "learningObjective": "Dominar sintaxe e semântica de MPI_Send e MPI_Recv para troca bloqueante ponto-a-ponto.",
                                  "commonMistakes": "Esquecer de incluir <mpi.h>; não chamar MPI_Init antes de usar funções MPI; mismatch em count/datatype entre send/recv."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar comunicação assíncrona não-bloqueante com MPI_Isend e MPI_Wait",
                                  "subSteps": [
                                    "Modificar código do Step 1 para usar MPI_Isend no processo 0 (retorna request handle imediatamente).",
                                    "No processo 1, usar MPI_Recv (bloqueante) ou MPI_Irecv para receber.",
                                    "Após Isend, chamar MPI_Wait(&request, &status) no processo 0 para aguardar conclusão.",
                                    "Adicionar múltiplas Isend em loop para simular overlap de comunicação e computação.",
                                    "Compilar e testar com mpirun -np 2, verificando timestamps ou contadores para overlap."
                                  ],
                                  "verification": "Executar programa e confirmar que comunicação não bloqueia computação extra (ex: adicionar delay e medir tempo total menor que síncrono).",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Mesmo do Step 1, mais MPI_Request e MPI_Status variáveis.",
                                  "tips": "Use MPI_Wait para polling simples; para produção, considere MPI_Test em loops.",
                                  "learningObjective": "Entender benefícios de comunicação não-bloqueante para hiding latency em aplicações paralelas.",
                                  "commonMistakes": "Não aguardar Isend com Wait (perda de dados); esquecer de inicializar MPI_Request."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar MPI_Bsend para envio buffered e combinar paradigmas",
                                  "subSteps": [
                                    "Configurar buffer estático com MPI_Bsend_init ou usar MPI_Buffer_attach para reserva de buffer.",
                                    "Implementar MPI_Bsend no processo 0 (envio buffered, não bloqueia até buffer cheio).",
                                    "No processo 1, usar MPI_Recv para receber do Bsend.",
                                    "Combinar Send, Isend e Bsend em um programa que testa cenários diferentes (ex: grande volume de dados).",
                                    "Liberar buffer com MPI_Buffer_detach se usado."
                                  ],
                                  "verification": "Executar com dados grandes (> buffer padrão) e verificar que não trava, imprimindo confirmações de envio/recepção.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Mesmo do Step 1, mais buffer array (ex: char buffer[10000]).",
                                  "tips": "MPI_Bsend é útil para envios pequenos/frequentes; reserve buffer 16x mensagem máxima.",
                                  "learningObjective": "Aplicar envios buffered para decoupling de comunicação em cargas variáveis.",
                                  "commonMistakes": "Buffer insuficiente causando deadlock; não chamar MPI_Init_threads se necessário."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar programa completo com múltiplos processos e depuração",
                                  "subSteps": [
                                    "Expandir para ring communication: cada processo envia/recv para next/prev usando Send/Recv/Isend/Bsend rotacionados.",
                                    "Adicionar MPI_Barrier para sincronização se necessário e MPI_Get_processor_name para debug.",
                                    "Compilar e executar com np=4 ou 8, variando tamanhos de mensagem.",
                                    "Usar mpirun --oversubscribe se em máquina single-node e analisar saída com diff ou grep.",
                                    "Otimizar: medir tempo com MPI_Wtime antes/depois de blocos de comunicação."
                                  ],
                                  "verification": "Programa roda sem deadlocks, todas mensagens chegam corretas em todos ranks; tempo de execução reportado.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "mpirun, valgrind-mpi para debug de memory leaks (opcional).",
                                  "tips": "Use tags diferentes para múltiplas mensagens; debug com printf + fflush(stdout).",
                                  "learningObjective": "Integrar síncrono/assíncrono/buffered em topologias reais de comunicação.",
                                  "commonMistakes": "Deadlock em ring sem coordenação; tags errados causando recv pendente."
                                }
                              ],
                              "practicalExample": "Programa em C onde 4 processos formam um ring: processo i envia array de 1000 ints para i+1 (mod 4) usando MPI_Isend seguido de computação local (soma), então MPI_Wait e MPI_Send para confirmação; processo 0 usa MPI_Bsend para iniciar com grande buffer. Saída: cada rank imprime soma recebida e tempo total < 1s.",
                              "finalVerifications": [
                                "Programa compila sem warnings com mpicc -Wall -g.",
                                "Executa com mpirun -np 4 sem deadlocks ou erros MPI (verificar MPI_Error_string).",
                                "Dados enviados/recebidos idênticos (checksum ou print).",
                                "Tempo de Isend + compute < tempo puro Send (overlap verificado).",
                                "Funciona com diferentes np (2,4,8) e tamanhos de mensagem.",
                                "Sem memory leaks (valgrind-mpi mostra clean)."
                              ],
                              "assessmentCriteria": [
                                "Correta especificação de buffers, counts, datatypes, ranks, tags e communicators em todas chamadas.",
                                "Uso apropriado de síncrono vs assíncrono vs buffered baseado em cenário.",
                                "Tratamento de MPI_Status para contagens reais recebidas.",
                                "Ausência de deadlocks em execuções multi-processo.",
                                "Eficiência: overlap demonstrado em benchmarks simples.",
                                "Código limpo, comentado e modular."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Analogia com sockets TCP/UDP para compreensão de latency/bandwidth.",
                                "Algoritmos Paralelos: Pré-requisito para collective operations como MPI_Allreduce.",
                                "Sistemas Operacionais: Concorrência, threads e race conditions em contextos distribuídos.",
                                "Engenharia de Software: Debugging distribuído e profiling com tools como mpiP."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: modelagem climática no Argonne National Lab), MPI_Send/Recv/Isend/Bsend habilitam troca eficiente de grids de dados entre milhares de nodes, reduzindo tempo de iterações de horas para minutos em supercomputadores como Frontier."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.1.4.2.3",
                            "name": "Aplicar operações coletivas em MPI",
                            "description": "Implementar MPI_Bcast(), MPI_Reduce(), MPI_Allgather() e MPI_Scatter() para comunicação em grupo, analisando seu impacto em algoritmos paralelos como soma global ou difusão.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambiente MPI e Entender Conceitos de Operações Coletivas",
                                  "subSteps": [
                                    "Instalar OpenMPI ou MPICH no sistema local.",
                                    "Compilar e executar um programa MPI básico com MPI_Init, MPI_Comm_rank e MPI_Finalize.",
                                    "Estudar documentação oficial do MPI para MPI_Bcast, MPI_Reduce, MPI_Allgather e MPI_Scatter.",
                                    "Identificar diferenças entre comunicação ponto-a-ponto e coletiva.",
                                    "Diagramar fluxos de dados para cada operação coletiva."
                                  ],
                                  "verification": "Programa básico MPI executa corretamente com mpirun -np 4 e imprime ranks corretos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "OpenMPI/MPICH instalado",
                                    "Compilador C (gcc)",
                                    "Documentação MPI oficial (man pages ou mpi-forum.org)"
                                  ],
                                  "tips": "Use mpirun -np <num> para testar com múltiplos processos; sempre verifique MPI_SUCCESS.",
                                  "learningObjective": "Compreender o papel das operações coletivas na sincronização e troca eficiente de dados em grupos de processos.",
                                  "commonMistakes": [
                                    "Esquecer de inicializar MPI com MPI_Init",
                                    "Não chamar MPI_Finalize",
                                    "Confundir communicator MPI_COMM_WORLD"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Bcast para Distribuição de Dados",
                                  "subSteps": [
                                    "Escrever código para um processo raiz enviar dados a todos os outros via MPI_Bcast.",
                                    "Definir buffer, count, datatype, root e communicator corretamente.",
                                    "Compilar com mpicc e testar com 4-8 processos.",
                                    "Medir tempo de execução comparando com loops ponto-a-ponto.",
                                    "Variar tamanho do buffer para observar escalabilidade."
                                  ],
                                  "verification": "Todos os processos recebem o mesmo valor broadcasted e imprimem confirmação idêntica.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Editor de código (VS Code ou Vim)",
                                    "Terminal com mpirun"
                                  ],
                                  "tips": "O buffer deve ser alocado antes do Bcast e acessível por todos; root é relativo ao communicator.",
                                  "learningObjective": "Dominar MPI_Bcast para inicialização eficiente de dados comuns em algoritmos paralelos.",
                                  "commonMistakes": [
                                    "Usar buffer local não compartilhado",
                                    "Datatype incompatível com count",
                                    "Executar com np=1 onde Bcast é trivial"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Reduce para Computações de Redução",
                                  "subSteps": [
                                    "Implementar soma global usando MPI_Reduce com operação MPI_SUM.",
                                    "Especificar sendbuf, recvbuf (no root), count, datatype, op, root e communicator.",
                                    "Testar com vetores de números aleatórios em múltiplos processos.",
                                    "Experimentar outras operações como MPI_MAX e MPI_MIN.",
                                    "Analisar impacto no tempo de soma serial vs paralelo."
                                  ],
                                  "verification": "Processo root recebe soma correta de todos os valores; outros processos imprimem seus contribuições.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código base do Step 2",
                                    "GDB para debug se necessário"
                                  ],
                                  "tips": "Recvbuf só é preenchido no root; use MPI_IN_PLACE para otimizar quando possível.",
                                  "learningObjective": "Aplicar MPI_Reduce para agregações eficientes como somas globais em simulações paralelas.",
                                  "commonMistakes": [
                                    "Confundir sendbuf com recvbuf",
                                    "Op não pré-definida",
                                    "Root não coleta resultado"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar MPI_Allgather e MPI_Scatter para Troca Irregular",
                                  "subSteps": [
                                    "Codificar MPI_Scatter para distribuir array do root para processos individuais.",
                                    "Implementar MPI_Allgather para que todos recebam dados de todos.",
                                    "Combinar em exemplo de matriz distribuição (Scatter) e coleta (Allgather).",
                                    "Compilar, executar e validar resultados com np=4.",
                                    "Comparar performance com Alltoall se disponível."
                                  ],
                                  "verification": "Cada processo recebe porção correta via Scatter e todos têm array completo via Allgather.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Arrays dinâmicos em C"
                                  ],
                                  "tips": "Count uniforme para todos processos em Scatter/Allgather; aloque buffers adequadamente.",
                                  "learningObjective": "Usar Scatter e Allgather para padrões de difusão e coleta em algoritmos distribuídos.",
                                  "commonMistakes": [
                                    "Tamanhos de buffer inconsistentes",
                                    "Esquecer displ em variantes avançadas",
                                    "Não sincronizar com barriers"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar Impacto em Algoritmos Paralelos e Otimizar",
                                  "subSteps": [
                                    "Integrar operações em algoritmo de soma global e difusão de Monte Carlo.",
                                    "Usar MPI_Wtime para medir speedup e eficiência.",
                                    "Identificar gargalos com profiling básico (np variando de 2 a 16).",
                                    "Otimizar com MPI_IN_PLACE e datatypes derivados.",
                                    "Documentar trade-offs (latência vs bandwidth)."
                                  ],
                                  "verification": "Algoritmo atinge speedup linear; resultados coincidem com versão serial.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "MPI com suporte a timing",
                                    "Gráficos simples via gnuplot para plotar speedup"
                                  ],
                                  "tips": "Teste em cluster se possível; considere topologia de rede.",
                                  "learningObjective": "Avaliar performance de coletivas em contextos reais para design de algoritmos paralelos.",
                                  "commonMistakes": [
                                    "Não normalizar tempos",
                                    "Ignorar overhead de inicialização",
                                    "Sobrecarga com np muito alto"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente uma soma global paralela: Cada processo gera 100 números aleatórios, usa MPI_Reduce(MPI_SUM) no rank 0 para somar tudo, e root imprime o total. Compare tempo com implementação manual via sends/recvs.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros com mpirun -np 8.",
                                "Resultados de Bcast, Reduce, Allgather e Scatter são corretos em todos processos.",
                                "Speedup demonstrado > 3x para np=4 em soma global.",
                                "Nenhum deadlock ou race condition observado.",
                                "Código limpo com comentários e error checking.",
                                "Performance varia corretamente com tamanho de dados."
                              ],
                              "assessmentCriteria": [
                                "Uso correto de parâmetros em todas as chamadas coletivas (buffers, ops, roots).",
                                "Eficiência comprovada via medições de tempo e speedup.",
                                "Análise de impacto inclui trade-offs (ex: Bcast vs Send para N=2).",
                                "Tratamento de erros com MPI_Error_string.",
                                "Código modular e reutilizável.",
                                "Validação cruzada com casos edge (np=1, buffers zero)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Computacional: Reduções em álgebra linear paralela.",
                                "Algoritmos: Paralelização de prefix sums e difusões.",
                                "Engenharia de Software: Design de APIs distribuídas.",
                                "Análise de Sistemas: Modelos de performance (Amdahl's Law).",
                                "Ciência de Dados: MPI em frameworks como PyTorch Distributed."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas (difusão de parâmetros via Bcast), treinamento distribuído de ML (reduções de gradientes), e processamento de big data em HPC clusters como TOP500."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.4.2.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.4.3",
                        "name": "Topologias, Comunicadores e Avaliação de Desempenho",
                        "description": "Estruturas avançadas em MPI para organização de processos e métricas para avaliar eficiência de programas baseados em troca de mensagens.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.3.1",
                            "name": "Configurar comunicadores e topologias",
                            "description": "Criar subcomunicadores com MPI_Comm_split() e definir topologias cartesianas ou grafos com MPI_Cart_create() e MPI_Graph_create() para otimizar comunicação em redes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender e Configurar Subcomunicadores com MPI_Comm_split",
                                  "subSteps": [
                                    "Estude a documentação oficial do MPI para MPI_Comm_split, focando em parâmetros key, color e communicator.",
                                    "Escreva um programa simples que divide o comunicador MPI_COMM_WORLD em dois subcomunicadores baseados em rank par/ímpar.",
                                    "Implemente MPI_Comm_rank e MPI_Comm_size nos subcomunicadores para verificar a divisão.",
                                    "Teste a comunicação intra-subcomunicador com MPI_Send e MPI_Recv.",
                                    "Libere os subcomunicadores com MPI_Comm_free."
                                  ],
                                  "verification": "Execute o programa com mpirun -np 4 e confirme que processos pares e ímpares se comunicam separadamente sem erros.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Instalação do OpenMPI ou MPICH, editor de código (VS Code ou similar), terminal para mpirun.",
                                  "tips": "Use chaves (key) crescentes para ordenação estável nos subcomunicadores.",
                                  "learningObjective": "Dominar a criação e uso de subcomunicadores para particionar grupos de processos.",
                                  "commonMistakes": "Esquecer de chamar MPI_Comm_free, levando a vazamentos de memória; usar cor (color) incorreta causando subcomunicadores vazios."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Topologias Cartesianas com MPI_Cart_create",
                                  "subSteps": [
                                    "Defina dimensões e períodos para uma grade 2D (ex: 2x2 com períodos falsos).",
                                    "Crie o topologia cartesiana usando MPI_Cart_create no MPI_COMM_WORLD.",
                                    "Obtenha coordenadas de ranks com MPI_Cart_coords e vizinhos com MPI_Cart_shift.",
                                    "Implemente troca de mensagens entre vizinhos (cima/baixo, esquerda/direita).",
                                    "Verifique ranks e coordenadas com MPI_Cart_rank."
                                  ],
                                  "verification": "Execute com mpirun -np 4; confirme que mensagens são trocadas corretamente entre vizinhos cartesianos via logs.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "OpenMPI instalado, exemplos de código MPI, debugger como TotalView (opcional).",
                                  "tips": "Comece com grades pequenas (2D 2x2) para depuração visual.",
                                  "learningObjective": "Criar e utilizar topologias cartesianas para otimizar padrões de comunicação regulares.",
                                  "commonMistakes": "Definir dimensões incompatíveis com número de processos (produto deve igualar np); ignorar retorno de MPI_Cart_create para communicator inválido."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar Topologias de Grafos com MPI_Graph_create",
                                  "subSteps": [
                                    "Defina índices e arestas para um grafo simples (ex: linha ou anel com 4 nós).",
                                    "Crie o topologia de grafo usando MPI_Graph_create com arrays index e edges.",
                                    "Use MPI_Graph_neighbors_count e MPI_Graph_neighbors para obter vizinhos.",
                                    "Implemente comunicação all-to-all restrita aos vizinhos do grafo.",
                                    "Compare desempenho com MPI_COMM_WORLD usando MPI_Wtime."
                                  ],
                                  "verification": "Execute com mpirun -np 4; verifique logs mostrando comunicação apenas entre vizinhos definidos no grafo.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Compilador MPI (mpicc), scripts de timing, documentação MPI 3.1+.",
                                  "tips": "Valide arrays index e edges: soma de degrees deve ser 2*arestas.",
                                  "learningObjective": "Modelar comunicações irregulares com topologias de grafos para eficiência em redes esparsas.",
                                  "commonMistakes": "Índices não ordenados ou duplicados em edges; não verificar se communicator retornado é MPI_COMM_NULL."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar Comunicadores e Topologias para Otimização",
                                  "subSteps": [
                                    "Combine MPI_Comm_split com MPI_Cart_create para subgrades cartesianas.",
                                    "Crie um grafo híbrido: divida em subcomunicadores e aplique topologias internas.",
                                    "Meça latência e throughput com MPI_Barrier e MPI_Wtime em diferentes topologias.",
                                    "Otimize roteamento comparando cart vs graph vs world.",
                                    "Documente ganhos de performance em um relatório simples."
                                  ],
                                  "verification": "Execute benchmarks com mpirun -np 8+; confirme redução de tempo de comunicação em topologias otimizadas (>10%).",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Cluster ou multi-core com OpenMPI, ferramentas de profiling como mpiP.",
                                  "tips": "Use MPI_Graph_neighbors para minimizar saltos desnecessários em grafos.",
                                  "learningObjective": "Otimizar comunicação em aplicações paralelas combinando comunicadores e topologias.",
                                  "commonMistakes": "Não inicializar/finalizar MPI corretamente em subcomunicadores; sobrecarregar com np muito alto sem hardware adequado."
                                }
                              ],
                              "practicalExample": "Em uma simulação de grade 2D para difusão de calor: Use MPI_Comm_split para dividir em subgrupos regionais, aplique MPI_Cart_create para comunicação local eficiente, e MPI_Graph_create para conexões de borda irregulares, reduzindo overhead de mensagens globais.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros de MPI em pelo menos 4 processos.",
                                "Subcomunicadores são criados corretamente (MPI_Comm_size >0 para membros).",
                                "Topologias cartesianas e grafos retornam vizinhos esperados via MPI_Cart_shift/MPI_Graph_neighbors.",
                                "Comunicação ocorre apenas entre vizinhos definidos, sem cross-talk.",
                                "Tempos de execução mostram otimização (>15% faster que MPI_COMM_WORLD).",
                                "Todos communicators são liberados sem warnings de memory leak."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação de MPI_Comm_split (divisão correta por color/key).",
                                "Correta definição de dimensões/períodos em MPI_Cart_create e validação de coords.",
                                "Validação de grafos (arrays index/edges corretos, vizinhos matching).",
                                "Integração funcional de múltiplas topologias em um programa coeso.",
                                "Análise quantitativa de performance com métricas claras.",
                                "Código limpo, comentado e portable (MPI standard-compliant)."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: Modelagem de redes de comunicação como grafos não-direcionados.",
                                "Algoritmos Paralelos: Otimização de stencil computations em grades cartesianas.",
                                "Redes de Computadores: Roteamento e topologias em clusters HPC.",
                                "Análise de Desempenho: Medição de bandwidth/latência em modelos de memória distribuída."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas ou CFD (Computational Fluid Dynamics), onde topologias cartesianas otimizam exchanges em malhas estruturadas, e grafos modelam malhas não-estruturadas, reduzindo tempo de simulação em ordens de magnitude em clusters como os do TOP500."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.1.4.3.2",
                            "name": "Avaliar desempenho de programas MPI",
                            "description": "Medir speedup, eficiência e overhead de comunicação usando ferramentas como MPI_Wtime() e análise de lei de Amdahl/Gustafson, com estudo de casos de aplicações paralelas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Instrumentar programa MPI com MPI_Wtime() para medição de tempo",
                                  "subSteps": [
                                    "Inclua as bibliotecas MPI necessárias (mpi.h) e inicialize o ambiente com MPI_Init().",
                                    "Insira chamadas MPI_Wtime() no início e fim das seções críticas do código (ex: computação principal e comunicação).",
                                    "Registre tempos locais em cada processo e use MPI_Reduce para agregar o tempo máximo ou médio entre processos.",
                                    "Adicione MPI_Barrier() antes das medições para sincronizar processos e evitar discrepâncias.",
                                    "Compile o programa com mpicc e execute com mpirun em 1 processo para obter tempo serial (baseline)."
                                  ],
                                  "verification": "O programa compila e executa sem erros, imprimindo tempos consistentes em múltiplas runs.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Máquina multi-core ou cluster acessível",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Sempre meça o tempo wall-clock com MPI_Wtime() em vez de CPU time para capturar overhead real.",
                                  "learningObjective": "Dominar a instrumentação básica de tempo em programas MPI para dados confiáveis.",
                                  "commonMistakes": [
                                    "Esquecer sincronização com MPI_Barrier()",
                                    "Usar tempo local sem redução coletiva",
                                    "Não medir comunicação separadamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar programa em diferentes configurações de processos e coletar dados",
                                  "subSteps": [
                                    "Execute o programa com mpirun -np 1, 2, 4, 8, 16 processos, registrando tempo total (T_p) para cada.",
                                    "Repita execuções (mínimo 5 runs por configuração) e calcule média e desvio padrão dos tempos.",
                                    "Varie tamanhos de input para observar escalabilidade (ex: matrizes de 100x100 a 1000x1000).",
                                    "Registre separadamente tempos de computação (T_comp) e comunicação (T_comm) usando múltiplos Wtime().",
                                    "Armazene dados em tabela (CSV ou planilha) com colunas: np, T_p, T_comp, T_comm."
                                  ],
                                  "verification": "Tabela completa com dados reproduzíveis, mostrando tempos decrescentes com mais processos até um ponto.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Cluster ou máquina multi-core",
                                    "Ferramenta de planilhas (Excel/Google Sheets)",
                                    "Programa MPI instrumentado do Step 1"
                                  ],
                                  "tips": "Use --oversubscribe no mpirun se processos excederem núcleos disponíveis.",
                                  "learningObjective": "Coletar dados empíricos de desempenho para análise quantitativa.",
                                  "commonMistakes": [
                                    "Poucas runs levando a variância alta",
                                    "Ignorar overhead de inicialização MPI",
                                    "Não variar workload"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular métricas de desempenho: speedup, eficiência e overhead",
                                  "subSteps": [
                                    "Calcule speedup S(p) = T_1 / T_p para cada p (número de processos).",
                                    "Calcule eficiência E(p) = S(p) / p, expressa em porcentagem.",
                                    "Estime overhead de comunicação como fração T_comm / T_p e isoefficiency.",
                                    "Plote gráficos: S(p) vs p, E(p) vs p usando ferramentas como Python/Matplotlib ou Gnuplot.",
                                    "Identifique gargalos onde S(p) < linear ou E(p) < 80%."
                                  ],
                                  "verification": "Gráficos gerados com cálculos corretos validados manualmente (ex: S(2) ≈ 1.8 para bom scaling).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com NumPy/Matplotlib ou Gnuplot",
                                    "Dados da tabela do Step 2"
                                  ],
                                  "tips": "Use speedup superlinear como indício de efeitos de cache, não bug.",
                                  "learningObjective": "Aplicar fórmulas padrão para quantificar desempenho paralelo.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Dividir por zero em T_1",
                                    "Ignorar variância nos plots"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar com Leis de Amdahl e Gustafson e estudar casos",
                                  "subSteps": [
                                    "Estime fração serial f da Lei de Amdahl: S_max = 1 / (f + (1-f)/p), ajuste f aos dados.",
                                    "Aplique Lei de Gustafson para workloads escaláveis: S(p) = p*(1-f) + f.",
                                    "Compare predições das leis com dados empíricos via ajuste de curvas.",
                                    "Estude caso: analise código de PI Monte Carlo ou stencil em MPI, reproduza resultados de papers.",
                                    "Documente insights: limites teóricos vs reais, otimizações sugeridas."
                                  ],
                                  "verification": "Relatório com curvas ajustadas onde predições batem dados dentro de 10% de erro.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Códigos de exemplo (GitHub: MPI Monte Carlo)",
                                    "Ferramentas de plotagem",
                                    "Papers sobre Amdahl/Gustafson"
                                  ],
                                  "tips": "Use scaled speedup de Gustafson para apps com memória-bound.",
                                  "learningObjective": "Interpretar limites teóricos e práticos de paralelismo.",
                                  "commonMistakes": [
                                    "Aplicar Amdahl a problemas escaláveis",
                                    "Confundir f serial com overhead",
                                    "Não validar com casos reais"
                                  ]
                                }
                              ],
                              "practicalExample": "Desenvolva um programa MPI para multiplicação de matrizes densa (NxN). Meça T_1 em 1 processo, T_p em 4-16 processos. Calcule S(4)=3.2, E(4)=80%, overhead comm=15%. Ajuste Amdahl f=0.1 prevendo S_max(16)=8.5, valide com plots.",
                              "finalVerifications": [
                                "Gere speedup >1.5 em pelo menos 3 configurações de p.",
                                "Eficiência calculada corretamente abaixo de 100% com interpretação.",
                                "Overhead de comunicação isolado e <30% do tempo total.",
                                "Predições de Amdahl/Gustafson alinhadas com dados empíricos.",
                                "Análise de caso com pelo menos 2 insights acionáveis.",
                                "Gráficos claros e reproduzíveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas métricas (erro <5%).",
                                "Uso correto e consistente de MPI_Wtime() e collectives.",
                                "Qualidade dos plots e tabelas (legendas, eixos rotulados).",
                                "Profundidade da análise teórica vs empírica.",
                                "Identificação de gargalos e sugestões de otimização.",
                                "Reprodutibilidade: código e dados compartilháveis."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Impacto de topologias de rede em overhead.",
                                "Algoritmos e Estruturas de Dados: Decomposição para paralelismo.",
                                "Estatística: Análise de variância e regressão nos dados.",
                                "Otimização e Engenharia de Software: Profiling e tuning.",
                                "Física Computacional: Casos em simulações paralelas."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, engenheiros usam essas análises para otimizar simulações climáticas, molecular dynamics ou IA distribuída, reduzindo tempo de run de dias para horas e maximizando uso de petascale systems."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.4.2.3"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.5",
                    "name": "Decomposição de Domínio",
                    "description": "Técnica de divisão de dados para programação paralela em memória compartilhada.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.5.1",
                        "name": "Fundamentos da Decomposição de Domínio",
                        "description": "Conceitos básicos da decomposição de domínio como técnica de divisão de dados em programação paralela, especialmente em sistemas de memória compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.5.1.1",
                            "name": "Definir Decomposição de Domínio",
                            "description": "Explicar o que é decomposição de domínio, diferenciando-a de outras técnicas como decomposição funcional, e sua relevância na taxonomia de Flynn para arquiteturas MIMD com memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a definição básica de decomposição de domínio",
                                  "subSteps": [
                                    "Leia a definição padrão: divisão do problema em subdomínios espaciais ou temporais independentes.",
                                    "Identifique características principais: independência relativa dos subdomínios e paralelização natural.",
                                    "Estude exemplos iniciais em problemas contínuos como equações diferenciais parciais (EDPs).",
                                    "Anote os benefícios: escalabilidade e simplicidade em arquiteturas paralelas.",
                                    "Compare brevemente com decomposição de tarefas para fixar o foco espacial."
                                  ],
                                  "verification": "Escreva uma definição em suas palavras e liste 3 características principais.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Artigo sobre programação paralela (ex: 'Introduction to Parallel Computing' de Grama)",
                                    "Vídeo introdutório no YouTube sobre decomposição de domínio",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Visualize o domínio como um mapa dividido em regiões para facilitar a compreensão.",
                                  "learningObjective": "Ao final deste passo, você será capaz de definir decomposição de domínio com precisão.",
                                  "commonMistakes": [
                                    "Confundir com divisão de código em funções",
                                    "Ignorar o aspecto espacial/temporal do domínio"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diferenciar decomposição de domínio de decomposição funcional",
                                  "subSteps": [
                                    "Defina decomposição funcional: divisão baseada em tarefas ou funções independentes do problema.",
                                    "Compare critérios: domínio foca em geometria/espaço, funcional em lógica/algoritmo.",
                                    "Analise tabela comparativa: independência, granularidade e overhead de comunicação.",
                                    "Estude casos onde uma é preferível à outra (ex: EDPs vs. processamento de imagem).",
                                    "Crie um diagrama ilustrando as diferenças."
                                  ],
                                  "verification": "Crie uma tabela comparativa com pelo menos 4 colunas e preencha com exemplos.",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Slides sobre técnicas de decomposição (ex: curso de programação paralela online)",
                                    "Ferramenta de desenho como Draw.io ou papel e caneta",
                                    "Referência: Quinn 'Parallel Programming in C with MPI and OpenMP'"
                                  ],
                                  "tips": "Use analogias: domínio como cortar uma pizza por fatias, funcional por ingredientes.",
                                  "learningObjective": "Ao final, diferencie claramente as duas técnicas com exemplos.",
                                  "commonMistakes": [
                                    "Achar que são sinônimos",
                                    "Não considerar overhead de comunicação em cada uma"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Revisar a Taxonomia de Flynn e seu contexto",
                                  "subSteps": [
                                    "Recapitule os 4 quadrantes: SISD, SIMD, MISD, MIMD.",
                                    "Foquem em MIMD: múltiplas instruções, múltiplos dados – flexível para problemas irregulares.",
                                    "Relacione decomposição de domínio com MIMD: permite alocação independente de subdomínios a processadores.",
                                    "Estude impacto na programação paralela: abstrai hardware heterogêneo.",
                                    "Anote exemplos de arquiteturas MIMD modernas (ex: clusters, GPUs multicore)."
                                  ],
                                  "verification": "Desenhe a matriz de Flynn e destaque MIMD com uma anotação sobre decomposição.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Diagrama da Taxonomia de Flynn (Wikipedia ou livro texto)",
                                    "Vídeo explicativo de 10 min sobre Flynn",
                                    "Folha de papel para matriz"
                                  ],
                                  "tips": "Memorize acrônimo MIMD como 'Muitos Independentes, Múltiplos Dados'.",
                                  "learningObjective": "Compreender como decomposição de domínio se encaixa na taxonomia.",
                                  "commonMistakes": [
                                    "Confundir MIMD com SIMD",
                                    "Esquecer que Flynn é sobre instruções e dados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com arquiteturas MIMD e memória compartilhada",
                                  "subSteps": [
                                    "Explique memória compartilhada em MIMD: acesso global, mas com contenção.",
                                    "Discuta relevância da decomposição: minimiza comunicações via domínios locais.",
                                    "Analise trade-offs: balanceamento de carga vs. fronteiras de domínio.",
                                    "Estude bibliotecas como PETSc ou OpenMP para suporte.",
                                    "Simule um cenário simples de alocação de subdomínios."
                                  ],
                                  "verification": "Escreva um parágrafo explicando a relevância em MIMD com memória compartilhada.",
                                  "estimatedTime": "30-40 minutos",
                                  "materials": [
                                    "Documentação OpenMP ou MPI",
                                    "Artigo sobre domínio decomposition em shared memory",
                                    "Simulador online ou pseudocódigo"
                                  ],
                                  "tips": "Pense em como evitar 'hotspots' de memória nas fronteiras.",
                                  "learningObjective": "Integrar todos os conceitos em um contexto arquitetural.",
                                  "commonMistakes": [
                                    "Ignorar contenção de memória",
                                    "Confundir memória compartilhada com distribuída"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de fluxo de fluido em um tubo (CFD), divida o domínio 2D em sub-regiões retangulares atribuídas a threads MIMD com memória compartilhada, resolvendo EDPs localmente e trocando dados nas bordas.",
                              "finalVerifications": [
                                "Defina decomposição de domínio em 1 frase precisa.",
                                "Liste 3 diferenças chave vs. decomposição funcional.",
                                "Explique relevância para MIMD na Taxonomia de Flynn.",
                                "Descreva impacto em memória compartilhada.",
                                "Forneça um exemplo prático simples.",
                                "Crie um diagrama conceitual."
                              ],
                              "assessmentCriteria": [
                                "Precisão e completude da definição (30%)",
                                "Clareza na diferenciação com funcional (25%)",
                                "Correta integração com Taxonomia de Flynn (20%)",
                                "Relevância para MIMD/memória compartilhada (15%)",
                                "Uso de exemplos e diagramas (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Solução numérica de EDPs (métodos de diferenças finitas)",
                                "Física: Simulações de dinâmica de fluidos e propagação de ondas",
                                "Engenharia de Software: Design de algoritmos paralelos escaláveis",
                                "Ciência da Computação: Otimização de alto desempenho (HPC)"
                              ],
                              "realWorldApplication": "Aplicada em simulações científicas como previsão climática (modelos GCM), análise estrutural em engenharia aeroespacial e renderização gráfica em jogos/efeitos visuais, permitindo execução eficiente em supercomputadores MIMD."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.1.2",
                            "name": "Identificar Particionamento de Dados",
                            "description": "Identificar estratégias de particionamento de dados em domínios geométricos ou lógicos para maximizar o paralelismo e minimizar comunicações em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Particionamento de Dados",
                                  "subSteps": [
                                    "Defina particionamento de dados como a divisão de dados em subconjuntos independentes para processamento paralelo.",
                                    "Explique o objetivo de maximizar o paralelismo, permitindo que múltiplos processadores trabalhem simultaneamente.",
                                    "Descreva como minimizar comunicações em memória compartilhada reduz overhead de sincronização e transferência.",
                                    "Identifique métricas chave: razão computação/comunicação e granularidade.",
                                    "Diferencie particionamento de dados de decomposição de tarefas."
                                  ],
                                  "verification": "Escreva um resumo de 100 palavras explicando os conceitos e seus objetivos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Slides introdutórios sobre programação paralela",
                                    "Artigo sobre modelos de memória compartilhada"
                                  ],
                                  "tips": "Visualize dados como um domínio contínuo (geométrico) ou discreto (lógico) para facilitar a compreensão.",
                                  "learningObjective": "Dominar definições e trade-offs do particionamento em contextos paralelos.",
                                  "commonMistakes": [
                                    "Confundir maximização de paralelismo com aumento de threads sem considerar dependências.",
                                    "Ignorar impactos da topologia de memória compartilhada."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Domínios Geométricos e Lógicos",
                                  "subSteps": [
                                    "Classifique domínios geométricos (ex: grades 2D/3D em simulações físicas).",
                                    "Classifique domínios lógicos (ex: grafos ou árvores em algoritmos).",
                                    "Analise exemplos: grade para equações diferenciais vs. grafo para busca.",
                                    "Mapeie domínios para estruturas de dados adequadas (arrays vs. listas de adjacência).",
                                    "Discuta adaptações para memória compartilhada, como alinhamento de cache."
                                  ],
                                  "verification": "Crie um diagrama distinguindo um domínio geométrico de um lógico com exemplos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramenta de desenho como Draw.io",
                                    "Exemplos de códigos em OpenMP ou MPI"
                                  ],
                                  "tips": "Use analogias: geométrico como fatiar uma pizza, lógico como dividir tarefas em um organograma.",
                                  "learningObjective": "Diferenciar e exemplificar tipos de domínios para particionamento.",
                                  "commonMistakes": [
                                    "Tratar todos os domínios como geométricos, ignorando irregularidades lógicas.",
                                    "Subestimar overhead de acesso não-local em memória compartilhada."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Avaliar Estratégias de Particionamento",
                                  "subSteps": [
                                    "Liste estratégias: particionamento em blocos, cíclico, em blocos com sobreposição.",
                                    "Avalie maximização de paralelismo: equilíbrio de carga e independência de subconjuntos.",
                                    "Avalie minimização de comunicações: bordas mínimas entre partições e locality de dados.",
                                    "Calcule métricas simples: número de arestas cortadas em um grafo de domínio.",
                                    "Compare estratégias via pseudocódigo ou simulação mental."
                                  ],
                                  "verification": "Selecione e justifique a melhor estratégia para um domínio dado, com cálculos de métricas.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Planilha para cálculo de métricas",
                                    "Pseudocódigos de exemplos clássicos"
                                  ],
                                  "tips": "Priorize estratégias que preservem locality para otimizar cache em memória compartilhada.",
                                  "learningObjective": "Selecionar e justificar estratégias baseadas em critérios de performance.",
                                  "commonMistakes": [
                                    "Escolher particionamento fino sem considerar custo de comunicação.",
                                    "Ignorar desbalanceamento de carga em domínios irregulares."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Validar Particionamento em Exemplo Prático",
                                  "subSteps": [
                                    "Escolha um problema simples (ex: soma de matriz).",
                                    "Implemente particionamento manual em pseudocódigo paralelo.",
                                    "Simule execução: identifique paralelismo e comunicações potenciais.",
                                    "Otimize iterativamente para reduzir comunicações.",
                                    "Documente melhorias em termos de speedup teórico."
                                  ],
                                  "verification": "Produza pseudocódigo particionado com análise de comunicações.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Editor de texto para pseudocódigo",
                                    "Calculadora para análise de complexidade"
                                  ],
                                  "tips": "Teste com tamanhos pequenos para validar balanceamento antes de escalar.",
                                  "learningObjective": "Aplicar conceitos em um cenário concreto e iterar otimizações.",
                                  "commonMistakes": [
                                    "Esquecer sincronizações implícitas em acessos compartilhados.",
                                    "Superestimar paralelismo sem verificar dependências de dados."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma multiplicação de matrizes NxN usando OpenMP em memória compartilhada, particione a matriz A em k blocos lineares (particionamento cíclico) atribuídos a k threads. Cada thread computa linhas independentes, minimizando comunicações a reads locais e reduzindo contenção de cache, alcançando speedup próximo de k para N grande.",
                              "finalVerifications": [
                                "Explicar diferenças entre domínios geométricos e lógicos com exemplos.",
                                "Identificar pelo menos 3 estratégias de particionamento e seus trade-offs.",
                                "Calcular razão computação/comunicação para um exemplo dado.",
                                "Justificar escolha de estratégia para maximizar paralelismo em memória compartilhada.",
                                "Simular particionamento em pseudocódigo sem erros de dependência.",
                                "Discutir impactos de topologias NUMA em escolhas de particionamento."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e distinção de conceitos fundamentais (20%).",
                                "Qualidade da análise de domínios e estratégias (25%).",
                                "Correção em cálculos de métricas de performance (20%).",
                                "Criatividade e realismo no exemplo prático (15%).",
                                "Profundidade nas justificativas de trade-offs (10%).",
                                "Clareza na documentação e verificações (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados: Particionamento de grafos (ex: Metis).",
                                "Otimização e Heurísticas: Problema de balanceamento de partições.",
                                "Arquitetura de Computadores: Locality de cache e NUMA.",
                                "Matemática Computacional: Decomposição de domínios em PDEs.",
                                "Engenharia de Software: Design escalável de aplicações paralelas."
                              ],
                              "realWorldApplication": "Em simulações climáticas (ex: modelos do IPCC), particione grades globais 3D em subdomínios para supercomputadores compartilhados, permitindo milhares de núcleos processarem independentes com mínimas trocas de borda via MPI-OpenMP hybrid, acelerando previsões em horas ao invés de dias."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.1.3",
                            "name": "Comparar com Troca de Mensagens",
                            "description": "Comparar decomposição de domínio em memória compartilhada com modelos de troca de mensagens em memória distribuída, destacando vantagens e desvantagens.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Decomposição de Domínio em Memória Compartilhada",
                                  "subSteps": [
                                    "Defina decomposição de domínio como a divisão do espaço geométrico ou lógico do problema em subdomínios independentes.",
                                    "Explique como em memória compartilhada (ex: threads em OpenMP ou Pthreads), subdomínios acessam dados comuns via variáveis globais.",
                                    "Identifique características chave: sincronização via locks/mutexes, race conditions potenciais.",
                                    "Estude exemplos como simulações numéricas (ex: método de diferenças finitas).",
                                    "Anote hierarquia: owner computes → ghost cells para comunicação implícita."
                                  ],
                                  "verification": "Crie um diagrama simples mostrando divisão de um grid 2D em subdomínios com overlap.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação OpenMP/Pthreads, papel e caneta para diagrama, vídeo tutorial sobre shared memory.",
                                  "tips": "Use analogia de uma equipe dividindo um mapa grande, mas todos olhando o mesmo mapa.",
                                  "learningObjective": "Dominar conceitos fundamentais de decomposição de domínio em contextos de memória compartilhada.",
                                  "commonMistakes": "Confundir com decomposição funcional; ignorar necessidade de sincronização."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender Modelo de Troca de Mensagens em Memória Distribuída",
                                  "subSteps": [
                                    "Defina memória distribuída como cada processo tendo sua memória local, comunicando via MPI_Send/Recv.",
                                    "Descreva decomposição similar, mas com exchanges explícitos de dados (halos/ghosts).",
                                    "Liste primitivas: point-to-point (send/recv), coletivas (broadcast, reduce).",
                                    "Compare latência: mensagens envolvem cópias de dados vs. acesso direto.",
                                    "Exemplo: simulação em cluster onde cada nó computa subdomínio e envia bordas."
                                  ],
                                  "verification": "Escreva pseudocódigo para MPI exchange de ghost cells em um grid.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação MPI, compilador com MPI (ex: OpenMPI), exemplos de código online.",
                                  "tips": "Pense em correio: cada processo envia 'cartas' com dados necessários.",
                                  "learningObjective": "Entender mecanismos de comunicação explícita em sistemas distribuídos.",
                                  "commonMistakes": "Subestimar overhead de comunicação; confundir com RPCs."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar as Duas Abordagens Estruturalmente",
                                  "subSteps": [
                                    "Crie tabela comparativa: acesso a dados (direto vs. explícito), escalabilidade (NUMA vs. WAN).",
                                    "Analise granularidade: shared memory bom para fine-grain, message passing para coarse-grain.",
                                    "Discuta portabilidade: shared memory limitado a máquina única, message passing para clusters.",
                                    "Examine debugging: shared memory usa ferramentas como Valgrind, message passing usa MPI tracers.",
                                    "Registre similaridades: ambas usam decomposição de domínio com overlaps."
                                  ],
                                  "verification": "Preencha tabela comparativa com pelo menos 5 dimensões (ex: performance, fault tolerance).",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Planilha (Google Sheets/Excel), artigos acadêmicos sobre Flynn Taxonomy.",
                                  "tips": "Use categorias como 'facilidade de programação' vs. 'escalabilidade máxima'.",
                                  "learningObjective": "Identificar similaridades e diferenças arquiteturais entre modelos.",
                                  "commonMistakes": "Focar só em performance sem considerar complexidade de programação."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Destacar Vantagens e Desvantagens",
                                  "subSteps": [
                                    "Liste vantagens shared memory: simplicidade, baixa latência, cache efficiency.",
                                    "Desvantagens: race conditions, escalabilidade limitada por contenda.",
                                    "Vantagens message passing: tolerância a falhas, escalabilidade infinita, portabilidade.",
                                    "Desvantagens: overhead de comunicação, deadlocks potenciais.",
                                    "Sintetize trade-offs: escolha baseada em hardware (SMP vs. cluster)."
                                  ],
                                  "verification": "Escreva parágrafo resumindo quando usar cada modelo, com 2 exemplos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Papel para brainstorm, benchmarks online (ex: NAS Parallel Benchmarks).",
                                  "tips": "Quantifique: shared memory até 100s cores, message passing milhares.",
                                  "learningObjective": "Avaliar trade-offs para seleção de modelo em cenários reais.",
                                  "commonMistakes": "Ignorar custos de hardware; generalizar sem contexto."
                                }
                              ],
                              "practicalExample": "Em uma simulação de propagação de calor em um grid 1000x1000: shared memory divide grid com threads acessando array global (OpenMP), message passing usa MPI com cada rank computando subgrid e trocando bordas via Isend/Irecv.",
                              "finalVerifications": [
                                "Pode diagramar decomposição de domínio para ambos modelos em um problema simples.",
                                "Lista corretamente 3 vantagens e 3 desvantagens de cada abordagem.",
                                "Explica impacto de latência de rede vs. memória em performance.",
                                "Identifica cenário onde message passing é preferível (ex: cluster heterogêneo).",
                                "Compara debugging e portabilidade com exemplos.",
                                "Sintetiza trade-offs em uma recomendação condicional."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas sem confusões (30%).",
                                "Profundidade da comparação: tabela/diagrama abrangente (25%).",
                                "Análise de trade-offs: vantagens/desvantagens balanceadas e contextualizadas (20%).",
                                "Exemplos práticos: relevância e concretude (15%).",
                                "Clareza de síntese: conclusão acionável (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: latência/bandwidth em message passing.",
                                "Sistemas Operacionais: sincronização e contenda em shared memory.",
                                "Algoritmos e Estruturas: impacto na complexidade de paralelização.",
                                "Engenharia de Software: portabilidade e modularidade em programação paralela."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, message passing (MPI) é usado para simulações climáticas distribuídas globalmente, enquanto shared memory otimiza workloads em GPUs para IA, permitindo escalar de laptops a data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.5.2",
                        "name": "Aplicação em Memória Compartilhada",
                        "description": "Técnicas práticas para aplicar decomposição de domínio em programação paralela com memória compartilhada, considerando sincronização e balanceamento de carga.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.5.2.1",
                            "name": "Dividir Dados em Subdomínios",
                            "description": "Implementar divisão de um domínio de dados em subdomínios independentes atribuíveis a threads ou processos em memória compartilhada, usando exemplos como matrizes 2D.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar o Domínio de Dados",
                                  "subSteps": [
                                    "Selecione um domínio de dados exemplo, como uma matriz 2D de dimensões NxM.",
                                    "Identifique as características do domínio: tamanho total, acessos de leitura/escrita e potenciais dependências.",
                                    "Desenhe um diagrama visual representando o domínio completo (ex: grid da matriz).",
                                    "Calcule o número total de elementos e defina o número de threads/processos disponíveis (ex: 4 threads).",
                                    "Documente restrições de memória compartilhada, como acessos concorrentes."
                                  ],
                                  "verification": "Crie um diagrama anotado do domínio e liste suas propriedades em um documento.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta ou ferramenta de diagramação (ex: Draw.io)",
                                    "Editor de código para notas"
                                  ],
                                  "tips": "Comece com matrizes pequenas (ex: 4x4) para visualização fácil antes de escalar.",
                                  "learningObjective": "Compreender a estrutura do domínio para identificar oportunidades de decomposição.",
                                  "commonMistakes": [
                                    "Ignorar dependências entre elementos adjacentes",
                                    "Subestimar o impacto do tamanho do domínio na divisão"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Planejar a Divisão em Subdomínios",
                                  "subSteps": [
                                    "Escolha uma estratégia de divisão: por linhas, colunas ou blocos (ex: blocos quadrados para matrizes).",
                                    "Calcule os limites de cada subdomínio: índices inicial e final para linhas e colunas.",
                                    "Garanta cobertura completa sem sobreposições: some tamanhos para igualar o domínio total.",
                                    "Verifique balanceamento de carga: tamanhos semelhantes para evitar gargalos em threads.",
                                    "Defina identificadores únicos para cada subdomínio (ex: thread ID 0-3)."
                                  ],
                                  "verification": "Liste os limites exatos de 4 subdomínios em uma tabela e confirme soma total.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Planilha ou editor de texto para cálculos",
                                    "Calculadora ou Python para validação rápida"
                                  ],
                                  "tips": "Use divisão inteira para índices: start_row = (N / num_threads) * thread_id.",
                                  "learningObjective": "Desenvolver habilidades para criar partições independentes e balanceadas.",
                                  "commonMistakes": [
                                    "Sobreposições em bordas de subdomínios",
                                    "Divisões desbalanceadas levando a threads ociosas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a Divisão em Código",
                                  "subSteps": [
                                    "Escreva funções para calcular limites de subdomínios baseados no ID da thread (ex: get_subdomain_bounds(thread_id)).",
                                    "Crie loops que processem apenas o subdomínio atribuído na matriz compartilhada.",
                                    "Use barreiras ou locks mínimos apenas se necessário, priorizando independência.",
                                    "Implemente uma operação exemplo: soma de elementos no subdomínio.",
                                    "Compile e execute sequencialmente para validar resultados."
                                  ],
                                  "verification": "Execute o código sequencial e compare soma total com versão não dividida.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Linguagem com suporte a threads (ex: C++ com OpenMP, Java com Threads)",
                                    "Compilador/IDE (ex: GCC, Eclipse)"
                                  ],
                                  "tips": "Use #pragma omp parallel for em OpenMP para automação inicial de divisão por linhas.",
                                  "learningObjective": "Traduzir plano de divisão em código executável para memória compartilhada.",
                                  "commonMistakes": [
                                    "Acessos fora dos limites do subdomínio",
                                    "Uso desnecessário de locks causando serialização"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Atribuir e Verificar Execução Paralela",
                                  "subSteps": [
                                    "Atribua subdomínios a threads/processos usando diretivas paralelas (ex: OpenMP parallel).",
                                    "Execute em paralelo e meça tempo de execução vs. sequencial.",
                                    "Use ferramentas de debug para inspecionar acessos (ex: printf por thread).",
                                    "Confirme independência: ausência de race conditions via soma global atômica.",
                                    "Otimize se necessário: ajuste tamanhos para melhor balanceamento."
                                  ],
                                  "verification": "Compare resultados paralelos com sequenciais e speedup >1.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramentas de profiling (ex: gprof, VisualVM)",
                                    "Máquina multi-core"
                                  ],
                                  "tips": "Monitore overhead de threads: ideal para domínios grandes (>1000 elementos).",
                                  "learningObjective": "Validar decomposição em ambiente paralelo real.",
                                  "commonMistakes": [
                                    "Race conditions em atualizações globais",
                                    "Overhead de sincronização excessivo"
                                  ]
                                }
                              ],
                              "practicalExample": "Divida uma matriz 100x100 em 4 subdomínios de 50x25 cada (divisão por linhas). Cada thread soma elementos de seu subdomínio e contribui para uma soma global usando atomic_add em C++ com OpenMP. Verifique que soma paralela equals soma sequencial.",
                              "finalVerifications": [
                                "Subdomínios cobrem 100% do domínio sem lacunas ou sobreposições.",
                                "Cada thread processa apenas seu subdomínio sem acessos externos.",
                                "Execução paralela produz resultados idênticos à sequencial.",
                                "Não há race conditions ou deadlocks observados.",
                                "Balanceamento de carga: tempos de execução por thread variam <10%.",
                                "Speedup mensurável (>1.5x em 4 cores)."
                              ],
                              "assessmentCriteria": [
                                "Precisão da divisão: cobertura e independência totais.",
                                "Balanceamento: tamanhos de subdomínios uniformes.",
                                "Eficiência do código: overhead mínimo de paralelismo.",
                                "Robustez: funciona para diferentes tamanhos de domínio e números de threads.",
                                "Documentação: diagramas e comentários claros no código.",
                                "Escalabilidade: adaptação fácil para mais threads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e divisão de espaços vetoriais.",
                                "Física Computacional: Decomposição em simulações numéricas (ex: Monte Carlo).",
                                "Engenharia de Software: Padrões de design para paralelismo.",
                                "Ciência de Dados: Particionamento de datasets em big data frameworks."
                              ],
                              "realWorldApplication": "Em processamento de imagens (ex: aplicar filtro Gaussiano dividindo a imagem em blocos para threads em Photoshop ou GIMP plugins), acelerando renderização em GPUs ou CPUs multi-core sem artefatos de borda."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.2.2",
                            "name": "Gerenciar Dependências de Dados",
                            "description": "Analisar e gerenciar dependências entre subdomínios, utilizando barreiras e exclusão mútua para evitar condições de corrida em acessos compartilhados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Dependências de Dados e Condições de Corrida",
                                  "subSteps": [
                                    "Identifique dependências entre subdomínios em um programa paralelo com memória compartilhada.",
                                    "Simule uma condição de corrida acessando uma variável compartilhada sem sincronização.",
                                    "Analise o impacto de acessos concorrentes em dados mutáveis.",
                                    "Diferencie dependências de leitura vs. escrita em contextos paralelos.",
                                    "Estude exemplos clássicos como o problema do produtor-consumidor."
                                  ],
                                  "verification": "Execute um código simples sem sincronização e observe resultados inconsistentes em múltiplas execuções.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação de threads em C++ (std::thread), compilador GCC, editor de código como VS Code.",
                                  "tips": "Use printf ou logs para visualizar a ordem de execução das threads.",
                                  "learningObjective": "Reconhecer quando e por que dependências de dados causam race conditions em memória compartilhada.",
                                  "commonMistakes": "Assumir que a ordem de execução é determinística sem sincronização; ignorar dependências de leitura."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Exclusão Mútua com Mutexes",
                                  "subSteps": [
                                    "Crie uma seção crítica envolvendo uma variável compartilhada.",
                                    "Inicialize e use std::mutex para proteger acessos à seção crítica.",
                                    "Aplique std::lock_guard para gerenciamento automático de locks.",
                                    "Teste o código com múltiplas threads escrevendo e lendo o recurso compartilhado.",
                                    "Meça o tempo de execução para observar overhead de sincronização."
                                  ],
                                  "verification": "Confirme que o valor final da variável compartilhada é consistente em 100 execuções.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Biblioteca <mutex> e <thread> em C++, exemplos de código do cppreference.com.",
                                  "tips": "Sempre use RAII (lock_guard) para evitar deadlocks por esquecimento de unlock.",
                                  "learningObjective": "Aplicar mutexes para garantir exclusão mútua em acessos compartilhados.",
                                  "commonMistakes": "Esquecer de unlock o mutex manualmente; aninhar locks sem cuidado, causando deadlocks."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Utilizar Barreiras para Sincronização de Fases",
                                  "subSteps": [
                                    "Defina pontos de sincronização onde todas as threads devem aguardar.",
                                    "Implemente uma barreira personalizada ou use std::barrier (C++20) ou pthread_barrier.",
                                    "Configure threads para processar subdomínios em fases dependentes.",
                                    "Execute e verifique se todas as threads avançam apenas após a barreira.",
                                    "Analise cenários onde barreiras evitam acessos prematuros a dados dependentes."
                                  ],
                                  "verification": "Adicione logs antes/depois da barreira e confirme ordem sincronizada em execuções.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Código fonte de barreiras em pthread ou C++20, debugger como GDB.",
                                  "tips": "Inicialize a barreira com o número exato de threads participantes.",
                                  "learningObjective": "Sincronizar grupos de threads usando barreiras para dependências entre fases.",
                                  "commonMistakes": "Configurar barreira com contagem errada de threads; usar barreiras em loops sem reset."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Gerenciar Dependências Complexas Combinando Técnicas",
                                  "subSteps": [
                                    "Modele um sistema com múltiplas dependências entre subdomínios.",
                                    "Integre mutexes para seções críticas e barreiras para fases globais.",
                                    "Implemente um exemplo de decomposição de domínio com acessos compartilhados.",
                                    "Otimize para minimizar contenção (ex: granulares locks).",
                                    "Teste escalabilidade com número variável de threads."
                                  ],
                                  "verification": "Simule carga alta e confirme ausência de race conditions via testes unitários e profiling.",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": "Ferramentas de profiling como Valgrind (Helgrind para race detection), código completo do projeto.",
                                  "tips": "Use atomic operations quando possível para reduzir overhead de mutexes.",
                                  "learningObjective": "Combinar exclusão mútua e barreiras para gerenciar dependências em aplicações reais.",
                                  "commonMistakes": "Sobreesincronizar, causando gargalos; ignorar prioridades de threads."
                                }
                              ],
                              "practicalExample": "Em um simulador de banco multi-threaded, threads representando caixas eletrônicos atualizam saldos compartilhados. Sem sincronização, saques concorrentes causam saldos negativos. Use mutex para proteger atualizações de saldo e barreiras para sincronizar relatórios diários de todas as agências.",
                              "finalVerifications": [
                                "Execute 1000 iterações com 8 threads e confirme consistência de dados.",
                                "Use Helgrind (Valgrind) para detectar race conditions não resolvidas.",
                                "Meça throughput e confirme redução de erros sem perda excessiva de performance.",
                                "Verifique logs de sincronização para ordem correta de barreiras e locks.",
                                "Teste falhas: remova um mutex e observe race condition reaparecer.",
                                "Confirme escalabilidade adicionando mais threads."
                              ],
                              "assessmentCriteria": [
                                "Correta identificação e eliminação de todas as race conditions.",
                                "Uso apropriado de mutexes apenas em seções críticas mínimas.",
                                "Implementação funcional de barreiras para dependências de fase.",
                                "Código limpo com RAII e sem vazamentos de locks.",
                                "Análise de performance mostrando trade-offs de sincronização.",
                                "Documentação clara de dependências modeladas."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Conceitos de semáforos e escalonamento de threads.",
                                "Algoritmos e Estruturas de Dados: Grafos de dependências para modelagem.",
                                "Design de Software: Padrões de concorrência como Producer-Consumer.",
                                "Banco de Dados: Transações ACID e locking em bancos distribuídos.",
                                "Engenharia de Software: Testes de estresse e profiling de performance."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx com worker threads, gerencia acessos concorrentes a caches compartilhados (mutex para updates) e sincroniza purgas periódicas (barreiras), evitando corrupção de dados em picos de tráfego e garantindo consistência em e-commerces de alto volume."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.2.3",
                            "name": "Balancear Carga entre Threads",
                            "description": "Aplicar técnicas de balanceamento de carga dinâmica e estática na decomposição de domínio para otimizar o desempenho em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Balanceamento de Carga Estático e Dinâmico",
                                  "subSteps": [
                                    "Estude definições: balanceamento estático (divisão fixa de trabalho) vs. dinâmico (redistribuição em runtime).",
                                    "Analise métricas: makespan, eficiência e métrica de balanceamento (ex: variance de tempos de threads).",
                                    "Revise decomposição de domínio em memória compartilhada (ex: OpenMP).",
                                    "Compare exemplos simples: soma sequencial vs. paralela desbalanceada.",
                                    "Identifique cenários onde cada técnica é apropriada (trabalho previsível vs. imprevisível)."
                                  ],
                                  "verification": "Resuma em um diagrama comparativo as diferenças entre estático e dinâmico, com exemplos de métricas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação OpenMP",
                                    "Artigos sobre taxonomia Flynn",
                                    "Slides de programação paralela"
                                  ],
                                  "tips": "Use analogias como divisão de tarefas em uma cozinha: estática para refeições iguais, dinâmica para tamanhos variados.",
                                  "learningObjective": "Diferenciar e justificar o uso de balanceamento estático vs. dinâmico em contextos multicores.",
                                  "commonMistakes": [
                                    "Confundir com particionamento de dados",
                                    "Ignorar overhead de redistribuição dinâmica"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Desbalanceamento em Decomposição de Domínio",
                                  "subSteps": [
                                    "Selecione um problema de domínio (ex: matriz irregular para processamento de imagem).",
                                    "Implemente decomposição inicial uniforme usando OpenMP parallel for.",
                                    "Meça tempos de execução por thread com ferramentas como omp_get_wtime().",
                                    "Calcule métricas de desbalanceamento (ex: max/min tempo de thread).",
                                    "Visualize com profiler (ex: gprof ou Intel VTune) para identificar gargalos."
                                  ],
                                  "verification": "Gere relatório com tempos por thread e métrica de balanceamento < 0.8 indicando desbalanceamento.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Compilador GCC com OpenMP",
                                    "Matriz de teste irregular (código fonte)",
                                    "Profiler OpenMP"
                                  ],
                                  "tips": "Comece com matrizes pequenas para depuração rápida; escale para validar.",
                                  "learningObjective": "Diagnosticar desbalanceamento quantitativamente em uma decomposição existente.",
                                  "commonMistakes": [
                                    "Não sincronizar medições corretamente",
                                    "Usar dados uniformes que mascaram o problema"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Balanceamento de Carga Estático",
                                  "subSteps": [
                                    "Ajuste chunk sizes no OpenMP schedule(static, chunk) baseado em análise prévia.",
                                    "Teste chunks variáveis (ex: chunk = linhas / threads ajustado por densidade).",
                                    "Compile e execute com diferentes números de threads (2-16).",
                                    "Meça speedup e eficiência vs. versão desbalanceada.",
                                    "Otimize chunk para maximizar métrica de balanceamento > 0.9."
                                  ],
                                  "verification": "Demonstre speedup >= 2x em 4 threads com balanceamento estático otimizado.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código base da Step 2",
                                    "Ambiente multicores (máquina com >=4 cores)"
                                  ],
                                  "tips": "Use schedule(static,1) como baseline e itere chunks maiores para reduzir overhead.",
                                  "learningObjective": "Aplicar decomposição estática otimizada para workloads previsíveis.",
                                  "commonMistakes": [
                                    "Chunks fixos sem análise de workload",
                                    "Ignorar overhead de scheduling"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e Comparar Balanceamento Dinâmico",
                                  "subSteps": [
                                    "Implemente schedule(dynamic) ou guided no OpenMP para redistribuição runtime.",
                                    "Adicione work-stealing manual se necessário (ex: fila de tarefas compartilhada).",
                                    "Execute em workloads imprevisíveis (ex: matriz com ruído gaussiano).",
                                    "Compare métricas com versão estática (tempo total, balanceamento).",
                                    "Analise trade-offs: overhead dinâmico vs. adaptabilidade."
                                  ],
                                  "verification": "Relatório comparativo mostrando dinâmica superior em workloads variáveis (balanceamento > 0.95).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código das steps anteriores",
                                    "Datasets variáveis (gerador de matrizes)"
                                  ],
                                  "tips": "Monitore overhead com contadores de iterações; prefira guided para chunk decrescente.",
                                  "learningObjective": "Implementar e avaliar balanceamento dinâmico para otimização em multicores.",
                                  "commonMistakes": [
                                    "Overhead excessivo sem tuning",
                                    "Não testar em cenários reais variáveis"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um filtro de imagem (ex: convolução em matriz 1024x1024 irregular), divida linhas por thread estáticamente baseado em densidade de pixels, ou use dynamic para regiões variáveis de complexidade, medindo speedup de 3.5x em 8 cores.",
                              "finalVerifications": [
                                "Métrica de balanceamento > 0.9 em ambas técnicas.",
                                "Speedup linear até 80% do número de cores.",
                                "Tempo total reduzido >= 50% vs. desbalanceado.",
                                "Profundidade de análise com gráficos de tempo por thread.",
                                "Código comentado e reproduzível.",
                                "Testes em 2-16 threads sem crashes."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (80%+ em quiz sobre conceitos).",
                                "Implementação correta (compila e executa sem erros).",
                                "Otimização efetiva (speedup quantificado).",
                                "Análise de métricas rigorosa (fórmulas e cálculos).",
                                "Relatório claro com visualizações.",
                                "Tratamento de edge cases (1 thread, dados extremos)."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos: Particionamento de grafos e heurísticas de scheduling.",
                                "Sistemas Operacionais: Gerenciamento de threads e affinity.",
                                "Engenharia de Software: Design patterns para paralelismo.",
                                "Matemática: Otimização linear e análise de variância.",
                                "Big Data: Balanceamento em MapReduce/Spark."
                              ],
                              "realWorldApplication": "Otimização de servidores web multithread (ex: Nginx processando requests variáveis), simulações científicas (CFD em clusters) e ML training (distribuição de batches em GPUs multicores), reduzindo tempo de resposta em 40-60%."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.5.3",
                        "name": "Implementação e Avaliação",
                        "description": "Implementação prática e avaliação de desempenho de programas usando decomposição de domínio, com referência a linguagens como OpenMP.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.5.3.1",
                            "name": "Implementar em OpenMP",
                            "description": "Codificar um exemplo de decomposição de domínio usando diretivas OpenMP para loops paralelos em memória compartilhada, como multiplicação de matrizes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento para OpenMP",
                                  "subSteps": [
                                    "Instalar um compilador compatível com OpenMP, como GCC ou Clang.",
                                    "Verificar o suporte a OpenMP com a flag -fopenmp.",
                                    "Criar um diretório de projeto e preparar um editor de código (VS Code ou similar).",
                                    "Testar compilação de um programa Hello World com OpenMP.",
                                    "Configurar variáveis de ambiente como OMP_NUM_THREADS."
                                  ],
                                  "verification": "Compilar e executar com sucesso um programa simples que imprime o número de threads.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "GCC/Clang instalado",
                                    "Editor de texto",
                                    "Terminal"
                                  ],
                                  "tips": "Use 'g++ -fopenmp teste.cpp -o teste' para compilar.",
                                  "learningObjective": "Configurar corretamente o ambiente para programação paralela com OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp",
                                    "Não definir OMP_NUM_THREADS",
                                    "Usar compilador sem suporte"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a multiplicação de matrizes sequencial",
                                  "subSteps": [
                                    "Definir estruturas para matrizes (vetores 2D ou arrays dinâmicos).",
                                    "Implementar alocação dinâmica de memória com malloc.",
                                    "Codificar o loop triplo para multiplicação C = A * B.",
                                    "Preencher matrizes com valores de teste.",
                                    "Adicionar função para imprimir matrizes e verificar resultados."
                                  ],
                                  "verification": "Executar o código sequencial e confirmar que o resultado da multiplicação está correto.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código base sequencial",
                                    "Compilador GCC"
                                  ],
                                  "tips": "Use constantes para tamanhos de matriz (ex: N=512) para testes rápidos.",
                                  "learningObjective": "Dominar a implementação sequencial como baseline para paralelização.",
                                  "commonMistakes": [
                                    "Índices invertidos nos loops",
                                    "Vazamento de memória sem free()",
                                    "Não inicializar matrizes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Paralelizar com diretivas OpenMP para decomposição de domínio",
                                  "subSteps": [
                                    "Incluir <omp.h> e adicionar #pragma omp parallel for no loop externo de i.",
                                    "Garantir independência das iterações (decomposição por linhas).",
                                    "Adicionar cláusulas schedule(static) para distribuição uniforme.",
                                    "Implementar redução se necessário, mas focar em domínio.",
                                    "Testar com poucas threads para depuração."
                                  ],
                                  "verification": "Compilar com -fopenmp e executar; verificar se usa múltiplas threads via omp_get_num_threads().",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código sequencial modificado",
                                    "Documentação OpenMP"
                                  ],
                                  "tips": "Comece com private variáveis de loop para evitar races.",
                                  "learningObjective": "Aplicar diretivas OpenMP para paralelizar loops por decomposição de domínio em memória compartilhada.",
                                  "commonMistakes": [
                                    "Corrida de dados sem private",
                                    "Sobrecarga com muitas threads",
                                    "Ignorar alinhamento de memória"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Compilar, executar e medir desempenho",
                                  "subSteps": [
                                    "Compilar versão paralela com diferentes números de threads.",
                                    "Executar múltiplas vezes e medir tempo com omp_get_wtime().",
                                    "Calcular speedup (tempo_seq / tempo_par).",
                                    "Plotar gráfico simples de performance vs. threads.",
                                    "Comparar resultados com versão sequencial."
                                  ],
                                  "verification": "Observar speedup >1 e resultados idênticos à versão sequencial.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Timer OpenMP",
                                    "Ferramenta de plotagem como GNUPlot ou Excel"
                                  ],
                                  "tips": "Use export OMP_NUM_THREADS=4 antes de executar.",
                                  "learningObjective": "Avaliar o ganho de performance da paralelização.",
                                  "commonMistakes": [
                                    "Medir tempo sem aquecimento de cache",
                                    "Não repetir execuções para média",
                                    "Confundir wall-time com CPU-time"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar corretude e otimizar",
                                  "subSteps": [
                                    "Implementar verificação elemento a elemento entre seq e par.",
                                    "Adicionar cláusulas collapse para loops aninhados.",
                                    "Experimentar schedule(dynamic) para cargas desbalanceadas.",
                                    "Analisar overhead com profiling básico.",
                                    "Documentar lições aprendidas."
                                  ],
                                  "verification": "Código passa em todos os testes de corretude e speedup otimizado.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código final",
                                    "Debugger GDB"
                                  ],
                                  "tips": "Use #pragma omp barrier se necessário para sincronização.",
                                  "learningObjective": "Garantir corretude e refinar a implementação paralela.",
                                  "commonMistakes": [
                                    "False sharing em memória compartilhada",
                                    "Excesso de sincronizações",
                                    "Ignorar escalabilidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente multiplicação de matrizes 512x512: versão sequencial leva ~10s, paralela com 4 threads ~3s (speedup 3x). Código: #pragma omp parallel for private(j,k) for(int i=0; i<N; i++) { for(int j=0; j<N; j++) { C[i][j]=0; for(int k=0; k<N; k++) C[i][j] += A[i][k]*B[k][j]; } }",
                              "finalVerifications": [
                                "Código compila e executa sem erros com OpenMP.",
                                "Resultados idênticos à versão sequencial.",
                                "Uso de múltiplas threads confirmado.",
                                "Speedup positivo medido.",
                                "Nenhuma race condition detectada.",
                                "Memória liberada corretamente."
                              ],
                              "assessmentCriteria": [
                                "Corretude: Resultados exatos (erro <1e-6).",
                                "Eficiência: Speedup >=2x com 4 threads.",
                                "Estrutura: Uso correto de diretivas e cláusulas.",
                                "Documentação: Código comentado e relatório de performance.",
                                "Otimização: Cláusulas adequadas aplicadas.",
                                "Escalabilidade: Testado com diferentes N e threads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e operações matriciais.",
                                "Arquitetura de Computadores: Modelos de memória compartilhada e Flynn.",
                                "Análise de Algoritmos: Complexidade temporal O(n^3) e paralelismo.",
                                "Engenharia de Software: Boas práticas em código paralelo."
                              ],
                              "realWorldApplication": "Aceleração de simulações científicas como modelagem climática, processamento de imagens em visão computacional e treinamento de redes neurais em clusters HPC."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.3.2",
                            "name": "Avaliar Desempenho Paralelo",
                            "description": "Medir speedup, eficiência e escalabilidade de um programa com decomposição de domínio, utilizando métricas como tempo de execução e overhead de sincronização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as Métricas Fundamentais de Desempenho Paralelo",
                                  "subSteps": [
                                    "Estude as definições de speedup (S = T_seq / T_par), eficiência (E = S / P, onde P é o número de processadores) e escalabilidade.",
                                    "Aprenda sobre overhead de sincronização, incluindo custos de comunicação e barreiras.",
                                    "Revise a Lei de Amdahl para entender limites teóricos de speedup.",
                                    "Identifique métricas adicionais como tempo de execução total e taxa de utilização de CPU.",
                                    "Compare decomposição de domínio com outras abordagens para contextualizar."
                                  ],
                                  "verification": "Resuma em um documento as fórmulas e exemplos de cada métrica, com pelo menos um cálculo manual simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de programação paralela (OpenMP/MPI)",
                                    "Slides ou vídeo sobre Lei de Gustafson e Amdahl",
                                    "Calculadora ou planilha"
                                  ],
                                  "tips": "Use diagramas para visualizar speedup ideal vs. real; foque em exemplos numéricos para fixar conceitos.",
                                  "learningObjective": "Dominar as fórmulas e interpretações das principais métricas de desempenho paralelo.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Ignorar overheads na decomposição de domínio",
                                    "Aplicar Lei de Amdahl sem considerar paralelismo perfeito"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar o Ambiente e o Programa de Teste",
                                  "subSteps": [
                                    "Selecione ou implemente um programa simples com decomposição de domínio (ex: soma de vetores ou multiplicação de matrizes).",
                                    "Compile versões sequencial e paralela usando ferramentas como GCC com OpenMP ou MPICH para MPI.",
                                    "Configure medição de tempo precisa com funções como omp_get_wtime() ou MPI_Wtime().",
                                    "Prepare hardware/software: múltiplos núcleos, cluster se possível, e ferramentas de profiling (ex: gprof, perf).",
                                    "Teste compilação e execução básica para validar setup."
                                  ],
                                  "verification": "Execute o programa sequencial e paralelo com 1 thread/processo e confirme saídas idênticas.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Editor de código (VS Code)",
                                    "Compilador GCC com suporte OpenMP/MPI",
                                    "Exemplo de código fonte para decomposição de domínio"
                                  ],
                                  "tips": "Use flags de otimização (-O3) consistentemente; rode em máquina dedicada para evitar interferências.",
                                  "learningObjective": "Preparar um ambiente reprodutível para medições precisas de desempenho.",
                                  "commonMistakes": [
                                    "Não sincronizar clocks entre processos",
                                    "Usar tempos de wall-clock sem repetições",
                                    "Ignorar cache effects na decomposição"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar Medições de Tempo de Execução",
                                  "subSteps": [
                                    "Meça tempo sequencial (T_seq) com múltiplas execuções (média de 10-20 runs).",
                                    "Varie número de threads/processos (1,2,4,8,16) e registre T_par para cada.",
                                    "Registre overheads: tempo em barreiras, locks e comunicações.",
                                    "Colete dados de uso de CPU e memória para contexto.",
                                    "Repita medições em diferentes tamanhos de input para testar escalabilidade."
                                  ],
                                  "verification": "Gere uma tabela com tempos médios e desvios padrão para pelo menos 4 configurações de P.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Scripts de automação (bash/python para loops de execução)",
                                    "Planilha Excel/Google Sheets para logging",
                                    "Ferramentas de timing integradas ao framework paralelo"
                                  ],
                                  "tips": "Aqueça o sistema com runs iniciais; use sementes fixas para reprodutibilidade em dados randômicos.",
                                  "learningObjective": "Coletar dados empíricos confiáveis de tempos de execução em cenários paralelos.",
                                  "commonMistakes": [
                                    "Média insuficiente de runs (causando variância alta)",
                                    "Não variar input size",
                                    "Medir tempo total incluindo I/O desnecessário"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e Interpretar Métricas de Desempenho",
                                  "subSteps": [
                                    "Calcule speedup e eficiência para cada P usando fórmulas aprendidas.",
                                    "Estime overhead de sincronização como fração de T_par.",
                                    "Compare resultados com Lei de Amdahl para validar limites.",
                                    "Plote gráficos: speedup vs. P, eficiência vs. P.",
                                    "Identifique gargalos baseados em overheads observados."
                                  ],
                                  "verification": "Produza relatório com cálculos, gráficos e interpretação de pelo menos um gargalo.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python/Matplotlib ou Excel para plots",
                                    "Planilha com fórmulas automáticas",
                                    "Referências teóricas para benchmarks"
                                  ],
                                  "tips": "Use log-scale para plots de escalabilidade; normalize dados para comparações.",
                                  "learningObjective": "Aplicar fórmulas matemáticas para quantificar desempenho e identificar ineficiências.",
                                  "commonMistakes": [
                                    "Erro aritmético em speedup (dividir errado)",
                                    "Interpretar superlinear speedup sem suspeitar de cache",
                                    "Ignorar variância nos cálculos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar Escalabilidade e Otimizar",
                                  "subSteps": [
                                    "Teste escalabilidade forte (input fixo, +P) vs. fraca (input ∝ P).",
                                    "Analise impacto da decomposição de domínio na escalabilidade.",
                                    "Proponha otimizações baseadas em métricas (reduzir sincronizações).",
                                    "Compare com benchmarks públicos ou papers.",
                                    "Documente conclusões e lições aprendidas."
                                  ],
                                  "verification": "Crie um gráfico de escalabilidade e relatório de 1 página com recomendações.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Ferramentas de plotting avançadas (GNUPlot)",
                                    "Papers sobre benchmarks paralelos (ex: NAS Parallel Benchmarks)"
                                  ],
                                  "tips": "Priorize escalabilidade fraca para apps reais; documente hardware specs.",
                                  "learningObjective": "Avaliar e melhorar a escalabilidade de programas paralelos.",
                                  "commonMistakes": [
                                    "Confundir escalabilidade forte com fraca",
                                    "Não considerar custo energético",
                                    "Generalizar resultados sem variar workloads"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente multiplicação de matrizes NxN com decomposição de domínio em linhas usando OpenMP. Meça T_seq para N=1000, então T_par com 1,4,8 threads em 10 runs cada. Calcule speedup (ex: S=3.2 para 4 threads), eficiência (E=80%) e overhead (15% em barreiras). Plote e analise gargalo em sincronização.",
                              "finalVerifications": [
                                "Calcular speedup e eficiência corretamente para dados fornecidos.",
                                "Identificar overhead >20% e propor redução.",
                                "Plotar gráfico de escalabilidade com interpretação válida.",
                                "Comparar resultados com Lei de Amdahl (erro <10%).",
                                "Documentar setup reprodutível.",
                                "Explicar impacto da decomposição de domínio nos resultados."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas métricas (erro <5%).",
                                "Qualidade e reprodutibilidade das medições.",
                                "Profundidade na análise de gargalos e overheads.",
                                "Clareza nos gráficos e relatórios.",
                                "Criatividade em otimizações propostas.",
                                "Integração correta de conceitos teóricos."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo de limites e análise assintótica (O(n)).",
                                "Estatística: Cálculo de médias, desvios e testes de significância.",
                                "Engenharia de Software: Profiling e otimização de código.",
                                "Física/Computação Científica: Simulações paralelas em HPC.",
                                "Gestão de Projetos: Análise custo-benefício de paralelização."
                              ],
                              "realWorldApplication": "Otimizar algoritmos em supercomputadores para simulações climáticas ou genômica, melhorar performance de apps multi-threaded em servidores cloud (ex: Netflix rendering), e avaliar escalabilidade em data centers para IA distribuída."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.6",
                    "name": "Exclusão Mútua",
                    "description": "Mecanismos para sincronização e controle de acesso concorrente em memória compartilhada.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.6.1",
                        "name": "Fundamentos da Exclusão Mútua",
                        "description": "Conceitos básicos de seção crítica, problemas associados à concorrência em memória compartilhada e propriedades requeridas para soluções corretas de sincronização.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.6.1.1",
                            "name": "Identificar seções críticas em programas paralelos",
                            "description": "Analisar trechos de código em programação paralela para reconhecer regiões de código (seções críticas) onde threads acessam recursos compartilhados mutuamente exclusivos, identificando potenciais condições de corrida.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Seções Críticas e Programação Paralela",
                                  "subSteps": [
                                    "Estude a definição de seção crítica: região de código onde um processo/thread acessa recursos compartilhados de forma mutuamente exclusiva.",
                                    "Revise conceitos de programação paralela, incluindo threads, processos e modelos de memória compartilhada.",
                                    "Aprenda sobre condições de corrida (race conditions): quando múltiplas threads acessam/modificam o mesmo recurso simultaneamente sem sincronização.",
                                    "Identifique exemplos clássicos, como contadores compartilhados ou buffers.",
                                    "Diferencie seções críticas de código não-crítico."
                                  ],
                                  "verification": "Explique em suas próprias palavras o que é uma seção crítica e dê um exemplo simples de race condition.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Documentação de pthreads ou OpenMP",
                                    "Vídeos tutoriais sobre programação paralela (ex: YouTube ou Coursera)",
                                    "Artigo sobre exclusão mútua"
                                  ],
                                  "tips": "Use diagramas de fluxo para visualizar o acesso concorrente de threads.",
                                  "learningObjective": "Dominar os conceitos teóricos que definem seções críticas e race conditions.",
                                  "commonMistakes": [
                                    "Confundir seções críticas apenas com variáveis globais",
                                    "Ignorar acessos de leitura como potenciais problemas",
                                    "Não diferenciar threads de processos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar a Estrutura Geral do Programa Paralelo",
                                  "subSteps": [
                                    "Identifique o número de threads ou processos no código.",
                                    "Mapeie as funções ou blocos executados por cada thread.",
                                    "Localize variáveis, estruturas ou objetos declarados como compartilhados (globais, estáticos ou passados por referência).",
                                    "Trace o fluxo de execução de cada thread usando comentários ou setas.",
                                    "Anote pontos de criação/join de threads."
                                  ],
                                  "verification": "Desenhe um diagrama mostrando threads e seus fluxos principais, destacando possíveis interseções.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Editor de código com highlighting (VS Code, CLion)",
                                    "Papel e caneta para diagramas",
                                    "Exemplos de código paralelos simples"
                                  ],
                                  "tips": "Comece pelo main() e siga chamadas de pthread_create ou equivalentes.",
                                  "learningObjective": "Mapear a arquitetura do programa para entender interações entre threads.",
                                  "commonMistakes": [
                                    "Focar apenas em uma thread ignorando o todo",
                                    "Não notar variáveis passadas por ponteiro",
                                    "Confundir variáveis locais com compartilhadas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar Recursos Compartilhados e Acessos Concorrentes",
                                  "subSteps": [
                                    "Liste todos os recursos compartilhados (variáveis, arrays, arquivos, etc.) acessados por múltiplas threads.",
                                    "Para cada recurso, marque linhas onde threads leem ou escrevem.",
                                    "Verifique se os acessos ocorrem em paralelo (sem sincronização visível como mutex ou locks).",
                                    "Avalie se o acesso é mutuamente exclusivo: leitura/escrita simultânea pode causar race condition?",
                                    "Classifique acessos como 'leitura apenas', 'escrita' ou 'leitura-escrita'."
                                  ],
                                  "verification": "Crie uma tabela com recursos, threads que acessam e tipo de operação (R/W).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramenta de análise estática como ThreadSanitizer",
                                    "Exemplos de código com race conditions conhecidas",
                                    "Planilha para tabular acessos"
                                  ],
                                  "tips": "Procure padrões como incrementos (++), atribuições condicionais ou pushes em queues.",
                                  "learningObjective": "Detectar precisamente onde ocorrem acessos concorrentes a recursos compartilhados.",
                                  "commonMistakes": [
                                    "Considerar apenas escritas, ignorando leituras concorrentes",
                                    "Não rastrear acessos indiretos via ponteiros",
                                    "Assumir sincronização sem ver locks explícitos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Marcar Seções Críticas e Validar Potenciais Race Conditions",
                                  "subSteps": [
                                    "Delimite as seções críticas: do primeiro ao último acesso concorrente ao mesmo recurso.",
                                    "Justifique por que cada seção é crítica, citando linhas específicas.",
                                    "Simule execução manualmente para demonstrar possível race condition.",
                                    "Sugira onde inserir mecanismos de sincronização (ex: mutex).",
                                    "Documente o código com comentários destacando seções críticas."
                                  ],
                                  "verification": "Aplique comentários no código original e execute com ferramenta de detecção de races para confirmar.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Compilador com suporte a threads (gcc com -pthread)",
                                    "ThreadSanitizer ou Helgrind (Valgrind)",
                                    "Código de teste compilável"
                                  ],
                                  "tips": "Teste com poucas threads primeiro para observar outputs inconsistentes.",
                                  "learningObjective": "Finalizar a identificação com marcação precisa e validação prática.",
                                  "commonMistakes": [
                                    "Marcar seções muito amplas ou estreitas",
                                    "Não considerar ordem não-determinística de threads",
                                    "Ignorar seções críticas em loops"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere este código C com pthreads:\n#include <pthread.h>\n#include <stdio.h>\nint counter = 0;\nvoid* increment(void* arg) {\n    for(int i=0; i<1000; i++) {\n        counter++;  // Seção crítica!\n    }\n    return NULL;\n}\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Counter: %d\\n\", counter);  // Esperado 2000, mas pode ser menos!\n    return 0;\n}\nA linha 'counter++' é uma seção crítica porque múltiplas threads acessam/modificam o counter compartilhado sem sincronização, causando race condition.",
                              "finalVerifications": [
                                "Identifica corretamente todas as seções críticas em um código dado.",
                                "Explica o risco de race condition para cada seção identificada.",
                                "Propõe locais precisos para sincronização.",
                                "Simula cenários de execução concorrente sem erros.",
                                "Documenta o código com marcações claras e justificativas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de recursos compartilhados (100% cobertura).",
                                "Correta delimitação de seções críticas (início/fim exatos).",
                                "Justificativa técnica robusta com referências a linhas de código.",
                                "Detecção de todos os potenciais race conditions, incluindo sutis.",
                                "Validação prática via simulação ou ferramentas.",
                                "Clareza na documentação e diagramas."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Mecanismos de sincronização como semáforos e monitores.",
                                "Algoritmos e Estruturas de Dados: Implementação thread-safe de queues e locks.",
                                "Engenharia de Software: Padrões de design para programação concorrente (ex: Producer-Consumer).",
                                "Segurança da Informação: Prevenção de vulnerabilidades como TOCTOU em threads.",
                                "Análise de Desempenho: Impacto de seções críticas no throughput de sistemas paralelos."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded como Apache ou Nginx, identificar seções críticas em caches compartilhados ou logs previne corrupção de dados e inconsistências durante picos de tráfego, garantindo escalabilidade e confiabilidade em aplicações de alto volume como e-commerce ou streaming."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.6.1.2",
                            "name": "Explicar as propriedades de uma solução de exclusão mútua",
                            "description": "Descrever detalhadamente as propriedades essenciais: exclusão mútua (apenas uma thread na seção crítica), progresso (evitar deadlock) e espera limitada (evitar starvation).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Conceito de Seção Crítica e Necessidade de Exclusão Mútua",
                                  "subSteps": [
                                    "Defina seção crítica como a parte do código onde um processo/thread acessa recurso compartilhado.",
                                    "Explique race condition: quando múltiplas threads acessam simultaneamente, causando resultados imprevisíveis.",
                                    "Discuta o objetivo da exclusão mútua: garantir que apenas uma thread execute a seção crítica por vez.",
                                    "Identifique exemplos simples de recursos compartilhados, como variáveis globais ou arquivos.",
                                    "Diferencie exclusão mútua de sincronização geral."
                                  ],
                                  "verification": "Escreva uma definição clara de seção crítica e dê um exemplo de race condition em pseudocódigo.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Pseudocódigo editor (como Notepad++ ou online REPL)",
                                    "Capítulo sobre threads em livro de SO (ex: Tanenbaum)"
                                  ],
                                  "tips": "Use diagramas de timeline para visualizar race conditions; desenhe threads competindo por recurso.",
                                  "learningObjective": "Compreender o problema fundamental que as propriedades de exclusão mútua resolvem.",
                                  "commonMistakes": [
                                    "Confundir seção crítica com todo o programa.",
                                    "Ignorar que race conditions só ocorrem em acessos concorrentes."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explicar a Propriedade de Exclusão Mútua",
                                  "subSteps": [
                                    "Defina exclusão mútua: em qualquer momento, no máximo uma thread está na seção crítica.",
                                    "Descreva formalmente: se Pi estiver na SE de Pi, então Pj não pode entrar na SE de Pj para i ≠ j.",
                                    "Analise cenários de violação: duas threads na SE simultaneamente levando a corrupção de dados.",
                                    "Discuta implicações: preserva integridade de dados compartilhados.",
                                    "Compare com ausência: caos em contadores compartilhados."
                                  ],
                                  "verification": "Simule dois threads tentando entrar na SE e confirme que apenas um succeeds.",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Ferramenta de simulação de threads (ex: Java Visualizer ou pseudocódigo manual)",
                                    "Diagrama de Venn para sobreposição de execuções"
                                  ],
                                  "tips": "Pense em banheiro unisex: apenas uma pessoa por vez para evitar confusão.",
                                  "learningObjective": "Dominar a definição e importância da propriedade de exclusão mútua.",
                                  "commonMistakes": [
                                    "Achar que é só 'não deixar dois entrarem', sem formalidade.",
                                    "Confundir com atomicidade de operações."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explicar a Propriedade de Progresso",
                                  "subSteps": [
                                    "Defina progresso: se nenhuma thread estiver na SE e houver threads querendo entrar, uma deve ser selecionada finitamente.",
                                    "Explique evitação de deadlock: sistema não trava indefinidamente.",
                                    "Analise violação: threads em loop infinito esperando umas às outras.",
                                    "Discuta decisão não-trivial: escolha deve ser finita sem inputs externos.",
                                    "Relacione com liveness: garante que o sistema avance."
                                  ],
                                  "verification": "Descreva um cenário sem progresso e corrija-o conceitualmente.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Exemplos de algoritmos como Dekker's em pseudocódigo",
                                    "Gráficos de estado de threads (waiting/inside/out)"
                                  ],
                                  "tips": "Visualize como um semáforo de trânsito: deve permitir passagem quando livre.",
                                  "learningObjective": "Entender como progresso previne deadlocks em soluções de EM.",
                                  "commonMistakes": [
                                    "Confundir com fairness; progresso não garante quem entra primeiro.",
                                    "Pensar que é só ausência de loops infinitos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explicar a Propriedade de Espera Limitada",
                                  "subSteps": [
                                    "Defina espera limitada: número finito de vezes que uma thread pode entrar na SE antes de outra esperando.",
                                    "Explique evitação de starvation: threads não esperam indefinidamente.",
                                    "Formalize: para thread Ti querendo entrar, existe bound B tal que após B entradas de outras, Ti entra.",
                                    "Compare com FCFS: garante turno eventual.",
                                    "Discuta trade-offs: mais forte que progresso, previne livelock/starvation."
                                  ],
                                  "verification": "Calcule um bound simples para 3 threads e verifique em simulação mental.",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Pseudocódigo de Peterson's algorithm",
                                    "Tabela de contadores de entradas por thread"
                                  ],
                                  "tips": "Analogie com fila de supermercado: ninguém espera para sempre se fila avança.",
                                  "learningObjective": "Compreender como espera limitada garante justiça em concorrência.",
                                  "commonMistakes": [
                                    "Confundir com tempo de espera fixo; é sobre número de entradas.",
                                    "Achar desnecessária se há progresso."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integrar e Verificar as Três Propriedades",
                                  "subSteps": [
                                    "Resuma as três propriedades e suas interdependências.",
                                    "Avalie uma solução hipotética (ex: sem uma propriedade) e identifique falhas.",
                                    "Discuta soluções reais como Peterson ou semáforos que satisfazem todas.",
                                    "Crie um checklist para validar qualquer algoritmo de EM.",
                                    "Reflita sobre por que todas são essenciais para corretude."
                                  ],
                                  "verification": "Escreva um parágrafo explicando as propriedades com um exemplo unificado.",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Resumo em tabela: Propriedade | Definição | Violação",
                                    "Algoritmo de exemplo (Peterson)"
                                  ],
                                  "tips": "Use mnemônico: MEPS (Mutual Exclusion, Progress, bounded waiting).",
                                  "learningObjective": "Sintetizar conhecimento para explicar propriedades de forma coesa.",
                                  "commonMistakes": [
                                    "Priorizar uma propriedade sobre outras.",
                                    "Ignorar que soluções podem satisfazer 2/3 mas falhar na terceira."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema bancário multi-threaded, três threads atualizam o saldo de uma conta compartilhada. Sem propriedades: thread1 e thread2 leem $100 simultaneamente, depositam $50 cada (saldo vira $150 em vez de $200 - viola EM); thread3 trava em loop esperando (sem progresso); thread4 nunca entra apesar de tentar (sem espera limitada). Com propriedades: apenas uma thread por vez atualiza corretamente, sistema avança, e cada thread eventualmente processa.",
                              "finalVerifications": [
                                "Defina corretamente as três propriedades sem erros conceituais.",
                                "Identifique violações em cenários dados.",
                                "Explique diferenças entre progresso e espera limitada.",
                                "Valide um algoritmo simples (ex: Peterson) contra as propriedades.",
                                "Dê exemplo real-world onde falha em uma propriedade causa problema.",
                                "Crie diagrama mostrando execução válida."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições formais (80% match com referências padrão).",
                                "Capacidade de identificar violações em pseudocódigo (pelo menos 3 exemplos).",
                                "Explicação clara de interdependências entre propriedades.",
                                "Uso de analogias ou diagramas para clareza.",
                                "Compreensão de implicações para corretude de programas paralelos.",
                                "Aplicação a cenários reais sem confusões."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados: análise de complexidade em soluções de EM.",
                                "Sistemas Operacionais: locks, semáforos e schedulers.",
                                "Teoria da Computação: modelos de máquina paralela e liveness.",
                                "Engenharia de Software: design thread-safe e padrões de concorrência.",
                                "Matemática Discreta: lógica temporal e propriedades de invariância."
                              ],
                              "realWorldApplication": "Em servidores web como Apache ou bancos de dados MySQL, garantindo que transações ACID (especialmente Isolation) evitem corrupção por acessos concorrentes; em apps mobile com múltiplos workers atualizando UI; em jogos multiplayer sincronizando estados compartilhados sem crashes ou injustiças."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.6.1.3",
                            "name": "Diferenciar problemas de sincronização relacionados",
                            "description": "Comparar exclusão mútua com outros problemas como produtor-consumidor e leitores-escritores, destacando o foco em controle de acesso concorrente a recursos compartilhados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar fundamentos da Exclusão Mútua",
                                  "subSteps": [
                                    "Defina exclusão mútua como mecanismo para garantir acesso exclusivo a recurso compartilhado por apenas um processo por vez.",
                                    "Identifique as propriedades essenciais: progresso, bounded waiting e não-estrelamento.",
                                    "Analise exemplos clássicos como Peterson's algorithm ou Dekker's algorithm.",
                                    "Discuta cenários onde falha na ME causa race conditions.",
                                    "Registre as diferenças iniciais com problemas que permitem múltiplos acessos."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando ME e suas propriedades, sem erros conceituais.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Slides de programação paralela, pseudocódigo de algoritmos de ME, livro de Sistemas Operacionais (Tanenbaum).",
                                  "tips": "Use diagramas de tempo para visualizar acessos concorrentes e evitar confusão com serialização.",
                                  "learningObjective": "Compreender o foco exclusivo da ME em controle de acesso unitário a recursos.",
                                  "commonMistakes": "Confundir ME com deadlocks ou assumir que ME resolve todos os problemas de sincronização."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o problema Produtor-Consumidor",
                                  "subSteps": [
                                    "Descreva o cenário: produtores inserem itens em buffer, consumidores retiram, sincronizando cheio/vazio.",
                                    "Explique o uso de semáforos ou monitores para wait/signal em mutex, full e empty.",
                                    "Compare com ME: PC permite múltiplos produtores/consumidores, mas buffer como recurso compartilhado.",
                                    "Simule uma execução com 2 produtores e 2 consumidores para ver sincronização.",
                                    "Identifique quando PC difere de ME puro (ex.: buffer FIFO vs acesso exclusivo simples)."
                                  ],
                                  "verification": "Desenhe um diagrama de sinalização para PC com buffer de tamanho 3 e verifique ausência de overflow/underflow.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Ferramenta de simulação como TLA+ ou pseudocódigo em Python, vídeo tutorial sobre semáforos.",
                                  "tips": "Pense no buffer como uma fila: foque em condições de não-vazio e não-cheio para sinalizar corretamente.",
                                  "learningObjective": "Reconhecer o foco de PC em coordenação de produção/consumo com buffers limitados.",
                                  "commonMistakes": "Ignorar a necessidade de mutex no buffer além dos semáforos de contagem."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar o problema Leitores-Escritores",
                                  "subSteps": [
                                    "Defina o problema: múltiplos leitores simultâneos ok, mas escritores exclusivos e sem leitores durante escrita.",
                                    "Discuta variantes: primeira prioridade ao escritor ou leitor.",
                                    "Use semáforos para mutex, wrt (write) e contagem de leitores.",
                                    "Compare com ME: permite múltiplos acessos de leitura, mas exclusivo para escrita.",
                                    "Analise riscos como starvation de escritores se leitores dominam."
                                  ],
                                  "verification": "Implemente pseudocódigo para L-E e teste com cenários de 3 leitores + 1 escritor.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Pseudocódigo de soluções L-E, simulador online de threads, notas de aula sobre semáforos.",
                                  "tips": "Lembre-se: leitores usam contagem compartilhada, mas escritores resetam para zero.",
                                  "learningObjective": "Entender o equilíbrio entre acessos concorrentes de leitura e exclusivos de escrita.",
                                  "commonMistakes": "Permitir escritores concorrentes ou leitores durante escrita."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar e diferenciar os problemas",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: foco (acesso exclusivo vs buffer vs multi-leitura), primitivas usadas, cenários típicos.",
                                    "Destaque ME: controle simples de recurso único; PC: sincronização de fluxo; L-E: hierarquia de acessos.",
                                    "Discuta sobreposições: todos usam ME internamente, mas com camadas adicionais.",
                                    "Aplique a um caso real: identifique qual problema se aplica a um web server (ex.: L-E para cache).",
                                    "Resuma diferenças chave em controle de acesso concorrente."
                                  ],
                                  "verification": "Preencha tabela comparativa e explique verbalmente ou por escrito as 3 diferenças principais.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Planilha ou ferramenta Markdown para tabela, exemplos de código de cada problema.",
                                  "tips": "Use mnemônicos: ME=1-por-vez, PC=enche/esvazia, L-E=leia-junto mas escreva-sozinho.",
                                  "learningObjective": "Diferenciar precisamente os problemas destacando focos em sincronização.",
                                  "commonMistakes": "Equiparar todos como 'apenas ME' ignorando semânticas específicas."
                                }
                              ],
                              "practicalExample": "Em um sistema de chat multiusuário: ME para atualizar contador de usuários online (exclusivo); PC para fila de mensagens enviadas/recebidas (produtores=usuarios enviando, consumidores=servidor processando); L-E para banco de dados de histórico (múltiplos leitores visualizando, escritores adicionando mensagens novas).",
                              "finalVerifications": [
                                "Explicar sem hesitação as 3 diferenças principais entre ME, PC e L-E.",
                                "Identificar corretamente o problema em um cenário descrito (ex.: buffer de jobs = PC).",
                                "Montar tabela comparativa sem erros factuais.",
                                "Simular falha em cada problema e propor correção.",
                                "Discutir quando usar cada um em um app real.",
                                "Verificar ausência de confusão entre primitivas (mutex vs semaphore)."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: distinção clara entre focos dos problemas (90%+ acerto).",
                                "Profundidade de comparação: inclusão de primitivas e propriedades (tabela completa).",
                                "Aplicação prática: exemplos relevantes sem generalizações erradas.",
                                "Clareza na explicação: uso de analogias e diagramas eficazes.",
                                "Compreensão de nuances: menção a starvation, prioridades e variantes.",
                                "Originalidade: síntese própria além de cópia de materiais."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Implementação de semáforos e monitores.",
                                "Redes de Computadores: Sincronização em protocolos distribuídos como TCP queues.",
                                "Banco de Dados: Locks de leitura/escrita em transações concorrentes.",
                                "Engenharia de Software: Padrões de design para threads em aplicações multi-threaded."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx: ME para logs compartilhados; PC para pools de conexões (produtores=requests, consumidores=workers); L-E para caches de conteúdo (leitores múltiplos, escritores atualizando)."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.6.2",
                        "name": "Algoritmos de Software para Exclusão Mútua",
                        "description": "Algoritmos clássicos baseados apenas em operações de leitura e escrita para implementar exclusão mútua entre dois ou mais processos sem suporte de hardware especial.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.6.2.1",
                            "name": "Implementar o algoritmo de Dekker",
                            "description": "Desenvolver e simular o algoritmo de Dekker para dois processos, utilizando variáveis de turno e flag para garantir exclusão mútua, progresso e espera limitada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Requisitos da Exclusão Mútua e Problemas Associados",
                                  "subSteps": [
                                    "Estude os três requisitos principais: exclusão mútua (ME), progresso e espera limitada.",
                                    "Analise exemplos de falhas sem sincronização, como race conditions em contadores compartilhados.",
                                    "Revise soluções peterson e Dekker como algoritmos de software para dois processos.",
                                    "Identifique limitações de spinlocks simples e por que Dekker é necessário.",
                                    "Desenhe diagramas de fluxo para processos P0 e P1 competindo por recurso."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito os três requisitos e dê um exemplo de violação de cada um.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Artigos sobre exclusão mútua (Tanenbaum ou Silberschatz)",
                                    "Vídeos sobre Dekker no YouTube",
                                    "Papel e caneta para diagramas"
                                  ],
                                  "tips": "Use analogias reais, como duas pessoas acessando uma porta única, para visualizar ME.",
                                  "learningObjective": "Dominar os fundamentos teóricos necessários para algoritmos de sincronização.",
                                  "commonMistakes": [
                                    "Confundir progresso com livelock",
                                    "Ignorar espera limitada, achando que busy-wait é suficiente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar a Estrutura e Lógica do Algoritmo de Dekker",
                                  "subSteps": [
                                    "Identifique as variáveis: boolean flag[2] = {false, false}; int turn;",
                                    "Estude a lógica do loop while: verificar flag do outro, setar própria flag, checar turn.",
                                    "Trace a execução sequencial para P0 e P1 entrando na seção crítica.",
                                    "Simule cenários de intercalação manualmente em papel.",
                                    "Explique como Dekker garante ME (um flag true e turn alternado), progresso e bounded waiting."
                                  ],
                                  "verification": "Desenhe um trace de execução com 10 iterações mostrando alternância correta.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Pseudocódigo oficial de Dekker",
                                    "Ferramenta de diagrama como Draw.io",
                                    "Simulador online de algoritmos de EM"
                                  ],
                                  "tips": "Comece com turn fixo para P0 e alterne manualmente para entender o politeness.",
                                  "learningObjective": "Compreender precisamente como flags e turn interagem para sincronização.",
                                  "commonMistakes": [
                                    "Esquecer de resetar flag ao sair da SC",
                                    "Confundir turn com prioridade fixa"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar o Algoritmo de Dekker em Pseudocódigo e Código Real",
                                  "subSteps": [
                                    "Escreva pseudocódigo completo para processo Pi (i=0 ou 1).",
                                    "Traduza para Python usando threading ou C com pthreads.",
                                    "Implemente seção crítica simples (ex: incrementar contador compartilhado 1000x).",
                                    "Adicione prints para trace de flag e turn durante execução.",
                                    "Compile e execute em ambiente multi-threaded."
                                  ],
                                  "verification": "Execute o código e confirme que o contador final é correto (sem race conditions).",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Editor de código (VS Code)",
                                    "Python com threading module ou C com pthreads",
                                    "Compilador GCC"
                                  ],
                                  "tips": "Use atomic operations apenas para demonstração inicial, depois remova para testar Dekker puro.",
                                  "learningObjective": "Traduzir teoria em implementação funcional e debugável.",
                                  "commonMistakes": [
                                    "Não usar volatile para variáveis compartilhadas",
                                    "Erros de indentação nos loops while"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Simular, Testar e Verificar Propriedades do Algoritmo",
                                  "subSteps": [
                                    "Crie cenários de teste: entrada simultânea, um esperando o outro.",
                                    "Use ferramentas como gdb ou printfs para inspecionar estados.",
                                    "Verifique ME: nunca dois na SC; progresso: ambos entram eventualmente; bounded wait: no starvation.",
                                    "Meça performance vs busy-wait simples.",
                                    "Documente falhas em implementações erradas e corrija."
                                  ],
                                  "verification": "Gere relatório com traces mostrando cumprimento dos 3 requisitos em 5 execuções.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Debugger (gdb ou pdb)",
                                    "Scripts de teste automatizados",
                                    "Ferramenta de profiling como timeit"
                                  ],
                                  "tips": "Aumente loops para estressar e revelar bugs sutis.",
                                  "learningObjective": "Validar empiricamente a corretão do algoritmo implementado.",
                                  "commonMistakes": [
                                    "Testar apenas execuções sequenciais",
                                    "Ignorar cenários de preemptção"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente dois threads em Python: um para 'Processo 0' e outro para 'Processo 1'. Cada um tenta entrar 1000 vezes em uma seção crítica que incrementa um contador compartilhado de 1. Use Dekker para sincronizar, garantindo que o contador final seja exatamente 2000, sem sobras ou perdas por race conditions. Adicione logs para visualizar flags e turn alternando.",
                              "finalVerifications": [
                                "O código implementa corretamente flags e turn sem violações de sintaxe.",
                                "Simulações mostram alternância perfeita entre processos.",
                                "Testes estressados confirmam ME, progresso e bounded waiting.",
                                "Contador compartilhado atinge valor exato em múltiplas runs.",
                                "Relatório documenta traces e propriedades comprovadas.",
                                "Código é limpo, comentado e executável."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação da lógica de Dekker (peso 30%).",
                                "Correção em simulações e testes (peso 25%).",
                                "Compreensão demonstrada em explicações e traces (peso 20%).",
                                "Eficiência e ausência de busy-wait infinito (peso 15%).",
                                "Documentação e relatórios claros (peso 10%)."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Sincronização de threads e semáforos.",
                                "Teoria da Computação: Autômatos e modelos de concorrência.",
                                "Programação Funcional: Abordagens imutáveis vs mutáveis.",
                                "Engenharia de Software: Design de algoritmos distribuídos.",
                                "Lógica Digital: Circuitos sequenciais para hardware EM."
                              ],
                              "realWorldApplication": "Em sistemas embarcados sem suporte hardware a locks (ex: microcontroladores antigos), ou em kernels de OS customizados para sincronização leve de dois drivers competindo por um barramento compartilhado, evitando overhead de mutexes pesados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.1.2"
                            ]
                          },
                          {
                            "id": "10.1.1.6.2.2",
                            "name": "Implementar o algoritmo de Peterson",
                            "description": "Codificar o algoritmo de Peterson para dois threads, explicando o uso de variáveis de intenção e turno para resolver o problema da seção crítica de forma justa.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os conceitos fundamentais do algoritmo de Peterson",
                                  "subSteps": [
                                    "Estude o problema da seção crítica (SC) e os requisitos: exclusão mútua, progresso e espera limitada.",
                                    "Revise as variáveis: flag[0] e flag[1] para intenção, e turn para decidir quem entra.",
                                    "Analise o pseudocódigo padrão do algoritmo para dois processos.",
                                    "Identifique como o loop while garante justiça e evita starvation."
                                  ],
                                  "verification": "Resuma em suas palavras os três requisitos e o papel de cada variável.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Pseudocódigo do algoritmo de Peterson (impresso ou online)",
                                    "Notas sobre problemas de concorrência"
                                  ],
                                  "tips": "Desenhe um diagrama de fluxo para visualizar as interações entre processos.",
                                  "learningObjective": "Compreender os princípios teóricos que sustentam o algoritmo de Peterson.",
                                  "commonMistakes": [
                                    "Confundir flag com turn",
                                    "Ignorar o requisito de bounded waiting"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar o ambiente de programação e declarar variáveis compartilhadas",
                                  "subSteps": [
                                    "Instale um compilador C com suporte a threads (pthreads).",
                                    "Crie um programa base com dois threads e uma seção crítica simulada (ex: contador compartilhado).",
                                    "Declare as variáveis globais: bool flag[2] = {false, false}; int turn;",
                                    "Inclua headers necessários: <pthread.h>, <stdio.h>, <unistd.h>."
                                  ],
                                  "verification": "Compile o esqueleto sem erros e verifique se as threads rodam alternadamente sem sincronização.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Compilador GCC com pthreads",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Use volatile para variáveis compartilhadas se necessário, mas foque em lógica primeiro.",
                                  "learningObjective": "Preparar um ambiente funcional para testar exclusão mútua.",
                                  "commonMistakes": [
                                    "Esquecer de inicializar flags como false",
                                    "Não linkar -lpthread no compile"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a entrada na seção crítica para o Processo 0 (Thread 0)",
                                  "subSteps": [
                                    "Defina o ID do processo: int proc = 0;",
                                    "Colete a intenção: flag[proc] = true; turn = 1 - proc;",
                                    "Implemente o loop while: while (flag[1 - proc] && turn == 1 - proc);",
                                    "Adicione logs para depuração dentro da SC."
                                  ],
                                  "verification": "Teste isolado: Thread 0 entra na SC sem bloqueio quando Thread 1 não quer entrar.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código esqueleto do passo anterior",
                                    "Documentação pthreads"
                                  ],
                                  "tips": "Use usleep() para simular trabalho na SC e tornar starvation visível.",
                                  "learningObjective": "Codificar corretamente a lógica de tentativa de entrada para um processo.",
                                  "commonMistakes": [
                                    "Erro no cálculo de 1 - proc",
                                    "Colocar turn antes do flag"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar a entrada/saída para o Processo 1 (Thread 1) e saídas",
                                  "subSteps": [
                                    "Repita para proc = 1: flag[proc] = true; turn = 1 - proc; while(flag[0] && turn == 0);",
                                    "Adicione saída da SC: flag[proc] = false;",
                                    "Crie função thread_func(int proc) que repete tentativas de entrada (loop externo).",
                                    "Configure pthread_create para duas threads."
                                  ],
                                  "verification": "Execute e verifique via logs que apenas um thread está na SC por vez.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código completo parcial"
                                  ],
                                  "tips": "Aumente iterações para testar fairness (espera limitada).",
                                  "learningObjective": "Completar a implementação simétrica e as saídas corretas.",
                                  "commonMistakes": [
                                    "Não resetar flag na saída",
                                    "Assimetria entre processos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar e verificar as propriedades do algoritmo",
                                  "subSteps": [
                                    "Compile e execute com múltiplas iterações (ex: 1000).",
                                    "Adicione contadores para entradas na SC e verifique interleaving justo.",
                                    "Simule cenários: um thread sempre querendo entrar, ambos competindo.",
                                    "Use gdb ou valgrind para checar race conditions ou deadlocks.",
                                    "Documente resultados em um relatório simples."
                                  ],
                                  "verification": "Confirme: sem violações de EM, progresso garantido, sem starvation em runs longas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Valgrind para detecção de erros",
                                    "GDB para debug"
                                  ],
                                  "tips": "Rode com diferentes seeds de tempo para estresse.",
                                  "learningObjective": "Validar empiricamente as propriedades teóricas do algoritmo.",
                                  "commonMistakes": [
                                    "Ignorar starvation em testes curtos",
                                    "Confundir busy-wait com deadlock"
                                  ]
                                }
                              ],
                              "practicalExample": "Dois threads simulam caixas eletrônicos acessando um saldo compartilhado: cada um debita/credita alternadamente usando Peterson para evitar saldo incorreto por race condition.",
                              "finalVerifications": [
                                "O programa compila e executa sem deadlocks ou crashes.",
                                "Logs mostram que apenas um thread acessa a SC por vez (exclusão mútua).",
                                "Ambos threads fazem progresso e entram na SC eventualmente (progresso).",
                                "Nenhum thread fica bloqueado indefinidamente em runs longas (bounded waiting).",
                                "Contador compartilhado final é correto após N iterações.",
                                "Valgrind não reporta erros de memória ou races.",
                                "Fairness: turn alterna corretamente em competições."
                              ],
                              "assessmentCriteria": [
                                "Uso correto e simétrico de flag[0]/flag[1] e turn.",
                                "Loop while com condições exatas: flag[outro] && turn == outro.",
                                "Reset de flag[proc] = false na saída da SC.",
                                "Loop externo para múltiplas tentativas.",
                                "Logs ou contadores comprovam propriedades.",
                                "Código limpo, comentado e compilável com pthreads.",
                                "Tratamento de argumentos de thread correto."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Mecanismos de sincronização e semáforos.",
                                "Arquitetura de Computadores: Modelos de memória e consistência.",
                                "Matemática Discreta: Lógica proposicional e invariantes.",
                                "Redes de Computadores: Protocolos de eleição e controle de acesso.",
                                "Segurança da Informação: Proteção de recursos compartilhados."
                              ],
                              "realWorldApplication": "Em aplicações multi-threaded como servidores web (ex: Nginx threads gerenciando conexões compartilhadas) ou bancos de dados (controle de locks lógicos sem hardware, garantindo transações ACID em ambientes sem suporte a atomicas nativas)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.1.2"
                            ]
                          },
                          {
                            "id": "10.1.1.6.2.3",
                            "name": "Analisar corretude de algoritmos de software",
                            "description": "Provar formalmente ou por casos as propriedades de corretude (exclusão mútua, progresso, bounded waiting) em algoritmos como Dekker e Peterson.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as propriedades de corretude para exclusão mútua",
                                  "subSteps": [
                                    "Defina mutual exclusion: no máximo um processo na seção crítica simultaneamente.",
                                    "Defina progress: se processos querem entrar e ninguém na seção crítica, decisão deve ser tomada em tempo finito.",
                                    "Defina bounded waiting: número finito de entradas na seção crítica por outros antes da sua vez.",
                                    "Estude violações comuns com exemplos de execuções concorrentes.",
                                    "Revise noções de intercalação (interleaving) de execuções."
                                  ],
                                  "verification": "Escreva definições precisas das três propriedades e dê um exemplo de violação de cada uma.",
                                  "estimatedTime": "1-2 hours",
                                  "materials": [
                                    "Notas de aula sobre exclusão mútua",
                                    "Pseudocódigo de algoritmos básicos",
                                    "Artigo ou capítulo sobre propriedades de Peterson"
                                  ],
                                  "tips": "Use diagramas de tempo para visualizar execuções concorrentes.",
                                  "learningObjective": "Dominar definições formais e intuitivas das propriedades de corretude.",
                                  "commonMistakes": [
                                    "Confundir progress com starvation.",
                                    "Ignorar cenários de dois ou mais processos."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar o algoritmo de Dekker em detalhes",
                                  "subSteps": [
                                    "Analise o pseudocódigo completo do algoritmo de Dekker para dois processos.",
                                    "Identifique variáveis compartilhadas (flag, turn).",
                                    "Trace uma execução passo a passo com dois processos competindo.",
                                    "Simule cenários onde um processo entra na seção crítica.",
                                    "Identifique pontos de decisão crítica no loop while."
                                  ],
                                  "verification": "Desenhe um diagrama de execução mostrando um processo entrando na seção crítica sem violação.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Pseudocódigo do Dekker",
                                    "Ferramenta de simulação como TLA+ ou papel e lápis",
                                    "Vídeo tutorial sobre Dekker"
                                  ],
                                  "tips": "Numere cada instrução para rastrear ordem de execução.",
                                  "learningObjective": "Entender a mecânica interna do algoritmo de Dekker.",
                                  "commonMistakes": [
                                    "Assumir ordem sequencial de execução.",
                                    "Esquecer atualizações atômicas de variáveis."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Provar mutual exclusion no algoritmo de Dekker",
                                  "subSteps": [
                                    "Assuma por contradição que ambos processos P0 e P1 estão na seção crítica.",
                                    "Analise valores de flag[0], flag[1] e turn.",
                                    "Mostre que pelo menos um while loop bloqueia um processo.",
                                    "Considere todos os casos possíveis de turn (0 ou 1).",
                                    "Formalize com lógica proposicional ou indução."
                                  ],
                                  "verification": "Escreva uma prova por contradição de 10-15 linhas para mutual exclusion.",
                                  "estimatedTime": "2-3 hours",
                                  "materials": [
                                    "Papel para provas formais",
                                    "Template de prova por casos",
                                    "Exemplos de provas de livros como Silberschatz"
                                  ],
                                  "tips": "Use tabelas verdade para combinações de flags e turn.",
                                  "learningObjective": "Aplicar prova por contradição em contextos concorrentes.",
                                  "commonMistakes": [
                                    "Não cobrir todos os casos de turn.",
                                    "Ignorar persistência das flags."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Provar progress e bounded waiting no Dekker e Peterson",
                                  "subSteps": [
                                    "Para progress: mostre que se ambos querem entrar e ninguém dentro, um entra.",
                                    "Analise bounded waiting: prove que cada processo espera no máximo uma vez pelo outro.",
                                    "Compare com algoritmo de Peterson (usando turn e interested).",
                                    "Simule violações potenciais e refute-as.",
                                    "Generalize para propriedades em ambos algoritmos."
                                  ],
                                  "verification": "Forneça provas curtas para progress e bounded waiting em ambos algoritmos.",
                                  "estimatedTime": "2-3 hours",
                                  "materials": [
                                    "Pseudocódigo de Peterson",
                                    "Ferramentas de model checking como SPIN",
                                    "Exercícios resolvidos de corretude"
                                  ],
                                  "tips": "Use invariantes para simplificar provas de progress.",
                                  "learningObjective": "Provar propriedades liveness além de safety.",
                                  "commonMistakes": [
                                    "Confundir bounded waiting com fairness absoluta.",
                                    "Não considerar loops infinitos sem bounded waiting."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar corretude por casos e prática integrada",
                                  "subSteps": [
                                    "Gere execuções exaustivas para 2 processos (até 10 passos cada).",
                                    "Verifique propriedades manualmente ou com script simples.",
                                    "Aplique a algoritmos variantes ou implementações reais.",
                                    "Discuta limitações (apenas 2 processos).",
                                    "Escreva relatório resumindo todas as provas."
                                  ],
                                  "verification": "Crie tabela de 5 execuções verificando todas propriedades sem violações.",
                                  "estimatedTime": "1-2 hours",
                                  "materials": [
                                    "Planilha Excel para rastrear estados",
                                    "Código Python para simulação básica",
                                    "Checklist de propriedades"
                                  ],
                                  "tips": "Automatize verificações simples com loops para brute-force.",
                                  "learningObjective": "Combinar provas formais com verificação empírica.",
                                  "commonMistakes": [
                                    "Testar apenas execuções lineares.",
                                    "Não escalar para cenários edge-case."
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente o algoritmo de Dekker em pseudocódigo e simule 10 execuções concorrentes diferentes. Para cada uma, prove manualmente que mutual exclusion é mantida (ex: em execução onde P0 define flag[0]=true, turn=1, P1 bloqueia no while(flag[0] && turn==1)). Em seguida, verifique progress mostrando que após saída de P0, P1 entra imediatamente.",
                              "finalVerifications": [
                                "Define corretamente mutual exclusion, progress e bounded waiting.",
                                "Fornece prova completa por contradição para mutual exclusion em Dekker.",
                                "Demonstra progress sem deadlock em cenários de competição.",
                                "Prova bounded waiting com contagem de esperas máximas.",
                                "Aplica análise similar ao algoritmo de Peterson.",
                                "Identifica pelo menos 3 execuções sem violações."
                              ],
                              "assessmentCriteria": [
                                "Precisão e formalidade das definições (30%)",
                                "Completude e lógica das provas (40%)",
                                "Cobertura de todos os casos e cenários (15%)",
                                "Clareza na apresentação com diagramas/tabelas (10%)",
                                "Generalização para Peterson e insights (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Lógica proposicional e prova por contradição/indução.",
                                "Teoria da Computação: Autômatos e verificação de modelos.",
                                "Sistemas Operacionais: Sincronização de threads e semáforos.",
                                "Programação: Implementação multi-threaded em linguagens como Java/C++."
                              ],
                              "realWorldApplication": "Em desenvolvimento de software concorrente, como servidores web multi-threaded (ex: Nginx) ou bancos de dados (ex: PostgreSQL locks), garantindo que algoritmos de lock evitem race conditions, deadlocks e starvation, prevenindo perdas financeiras ou falhas de sistema."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.6.3",
                        "name": "Primitivas de Hardware e Abstrações de Alto Nível",
                        "description": "Instruções atômicas de hardware e bibliotecas modernas para implementar exclusão mútua de forma eficiente em plataformas multicores como OpenMP e pthreads.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.6.3.1",
                            "name": "Utilizar instruções atômicas como Test-and-Set",
                            "description": "Explicar e implementar exclusão mútua usando a primitiva Test-and-Set (TAS), incluindo busy-waiting e sua limitação para múltiplos processadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos de exclusão mútua e instrução Test-and-Set (TAS)",
                                  "subSteps": [
                                    "Estude o problema da exclusão mútua em programação paralela: defina seção crítica, race condition e requisitos (progresso, bounded waiting).",
                                    "Analise a primitiva de hardware Test-and-Set: leia o valor de uma variável e defina-a para 1 atomically, retornando o valor original.",
                                    "Compare TAS com outras primitivas como Compare-and-Swap (CAS).",
                                    "Identifique o papel do TAS em fornecer atomicidade em nível de hardware.",
                                    "Revise exemplos de cenários onde race conditions ocorrem sem sincronização."
                                  ],
                                  "verification": "Resuma em um parágrafo os conceitos de exclusão mútua e TAS, citando os 4 requisitos clássicos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação de arquitetura x86 (Intel manuals)",
                                    "Livro 'Operating System Concepts' capítulo sobre sincronização",
                                    "Pseudocódigo de TAS"
                                  ],
                                  "tips": "Use diagramas de tempo para visualizar race conditions entre threads.",
                                  "learningObjective": "Entender o problema da exclusão mútua e como TAS resolve atomicidade básica.",
                                  "commonMistakes": [
                                    "Confundir TAS com set simples (não atômico)",
                                    "Ignorar que TAS é uma operação de leitura-modificação-escrita atômica"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar exclusão mútua usando Test-and-Set com busy-waiting",
                                  "subSteps": [
                                    "Defina uma variável lock global inicializada em 0.",
                                    "Implemente a função test_and_set() que retorna o valor antigo e seta para 1.",
                                    "Crie o loop de aquisição: while (test_and_set(&lock)) ; // busy wait",
                                    "Implemente liberação: lock = 0;",
                                    "Teste em pseudocódigo com duas threads acessando uma variável compartilhada."
                                  ],
                                  "verification": "Execute o código em simulador ou ambiente single-core e confirme ausência de race conditions.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Compilador C com intrinsics __sync_lock_test_and_set (GCC)",
                                    "Simulador de threads como pthreads",
                                    "Editor de código (VS Code)"
                                  ],
                                  "tips": "Use printf com thread ID para depurar a ordem de execução.",
                                  "learningObjective": "Implementar corretamente o algoritmo TAS para proteger seção crítica.",
                                  "commonMistakes": [
                                    "Esquecer de liberar o lock (deadlock)",
                                    "Usar lock sem busy-wait (falha em atomicidade)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar o busy-waiting e suas implicações de performance",
                                  "subSteps": [
                                    "Meça o overhead do busy-waiting: conte ciclos de CPU desperdiçados em spin.",
                                    "Discuta vantagens: simplicidade, sem overhead de contexto switch em curtas esperas.",
                                    "Analise desvantagens: alto consumo de CPU, ineficiência em locks longos.",
                                    "Implemente timeout no busy-wait para evitar spins infinitos.",
                                    "Compare com soluções como sleep() em loops."
                                  ],
                                  "verification": "Gere um gráfico de CPU usage com e sem busy-waiting usando ferramentas como perf.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Ferramenta perf ou top para monitorar CPU",
                                    "Código do step 2 modificado",
                                    "Gráficos em Python (matplotlib)"
                                  ],
                                  "tips": "Teste com delays artificiais na seção crítica para simular locks longos.",
                                  "learningObjective": "Avaliar trade-offs do busy-waiting em termos de performance e eficiência.",
                                  "commonMistakes": [
                                    "Assumir que busy-waiting é sempre ineficiente sem medições",
                                    "Ignorar cache coherence em análise"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar limitações em multiprocessadores e introduzir abstrações",
                                  "subSteps": [
                                    "Explique por que TAS funciona em single-processor mas falha em cache coherence (MESI protocol).",
                                    "Discuta problemas de escalabilidade: contenda em cache lines compartilhadas.",
                                    "Introduza melhorias: TAS com backoff exponencial ou ticket locks.",
                                    "Compare com abstrações de alto nível como mutex em pthreads.",
                                    "Implemente uma versão melhorada com backoff simples."
                                  ],
                                  "verification": "Simule em multi-core (2+ threads) e meça throughput com ferramentas como likwid.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Máquina multi-core",
                                    "Livro 'The Art of Multiprocessor Programming'",
                                    "Código pthread com TAS intrinsics"
                                  ],
                                  "tips": "Use rdmsr para monitorar cache misses em Linux.",
                                  "learningObjective": "Identificar e mitigar limitações do TAS em sistemas SMP.",
                                  "commonMistakes": [
                                    "Pensar que TAS é escalável sem considerar memória compartilhada",
                                    "Confundir uniprocessor com multiprocessor"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de banco simples com threads depositando em conta compartilhada: use TAS para lock em 'while(test_and_set(&account_lock)); balance += amount; account_lock=0;'. Teste com 4 threads em loop de 1M iterações para verificar consistência.",
                              "finalVerifications": [
                                "Implemente e execute código TAS sem race conditions em single-core.",
                                "Meça CPU usage >90% durante busy-waiting.",
                                "Explique falha de TAS em multi-core devido a cache invalidations.",
                                "Modifique com backoff e demonstre redução de contenda.",
                                "Compare performance com std::mutex em C++.",
                                "Resuma requisitos de Peterson's algorithm vs TAS."
                              ],
                              "assessmentCriteria": [
                                "Correção da implementação TAS (ausência de races).",
                                "Análise precisa de busy-waiting (prós e contras com evidências).",
                                "Identificação correta de limitações multiprocessador.",
                                "Qualidade do exemplo prático (reprodutível e mensurável).",
                                "Profundidade nas conexões com hardware (cache coherence).",
                                "Clareza na explicação oral ou escrita dos conceitos."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Protocolos de cache (MESI).",
                                "Sistemas Operacionais: Implementação de spinlocks em kernels.",
                                "Programação Concorrente: Comparação com locks de software.",
                                "Análise de Algoritmos: Complexidade em tempo e espaço para sincronização.",
                                "Engenharia de Software: Padrões de design para thread-safety."
                              ],
                              "realWorldApplication": "Spinlocks baseados em TAS são usados em kernels Linux (futexes), bancos de dados (InnoDB row locks) e bibliotecas como Intel TBB para locks de baixa latência em workloads de alta contenda curta."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.1.3"
                            ]
                          },
                          {
                            "id": "10.1.1.6.3.2",
                            "name": "Aplicar Compare-and-Swap (CAS) para locks",
                            "description": "Desenvolver um lock não-bloqueante usando Compare-and-Swap, comparando com soluções tradicionais e discutindo otimismo em cenários de baixa contenda.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de Compare-and-Swap (CAS)",
                                  "subSteps": [
                                    "Estude a definição de CAS: operação atômica que compara o valor atual de uma variável com um valor esperado e, se iguais, substitui por um novo valor.",
                                    "Analise a assinatura típica em linguagens como C++ (std::atomic::compare_exchange_strong) ou Java (AtomicInteger.compareAndSet).",
                                    "Discuta as propriedades: atomicidade, linearizabilidade e não-bloqueio.",
                                    "Compare CAS com operações tradicionais de leitura/escrita, destacando problemas de race conditions.",
                                    "Revise exemplos simples de uso em cenários de contenda baixa."
                                  ],
                                  "verification": "Explique em suas palavras como CAS previne race conditions e escreva um pseudocódigo básico.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação de std::atomic (C++)",
                                    "Artigo sobre primitivas de hardware (Intel/ARM manuals)",
                                    "Vídeo introdutório sobre non-blocking synchronization"
                                  ],
                                  "tips": "Visualize CAS como uma 'porta giratória' que só abre se ninguém interferir.",
                                  "learningObjective": "Entender o funcionamento e as vantagens do CAS como primitiva de hardware para sincronização não-bloqueante.",
                                  "commonMistakes": [
                                    "Confundir CAS com operações condicionais não-atômicas",
                                    "Ignorar o loop de retry em implementações práticas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar um lock não-bloqueante básico usando CAS",
                                  "subSteps": [
                                    "Defina a estrutura do lock: use um atomic<int> para estado (0=desbloqueado, 1=bloqueado).",
                                    "Implemente lock(): loop while(!cas(0,1)) para adquirir o lock.",
                                    "Implemente unlock(): cas(1,0) para liberar.",
                                    "Teste com duas threads tentando acessar uma variável compartilhada.",
                                    "Adicione suporte a threads nomeadas para depuração."
                                  ],
                                  "verification": "Compile e execute o código com múltiplas threads; verifique ausência de race conditions via logs.",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "Compilador C++17+ com suporte a threads",
                                    "GDB ou debugger para threads",
                                    "Exemplo de código base em GitHub sobre CAS locks"
                                  ],
                                  "tips": "Use busy-waiting com pausas curtas (std::this_thread::yield()) para reduzir CPU em falhas de CAS.",
                                  "learningObjective": "Desenvolver um lock funcional usando apenas CAS, demonstrando programação não-bloqueante.",
                                  "commonMistakes": [
                                    "Esquecer o loop de retry no lock()",
                                    "Não tratar falhas de CAS adequadamente",
                                    "Usar variáveis não-atomic para estado"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar com soluções tradicionais de locks",
                                  "subSteps": [
                                    "Implemente um spinlock tradicional usando atomic_flag ou busy-wait simples.",
                                    "Implemente um mutex padrão (std::mutex) para comparação.",
                                    "Meça overhead: tempo de aquisição em cenários sem contenda e com contenda moderada.",
                                    "Discuta trade-offs: bloqueio vs. não-bloqueio, escalabilidade.",
                                    "Analise métricas como throughput e latência."
                                  ],
                                  "verification": "Gere gráficos comparativos de performance usando ferramentas como perf ou Google Benchmark.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Biblioteca Google Benchmark",
                                    "std::mutex e std::atomic_flag docs",
                                    "Ferramenta de profiling como perf (Linux)"
                                  ],
                                  "tips": "Teste com cargas balanceadas: 90% sem contenda para destacar otimismo do CAS.",
                                  "learningObjective": "Comparar empiricamente CAS locks com locks bloqueantes, identificando cenários ideais.",
                                  "commonMistakes": [
                                    "Testar apenas em alta contenda, onde CAS perde",
                                    "Ignorar overhead de context switch em mutex"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar otimismo em cenários de baixa contenda e otimizar",
                                  "subSteps": [
                                    "Simule cenários reais: workloads com 1-10% de contenda.",
                                    "Otimize com backoff exponencial em falhas de CAS.",
                                    "Discuta linearizabilidade e progress guarantee (lockout-freedom).",
                                    "Teste escalabilidade com 2-16 threads.",
                                    "Documente lições aprendidas e limitações (ABA problem)."
                                  ],
                                  "verification": "Execute benchmarks mostrando superioridade do CAS em baixa contenda; escreva relatório de 200 palavras.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código das implementações anteriores",
                                    "Ferramentas de benchmark multi-thread",
                                    "Artigo sobre ABA problem e soluções (hazard pointers)"
                                  ],
                                  "tips": "Monitore cache lines para evitar falsos compartilhamentos em variáveis atomic.",
                                  "learningObjective": "Avaliar e otimizar CAS locks para aplicações reais de baixa contenda.",
                                  "commonMistakes": [
                                    "Aplicar CAS em alta contenda sem otimizações",
                                    "Não detectar ABA problem em testes longos"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um contador thread-safe para rastrear acessos a um site simulado: 10 threads incrementam o contador 1.000.000 vezes cada, usando CAS lock vs. mutex. Meça tempo total e verifique exatidão final.",
                              "finalVerifications": [
                                "Implementação do CAS lock compila e executa sem deadlocks ou race conditions.",
                                "Benchmarks mostram ganho de performance em baixa contenda (>20% vs. mutex).",
                                "Explicação escrita correta sobre otimismo do CAS.",
                                "Identificação de pelo menos 2 limitações (ex: ABA, alta contenda).",
                                "Código inclui retry loops e yield para eficiência.",
                                "Testes com múltiplas threads (4+) confirmam corretude."
                              ],
                              "assessmentCriteria": [
                                "Correção funcional: ausência de erros de concorrência (100%).",
                                "Eficiência: superioridade em baixa contenda comprovada por métricas.",
                                "Qualidade de código: legível, comentado, com handling de edge cases.",
                                "Análise comparativa: discussão profunda de trade-offs.",
                                "Otimização: inclusão de backoff ou yield.",
                                "Documentação: relatório com gráficos e conclusões."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Primitivas de hardware (LL/SC, TSO).",
                                "Algoritmos e Estruturas de Dados: Estruturas não-bloqueantes (queues, stacks).",
                                "Sistemas Operacionais: Sincronização de kernel e user-space.",
                                "Desempenho e Otimização: Profiling e escalabilidade.",
                                "Matemática Discreta: Propriedades de atomicidade e linearizabilidade."
                              ],
                              "realWorldApplication": "CAS locks são fundamentais em bibliotecas de concorrência como Java's AtomicReference (usado em Hazelcast, Disruptor), otimizando performance em microsserviços, caches distribuídos (Redis) e engines de jogos multiplayer com baixa latência."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.3.1"
                            ]
                          },
                          {
                            "id": "10.1.1.6.3.3",
                            "name": "Implementar mutex com pthreads ou OpenMP",
                            "description": "Criar programas paralelos usando pthread_mutex_t ou #pragma omp critical em OpenMP para proteger seções críticas em memória compartilhada, medindo overhead.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente e criar programa base sem sincronização",
                                  "subSteps": [
                                    "Instale bibliotecas pthreads e OpenMP (ex: gcc com -fopenmp).",
                                    "Crie um programa simples com threads paralelas acessando uma variável compartilhada (ex: contador incrementado por múltiplas threads).",
                                    "Compile e execute sem sincronização para observar condição de corrida (race condition).",
                                    "Registre o output inconsistente múltiplas vezes para confirmar o problema.",
                                    "Meça tempo de execução base com gettimeofday() ou similar."
                                  ],
                                  "verification": "Programa compila e executa mostrando valores inconsistentes no contador (ex: menos que threads * iterações).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte a pthreads e OpenMP",
                                    "Editor de código (VS Code, Vim)",
                                    "Terminal Linux/Mac"
                                  ],
                                  "tips": "Use um número alto de iterações (ex: 100000) e threads (ex: 4) para evidenciar race conditions rapidamente.",
                                  "learningObjective": "Entender o impacto de acessos concorrentes não sincronizados em memória compartilhada.",
                                  "commonMistakes": [
                                    "Esquecer de linkar -lpthread",
                                    "Usar poucos loops/threads, mascarando o problema",
                                    "Ignorar warnings do compilador"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar mutex com pthreads",
                                  "subSteps": [
                                    "Inclua <pthread.h> e declare pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;",
                                    "Inicialize threads com pthread_create() para incrementarem o contador.",
                                    "Proteja a seção crítica com pthread_mutex_lock(&mutex); ... pthread_mutex_unlock(&mutex);",
                                    "Compile com gcc -o prog prog.c -lpthread e execute para verificar output correto.",
                                    "Meça tempo de execução com sincronização usando clock_gettime()."
                                  ],
                                  "verification": "Contador atinge valor exato esperado (threads * iterações) em todas as execuções.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código base do Step 1",
                                    "Documentação pthread_mutex (man 3 pthread_mutex_lock)"
                                  ],
                                  "tips": "Sempre destrua o mutex com pthread_mutex_destroy() no final para evitar leaks.",
                                  "learningObjective": "Dominar primitivas de mutex em pthreads para exclusão mútua.",
                                  "commonMistakes": [
                                    "Esquecer unlock() causando deadlock",
                                    "Lock/unlock fora da seção crítica desnecessariamente",
                                    "Não inicializar mutex corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar seção crítica com OpenMP",
                                  "subSteps": [
                                    "Compile com -fopenmp e use #pragma omp parallel num_threads(4).",
                                    "Declare variável compartilhada: int counter = 0;",
                                    "Proteja incremento com #pragma omp critical { counter++; }",
                                    "Execute e verifique output correto do contador.",
                                    "Meça tempo comparando com versão pthread."
                                  ],
                                  "verification": "Output idêntico ao pthread: contador correto, sem race conditions.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código pthread adaptado",
                                    "Documentação OpenMP critical (openmp.org)"
                                  ],
                                  "tips": "Use omp_get_thread_num() para debug de threads específicas.",
                                  "learningObjective": "Aplicar diretivas OpenMP para sincronização em loops paralelos.",
                                  "commonMistakes": [
                                    "Esquecer -fopenmp no compile",
                                    "Usar critical em operações desnecessárias, impactando performance",
                                    "Nomear critical sections iguais causando serialização excessiva"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Medir overhead e comparar abordagens",
                                  "subSteps": [
                                    "Implemente função de timing precisa com clock_gettime(CLOCK_MONOTONIC).",
                                    "Execute cada versão (sem sync, pthread, OpenMP) 100 vezes e calcule média/desvio.",
                                    "Compare overhead: (tempo_sync - tempo_base) / tempo_base * 100%.",
                                    "Gere gráfico simples com gnuplot ou printf para visualizar.",
                                    "Otimize se overhead > 20% ajustando granularidade da seção crítica."
                                  ],
                                  "verification": "Relatório com tempos médios e overhead < 50% para ambas sincronizações.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Códigos anteriores",
                                    "Gnuplot ou Excel para gráficos"
                                  ],
                                  "tips": "Aqueça o sistema com execuções iniciais descartadas para evitar cache effects.",
                                  "learningObjective": "Quantificar custo de sincronização e trade-offs em programação paralela.",
                                  "commonMistakes": [
                                    "Medir apenas uma execução (ruído)",
                                    "Ignorar overhead de thread creation",
                                    "Comparar apples-to-oranges (diferentes #threads)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar robustez e depurar",
                                  "subSteps": [
                                    "Teste com mais threads (8-16) e iterações para escalabilidade.",
                                    "Introduza deadlock artificial (ex: nested locks) e corrija.",
                                    "Use Valgrind --tool=helgrind para detectar erros de concorrência.",
                                    "Documente diferenças pthread vs OpenMP em overhead e usabilidade.",
                                    "Escreva relatório final com código fonte e métricas."
                                  ],
                                  "verification": "Valgrind limpo, sem deadlocks ou races; relatório completo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Valgrind instalado",
                                    "Template de relatório Markdown"
                                  ],
                                  "tips": "Helgrind é lento; use em execuções curtas primeiro.",
                                  "learningObjective": "Garantir corretude e performance em cenários reais de paralelismo.",
                                  "commonMistakes": [
                                    "Não testar escalabilidade",
                                    "Confiar só em outputs visuais",
                                    "Ignorar memory barriers implícitas"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa de contador compartilhado: 4 threads executam 100.000 incrementos cada. Sem sync: ~200.000 final. Com mutex/critical: exatamente 400.000. Overhead pthread ~15%, OpenMP ~10%.",
                              "finalVerifications": [
                                "Contador atinge valor exato em 100 execuções consecutivas.",
                                "Tempos medidos com <10% variação entre runs.",
                                "Overhead de sincronização quantificado e <50%.",
                                "Valgrind/Helgrind reporta zero erros de thread.",
                                "Código compila e roda em ambas APIs sem warnings.",
                                "Gráfico compara performance das três versões."
                              ],
                              "assessmentCriteria": [
                                "Corretude: Ausência total de race conditions (100%).",
                                "Eficiência: Overhead medido e otimizado adequadamente.",
                                "Código limpo: Comentado, modular e segue best practices.",
                                "Análise: Relatório explica trade-offs pthread vs OpenMP.",
                                "Testes: Cobertura com múltiplos cenários e ferramentas.",
                                "Escalabilidade: Funciona com 2-16 threads."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Primitivas de sincronização kernel-level.",
                                "Algoritmos: Análise de complexidade em tempo paralelo (Amdahl's Law).",
                                "Engenharia de Software: Thread-safety em design de APIs.",
                                "Matemática: Estatística para análise de performance (média, desvio).",
                                "Redes: Similar a locks em protocolos distribuídos (ex: Raft)."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded (ex: Nginx com worker threads protegendo logs compartilhados), bancos de dados (MySQL InnoDB mutex para transações), ou simulações científicas (OpenMP em HPC para atualizar grids compartilhados), evitando corrupção de dados e garantindo consistência."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.2.2"
                            ]
                          },
                          {
                            "id": "10.1.1.6.3.4",
                            "name": "Avaliar desempenho de mecanismos de exclusão mútua",
                            "description": "Comparar tempos de execução e escalabilidade de soluções de software, hardware e alto nível em cenários de alta e baixa contenda, usando métricas como speedup.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os mecanismos de exclusão mútua e suas características",
                                  "subSteps": [
                                    "Estudar primitivas de hardware: Test-and-Set (TAS), Compare-and-Swap (CAS) e suas implementações em assembly.",
                                    "Analisar algoritmos de software: Peterson, Dekker e Lamport Bakery, focando em busy-waiting e fairness.",
                                    "Explorar abstrações de alto nível: semáforos, monitores e mutexes em bibliotecas como pthreads ou Java.",
                                    "Identificar impactos em cenários de baixa contenda (poucas threads competindo) vs. alta contenda (muitas threads)."
                                  ],
                                  "verification": "Criar uma tabela comparativa resumindo overhead, escalabilidade e comportamento em contenda para cada mecanismo.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Modern Operating Systems' de Tanenbaum (cap. exclusão mútua)",
                                    "Documentação pthread_mutex e atomic operations em C++",
                                    "Códigos de exemplo no GitHub para Peterson e TAS"
                                  ],
                                  "tips": "Use diagramas de estado para visualizar busy-waiting em alta contenda.",
                                  "learningObjective": "Diferenciar mecanismos por tipo e prever comportamentos qualitativos em diferentes contendas.",
                                  "commonMistakes": [
                                    "Confundir busy-waiting com blocking (spinlock vs sleep)",
                                    "Ignorar cache coherence em hardware primitives"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente de benchmark e implementações",
                                  "subSteps": [
                                    "Instalar ferramentas: GCC com suporte OpenMP ou pthreads, perf para profiling.",
                                    "Implementar ou adaptar códigos de teste: contador compartilhado com seções críticas usando TAS, Peterson, semáforo e std::mutex.",
                                    "Definir workloads: baixa contenda (2-4 threads, 80% compute local), alta contenda (16-64 threads, 20% compute local).",
                                    "Configurar métricas: tempo de execução total, throughput (ops/seg), latência de aquisição."
                                  ],
                                  "verification": "Executar teste unitário com 1 thread (sem contenda) e confirmar tempos próximos de zero overhead.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ambiente Linux com GCC 11+",
                                    "Códigos base de benchmarks como lock-contention no GitHub",
                                    "Ferramentas: time, perf, gprof"
                                  ],
                                  "tips": "Use barreiras para sincronizar start e isolando apenas a seção crítica.",
                                  "learningObjective": "Preparar um setup reproduzível para medições precisas de desempenho.",
                                  "commonMistakes": [
                                    "Não isolar variáveis como NUMA ou cache warmup",
                                    "Usar threads fixas sem variar carga"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar experimentos em cenários de contenda",
                                  "subSteps": [
                                    "Rodar benchmarks em baixa contenda: variar 2-8 threads, 10 repetições, registrar tempos médios.",
                                    "Executar em alta contenda: 16-64 threads, workloads com alta frequência de lock/unlock.",
                                    "Medir múltiplas runs para calcular speedup: S(p) = T(1)/T(p), onde T é tempo serial/paralelo.",
                                    "Coleta de dados adicionais: contadores de spinloops (via perf) e taxa de falhas CAS."
                                  ],
                                  "verification": "Gerar planilha ou CSV com dados brutos: colunas para mecanismo, threads, tempo médio, desvio padrão, speedup.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Scripts bash para automação de runs",
                                    "Google Sheets ou Python Pandas para coleta inicial",
                                    "Máquina multi-core (8+ cores recomendada)"
                                  ],
                                  "tips": "Aqueça caches com 1000 iterações antes de medir para resultados estáveis.",
                                  "learningObjective": "Coletar dados empíricos comparáveis entre mecanismos.",
                                  "commonMistakes": [
                                    "Runs insuficientes levando a variância alta",
                                    "Medir tempo wall-clock sem considerar overhead de criação de threads"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar resultados e calcular métricas de desempenho",
                                  "subSteps": [
                                    "Plotar gráficos: tempo vs. threads, speedup vs. threads para cada mecanismo (use Matplotlib ou Excel).",
                                    "Comparar escalabilidade: identificar ponto de thrashing em alta contenda (ex: spinlocks degradam).",
                                    "Calcular eficiência: E(p) = S(p)/p e identificar vencedores por cenário (hardware em baixa, software em alta).",
                                    "Documentar insights: ex. CAS melhor que TAS por evitar invalidação de cache."
                                  ],
                                  "verification": "Produzir relatório com 3 gráficos e tabela de ranking por métrica/scenario.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com Matplotlib/Seaborn ou GNUPlot",
                                    "Jupyter Notebook para análise interativa"
                                  ],
                                  "tips": "Normalize tempos pela baseline serial para comparações justas.",
                                  "learningObjective": "Interpretar dados quantitativamente e qualitativamente para recomendações.",
                                  "commonMistakes": [
                                    "Escala log nos gráficos sem justificar",
                                    "Ignorar confiança intervals em médias"
                                  ]
                                }
                              ],
                              "practicalExample": "Simular um sistema de bilheteria online onde múltiplas threads (clientes) competem por assentos limitados usando um contador compartilhado. Implemente com TAS (hardware), Peterson (software) e mutex (alto nível), meça tempo para 1 milhão de tentativas de reserva em 32 threads (alta contenda) e compare speedup.",
                              "finalVerifications": [
                                "Gráficos mostram speedup >1 em baixa contenda para todos, mas degradação em alta para spinlocks.",
                                "Tabela compara throughput: ex. semáforo 2x melhor que TAS em 64 threads.",
                                "Relatório identifica CAS como ótimo para workloads mistos.",
                                "Cálculos de speedup coincidem com fórmulas teóricas dentro de 10% de erro.",
                                "Análise cita impactos reais como cache line bouncing."
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições: desvio <5% em 10 runs.",
                                "Qualidade dos gráficos: eixos labelados, legendas claras, escalas adequadas.",
                                "Interpretação correta: liga resultados a conceitos teóricos (ex. convoy effect).",
                                "Completude: cobre todos cenários e mecanismos especificados.",
                                "Originalidade: insights além de cópia de resultados conhecidos."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: cache coherence e atomic instructions.",
                                "Sistemas Operacionais: scheduling e kernel locks.",
                                "Banco de Dados: locking em transações concorrentes.",
                                "Engenharia de Software: design de APIs thread-safe.",
                                "Análise de Desempenho: modelagem de filas e Little's Law."
                              ],
                              "realWorldApplication": "Em servidores de e-commerce como Amazon, onde milhares de requisições competem por inventário compartilhado; escolher mutex híbrido (spin+mcs) otimiza latência sob carga, reduzindo tempo de resposta em 30% durante picos de Black Friday."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.1.6.3.3"
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.2",
                "name": "Modelos de Programação Paralela para Memória Distribuída",
                "description": "Foca na troca de mensagens como abordagem principal para programação em sistemas com memória distribuída.",
                "totalSkills": 50,
                "atomicTopics": [
                  {
                    "id": "10.1.2.1",
                    "name": "Paradigma de Troca de Mensagens",
                    "description": "Abordagem principal para comunicação entre processos em sistemas de memória distribuída, utilizando envio e recebimento de mensagens.",
                    "individualConcepts": [
                      {
                        "id": "10.1.2.1.1",
                        "name": "Fundamentos do Paradigma de Troca de Mensagens",
                        "description": "Conceitos básicos sobre o paradigma de troca de mensagens como abordagem principal para comunicação em sistemas de memória distribuída, contrastando com modelos de memória compartilhada e relacionando com a taxonomia de Flynn.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.1.1.1",
                            "name": "Identificar cenários de aplicação da troca de mensagens",
                            "description": "Reconhecer situações em que o paradigma de troca de mensagens é apropriado, como em clusters de computadores ou sistemas distribuídos sem memória compartilhada, diferenciando de modelos de domínio compartilhado.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos dos Modelos de Programação Paralela",
                                  "subSteps": [
                                    "Estude a definição de paradigma de troca de mensagens (message-passing) e suas premissas básicas, como ausência de memória compartilhada.",
                                    "Revise o modelo de domínio compartilhado (shared-memory), destacando comunicação via variáveis globais ou locks.",
                                    "Compare as diferenças chave: independência de processos vs. sincronização explícita.",
                                    "Anote exemplos iniciais de hardware que suportam cada modelo (ex.: clusters vs. multicore).",
                                    "Crie um diagrama simples comparando os dois modelos."
                                  ],
                                  "verification": "Diagrama comparativo completo com pelo menos 3 diferenças identificadas e compartilhado com um colega para feedback.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Slides ou notas sobre modelos paralelos",
                                    "Papel e caneta ou ferramenta de diagrama como Draw.io"
                                  ],
                                  "tips": "Use tabelas para organizar diferenças; foque em trade-offs de escalabilidade.",
                                  "learningObjective": "Compreender as bases conceituais para diferenciar os paradigmas.",
                                  "commonMistakes": [
                                    "Confundir troca de mensagens com RPC; ignorar overhead de rede na troca de mensagens."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Características de Cenários de Memória Distribuída",
                                  "subSteps": [
                                    "Liste atributos de sistemas distribuídos: nós independentes, comunicação via rede, falhas parciais possíveis.",
                                    "Analise cenários como clusters de computadores, grids computacionais e computação em nuvem.",
                                    "Identifique quando memória compartilhada é impraticável: latência alta de rede, escalabilidade horizontal.",
                                    "Pesquise estatísticas reais (ex.: número de nós em supercomputadores).",
                                    "Classifique 5 cenários hipotéticos como 'distribuídos' ou não."
                                  ],
                                  "verification": "Lista de pelo menos 5 cenários classificados corretamente, com justificativa para cada.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Artigos sobre MPI e clusters (ex.: Wikipedia MPI)",
                                    "Navegador web para pesquisa rápida"
                                  ],
                                  "tips": "Pense em custo: memória compartilhada não escala economicamente além de poucos nós.",
                                  "learningObjective": "Reconhecer traços que tornam a troca de mensagens necessária.",
                                  "commonMistakes": [
                                    "Assumir que todos os sistemas multi-nós usam troca de mensagens; subestimar hibridizações."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diferenciar e Comparar com Modelos de Domínio Compartilhado",
                                  "subSteps": [
                                    "Crie uma matriz de decisão: colunas para cenários (cluster, multicore, nuvem); linhas para critérios (escalabilidade, latência, hardware).",
                                    "Aplique a matriz a 4 casos reais: supercomputador TOP500, app web em Kubernetes, app desktop multi-threaded.",
                                    "Simule trade-offs: calcule tempo de comunicação em rede vs. cache local.",
                                    "Discuta exceções: quando domínio compartilhado é usado em distribuídos (ex.: DSM).",
                                    "Refine a matriz com feedback autoavaliado."
                                  ],
                                  "verification": "Matriz de decisão preenchida e justificada, com pelo menos 80% de acurácia em classificações.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Lista TOP500 supercomputadores"
                                  ],
                                  "tips": "Priorize escalabilidade > 64 nós como threshold para distribuído.",
                                  "learningObjective": "Desenvolver ferramenta mental para diferenciação rápida.",
                                  "commonMistakes": [
                                    "Ignorar latência de rede como fator decisivo; confundir threads com processos distribuídos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar Identificação em Cenários Hipotéticos e Reais",
                                  "subSteps": [
                                    "Resolva 6 exercícios: descreva cenários e escolha paradigma correto com razões.",
                                    "Analise código fonte simples de MPI vs. OpenMP para validar escolhas.",
                                    "Crie seu próprio cenário (ex.: app de ML distribuído) e classifique.",
                                    "Debata com parceiro: defenda escolhas em 2 cenários controversos.",
                                    "Registre aprendizados em um journal de decisões."
                                  ],
                                  "verification": "Journal com 6 exercícios resolvidos, taxa de acerto >90%, e 1 cenário original.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Exercícios impressos ou online",
                                    "Código exemplo MPI/OpenMP do GitHub"
                                  ],
                                  "tips": "Use 'por quê não o outro paradigma?' para fortalecer justificativas.",
                                  "learningObjective": "Aplicar conhecimento de forma autônoma e confiante.",
                                  "commonMistakes": [
                                    "Escolhas baseadas em buzzwords; não considerar restrições de hardware/falhas."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 100 nós para simulação climática, onde cada nó processa dados locais de satélites, use troca de mensagens (MPI_Send/Recv) para sincronizar resultados parciais, evitando memória compartilhada devido à latência de rede de 100μs entre nós.",
                              "finalVerifications": [
                                "Lista 4 cenários reais onde troca de mensagens é essencial (ex.: Hadoop, MPI em HPC).",
                                "Explica corretamente 3 diferenças chave vs. domínio compartilhado em uma conversa de 2 minutos.",
                                "Classifica 5 cenários mistos com >90% acurácia usando matriz de decisão.",
                                "Identifica limitações da troca de mensagens em 2 casos de uso inadequados.",
                                "Cria um diagrama de fluxo para decidir paradigma em novos projetos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de cenários distribuídos (sem falsos positivos).",
                                "Profundidade de justificativas, citando pelo menos 2 fatores (latência, escalabilidade).",
                                "Capacidade de diferenciação clara de modelos alternativos.",
                                "Criatividade em cenários originais com aplicação realista.",
                                "Consistência em verificações e exercícios práticos."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação (TCP/IP, sockets).",
                                "Sistemas Operacionais: Gerenciamento de processos distribuídos e IPC.",
                                "Engenharia de Software: Arquitetura de microsserviços e escalabilidade.",
                                "Banco de Dados: Sistemas distribuídos como Cassandra (gossip protocol)."
                              ],
                              "realWorldApplication": "Em computação de alto desempenho (HPC), como simulações em supercomputadores (ex.: Frontier usando MPI); em big data com Apache Spark para processamento distribuído; ou em IoT para coordenação de sensores sem memória central."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.1.1.2",
                            "name": "Comparar com outros modelos de programação paralela",
                            "description": "Comparar o paradigma de troca de mensagens com decomposição de domínio e exclusão mútua em memória compartilhada, destacando vantagens em ambientes distribuídos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos do Paradigma de Troca de Mensagens",
                                  "subSteps": [
                                    "Estude os conceitos básicos: processos independentes, comunicação assíncrona/síncrona via send/receive.",
                                    "Identifique primitivas chave como MPI_Send, MPI_Recv em MPI.",
                                    "Analise ausência de memória compartilhada e foco em topologias distribuídas.",
                                    "Liste exemplos de aplicações: clusters de computadores.",
                                    "Registre vantagens iniciais: escalabilidade em redes heterogêneas."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando send/receive e confirme com auto-perguntas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação MPI oficial (mpi-forum.org)",
                                    "Capítulo 4 de 'Introduction to Parallel Computing' de Grama et al."
                                  ],
                                  "tips": "Use diagramas para visualizar fluxos de mensagens entre processos.",
                                  "learningObjective": "Compreender os pilares do message passing e suas primitivas básicas.",
                                  "commonMistakes": "Confundir com chamadas de função síncronas em vez de comunicação bloqueante/não-bloqueante."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Decomposição de Domínio em Memória Compartilhada",
                                  "subSteps": [
                                    "Defina decomposição de domínio: divisão do espaço de dados em domínios independentes.",
                                    "Estude técnicas: decomposição geométrica para grids (ex: imagens ou simulações físicas).",
                                    "Analise alocação de tarefas a threads/processos que acessam memória compartilhada.",
                                    "Examine overheads: migração de dados e balanceamento de carga.",
                                    "Compare com master-slave para domínios irregulares."
                                  ],
                                  "verification": "Desenhe um diagrama de decomposição de uma matriz 2D em 4 domínios e liste tarefas por thread.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Capítulo 3 de 'Parallel Programming in C with MPI and OpenMP' de Quinn",
                                    "Tutoriais OpenMP (openmp.org)"
                                  ],
                                  "tips": "Comece com exemplos simples como soma de matriz para visualizar partições.",
                                  "learningObjective": "Dominar como dados são particionados em modelos de memória compartilhada.",
                                  "commonMistakes": "Ignorar granularidade fina vs. grossa, levando a overheads desnecessários."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Exclusão Mútua em Memória Compartilhada",
                                  "subSteps": [
                                    "Explique exclusão mútua: mutex, semáforos para regiões críticas.",
                                    "Estude primitivas: pthread_mutex_lock/unlock em POSIX threads.",
                                    "Discuta problemas: deadlocks, starvation e overhead de contenção.",
                                    "Compare com barreiras e condições para sincronização.",
                                    "Liste cenários onde falha: alta contenção em locks globais."
                                  ],
                                  "verification": "Implemente um código simples com mutex para contador compartilhado e teste com múltiplas threads.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Documentação Pthreads (man7.org/linux/man-pages)",
                                    "Capítulo 5 de 'Programming with POSIX Threads' de Butenhof"
                                  ],
                                  "tips": "Teste com ferramentas como Valgrind para detectar race conditions.",
                                  "learningObjective": "Entender mecanismos de sincronização para acesso seguro à memória compartilhada.",
                                  "commonMistakes": "Esquecer de unlock mutex, causando deadlocks permanentes."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar os Modelos e Destacar Vantagens em Ambientes Distribuídos",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: comunicação (mensagens vs. locks), escalabilidade, tolerância a falhas.",
                                    "Analise diferenças: message passing portável para distribuído; shared memory limitado a multiprocessadores.",
                                    "Destaque vantagens de message passing: sem overhead de cache coherence, melhor em WANs.",
                                    "Discuta desvantagens: latência de mensagens vs. custo baixo de locks locais.",
                                    "Sintetize cenários ideais: message passing para clusters geodistribuídos."
                                  ],
                                  "verification": "Preencha uma tabela de comparação com pelo menos 5 critérios e discuta com um par.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Artigo 'MPI vs OpenMP' de Chapman et al.",
                                    "Slides de curso de Programação Paralela (ex: MIT OpenCourseWare)"
                                  ],
                                  "tips": "Use métricas quantitativas como speedup e eficiência para comparações.",
                                  "learningObjective": "Capacitar comparações sistemáticas entre message passing e shared memory.",
                                  "commonMistakes": "Superestimar portabilidade de shared memory ignorando limites de hardware."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar Comparação em um Caso Prático",
                                  "subSteps": [
                                    "Escolha um problema: multiplicação de matrizes distribuída.",
                                    "Simule message passing (MPI) vs. shared memory (OpenMP com mutex/domínio).",
                                    "Meça performance em ambiente simulado ou real.",
                                    "Conclua vantagens em distribuído: message passing escala melhor.",
                                    "Documente lições aprendidas em relatório curto."
                                  ],
                                  "verification": "Execute benchmarks e gere gráfico de speedup vs. número de nós.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Ambiente com MPICH ou OpenMPI instalado",
                                    "Código de exemplo de matrix multiply paralelo"
                                  ],
                                  "tips": "Use máquinas virtuais para simular cluster distribuído.",
                                  "learningObjective": "Aplicar conhecimentos comparativos para tomada de decisão arquitetural.",
                                  "commonMistakes": "Não considerar latência de rede, invalidando comparações distribuídas."
                                }
                              ],
                              "practicalExample": "Em um sistema de processamento de big data para análise de imagens satélites em um cluster de 10 nós remotos: use message passing (MPI) para trocar blocos de imagem entre nós sem compartilhamento de memória, evitando overheads de sincronização global que paralisariam threads em shared memory.",
                              "finalVerifications": [
                                "Pode listar 4 diferenças chave entre message passing e shared memory?",
                                "Explica por que message passing é superior em ambientes distribuídos?",
                                "Identifica 3 cenários onde shared memory falha em escala distribuída?",
                                "Cria uma tabela comparativa precisa?",
                                "Discute trade-offs de latência e overhead corretamente?",
                                "Aplica conceitos a um exemplo real?"
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas de primitivas (90%+ acerto).",
                                "Profundidade comparativa: análise de pelo menos 5 critérios com exemplos.",
                                "Foco em distribuído: destaque claro de vantagens de message passing.",
                                "Uso de evidências: inclusão de diagramas ou benchmarks.",
                                "Clareza de expressão: tabela ou relatório bem estruturado.",
                                "Originalidade: insights além de cópia de materiais."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: protocolos de comunicação como TCP/IP subjacentes a MPI.",
                                "Sistemas Operacionais: conceitos de processos, threads e IPC.",
                                "Engenharia de Software: design de APIs paralelas e padrões arquiteturais.",
                                "Ciência de Dados: paralelização em frameworks como Spark (message passing).",
                                "Computação em Nuvem: orquestração em Kubernetes com pods distribuídos."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, message passing (MPI) é usado para simulações climáticas distribuídas globalmente, superando shared memory em eficiência para milhares de nós heterogêneos, como no modelo CESM para previsão do tempo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.1.1.3",
                            "name": "Relacionar com taxonomia de Flynn e modelos de memória",
                            "description": "Explicar como o paradigma se enquadra em arquiteturas MIMD com memória distribuída, usando a taxonomia de Flynn para contextualizar.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude as quatro categorias principais: SISD, SIMD, MISD e MIMD, definindo cada uma com base em instruções e dados.",
                                    "Identifique exemplos clássicos para cada categoria, como processadores von Neumann para SISD e GPUs para SIMD.",
                                    "Analise como MIMD permite execução independente de múltiplos processadores com instruções e dados distintos.",
                                    "Crie um diagrama simples comparando as categorias em termos de paralelismo de instrução e dados.",
                                    "Memorize as características chave de MIMD: flexibilidade para programação paralela heterogênea."
                                  ],
                                  "verification": "Desenhe e explique um diagrama da taxonomia de Flynn corretamente, identificando MIMD como relevante para memória distribuída.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de aula sobre taxonomia de Flynn, diagrama interativo online (ex: Wikipedia ou Khan Academy), papel e caneta para esboços.",
                                  "tips": "Use mnemônicos como 'Single Instruction, Multiple Data' para SIMD para facilitar a memorização.",
                                  "learningObjective": "Compreender as categorias da taxonomia de Flynn e posicionar MIMD como base para arquiteturas paralelas avançadas.",
                                  "commonMistakes": "Confundir SIMD (vetorizado) com MIMD (independente); sempre diferencie pelo controle de instruções."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Modelos de Memória em Sistemas Paralelos",
                                  "subSteps": [
                                    "Defina memória compartilhada (UMD - Uniform Memory Access) versus memória distribuída (NUMA ou clusters).",
                                    "Compare uniformidade de acesso: compartilhada permite acesso global rápido, distribuída requer comunicação explícita.",
                                    "Discuta desafios da memória distribuída: latência de comunicação e falta de cache coerência automática.",
                                    "Examine arquiteturas MIMD com memória distribuída, como clusters de nós independentes.",
                                    "Liste vantagens da distribuída: escalabilidade para milhares de processadores."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as diferenças entre memória compartilhada e distribuída, com exemplos de MIMD.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Artigos sobre modelos de memória (ex: slides de Tanenbaum ou Patterson & Hennessy), ferramenta de desenho como Draw.io.",
                                  "tips": "Pense em memória compartilhada como 'uma grande casa compartilhada' vs. distribuída como 'várias casas separadas comunicando por telefone'.",
                                  "learningObjective": "Diferenciar modelos de memória e reconhecer memória distribuída como ideal para MIMD escalável.",
                                  "commonMistakes": "Assumir que MIMD só usa compartilhada; lembre que distribuída é comum em supercomputadores MIMD."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar o Paradigma de Troca de Mensagens",
                                  "subSteps": [
                                    "Descreva o paradigma: processos independentes em nós distintos trocam dados via mensagens explícitas (send/receive).",
                                    "Compare com memória compartilhada: sem acesso direto à memória alheia, evitando problemas de coerência.",
                                    "Estude primitivas básicas: bloqueante vs. não-bloqueante, broadcast, scatter/gather.",
                                    "Relacione com bibliotecas como MPI: projetada para MIMD/distribuída.",
                                    "Simule um fluxo simples de troca de mensagens entre dois processos."
                                  ],
                                  "verification": "Escreva um pseudocódigo de send/receive entre dois nós e explique sua necessidade em memória distribuída.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Documentação MPI básica, simulador online como MPI Playground, pseudocódigo editor.",
                                  "tips": "Visualize mensagens como 'cartas enviadas por correio' em vez de 'gritar pela janela' (compartilhada).",
                                  "learningObjective": "Entender o paradigma de mensagens como solução para comunicação em MIMD com memória distribuída.",
                                  "commonMistakes": "Ignorar overhead de comunicação; sempre considere latência em cenários reais."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar Paradigma de Mensagens com Flynn e Memória",
                                  "subSteps": [
                                    "Posicione: Troca de mensagens é nativa de MIMD (múltiplas instruções/dados independentes) com memória distribuída.",
                                    "Contextualize: Flynn classifica MIMD; mensagens resolvem ausência de compartilhamento.",
                                    "Compare com outros: SIMD usa sincronia implícita, MIMD/mensagens permite assincronia.",
                                    "Crie um mapa conceitual ligando Flynn > MIMD > Distribuída > Mensagens.",
                                    "Discuta limitações: não para todos MIMD (ex: OpenMP é compartilhada)."
                                  ],
                                  "verification": "Produza um ensaio curto (200 palavras) ou mapa explicando o encaixe, com referências corretas.",
                                  "estimatedTime": "55 minutos",
                                  "materials": "Ferramenta de mindmap (ex: MindMeister), referências acadêmicas sobre Flynn e MPI.",
                                  "tips": "Use setas no mapa: Flynn (classificação) → MIMD → Distribuída → Mensagens (comunicação).",
                                  "learningObjective": "Integrar conceitos para explicar por que mensagens se enquadram perfeitamente em MIMD/distribuída.",
                                  "commonMistakes": "Generalizar MIMD como só mensagens; esclareça que depende do modelo de memória."
                                }
                              ],
                              "practicalExample": "Em um cluster de computação usando MPI (Message Passing Interface), 4 nós MIMD com memória distribuída calculam partes de uma matriz: cada nó processa sua porção local e usa MPI_Send/MPI_Recv para trocar bordas, exemplificando MIMD (instruções independentes) e mensagens para superar distribuição de memória.",
                              "finalVerifications": [
                                "Classifique corretamente o paradigma de mensagens como MIMD com memória distribuída na taxonomia de Flynn.",
                                "Explique sem erros as diferenças entre memória compartilhada e distribuída em contextos MIMD.",
                                "Descreva primitivas de mensagens e sua relação com independência de processadores MIMD.",
                                "Crie um diagrama preciso ligando Flynn, MIMD, distribuída e mensagens.",
                                "Identifique pelo menos 3 aplicações reais de MIMD/mensagens (ex: supercomputadores).",
                                "Responda a perguntas hipotéticas sobre adaptações para outros quadrantes de Flynn."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: Correta identificação de MIMD e memória distribuída (30%).",
                                "Profundidade de relação: Explicação clara do encaixe do paradigma (25%).",
                                "Uso de exemplos: Inclusão de casos práticos como MPI (20%).",
                                "Clareza e estrutura: Organização lógica com diagramas ou mapas (15%).",
                                "Originalidade: Insights sobre limitações ou extensões (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação semelhantes a TCP/IP em mensagens.",
                                "Sistemas Operacionais: Gerenciamento de processos distribuídos e escalonamento.",
                                "Algoritmos e Estruturas de Dados: Paralelização de algoritmos em grafos via mensagens.",
                                "Engenharia de Software: Padrões de design para sistemas distribuídos (ex: microservices)."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500 (ex: Frontier), arquiteturas MIMD com memória distribuída usam MPI para simulações climáticas ou folding de proteínas, onde milhares de nós trocam mensagens para coordenar computações massivamente paralelas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.1.2",
                        "name": "Operações Básicas de Envio e Recebimento",
                        "description": "Detalhes sobre as operações fundamentais de envio (send) e recebimento (receive) de mensagens entre processos em memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.1.2.1",
                            "name": "Descrever operação de envio de mensagens",
                            "description": "Explicar os parâmetros envolvidos no envio de mensagens (dados, destino, tag), incluindo exemplos pseudocódigo em linguagens como MPI.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais da operação de envio de mensagens",
                                  "subSteps": [
                                    "Estude o paradigma de troca de mensagens em memória distribuída.",
                                    "Identifique o papel do envio como operação síncrona ou assíncrona em MPI.",
                                    "Diferencie envio ponto-a-ponto de coletivo.",
                                    "Revise o modelo de comunicação em processos paralelos.",
                                    "Anote as responsabilidades do remetente e do receptor."
                                  ],
                                  "verification": "Resuma em 3 frases os conceitos chave e compare com recebimento.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Documentação oficial do MPI, slides sobre programação paralela.",
                                  "tips": "Use diagramas de fluxo para visualizar o processo de envio.",
                                  "learningObjective": "Entender o propósito e o fluxo básico da operação de envio.",
                                  "commonMistakes": "Confundir envio com cópia de memória compartilhada."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Descrever os parâmetros envolvidos no envio",
                                  "subSteps": [
                                    "Liste e defina 'dados' (buffer, count, datatype).",
                                    "Explique 'destino' (rank do processo receptor).",
                                    "Detalhe o 'tag' como identificador da mensagem.",
                                    "Mencione o comunicador (comm) como contexto de grupo.",
                                    "Discuta tamanhos e tipos compatíveis entre sender e receiver."
                                  ],
                                  "verification": "Crie uma tabela com parâmetros, tipos e exemplos de valores.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Referência MPI_Send, exemplos de código fonte.",
                                  "tips": "Associe cada parâmetro a um exemplo numérico simples.",
                                  "learningObjective": "Dominar a função e especificações de cada parâmetro.",
                                  "commonMistakes": "Ignorar o datatype ou usar tag inválido (negativo)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar a sintaxe da operação de envio em MPI",
                                  "subSteps": [
                                    "Memorize a assinatura: MPI_Send(buffer, count, datatype, dest, tag, comm).",
                                    "Identifique retornos de erro e códigos de status.",
                                    "Compare MPI_Send (bloqueante) com MPI_Isend (não-bloqueante).",
                                    "Estude o cabeçalho necessário (#include <mpi.h>).",
                                    "Pratique a inicialização MPI_Init() antes do envio."
                                  ],
                                  "verification": "Escreva a sintaxe completa de memória sem consultar referências.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Compilador MPI (mpicc), man page de MPI_Send.",
                                  "tips": "Teste sintaxe em um editor com realce de sintaxe.",
                                  "learningObjective": "Reproduzir corretamente a sintaxe e variações.",
                                  "commonMistakes": "Esquecer MPI_Finalize() ou não chamar MPI_Init()."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir e exemplificar pseudocódigo para envio de mensagens",
                                  "subSteps": [
                                    "Crie pseudocódigo para envio de array de inteiros.",
                                    "Inclua verificação de rank (if rank == 0 send to 1).",
                                    "Adicione exemplo com tag diferente para múltiplas mensagens.",
                                    "Simule cenário com 2 processos.",
                                    "Valide compatibilidade de parâmetros no exemplo."
                                  ],
                                  "verification": "Execute pseudocódigo mentalmente e identifique fluxos.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Editor de texto, exemplos de código MPI online.",
                                  "tips": "Use comentários no pseudocódigo para explicar cada linha.",
                                  "learningObjective": "Aplicar conhecimentos em exemplos acionáveis.",
                                  "commonMistakes": "Enviar para destino inválido (fora do comm size)."
                                }
                              ],
                              "practicalExample": "Pseudocódigo MPI para envio:\n#include <mpi.h>\nint main(int argc, char** argv) {\n  MPI_Init(&argc, &argv);\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  if (rank == 0) {\n    int data[10] = {1,2,3,4,5,6,7,8,9,10};\n    MPI_Send(data, 10, MPI_INT, 1, 42, MPI_COMM_WORLD);\n  }\n  MPI_Finalize();\n  return 0;\n}\nAqui, dados= data[10], count=10, datatype=MPI_INT, dest=1, tag=42, comm=MPI_COMM_WORLD.",
                              "finalVerifications": [
                                "Descreva corretamente todos os 6 parâmetros de MPI_Send.",
                                "Forneça um exemplo válido de pseudocódigo sem erros sintáticos.",
                                "Explique a diferença entre tag e destino.",
                                "Identifique quando usar MPI_Send vs MPI_Isend.",
                                "Liste 3 erros comuns em envios e como evitá-los.",
                                "Desenhe um diagrama de envio entre dois processos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição dos parâmetros (100% cobertura).",
                                "Clareza e correção do pseudocódigo fornecido.",
                                "Capacidade de explicar exemplos com variações (tag, dados).",
                                "Identificação de erros comuns e soluções.",
                                "Integração com contexto de programação paralela.",
                                "Uso correto de terminologia MPI."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação como TCP/IP.",
                                "Algoritmos e Estruturas de Dados: Sincronização em grafos distribuídos.",
                                "Sistemas Operacionais: Gerenciamento de processos e IPC.",
                                "Engenharia de Software: Padrões de design para paralelismo."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (ex: Weather Research and Forecasting - WRF), processos em clusters enviam dados meteorológicos parciais via MPI_Send para agregação em nós principais, otimizando computação distribuída em supercomputadores."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.1.2.2",
                            "name": "Descrever operação de recebimento de mensagens",
                            "description": "Detalhar como processos recebem mensagens, especificando origens, tags e buffers, com exemplos de recebimento bloqueante e não-bloqueante.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais da operação de recebimento",
                                  "subSteps": [
                                    "Identificar os parâmetros principais: origem (source), tag, buffer de destino, contagem de elementos, tipo de dados e comunicador.",
                                    "Explicar o papel da origem: MPI_ANY_SOURCE para qualquer remetente ou rank específico.",
                                    "Descrever o buffer: memória alocada para armazenar a mensagem recebida.",
                                    "Entender tags: identificadores para filtrar mensagens específicas.",
                                    "Revisar o comunicador: contexto de comunicação entre processos."
                                  ],
                                  "verification": "Listar e definir corretamente todos os 6 parâmetros principais em um diagrama ou tabela.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Documentação oficial do MPI (seção de MPI_Recv), editor de texto para anotações.",
                                  "tips": "Use diagramas de fluxo para visualizar o caminho da mensagem do remetente ao receptor.",
                                  "learningObjective": "Dominar os parâmetros essenciais da operação de recebimento de mensagens.",
                                  "commonMistakes": "Confundir origem com destino ou ignorar o papel do comunicador."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o recebimento bloqueante (MPI_Recv)",
                                  "subSteps": [
                                    "Analisar a sintaxe: MPI_Recv(buf, count, datatype, source, tag, comm, status).",
                                    "Simular o comportamento: processo bloqueia até mensagem chegar com tag e origem correspondentes.",
                                    "Examinar o status: recuperar informações como contagem real de elementos recebidos.",
                                    "Testar wildcards: MPI_ANY_TAG e MPI_ANY_SOURCE para flexibilidade.",
                                    "Discutir deadlock: risco quando múltiplos processos esperam uns pelos outros."
                                  ],
                                  "verification": "Escrever pseudocódigo de MPI_Recv e simular execução com 2 processos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Compilador MPI (mpicc), terminal para execução de exemplos simples.",
                                  "tips": "Sempre inicialize status com MPI_Status para capturar metadados.",
                                  "learningObjective": "Entender e simular o funcionamento síncrono do recebimento bloqueante.",
                                  "commonMistakes": "Esquecer de tratar wildcards corretamente, levando a bloqueios inesperados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar o recebimento não-bloqueante (MPI_Irecv)",
                                  "subSteps": [
                                    "Estudar a sintaxe: MPI_Irecv(buf, count, datatype, source, tag, comm, request).",
                                    "Explicar o request handle: identificador para operação assíncrona pendente.",
                                    "Aprender a testar conclusão: usar MPI_Test ou MPI_Wait no request.",
                                    "Comparar com bloqueante: permite sobreposição de computação e comunicação.",
                                    "Gerenciar múltiplos requests: com MPI_Request array."
                                  ],
                                  "verification": "Implementar um exemplo mínimo de MPI_Irecv seguido de MPI_Wait e compilar.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Ambiente MPI instalado (OpenMPI ou MPICH), código-fonte de exemplo.",
                                  "tips": "Combine com MPI_Isend para comunicação fully assíncrona e evite busy-waiting.",
                                  "learningObjective": "Dominar operações assíncronas para otimizar desempenho em aplicações paralelas.",
                                  "commonMistakes": "Acessar buffer antes de completar o request, causando dados inconsistentes."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar exemplos e comparações",
                                  "subSteps": [
                                    "Implementar código com MPI_Recv e MPI_Irecv em um programa de ping-pong.",
                                    "Comparar tempos de execução entre bloqueante e não-bloqueante.",
                                    "Analisar cenários de erro: mismatch de tag ou origem.",
                                    "Documentar diferenças em uma tabela: sincronia, performance, uso de casos.",
                                    "Executar com múltiplos processos (mpirun -np 4)."
                                  ],
                                  "verification": "Rodar programa compilado e capturar saída com prints de status.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Compilador MPI, máquina com suporte a multiprocessos.",
                                  "tips": "Use mpirun com --oversubscribe para testes locais sem limitações de cores.",
                                  "learningObjective": "Aplicar conceitos em código real e diferenciar modos de recebimento.",
                                  "commonMistakes": "Não sincronizar processos adequadamente, levando a saídas erráticas."
                                }
                              ],
                              "practicalExample": "Em um programa MPI com 2 processos: Processo 0 envia 'Olá' (tag=1) para processo 1. Processo 1 usa MPI_Recv(buf, 5, MPI_CHAR, 0, 1, MPI_COMM_WORLD, status) para receber bloqueante, imprimindo 'Mensagem recebida: Olá'. Para não-bloqueante: MPI_Irecv seguido de MPI_Wait, permitindo computação intermediária como soma de loop.",
                              "finalVerifications": [
                                "Explicar corretamente os 6 parâmetros de MPI_Recv.",
                                "Diferenciar bloqueante vs não-bloqueante com exemplos de risco (deadlock vs race condition).",
                                "Implementar e executar código funcional de ping-pong assíncrono.",
                                "Identificar wildcards apropriados para cenários flexíveis.",
                                "Descrever como status fornece metadados pós-recebimento.",
                                "Simular erro de mismatch de tag e propor solução."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição de parâmetros e wildcards (80% cobertura).",
                                "Correção sintática em exemplos de código MPI.",
                                "Compreensão de deadlock em bloqueante e acesso prematuro em não-bloqueante.",
                                "Uso efetivo de status e request handles.",
                                "Capacidade de comparar performance via execução prática.",
                                "Clareza em diagramas ou tabelas explicativas."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação ponto-a-ponto semelhantes a TCP/UDP.",
                                "Sistemas Operacionais: Gerenciamento de processos e primitivas de sincronização (wait/notify).",
                                "Algoritmos e Estruturas de Dados: Buffers como filas para mensagens pendentes.",
                                "Engenharia de Software: Padrões assíncronos em programação distribuída."
                              ],
                              "realWorldApplication": "Em simulações científicas em supercomputadores (ex: modelagem climática no MPI), onde nós distribuídos recebem dados de vizinhos para iterações paralelas, usando não-bloqueante para maximizar throughput em clusters HPC como os do TOP500."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.1.2.3",
                            "name": "Implementar envio e recebimento simples",
                            "description": "Criar código básico para troca ponto-a-ponto de mensagens entre dois processos, utilizando pseudocódigo ou API como MPI_Send e MPI_Recv.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar o ambiente MPI e obter identificadores de processos",
                                  "subSteps": [
                                    "Inclua as bibliotecas necessárias (ex: #include <mpi.h>)",
                                    "Chame MPI_Init(&argc, &argv) no início do main",
                                    "Obtenha o número de processos com MPI_Comm_size(MPI_COMM_WORLD, &size)",
                                    "Obtenha o rank do processo atual com MPI_Comm_rank(MPI_COMM_WORLD, &rank)",
                                    "Adicione uma saída de debug com printf para exibir rank e size"
                                  ],
                                  "verification": "Execute o programa e verifique se todos os processos imprimem seus ranks corretamente sem erros de inicialização",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Compilador com suporte a MPI (mpicc), editor de código (VS Code ou similar), terminal",
                                  "tips": "Sempre verifique o retorno de funções MPI com MPI_SUCCESS para depuração",
                                  "learningObjective": "Entender a configuração básica de um programa MPI e identificação de processos",
                                  "commonMistakes": "Esquecer de chamar MPI_Init antes de usar qualquer função MPI; não declarar variáveis size e rank"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar dados para envio no processo remetente (rank 0)",
                                  "subSteps": [
                                    "Declare uma variável de mensagem (ex: int message = 42;) no processo com rank 0",
                                    "Use if (rank == 0) para condicionar o código do remetente",
                                    "Defina o destino como rank 1 e o tag como 0 (MPI_Send(buffer, count, datatype, dest, tag, comm))",
                                    "Prepare o buffer de envio com os dados a serem transmitidos"
                                  ],
                                  "verification": "Adicione printf no remetente para confirmar que a mensagem foi preparada antes do envio",
                                  "estimatedTime": "10 minutos",
                                  "materials": "Mesmo ambiente do Step 1",
                                  "tips": "Escolha tags únicos para diferentes mensagens para evitar confusões em comunicações futuras",
                                  "learningObjective": "Preparar buffers de dados para comunicação ponto-a-ponto em MPI",
                                  "commonMistakes": "Usar rank incorreto como destino; esquecer de condicionar com if (rank == X)"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar envio (MPI_Send) e recebimento (MPI_Recv)",
                                  "subSteps": [
                                    "No remetente (rank 0): Chame MPI_Send(&message, 1, MPI_INT, 1, 0, MPI_COMM_WORLD)",
                                    "No receptor (rank 1): Declare variável int received; e chame MPI_Recv(&received, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status)",
                                    "Use if (rank == 1) para o receptor e inclua MPI_Status status",
                                    "Imprima a mensagem recebida no receptor para confirmação",
                                    "Adicione MPI_Barrier(MPI_COMM_WORLD) se necessário para sincronização"
                                  ],
                                  "verification": "Execute e confirme que o receptor imprime o valor enviado corretamente",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Mesmo ambiente anterior",
                                  "tips": "MPI_Send pode ser bloqueante; use MPI_Isend para não-bloqueante em casos avançados",
                                  "learningObjective": "Executar troca básica de mensagens ponto-a-ponto com MPI_Send e MPI_Recv",
                                  "commonMistakes": "Mismatch no count, datatype, src/dest ou tag entre Send e Recv; esquecer MPI_Status"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar MPI, compilar e testar o programa",
                                  "subSteps": [
                                    "Chame MPI_Finalize() no final do main em todos os processos",
                                    "Compile com mpicc -o programa programa.c",
                                    "Execute com mpirun -np 2 ./programa",
                                    "Teste com diferentes valores de mensagem e np=2",
                                    "Depure erros comuns como deadlocks com mpirun --oversubscribe"
                                  ],
                                  "verification": "Programa termina sem erros, MPI_Finalize é chamado e saída mostra troca bem-sucedida",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Terminal com MPI instalado (OpenMPI ou MPICH)",
                                  "tips": "Use valgrind ou mpirun com --report-unbound para detectar vazamentos de memória",
                                  "learningObjective": "Compilar, executar e finalizar programas MPI corretamente",
                                  "commonMistakes": "Executar com np != 2; esquecer MPI_Finalize causando hang"
                                }
                              ],
                              "practicalExample": "Programa MPI simples: Processo 0 envia '42' para processo 1 usando MPI_Send/MPI_Recv. Rank 1 recebe e imprime 'Recebido: 42'. Código completo em C com inicialização, comunicação e finalização.",
                              "finalVerifications": [
                                "Todos os processos inicializam e finalizam sem erros",
                                "Mensagem é enviada de rank 0 e recebida corretamente em rank 1",
                                "Saída de printf confirma ranks, tamanhos e conteúdo da mensagem",
                                "Programa executa com mpirun -np 2 sem deadlocks ou crashes",
                                "Alterar valor da mensagem reflete na recepção",
                                "Nenhum warning de compilação com mpicc"
                              ],
                              "assessmentCriteria": [
                                "Código inclui MPI_Init, Comm_rank/size e MPI_Finalize corretamente",
                                "Uso preciso de MPI_Send/Recv com parâmetros matching (count, type, tag, etc.)",
                                "Condicionais if (rank == 0/1) protegem códigos de envio/recebimento",
                                "Verificação de status e tratamento básico de erros",
                                "Compilação e execução bem-sucedidas com saída esperada",
                                "Comentários explicando cada seção de comunicação"
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Semelhanças com sockets TCP para comunicação ponto-a-ponto",
                                "Sistemas Operacionais: Gerenciamento de processos e sincronização",
                                "Algoritmos e Estruturas de Dados: Buffers como arrays para mensagens complexas",
                                "Engenharia de Software: Modularidade em programas distribuídos"
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática no supercomputador), onde processos em nós distribuídos trocam dados parciais de cálculos para resultados globais; ou em aplicações de big data como MPI em Hadoop para agregação de resultados de workers."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.2.1.2.4",
                            "name": "Gerenciar buffers e tipos de dados em mensagens",
                            "description": "Definir e manipular estruturas de dados complexas em mensagens, incluindo serialização e desserialização para comunicação eficiente.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Básicos de Buffers e Tipos de Dados",
                                  "subSteps": [
                                    "Estude o que são buffers em comunicação de mensagens: regiões de memória contíguas para dados.",
                                    "Aprenda tipos de dados suportados (primitivos como int, float; derivados como arrays e structs).",
                                    "Revise serialização (empacotamento de dados em buffer) e desserialização (extração).",
                                    "Analise exemplos de mismatches de tipo e seus impactos em programas paralelos.",
                                    "Explore documentação de MPI (ex: MPI_Datatype) para tipos personalizados."
                                  ],
                                  "verification": "Resuma em um diagrama os conceitos de buffer, serialização e desserialização.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação MPI oficial, editor de texto para anotações.",
                                  "tips": "Use diagramas visuais para mapear fluxo de dados de app para buffer.",
                                  "learningObjective": "Identificar e explicar componentes chave de buffers e tipos em mensagens.",
                                  "commonMistakes": "Confundir buffer com variável simples; ignorar alinhamento de memória."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Criar e Gerenciar Buffers Simples",
                                  "subSteps": [
                                    "Declare buffers usando arrays primitivos (ex: int buffer[100]).",
                                    "Inicialize buffers com dados de exemplo usando loops ou funções.",
                                    "Implemente cópias de dados para buffers com memcpy ou atribuições diretas.",
                                    "Teste alocação dinâmica com malloc para buffers de tamanho variável.",
                                    "Verifique integridade do buffer com checksums simples."
                                  ],
                                  "verification": "Compile e execute um programa que preenche e imprime um buffer sem erros.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Compilador MPI (mpicc), terminal para execução (mpirun).",
                                  "tips": "Sempre inicialize buffers para evitar lixo de memória.",
                                  "learningObjective": "Manipular buffers primitivos de forma segura e eficiente.",
                                  "commonMistakes": "Acessar além dos limites do buffer (buffer overflow); não liberar memória alocada."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir Estruturas de Dados Complexas",
                                  "subSteps": [
                                    "Crie structs C com campos heterogêneos (ex: struct {int id; double value; char name[20];}).",
                                    "Defina MPI_Datatypes personalizados usando MPI_Type_contiguous, MPI_Type_struct.",
                                    "Commit o datatype com MPI_Type_commit para uso em comunicações.",
                                    "Preencha instâncias da struct e associe a buffers.",
                                    "Teste commit e uso em um programa serial simples."
                                  ],
                                  "verification": "Crie e commite um datatype personalizado; imprima campos para confirmação.",
                                  "estimatedTime": "1 hora e 15 minutos",
                                  "materials": "Código fonte MPI, debugger (gdb ou printf para debug).",
                                  "tips": "Ordene campos da struct por tamanho decrescente para otimizar packing.",
                                  "learningObjective": "Construir e registrar tipos de dados compostos para mensagens.",
                                  "commonMistakes": "Esquecer MPI_Type_commit; desalinhamento de campos na struct."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar Serialização, Envio e Desserialização",
                                  "subSteps": [
                                    "Integre datatype em MPI_Send e MPI_Recv com buffers e contagens corretas.",
                                    "Implemente packing manual com MPI_Pack se necessário para estruturas não-contíguas.",
                                    "Adicione unpacking com MPI_Unpack no receptor.",
                                    "Execute com múltiplos ranks (mpirun -np 4) e valide dados recebidos.",
                                    "Otimize com MPI_Type_free após uso."
                                  ],
                                  "verification": "Programa paralelo envia struct de rank 0 para outros e todos imprimem dados idênticos.",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": "Cluster ou multi-core local, mpirun, valgrind para leaks.",
                                  "tips": "Use MPI_Bcast para testes iniciais antes de point-to-point.",
                                  "learningObjective": "Realizar comunicação eficiente com tipos complexos serializados.",
                                  "commonMistakes": "Mismatch entre count/datatype no send/recv; não sincronizar com MPI_Barrier."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimizar e Depurar Gerenciamento de Buffers",
                                  "subSteps": [
                                    "Profile performance com MPI profiling tools ou timers.",
                                    "Implemente verificações de erro (MPI_SUCCESS) em todas chamadas.",
                                    "Teste edge cases: buffers vazios, tamanhos máximos, tipos aninhados.",
                                    "Refatore código para reutilizar datatypes entre comunicações.",
                                    "Documente o código com comentários sobre buffers e tipos."
                                  ],
                                  "verification": "Execute testes unitários; performance < threshold e zero erros.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Ferramentas de profiling (Intel Trace Analyzer ou TAU), scripts de teste.",
                                  "tips": "Sempre cheque status de MPI calls em produção.",
                                  "learningObjective": "Garantir robustez e eficiência em gerenciamento de mensagens complexas.",
                                  "commonMistakes": "Não free datatypes; ignorar erros de rede em clusters."
                                }
                              ],
                              "practicalExample": "Em um programa MPI, defina struct Particle {int id; double pos[3]; float mass;}; crie MPI_Datatype particle_type com MPI_Type_create_struct, commit, preencha buffer com array de Particles, envie de rank 0 para 1 via MPI_Send(&buffer, num_particles, particle_type, 1, 0, MPI_COMM_WORLD); no rank 1, receba e unpack com MPI_Recv, imprima para verificar pos e mass idênticos.",
                              "finalVerifications": [
                                "Programa compila e executa com mpirun -np 4 sem crashes.",
                                "Dados serializados são transmitidos corretamente entre ranks.",
                                "MPI datatypes são committed e freed adequadamente.",
                                "Nenhum buffer overflow ou memory leak detectado por valgrind.",
                                "Performance de comunicação medida e otimizada (ex: <1ms por mensagem).",
                                "Edge cases (buffer vazio, struct grande) funcionam."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de MPI_Datatypes (100% match com struct).",
                                "Correta serialização/desserialização sem perda de dados (verificação bitwise).",
                                "Eficiência: uso mínimo de packing manual quando possível.",
                                "Robustez: handling de erros e sincronização perfeita.",
                                "Clareza do código: comentários e estrutura modular.",
                                "Escalabilidade: funciona com 2-16 ranks sem degradação."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de serialização como Protocol Buffers.",
                                "Estruturas de Dados: Árvores e grafos serializados em mensagens.",
                                "Bancos de Dados: Serialização de records para replicação distribuída.",
                                "Sistemas Operacionais: Gerenciamento de memória compartilhada vs. buffers."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: modelagem climática com milhões de partículas), gerenciar buffers de structs Particle permite troca eficiente de estados entre processos em clusters, reduzindo latência e overhead de comunicação em supercomputadores."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.1.2.1",
                              "10.1.2.1.2.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.1.3",
                        "name": "Modos de Troca e Avaliação de Desempenho",
                        "description": "Tipos de troca de mensagens (síncrona/assíncrona, bloqueante/não-bloqueante) e métricas para avaliar programas baseados nesse paradigma.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.1.3.1",
                            "name": "Diferenciar modos bloqueante e não-bloqueante",
                            "description": "Comparar impactos no desempenho e na programação de trocas bloqueantes (ex: MPI_Send) versus não-bloqueantes (ex: MPI_Isend/MPI_Wait).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de modos bloqueante e não-bloqueante",
                                  "subSteps": [
                                    "Ler definições: Modo bloqueante (processo para até completar a operação, ex: MPI_Send).",
                                    "Ler definições: Modo não-bloqueante (operação inicia sem bloquear, ex: MPI_Isend + MPI_Wait).",
                                    "Identificar diferenças chave: sincronização vs. assincronia, impacto na sobreposição de comunicação e computação.",
                                    "Estudar diagrama de fluxo de execução para ambos os modos.",
                                    "Anotar vantagens/desvantagens iniciais de cada modo."
                                  ],
                                  "verification": "Resumir em 3 frases as diferenças principais e desenhar um fluxograma simples.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Documentação oficial MPI (Capítulo 3)",
                                    "Editor de texto ou papel para diagramas"
                                  ],
                                  "tips": "Use analogias cotidianas: bloqueante como esperar na fila; não-bloqueante como deixar um pedido e continuar.",
                                  "learningObjective": "Diferenciar conceitualmente modos bloqueante e não-bloqueante em trocas de mensagens.",
                                  "commonMistakes": [
                                    "Confundir bloqueio com falha de comunicação",
                                    "Ignorar overhead de polling em não-bloqueante"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e analisar trocas bloqueantes com MPI_Send",
                                  "subSteps": [
                                    "Configurar ambiente MPI com mpirun.",
                                    "Escrever código simples: processo 0 envia para processo 1 usando MPI_Send e MPI_Recv.",
                                    "Compilar e executar em 2 processos, observando tempo de execução.",
                                    "Adicionar computação dummy entre envios para simular workload real.",
                                    "Medir tempo total com MPI_Wtime."
                                  ],
                                  "verification": "Executar código e confirmar que o remetente bloqueia até recepção completa.",
                                  "estimatedTime": "30-40 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Terminal com MPI instalado (OpenMPI ou MPICH)"
                                  ],
                                  "tips": "Use buffers pequenos inicialmente para testes rápidos; aumente para observar bloqueios longos.",
                                  "learningObjective": "Implementar troca bloqueante e observar seu comportamento síncrono.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init e MPI_Finalize",
                                    "Mismatch de tamanhos de buffer entre Send/Recv"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e analisar trocas não-bloqueantes com MPI_Isend e MPI_Wait",
                                  "subSteps": [
                                    "Modificar código anterior: substituir MPI_Send por MPI_Isend.",
                                    "Adicionar MPI_Wait após computação para completar a operação.",
                                    "Executar e observar se comunicação sobrepõe com computação.",
                                    "Testar múltiplos Isend em loop para simular pipelining.",
                                    "Comparar saída com versão bloqueante."
                                  ],
                                  "verification": "Confirmar que tempo total diminui devido à sobreposição (medir com MPI_Wtime).",
                                  "estimatedTime": "30-40 minutos",
                                  "materials": [
                                    "Mesmo ambiente MPI do step anterior",
                                    "Código do step 2 como base"
                                  ],
                                  "tips": "Sempre pareie Isend com Wait correspondente usando request handles.",
                                  "learningObjective": "Implementar troca não-bloqueante e demonstrar sobreposição.",
                                  "commonMistakes": [
                                    "Não testar MPI_Wait, causando perda de mensagens",
                                    "Reutilizar request sem completar anterior"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar impactos no desempenho e na programação",
                                  "subSteps": [
                                    "Executar benchmarks: variar tamanho de mensagem e workload computacional.",
                                    "Registrar tempos: bloqueante vs. não-bloqueante em tabela.",
                                    "Analisar métricas: throughput, latência, escalabilidade.",
                                    "Discutir cenários ideais: bloqueante para simplicidade, não-bloqueante para alto desempenho.",
                                    "Refatorar código para híbrido (bloqueante + não-bloqueante)."
                                  ],
                                  "verification": "Criar tabela comparativa com pelo menos 3 cenários testados.",
                                  "estimatedTime": "40-50 minutos",
                                  "materials": [
                                    "Códigos dos steps anteriores",
                                    "Planilha (Excel ou similar) para tabelas"
                                  ],
                                  "tips": "Use MPI_Barrier para sincronizar medições precisas; rode múltiplas vezes para média.",
                                  "learningObjective": "Quantificar diferenças de desempenho e escolher modo adequado.",
                                  "commonMistakes": [
                                    "Testar apenas com mensagens pequenas (esconde benefícios não-bloqueante)",
                                    "Ignorar overhead de não-bloqueante em workloads leves"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa MPI para multiplicação de matrizes distribuída: Processo raiz envia fatias de matriz para workers com MPI_Isend, workers computam localmente enquanto comunicação prossegue, finalizando com MPI_Wait. Comparado a MPI_Send, reduz tempo total em 20-30% para matrizes grandes.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças sem consultar notas.",
                                "Converter código bloqueante para não-bloqueante sem erros.",
                                "Identificar em código alheio uso de modos mistos.",
                                "Prever impacto de latência alta em cada modo.",
                                "Criar benchmark mostrando ganho >10% com não-bloqueante.",
                                "Discutir trade-offs em whiteboard."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas sem confusões.",
                                "Implementação funcional: códigos compilam e executam sem deadlocks.",
                                "Análise quantitativa: medições com variações de workload.",
                                "Escolha contextual: justificar modo por cenário.",
                                "Comunicação clara: tabelas/diagramas legíveis.",
                                "Profundidade: mencionar overheads e sobreposição."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: conceitos de threads e busy-waiting em não-bloqueante.",
                                "Redes de Computadores: latência e bandwidth em comunicações distribuídas.",
                                "Algoritmos e Estruturas: pipelining e paralelismo assíncrono.",
                                "Engenharia de Software: trade-offs simplicidade vs. performance."
                              ],
                              "realWorldApplication": "Em simulações climáticas ou modelagem molecular em supercomputadores (ex: HPC clusters), modos não-bloqueantes otimizam comunicação em milhares de nós, reduzindo tempo de simulação de dias para horas, como no código do Projeto Human Genome ou previsões meteorológicas do ECMWF."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.1.2.1"
                            ]
                          },
                          {
                            "id": "10.1.2.1.3.2",
                            "name": "Aplicar métricas de desempenho",
                            "description": "Calcular speedup, eficiência e overhead de comunicação em programas de troca de mensagens, usando exemplos de estudo de casos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender as definições das métricas de desempenho",
                                  "subSteps": [
                                    "Estude a definição de speedup: S(p) = T(1) / T(p), onde T(1) é o tempo de execução serial e T(p) o tempo paralelo com p processadores.",
                                    "Revise eficiência: E(p) = S(p) / p, representando a fração de idealidade do paralelismo.",
                                    "Aprenda overhead de comunicação: OH = T(p) * p - T(1), ou decomposição em tempo computacional e comunicação em modelos como LogP.",
                                    "Leia exemplos teóricos de programas de troca de mensagens (MPI send/receive).",
                                    "Anote fórmulas em um caderno para referência rápida."
                                  ],
                                  "verification": "Resuma as três métricas em suas próprias palavras e forneça as fórmulas corretas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI (man pages ou tutoriais online)",
                                    "Caderno e caneta",
                                    "Slides ou PDF sobre métricas de paralelismo"
                                  ],
                                  "tips": "Use analogias como 'speedup é quanto mais rápido fica com mais carros na estrada'.",
                                  "learningObjective": "Compreender conceitualmente speedup, eficiência e overhead para aplicação posterior.",
                                  "commonMistakes": "Confundir speedup com eficiência; esquecer que speedup é relativo ao serial."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente e implementar programa de exemplo",
                                  "subSteps": [
                                    "Instale MPI (OpenMPI ou MPICH) e compile um programa simples de soma de vetor com MPI_Allreduce.",
                                    "Implemente versão serial: soma sequencial de um vetor grande (ex: 1e8 elementos).",
                                    "Implemente versão paralela: distribua o vetor entre p processadores (p=1,2,4,8).",
                                    "Adicione medição de tempo com MPI_Wtime() em pontos chave.",
                                    "Compile e execute com mpirun para diferentes p, registrando tempos médios de 10 runs."
                                  ],
                                  "verification": "Execute o programa e obtenha tempos T(1), T(2), T(4) com valores plausíveis (ex: T(1)=5s, T(4)=1.5s).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Computador com Linux/Mac",
                                    "Compilador GCC + MPI",
                                    "Código-fonte exemplo de MPI vector sum"
                                  ],
                                  "tips": "Use --oversubscribe em mpirun se poucos cores; rode em máquina multi-core.",
                                  "learningObjective": "Configurar e medir tempos reais em programas de troca de mensagens.",
                                  "commonMistakes": "Não sincronizar com MPI_Barrier antes de medir; ignorar overhead de inicialização MPI."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular speedup e eficiência",
                                  "subSteps": [
                                    "Colete dados de tempo: crie tabela com p, T(p), T(1).",
                                    "Calcule S(p) para p=2,4,8 usando planilha (Excel/Google Sheets).",
                                    "Calcule E(p) = S(p)/p e plote gráficos S(p) vs p e E(p) vs p.",
                                    "Interprete: speedup superlinear? Eficiência >80% bom?",
                                    "Repita com vetor maior para observar escalabilidade."
                                  ],
                                  "verification": "Produza tabela com S(4)=2.5 e E(4)=0.625, com gráfico mostrando queda de eficiência.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha Excel/Google Sheets",
                                    "Dados de tempo do Step 2"
                                  ],
                                  "tips": "Média de múltiplos runs para reduzir variância; log escala em gráficos.",
                                  "learningObjective": "Aplicar fórmulas de speedup e eficiência em dados reais.",
                                  "commonMistakes": "Usar tempo wall-clock sem excluir init; dividir errado (S(p)=T(p)/T(1))."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e analisar overhead de comunicação",
                                  "subSteps": [
                                    "Calcule overhead total: OH(p) = p * T(p) - T(1).",
                                    "Estime overhead por comunicação: em programa com k sends/receives, OH_comm ≈ k * (latência + tamanho/bandwidth).",
                                    "Modifique programa para mais comunicações (ex: all-to-all) e recalcule.",
                                    "Compare OH em diferentes topologias (ring vs tree).",
                                    "Escreva relatório curto com análise: 'OH domina para p>4 devido a latência'."
                                  ],
                                  "verification": "Relatório mostra OH(8)=10s vs T(1)=5s, identificando comunicação como bottleneck.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Programa modificado do Step 2",
                                    "Referência LogP model",
                                    "Planilha atualizada"
                                  ],
                                  "tips": "Use MPI profiling tools como Vampir para visualizar comunicações.",
                                  "learningObjective": "Quantificar e decompor overhead em componentes computacionais e de comunicação.",
                                  "commonMistakes": "Ignorar que OH inclui tanto comm quanto imbalance; assumir modelo ideal sem dados reais."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar em estudo de caso e interpretar resultados",
                                  "subSteps": [
                                    "Escolha case: matrix multiplication com MPI (disponível online).",
                                    "Meça métricas para diferentes tamanhos de matriz e p.",
                                    "Compare com paper acadêmico (ex: busca 'MPI matrix mult speedup').",
                                    "Discuta limitações: Amdahl's law, comunicação vs compute.",
                                    "Proponha otimizações baseadas em métricas (reduzir comm com block sizes)."
                                  ],
                                  "verification": "Análise final com speedup=6.2 para p=8, E=77%, OH=20% do tempo total.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código matrix mult MPI",
                                    "Papers ou benchmarks HPC"
                                  ],
                                  "tips": "Use cluster se disponível (Google Colab com MPI simulado); foque em tendências.",
                                  "learningObjective": "Integrar métricas em cenários reais e propor melhorias.",
                                  "commonMistakes": "Overfitting a um case; não considerar hardware variability."
                                }
                              ],
                              "practicalExample": "Em um programa MPI para soma de vetor de 1e8 doubles: T(1)=4.2s, T(4)=1.1s, T(8)=0.9s. Speedup S(4)=3.82, E(4)=0.955; S(8)=4.67 (superlinear devido cache), E(8)=0.58. Overhead comm alto em T(8) por Allreduce frequente.",
                              "finalVerifications": [
                                "Calculou corretamente S(p), E(p) e OH(p) para pelo menos 3 valores de p.",
                                "Identificou se speedup é sub/superlinear e explicou causa.",
                                "Ploteou gráficos de S(p) e E(p) mostrando escalabilidade.",
                                "Decompôs overhead em comm vs compute com evidências.",
                                "Propôs uma otimização baseada nas métricas (ex: menos Allreduce).",
                                "Comparou resultados com benchmark publicado."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: fórmulas e cálculos sem erros (>95% accuracy).",
                                "Qualidade de medição: uso de médias, barriers e múltiplos runs.",
                                "Análise interpretativa: explicação de resultados além de números.",
                                "Visualizações: gráficos claros e informativos.",
                                "Abrangência: cobre speedup, eficiência e overhead.",
                                "Criatividade: aplicação em case real e sugestões de melhoria."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear para decomposição de overhead, gráficos e funções.",
                                "Estatística: Análise de variância em tempos de execução, médias e desvios.",
                                "Engenharia de Software: Profiling e otimização de código paralelo.",
                                "Física/Computação Científica: Modelos de performance em simulações HPC.",
                                "Gestão de Projetos: Métricas de ROI em sistemas distribuídos."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier (HPC), otimizar apps como clima ou genômica calculando speedup para alocar nós eficientemente; em cloud (AWS ParallelCluster), reduzir custos medindo eficiência antes de escalar instâncias."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.1.1.2"
                            ]
                          },
                          {
                            "id": "10.1.2.1.3.3",
                            "name": "Explorar linguagens e bibliotecas",
                            "description": "Identificar e descrever uso de MPI, PVM ou UPC para implementação do paradigma em plataformas multicores e na nuvem.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar e Pesquisar Linguagens e Bibliotecas de Programação Paralela",
                                  "subSteps": [
                                    "Pesquise definições e histórico de MPI (Message Passing Interface), PVM (Parallel Virtual Machine) e UPC (Unified Parallel C).",
                                    "Compare características principais: MPI é padrão, PVM é mais antigo e flexível, UPC é extensão do C para partilha de memória.",
                                    "Identifique plataformas suportadas: multicores locais e ambientes de nuvem como AWS ou Google Cloud.",
                                    "Colete documentações oficiais: mpi-forum.org para MPI, pvm.crest.iu.edu para PVM, upc.lbl.gov para UPC.",
                                    "Anote casos de uso iniciais para cada uma em memória distribuída."
                                  ],
                                  "verification": "Criar um resumo de 1 página listando definições, diferenças e links de documentação.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação oficial MPI, PVM, UPC (sites oficiais)",
                                    "Navegador web",
                                    "Editor de texto para notas"
                                  ],
                                  "tips": "Use tabelas comparativas para facilitar a visualização de diferenças.",
                                  "learningObjective": "Compreender as bases conceituais e diferenças entre MPI, PVM e UPC.",
                                  "commonMistakes": "Confundir MPI com bibliotecas de threads (como OpenMP); foque em mensagem passing."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar Conceitos e Sintaxe Básica do MPI",
                                  "subSteps": [
                                    "Instale MPICH ou OpenMPI em sua máquina local ou use um container Docker.",
                                    "Aprenda funções essenciais: MPI_Init, MPI_Comm_rank, MPI_Comm_size, MPI_Send, MPI_Recv, MPI_Finalize.",
                                    "Estude modos de troca: síncrono vs assíncrono e blocking vs non-blocking.",
                                    "Leia exemplos de código hello world e broadcast.",
                                    "Entenda topologias de comunicação em multicores."
                                  ],
                                  "verification": "Compilar e executar um programa MPI hello world que imprima ranks e size.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "MPICH/OpenMPI instalado",
                                    "Compilador C/MPI (mpicc)",
                                    "Exemplos de código do site MPI Tutorial"
                                  ],
                                  "tips": "Execute com mpirun -np 4 para testar múltiplos processos.",
                                  "learningObjective": "Dominar sintaxe básica do MPI para troca de mensagens.",
                                  "commonMistakes": "Esquecer MPI_Init antes de usar funções MPI; sempre inicialize primeiro."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Programa Paralelo em Plataforma Multicores",
                                  "subSteps": [
                                    "Desenvolva um programa para calcular pi usando método de Monte Carlo com MPI_Send/Recv.",
                                    "Divida o trabalho entre processos: root coordena e recebe resultados parciais.",
                                    "Compile e execute em máquina multicores com 4-8 cores.",
                                    "Meça tempo de execução com MPI_Wtime para avaliar speedup.",
                                    "Otimize com non-blocking sends para melhorar desempenho."
                                  ],
                                  "verification": "Programa roda corretamente, speedup >1 comparado à versão serial.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Código base Monte Carlo serial",
                                    "MPICH instalado",
                                    "Máquina com múltiplos cores"
                                  ],
                                  "tips": "Use gdb ou valgrind para debug de deadlocks em comunicação.",
                                  "learningObjective": "Aplicar MPI em implementação paralela e medir desempenho inicial.",
                                  "commonMistakes": "Mismatch em tags ou communicators em Send/Recv causando hangs."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Adaptação para Nuvem e Avaliação de Desempenho",
                                  "subSteps": [
                                    "Configure ambiente de nuvem: AWS EC2 com múltiplas instâncias ou Google Cloud VMs.",
                                    "Adapte o programa MPI para rodar via SSH ou Slurm em cluster nuvem.",
                                    "Execute em diferentes escalas (8-32 processos) e colete métricas: latency, bandwidth.",
                                    "Compare desempenho multicores local vs nuvem usando gráficos (matplotlib).",
                                    "Descreva limitações de PVM/UPC em nuvem e quando usar cada uma."
                                  ],
                                  "verification": "Relatório com gráficos de speedup e descrição de usos em nuvem.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Conta AWS/Google Cloud",
                                    "Slurm ou mpirun em cluster",
                                    "Python/Matplotlib para plots"
                                  ],
                                  "tips": "Use instâncias spot na nuvem para economizar custos em testes.",
                                  "learningObjective": "Avaliar e descrever uso de MPI/PVM/UPC em plataformas distribuídas como nuvem.",
                                  "commonMistakes": "Ignorar custos de rede na nuvem; sempre benchmark comunicação."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Comparar e Documentar Usos das Bibliotecas",
                                  "subSteps": [
                                    "Implemente o mesmo programa em PVM ou UPC para comparação.",
                                    "Documente prós/contras: portabilidade MPI vs heterogeneidade PVM.",
                                    "Crie tabela de avaliação de desempenho em multicores/nuvem.",
                                    "Descreva cenários ideais: simulações científicas para MPI.",
                                    "Prepare apresentação resumida das bibliotecas."
                                  ],
                                  "verification": "Documento final com códigos, tabelas e conclusões.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Códigos anteriores",
                                    "PVM/UPC instalados opcionalmente",
                                    "LaTeX ou Markdown para relatório"
                                  ],
                                  "tips": "Foque em métricas quantitativas para comparações objetivas.",
                                  "learningObjective": "Sintetizar conhecimentos para identificar usos ótimos de cada biblioteca.",
                                  "commonMistakes": "Generalizar sem dados; baseie em experimentos reais."
                                }
                              ],
                              "practicalExample": "Implemente um programa MPI para aproximação de pi via Monte Carlo: root gera números aleatórios distribuídos aos workers via MPI_Scatter; workers contam pontos dentro do círculo e retornam via MPI_Gather. Execute com mpirun -np 8 em 8 cores, medindo speedup de 6.5x.",
                              "finalVerifications": [
                                "Lista corretamente funções chave de MPI, PVM e UPC.",
                                "Executa programa paralelo funcional em multicores com speedup mensurável.",
                                "Descreve adaptação para nuvem incluindo métricas de rede.",
                                "Compara as três bibliotecas com tabela de prós/contras.",
                                "Identifica cenários reais de uso (ex: simulações climáticas).",
                                "Gera relatório com códigos e gráficos de desempenho."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação e descrição das bibliotecas (20%)",
                                "Corretude da implementação MPI em multicores (25%)",
                                "Qualidade da avaliação de desempenho e gráficos (20%)",
                                "Profundidade na adaptação para nuvem (15%)",
                                "Comparação abrangente entre MPI/PVM/UPC (10%)",
                                "Clareza do relatório e exemplos práticos (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Entender latency e bandwidth em trocas de mensagens.",
                                "Cloud Computing: Configuração de clusters virtuais para paralelismo.",
                                "Algoritmos e Estruturas de Dados: Paralelização de Monte Carlo e reduções.",
                                "Sistemas Operacionais: Gerenciamento de processos em ambientes distribuídos.",
                                "Matemática Computacional: Aplicações em simulações numéricas."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, MPI é usado em simulações climáticas (ex: CESM model) e genômica (ex: BLAST paralelo), permitindo processar petabytes de dados em clusters de nuvem para pesquisa científica acelerada."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.2",
                    "name": "Primitivas Básicas de Troca de Mensagens",
                    "description": "Operações fundamentais como send, receive, broadcast e reduce para intercâmbio de dados entre processos.",
                    "individualConcepts": [
                      {
                        "id": "SC-64.1.1",
                        "name": "Send e Receive",
                        "description": "Operações fundamentais de envio e recebimento ponto a ponto de mensagens entre processos em memória distribuída, permitindo comunicação síncrona ou assíncrona.",
                        "specificSkills": [
                          {
                            "id": "SC-64.1.1.1",
                            "name": "Implementar Send Bloqueante",
                            "description": "Desenvolver código para envio bloqueante de mensagens usando primitivas como MPI_Send, aguardando confirmação de recebimento pelo destino.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambiente MPI e Programa Básico",
                                  "subSteps": [
                                    "Instalar e verificar instalação do MPI (ex: OpenMPI ou MPICH) usando comandos como 'mpicc --version'.",
                                    "Criar um arquivo fonte C vazio (ex: send_blocking.c) e incluir headers necessários: #include <mpi.h> e #include <stdio.h>.",
                                    "Implementar MPI_Init(&argc, &argv); e MPI_Finalize(); em main para estrutura básica.",
                                    "Adicionar MPI_Comm_rank(MPI_COMM_WORLD, &rank); e MPI_Comm_size(MPI_COMM_WORLD, &size); para identificar processos.",
                                    "Definir buffers de mensagem: char message[100]; int buffer_size = 100;"
                                  ],
                                  "verification": "Compilar com 'mpicc -o send_blocking send_blocking.c' sem erros e executar 'mpirun -n 2 ./send_blocking' para ver ranks impressos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "MPI instalado (OpenMPI/MPICH)",
                                    "Compilador mpicc",
                                    "Editor de texto/IDE (VSCode)"
                                  ],
                                  "tips": "Use 'module load mpi' em clusters HPC se disponível. Sempre verifique erros com MPI_SUCCESS.",
                                  "learningObjective": "Entender inicialização e estrutura básica de um programa MPI.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init antes de chamadas MPI.",
                                    "Não chamar MPI_Finalize no final.",
                                    "Usar MPI_COMM_WORLD incorretamente."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Send Bloqueante no Processo Remetente",
                                  "subSteps": [
                                    "No processo com rank 0 (remetente): inicializar buffer com sprintf(message, \"Hello from rank %d!\", rank);.",
                                    "Chamar MPI_Send(message, strlen(message)+1, MPI_CHAR, 1, 0, MPI_COMM_WORLD); onde destino é rank 1, tag=0.",
                                    "Adicionar printf para confirmar envio: printf(\"Process %d enviou mensagem.\\n\", rank); fflush(stdout);.",
                                    "Verificar status de retorno: int err = MPI_Send(...); if(err != MPI_SUCCESS) { MPI_Abort(...); }.",
                                    "Garantir que MPI_Send bloqueie até a mensagem ser copiada para buffer ou recebida (comportamento padrão synchronous em muitos impls)."
                                  ],
                                  "verification": "Executar e observar que rank 0 imprime 'enviou' apenas após receptor estar pronto (sem deadlock prematuro).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código do Step 1",
                                    "Documentação MPI_Send (mpi-forum.org)"
                                  ],
                                  "tips": "Use strlen(message)+1 para incluir null terminator em strings. Tags ajudam a diferenciar mensagens.",
                                  "learningObjective": "Dominar sintaxe e semântica de MPI_Send bloqueante.",
                                  "commonMistakes": [
                                    "Tamanho incorreto do buffer (causa truncamento).",
                                    "Não flush stdout (mensagens perdidas).",
                                    "Enviar para rank inválido."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Recv no Processo Receptor",
                                  "subSteps": [
                                    "No processo com rank 1 (receptor): declarar buffer de recebimento char recv_msg[100];.",
                                    "Chamar MPI_Recv(recv_msg, 100, MPI_CHAR, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); com origem rank 0, tag=0.",
                                    "Após recv, imprimir: printf(\"Process %d recebeu: %s\\n\", rank, recv_msg); fflush(stdout);.",
                                    "Verificar que recv bloqueia até mensagem chegar, sincronizando com send.",
                                    "Adicionar tratamento de erro similar ao send."
                                  ],
                                  "verification": "Executar 'mpirun -n 2 ./send_blocking' e confirmar que rank 1 recebe e imprime a mensagem corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código dos Steps 1-2",
                                    "Referência MPI_Recv"
                                  ],
                                  "tips": "MPI_STATUS_IGNORE para simplicidade; use MPI_Get_count para tamanhos dinâmicos em casos avançados.",
                                  "learningObjective": "Compreender bloqueio mútuo via send-recv pareados.",
                                  "commonMistakes": [
                                    "Recv antes de send (deadlock).",
                                    "Buffer pequeno demais.",
                                    "Tag origem mismatch."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Compilar, Executar e Depurar o Programa Completo",
                                  "subSteps": [
                                    "Compilar versão final: mpicc -Wall -g -o send_blocking send_blocking.c.",
                                    "Executar com 2 processos: mpirun -n 2 ./send_blocking e observar saídas sincronizadas.",
                                    "Testar com mais processos (ex: -n 4, condicionar if(rank==0) send, else recv).",
                                    "Usar mpirun --oversubscribe se necessário; depurar com gdb: mpirun -n 2 xterm -e gdb ./send_blocking.",
                                    "Analisar com ferramentas como Valgrind: mpirun -n 2 valgrind ./send_blocking para leaks."
                                  ],
                                  "verification": "Programa executa sem deadlock, mensagens trocadas corretamente em múltiplas runs.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Valgrind/GDB opcionais",
                                    "Cluster local ou máquina multi-core"
                                  ],
                                  "tips": "Use -np para número exato de processos. Logs em arquivos para debug.",
                                  "learningObjective": "Testar e validar comunicação bloqueante MPI.",
                                  "commonMistakes": [
                                    "Deadlock por ordem errada send/recv.",
                                    "Não sincronizar prints.",
                                    "Execução com -n 1 (falha)."
                                  ]
                                }
                              ],
                              "practicalExample": "Programa MPI com 2 processos: rank 0 envia 'Hello from rank 0!' via MPI_Send para rank 1, que recebe com MPI_Recv e imprime. Execução: mpirun -n 2 ./send_blocking mostra 'Process 0 enviou mensagem.' seguido de 'Process 1 recebeu: Hello from rank 0!'.",
                              "finalVerifications": [
                                "Programa compila sem warnings/erros.",
                                "Executa com mpirun -n 2 sem deadlock ou crashes.",
                                "Mensagem é enviada e recebida corretamente (ver prints).",
                                "Funciona com tamanhos de mensagem variados (teste 1KB).",
                                "Sem memory leaks (valgrind clean).",
                                "Sincronização correta: prints em ordem esperada."
                              ],
                              "assessmentCriteria": [
                                "Código usa MPI_Send/Recv corretamente com parâmetros exatos.",
                                "Tratamento de erros MPI implementado.",
                                "Buffers gerenciados sem overflows/underflows.",
                                "Execução determinística em múltiplas runs.",
                                "Comentários explicando bloqueio e sincronização.",
                                "Eficiência: sem busy-waiting desnecessário."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Similar a sockets bloqueantes TCP.",
                                "Sistemas Operacionais: Sincronização via primitives como semáforos.",
                                "Algoritmos Paralelos: Base para broadcast/reduce.",
                                "Engenharia de Software: Testes unitários em código distribuído.",
                                "HPC: Fundamento para simulações científicas (CFD, ML distribuído)."
                              ],
                              "realWorldApplication": "Em computação de alto desempenho (HPC), usado em simulações numéricas como modelagem climática ou genômica, onde clusters de nós trocam dados particionados de forma síncrona para garantir consistência antes de prosseguir iterações."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "SC-64.1.1.2",
                            "name": "Implementar Receive Bloqueante",
                            "description": "Criar código para recebimento bloqueante de mensagens com MPI_Recv, especificando origem, tag e buffer de destino.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar o ambiente MPI",
                                  "subSteps": [
                                    "Incluir o cabeçalho necessário: #include <mpi.h>",
                                    "No função main, chamar MPI_Init(&argc, &argv) como primeira operação MPI",
                                    "Obter o número de processos com MPI_Comm_size(MPI_COMM_WORLD, &size)",
                                    "Obter o rank do processo atual com MPI_Comm_rank(MPI_COMM_WORLD, &rank)"
                                  ],
                                  "verification": "Adicione printf para imprimir rank e size; execute com mpirun -np 2 e confirme saídas corretas sem erros de MPI.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Instalação de MPI (OpenMPI ou MPICH)",
                                    "Compilador mpicc",
                                    "Editor de texto (VS Code ou similar)"
                                  ],
                                  "tips": "Sempre chame MPI_Init antes de qualquer outra função MPI para evitar erros de runtime.",
                                  "learningObjective": "Compreender e implementar a inicialização básica do MPI para preparar o ambiente de comunicação paralela.",
                                  "commonMistakes": [
                                    "Chamar funções MPI antes de MPI_Init",
                                    "Esquecer de passar argc e argv corretamente",
                                    "Não verificar o retorno de MPI_Init"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar buffer de destino e parâmetros de MPI_Recv",
                                  "subSteps": [
                                    "Declarar o buffer de destino: char buffer[256];",
                                    "Definir origem: int source = 0; (ou MPI_ANY_SOURCE para qualquer origem)",
                                    "Definir tag: int tag = 0;",
                                    "Declarar MPI_Status status; para capturar metadados da mensagem",
                                    "Inicializar buffer se necessário: memset(buffer, 0, sizeof(buffer));"
                                  ],
                                  "verification": "Inspecione o código fonte para confirmar declarações corretas e inicialização do buffer; compile sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Documentação MPI (mpi.h ou man pages)",
                                    "Código fonte do Step 1"
                                  ],
                                  "tips": "Use MPI_ANY_SOURCE para flexibilidade em cenários onde a origem não é fixa.",
                                  "learningObjective": "Preparar adequadamente os argumentos necessários para uma chamada segura de MPI_Recv.",
                                  "commonMistakes": [
                                    "Buffer muito pequeno para a mensagem esperada",
                                    "Não declarar MPI_Status",
                                    "Usar tag inconsistente com o sender"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a chamada bloqueante MPI_Recv",
                                  "subSteps": [
                                    "Chamar MPI_Recv(buffer, 256, MPI_CHAR, source, tag, MPI_COMM_WORLD, &status);",
                                    "Verificar erros: int err = MPI_Get_count(&status, MPI_CHAR, &count); if(err != MPI_SUCCESS) { erro };",
                                    "Usar os dados recebidos: printf('Process %d received: %s from %d\\n', rank, buffer, status.MPI_SOURCE);",
                                    "Confirmar origem real via status.MPI_SOURCE se usou MPI_ANY_SOURCE"
                                  ],
                                  "verification": "Execute o programa completo; confirme que o processo receptor bloqueia até mensagem chegar e imprime corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Programa sender complementar para testar"
                                  ],
                                  "tips": "MPI_Recv bloqueia até a mensagem exata (origem+tag) chegar; combine com sender para testar.",
                                  "learningObjective": "Executar e validar o receive bloqueante, capturando status para inspeção.",
                                  "commonMistakes": [
                                    "Passar parâmetros errados na ordem",
                                    "Esquecer &status como último argumento",
                                    "Não tratar buffer nulo pós-receive"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar comunicação e testar o programa",
                                  "subSteps": [
                                    "Chamar MPI_Finalize() no final do main",
                                    "Compilar: mpicc -o recv_test programa.c",
                                    "Executar: mpirun -np 2 ./recv_test",
                                    "Debugar com mpirun -np 2 --oversubscribe ./recv_test se necessário",
                                    "Verificar saída: receptor deve imprimir mensagem sem travamentos"
                                  ],
                                  "verification": "Programa executa sem leaks (valgrind mpirun se disponível) e produz saída esperada consistentemente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "mpirun",
                                    "Programa sender MPI_Send para simular envio"
                                  ],
                                  "tips": "Teste com múltiplos np (2-4) para validar escalabilidade básica.",
                                  "learningObjective": "Integrar MPI_Recv em um programa completo e validar execução paralela.",
                                  "commonMistakes": [
                                    "Chamar MPI_Finalize antes de todas comunicações",
                                    "Executar sem mpirun",
                                    "Não limpar buffer antes"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de 2 processos, rank 0 envia 'Hello MPI!' com MPI_Send(buffer, 10, MPI_CHAR, 1, 0, MPI_COMM_WORLD). Rank 1 executa: char recv_buf[256]; MPI_Status st; MPI_Recv(recv_buf, 256, MPI_CHAR, 0, 0, MPI_COMM_WORLD, &st); printf(\"Rank 1 received: %s from %d\\n\", recv_buf, st.MPI_SOURCE); Rank 1 bloqueia até receber e imprime corretamente.",
                              "finalVerifications": [
                                "Programa compila com mpicc sem erros ou warnings MPI.",
                                "Execução com mpirun -np 2 mostra receptor bloqueando e recebendo mensagem exata.",
                                "status.MPI_SOURCE reflete origem correta; sem erros em MPI_Get_count.",
                                "Nenhum deadlock ou crash ao variar np entre 2-4.",
                                "MPI_Finalize chamado após receive, programa encerra graciosamente.",
                                "Buffer contém dados corretos sem overflow ou lixo."
                              ],
                              "assessmentCriteria": [
                                "Sintaxe precisa de MPI_Recv com 7 argumentos corretos (buffer, count, datatype, source, tag, comm, status).",
                                "Uso apropriado de MPI_ANY_SOURCE ou source específico com validação via status.",
                                "Verificação pós-receive de erros e metadados (tag, count, source).",
                                "Integração completa com MPI_Init, Comm_rank/size e Finalize.",
                                "Demonstração de comportamento bloqueante via teste com sender.",
                                "Buffer dimensionado corretamente com inicialização."
                              ],
                              "crossCurricularConnections": [
                                "Programação em C: manipulação de ponteiros e arrays para buffers.",
                                "Redes de Computadores: conceitos de sockets bloqueantes e sincronização.",
                                "Sistemas Operacionais: gerenciamento de processos e primitivas IPC.",
                                "Algoritmos Paralelos: sincronização em modelos message-passing."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC como modelagem climática (ex: Weather Research Forecasting model), processos recebem dados bloqueantemente de vizinhos para iterações sincronizadas, garantindo consistência em grids distribuídos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "SC-64.1.1.3",
                            "name": "Usar Send/Receive Não-Bloqueantes",
                            "description": "Aplicar MPI_Isend e MPI_Irecv para comunicação assíncrona, gerenciando requests com MPI_Wait ou MPI_Test.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Comunicação Não-Bloqueante",
                                  "subSteps": [
                                    "Estude a diferença entre comunicação síncrona (MPI_Send/MPI_Recv) e assíncrona (MPI_Isend/MPI_Irecv).",
                                    "Leia a documentação oficial do MPI sobre funções não-bloqueantes e requests MPI_Request.",
                                    "Analise diagramas de timeline mostrando overlap de comunicação e computação.",
                                    "Identifique cenários onde comunicação não-bloqueante melhora performance (ex: aplicações HPC).",
                                    "Revise conceitos de progresso de comunicação no MPI (eager vs rendezvous protocol)."
                                  ],
                                  "verification": "Explique em suas palavras a vantagem do não-bloqueante sobre bloqueante e desenhe um diagrama simples de overlap.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI (Capítulo 3 do MPI Standard)",
                                    "Editor de texto ou Jupyter Notebook para anotações"
                                  ],
                                  "tips": "Use ferramentas como MPI tracers (ex: Vampir) para visualizar timelines futuramente.",
                                  "learningObjective": "Diferenciar comunicação bloqueante e não-bloqueante, entendendo requests e progresso assíncrono.",
                                  "commonMistakes": [
                                    "Confundir MPI_Isend com MPI_Send (bloqueante).",
                                    "Ignorar que MPI_Isend retorna imediatamente, mas mensagem pode não estar enviada."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Isend e MPI_Irecv Básicos",
                                  "subSteps": [
                                    "Inclua headers necessários: #include <mpi.h>.",
                                    "Inicialize MPI com MPI_Init e obtenha rank/world_size.",
                                    "No processo 0, prepare buffer de envio e chame MPI_Isend com MPI_REQUEST_INIT para request.",
                                    "No processo 1, prepare buffer de recepção e chame MPI_Irecv similarmente.",
                                    "Compile com mpicc e execute com mpirun -np 2 para testar sintaxe."
                                  ],
                                  "verification": "O programa compila e executa sem crash, mas aguarde para verificar requests pendentes.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Terminal ou IDE com suporte MPI (ex: VSCode com C/C++ extension)"
                                  ],
                                  "tips": "Sempre inicialize requests com MPI_Request request; MPI_Request_init(&request);",
                                  "learningObjective": "Codificar corretamente MPI_Isend e MPI_Irecv com gerenciamento de buffers e tags.",
                                  "commonMistakes": [
                                    "Esquecer de declarar MPI_Request.",
                                    "Usar buffers não alocados ou tamanhos incorretos em MPI_Isend/MPI_Irecv."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerenciar Requests com MPI_Wait e MPI_Test",
                                  "subSteps": [
                                    "Adicione MPI_Wait(&request_send, MPI_STATUS_IGNORE) após Isend para sincronizar.",
                                    "Implemente MPI_Test(&request_recv, &flag, MPI_STATUS_IGNORE) em loop para polling.",
                                    "Combine: envie Isend, faça computação local, então Wait no request.",
                                    "Teste com ping-pong: processo 0 envia para 1, 1 recebe e responde.",
                                    "Adicione prints para medir tempo de computação vs comunicação."
                                  ],
                                  "verification": "Execute e confirme que requests completam sem perda de mensagens (use printf para valores trocados).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código base do Step 2",
                                    "mpirun para execução paralela"
                                  ],
                                  "tips": "Use MPI_Waitall para múltiplos requests; evite busy-waiting excessivo com MPI_Test.",
                                  "learningObjective": "Controlar conclusão de operações assíncronas usando wait e test para habilitar overlap.",
                                  "commonMistakes": [
                                    "Não chamar Wait/Test, causando leaks de requests.",
                                    "Ignorar status com MPI_STATUS_IGNORE prematuramente (use para debug inicial)."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e Otimizar Programa com Overlap",
                                  "subSteps": [
                                    "Implemente computação fake (loop for) entre Isend e Wait para simular overlap.",
                                    "Meça tempo total com MPI_Wtime() antes/depois da seção crítica.",
                                    "Execute com diferentes np (2-8) e compare performance vs versão bloqueante.",
                                    "Debug com mpirun -np 2 ./prog 2>&1 | grep erros.",
                                    "Refatore para múltiplas mensagens com MPI_Request array e MPI_Waitall."
                                  ],
                                  "verification": "Tempo de execução mostra ganho de performance devido a overlap (compare com MPI_Send/Recv).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Scripts para timing (opcional: MPI_Wtick)"
                                  ],
                                  "tips": "Para overlap real, use computações independentes da comunicação.",
                                  "learningObjective": "Demonstrar e quantificar benefícios de comunicação assíncrona em cenários reais.",
                                  "commonMistakes": [
                                    "Computação muito curta, mascarando falta de overlap.",
                                    "Deadlock por ordem errada de Wait em processos assimétricos."
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um programa de multiplicação de vetores distribuída onde cada processo envia seu vetor parcial via MPI_Isend, computa produto local durante recepção assíncrona com MPI_Irecv, e finaliza com MPI_Waitall. Execute com 4 processos: verifique se tempo total < soma de comm + comp individual.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros ou deadlocks em múltiplos ranks.",
                                "Mensagens são trocadas corretamente (valores impressos coincidem).",
                                "Requests são todos completados (sem leaks detectados via Valgrind-MPI).",
                                "Overlap é observável: tempo total reduzido vs versão síncrona.",
                                "Funciona com diferentes tamanhos de mensagem e np.",
                                "Nenhum busy-waiting excessivo (CPU usage razoável)."
                              ],
                              "assessmentCriteria": [
                                "Correção: comunicação assíncrona sem perda ou duplicação de dados.",
                                "Eficiência: demonstra overlap mensurável (>10% ganho).",
                                "Robustez: gerencia múltiplos requests e erros (ex: tags corretos).",
                                "Clareza: código comentado com explicação de requests.",
                                "Escalabilidade: performance mantida com np crescente.",
                                "Debugging: uso apropriado de MPI_Get_count ou status para verificação."
                              ],
                              "crossCurricularConnections": [
                                "Programação Sequencial: Analogia com threads assíncronas (pthreads async).",
                                "Sistemas Operacionais: Conceitos de non-blocking I/O e scheduling de processos.",
                                "Redes de Computadores: Protocolos assíncronos como TCP non-blocking sockets.",
                                "Matemática Computacional: Aplicações em álgebra linear distribuída (BLAS paralelas)."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: modelagem climática no CPTEC/INPE), onde MPI_Isend/Irecv permite overlap de envio de grids de temperatura com computações locais de difusão, reduzindo tempo total em supercomputadores como o Santos Dumont."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "SC-64.1.1.1",
                              "SC-64.1.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "SC-64.1.2",
                        "name": "Broadcast",
                        "description": "Primitiva coletiva para envio de uma mensagem de um processo raiz para todos os outros processos em um comunicador.",
                        "specificSkills": [
                          {
                            "id": "SC-64.1.2.1",
                            "name": "Executar Broadcast Simétrico",
                            "description": "Implementar MPI_Bcast para distribuir dados de um buffer do processo raiz para buffers idênticos em todos os processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar o ambiente MPI",
                                  "subSteps": [
                                    "Incluir a biblioteca MPI: #include <mpi.h>",
                                    "No main(), chamar MPI_Init(&argc, &argv);",
                                    "Obter o número total de processos: int size; MPI_Comm_size(MPI_COMM_WORLD, &size);",
                                    "Obter o rank do processo atual: int rank; MPI_Comm_rank(MPI_COMM_WORLD, &rank);",
                                    "Definir o processo raiz (geralmente rank 0) como variável root = 0;"
                                  ],
                                  "verification": "Executar com mpirun -np 4 e verificar via printf que size e rank são corretos em todos os processos.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal para mpirun"
                                  ],
                                  "tips": [
                                    "Sempre verifique o código de retorno das funções MPI com MPI_SUCCESS.",
                                    "Use MPI_COMM_WORLD para comunicador global."
                                  ],
                                  "learningObjective": "Configurar o ambiente de comunicação paralela com MPI de forma correta e robusta.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes de usar funções MPI.",
                                    "Não declarar variáveis size e rank corretamente.",
                                    "Executar sem mpirun -np N."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar os buffers de dados",
                                  "subSteps": [
                                    "Definir o tamanho do buffer: const int COUNT = 10; int buffer[COUNT];",
                                    "No processo raiz (if(rank == root)): preencher buffer, ex: for(int i=0; i<COUNT; i++) buffer[i] = root * 100 + i;",
                                    "Nos outros processos (else): inicializar com valor sentinela, ex: memset(buffer, -1, sizeof(buffer));",
                                    "Definir variáveis: int count = COUNT; MPI_Datatype datatype = MPI_INT;",
                                    "Imprimir buffer inicial para depuração (apenas primeiro e último elemento)."
                                  ],
                                  "verification": "Compilar e rodar; buffers devem diferir entre raiz e outros processos antes do broadcast.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador MPI",
                                    "Documentação MPI para MPI_Datatype"
                                  ],
                                  "tips": [
                                    "Garanta que todos os buffers tenham o mesmo tamanho e tipo para evitar erros de segmentação.",
                                    "Use memset para inicialização consistente."
                                  ],
                                  "learningObjective": "Preparar dados de forma simétrica em todos os processos, diferenciando raiz e não-raiz.",
                                  "commonMistakes": [
                                    "Buffers de tamanhos diferentes entre processos.",
                                    "Esquecer de incluir <string.h> para memset.",
                                    "Preencher buffer em todos os processos igualmente."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o MPI_Bcast",
                                  "subSteps": [
                                    "Chamar a função: MPI_Bcast(buffer, count, datatype, root, MPI_COMM_WORLD);",
                                    "Verificar o retorno: int err = ...; if(err != MPI_SUCCESS) { printf('Erro: %d\\n', err); }",
                                    "Adicionar barreira se necessário: MPI_Barrier(MPI_COMM_WORLD); para sincronização.",
                                    "Imprimir confirmação de execução em cada rank.",
                                    "Garantir que buffer seja passado como ponteiro (void*)."
                                  ],
                                  "verification": "Após chamada, imprimir buffers; devem ser idênticos em todos os processos.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Documentação oficial MPI para MPI_Bcast",
                                    "Exemplos de código MPI"
                                  ],
                                  "tips": [
                                    "O processo raiz envia, mas todos fornecem buffer de destino.",
                                    "Sempre cheque erros de MPI para depuração."
                                  ],
                                  "learningObjective": "Implementar corretamente a primitiva de broadcast simétrico com todos os parâmetros obrigatórios.",
                                  "commonMistakes": [
                                    "Parâmetros errados: confundir count com sizeof.",
                                    "Passar buffer errado como não-ponteiro.",
                                    "Usar root incorreto."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar resultados e finalizar MPI",
                                  "subSteps": [
                                    "Em todos os processos, imprimir o buffer completo ou checksum: int sum=0; for(i=0;i<count;i++) sum+=buffer[i]; printf('Rank %d sum=%d\\n', rank, sum);",
                                    "Comparar sums entre ranks para validar igualdade.",
                                    "Chamar MPI_Finalize(); no final do main().",
                                    "Compilar: mpicc programa.c -o prog && mpirun -np 4 ./prog.",
                                    "Analisar saída para confirmar distribuição correta."
                                  ],
                                  "verification": "Todos os processos reportam o mesmo sum e buffer idêntico ao do raiz.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Terminal para execução paralela",
                                    "mpirun/mpiexec"
                                  ],
                                  "tips": [
                                    "Use checksums para validação eficiente em buffers grandes.",
                                    "Nunca use MPI após Finalize."
                                  ],
                                  "learningObjective": "Validar a operação de broadcast e encerrar o ambiente MPI corretamente.",
                                  "commonMistakes": [
                                    "Chamar MPI_Finalize antes de verificações.",
                                    "Não sincronizar com barreira se necessário.",
                                    "Ignorar saídas de printf em execuções paralelas."
                                  ]
                                }
                              ],
                              "practicalExample": "Criar um programa MPI que broadcast um array de 10 inteiros do rank 0 (preenchido com valores 100-109) para todos os processos. Cada processo imprime o array recebido e um checksum. Executar com mpirun -np 4; saída deve mostrar arrays idênticos em todos ranks.",
                              "finalVerifications": [
                                "Buffers são idênticos em todos os processos após MPI_Bcast.",
                                "Nenhum código de erro MPI é reportado.",
                                "Programa executa corretamente com 2-8 processos via mpirun -np N.",
                                "Checksums ou somas coincidem entre todos os ranks.",
                                "MPI_Finalize é chamado corretamente sem vazamentos.",
                                "Compilação sem warnings com mpicc."
                              ],
                              "assessmentCriteria": [
                                "Uso correto de todos os parâmetros em MPI_Bcast (buffer, count, datatype, root, comm).",
                                "Verificação de erros em chamadas MPI.",
                                "Preparação diferenciada de buffers (raiz vs. outros).",
                                "Validação de resultados com prints ou checksums em múltiplos processos.",
                                "Código limpo, comentado e segue boas práticas MPI.",
                                "Execução bem-sucedida em ambiente paralelo real."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos Paralelos: Base para scatter, gather e reduce.",
                                "Redes de Computadores: Similar a multicast em protocolos de rede.",
                                "Sistemas Operacionais: Comunicação IPC em clusters distribuídos.",
                                "Matemática Computacional: Distribuição de dados iniciais em simulações.",
                                "Engenharia de Software: Padrões de programação paralela e sincronização."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática com MPI em supercomputadores), distribuição de parâmetros iniciais ou grids de um nó mestre para todos os workers; ou em machine learning distribuído para broadcast de hiperparâmetros em frameworks como Horovod."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "SC-64.1.2.2",
                            "name": "Gerenciar Buffers em Broadcast",
                            "description": "Configurar buffers de envio e recebimento com contadores e tipos de dados compatíveis em MPI_Bcast.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de buffers em MPI_Bcast",
                                  "subSteps": [
                                    "Estude a assinatura da função MPI_Bcast: MPI_Bcast(void* buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm)",
                                    "Identifique que o buffer é compartilhado para envio e recebimento",
                                    "Aprenda que o root fornece os dados e os outros processos alocam espaço equivalente",
                                    "Revise exemplos básicos de MPI_Bcast na documentação oficial",
                                    "Anote diferenças entre buffers em Bcast e outras coletivas como Send/Recv"
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o fluxo de dados do buffer no Bcast",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Documentação MPI oficial",
                                    "Editor de texto para anotações"
                                  ],
                                  "tips": "Sempre consulte MPI_Bcast man page para esclarecer parâmetros",
                                  "learningObjective": "Entender o papel unificado do buffer em operações de broadcast",
                                  "commonMistakes": "Confundir buffer de Bcast com buffers separados de Send/Recv"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar o buffer no processo raiz (root)",
                                  "subSteps": [
                                    "Declare uma variável para o buffer com tamanho conhecido (ex: int buffer[10])",
                                    "Inicialize o buffer com dados no processo raiz usando if (rank == root)",
                                    "Defina count como o número de elementos (ex: 10) e datatype como MPI_INT",
                                    "Compile e execute um código simples apenas no root para testar inicialização",
                                    "Use MPI_Barrier para sincronizar antes do Bcast"
                                  ],
                                  "verification": "Imprima o buffer no root antes do Bcast e confirme valores corretos",
                                  "estimatedTime": "30-40 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Cluster ou multiprocessador local"
                                  ],
                                  "tips": "Use valores iniciais distintos para facilitar depuração",
                                  "learningObjective": "Preparar corretamente o buffer fonte no processo raiz",
                                  "commonMistakes": "Esquecer de inicializar o buffer apenas no root, poluindo dados nos outros"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Alocar e preparar buffers nos processos não-raiz",
                                  "subSteps": [
                                    "Declare o buffer com o mesmo tipo e tamanho em todos os processos",
                                    "Inicialize com valores conhecidos (ex: -1) nos não-raiz para depuração",
                                    "Garanta que count e datatype sejam idênticos ao root",
                                    "Teste alocação dinâmica com MPI_Alloc_mem se necessário para buffers grandes",
                                    "Execute e imprima buffers pós-alocação para verificar espaço"
                                  ],
                                  "verification": "Confirme por impressão que buffers não-raiz estão alocados e inicializados",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Código fonte MPI",
                                    "mpirun para executar com múltiplos processos"
                                  ],
                                  "tips": "Inicialize não-raiz com sentinelas como -999 para detectar sobrescrita",
                                  "learningObjective": "Garantir buffers receptores prontos e compatíveis",
                                  "commonMistakes": "Usar tamanhos ou tipos diferentes, causando MPI_ERR_TYPE ou crashes"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar MPI_Bcast e verificar compatibilidade",
                                  "subSteps": [
                                    "Chame MPI_Bcast(buffer, count, datatype, root, MPI_COMM_WORLD) em todos os processos",
                                    "Imprima buffers em todos os ranks após o Bcast para comparação",
                                    "Teste com diferentes datatypes (MPI_INT, MPI_DOUBLE, MPI_CHAR)",
                                    "Verifique erros com MPI_Finalized e códigos de erro",
                                    "Execute com 2-8 processos para validar broadcast"
                                  ],
                                  "verification": "Todos os processos exibem os mesmos dados do root pós-Bcast",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": [
                                    "Terminal com mpirun",
                                    "Códigos de teste variados"
                                  ],
                                  "tips": "Sempre use MPI_Init e MPI_Finalize corretamente",
                                  "learningObjective": "Executar Bcast com buffers gerenciados corretamente",
                                  "commonMistakes": "Contadores (count) inconsistentes entre processos"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Depurar e otimizar gerenciamento de buffers",
                                  "subSteps": [
                                    "Introduza erros comuns (ex: count errado) e corrija-os",
                                    "Meça performance com buffers grandes vs pequenos",
                                    "Use MPI_Get_count para validar pós-recebimento",
                                    "Teste em topologias diferentes (ex: root=0 vs root=1)",
                                    "Documente lições aprendidas em um relatório curto"
                                  ],
                                  "verification": "Código roda sem erros e performance é consistente",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Profiler MPI como Tau ou Vampir",
                                    "Scripts de teste"
                                  ],
                                  "tips": "Use gdb com mpirun para depuração paralela",
                                  "learningObjective": "Identificar e corrigir problemas em buffers de Bcast",
                                  "commonMistakes": "Ignorar erros de MPI como MPI_ERR_BUFFER ou MPI_ERR_COUNT"
                                }
                              ],
                              "practicalExample": "Em um programa MPI com 4 processos, root=0 tem int buffer[5] = {10,20,30,40,50}, count=5, MPI_INT. Chama MPI_Bcast(buffer,5,MPI_INT,0,MPI_COMM_WORLD). Todos imprimem {10,20,30,40,50} pós-chamada.",
                              "finalVerifications": [
                                "Todos os processos recebem dados idênticos sem erros MPI",
                                "Buffers mantêm integridade com múltiplos Bcasts consecutivos",
                                "Compatibilidade confirmada com datatypes compostos (MPI_Type_struct)",
                                "Sem vazamentos de memória detectados por valgrind",
                                "Performance escalável com aumento de processos",
                                "Root pode ser qualquer rank sem falhas"
                              ],
                              "assessmentCriteria": [
                                "Correta configuração de buffers com count e datatype matching (100%)",
                                "Código executa sem warnings ou erros em 4+ processos",
                                "Explicação clara de fluxos de buffer em Bcast",
                                "Uso de verificações (impressões, MPI_Get_count) para validação",
                                "Identificação e correção de 3+ erros comuns",
                                "Otimização básica para buffers grandes demonstrada"
                              ],
                              "crossCurricularConnections": [
                                "Gerenciamento de memória em C/C++ (alocação dinâmica)",
                                "Programação de redes (protocolos de broadcast UDP)",
                                "Algoritmos distribuídos (consenso em sistemas distribuídos)",
                                "Otimização de performance (cache e alinhamento de dados)"
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: clima ou física de partículas), broadcast de parâmetros globais ou meshes para todos os nós de um cluster, garantindo eficiência e correção em milhares de processos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "SC-64.1.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "SC-64.1.3",
                        "name": "Reduce",
                        "description": "Operação coletiva de redução que aplica uma função associativa e comutativa aos dados de todos os processos, acumulando o resultado no processo raiz.",
                        "specificSkills": [
                          {
                            "id": "SC-64.1.3.1",
                            "name": "Aplicar Reduce com Soma",
                            "description": "Usar MPI_Reduce com MPI_SUM para somar elementos de vetores locais em um vetor global no processo raiz.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar MPI e alocar vetores locais",
                                  "subSteps": [
                                    "Incluir as bibliotecas necessárias: #include <mpi.h> e #include <stdio.h>",
                                    "No main, chamar MPI_Init(&argc, &argv) para inicializar o ambiente MPI",
                                    "Obter o comunicador MPI_COMM_WORLD, o rank do processo com MPI_Comm_rank e o número de processos com MPI_Comm_size",
                                    "Alocar um vetor local (sendbuf) de tamanho fixo, por exemplo, 4 elementos inteiros, usando int local_vec[4]"
                                  ],
                                  "verification": "Executar o programa e verificar via printf que MPI_Init retorna MPI_SUCCESS, rank e size são impressos corretamente em cada processo",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Editor de código (VS Code ou similar)",
                                    "Compilador MPI (mpicc)",
                                    "Terminal para compilação e execução com mpirun"
                                  ],
                                  "tips": "Sempre verifique o código de retorno das funções MPI para depuração precoce",
                                  "learningObjective": "Configurar corretamente o ambiente de programação paralela com MPI e preparar estruturas de dados locais",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes de usar qualquer função MPI",
                                    "Confundir MPI_Comm_rank com MPI_Comm_size",
                                    "Não declarar argc/argv corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preencher e preparar os vetores locais",
                                  "subSteps": [
                                    "Inicializar um gerador de números aleatórios com srand(getpid()) ou valores fixos baseados no rank para dados únicos",
                                    "Preencher o vetor local com valores, por exemplo: local_vec[0] = rank + 1; local_vec[1] = rank + 2; etc.",
                                    "Imprimir o vetor local de cada processo usando if(rank == 0) ou printf com rank para depuração",
                                    "Definir o tamanho do vetor (count = 4) como uma constante para uso posterior"
                                  ],
                                  "verification": "Executar e confirmar que cada processo imprime um vetor local diferente e correto via saída no terminal",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Código fonte do Step 1",
                                    "mpicc para recompilar",
                                    "mpirun -np 4 ./programa para testar com 4 processos"
                                  ],
                                  "tips": "Use valores fixos inicialmente para facilitar a verificação manual dos resultados esperados",
                                  "learningObjective": "Gerar e gerenciar dados locais distribuídos de forma consistente em processos paralelos",
                                  "commonMistakes": [
                                    "Usar o mesmo seed em todos os processos resultando em dados idênticos",
                                    "Não imprimir com rank para distinguir saídas de processos",
                                    "Definir count incorretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar MPI_Reduce com MPI_SUM",
                                  "subSteps": [
                                    "Alocar o vetor de recepção (recvbuf) apenas no processo raiz (root=0): int global_vec[4]; se rank==0",
                                    "Chamar MPI_Reduce(local_vec, rank==0 ? global_vec : NULL, count, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD)",
                                    "Verificar o código de retorno da MPI_Reduce para garantir sucesso (MPI_SUCCESS)",
                                    "Garantir que processos não-raiz passem NULL para recvbuf para evitar alocações desnecessárias"
                                  ],
                                  "verification": "Compilar e executar; no processo raiz, adicionar printf para mostrar global_vec e confirmar somas parciais",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código fonte atualizado",
                                    "Documentação MPI para MPI_Reduce (mpi-forum.org)",
                                    "mpirun para execução paralela"
                                  ],
                                  "tips": "Lembre-se: recvbuf é NULL em não-raiz; use MPI_IN_PLACE se quiser otimizar, mas evite por simplicidade inicial",
                                  "learningObjective": "Aplicar corretamente a primitiva de redução coletiva MPI_Reduce para soma paralela",
                                  "commonMistakes": [
                                    "Passar recvbuf não-NULL em não-raiz causando erros de segmentação",
                                    "Usar tipo de dado errado (ex: MPI_FLOAT em vez de MPI_INT)",
                                    "Especificar root incorreto ou op errado (MPI_SUM)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar resultados no processo raiz e finalizar",
                                  "subSteps": [
                                    "No processo raiz (if(rank==0)), imprimir o vetor global e calcular soma total para validação",
                                    "Comparar soma global esperada (soma de todos locais) com resultado obtido",
                                    "Chamar MPI_Finalize() no final de todos os processos",
                                    "Adicionar MPI_Barrier(MPI_COMM_WORLD) antes de finalize se necessário para sincronização"
                                  ],
                                  "verification": "Executar com mpirun -np 4 e confirmar que apenas o raiz imprime global_vec correto e soma bate com expectativa manual",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Código completo",
                                    "mpicc e mpirun",
                                    "Calculadora para verificar soma esperada manualmente"
                                  ],
                                  "tips": "Teste com np=2 primeiro para depuração antes de mais processos",
                                  "learningObjective": "Coletar, validar e finalizar corretamente operações de redução paralela",
                                  "commonMistakes": [
                                    "Imprimir global_vec em todos os processos (undefined em não-raiz)",
                                    "Esquecer MPI_Finalize causando hang",
                                    "Não sincronizar antes de finalize"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere 4 processos (ranks 0-3), cada um com vetor local [rank+1, rank+2, rank+3, rank+4]. Após MPI_Reduce com MPI_SUM no root=0, global_vec = [10, 14, 18, 22] (somas: 1+2+3+4=10, etc.). Raiz imprime e verifica soma total=64.",
                              "finalVerifications": [
                                "Programa compila sem erros com mpicc",
                                "Executa sem crashes com mpirun -np 4",
                                "Processo raiz recebe vetor global com somas corretas de todos elementos locais",
                                "Soma total do vetor global matches soma esperada calculada manualmente",
                                "Nenhum processo não-raiz tenta acessar recvbuf",
                                "MPI_Finalize é chamado corretamente sem hangs"
                              ],
                              "assessmentCriteria": [
                                "Código usa MPI_Reduce com parâmetros corretos (MPI_SUM, root=0, tipo MPI_INT)",
                                "Gerenciamento correto de buffers: local em todos, global só no raiz",
                                "Verificação de retornos de funções MPI",
                                "Saída imprime resultados apenas no raiz com valores exatos esperados",
                                "Código limpo, comentado e indentado corretamente",
                                "Funciona escalável para diferentes np (testado com 2 e 4 processos)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Operações vetoriais e redução de somas em álgebra linear",
                                "Algoritmos e Estruturas de Dados: Padrões de redução em programação paralela e MapReduce",
                                "Computação de Alto Desempenho: Primitivas coletivas em HPC e supercomputação",
                                "Engenharia de Software: Gerenciamento de memória distribuída e depuração paralela"
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática ou física de partículas, onde cada processo computa contribuições locais (ex: forças em células) e MPI_Reduce soma para estatísticas globais como energia total do sistema."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "SC-64.1.3.2",
                            "name": "Implementar Reduce com Operações Customizadas",
                            "description": "Definir e aplicar operações de redução personalizadas com MPI_Op_create para funções como máximo, mínimo ou produto.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender e Definir a Função de Redução Customizada",
                                  "subSteps": [
                                    "Estude a assinatura da função de redução: void op(void *invec, void *inoutvec, int *len, MPI_Datatype *datatype)",
                                    "Implemente uma operação personalizada, como máximo com índice: combine valor máximo e rank do processo",
                                    "Garanta que a operação seja associativa e comutativa, conforme requisitos do MPI",
                                    "Teste a função localmente com dados simples em uma função main isolada",
                                    "Defina tipos de dados compatíveis, como float para valores e int para ranks"
                                  ],
                                  "verification": "Chame a função com vetores de teste e verifique se o resultado é o máximo com o rank correto via printf",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação MPI_Reduce e MPI_Op_create",
                                    "Editor de código (VS Code ou similar)",
                                    "Compilador C local"
                                  ],
                                  "tips": "Comece com uma operação simples como máximo; use structs para combinar valor e índice",
                                  "learningObjective": "Compreender a interface de uma operação de redução MPI e implementá-la corretamente",
                                  "commonMistakes": [
                                    "Ignorar a associatividade, levando a resultados inconsistentes",
                                    "Não tratar len corretamente para vetores",
                                    "Modificar invec incorretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Registrar a Operação Customizada com MPI_Op_create",
                                  "subSteps": [
                                    "Inclua os headers necessários: #include <mpi.h>",
                                    "Defina a função op como static para visibilidade",
                                    "Chame MPI_Op_create(&op, 1, &my_max_op) após MPI_Init, passando commutable=1",
                                    "Verifique o código de erro retornado por MPI_Op_create",
                                    "Armazene o handle MPI_Op em uma variável global ou passe para funções"
                                  ],
                                  "verification": "Execute um programa mínimo que cria o Op e chama MPI_Op_free no final; confira logs sem erros",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código template MPI básico",
                                    "mpicc compilador",
                                    "Documentação MPI_Op_create"
                                  ],
                                  "tips": "Use MPI_COMM_WORLD como communicator; sempre libere com MPI_Op_free antes de MPI_Finalize",
                                  "learningObjective": "Saber registrar e gerenciar operações customizadas de forma segura",
                                  "commonMistakes": [
                                    "Chamar MPI_Op_create antes de MPI_Init",
                                    "Esquecer MPI_Op_free causando vazamentos",
                                    "Passar commutable=0 para operações comutativas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Reduce com a Operação Customizada",
                                  "subSteps": [
                                    "Inicialize MPI e obtenha rank e size com MPI_Comm_rank e MPI_Comm_size",
                                    "Crie buffers de envio e recebimento usando structs {float value; int rank;}",
                                    "Preencha buffer local com valor gerado pelo rank (ex: valor = rank * 10.0)",
                                    "Chame MPI_Reduce(sendbuf, recvbuf, 1, MPI_FLOAT_INT, my_max_op, 0, MPI_COMM_WORLD) – defina datatype customizado se necessário",
                                    "No processo root (rank 0), imprima o resultado recebido"
                                  ],
                                  "verification": "Execute com mpirun -np 4 e confirme que root recebe o máximo valor com rank correto",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "mpirun ou ambiente cluster",
                                    "Código dos steps anteriores",
                                    "Struct definitions para datatype"
                                  ],
                                  "tips": "Defina MPI_Datatype customizado com MPI_Type_create_struct se usar structs compostos",
                                  "learningObjective": "Integrar operação customizada em MPI_Reduce para computação coletiva",
                                  "commonMistakes": [
                                    "Usar datatype incorreto (ex: MPI_FLOAT em vez de custom)",
                                    "Não inicializar buffers corretamente",
                                    "Chamar Reduce sem root válido"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, Depurar e Verificar o Programa Completo",
                                  "subSteps": [
                                    "Compile com mpicc -o reduce_custom reduce_custom.c",
                                    "Execute com diferentes np (2,4,8) e valores seed variados",
                                    "Adicione prints em processos para rastrear valores parciais",
                                    "Use MPI_Barrier se necessário para sincronização de debug",
                                    "Compare resultados com implementação sequencial para validação"
                                  ],
                                  "verification": "Resultados consistentes em múltiplas runs; sem deadlocks ou crashes",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Ambiente MPI instalado (OpenMPI/MPICH)",
                                    "Valgrind para memory leaks (opcional)",
                                    "Scripts de teste"
                                  ],
                                  "tips": "Use gdb com mpirun --oversubscribe para debug multi-processo",
                                  "learningObjective": "Garantir robustez e corretude em programas MPI com reduces customizados",
                                  "commonMistakes": [
                                    "Deadlocks por prints desbalanceados",
                                    "Não tratar erros de MPI calls",
                                    "Escala mal com np alto sem otimização"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 4 nós simulando sensores IoT, cada processo gera temperatura (rank * 20.5 + rand()), use reduce customizado para encontrar a temperatura máxima e o ID do sensor (rank) que a reportou, enviando ao nó root para alerta de superaquecimento.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros com mpirun -np 4+",
                                "Root recebe corretamente o máximo valor e seu rank original",
                                "Resultados idênticos em execuções repetidas com mesmas seeds",
                                "MPI_Op_free é chamado antes de MPI_Finalize",
                                "Nenhum memory leak detectado (valgrind)",
                                "Funciona com diferentes datatypes e tamanhos de len"
                              ],
                              "assessmentCriteria": [
                                "Função op implementada corretamente e associativa",
                                "Uso preciso de MPI_Op_create com parâmetros corretos",
                                "Integração seamless em MPI_Reduce com buffers adequados",
                                "Tratamento de erros MPI em todas as chamadas",
                                "Código limpo, comentado e escalável",
                                "Verificações finais passam em testes multi-nós"
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos: Reduções em divide-and-conquer e árvores de soma",
                                "Matemática: Operações associativas/comutativas em álgebra abstrata",
                                "Programação Funcional: Conceito de fold/reduce em linguagens como Haskell",
                                "Engenharia de Software: Abstrações e extensibilidade de APIs",
                                "Big Data: Reduções em MapReduce (Hadoop/Spark)"
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática com MPI em supercomputadores), reduzindo estatísticas globais como máximo de pressão atmosférica de grids distribuídos; ou em processamento de dados paralelos para encontrar picos em sinais de sensores industriais."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "SC-64.1.3.1"
                            ]
                          },
                          {
                            "id": "SC-64.1.3.3",
                            "name": "Combinar Reduce com Allreduce",
                            "description": "Implementar MPI_Allreduce para que todos os processos obtenham o resultado da redução, comparando com MPI_Reduce.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o funcionamento do MPI_Reduce",
                                  "subSteps": [
                                    "Relembre a sintaxe de MPI_Reduce: MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm)",
                                    "Entenda que apenas o processo root recebe o resultado da redução",
                                    "Identifique cenários onde MPI_Reduce é útil, como agregação de dados em um líder",
                                    "Compile e execute um código simples de soma usando MPI_Reduce",
                                    "Observe que apenas o root imprime o resultado total"
                                  ],
                                  "verification": "Execute o código e confirme que apenas o processo root exibe o resultado da redução",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Ambiente MPI instalado (OpenMPI ou MPICH), editor de código (VS Code ou similar), terminal para mpirun",
                                  "tips": "Use MPI_SUM como operação inicial para soma simples",
                                  "learningObjective": "Compreender as limitações do MPI_Reduce em termos de distribuição de resultados",
                                  "commonMistakes": "Esquecer de inicializar MPI com MPI_Init ou finalizar com MPI_Finalize; usar root inválido"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar um exemplo prático com MPI_Reduce",
                                  "subSteps": [
                                    "Crie um programa onde cada processo gera um valor local (ex: rank * 10)",
                                    "Use MPI_Reduce para somar todos os valores no root (processo 0)",
                                    "Adicione prints no root para mostrar o resultado global",
                                    "Teste com 4 processos: mpirun -np 4 ./programa",
                                    "Meça o tempo de execução com MPI_Wtime"
                                  ],
                                  "verification": "Confirme que o root imprime a soma correta (ex: para ranks 0-3, soma=60) e outros processos não",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código base de MPI_Reduce, compilador MPI (mpicc), máquina com múltiplos cores",
                                  "tips": "Inicialize sendbuf com valores locais únicos para depuração fácil",
                                  "learningObjective": "Aplicar MPI_Reduce em um cenário de agregação de dados distribuídos",
                                  "commonMistakes": "Não alocar buffers corretos com MPI_Type_size; confundir sendbuf e recvbuf"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir e implementar MPI_Allreduce",
                                  "subSteps": [
                                    "Estude a sintaxe de MPI_Allreduce: similar ao Reduce, mas sem root, todos recebem recvbuf",
                                    "Modifique o código anterior: substitua MPI_Reduce por MPI_Allreduce",
                                    "Adicione prints em todos os processos para mostrar o resultado global",
                                    "Compile e execute novamente com o mesmo número de processos",
                                    "Verifique se todos os processos exibem o mesmo resultado"
                                  ],
                                  "verification": "Todos os processos imprimem a soma correta e idêntica",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Código modificado do Step 2, documentação MPI (man MPI_Allreduce)",
                                  "tips": "Use o mesmo recvbuf alocado para todos, pois é preenchido coletivamente",
                                  "learningObjective": "Dominar MPI_Allreduce para sincronização coletiva de resultados",
                                  "commonMistakes": "Esquecer que MPI_Allreduce bloqueia até todos participarem; usar operação incompatível"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar MPI_Reduce e MPI_Allreduce",
                                  "subSteps": [
                                    "Meça tempos de execução de ambos em diferentes tamanhos de dados (aumente count)",
                                    "Analise overhead: Allreduce tipicamente mais lento devido à difusão",
                                    "Discuta trade-offs: Reduce para hierarquias, Allreduce para peers iguais",
                                    "Implemente um benchmark simples com loops de repetição",
                                    "Documente diferenças em um relatório curto"
                                  ],
                                  "verification": "Gráfico ou tabela mostrando tempos, com Allreduce consistentemente mais lento em ~20-50%",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Ferramentas de plotagem (Python matplotlib ou Excel), dados de timing",
                                  "tips": "Use MPI_Barrier para isolação precisa de tempos",
                                  "learningObjective": "Avaliar quando usar cada primitiva com base em performance e requisitos",
                                  "commonMistakes": "Ignorar sincronização antes de prints; testar em np=1 (sem paralelismo)"
                                }
                              ],
                              "practicalExample": "Em um programa de simulação Monte Carlo distribuída, cada processo calcula parcial soma de π; use MPI_Reduce para relatório final no root, ou MPI_Allreduce para que todos ajustem estimativas localmente em iterações subsequentes.",
                              "finalVerifications": [
                                "Todos os processos obtêm e imprimem o mesmo resultado da redução com MPI_Allreduce",
                                "Código compila sem warnings com mpicc -Wall",
                                "Testes com 2, 4 e 8 processos produzem resultados consistentes",
                                "Tempos de execução medidos mostram diferenças esperadas entre Reduce e Allreduce",
                                "Nenhum deadlock ou perda de mensagens em execuções múltiplas",
                                "Uso correto de MPI_Init, MPI_Finalize e handles de communicator"
                              ],
                              "assessmentCriteria": [
                                "Correção funcional: resultados idênticos em todos processos para Allreduce",
                                "Eficiência: tempos razoáveis e análise comparativa precisa",
                                "Robustez: código lida com diferentes np e tamanhos de dados",
                                "Clareza: comentários explicando diferenças entre primitivas",
                                "Documentação: prints informativos e verificações integradas",
                                "Boas práticas: alocação dinâmica de buffers, tratamento de erros MPI"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Operações associativas e comutativas em reduções (álgebra linear)",
                                "Algoritmos: Padrões de coleta/difusão em grafos distribuídos",
                                "Redes de Computadores: Latência e largura de banda em coletivas MPI",
                                "Engenharia de Software: Abstrações para paralelismo portável"
                              ],
                              "realWorldApplication": "Em treinamento distribuído de redes neurais (ex: TensorFlow com Horovod), MPI_Allreduce sincroniza gradientes médios entre GPUs para convergência otimizada em supercomputadores."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "SC-64.1.3.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "SC-64.1.4",
                        "name": "Combinação de Primitivas",
                        "description": "Integração de send/receive, broadcast e reduce em fluxos de programação paralela para memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "SC-64.1.4.1",
                            "name": "Desenvolver Programa com Múltiplas Primitivas",
                            "description": "Criar um programa MPI que combine send/receive para dados privados, broadcast para parâmetros globais e reduce para agregação de resultados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente MPI e inicializar o comunicador",
                                  "subSteps": [
                                    "Instalar ou verificar a instalação do MPI (ex: OpenMPI ou MPICH)",
                                    "Criar um arquivo fonte C/C++ e incluir <mpi.h>",
                                    "Implementar MPI_Init(&argc, &argv) no início do main",
                                    "Obter o número de processos com MPI_Comm_size(MPI_COMM_WORLD, &size)",
                                    "Obter o rank do processo atual com MPI_Comm_rank(MPI_COMM_WORLD, &rank)"
                                  ],
                                  "verification": "Compilar com mpicc e executar com mpirun -np 4 ./programa para ver saídas de rank e size corretas",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal com MPI instalado"
                                  ],
                                  "tips": "Sempre inicialize argc e argv corretamente para passagem de argumentos",
                                  "learningObjective": "Dominar a inicialização básica do ambiente MPI e identificação de processos",
                                  "commonMistakes": [
                                    "Esquecer de incluir mpi.h",
                                    "Não chamar MPI_Init antes de qualquer chamada MPI",
                                    "Confundir MPI_COMM_WORLD"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar broadcast para distribuição de parâmetros globais",
                                  "subSteps": [
                                    "Definir uma variável global (ex: int N = 1000; no processo raiz, rank 0)",
                                    "Chamar MPI_Bcast(&N, 1, MPI_INT, 0, MPI_COMM_WORLD) no raiz e todos os processos",
                                    "Verificar o valor de N em todos os processos com printf",
                                    "Tratar erros de retorno da função MPI_Bcast",
                                    "Testar com diferentes valores de N"
                                  ],
                                  "verification": "Executar o programa e confirmar que todos os processos imprimem o mesmo valor de N",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código do Step 1",
                                    "Documentação MPI_Bcast"
                                  ],
                                  "tips": "O root especifica o processo que envia (geralmente rank 0); todos devem chamar a função",
                                  "learningObjective": "Entender e aplicar broadcast para sincronizar dados comuns a todos os processos",
                                  "commonMistakes": [
                                    "Chamar Bcast apenas no root",
                                    "Tipo de dado incorreto no MPI_Type",
                                    "Esquecer de incluir tamanho do buffer"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar send/receive para troca de dados privados entre processos",
                                  "subSteps": [
                                    "Gerar dados locais privados em cada processo (ex: double local_data[10])",
                                    "No processo 0: MPI_Send(local_data, 10, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD)",
                                    "No processo 1: MPI_Recv(local_data, 10, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &status)",
                                    "Implementar troca bidirecional ou em pares de processos",
                                    "Verificar status.MPI_ERROR e tag da mensagem"
                                  ],
                                  "verification": "Imprimir dados recebidos e confirmar que correspondem aos enviados pelo par correto",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código anterior",
                                    "MPI_Status estrutura",
                                    "Documentação MPI_Send/Recv"
                                  ],
                                  "tips": "Use tags diferentes para mensagens distintas; sempre alinhe send e recv",
                                  "learningObjective": "Aplicar comunicação ponto-a-ponto para dados não compartilhados",
                                  "commonMistakes": [
                                    "Deadlock por ordem errada de send/recv",
                                    "Tamanhos de buffer mismatch",
                                    "Tag ou destino incorreto"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar reduce para agregação de resultados locais",
                                  "subSteps": [
                                    "Preparar array de resultados locais (ex: double local_sum = calcular_local() em cada processo)",
                                    "Definir array global_sum no processo raiz",
                                    "Chamar MPI_Reduce(&local_sum, &global_sum, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD)",
                                    "No não-raiz: passar NULL ou buffer temporário",
                                    "Imprimir global_sum apenas no rank 0"
                                  ],
                                  "verification": "Comparar global_sum com soma manual sequencial para validar",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código completo até aqui",
                                    "Documentação MPI_Reduce e operações como MPI_SUM"
                                  ],
                                  "tips": "Escolha a operação correta (SUM, MAX, etc.); raiz recebe o resultado",
                                  "learningObjective": "Coletar e agregar dados de múltiplos processos de forma eficiente",
                                  "commonMistakes": [
                                    "Usar buffer errado no não-raiz",
                                    "Operação MPI incorreta",
                                    "Esquecer de inicializar locals"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Finalizar o programa, compilar e testar completamente",
                                  "subSteps": [
                                    "Adicionar MPI_Finalize() no final do main",
                                    "Compilar com mpicc -o programa programa.c -lm",
                                    "Executar com mpirun -np 4 -hostfile hosts ./programa",
                                    "Testar com 2, 4 e 8 processos",
                                    "Debugar com mpirun -np 4 valgrind ./programa ou gdb"
                                  ],
                                  "verification": "Programa executa sem vazamentos, resultados escalam corretamente com np",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código final",
                                    "Valgrind ou debugger",
                                    "Hosts file para multi-nó opcional"
                                  ],
                                  "tips": "Sempre finalize para liberar recursos; use -hostfile para testes distribuídos",
                                  "learningObjective": "Garantir ciclo completo de vida do programa MPI",
                                  "commonMistakes": [
                                    "Esquecer MPI_Finalize causando hangs",
                                    "Não tratar múltiplos nós",
                                    "Ignorar warnings de compilação"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa MPI para aproximação de Pi via Monte Carlo: Processo 0 broadcast N (itercções); cada processo gera pontos locais aleatórios e envia estatísticas privadas para rank 1 via send/recv; todos reduzem a soma de acertos com MPI_Reduce no rank 0, computando Pi = 4 * (acertos/N_total).",
                              "finalVerifications": [
                                "Programa compila e executa com mpirun -np X sem erros ou deadlocks",
                                "Broadcast distribui N igualmente a todos os processos",
                                "Send/recv trocam dados privados corretamente entre pares",
                                "Reduce agrega resultados com precisão numérica esperada",
                                "Escalabilidade: tempo diminui com mais processos",
                                "MPI_Finalize é chamado e recursos liberados"
                              ],
                              "assessmentCriteria": [
                                "Correto uso de MPI_Bcast com root, tipo e tamanho adequados",
                                "Implementação sem deadlocks em send/recv com tags e status",
                                "MPI_Reduce com operação SUM e coleta no root",
                                "Tratamento de erros em todas as chamadas MPI",
                                "Código limpo, comentado e modular",
                                "Validação numérica dos resultados agregados"
                              ],
                              "crossCurricularConnections": [
                                "Matemática Computacional: Métodos numéricos paralelizáveis",
                                "Redes de Computadores: Protocolos de comunicação distribuída",
                                "Algoritmos e Estruturas de Dados: Agregação e sincronização",
                                "Engenharia de Software: Desenvolvimento e depuração distribuída",
                                "Big Data: Processamento paralelo em clusters"
                              ],
                              "realWorldApplication": "Desenvolvimento de simulações científicas em supercomputadores (ex: modelagem climática no CPTEC), treinamento distribuído de modelos de ML em clusters Hadoop/Spark, ou processamento de dados em tempo real em sistemas HPC para finanças e bioinformática."
                            },
                            "estimatedTime": "4 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "SC-64.1.1.3",
                              "SC-64.1.2.2",
                              "SC-64.1.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.3",
                    "name": "Decomposição de Domínio",
                    "description": "Técnica de divisão do problema computacional em subdomínios independentes para distribuição em memória distribuída.",
                    "individualConcepts": [
                      {
                        "id": "10.1.2.3.1",
                        "name": "Princípios Fundamentais da Decomposição de Domínio",
                        "description": "Conceitos básicos que definem a decomposição de domínio como técnica para dividir problemas computacionais em subdomínios independentes, adequados para sistemas de memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.3.1.1",
                            "name": "Definir decomposição de domínio",
                            "description": "Explicar a decomposição de domínio como a divisão de um problema em subdomínios espaciais ou lógicos independentes, mapeados para processos em memória distribuída, minimizando dependências.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito Fundamental de Decomposição de Domínio",
                                  "subSteps": [
                                    "Leia definições padrão de decomposição de domínio em livros de programação paralela.",
                                    "Identifique que decomposição de domínio divide o problema em partes menores independentes.",
                                    "Anote exemplos iniciais de problemas que podem ser decompostos, como matrizes ou simulações.",
                                    "Compare com decomposição de tarefas para destacar diferenças.",
                                    "Resuma em suas palavras o que significa 'domínio' no contexto de problemas computacionais."
                                  ],
                                  "verification": "Escreva uma definição de 100 palavras e compare com fontes confiáveis para precisão.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Introduction to Parallel Computing' de Grama et al.",
                                    "Artigos online sobre MPI e decomposição",
                                    "Bloco de notas"
                                  ],
                                  "tips": "Use analogias como dividir um mapa em regiões para visualizar melhor.",
                                  "learningObjective": "Definir decomposição de domínio e diferenciá-la de outros métodos de paralelização.",
                                  "commonMistakes": [
                                    "Confundir com decomposição de tarefas",
                                    "Ignorar o aspecto espacial/lógico",
                                    "Pensar que todas as partes devem ser iguais em tamanho"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diferenciar Subdomínios Espaciais e Lógicos",
                                  "subSteps": [
                                    "Estude exemplos de decomposição espacial: grids 1D, 2D ou 3D em simulações.",
                                    "Analise decomposição lógica: divisão por dados ou funcionalidades independentes.",
                                    "Desenhe diagramas comparando ambos os tipos para um problema como multiplicação de matrizes.",
                                    "Liste vantagens e desvantagens de cada tipo em memória distribuída.",
                                    "Crie um fluxograma mostrando quando usar cada um."
                                  ],
                                  "verification": "Crie dois diagramas e explique oralmente ou por escrito as diferenças.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Ferramenta de desenho como Draw.io",
                                    "Tutoriais de decomposição em YouTube",
                                    "Papel e caneta"
                                  ],
                                  "tips": "Comece com problemas 2D simples para visualizar facilmente.",
                                  "learningObjective": "Classificar e exemplificar subdomínios espaciais versus lógicos.",
                                  "commonMistakes": [
                                    "Assumir que espacial é sempre melhor",
                                    "Não considerar balanceamento de carga",
                                    "Misturar conceitos de domínio com threads"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Mapear Subdomínios para Processos em Memória Distribuída",
                                  "subSteps": [
                                    "Revise conceitos de memória distribuída e comunicação via mensagens (MPI).",
                                    "Aprenda a atribuir subdomínios a processos, considerando topologias de rede.",
                                    "Implemente um mapeamento simples em pseudocódigo para um grid 2D.",
                                    "Simule alocação de dados locais por processo.",
                                    "Teste com um exemplo pequeno para verificar independência."
                                  ],
                                  "verification": "Escreva pseudocódigo funcional e execute mentalmente para 4 processos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação MPI oficial",
                                    "Editor de código como VS Code",
                                    "Exemplos de código em GitHub"
                                  ],
                                  "tips": "Use ranks de processos para numerar subdomínios sistematicamente.",
                                  "learningObjective": "Mapear subdomínios a processos, garantindo dados locais minimizem comunicação.",
                                  "commonMistakes": [
                                    "Ignorar overhead de comunicação",
                                    "Mapeamento desbalanceado",
                                    "Esquecer ghost cells em domínios espaciais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Minimizar Dependências e Avaliar Benefícios",
                                  "subSteps": [
                                    "Identifique dependências residuais e técnicas para reduzi-las (ex: overlapping).",
                                    "Calcule métricas como granularidade e balanceamento de carga.",
                                    "Compare desempenho sequencial vs paralelo em um exemplo teórico.",
                                    "Discuta escalabilidade em grandes clusters.",
                                    "Documente trade-offs em um relatório curto."
                                  ],
                                  "verification": "Produza um relatório de 1 página com cálculos e conclusões.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Calculadora ou planilha Excel",
                                    "Slides de aulas sobre performance paralela",
                                    "Ferramentas de profiling como TAU (opcional)"
                                  ],
                                  "tips": "Foquem em AIM (Arithmetic Intensity) para priorizar computação sobre comunicação.",
                                  "learningObjective": "Otimizar decomposição minimizando dependências e maximizando independência.",
                                  "commonMistakes": [
                                    "Subestimar comunicações em bordas",
                                    "Não balancear workloads",
                                    "Confundir independência lógica com ausência total de sync"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de propagação de calor em uma placa 2D (grid 1000x1000), divida o grid em 4 subdomínios espaciais quadrados, mapeie cada um para um processo MPI, use ghost cells nas bordas para trocar dados mínimos, permitindo computação independente local.",
                              "finalVerifications": [
                                "Definição precisa de decomposição de domínio fornecida verbalmente.",
                                "Diagrama de mapeamento para exemplo prático criado corretamente.",
                                "Explicação clara de minimização de dependências demonstrada.",
                                "Diferenças entre espacial e lógico exemplificadas.",
                                "Métricas de balanceamento calculadas para um caso teste.",
                                "Pseudocódigo de mapeamento validado sem erros lógicos."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (30%): Definição e termos corretos.",
                                "Clareza de explicação (20%): Linguagem acessível e lógica.",
                                "Uso de exemplos (20%): Relevância e concretude.",
                                "Profundidade técnica (15%): Cobertura de mapeamento e dependências.",
                                "Criatividade em diagramas (10%): Visualizações eficazes.",
                                "Análise de trade-offs (5%): Identificação de prós/contras."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Divisão de domínios em geometria computacional e álgebra linear.",
                                "Física: Modelagem de fenômenos espaciais como difusão ou fluidos.",
                                "Engenharia de Software: Design de sistemas distribuídos e escaláveis.",
                                "Ciência de Dados: Particionamento de dados em big data frameworks como Spark."
                              ],
                              "realWorldApplication": "Usado em simulações climáticas (dividindo o globo em grids regionais para supercomputadores), processamento de imagens em paralelo (sub-regiões de pixels) e jogos multiplayer (divisão lógica de mundo virtual por servidores)."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.1.2",
                            "name": "Identificar independência de subdomínios",
                            "description": "Reconhecer características de subdomínios independentes, como ausência de dependências diretas de dados, facilitando distribuição em arquiteturas de memória distribuída conforme taxonomia de Flynn.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de Decomposição de Domínio",
                                  "subSteps": [
                                    "Estude a decomposição de domínio como divisão do problema em subdomínios espaciais ou lógicos.",
                                    "Revise a taxonomia de Flynn, focando em arquiteturas MIMD com memória distribuída.",
                                    "Entenda que independência significa ausência de comunicação direta entre subdomínios.",
                                    "Analise exemplos simples de domínios acoplados vs. desacoplados.",
                                    "Anote definições chave em um glossário pessoal."
                                  ],
                                  "verification": "Crie um mapa mental conectando decomposição de domínio à taxonomia de Flynn com pelo menos 5 nós.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Slides ou PDF sobre taxonomia de Flynn, vídeo introdutório de programação paralela (ex: YouTube ou MIT OpenCourseWare).",
                                  "tips": "Use analogias como 'ilhas independentes' para visualizar subdomínios sem pontes de dados.",
                                  "learningObjective": "Compreender os pilares teóricos que suportam a identificação de independência.",
                                  "commonMistakes": "Confundir independência de dados com independência computacional; sempre verifique dependências de entrada/saída."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Mapear Dependências em um Domínio de Exemplo",
                                  "subSteps": [
                                    "Escolha um problema de domínio, como simulação de fluidos ou grade 2D.",
                                    "Desenhe um grafo de dependências marcando fluxos de dados entre pontos.",
                                    "Classifique arestas como 'diretas' (leitura/escrita compartilhada) ou 'indiretas' (via mensagens).",
                                    "Identifique subdomínios com grau zero de dependência direta.",
                                    "Documente o grafo em papel ou ferramenta como Draw.io."
                                  ],
                                  "verification": "Gere um grafo onde subdomínios independentes sejam isolados (sem arestas conectadas).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Papel/graph paper, software de diagramação (Draw.io ou Graphviz), exemplo de código de simulação simples em Python.",
                                  "tips": "Comece com grades pequenas (4x4) para visualizar dependências facilmente.",
                                  "learningObjective": "Desenvolver habilidade para visualizar e quantificar acoplamentos de dados.",
                                  "commonMistakes": "Ignorar dependências temporais; considere o ciclo de iteração completo."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir e Reconhecer Critérios de Independência",
                                  "subSteps": [
                                    "Liste características: ausência de leitura/escrita compartilhada, computação autônoma, fronteiras sem overlap de dados.",
                                    "Aplique critérios a subdomínios mapeados no passo anterior.",
                                    "Compare com taxonomia de Flynn: independência facilita MIMD distribuído.",
                                    "Crie uma checklist de 5 itens para validação rápida.",
                                    "Teste a checklist em 2 exemplos variados."
                                  ],
                                  "verification": "Preencha a checklist para um subdomínio e justifique 'independente' ou 'dependente' com evidências.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Checklist template (Google Docs), artigos sobre decomposição de domínio (ex: IEEE papers).",
                                  "tips": "Use cores no grafo: verde para independente, vermelho para dependente.",
                                  "learningObjective": "Estabelecer critérios padronizados para reconhecimento preciso.",
                                  "commonMistakes": "Considerar independência estática apenas; avalie dinamicamente em loops."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar Identificação em Cenários Complexos",
                                  "subSteps": [
                                    "Selecione um caso real, como decomposição em CFD (Computational Fluid Dynamics).",
                                    "Aplique grafo + checklist para identificar subdomínios independentes.",
                                    "Simule distribuição: atribua subdomínios a nós sem comunicação extra.",
                                    "Avalie overhead de distribuição e otimizações.",
                                    "Registre achados em relatório curto."
                                  ],
                                  "verification": "Produza um plano de distribuição com 80% de subdomínios independentes identificados corretamente.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Código de exemplo em MPI (Message Passing Interface), simulador online de grades.",
                                  "tips": "Integre ferramentas como ParMETIS para validação automática de partições.",
                                  "learningObjective": "Aplicar conhecimento em contextos reais para consolidação.",
                                  "commonMistakes": "Superestimar independência em bordas; sempre cheque ghost cells ou halos."
                                }
                              ],
                              "practicalExample": "Em uma simulação de Monte Carlo para estimativa de Pi, subdomínios são amostras independentes de pontos aleatórios em um quadrado unitário; cada subdomínio gera pontos sem acessar dados de outros, permitindo distribuição trivial em cluster MIMD sem MPI para dados principais.",
                              "finalVerifications": [
                                "Lista corretamente 4 características de subdomínios independentes.",
                                "Mapeia dependências em um grafo de exemplo sem erros.",
                                "Aplica checklist a novo domínio com acurácia >90%.",
                                "Explica ligação com taxonomia de Flynn em parágrafo coerente.",
                                "Propõe distribuição válida para 3 subdomínios independentes.",
                                "Identifica limitações em cenários com 20% de dependências residuais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de independência (sem falsos positivos/negativos).",
                                "Completude do mapeamento de dependências (cobertura >95%).",
                                "Clareza na justificativa teórica e prática.",
                                "Criatividade em exemplos e conexões com Flynn.",
                                "Eficiência temporal na aplicação (dentro de estimados).",
                                "Profundidade nos substeps e verificações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Teoria de Grafos para modelagem de dependências.",
                                "Física: Simulações numéricas em dinâmica de fluidos ou partículas.",
                                "Engenharia de Software: Design de sistemas distribuídos e escalabilidade.",
                                "Ciência de Dados: Particionamento de dados em big data frameworks como Spark."
                              ],
                              "realWorldApplication": "Em supercomputação para simulações climáticas (ex: modelos ECMWF), identificar subdomínios independentes permite escalar para milhares de nós em clusters HPC sem gargalos de comunicação, reduzindo tempo de simulação de dias para horas."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.1.3",
                            "name": "Relacionar com modelos de memória distribuída",
                            "description": "Associar decomposição de domínio aos modelos de programação paralela baseados em troca de mensagens, diferenciando de memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de Decomposição de Domínio",
                                  "subSteps": [
                                    "Defina decomposição de domínio como a divisão do problema em subdomínios independentes baseados no espaço de dados.",
                                    "Identifique tipos de decomposição: geométrica, funcional e de dados.",
                                    "Explique como a decomposição visa balanceamento de carga e minimizar comunicações.",
                                    "Discuta mapeamento de subdomínios para processadores.",
                                    "Analise exemplos simples como decomposição de uma grade 2D."
                                  ],
                                  "verification": "Resuma em um diagrama os componentes da decomposição de domínio e liste 3 benefícios.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Slides sobre decomposição de domínio",
                                    "Artigo 'Domain Decomposition Methods' de PDF acadêmico"
                                  ],
                                  "tips": "Use desenhos à mão para visualizar subdomínios em problemas reais como simulações numéricas.",
                                  "learningObjective": "Compreender a base da decomposição de domínio para relacioná-la com arquiteturas distribuídas.",
                                  "commonMistakes": "Confundir decomposição de domínio com decomposição de tarefas (focar em dados, não em funções)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diferenciar Memória Compartilhada de Memória Distribuída",
                                  "subSteps": [
                                    "Descreva memória compartilhada: acesso global a dados via barramento ou cache coerente (ex: multicore).",
                                    "Descreva memória distribuída: cada processador tem memória local, comunicação via mensagens.",
                                    "Liste vantagens/desvantagens: escalabilidade em distribuída vs. simplicidade em compartilhada.",
                                    "Compare modelos: OpenMP para compartilhada vs. MPI para distribuída.",
                                    "Identifique quando usar cada uma com base em tamanho do problema."
                                  ],
                                  "verification": "Crie uma tabela comparativa com 4 colunas: Aspecto, Compartilhada, Distribuída, Exemplo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação OpenMP e MPI",
                                    "Vídeo comparativo no YouTube sobre modelos de memória"
                                  ],
                                  "tips": "Pense em um laptop (compartilhada) vs. cluster de PCs (distribuída) para analogias.",
                                  "learningObjective": "Distinguir arquiteturas para contextualizar a decomposição em cenários distribuídos.",
                                  "commonMistakes": "Assumir que memória distribuída é sempre mais lenta; depende do overhead de comunicação."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Modelos de Programação Paralela Baseados em Troca de Mensagens",
                                  "subSteps": [
                                    "Introduza MPI como padrão para troca de mensagens em memória distribuída.",
                                    "Descreva primitivas: Send/Recv, Broadcast, Reduce.",
                                    "Explique como decomposição de domínio se alinha: cada subdomínio em um processo.",
                                    "Discuta padrões de comunicação: halo exchanges em decomposição geométrica.",
                                    "Simule um programa simples com pseudocódigo MPI."
                                  ],
                                  "verification": "Escreva pseudocódigo para decompor uma matriz e trocar bordas entre processos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Instalação local de MPI (OpenMPI)",
                                    "Tutorial MPI basics de LLNL"
                                  ],
                                  "tips": "Comece com 4 processos em grade 2x2 para visualizar trocas.",
                                  "learningObjective": "Mapear decomposição de domínio diretamente aos modelos de mensagens.",
                                  "commonMistakes": "Ignorar sincronização; mensagens requerem coordenação explícita."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Associar Decomposição de Domínio aos Modelos de Memória Distribuída",
                                  "subSteps": [
                                    "Relacione subdomínios locais com memória por processo.",
                                    "Explique necessidade de trocas de mensagens para dependências entre subdomínios.",
                                    "Diferencie de compartilhada: sem acesso direto, só via mensagens.",
                                    "Analise impacto no desempenho: overhead de comunicação vs. paralelismo.",
                                    "Crie um fluxograma da relação: Decomposição → Alocação → Comunicação."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito como decomposição mitiga problemas de distribuída.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Exemplos de código CFD com domain decomposition",
                                    "Livro 'Parallel Programming with MPI' de Pacheco"
                                  ],
                                  "tips": "Use ferramentas como ParaView para visualizar decomposições em simulações.",
                                  "learningObjective": "Estabelecer a associação conceitual clara entre decomposição e troca de mensagens.",
                                  "commonMistakes": "Subestimar comunicações; sempre calcule volume de dados trocados."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar e Verificar a Relação em um Cenário Prático",
                                  "subSteps": [
                                    "Implemente um exemplo simples de decomposição em MPI.",
                                    "Meça tempo de comunicação vs. computação.",
                                    "Compare com versão compartilhada hipotética.",
                                    "Otimize partição para minimizar mensagens.",
                                    "Documente lições aprendidas."
                                  ],
                                  "verification": "Execute o código e gere relatório com métricas de speedup.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Ambiente de cluster ou Mininet para simulação distribuída",
                                    "Código-fonte exemplo de stencil computation"
                                  ],
                                  "tips": "Teste com tamanhos variados para observar escalabilidade.",
                                  "learningObjective": "Consolidar o conhecimento através de implementação hands-on.",
                                  "commonMistakes": "Não balancear cargas; leva a gargalos em processos ociosos."
                                }
                              ],
                              "practicalExample": "Em uma simulação de fluxo de calor em uma grade 2D usando MPI: decomponha a grade em subgrades por processo, compute localmente e troque valores de borda via MPI_Sendrecv, diferenciando de OpenMP onde todos acessam a grade compartilhada sem mensagens explícitas.",
                              "finalVerifications": [
                                "Explicar verbalmente a diferença entre decomposição em compartilhada vs. distribuída.",
                                "Desenhar diagrama de trocas de mensagens para um problema de 4 subdomínios.",
                                "Identificar 3 primitivas MPI usadas em domain decomposition.",
                                "Comparar overheads em um exemplo numérico simples.",
                                "Listar cenários onde distribuída é preferível devido à decomposição.",
                                "Implementar e rodar código mínimo sem erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual na associação decomposição-troca de mensagens (30%)",
                                "Capacidade de diferenciar modelos de memória com exemplos (25%)",
                                "Qualidade do pseudocódigo ou implementação prática (20%)",
                                "Análise de desempenho e otimizações sugeridas (15%)",
                                "Clareza em diagramas e explicações (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação semelhantes a TCP/IP.",
                                "Banco de Dados Distribuídos: Particionamento de dados e sharding.",
                                "Inteligência Artificial: Treinamento distribuído em frameworks como Horovod.",
                                "Engenharia de Software: Design de sistemas escaláveis e microservices."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, domain decomposition com MPI é usado em simulações climáticas (ex: ECMWF) e CFD (ex: NASA), permitindo escalar para milhares de nós onde memória compartilhada falha por limitações de hardware."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.3.2",
                        "name": "Estratégias de Particionamento de Domínio",
                        "description": "Técnicas para dividir o domínio computacional em subdomínios balanceados, considerando carga de trabalho e topologia de rede em ambientes distribuídos.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.3.2.1",
                            "name": "Aplicar particionamento geométrico",
                            "description": "Implementar divisão geométrica de domínios em grades ou malhas para problemas como simulações físicas, distribuindo subdomínios em nós de cluster.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Domínio e Requisitos do Problema",
                                  "subSteps": [
                                    "Analise o domínio geométrico do problema (ex: malha 2D ou 3D para simulação física).",
                                    "Identifique o número de nós no cluster e requisitos de balanceamento de carga.",
                                    "Defina métricas chave: balanceamento (tamanho igual de subdomínios), minimização de interfaces.",
                                    "Estude exemplos de domínios comuns como grades retangulares ou triangulares irregulares.",
                                    "Documente restrições como topologia do cluster e tipo de simulação (ex: CFD, FEM)."
                                  ],
                                  "verification": "Crie um diagrama do domínio original e anote requisitos em um relatório inicial.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Software de visualização de malhas (ex: Paraview, Gmsh)",
                                    "Documentação do problema de simulação"
                                  ],
                                  "tips": "Comece com domínios simples para ganhar intuição antes de complexos.",
                                  "learningObjective": "Identificar características geométricas e computacionais do domínio para guiar o particionamento.",
                                  "commonMistakes": [
                                    "Ignorar topologia do cluster",
                                    "Subestimar impacto de interfaces na comunicação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Selecionar e Configurar Algoritmo de Particionamento Geométrico",
                                  "subSteps": [
                                    "Escolha método: recursive coordinate bisection (RCB), space-filling curves (SFC) ou METIS para geométrico.",
                                    "Instale bibliotecas: ParMETIS ou Zoltan para suporte a particionamento geométrico.",
                                    "Configure parâmetros: número de partições = número de nós, tolerância de balanceamento (ex: 1.05).",
                                    "Gere coordenadas dos elementos da malha e prepare dados de entrada.",
                                    "Execute particionamento em modo serial para validar configuração inicial."
                                  ],
                                  "verification": "Verifique saída: cada partição tem IDs únicos e tamanhos balanceados (desvio <5%).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Bibliotecas ParMETIS/Zoltan",
                                    "Compilador MPI (ex: OpenMPI)",
                                    "Malha de teste (ex: grade 100x100)"
                                  ],
                                  "tips": "Use RCB para domínios regulares; SFC para irregulares para melhor localidade.",
                                  "learningObjective": "Selecionar e parametrizar algoritmo geométrico otimizado para o domínio.",
                                  "commonMistakes": [
                                    "Escolher método inadequado para geometria",
                                    "Parâmetros padrão sem tuning"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Particionamento e Mapeamento em Código Paralelo",
                                  "subSteps": [
                                    "Integre chamadas à biblioteca no código MPI: leia malha, aplique particionador, atribua subdomínios.",
                                    "Crie estruturas de dados: array de ownership por elemento/nó.",
                                    "Implemente troca de fantasmas (ghost elements) nas interfaces.",
                                    "Mapeie partições para ranks MPI considerando topologia do cluster.",
                                    "Adicione logging para tamanhos de partição e volume de comunicação."
                                  ],
                                  "verification": "Compile e rode em 2-4 processos: confira logs mostram balanceamento e ghosts corretos.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Código base MPI",
                                    "Editor IDE (ex: VSCode com MPI support)",
                                    "Cluster de teste ou SLURM"
                                  ],
                                  "tips": "Teste incremental: serial -> 2 nós -> full cluster.",
                                  "learningObjective": "Codificar integração de particionamento geométrico em aplicação paralela.",
                                  "commonMistakes": [
                                    "Erros em indexing de elementos",
                                    "Falta de ghosts levando a inconsistências"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar, Otimizar e Avaliar Desempenho",
                                  "subSteps": [
                                    "Execute em cluster full: meça tempo de particionamento e iterações de simulação.",
                                    "Calcule métricas: edge-cut ratio, load imbalance, speedup.",
                                    "Visualize partições com Paraview para inspecionar qualidade geométrica.",
                                    "Tune parâmetros e re-particione se imbalance >3%.",
                                    "Compare com particionamento uniforme para quantificar ganhos."
                                  ],
                                  "verification": "Relatório com métricas: imbalance <2%, edge-cut minimizado vs baseline.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Cluster computacional",
                                    "Ferramentas de profiling (ex: TAU, Vampir)",
                                    "Paraview"
                                  ],
                                  "tips": "Monitore comunicação: alto edge-cut indica necessidade de refinamento.",
                                  "learningObjective": "Avaliar e refinar particionamento para eficiência em simulações distribuídas.",
                                  "commonMistakes": [
                                    "Não validar visualmente",
                                    "Ignorar overhead de comunicação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de fluxo de fluido em torno de um aerofólio (malha 2D com 50k células), aplique RCB para dividir em 16 subdomínios para 16 nós de cluster, garantindo balanceamento e minimizando fluxos de dados nas interfaces.",
                              "finalVerifications": [
                                "Subdomínios têm tamanhos balanceados (desvio <3%).",
                                "Interfaces minimizadas (edge-cut <10% do total).",
                                "Ghost elements corretamente trocados entre processos.",
                                "Simulação roda sem erros de domínio em cluster.",
                                "Tempo de simulação reduzido vs particionamento round-robin.",
                                "Visualização confirma partições geométricas contíguas."
                              ],
                              "assessmentCriteria": [
                                "Precisão do balanceamento de carga (>95% uniforme).",
                                "Eficiência na minimização de comunicação (edge-cut otimizado).",
                                "Corretude da implementação (sem vazamentos de domínio).",
                                "Escalabilidade demonstrada em 4-16 nós.",
                                "Documentação clara de métricas e tuning.",
                                "Integração seamless com código de simulação existente."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Geometria computacional e curvas preenchimento de espaço.",
                                "Física: Modelagem de simulações numéricas (CFD, FEM).",
                                "Otimização: Algoritmos de heurística para particionamento.",
                                "Redes: Topologia de clusters e comunicação MPI.",
                                "Engenharia de Software: Bibliotecas paralelas e modularidade."
                              ],
                              "realWorldApplication": "Em simulações de dinâmica de fluidos computacional (CFD) para design aeroespacial na NASA, ou análise de elementos finitos (FEM) em estruturas civis, onde malhas grandes são particionadas geometricamente para rodar em supercomputadores, reduzindo tempo de simulação de dias para horas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.2.2",
                            "name": "Realizar balanceamento de carga",
                            "description": "Calcular e ajustar tamanhos de subdomínios para equilibrar carga computacional, evitando gargalos em sistemas heterogêneos de memória distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os princípios de balanceamento de carga em memória distribuída",
                                  "subSteps": [
                                    "Estudar a definição de balanceamento de carga e sua importância em sistemas heterogêneos.",
                                    "Analisar diferenças entre balanceamento estático e dinâmico.",
                                    "Identificar fontes de desbalanceamento: computação, comunicação e I/O.",
                                    "Revisar métricas como tempo de execução máximo, makespan e eficiência.",
                                    "Explorar exemplos de gargalos em clusters heterogêneos."
                                  ],
                                  "verification": "Resumir em um diagrama os tipos de desbalanceamento e métricas chave.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação MPI/OpenMP",
                                    "Artigos sobre HPC (ex: IEEE papers)",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Use analogias como dividir trabalho desigual em uma equipe para visualizar gargalos.",
                                  "learningObjective": "Dominar conceitos teóricos para identificar problemas de carga.",
                                  "commonMistakes": [
                                    "Confundir balanceamento com escalabilidade",
                                    "Ignorar heterogeneidade de hardware"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Modelar e medir a carga computacional dos subdomínios",
                                  "subSteps": [
                                    "Definir o domínio problema (ex: grade 2D para simulação).",
                                    "Estimar flops ou tempo de computação por subdomínio usando profiling.",
                                    "Medir overhead de comunicação entre subdomínios.",
                                    "Coletar dados de hardware: CPU, memória e rede dos nós.",
                                    "Calcular pesos iniciais de carga para cada subdomínio."
                                  ],
                                  "verification": "Gerar uma tabela com pesos de carga para um domínio de teste.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de profiling: TAU, Vampir",
                                    "Código de exemplo em MPI",
                                    "Planilha Excel/Google Sheets"
                                  ],
                                  "tips": "Profile em pequena escala primeiro para evitar tempo excessivo.",
                                  "learningObjective": "Quantificar cargas para basear ajustes em dados reais.",
                                  "commonMistakes": [
                                    "Subestimar custos de comunicação",
                                    "Usar médias em vez de máximos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e ajustar tamanhos de subdomínios",
                                  "subSteps": [
                                    "Aplicar fórmula de balanceamento: tamanho_i = total / (num_nos * peso_i).",
                                    "Usar métodos iterativos como diffusive load balancing para refinamento.",
                                    "Ajustar partições minimizando métrica de desbalanceamento (ex: max/min < 1.2).",
                                    "Simular reparticionamento com grafos de domínio.",
                                    "Implementar em pseudocódigo ou script."
                                  ],
                                  "verification": "Calcular tamanhos para um exemplo e verificar soma total igual ao domínio original.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Biblioteca METIS/ParMETIS para particionamento",
                                    "Python com NumPy/SciPy",
                                    "Documentação de algoritmos"
                                  ],
                                  "tips": "Comece com partições 1D para simplicidade antes de 2D/3D.",
                                  "learningObjective": "Executar cálculos precisos para tamanhos otimizados.",
                                  "commonMistakes": [
                                    "Ignorar continuidade de subdomínios",
                                    "Não normalizar pesos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar, testar e otimizar o balanceamento",
                                  "subSteps": [
                                    "Integrar balanceador em código paralelo (MPI).",
                                    "Executar em cluster simulado ou real e medir tempos.",
                                    "Comparar antes/depois com profiling.",
                                    "Ajustar iterativamente até convergência.",
                                    "Documentar melhorias em eficiência."
                                  ],
                                  "verification": "Relatório com gráficos de tempo por nó mostrando redução de gargalos.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Cluster local ou cloud (AWS/GCP)",
                                    "MPI implementation",
                                    "Ferramentas de plot: Matplotlib"
                                  ],
                                  "tips": "Use seeds fixos para reprodutibilidade em simulações.",
                                  "learningObjective": "Aplicar e validar balanceamento em ambiente real.",
                                  "commonMistakes": [
                                    "Testar só em hardware homogêneo",
                                    "Esquecer logging de métricas"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de multiplicação de matrizes 1000x1000 distribuída em 4 nós heterogêneos (CPU speeds: 2.0, 2.5, 1.8, 3.0 GHz), calcular pesos baseados em flops por linha/coluna, ajustar tamanhos de submatrizes para equalizar tempo total em ~5s por nó, reduzindo makespan de 8s para 5.2s.",
                              "finalVerifications": [
                                "Tempo de execução máximo entre nós varia <10%.",
                                "Eficiência global >90%.",
                                "Sobrecarga de comunicação <20% do tempo total.",
                                "Partições mantêm continuidade do domínio.",
                                "Testes em pelo menos 3 configurações de hardware.",
                                "Documentação com métricas antes/depois."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de pesos (erro <5%).",
                                "Redução efetiva de makespan (>20%).",
                                "Implementação correta em código paralelo.",
                                "Análise de trade-offs (computação vs comunicação).",
                                "Relatório claro com visualizações.",
                                "Adaptabilidade a heterogeneidade."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Otimização e álgebra linear para modelagem.",
                                "Engenharia de Software: Design de algoritmos paralelos.",
                                "Física Computacional: Simulações numéricas em HPC.",
                                "Redes de Computadores: Impacto na latência de comunicação."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas (ex: modelos GCM), onde nós heterogêneos processam grids globais, balanceando carga para evitar gargalos em regiões computacionalmente intensas como oceanos ou atmosferas turbulentas, otimizando tempo de simulação de dias para horas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.2.3",
                            "name": "Usar ferramentas de particionamento",
                            "description": "Explorar bibliotecas como METIS ou ParMETIS para particionamento gráfico de domínios em aplicações paralelas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Instalação e Configuração Inicial da Biblioteca METIS",
                                  "subSteps": [
                                    "Baixe a versão mais recente do METIS do site oficial ou repositório GitHub.",
                                    "Compile a biblioteca usando make ou cmake, configurando para suporte a múltiplos núcleos.",
                                    "Instale as bibliotecas e cabeçalhos em um diretório acessível (ex: /usr/local).",
                                    "Teste a instalação compilando e executando o exemplo kmetis fornecido.",
                                    "Configure variáveis de ambiente como LD_LIBRARY_PATH para linking dinâmico."
                                  ],
                                  "verification": "Execute o exemplo kmetis em um grafo simples e verifique se produz arquivos de partição sem erros.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Computador com Linux/Unix, compilador GCC/MPI, acesso à internet para download.",
                                  "tips": "Use opções de make para otimização com flags como -O3 para melhor performance.",
                                  "learningObjective": "Configurar ambiente de desenvolvimento pronto para uso de METIS em projetos paralelos.",
                                  "commonMistakes": "Ignorar dependências como MPI ou falhar em setar paths corretos, causando erros de linking."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparação do Grafo de Entrada para Particionamento",
                                  "subSteps": [
                                    "Represente o domínio como grafo: vértices para elementos, arestas para conexões vizinhas.",
                                    "Gere arquivos de entrada no formato METIS: graph file (.graph) com header e listas de adjacência.",
                                    "Atribua pesos a vértices e arestas se necessário (ex: tamanho de subdomínios).",
                                    "Valide o grafo usando ferramentas como graphchk do METIS.",
                                    "Crie um script para gerar grafos automaticamente de malhas (ex: de FEM)."
                                  ],
                                  "verification": "Use graphchk para confirmar que o grafo é válido e simétrico.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": "Editor de texto ou Python/MATLAB para gerar grafos, exemplos de malhas de domínio.",
                                  "tips": "Mantenha grafos pequenos inicialmente (milhares de vértices) para testes rápidos.",
                                  "learningObjective": "Transformar domínios computacionais em representações gráficas adequadas para particionamento.",
                                  "commonMistakes": "Erro em numeração de vértices (deve iniciar em 1) ou listas de adjacência não ordenadas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Execução do Particionamento Gráfico com METIS",
                                  "subSteps": [
                                    "Escolha parâmetros: número de partições (k), desbalanceamento permitido (ublkvfrac).",
                                    "Execute kmetis ou pmetis via linha de comando: kmetis graph.kmetis k n.",
                                    "Integre via API C: inclua metis.h, chame METIS_PartGraphKway com arrays de entrada.",
                                    "Capture saídas: epart (partição de arestas), vpart (partição de vértices).",
                                    "Experimente opções como recursive ou hypergraph para diferentes cenários."
                                  ],
                                  "verification": "Verifique balanceamento (pesos por partição < 1.03 * ideal) e edge-cut mínimo.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Terminal, código fonte simples em C para API, grafos preparados.",
                                  "tips": "Use -ptype=rb para recursive bisection em grafos grandes para estabilidade.",
                                  "learningObjective": "Aplicar algoritmos de particionamento para obter decomposições balanceadas e minimizar comunicações.",
                                  "commonMistakes": "Definir k maior que núcleos disponíveis ou ignorar pesos, levando a balanceamento ruim."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integração e Teste em Aplicação Paralela com MPI",
                                  "subSteps": [
                                    "Carregue partições em código MPI: distribua vértices por ranks baseado em vpart.",
                                    "Implemente exchange de ghosts/bordas entre subdomínios adjacentes.",
                                    "Meça métricas: tempo de setup, balanceamento, comunicações (MPI_Alltoallv).",
                                    "Execute com mpirun em múltiplos processos e compare performance serial vs paralela.",
                                    "Otimize refinando partição com MLPartEdgeRefine."
                                  ],
                                  "verification": "Rode simulação paralela e confirme speedup >1 com particionamento vs decomposição uniforme.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "MPI instalado (OpenMPI/MPICH), código base de stencil ou FEM simples.",
                                  "tips": "Profile com tools como TAU ou Vampir para identificar gargalos de comunicação.",
                                  "learningObjective": "Incorporar particionamento em fluxos paralelos para escalabilidade em memória distribuída.",
                                  "commonMistakes": "Não mapear partições corretamente para ranks MPI, causando duplicação de dados."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Análise e Otimização dos Resultados de Particionamento",
                                  "subSteps": [
                                    "Calcule métricas: edge-cut, balanceamento, migrações de vértices.",
                                    "Visualize partições com ParaView ou Graphviz.",
                                    "Compare METIS vs ParMETIS para grafos grandes (hypergraph mode).",
                                    "Ajuste parâmetros e re-particione iterativamente.",
                                    "Documente trade-offs (qualidade vs tempo)."
                                  ],
                                  "verification": "Gere relatório com métricas mostrando edge-cut <5% das arestas totais.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": "Scripts Python para métricas, visualizadores gráficos.",
                                  "tips": "Para domínios 3D, use KaHIP como alternativa se METIS falhar em qualidade.",
                                  "learningObjective": "Avaliar e refinar particionamentos para aplicações reais de alto desempenho.",
                                  "commonMistakes": "Sobrepor análise qualitativa sem métricas quantitativas."
                                }
                              ],
                              "practicalExample": "Particione uma malha 2D de 10k elementos para simulação de equação de calor paralela com 8 processos MPI: use METIS para decompor em 8 subdomínios balanceados, reduzindo comunicações em 40% vs grid uniforme.",
                              "finalVerifications": [
                                "Biblioteca METIS instalada e API callable sem erros de compilação.",
                                "Grafo válido particionado com balanceamento <3% de desvio.",
                                "Edge-cut mínimo comparado a baseline manual.",
                                "Aplicação MPI executa corretamente com partições distribuídas.",
                                "Métricas de performance mostram redução em comunicações.",
                                "Visualização confirma subdomínios conectados adequadamente."
                              ],
                              "assessmentCriteria": [
                                "Qualidade do particionamento: edge-cut <10% das arestas totais.",
                                "Balanceamento: máximo desvio de carga <5%.",
                                "Tempo de particionamento escalável para grafos >100k vértices.",
                                "Integração seamless em código MPI sem overhead >10%.",
                                "Correção: solução paralela converge igual à serial.",
                                "Documentação de parâmetros e métricas completa."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: modelagem de domínios como grafos pesados.",
                                "Algoritmos de Otimização: heurísticas para min-cut.",
                                "Programação Paralela: mapeamento para memória distribuída.",
                                "Engenharia de Software: integração de bibliotecas externas.",
                                "Visualização Científica: análise de partições."
                              ],
                              "realWorldApplication": "Em simulações HPC como CFD (ex: OpenFOAM) ou FEM (ex: deal.II), particionamento com METIS equilibra carga em milhares de núcleos de supercomputadores, minimizando tempo de simulação em problemas industriais como aerodinâmica automotiva."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.3.3",
                        "name": "Gerenciamento de Fronteiras e Comunicação",
                        "description": "Tratamento de interações entre subdomínios adjacentes, incluindo troca de mensagens para sincronização em memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.3.3.1",
                            "name": "Identificar fronteiras de subdomínios",
                            "description": "Detectar e mapear regiões de fronteira onde subdomínios se sobrepõem ou trocam dados, essencial para precisão em simulações.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar o Domínio de Problema e Decomposição Inicial",
                                  "subSteps": [
                                    "Revise a definição do domínio de simulação (ex.: grade 2D para fluxo de calor).",
                                    "Identifique a decomposição inicial em subdomínios (ex.: divisão em blocos quadrados).",
                                    "Liste os dados computados em cada subdomínio (ex.: temperaturas nos pontos internos).",
                                    "Anote dependências de dados entre regiões adjacentes.",
                                    "Crie um diagrama esquemático da grade dividida."
                                  ],
                                  "verification": "Confirme que o diagrama mostra subdomínios claramente delimitados sem sobreposições iniciais.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Papel, lápis ou software de desenho (ex.: Draw.io, Jupyter Notebook com matplotlib).",
                                  "tips": "Comece com uma grade pequena (ex.: 8x8) para facilitar a visualização.",
                                  "learningObjective": "Compreender a estrutura espacial do domínio e sua partição inicial.",
                                  "commonMistakes": "Ignorar dependências de fronteira ao focar apenas em computações internas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Visualizar Subdomínios e Identificar Regiões Adjacentes",
                                  "subSteps": [
                                    "Desenhe os subdomínios em uma grade representativa.",
                                    "Marque arestas compartilhadas entre subdomínios vizinhos.",
                                    "Calcule o perímetro de cada subdomínio.",
                                    "Identifique cantos e vértices onde múltiplos subdomínios se encontram.",
                                    "Use cores diferentes para destacar regiões adjacentes."
                                  ],
                                  "verification": "O diagrama deve mostrar todas as adjacências com linhas ou setas indicando potenciais fronteiras.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Software de visualização (matplotlib, Paraview) ou grade impressa.",
                                  "tips": "Aumente a resolução da grade para ver padrões emergentes em decomposições não uniformes.",
                                  "learningObjective": "Mapear visualmente interações espaciais entre subdomínios.",
                                  "commonMistakes": "Confundir adjacência geométrica com dependência de dados real."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Detectar Sobreposições e Fluxos de Dados nas Fronteiras",
                                  "subSteps": [
                                    "Analise o stencil de computação (ex.: 5-pontos para Laplace).",
                                    "Marque pontos de halo (ghost cells) necessários para cada subdomínio.",
                                    "Identifique trocas de dados obrigatórias (ex.: envios/recebimentos MPI).",
                                    "Quantifique o volume de dados na fronteira (ex.: número de células fronteiriças).",
                                    "Classifique fronteiras como internas (entre subdomínios) ou externas (com ambiente)."
                                  ],
                                  "verification": "Liste todas as fronteiras com volumes de dados e tipos de troca associados.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Código de exemplo em C++/MPI ou Python/MPI4Py, calculadora.",
                                  "tips": "Simule uma iteração manual para rastrear fluxos de dados.",
                                  "learningObjective": "Reconhecer padrões de sobreposição baseados no algoritmo de simulação.",
                                  "commonMistakes": "Subestimar halos em decomposições irregulares ou 3D."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Documentar e Validar Fronteiras Identificadas",
                                  "subSteps": [
                                    "Crie um mapa final de fronteiras com rótulos (ex.: 'fronteira E-O: 10 células').",
                                    "Verifique cobertura total do domínio sem lacunas ou excessos.",
                                    "Teste com um protótipo simples (ex.: soma de fronteiras deve igualar trocas esperadas).",
                                    "Registre métricas como razão fronteira/volume por subdomínio.",
                                    "Discuta otimizações potenciais (ex.: alinhar fronteiras com cache)."
                                  ],
                                  "verification": "O mapa final permite gerar código de comunicação sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Planilha (Excel/Google Sheets) para métricas, código de teste MPI.",
                                  "tips": "Use ferramentas como TAU ou Vampir para validar em execuções reais mais tarde.",
                                  "learningObjective": "Garantir precisão e utilidade prática da identificação de fronteiras.",
                                  "commonMistakes": "Esquecer validação numérica, levando a erros em simulações paralelas."
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão em grade 2D 100x100 dividida em 4 subdomínios 50x50, identifique fronteiras: vertical entre subdomínio 1-2 (50 células, troca Norte-Sul), horizontal entre 1-3 (50 células, troca Leste-Oeste), e canto em (50,50) com 4 subdomínios trocando halos de 1 célula.",
                              "finalVerifications": [
                                "Mapa de fronteiras cobre 100% das dependências de dados.",
                                "Volumes de troca calculados coincidem com stencil do algoritmo.",
                                "Nenhum subdomínio isolado sem fronteiras necessárias.",
                                "Métricas de superfície/volume < 10% para eficiência.",
                                "Diagrama permite gerar topologia de comunicação MPI.",
                                "Teste manual confirma ausência de dados perdidos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na detecção de todas as sobreposições (100%).",
                                "Clareza e completude do mapeamento visual.",
                                "Correção quantitativa de volumes de fronteira.",
                                "Identificação de tipos de troca (unidirecional/bidirecional).",
                                "Validação prática via protótipo sem erros.",
                                "Eficiência sugerida para minimizar comunicações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Geometria computacional e análise de malhas.",
                                "Grafos: Modelagem de subdomínios como vértices e fronteiras como arestas.",
                                "Física: Entropia e fluxos em simulações de difusão/transportes.",
                                "Engenharia de Software: Design de interfaces em sistemas distribuídos."
                              ],
                              "realWorldApplication": "Em simulações CFD (ex.: OpenFOAM) ou clima (WRF), identificar fronteiras otimiza comunicações em supercomputadores, reduzindo latência em milhares de processos e acelerando previsões meteorológicas ou design aerodinâmico."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.3.2",
                            "name": "Implementar troca de mensagens em fronteiras",
                            "description": "Programar comunicação assíncrona ou síncrona via MPI para halo exchanges entre subdomínios em decomposição de domínio.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e decomposição de domínio",
                                  "subSteps": [
                                    "Instalar e inicializar MPI com mpirun e mpicc.",
                                    "Definir o grid global (ex: 2D NxN) e decompor em subdomínios por linhas/colunas.",
                                    "Atribuir ranks aos processos e calcular dimensões locais usando MPI_Comm_size e MPI_Comm_rank.",
                                    "Criar arrays locais com ghost cells (halos) nas bordas.",
                                    "Alocar memória para buffers de envio/recebimento."
                                  ],
                                  "verification": "Executar código inicial e verificar com MPI_Barrier que todos os ranks inicializaram corretamente; imprimir dimensões locais.",
                                  "estimatedTime": "45 minutes",
                                  "materials": "Compilador MPI (OpenMPI/MPICH), editor de código, terminal para mpirun.",
                                  "tips": "Use MPI_Wtime para medir tempos iniciais e garantir balanceamento de carga.",
                                  "learningObjective": "Compreender inicialização MPI e mapeamento de domínio global para local.",
                                  "commonMistakes": "Esquecer MPI_Init/MPI_Finalize; calcular errado dimensões locais levando a overlaps incorretos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar vizinhos e definir regiões de halo",
                                  "subSteps": [
                                    "Calcular coordenadas cartesianas dos subdomínios (ex: row = rank / cols_per_row).",
                                    "Identificar vizinhos: superior, inferior, esquerdo, direito via MPI_Cart_create ou manualmente.",
                                    "Definir tamanhos dos halos (ex: 1 célula nas bordas).",
                                    "Preparar índices para packing de dados de halo em buffers.",
                                    "Testar packing/unpacking em serial para validar."
                                  ],
                                  "verification": "Imprimir vizinhos e tamanhos de buffers por rank; comparar com grid esperado.",
                                  "estimatedTime": "30 minutes",
                                  "materials": "Código base do Step 1, debugger como gdb com MPI.",
                                  "tips": "Use MPI_Cart_shift para abstrair vizinhos em topologias regulares.",
                                  "learningObjective": "Mapear topologia de subdomínios e regiões de fronteira para comunicação.",
                                  "commonMistakes": "Vizinhos errados em decomposições não-regulares; off-by-one em índices de halo."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar trocas não-bloqueantes com MPI_Isend e MPI_Irecv",
                                  "subSteps": [
                                    "Iniciar MPI_Isend para enviar dados de halo para cada vizinho.",
                                    "Iniciar MPI_Irecv para receber de cada vizinho correspondente.",
                                    "Gerenciar requests em array para múltiplas comunicações.",
                                    "Implementar packing de dados reais para buffers antes do send.",
                                    "Garantir ordem: postar todos sends/recvs antes de wait."
                                  ],
                                  "verification": "Chamar MPI_Waitall e imprimir valores recebidos nas halos para matching com envios.",
                                  "estimatedTime": "60 minutes",
                                  "materials": "Documentação MPI (man pages), exemplos de stencil code.",
                                  "tips": "Use MPI_Request array dimensionado pelo número de vizinhos (máx 4 em 2D).",
                                  "learningObjective": "Executar comunicação assíncrona para sobreposição de comm/compute.",
                                  "commonMistakes": "Esquecer de postar recv antes de send; mismatch de tags ou contadores."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Completar comunicações e integrar ao loop de computação",
                                  "subSteps": [
                                    "Chamar MPI_Waitall após computação local para sincronizar.",
                                    "Unpack dados recebidos nas ghost cells.",
                                    "Integrar em loop iterativo (ex: 100 iterações de stencil Laplace).",
                                    "Adicionar condições de borda para domínios fronteira.",
                                    "Implementar redução global (MPI_Reduce) para verificar soma total."
                                  ],
                                  "verification": "Executar com 4-8 ranks; verificar convergência e consistência nas fronteiras via output.",
                                  "estimatedTime": "45 minutes",
                                  "materials": "Cluster ou multi-core com mpirun -np 8, valgrind para leaks.",
                                  "tips": "Profile com MPI_Wtick para overlap; teste com grids pequenos primeiro.",
                                  "learningObjective": "Sincronizar e validar trocas em contexto de simulação paralela.",
                                  "commonMistakes": "Deadlocks por waits prematuros; leaks de requests não esperados."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar, debugar e otimizar trocas",
                                  "subSteps": [
                                    "Executar com diferentes números de ranks e grids.",
                                    "Usar MPI_Get_count para validar tamanhos recebidos.",
                                    "Otimizar com MPI_Sendrecv para casos periódicos.",
                                    "Medir bandwidth e latency com loops vazios.",
                                    "Adicionar error handling com MPI_Error_string."
                                  ],
                                  "verification": "Sem erros MPI, dados corretos em todos ranks, performance escalável.",
                                  "estimatedTime": "30 minutes",
                                  "materials": "Ferramentas de profiling (TAU, Vampir), scripts de benchmark.",
                                  "tips": "Compare síncrono vs assíncrono para ganhos.",
                                  "learningObjective": "Garantir robustez e performance em cenários reais.",
                                  "commonMistakes": "Ignorar periodicidade em bordas; escalabilidade ruim por all-to-all implícito."
                                }
                              ],
                              "practicalExample": "Em uma simulação de equação de Laplace em grid 2D 1024x1024 decomposado em 4x4 subdomínios, cada processo envia linha superior para vizinho inferior via MPI_Isend e recebe linha inferior; após wait, atualiza ghost cells e computa stencil de 5 pontos, garantindo solução convergente idêntica à serial.",
                              "finalVerifications": [
                                "Dados nas ghost cells de todos ranks coincidem com vizinhos após troca.",
                                "Nenhuma violação de MPI_ERROR ou deadlock em execuções múltiplas.",
                                "Soma global dos valores do grid permanece conservada via MPI_Allreduce.",
                                "Tempo de comunicação escala linearmente com tamanho do halo.",
                                "Código executa corretamente em 2D e estensível a 3D.",
                                "Valores de fronteira não alteram após múltiplas iterações."
                              ],
                              "assessmentCriteria": [
                                "Correção: Halos trocados precisamente sem corrupção de dados.",
                                "Eficiência: Uso de non-blocking comm com >50% overlap compute-comm.",
                                "Robustez: Lida com diferentes topologias e números de ranks.",
                                "Escalabilidade: Performance degrada minimamente até 64 ranks.",
                                "Clareza: Código comentado com explicação de vizinhos e buffers.",
                                "Documentação: Relatório com timings e plots de speedup."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Solução numérica de PDEs parciais via métodos de diferenças finitas.",
                                "Física: Modelagem de difusão de calor ou fluxo em malhas paralelas.",
                                "Engenharia de Software: Design de algoritmos distribuídos tolerantes a falhas.",
                                "Análise de Dados: Processamento paralelo de grids em big data spatial."
                              ],
                              "realWorldApplication": "Em simulações CFD (Computational Fluid Dynamics) como nas turbinas da GE ou previsões climáticas do IPCC, onde decomposição de domínio com halo exchanges via MPI permite escalar simulações de milhões de células em supercomputadores para otimizar designs e previsões precisas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.3.3",
                            "name": "Avaliar overhead de comunicação",
                            "description": "Medir impacto da comunicação em fronteiras no desempenho geral, usando métricas como speedup e eficiência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Overhead de Comunicação e Métricas de Desempenho",
                                  "subSteps": [
                                    "Defina overhead de comunicação como o tempo gasto em trocas de dados entre processos em memória distribuída.",
                                    "Estude speedup como S(p) = T(1)/T(p), onde T(1) é tempo sequencial e T(p) é tempo com p processadores.",
                                    "Aprenda eficiência E(p) = S(p)/p e como overhead impacta negativamente essas métricas.",
                                    "Revise decomposição de domínio e como fronteiras aumentam volume de comunicação.",
                                    "Analise exemplos teóricos de comunicação em grades 1D vs 2D."
                                  ],
                                  "verification": "Resuma em um diagrama as relações entre overhead, speedup e eficiência, com fórmulas corretas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação MPI/OpenMP",
                                    "Slides sobre programação paralela",
                                    "Calculadora ou Python para fórmulas"
                                  ],
                                  "tips": "Use analogias como tráfego em estradas para visualizar overhead em fronteiras.",
                                  "learningObjective": "Identificar e formular métricas chave para quantificar overhead de comunicação.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Ignorar tempo de latência vs bandwidth",
                                    "Não considerar overhead sequencial"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente de Benchmark para Medição de Comunicação",
                                  "subSteps": [
                                    "Instale MPI (ex: OpenMPI) e compile um programa de stencil 2D simples com decomposição de domínio.",
                                    "Implemente gerenciamento de fronteiras com MPI_Sendrecv para trocas halo.",
                                    "Crie scripts para variar número de processadores (p=1 a 16) e tamanho da grade (N=100 a 1000).",
                                    "Adicione timers precisos (MPI_Wtime) ao redor de fases de comunicação e computação.",
                                    "Teste execução sequencial para baseline T(1)."
                                  ],
                                  "verification": "Execute mpirun com diferentes configurações e confirme logs de tempo sem erros de compilação.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "OpenMPI instalado",
                                    "Editor de código (VSCode)",
                                    "Cluster local ou cloud (AWS/Google Cloud com MPI)"
                                  ],
                                  "tips": "Use --hostfile para controlar alocação e evitar falsos compartilhados.",
                                  "learningObjective": "Preparar um benchmark reproduzível que isole overhead de fronteiras.",
                                  "commonMistakes": [
                                    "Timers imprecisos incluindo I/O",
                                    "Não sincronizar com MPI_Barrier",
                                    "Grades não divisíveis por p"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar Experimentos e Coletar Dados de Desempenho",
                                  "subSteps": [
                                    "Execute o benchmark para múltiplos p e N, registrando tempos de comunicação (T_comm), computação (T_comp) e total (T_total).",
                                    "Repita execuções (mínimo 5) para calcular médias e desvios padrão.",
                                    "Meça volume de comunicação (ex: bytes trocados por iteração em fronteiras).",
                                    "Varie padrões de decomposição (strip vs block) para comparar overhead.",
                                    "Exporte dados para CSV para análise posterior."
                                  ],
                                  "verification": "Gere tabela com pelo menos 20 medições, incluindo médias de T_comm/T_total > 10%.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Scripts MPI prontos",
                                    "Planilha (Excel/Google Sheets)",
                                    "Ferramenta de profiling como TAU ou Vampir"
                                  ],
                                  "tips": "Monitore uso de rede com tools como iftop para validar overhead.",
                                  "learningObjective": "Coletar dados empíricos confiáveis de impacto de comunicação em desempenho.",
                                  "commonMistakes": [
                                    "Amostras insuficientes levando a variância alta",
                                    "Não normalizar por iterações",
                                    "Ignorar overhead de inicialização MPI"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Resultados e Avaliar Overhead",
                                  "subSteps": [
                                    "Calcule speedup S(p) e eficiência E(p) plotando gráficos (Matplotlib).",
                                    "Quantifique overhead como fração T_comm / T_total e isole impacto de fronteiras.",
                                    "Identifique scaling limits (ex: iso-efficiency onde E(p) cai abaixo 50%).",
                                    "Compare decomposições e proponha otimizações (ex: reduzir fronteiras com padding).",
                                    "Documente insights em relatório com gráficos e conclusões."
                                  ],
                                  "verification": "Produza relatório com gráficos mostrando overhead >20% em p>8, com cálculos validados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python com Matplotlib/Pandas",
                                    "Jupyter Notebook",
                                    "Relatório template LaTeX/Markdown"
                                  ],
                                  "tips": "Use log-log plots para iso-efficiency function.",
                                  "learningObjective": "Interpretar dados para avaliar e mitigar overhead de comunicação.",
                                  "commonMistakes": [
                                    "Plots sem escalas logarítmicas",
                                    "Não plotar baselines",
                                    "Confundir correlação com causalidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um solver de equações diferenciais finitas (stencil 2D) com MPI, decomponha uma grade 512x512 em 16 processadores (4x4). Meça T_comm em halos de fronteiras, calcule speedup=6.2 (ideal=16) e eficiência=39%, identificando overhead de 35% do tempo total devido a latência em links Ethernet.",
                              "finalVerifications": [
                                "Speedup e eficiência calculados corretamente para todos p testados.",
                                "Gráficos mostram impacto crescente de overhead com p.",
                                "Relatório identifica pelo menos duas otimizações baseadas em análise.",
                                "Dados reproduzíveis com desvios <5%.",
                                "Overhead quantificado como % de T_total.",
                                "Comparação entre decomposições diferentes."
                              ],
                              "assessmentCriteria": [
                                "Precisão das métricas (speedup/erros <1%).",
                                "Qualidade dos experimentos (variáveis controladas, repetições).",
                                "Profundidade da análise (gráficos, insights quantitativos).",
                                "Clareza do relatório (visualizações, conclusões acionáveis).",
                                "Criatividade em otimizações propostas.",
                                "Uso correto de ferramentas MPI/profiling."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Latência e bandwidth em topologias.",
                                "Otimização Numérica: Balanceamento computação/comunicação.",
                                "Análise de Dados: Estatística descritiva e visualização.",
                                "Engenharia de Software: Design de benchmarks reproduzíveis.",
                                "Matemática Computacional: Análise de complexidade em grids."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier (HPC), otimizar comunicação em simulações climáticas ou CFD reduz overhead de 40% para 15%, permitindo escalar para exaflops sem perda de eficiência, essencial para centros de pesquisa como ORNL."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.3.3.4",
                            "name": "Analisar estudo de caso",
                            "description": "Estudar aplicação de decomposição de domínio em simulações CFD ou processamento de imagens, referenciando Grama et al. (2003).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Leitura e Compreensão Inicial do Estudo de Caso",
                                  "subSteps": [
                                    "Ler o estudo de caso completo, focando na introdução e descrição do problema (ex: simulação CFD ou processamento de imagens).",
                                    "Identificar o contexto de decomposição de domínio e os objetivos do experimento.",
                                    "Anotar termos chave como 'fronteiras', 'comunicação' e 'ghost cells'.",
                                    "Resumir em 1 parágrafo o problema principal e a abordagem paralela utilizada.",
                                    "Mapear a referência de Grama et al. (2003) com as seções relevantes."
                                  ],
                                  "verification": "Produzir um resumo escrito de 200-300 palavras com termos chave destacados.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Artigo ou capítulo de Grama et al. (2003), PDF do estudo de caso, caderno de anotações ou editor de texto.",
                                  "tips": "Leia ativamente sublinhando passagens sobre domínio e fronteiras para facilitar a análise posterior.",
                                  "learningObjective": "Compreender o escopo e os fundamentos do estudo de caso em decomposição de domínio.",
                                  "commonMistakes": "Ignorar detalhes matemáticos iniciais ou pular a introdução sem anotar."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificação das Técnicas de Decomposição de Domínio e Gerenciamento de Fronteiras",
                                  "subSteps": [
                                    "Desenhar o domínio original e sua decomposição (ex: em blocos 1D/2D para CFD).",
                                    "Identificar métodos de gerenciamento de fronteiras (ghost cells, overlapping domains).",
                                    "Mapear padrões de comunicação (MPI_Send/Recv ou similares).",
                                    "Listar vantagens e desvantagens da decomposição escolhida conforme Grama et al.",
                                    "Comparar com decomposições alternativas mencionadas no estudo."
                                  ],
                                  "verification": "Criar um diagrama esquemático da decomposição com legendas explicativas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Papel ou software de desenho (Draw.io), código fonte do estudo se disponível, referência Grama et al.",
                                  "tips": "Use cores diferentes para distinguir fronteiras internas e ghost regions no diagrama.",
                                  "learningObjective": "Reconhecer e diagramar técnicas específicas de decomposição e comunicação em memória distribuída.",
                                  "commonMistakes": "Confundir decomposição espacial com temporal ou ignorar overhead de comunicação nas fronteiras."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Análise do Desempenho e Impacto da Comunicação",
                                  "subSteps": [
                                    "Extrair métricas de speedup, eficiência e tempo de comunicação do estudo.",
                                    "Calcular ou estimar o volume de dados trocados nas fronteiras por iteração.",
                                    "Analisar gráficos de scaling (weak/strong) e identificar gargalos.",
                                    "Relacionar resultados com princípios de Grama et al. sobre balanceamento de carga.",
                                    "Simular um cenário simples de comunicação usando pseudocódigo MPI."
                                  ],
                                  "verification": "Gerar uma tabela comparativa de métricas de desempenho com interpretações.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Planilha (Excel/Google Sheets), gráficos do estudo de caso, documentação MPI.",
                                  "tips": "Foquem em ratios de comunicação/computação para quantificar impactos.",
                                  "learningObjective": "Avaliar quantitativamente o desempenho de estratégias de gerenciamento de fronteiras.",
                                  "commonMistakes": "Interpretar speedup sem considerar o número de processos ou topologias de rede."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliação Crítica e Propostas de Melhoria",
                                  "subSteps": [
                                    "Criticar limitações do estudo (ex: escalabilidade em domínios irregulares).",
                                    "Propor otimizações como decomposição adaptativa ou redução de ghost cells.",
                                    "Comparar com estudos similares em processamento de imagens.",
                                    "Concluir sobre aplicabilidade geral baseada em Grama et al.",
                                    "Escrever recomendações para implementações futuras."
                                  ],
                                  "verification": "Redigir um relatório crítico de 500 palavras com propostas específicas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Editor de texto, estudos de caso adicionais, referência Grama et al.",
                                  "tips": "Baseie críticas em evidências do estudo para manter objetividade.",
                                  "learningObjective": "Desenvolver pensamento crítico sobre trade-offs em programação paralela.",
                                  "commonMistakes": "Fazer propostas genéricas sem ligação aos resultados observados."
                                }
                              ],
                              "practicalExample": "Analisar o estudo de caso de simulação CFD de fluxo laminar em torno de um cilindro (Grama et al., 2003, Capítulo 6), decompondo o domínio 2D em 4 subdomínios com ghost cells de largura 2 para gerenciamento de fronteiras via MPI_Isend/Irecv, medindo redução de 30% no tempo de comunicação.",
                              "finalVerifications": [
                                "Explicar verbalmente o papel das ghost cells na precisão numérica.",
                                "Reproduzir diagrama da decomposição sem consultar materiais.",
                                "Interpretar corretamente um gráfico de speedup do estudo.",
                                "Propor uma melhoria viável para o gerenciamento de fronteiras.",
                                "Relacionar o estudo com conceitos de balanceamento de carga de Grama et al.",
                                "Identificar 3 gargalos potenciais em cenários reais."
                              ],
                              "assessmentCriteria": [
                                "Profundidade na identificação de técnicas de fronteiras (30%)",
                                "Precisão quantitativa na análise de desempenho (25%)",
                                "Qualidade dos diagramas e visualizações (20%)",
                                "Originalidade e relevância das críticas/propostas (15%)",
                                "Integração correta da referência Grama et al. (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Equações de Navier-Stokes e métodos de diferenças finitas.",
                                "Física: Dinâmica de fluidos computacional (CFD).",
                                "Engenharia de Software: Design de algoritmos paralelos escaláveis.",
                                "Processamento de Sinais: Decomposição em imagens médicas ou satélite."
                              ],
                              "realWorldApplication": "Otimização de simulações CFD em design aerodinâmico de aviões (NASA), previsão climática (modelos globais) ou processamento paralelo de imagens em visão computacional para veículos autônomos, reduzindo tempo de computação de dias para horas em clusters HPC."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.4",
                    "name": "Topologias de Comunicação",
                    "description": "Estruturas de interconexão entre processos, como anel, malha e hipercube, para otimizar trocas de mensagens.",
                    "individualConcepts": [
                      {
                        "id": "10.1.2.4.1",
                        "name": "Topologia em Anel",
                        "description": "Estrutura de interconexão onde cada processo é conectado a exatamente dois vizinhos, formando um ciclo fechado. Otimiza trocas de mensagens unidirecionais ou bidirecionais em cenários de memória distribuída, como em algoritmos de redução ou broadcast sequencial.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.4.1.1",
                            "name": "Descrever a estrutura e propriedades da topologia em anel",
                            "description": "Explicar o grau (2), diâmetro (N-1 para N processos), conectividade e como mensagens propagam em um anel unidirecional ou bidirecional, relacionando com modelos de troca de mensagens em MPI.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a estrutura básica da topologia em anel",
                                  "subSteps": [
                                    "Desenhar um diagrama com N processos dispostos em círculo.",
                                    "Identificar conexões: cada processo ligado a exatamente dois vizinhos.",
                                    "Explicar que forma um ciclo fechado, unidirecional ou bidirecional."
                                  ],
                                  "verification": "Diagrama desenhado corretamente mostrando conexões vizinhas sem ramificações.",
                                  "estimatedTime": "10 minutos",
                                  "materials": "Papel e caneta ou software de desenho como Draw.io",
                                  "tips": "Comece com poucos processos (ex: 4) para visualizar melhor o ciclo.",
                                  "learningObjective": "Visualizar e representar graficamente a topologia em anel.",
                                  "commonMistakes": "Confundir com topologia em linha (não cíclica) ou estrela (grau variável)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular as propriedades fundamentais: grau, diâmetro e conectividade",
                                  "subSteps": [
                                    "Determinar o grau: sempre 2 para cada nó.",
                                    "Calcular o diâmetro: N-1 para N processos (maior distância entre nós).",
                                    "Analisar conectividade: 1 em unidirecional, 2 em bidirecional."
                                  ],
                                  "verification": "Listar valores corretos para um exemplo com N=5: grau=2, diâmetro=4, conectividade=1 ou 2.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Calculadora ou planilha para simular distâncias",
                                  "tips": "Use fórmula diâmetro = floor(N/2) para bidirecional se aplicável, mas foque em unidirecional.",
                                  "learningObjective": "Quantificar propriedades métricas da topologia.",
                                  "commonMistakes": "Errar diâmetro como N em vez de N-1 ou ignorar direção nas conexões."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar propagação de mensagens em anel unidirecional",
                                  "subSteps": [
                                    "Simular envio de mensagem de um processo origem passando por vizinhos.",
                                    "Contar saltos necessários para alcançar destino (distância no ciclo).",
                                    "Descrever broadcast: mensagem circula até voltar ao origem."
                                  ],
                                  "verification": "Traçar caminho de mensagem de P0 para P3 em anel de 5 processos (passa por P1,P2).",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Exemplo de código MPI simples ou simulador gráfico",
                                  "tips": "Pense em 'token passing': mensagem só avança no sentido horário.",
                                  "learningObjective": "Entender fluxo sequencial de mensagens em rede cíclica.",
                                  "commonMistakes": "Assumir comunicação direta (p2p) em vez de relay via vizinhos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar anel unidirecional vs bidirecional e relacionar com MPI",
                                  "subSteps": [
                                    "Explicar bidirecional: mensagens em ambos sentidos, reduz diâmetro.",
                                    "Mapear para MPI: usar MPI_Graph_create com vizinhos definidos.",
                                    "Discutir vantagens/desvantagens: simples mas latência alta."
                                  ],
                                  "verification": "Escrever pseudocódigo MPI para vizinhos em anel e explicar diferenças.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Documentação MPI (mpi-forum.org) e editor de código",
                                  "tips": "Em MPI, defina graph com 2 arestas por rank: prev e next.",
                                  "learningObjective": "Conectar teoria à implementação prática em MPI.",
                                  "commonMistakes": "Confundir com topologias cartesianas ou ignorar overhead de MPI."
                                }
                              ],
                              "practicalExample": "Em um cluster com 4 processos (P0-P1-P2-P3), P0 envia 'Olá' para P2 em anel unidirecional: P0→P1→P2 (2 saltos). Para broadcast, mensagem circula P0→P1→P2→P3→P0. No MPI: MPI_Graph_create com coords [[0,1],[1,2],[2,3],[3,0]].",
                              "finalVerifications": [
                                "Desenhar diagrama de anel com 6 nós e rotular conexões.",
                                "Calcular diâmetro e grau para N=10.",
                                "Simular propagação de mensagem de nó 0 para nó 7.",
                                "Explicar diferença unidirecional vs bidirecional.",
                                "Mapear para função MPI_Graph_neighbors.",
                                "Identificar conectividade correta."
                              ],
                              "assessmentCriteria": [
                                "Precisão no grau (sempre 2) e diâmetro (N-1).",
                                "Correta descrição da propagação sequencial de mensagens.",
                                "Diagrama claro e sem erros topológicos.",
                                "Relação explícita com MPI e modelos de troca.",
                                "Identificação de conectividade e direções.",
                                "Explicação de vantagens/desvantagens lógicas."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: Anel como grafo cíclico C_n.",
                                "Redes de Computadores: Protocolo Token Ring.",
                                "Algoritmos Distribuídos: Eleição de líder (algoritmo de Chang-Roberts).",
                                "Sistemas Operacionais: Comunicação inter-processo em clusters."
                              ],
                              "realWorldApplication": "Usado em redes Token Ring históricas para evitar colisões; em blockchain para consenso em anel (ex: ring signatures); em supercomputadores para topologias lógicas simples em MPI para testes de latência em clusters distribuídos."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.1.2",
                            "name": "Identificar vantagens e desvantagens da topologia em anel",
                            "description": "Listar vantagens como simplicidade de implementação e custo baixo de hardware; desvantagens como latência alta para mensagens distantes e falha crítica em um nó. Comparar com taxonomia de Flynn para memória distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o funcionamento básico da topologia em anel",
                                  "subSteps": [
                                    "Desenhe um diagrama simples de uma topologia em anel com 4-6 nós conectados unidirecionalmente.",
                                    "Explique como as mensagens circulam: cada nó envia para o próximo e recebe do anterior.",
                                    "Simule o envio de uma mensagem de um nó para outro adjacente e para um distante.",
                                    "Identifique o caminho único que uma mensagem percorre em uma rede em anel.",
                                    "Discuta o conceito de token passing em variações como Token Ring."
                                  ],
                                  "verification": "Desenhe e rotule corretamente um diagrama de topologia em anel e simule o fluxo de uma mensagem verbalmente ou em papel.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta para diagramas",
                                    "Vídeo tutorial sobre topologia em anel (ex: YouTube ou Khan Academy)",
                                    "Simulador online de redes como Cisco Packet Tracer"
                                  ],
                                  "tips": "Comece com poucos nós para visualizar melhor o fluxo circular; use setas para indicar direção.",
                                  "learningObjective": "Entender a estrutura e o mecanismo de comunicação na topologia em anel.",
                                  "commonMistakes": [
                                    "Confundir com topologia em estrela (múltiplos caminhos)",
                                    "Ignorar a unidirecionalidade do anel",
                                    "Achar que mensagens podem pular nós"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e analisar as vantagens da topologia em anel",
                                  "subSteps": [
                                    "Liste vantagens como simplicidade de implementação (poucas conexões por nó).",
                                    "Discuta custo baixo de hardware (apenas 2 cabos por nó).",
                                    "Explique previsibilidade de desempenho em redes pequenas.",
                                    "Compare com topologias mais complexas como malha completa.",
                                    "Forneça exemplos históricos como Token Ring da IBM."
                                  ],
                                  "verification": "Escreva uma lista de pelo menos 3 vantagens com justificativas curtas e um exemplo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Artigo sobre topologias de rede (Wikipedia: Ring Network)",
                                    "Tabela comparativa em branco para anotações"
                                  ],
                                  "tips": "Pense em cenários de baixo orçamento; associe simplicidade a menos falhas de cabeamento.",
                                  "learningObjective": "Reconhecer as vantagens práticas da topologia em anel em contextos de memória distribuída.",
                                  "commonMistakes": [
                                    "Superestimar escalabilidade como vantagem",
                                    "Ignorar limitações em redes grandes",
                                    "Confundir com bidirecionalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar e analisar as desvantagens da topologia em anel",
                                  "subSteps": [
                                    "Descreva latência alta para mensagens distantes (devem percorrer o anel inteiro).",
                                    "Explique falha crítica: um nó falho interrompe toda a comunicação.",
                                    "Discuta dificuldade de adicionar/remover nós sem downtime.",
                                    "Simule uma falha em um nó e observe o impacto global.",
                                    "Compare com topologias tolerantes a falhas como hiper-cubo."
                                  ],
                                  "verification": "Crie um diagrama mostrando uma falha e liste 3 desvantagens com impactos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Simulador de falhas em redes (NS-3 ou similar)",
                                    "Papel para diagramas de falha"
                                  ],
                                  "tips": "Teste falhas em simulações para ver o 'efeito dominó'; priorize desvantagens em escalabilidade.",
                                  "learningObjective": "Analisar limitações da topologia em anel, especialmente em memória distribuída.",
                                  "commonMistakes": [
                                    "Subestimar latência em anéis grandes",
                                    "Achar que falha em um nó é isolada",
                                    "Ignorar overhead de token passing"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com a taxonomia de Flynn no contexto de memória distribuída",
                                  "subSteps": [
                                    "Revise taxonomia de Flynn: foque em MIMD para memória distribuída.",
                                    "Explique como topologia em anel suporta MIMD com comunicação ponto-a-ponto sequencial.",
                                    "Compare latência do anel vs. memória compartilhada (SISD/SIMD).",
                                    "Discuta adequação para programação paralela em clusters distribuídos.",
                                    "Crie uma tabela comparativa: anel vs. outras topologias em Flynn."
                                  ],
                                  "verification": "Preencha uma tabela comparativa com Flynn e liste adequações/desadequações.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Resumo da taxonomia de Flynn (PDF ou slide)",
                                    "Tabela em Excel/Google Sheets"
                                  ],
                                  "tips": "Lembre: Flynn classifica por instrução/dados, topologias por comunicação; conecte via MIMD distribuída.",
                                  "learningObjective": "Relacionar topologia em anel à taxonomia de Flynn para programação paralela.",
                                  "commonMistakes": [
                                    "Confundir Flynn com topologias (Flynn é arquitetural)",
                                    "Ignorar MIMD distribuída",
                                    "Não contextualizar com memória distribuída"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 8 computadores simulando sensores IoT em uma fábrica, configure uma topologia em anel usando MPI para enviar alertas de temperatura. Observe como um alerta de um sensor distante demora (alta latência) e como falhar um nó para toda a fábrica (falha crítica), destacando simplicidade inicial vs. riscos.",
                              "finalVerifications": [
                                "Liste corretamente 3 vantagens e 3 desvantagens sem erros factuais.",
                                "Desenhe diagrama de anel com fluxo de mensagem e falha marcada.",
                                "Explique impacto na taxonomia de Flynn para MIMD distribuída.",
                                "Simule em ferramenta e descreva observações de latência.",
                                "Compare verbalmente com topologia em barramento."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de vantagens/desvantagens (80% corretas).",
                                "Profundidade na análise de latência e falhas com exemplos.",
                                "Correta integração com taxonomia de Flynn (MIMD distribuída).",
                                "Qualidade de diagramas e simulações (clareza visual).",
                                "Capacidade de discutir aplicações reais e limitações.",
                                "Completude de listas e comparações (mínimo 3 itens por categoria)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Comparação com Ethernet e Token Ring.",
                                "Análise de Sistemas: Modelagem de desempenho e MTBF em topologias.",
                                "Programação Paralela: Implementação em MPI/OpenMPI para anéis.",
                                "Engenharia de Software: Trade-offs em design de sistemas distribuídos."
                              ],
                              "realWorldApplication": "Usada em redes Token Ring antigas (IBM), anéis de fibra ótica em telecomunicações, e em blockchains como proof-of-stake gossip protocols ou sensores em anel em monitoramento industrial, onde simplicidade compensa baixa escalabilidade."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.1.3",
                            "name": "Implementar comunicação básica em topologia de anel com MPI",
                            "description": "Codificar envio e recebimento ponto-a-ponto em um anel usando MPI_Send e MPI_Recv para simular broadcast ou all-reduce, medindo tempo de execução em clusters.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e definir topologia de anel",
                                  "subSteps": [
                                    "Inclua as bibliotecas necessárias: #include <mpi.h> e headers padrão como stdio.h, stdlib.h",
                                    "Inicialize MPI com MPI_Init(&argc, &argv);",
                                    "Obtenha o número de processos com MPI_Comm_size(MPI_COMM_WORLD, &size); e o rank com MPI_Comm_rank(MPI_COMM_WORLD, &rank);",
                                    "Defina os vizinhos no anel: próximo = (rank + 1) % size; anterior = (rank + size - 1) % size;",
                                    "Prepare variáveis para dados a serem enviados (ex: int message = rank;)"
                                  ],
                                  "verification": "Compile e execute o programa com mpirun -np 4 ./programa para verificar se MPI inicializa corretamente e ranks são impressos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Cluster ou máquina multi-core com OpenMPI/MPICH instalado",
                                    "Editor de código (VSCode, Vim)"
                                  ],
                                  "tips": "Use MPI_COMM_WORLD para comunicação global simples. Teste com poucos processos (4-8) localmente antes de cluster.",
                                  "learningObjective": "Entender inicialização MPI e modelagem lógica de topologia de anel.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init antes de chamadas MPI.",
                                    "Cálculo incorreto de vizinhos levando a deadlocks.",
                                    "Não verificar size >= 2."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar envio de mensagem do processo raiz em sentido horário",
                                  "subSteps": [
                                    "Se rank == 0 (raiz), prepare a mensagem inicial (ex: int data = 42;).",
                                    "Use MPI_Send(&data, 1, MPI_INT, next, 0, MPI_COMM_WORLD); para enviar ao próximo.",
                                    "Adicione uma barreira opcional MPI_Barrier(MPI_COMM_WORLD); para sincronizar.",
                                    "Imprima confirmação de envio no processo raiz.",
                                    "Garanta que apenas raiz envia inicialmente para simular broadcast."
                                  ],
                                  "verification": "Execute e verifique logs: apenas processo 0 envia, próximo recebe sinal de chegada.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Mesmo ambiente do step 1",
                                    "Exemplos de código MPI_Send da documentação MPI"
                                  ],
                                  "tips": "Use tag=0 para simplicidade em MPI_Send/Recv. Monitore com printf e fflush(stdout).",
                                  "learningObjective": "Dominar MPI_Send para comunicação ponto-a-ponto síncrona.",
                                  "commonMistakes": [
                                    "Enviar de todos os processos causando loops prematuros.",
                                    "Tipo de dado mismatch entre Send/Recv.",
                                    "Não sincronizar com barreira."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar recebimento e reenvio pelos processos intermediários",
                                  "subSteps": [
                                    "Para todos os processos: MPI_Recv(&data, 1, MPI_INT, prev, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);",
                                    "Após receber, imprima 'Processo [rank] recebeu [data]'.",
                                    "Reenvie para próximo: MPI_Send(&data, 1, MPI_INT, next, 0, MPI_COMM_WORLD);",
                                    "Para raiz, receba de volta do último para completar o ciclo do anel.",
                                    "Adicione loop para múltiplas iterações se simulando all-reduce básico (ex: somar valores)."
                                  ],
                                  "verification": "Logs mostram mensagem circulando: 0 ->1 ->2 ->... ->0 corretamente em todos processos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI para MPI_Recv e status",
                                    "Debugger como gdb com mpirun"
                                  ],
                                  "tips": "Recv bloqueia até mensagem chegar; use non-blocking (Isend/Irecv) para otimizações futuras.",
                                  "learningObjective": "Implementar forwarding em topologia de anel para simular broadcast.",
                                  "commonMistakes": [
                                    "Deadlock por ordem errada Send/Recv.",
                                    "Ignorar status de erro em Recv.",
                                    "Não tratar raiz corretamente no ciclo."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Medir tempo de execução e simular operação coletiva",
                                  "subSteps": [
                                    "Inclua <time.h> ou MPI_Wtime() para medição precisa.",
                                    "Se rank==0, inicie timer: double start = MPI_Wtime(); antes do Send inicial.",
                                    "Após ciclo completo (raiz recebe de volta), finalize timer: double end = MPI_Wtime();",
                                    "Calcule tempo: double time = end - start; e use MPI_Reduce para média global.",
                                    "Imprima tempos por processo e média para análise em clusters."
                                  ],
                                  "verification": "Execute com -np 8; verifique tempos impressos e escalabilidade (tempo ~ O(N) para anel).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Acesso a cluster (SLURM ou similar)",
                                    "Scripts de submissão PBS/SLURM"
                                  ],
                                  "tips": "MPI_Wtime() é wall-clock preciso. Rode múltiplas vezes para média.",
                                  "learningObjective": "Medir performance de comunicação em topologias distribuídas.",
                                  "commonMistakes": [
                                    "Usar clock() local em vez de MPI_Wtime() global.",
                                    "Não sincronizar timers com barreira.",
                                    "Reduce sem inicializar dados corretamente."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Finalizar programa, compilar, testar e depurar",
                                  "subSteps": [
                                    "Adicione MPI_Finalize(); no final de todos processos.",
                                    "Compile: mpicc -o ring ring.c -Wall -O2.",
                                    "Teste local: mpirun -np 4 ./ring; depois em cluster.",
                                    "Depure erros comuns com mpirun --oversubscribe ou valgrind.",
                                    "Otimize: teste com mais processos e compare tempos."
                                  ],
                                  "verification": "Programa executa sem leaks, ciclo completa em <1s para 8 processos, tempos consistentes.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Ferramentas de profiling como mpiP ou TAU",
                                    "Scripts de teste automatizados"
                                  ],
                                  "tips": "Use -hostfile para pinning em cluster. Valide com N=2,4,8.",
                                  "learningObjective": "Garantir programa robusto e performático em ambientes paralelos.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Finalize() causando hangs.",
                                    "Compilação sem flags de warning.",
                                    "Não testar escalabilidade."
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa 'ring_broadcast.c' onde o processo 0 envia 'Olá do processo raiz!' que circula pelo anel de 8 processos. Cada processo imprime ao receber e reenvia. Meça tempo total com MPI_Wtime() e imprima média via MPI_Reduce. Execute em cluster: srun -n 8 ./ring_broadcast.",
                              "finalVerifications": [
                                "Programa compila e executa com 2-16 processos sem erros ou deadlocks.",
                                "Mensagem circula corretamente pelo anel em todos ranks.",
                                "Tempos de execução são medidos e impressos globalmente.",
                                "Simulação de broadcast completa em O(N) passos.",
                                "Nenhum processo trava ou perde mensagens.",
                                "Resultados consistentes em múltiplas runs."
                              ],
                              "assessmentCriteria": [
                                "Uso correto de MPI_Send/MPI_Recv com tags e tipos.",
                                "Topologia de anel implementada logicamente sem hardcode.",
                                "Medição de tempo precisa com MPI_Wtime() e redução coletiva.",
                                "Código limpo, comentado e livre de race conditions/deadlocks.",
                                "Escalabilidade demonstrada em testes com diferentes N.",
                                "Tratamento de bordas (raiz e size=2)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Topologias físicas vs lógicas em LAN/WAN.",
                                "Algoritmos e Estruturas: Grafos cíclicos e traversais.",
                                "Sistemas Operacionais: Gerenciamento de processos distribuídos.",
                                "Análise de Performance: Big-O em comunicações paralelas.",
                                "Engenharia de Software: Debugging em ambientes não-determinísticos."
                              ],
                              "realWorldApplication": "Em supercomputadores HPC, topologias de anel são base para algoritmos de gossip em MPI collectives (Allgather, Allreduce), usadas em simulações científicas como clima ou genômica, otimizando bandwidth em clusters sem hardware especial."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.1.4",
                            "name": "Analisar desempenho de trocas em anel",
                            "description": "Calcular tempo de comunicação para operações coletivas (ex.: tempo = (N-1)*α + N*β para broadcast, onde α é latência e β é taxa de transferência) e otimizar com MPI topologies.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Básicos de Latência e Taxa de Transferência em Topologias de Anel",
                                  "subSteps": [
                                    "Defina latência (α) como o tempo fixo de inicialização de uma mensagem.",
                                    "Defina taxa de transferência (β) como o tempo por byte transferido.",
                                    "Descreva a topologia em anel: cada processo envia para o vizinho seguinte.",
                                    "Explique o fluxo unidirecional em anel para operações coletivas.",
                                    "Identifique o número de saltos em anel: N-1 para broadcast de uma origem."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito os conceitos de α e β, e desenhe um anel com 4 nós mostrando o caminho de broadcast.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Documentação MPI sobre topologias",
                                    "Papel e caneta para diagramas",
                                    "Notebook com Python ou C para anotações"
                                  ],
                                  "tips": "Use analogias como uma mensagem passando por uma fila circular para visualizar o anel.",
                                  "learningObjective": "Compreender os parâmetros fundamentais α e β e sua aplicação em topologias de anel.",
                                  "commonMistakes": [
                                    "Confundir α com β (latência vs. bandwidth)",
                                    "Ignorar o overhead de inicialização em mensagens pequenas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular o Tempo de Comunicação para Broadcast em Topologia de Anel",
                                  "subSteps": [
                                    "Escreva a fórmula para broadcast: tempo = (N-1) * α + N * β * tamanho_mensagem.",
                                    "Escolha valores exemplo: N=8, α=10μs, β=1μs/byte, mensagem=1KB.",
                                    "Calcule passo a passo: saltos =7, overhead latência=70μs, transferência=8*1024μs.",
                                    "Implemente uma função simples em Python para automatizar o cálculo.",
                                    "Teste com diferentes tamanhos de mensagem e valores de N."
                                  ],
                                  "verification": "Forneça cálculos corretos para 3 cenários diferentes e valide com código Python.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Calculadora ou Python/Jupyter Notebook",
                                    "Referência: modelo de Hockney para comunicação MPI"
                                  ],
                                  "tips": "Sempre fatorize o tamanho da mensagem em bytes para evitar erros de unidade.",
                                  "learningObjective": "Aplicar a fórmula de tempo de broadcast em anel com precisão numérica.",
                                  "commonMistakes": [
                                    "Esquecer o fator N na transferência (é N hops * tamanho)",
                                    "Usar unidades inconsistentes (μs vs. ms)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Desempenho de Trocas (Exchanges) e Outras Operações Coletivas em Anel",
                                  "subSteps": [
                                    "Diferencie broadcast de all-to-all exchange: em anel, all-to-all requer 2*(N-1) passes.",
                                    "Calcule tempo para exchange: tempo ≈ N*(N-1)*α + N*(N-1)*β*tamanho.",
                                    "Compare com reduce ou all-reduce, adaptando para anel bidirecional.",
                                    "Meça impacto de mensagem pequena vs. grande em trocas.",
                                    "Simule com pseudocódigo MPI_Alltoall em anel."
                                  ],
                                  "verification": "Calcule e compare tempos para broadcast vs. all-to-all em N=16, justificando diferenças.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Pseudocódigo MPI",
                                    "Ferramenta de plotagem como Matplotlib para gráficos de tempo vs. N"
                                  ],
                                  "tips": "Desenhe o anel rotacionando para visualizar múltiplos passes em exchanges.",
                                  "learningObjective": "Modelar e calcular tempos para trocas e coletivas além de broadcast em anel.",
                                  "commonMistakes": [
                                    "Subestimar passes múltiplos em all-to-all (não é um único ciclo)",
                                    "Ignorar sincronização implícita"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar Desempenho Usando MPI Topologies e Comparações",
                                  "subSteps": [
                                    "Configure topologia de anel com MPI_Graph_create ou MPI_Cart_create aproximando anel.",
                                    "Compare tempo teórico de anel vs. hiper-cubo ou fully-connected.",
                                    "Identifique otimizações: anel bidirecional reduz saltos pela metade.",
                                    "Implemente benchmark simples com MPI_Bcast e MPI_Alltoallv em anel.",
                                    "Analise trade-offs: escalabilidade vs. latência em grandes N."
                                  ],
                                  "verification": "Gere relatório com comparações numéricas e sugestões de otimização para N=32.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Ambiente MPI (OpenMPI + cluster local ou cloud)",
                                    "Código template para topologias MPI"
                                  ],
                                  "tips": "Use MPI_Wtime para medir real vs. teórico e validar modelo.",
                                  "learningObjective": "Otimizar comunicações em anel e avaliar contra alternativas.",
                                  "commonMistakes": [
                                    "Não considerar contenda em links compartilhados",
                                    "Sobreestimar benefícios sem benchmarks reais"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 8 nós simulando processamento de imagem distribuída: use broadcast para distribuir kernels (1KB), calcule tempo=7*10μs +8*1024*1μs ≈10ms; para all-to-all exchange de tiles de imagem (64KB cada), otimize com anel bidirecional reduzindo de ~1s para 0.5s.",
                              "finalVerifications": [
                                "Calcula corretamente tempo de broadcast para N=16 com α=5μs, β=0.5μs/byte, 4KB.",
                                "Explica diferença entre unidirecional e bidirecional em trocas.",
                                "Implementa e roda benchmark MPI simples mostrando modelo teórico vs. medido.",
                                "Sugere otimização para cenário real com N=100.",
                                "Compara anel vs. outra topologia com razões quantitativas."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos (erro <5%)",
                                "Compreensão conceitual demonstrada em explicações",
                                "Capacidade de generalizar para operações além de broadcast",
                                "Uso correto de MPI topologies em código",
                                "Análise de trade-offs e otimizações claras",
                                "Validação com exemplos numéricos e benchmarks"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelos lineares e análise assintótica O(N).",
                                "Redes de Computadores: Latência e bandwidth em redes reais.",
                                "Algoritmos: Grafos e topologias para paralelismo.",
                                "Otimização: Técnicas de minimização de custo em sistemas distribuídos."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, otimizar MPI collectives em topologias de anel para simulações climáticas ou genômica, reduzindo tempo de comunicação de horas para minutos em clusters de milhares de nós."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.4.2",
                        "name": "Topologia em Malha (Mesh)",
                        "description": "Organização bidimensional ou tridimensional de processos em uma grade, onde cada nó se conecta a até 4 (2D) ou 6 (3D) vizinhos ortogonais. Adequada para problemas de decomposição de domínio em simulações científicas.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.4.2.1",
                            "name": "Descrever a estrutura e métricas da topologia em malha",
                            "description": "Definir grau (até 4 em 2D), diâmetro (2*(√N -1) para malha √N x √N), e roteamento de mensagens via caminhos Manhattan, integrando com modelos de memória distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a estrutura básica da topologia em malha",
                                  "subSteps": [
                                    "Visualize uma malha 2D como uma grade de nós conectados horizontal e verticalmente.",
                                    "Identifique nós de canto (2 vizinhos), borda (3 vizinhos) e interior (4 vizinhos).",
                                    "Estenda para malhas 3D com conexões em x, y e z.",
                                    "Desenhe uma malha √N x √N para N processadores.",
                                    "Compare com topologias lineares ou hipercubos para contrastar."
                                  ],
                                  "verification": "Desenhe e rotule corretamente uma malha 4x4 identificando tipos de nós.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Papel e caneta, software de desenho como Draw.io, vídeo introdutório sobre topologias paralelas.",
                                  "tips": "Comece com malhas pequenas (2x2 ou 3x3) para intuitividade.",
                                  "learningObjective": "Descrever visual e conceitualmente a disposição dos nós e arestas em uma topologia mesh.",
                                  "commonMistakes": "Confundir malha toroidal (com wrap-around) com malha padrão aberta."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular e interpretar o grau dos nós",
                                  "subSteps": [
                                    "Defina grau como o número máximo de vizinhos diretos de um nó.",
                                    "Calcule grau em 2D: máximo 4 (norte, sul, leste, oeste).",
                                    "Discuta variações: 2 para cantos, 3 para bordas.",
                                    "Estenda para 3D: máximo 6.",
                                    "Relacione com largura de banda de comunicação."
                                  ],
                                  "verification": "Liste graus para todos nós em uma malha 3x3 e identifique o máximo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Planilha Excel ou Python para cálculo, diagrama de malha impresso.",
                                  "tips": "Use coordenadas (i,j) para identificar vizinhos: (i±1,j) e (i,j±1).",
                                  "learningObjective": "Determinar e explicar o grau nodal em malhas 2D e 3D.",
                                  "commonMistakes": "Ignorar que grau varia por posição, assumindo uniforme."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Determinar o diâmetro da topologia em malha",
                                  "subSteps": [
                                    "Defina diâmetro como a maior distância mínima entre qualquer par de nós.",
                                    "Derive fórmula para 2D √N x √N: 2*(√N - 1).",
                                    "Calcule exemplos: N=9 (3x3) → diâmetro 4; N=16 (4x4) → 6.",
                                    "Compare com outras topologias (ex: linha tem diâmetro N-1).",
                                    "Discuta impacto na latência de comunicação."
                                  ],
                                  "verification": "Calcule diâmetro para malha 5x5 e prove com caminhos entre cantos opostos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Calculadora, pseudocódigo para BFS em grafos, ferramenta online de grafos.",
                                  "tips": "Distância Manhattan entre (1,1) e (√N,√N) é o diâmetro.",
                                  "learningObjective": "Calcular e justificar o diâmetro usando distâncias Manhattan.",
                                  "commonMistakes": "Usar √(2*(√N-1)) em vez da soma Manhattan (2*(√N-1))."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar roteamento de mensagens via caminhos Manhattan",
                                  "subSteps": [
                                    "Explique roteamento Manhattan: mover apenas em eixos x/y até destino.",
                                    "Implemente algoritmo simples: priorize x depois y.",
                                    "Calcule comprimento mínimo: |Δx| + |Δy|.",
                                    "Discuta deadlocks e soluções como dimension-order routing.",
                                    "Simule envio de mensagem de (1,1) para (3,4)."
                                  ],
                                  "verification": "Trace 3 rotas diferentes de um nó fonte a destino e identifique a mais curta.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Simulador de rede como ns-3 ou papel para tracing manual.",
                                  "tips": "Evite diagonais; só ortogonais para preservar regularidade.",
                                  "learningObjective": "Descrever e simular roteamento determinístico em malhas.",
                                  "commonMistakes": "Permitir movimentos diagonais, violando topologia."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integrar com modelos de memória distribuída",
                                  "subSteps": [
                                    "Relacione malha com MPI em clusters distribuídos.",
                                    "Discuta como grau afeta all-to-all communication.",
                                    "Explique impacto de diâmetro em collective operations (broadcast).",
                                    "Compare overhead de roteamento vs. topologias de menor diâmetro.",
                                    "Exemplo: Mapear malha lógica sobre hardware físico."
                                  ],
                                  "verification": "Escreva parágrafo conectando métricas da malha a performance em MPI_Sendrecv.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Documentação MPI, paper sobre topologias paralelas.",
                                  "tips": "Pense em supercomputadores como Blue Waters usando malhas.",
                                  "learningObjective": "Conectar métricas de topologia a desempenho em memória distribuída.",
                                  "commonMistakes": "Isolar topologia de contexto de programação paralela."
                                }
                              ],
                              "practicalExample": "Em uma malha 4x4 (16 nós), calcule grau máximo=4, diâmetro=6 (de (1,1) a (4,4): 3 direita + 3 baixo). Simule MPI mensagem de nó 0 para nó 15 via caminho Manhattan, medindo hops=6.",
                              "finalVerifications": [
                                "Explicar estrutura: nós em grade com conexões 4-vizinhança em 2D.",
                                "Calcular grau corretamente para posições variadas.",
                                "Derivar e computar diâmetro: 2*(√N -1).",
                                "Desenhar rota Manhattan entre dois nós arbitrários.",
                                "Relacionar métricas a latência em memória distribuída.",
                                "Identificar limitações vs. topologias como torus."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de estrutura e conexões (20%)",
                                "Correção em cálculos de grau e diâmetro (25%)",
                                "Clareza na descrição de roteamento Manhattan (20%)",
                                "Profundidade na integração com memória distribuída (20%)",
                                "Uso de exemplos e diagramas (10%)",
                                "Identificação de erros comuns e soluções (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: Distâncias, graus e diâmetros em grafos regulares.",
                                "Redes de Computadores: Topologias WAN/LAN semelhantes a malhas.",
                                "Algoritmos: Busca em largura (BFS) para diâmetros.",
                                "Matemática Discreta: Coordenadas cartesianas e distâncias L1.",
                                "Engenharia de Software: Modelagem de sistemas distribuídos."
                              ],
                              "realWorldApplication": "Usado em supercomputadores como Cray XT5 (malha 3D para milhares de nós), GPUs NVIDIA com grids de threads em malha, e data centers Google para roteamento de tráfego em switches em grade, otimizando latência em workloads paralelos como simulações climáticas."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.2.2",
                            "name": "Comparar variantes de malha (toroidal vs. não-toroidal)",
                            "description": "Explicar como malha toroidal reduz diâmetro pela metade adicionando conexões de borda, e discutir impacto em algoritmos de stencil em programação paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a topologia de malha não-toroidal",
                                  "subSteps": [
                                    "Defina uma malha 2D não-toroidal como um grafo grade com N x M nós, onde cada nó interno conecta-se a 4 vizinhos (cima, baixo, esquerda, direita).",
                                    "Identifique as bordas abertas: nós nas extremidades têm menos de 4 conexões.",
                                    "Calcule o diâmetro: distância máxima entre dois nós (ex: de (1,1) a (N,M) é N+M-2 passos).",
                                    "Desenhe uma malha 4x4 e marque caminhos entre cantos opostos.",
                                    "Discuta o comprimento médio de caminho e o grau médio dos nós."
                                  ],
                                  "verification": "Desenhar a malha e calcular corretamente o diâmetro para uma grade 4x4 (deve ser 6).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Ferramenta de desenho de grafos como Graphviz ou Draw.io"
                                  ],
                                  "tips": "Sempre rotule os nós com coordenadas (i,j) para facilitar cálculos de distância Manhattan.",
                                  "learningObjective": "Dominar a estrutura e métricas básicas de uma malha não-toroidal.",
                                  "commonMistakes": [
                                    "Confundir distância Manhattan com Euclidiana",
                                    "Ignorar que bordas reduzem conectividade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir a topologia de malha toroidal",
                                  "subSteps": [
                                    "Explique que a malha toroidal 'enrola' as bordas: conecta a borda esquerda à direita e topo ao fundo, formando um toro.",
                                    "Descreva como cada nó agora tem exatamente 4 vizinhos, independentemente da posição.",
                                    "Calcule o novo diâmetro: aproximadamente metade do não-toroidal, min(N/2 + M/2, N+M/2).",
                                    "Desenhe uma malha 4x4 toroidal e trace caminhos curtos entre cantos (usando wrap-around).",
                                    "Compare visualmente com a versão não-toroidal."
                                  ],
                                  "verification": "Calcular diâmetro de malha 4x4 toroidal (deve ser 4 ou 3, confirmando redução).",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Simulador online de topologias como NetworkX em Python"
                                  ],
                                  "tips": "Pense na malha como um donut: saindo de uma borda, você entra pela oposta.",
                                  "learningObjective": "Entender como as conexões de borda transformam a topologia em toroidal.",
                                  "commonMistakes": [
                                    "Esquecer de aplicar wrap-around em cálculos",
                                    "Subestimar redução no diâmetro"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar métricas quantitativas das variantes",
                                  "subSteps": [
                                    "Calcule diâmetro, raio e comprimento médio de caminho para ambas em grades NxN.",
                                    "Compare grau dos nós: constante 4 em toroidal vs. variável em não-toroidal.",
                                    "Discuta impacto na latência: toroidal reduz saltos máximos pela metade.",
                                    "Crie uma tabela comparativa para N=8 e N=16.",
                                    "Analise overhead: toroidal adiciona apenas 4 arestas por dimensão."
                                  ],
                                  "verification": "Preencher tabela comparativa com valores corretos (ex: diâmetro toroidal ~N para NxN).",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Calculadora"
                                  ],
                                  "tips": "Use fórmula de distância toroidal: min(|x1-x2|, N-|x1-x2|) + min(|y1-y2|, M-|y1-y2|).",
                                  "learningObjective": "Quantificar vantagens da topologia toroidal sobre a não-toroidal.",
                                  "commonMistakes": [
                                    "Calcular diâmetro toroidal como não-toroidal",
                                    "Ignorar wrap-around em médias"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar impacto em algoritmos de stencil na programação paralela",
                                  "subSteps": [
                                    "Explique stencil: operações locais em grades (ex: Laplace em simulações CFD).",
                                    "Descreva como topologia afeta comunicação: toroidal minimiza hops em trocas de halo.",
                                    "Simule iterações: não-toroidal tem gargalos em bordas; toroidal equilibra.",
                                    "Discuta escalabilidade em memória distribuída (MPI): menor diâmetro reduz tempo de sincronização.",
                                    "Avalie trade-offs: custo de hardware vs. performance."
                                  ],
                                  "verification": "Explicar verbalmente ou por escrito como toroidal acelera stencil em 20-50% em grandes grids.",
                                  "estimatedTime": "55 minutos",
                                  "materials": [
                                    "Código MPI simples para stencil (ex: GitHub repo)",
                                    "Ambiente Python com MPI"
                                  ],
                                  "tips": "Execute stencil em malha pequena para medir tempos de comunicação.",
                                  "learningObjective": "Relacionar topologias com performance em programação paralela.",
                                  "commonMistakes": [
                                    "Subestimar impacto de comunicação em stencil",
                                    "Confundir com memória compartilhada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma malha 8x8 para simulação de difusão térmica (stencil de 5 pontos): não-toroidal tem diâmetro 14, exigindo até 14 hops para dados de canto; toroidal reduz para 8 hops, halando iterações em ~40% em cluster MPI com 64 nós.",
                              "finalVerifications": [
                                "Calcular diâmetro corretamente para malhas 4x4 e 8x8 de ambas variantes.",
                                "Desenhar e rotular ambas topologias mostrando wrap-around.",
                                "Explicar redução pela metade no diâmetro com exemplo numérico.",
                                "Identificar impacto positivo em stencil: menor latência de comunicação.",
                                "Preencher tabela comparativa de métricas (diâmetro, grau médio).",
                                "Simular 10 iterações de stencil e notar diferença em hops."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de diâmetro e distâncias (90% correto).",
                                "Clareza na explicação visual e tabular das diferenças.",
                                "Compreensão profunda do impacto em programação paralela (ex: MPI).",
                                "Identificação correta de trade-offs (hardware vs. performance).",
                                "Capacidade de aplicar a exemplos reais como simulações científicas.",
                                "Ausência de erros comuns como ignorar wrap-around."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos (Matemática): distâncias e diâmetros em grades.",
                                "Redes de Computadores: topologias em switches e data centers.",
                                "Física Computacional: simulações de PDEs em malhas (CFD, clima).",
                                "Engenharia de Software: otimização de comunicação em HPC.",
                                "Análise Numérica: métodos de diferenças finitas em stencil."
                              ],
                              "realWorldApplication": "Em supercomputadores como Fugaku ou Frontier, malhas toroidais em topologias de rede (ex: Tofu, Slingshot) reduzem latência em simulações globais de clima ou fusão nuclear, acelerando stencil computations em ordens de magnitude para grids de bilhões de pontos."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.2.3",
                            "name": "Implementar vizinhança e comunicação em malha com MPI",
                            "description": "Usar MPI_Cart_create para mapear topologia 2D, implementar troca de dados com vizinhos via MPI_Sendrecv em decomposição de domínio para equações diferenciais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar MPI e criar topologia cartesiana 2D",
                                  "subSteps": [
                                    "Incluir headers necessários: <mpi.h> e inicializar MPI com MPI_Init.",
                                    "Definir dimensões da malha (ex: dims[0]=4, dims[1]=4 para 16 processos).",
                                    "Criar comunicador cartesiano com MPI_Cart_create(comm_old, ndims=2, dims, periods={0,0}, reorder=1, &comm_cart).",
                                    "Obter coordenadas do processo atual com MPI_Cart_coords(comm_cart, rank, 2, coords).",
                                    "Verificar se todos os processos estão mapeados corretamente imprimindo coordenadas."
                                  ],
                                  "verification": "Compilar e executar o código; cada processo deve imprimir suas coordenadas únicas sem erros de MPI.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Documentação MPI oficial",
                                    "Exemplo de código base MPI"
                                  ],
                                  "tips": "Use reorder=1 para otimizar mapeamento; teste com número de processos que seja produto das dimensões (ex: 16 processos).",
                                  "learningObjective": "Entender como mapear processos em uma grade 2D virtual usando MPI_Cart_create.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes",
                                    "Definir dims incompatível com número de processos",
                                    "Não tratar o caso de ranks extras"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar ranks dos vizinhos na malha",
                                  "subSteps": [
                                    "Para cada direção (norte, sul, leste, oeste), criar coordenadas do vizinho alterando coords[i] por ±1.",
                                    "Usar MPI_Cart_rank(comm_cart, neighbor_coords, &neighbor_rank) para obter rank.",
                                    "Verificar limites: se coords[0]==0, vizinho norte=-1 (sem troca); similar para outras bordas.",
                                    "Armazenar ranks em array vizinhos[4] com convenção: 0=norte, 1=sul, 2=leste, 3=oeste.",
                                    "Imprimir ranks dos vizinhos para depuração."
                                  ],
                                  "verification": "Executar e verificar logs: processos nas bordas têm -1 em direções ausentes; internos têm 4 vizinhos válidos.",
                                  "estimatedTime": "45 minutes",
                                  "materials": [
                                    "Código do Step 1",
                                    "Ferramenta de depuração como mpirun -np 16 ./a.out | sort"
                                  ],
                                  "tips": "Use MPI_PROC_NULL para vizinhos inexistentes em Sendrecv para evitar condições especiais.",
                                  "learningObjective": "Mapear relações de vizinhança em topologias de malha para comunicação eficiente.",
                                  "commonMistakes": [
                                    "Índices invertidos nas coordenadas",
                                    "Não tratar bordas corretamente",
                                    "Acessar coords sem MPI_Cart_coords"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar troca de dados com MPI_Sendrecv",
                                  "subSteps": [
                                    "Definir buffers de envio e recebimento (ex: double send_buf[2], recv_buf[2]).",
                                    "Para cada direção válida: MPI_Sendrecv(senddata=right_buf, count=1, MPI_DOUBLE, right_rank, tag_right, recvdata=left_buf, count=1, MPI_DOUBLE, left_rank, tag_left, comm_cart, &status).",
                                    "Implementar trocas em pares opostos (leste-oeste, norte-sul) para evitar deadlocks.",
                                    "Atualizar grade local com dados recebidos (ex: em decomposição de domínio para EDP).",
                                    "Adicionar barreira MPI_Barrier(comm_cart) após trocas para sincronização."
                                  ],
                                  "verification": "Executar com dados iniciais únicos por processo; verificar se bordas internas coincidem após trocas.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Código dos Steps anteriores",
                                    "Array 2D simulado para grade (ex: double grid[local_rows][local_cols])"
                                  ],
                                  "tips": "Use tags únicos por direção para evitar confusão; teste com dados não-simétricos.",
                                  "learningObjective": "Realizar comunicação não-bloqueante segura entre vizinhos usando Sendrecv.",
                                  "commonMistakes": [
                                    "Deadlock por ordem errada de Send/Recv",
                                    "Tamanhos de buffer inconsistentes",
                                    "Esquecer MPI_Wait para requests se usar Isend/Irecv"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar em solver de EDP e testar completude",
                                  "subSteps": [
                                    "Implementar iteração de Jacobi para equação de Laplace em grade 2D usando trocas.",
                                    "Inicializar grade com condição inicial (ex: pico central), iterar 100 passos com atualizações e trocas.",
                                    "Coletar resultados com MPI_Gather para processo raiz visualizar solução convergida.",
                                    "Executar com diferentes tamanhos (np=4,9,16) e verificar convergência.",
                                    "Perfilhar tempo de comunicação vs computação com MPI_Wtime."
                                  ],
                                  "verification": "Solução final deve ser suave e convergida; tempo de comunicação escalável.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Código completo",
                                    "Visualizador como Python/Matplotlib para output raiz",
                                    "mpirun com valgrind para leaks"
                                  ],
                                  "tips": "Use MPI_Cart_shift para abstrair vizinhos em vez de calcular manualmente em códigos maiores.",
                                  "learningObjective": "Aplicar topologia de malha em simulação numérica real de EDP.",
                                  "commonMistakes": [
                                    "Atualizar grade sem trocar ghost cells",
                                    "Não inicializar buffers corretamente",
                                    "Perda de precisão em Gather"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão de calor em uma placa 2D de 100x100 pontos, divida em domínios 25x25 por processo (4x4 malha). Cada iteração, troque valores das bordas com vizinhos via Sendrecv e atualize interior com stencil de 5 pontos. Após 500 iterações, o calor difunde uniformemente.",
                              "finalVerifications": [
                                "Código compila e executa sem erros MPI para múltiplos np (4-64).",
                                "Coordenadas e vizinhos impressos corretamente para todos processos.",
                                "Dados trocados validam: valor enviado por P(i,j) recebido por vizinho.",
                                "Solução de EDP converge independentemente do número de domínios.",
                                "Sem deadlocks ou perdas de mensagens em execuções longas.",
                                "Tempo de comunicação < 10% do total em malha 8x8."
                              ],
                              "assessmentCriteria": [
                                "Corretude da topologia: MPI_Cart_create retorna COMM_CART válido.",
                                "Identificação precisa de vizinhos, incluindo tratamento de bordas.",
                                "Implementação deadlock-free de Sendrecv com tags e status.",
                                "Integração funcional em solver iterativo de EDP.",
                                "Eficiência: escalabilidade linear com número de processos.",
                                "Código limpo, comentado e modular."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Discretização de EDPs parciais (diferenças finitas).",
                                "Física: Modelagem de difusão, ondas em malhas 2D.",
                                "Engenharia de Software: Abstrações de topologia para paralelismo.",
                                "Análise de Desempenho: Perfilagem de comunicações vs computação.",
                                "Visualização de Dados: Renderização de grades distribuídas."
                              ],
                              "realWorldApplication": "Simulações CFD em malhas não-estruturadas para previsão climática (ex: modelos de oceanos em supercomputadores), onde decomposição de domínio em malhas 2D/3D com MPI otimiza comunicação local, reduzindo latência em bilhões de pontos de grade."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.2.4",
                            "name": "Avaliar sobrecarga de comunicação em malha",
                            "description": "Estimar bandwidth e latência para padrões de acesso locais vs. globais, usando ferramentas como MPI profiling para otimizar em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Fundamentos de Topologia em Malha e Sobrecarga de Comunicação",
                                  "subSteps": [
                                    "Estude a estrutura de uma topologia em malha (mesh), incluindo dimensões 1D, 2D e 3D.",
                                    "Defina sobrecarga de comunicação: bandwidth (largura de banda) e latência como funções de hops.",
                                    "Compare acessos locais (vizinhos diretos) vs. globais (múltiplos hops).",
                                    "Calcule hops teóricos em uma malha NxN para comunicação entre nós arbitrários.",
                                    "Revise métricas MPI como tempo de envio/recebimento e throughput."
                                  ],
                                  "verification": "Resuma em um diagrama hops locais vs. globais para uma malha 4x4 e calcule latência teórica para 2 hops.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Documentação MPI (mpitutorial.com)",
                                    "Papel e lápis para diagramas",
                                    "Slides sobre topologias paralelas"
                                  ],
                                  "tips": "Visualize a malha como uma grade de pixels para intuitividade.",
                                  "learningObjective": "Identificar diferenças entre padrões de acesso locais e globais em malhas.",
                                  "commonMistakes": [
                                    "Confundir bandwidth com latência; ignorar overhead de sincronização."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente de Simulação MPI para Malha",
                                  "subSteps": [
                                    "Instale MPI (OpenMPI ou MPICH) em um cluster multicores ou use container Docker.",
                                    "Implemente um programa MPI básico que inicialize uma topologia em malha virtual (ex: 4x4 grid).",
                                    "Defina ranks como coordenadas (i,j) e crie funções para vizinhos (norte, sul, leste, oeste).",
                                    "Teste comunicação ponto-a-ponto entre vizinhos adjacentes.",
                                    "Compile e execute com 16 processos para simular a malha."
                                  ],
                                  "verification": "Execute o código e confirme que cada rank recebe mensagens de vizinhos sem erros (use mpirun -np 16).",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "OpenMPI instalado",
                                    "Editor de código (VSCode)",
                                    "Exemplo de código MPI grid topology"
                                  ],
                                  "tips": "Use MPI_Cart_create para topologia cartesiana automática.",
                                  "learningObjective": "Configurar uma malha distribuída funcional em MPI.",
                                  "commonMistakes": [
                                    "Não inicializar MPI corretamente; erros em mapeamento de ranks para coordenadas."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Medir Bandwidth e Latência com Padrões Locais vs. Globais",
                                  "subSteps": [
                                    "Implemente padrões locais: MPI_Sendrecv para vizinhos diretos.",
                                    "Implemente padrões globais: all-to-all ou broadcasts através de múltiplos hops.",
                                    "Use MPI_Wtime para medir tempos de comunicação em loops repetidos (1000 iterações).",
                                    "Calcule bandwidth = tamanho_mensagem / tempo_medio; latência = intercepto linear.",
                                    "Registre dados para diferentes tamanhos de mensagem (1KB a 1MB)."
                                  ],
                                  "verification": "Gere tabela com bandwidth/latência para acessos locais (1 hop) vs. globais (diametro da malha).",
                                  "estimatedTime": "2.5 hours",
                                  "materials": [
                                    "Código MPI da Step 2",
                                    "Planilha Excel/Google Sheets para plots"
                                  ],
                                  "tips": "Aqueça o canal com mensagens pequenas antes de medições.",
                                  "learningObjective": "Estimar quantitativamente sobrecarga em diferentes padrões.",
                                  "commonMistakes": [
                                    "Amostras insuficientes; não considerar variância de rede."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar com Ferramentas de Profiling e Otimizar",
                                  "subSteps": [
                                    "Instale e use ferramentas MPI como mpiP ou TAU para profiling.",
                                    "Execute o programa com profiling: mpirun -np 16 ./programa -profile.",
                                    "Analise traces: identifique bottlenecks em comunicação global.",
                                    "Otimize: use MPI_Isend/Irecv não-bloqueante ou collective operations.",
                                    "Reexecute medições e compare melhorias em bandwidth/latência."
                                  ],
                                  "verification": "Relatório com gráficos de profiling mostrando redução de 20%+ em sobrecarga global.",
                                  "estimatedTime": "3 hours",
                                  "materials": [
                                    "mpiP ou Vampir",
                                    "GNUPlot/Matplotlib para visualização"
                                  ],
                                  "tips": "Filtre traces por comunicação para foco em malha.",
                                  "learningObjective": "Usar profiling para otimizar topologias em malha.",
                                  "commonMistakes": [
                                    "Interpretar mal traces; otimizar sem baseline."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Documentar Avaliação Completa",
                                  "subSteps": [
                                    "Compare resultados teóricos vs. empíricos (Hockney model).",
                                    "Teste em diferentes configurações multicores (2-16 cores).",
                                    "Documente thresholds: quando local > global em performance.",
                                    "Crie script automatizado para reexecução.",
                                    "Escreva relatório com recomendações de otimização."
                                  ],
                                  "verification": "Documento final com curvas de performance e conclusões acionáveis.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Relatórios anteriores",
                                    "LaTeX ou Markdown para doc"
                                  ],
                                  "tips": "Use log-log plots para bandwidth vs. tamanho.",
                                  "learningObjective": "Sintetizar avaliação para decisões de design paralela.",
                                  "commonMistakes": [
                                    "Ignorar escalabilidade; generalizações sem testes variados."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão em malha 8x8 com 64 processos MPI em um cluster de 4 nós multicores, meça latência local (1 hop: 10us) vs. global (7 hops: 70us), use mpiP para identificar 40% overhead em all-gather global, otimize com MPI_Alltoallv reduzindo para 25us.",
                              "finalVerifications": [
                                "Calcula hops corretamente em malha 2D/3D.",
                                "Medições empíricas batem com modelo teórico (±10%).",
                                "Profiling identifica top 3 bottlenecks de comunicação.",
                                "Otimização demonstra melhoria mensurável.",
                                "Relatório inclui thresholds locais/globais.",
                                "Script reproduz resultados em <5min."
                              ],
                              "assessmentCriteria": [
                                "Precisão das estimativas de bandwidth/latência (erro <15%).",
                                "Uso correto de ferramentas MPI profiling.",
                                "Profundidade de análise subSteps (cobertura >90%).",
                                "Qualidade de otimizações (melhoria >20%).",
                                "Clareza do relatório e visualizações.",
                                "Escalabilidade demonstrada em múltiplas configs."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Modelos de latência em switches.",
                                "Otimização Numérica: Trade-offs compute vs. communication.",
                                "Análise de Desempenho: Amostragem estatística e profiling.",
                                "Arquitetura de Computadores: Impacto de cache em multicores.",
                                "Engenharia de Software: Testes automatizados em paralelo."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier, otimizar stencil codes em malhas para simulações climáticas, reduzindo tempo de comunicação de 30% em codes de CFD (Computational Fluid Dynamics)."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.4.3",
                        "name": "Topologia Hipercubo",
                        "description": "Rede multidimensional onde cada um dos N=2^d processos conecta-se a d=log2(N) vizinhos via bits XOR. Oferece diâmetro logarítmico, ideal para trocas rápidas em supercomputadores.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.4.3.1",
                            "name": "Explicar construção e propriedades do hipercube",
                            "description": "Descrever como coordenadas binárias definem conexões (mudança de 1 bit), grau (log N), diâmetro (log N) e hamiltonicidade, relacionando com programação paralela distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os hipercubos em baixas dimensões (2D e 3D)",
                                  "subSteps": [
                                    "Desenhe um quadrado (hipercubo 2D) com 4 vértices rotulados de 00, 01, 10, 11.",
                                    "Identifique as arestas conectando vértices que diferem em exatamente um bit.",
                                    "Expanda para um cubo 3D com 8 vértices (000 a 111), desenhando as 12 arestas baseadas na regra de um bit de diferença.",
                                    "Conte o número de vizinhos por vértice (grau = dimensão atual).",
                                    "Visualize rotações para entender a simetria."
                                  ],
                                  "verification": "Desenho correto do cubo 3D com todas as arestas rotuladas por coordenadas binárias.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Vídeo tutorial sobre cubos hiperdimensionais (YouTube)"
                                  ],
                                  "tips": "Use cores diferentes para cada dimensão ao desenhar para facilitar a visualização.",
                                  "learningObjective": "Visualizar e construir hipercubos em 2D e 3D para intuitar a generalização.",
                                  "commonMistakes": [
                                    "Conectar vértices que diferem em mais de um bit",
                                    "Esquecer de rotular coordenadas binárias"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Generalizar a construção para n-dimensões usando coordenadas binárias",
                                  "subSteps": [
                                    "Defina um hipercube de dimensão n como grafo com 2^n vértices, cada um representado por string binária de n bits.",
                                    "Conecte dois vértices se suas coordenadas diferem em exatamente um bit (distância Hamming = 1).",
                                    "Calcule o número total de vértices: N = 2^n.",
                                    "Liste exemplos: n=1 (2 pontos), n=4 (16 vértices).",
                                    "Implemente uma função simples em Python para gerar vizinhos de um vértice dado."
                                  ],
                                  "verification": "Código Python que lista corretamente os n vizinhos de um vértice exemplo (ex: '001' em n=3).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Editor de código Python (VS Code ou Jupyter)",
                                    "Biblioteca itertools para combinações"
                                  ],
                                  "tips": "Use XOR bitwise (^ em Python) para calcular diferença de bits entre coordenadas.",
                                  "learningObjective": "Dominar a representação binária e regra de conexão para qualquer dimensão n.",
                                  "commonMistakes": [
                                    "Confundir distância Hamming com diferença numérica",
                                    "Gerar loops ou conexões inválidas no código"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar propriedades fundamentais: grau, diâmetro e conectividade",
                                  "subSteps": [
                                    "Determine o grau de cada vértice: exatamente n vizinhos (um por dimensão).",
                                    "Calcule o diâmetro: maior distância entre vértices é n (flipar todos os bits).",
                                    "Explique por que qualquer par de vértices tem caminho único de comprimento <= n.",
                                    "Verifique com exemplo: distância entre 000 e 111 em n=3 é 3.",
                                    "Discuta implicações: baixa latência em comunicações paralelas."
                                  ],
                                  "verification": "Tabela com grau, diâmetro e N para n=1 a 5, com justificativa matemática.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Planilha Excel ou papel para tabelas",
                                    "Referência: Wikipedia Hypercube graph"
                                  ],
                                  "tips": "Lembre que grau = log2(N), diâmetro = log2(N) para balanceamento em topologias.",
                                  "learningObjective": "Quantificar propriedades métricas do hipercube e sua eficiência.",
                                  "commonMistakes": [
                                    "Confundir grau com número total de arestas (n*2^{n-1})",
                                    "Achar diâmetro maior que n"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar hamiltonicidade e aplicações em programação paralela",
                                  "subSteps": [
                                    "Defina caminho/ciclo hamiltoniano: visita cada vértice exatamente uma vez.",
                                    "Prove que hipercubos são hamiltonianos via Gray Code (sequência onde bits mudam um por vez).",
                                    "Implemente Gray Code para n=3 e trace o ciclo no cubo desenhado.",
                                    "Relacione com programação paralela: mapeamento de processos em nós, roteamento de mensagens.",
                                    "Exemplo: Algoritmo de soma paralela em hipercube distribuído."
                                  ],
                                  "verification": "Sequência Gray Code completa para n=3 que forma ciclo hamiltoniano.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python para gerar Gray Code (função bin(i) ^ (i>>1))",
                                    "Artigo sobre topologias MPI"
                                  ],
                                  "tips": "Gray Codes são chave para roteamento eficiente sem conflitos em redes distribuídas.",
                                  "learningObjective": "Conectar propriedades teóricas a usos práticos em sistemas distribuídos.",
                                  "commonMistakes": [
                                    "Achar que todos grafos são hamiltonianos",
                                    "Ignorar overhead de roteamento em diâmetro log N"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma rede de 8 computadores (hipercubo 3D), cada máquina tem coordenada binária (ex: 101). Para enviar mensagem de 000 para 111, roteie via flips: 000 -> 001 -> 011 -> 111 (3 hops = diâmetro), simulando em Python com MPI ou sockets.",
                              "finalVerifications": [
                                "Desenhar hipercube 4D com rótulos corretos e 4 vizinhos por vértice.",
                                "Calcular grau e diâmetro para N=16 (n=4).",
                                "Gerar código Python listando vizinhos e distâncias Hamming.",
                                "Explicar Gray Code para ciclo hamiltoniano em n=3.",
                                "Descrever como hipercube otimiza comunicação em cluster distribuído.",
                                "Identificar aplicação em programação paralela (ex: all-reduce)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na regra de conexão (1 bit flip): 100% dos exemplos corretos.",
                                "Cálculos matemáticos exatos para grau (n) e diâmetro (n).",
                                "Implementação funcional de gerador de vizinhos ou Gray Code.",
                                "Explicação clara da hamiltonicidade com exemplo.",
                                "Conexão explícita com programação paralela distribuída.",
                                "Uso correto de terminologia (Hamming, topologia)."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: hipercube como grafo Q_n, isomorfismo com cubos.",
                                "Álgebra Linear: autovalores da matriz de adjacência.",
                                "Ciência da Computação: algoritmos paralelos (FFT, sorting em hipercubos).",
                                "Matemática Discreta: códigos Gray e combinatoria binária.",
                                "Redes de Computadores: topologias escaláveis como Fat-Tree inspiradas em hipercubos."
                              ],
                              "realWorldApplication": "Hipercubos foram usados em supercomputadores como Intel iPSC/860 e Connection Machine, otimizando roteamento de mensagens em programação paralela com MPI. Hoje, inspiram data centers escaláveis e algoritmos quânticos em qubits (hipercubo como espaço de estados)."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.3.2",
                            "name": "Identificar vantagens para operações coletivas",
                            "description": "Destacar bit-reversal para FFT paralela, e-mesh para roteamento, superioridade em relação a anel/malha em termos de tempo de comunicação O(log N).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos básicos de topologias de rede e operações coletivas",
                                  "subSteps": [
                                    "Defina topologias comuns: anel, malha 2D e hipercubo.",
                                    "Explique operações coletivas como broadcast, reduce e all-to-all.",
                                    "Identifique métricas chave: diâmetro da rede e tempo de comunicação.",
                                    "Calcule diâmetro para anel (O(N)) e malha 2D (O(√N)).",
                                    "Liste exemplos de aplicações de operações coletivas em computação paralela."
                                  ],
                                  "verification": "Resuma em um diagrama comparativo as topologias e métricas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notas de aula sobre topologias, papel e caneta ou ferramenta de diagramação como Draw.io.",
                                  "tips": "Use analogias visuais, como comparar diâmetro a distância em uma cidade.",
                                  "learningObjective": "Compreender fundamentos para contextualizar vantagens do hipercubo.",
                                  "commonMistakes": "Confundir diâmetro com grau de conectividade; sempre diferencie."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar propriedades da topologia hipercubo",
                                  "subSteps": [
                                    "Descreva estrutura do hipercubo: dimensões d, N=2^d nós, arestas binárias.",
                                    "Calcule diâmetro: O(log N) ou d passos.",
                                    "Explique roteamento bit-reversal: inverter bits para permutações eficientes.",
                                    "Simule roteamento em hipercubo de dimensão 3 (8 nós).",
                                    "Discuta conectividade: 2d vizinhos por nó."
                                  ],
                                  "verification": "Desenhe hipercubo de 3D e trace um caminho bit-reversal de 000 para 111.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Simulador online de hipercubo ou software como Graphviz.",
                                  "tips": "Pense em hipercubo como cubo multidimensional; visualize projeções 2D.",
                                  "learningObjective": "Dominar características únicas que habilitam eficiência em coletivas.",
                                  "commonMistakes": "Ignorar que N deve ser potência de 2; verifique sempre."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar tempos de comunicação com anel e malha",
                                  "subSteps": [
                                    "Compare diâmetros: hipercubo O(log N) vs anel O(N) vs malha O(√N).",
                                    "Analise broadcast: hipercubo dobra em cada dimensão.",
                                    "Calcule tempo para all-reduce em cada topologia.",
                                    "Quantifique superioridade: fator log N vs linear.",
                                    "Crie tabela comparativa com N=1024."
                                  ],
                                  "verification": "Preencha tabela mostrando tempos relativos para N=16, 64, 256.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Planilha Excel ou Python para cálculos simples.",
                                  "tips": "Use log2(N) para diâmetro hipercubo; pratique com calculadora.",
                                  "learningObjective": "Quantificar vantagens métricas do hipercubo.",
                                  "commonMistakes": "Esquecer latência vs bandwidth; foque em hops para comunicação."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar vantagens específicas em FFT paralela e roteamento e-mesh",
                                  "subSteps": [
                                    "Explique bit-reversal em FFT: mapeamento natural em hipercubo.",
                                    "Descreva implementação paralela de FFT: O(log N) estágios.",
                                    "Defina e-mesh: roteamento em hipercubo para padrões mesh-like.",
                                    "Compare eficiência: FFT em hipercubo vs malha (menos atrasos).",
                                    "Liste 3 vantagens chave para operações coletivas."
                                  ],
                                  "verification": "Escreva parágrafo explicando por que hipercubo é superior para FFT.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Código exemplo de FFT paralela (MPI ou pseudocódigo), artigos sobre hipercubo.",
                                  "tips": "Assista vídeo de FFT em hipercubo para visualização.",
                                  "learningObjective": "Identificar e articular vantagens concretas para coletivas.",
                                  "commonMistakes": "Generalizar sem exemplos; sempre cite bit-reversal ou e-mesh."
                                }
                              ],
                              "practicalExample": "Em um cluster de 16 nós (hipercubo 4D), implemente FFT paralela usando bit-reversal para permutar dados em O(log N)=4 hops, contrastando com malha 4x4 que requer até 6 hops, reduzindo tempo total de comunicação em 30-50%.",
                              "finalVerifications": [
                                "Explica corretamente bit-reversal para FFT em hipercubo.",
                                "Compara diâmetros: O(log N) vs O(N) e O(√N).",
                                "Identifica e-mesh como otimização de roteamento.",
                                "Lista pelo menos 3 vantagens quantitativas para coletivas.",
                                "Desenha caminho de comunicação em hipercubo vs anel.",
                                "Calcula tempo para N=1024 em topologias diferentes."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (diâmetros e propriedades: 30%)",
                                "Uso de exemplos específicos (bit-reversal, e-mesh: 25%)",
                                "Quantificação de vantagens (O(log N): 20%)",
                                "Clareza na comparação com anel/malha (15%)",
                                "Profundidade de análise para FFT e coletivas (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: diâmetro e Hamiltoniano em hipercubos.",
                                "Algoritmos Paralelos: MPI collectives e topologias lógicas.",
                                "Redes de Computadores: Latência em interconexões como Fat-Tree.",
                                "Matemática Discreta: Operações bitwise e logaritmos."
                              ],
                              "realWorldApplication": "Em supercomputadores como IBM Blue Gene (hipercubo-like), acelera simulações científicas (ex: modelagem climática via FFT paralela), reduzindo tempo de comunicação em ordens de magnitude comparado a topologias mesh em clusters Ethernet."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.3.3",
                            "name": "Implementar roteamento e comunicação em hipercube com MPI",
                            "description": "Codificar MPI_Graph_create para hipercube, implementar unicast via XOR e collective como all-to-all, testando em emuladores de cluster.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e criar topologia hipercube com MPI_Graph_create",
                                  "subSteps": [
                                    "Instalar e configurar um ambiente MPI local (ex: OpenMPI ou MPICH) com suporte a emuladores como SmPVM ou Cluster Emulator.",
                                    "Escrever código C/MPI para inicializar MPI_Init e obter o rank e size do comunicador.",
                                    "Implementar função para gerar vizinhos do hipercube usando bitwise XOR: para um rank r em dimensão d=0 a log2(P), vizinho = r XOR (1 << d).",
                                    "Usar MPI_Graph_create para definir a topologia: passar array de índices de vizinhos e edges para cada processo.",
                                    "Verificar criação com MPI_Graph_neighbors_count e MPI_Topo_test."
                                  ],
                                  "verification": "Executar o programa e confirmar que MPI_Topo_test retorna MPI_GRAPH e cada processo lista exatamente log2(P) vizinhos corretos via MPI_Graph_neighbors.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "OpenMPI ou MPICH instalado",
                                    "Compilador C (gcc/mpicc)",
                                    "Editor de código (VSCode)",
                                    "Documentação MPI 3.1+ sobre topologias"
                                  ],
                                  "tips": [
                                    "Comece com P=8 (3D hipercube) para depuração fácil.",
                                    "Use MPI_Comm_dup para preservar o comunicador original.",
                                    "Imprima ranks e vizinhos para verificação visual."
                                  ],
                                  "learningObjective": "Entender e implementar a criação de topologias gráficas em MPI para modelar hipercubos.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Graph_create_dynamic se necessário.",
                                    "Índices de edges incorretos levando a grafos desconexos.",
                                    "Não sincronizar com MPI_Barrier após criação."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar roteamento unicast minimal-path usando XOR em hipercube",
                                  "subSteps": [
                                    "Definir função roteamento: dado origem src e destino dst, calcular caminho mínimo via XOR: diff = src XOR dst, então sequência de dimensões onde bits diferem.",
                                    "Implementar envio unicast: no nó origem, enviar mensagem com caminho para primeiro vizinho; receptores forwarding até destino.",
                                    "Usar MPI_Send e MPI_Recv com tags para distinguir dados de rotas.",
                                    "Gerenciar buffer para mensagem + caminho (array de ranks).",
                                    "Adicionar timeout ou hop limit para evitar loops infinitos."
                                  ],
                                  "verification": "Testar envio de uma mensagem de rank 0 para rank 7 em 3D hipercube (caminho de 3 hops) e confirmar recepção correta sem perdas.",
                                  "estimatedTime": "3 hours",
                                  "materials": [
                                    "Código base do Step 1",
                                    "mpirun para múltiplos processos (mpirun -np 8)",
                                    "Debugger como gdb ou printf para tracing de rotas"
                                  ],
                                  "tips": [
                                    "Represente caminho como lista de bits set em diff para ordem determinística.",
                                    "Use MPI_Isend/Iprobe para non-blocking em caminhos longos.",
                                    "Log rotas com printf para depuração."
                                  ],
                                  "learningObjective": "Dominar roteamento dimension-order (XOR-based) em topologias hipercube para comunicação ponto-a-ponto eficiente.",
                                  "commonMistakes": [
                                    "Não tratar src == dst (envio local).",
                                    "Forwarding sem decrementar hops leva a loops.",
                                    "Tags de MPI colidindo entre dados e controle."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar comunicação coletiva all-to-all personalizada sobre hipercube",
                                  "subSteps": [
                                    "Estender unicast para all-to-all: cada processo envia dados únicos para todos outros via roteamento minimal.",
                                    "Otimizar com buffering: alocar buffers por destino, coletar e enviar em batches por dimensão.",
                                    "Implementar recv-side: cada processo recebe de múltiplos vizinhos e forwarding.",
                                    "Usar MPI_Alltoall como baseline para comparação de performance.",
                                    "Medir tempo com MPI_Wtime para latência e throughput."
                                  ],
                                  "verification": "Executar all-to-all com matriz de dados únicos (ex: rank envia seu ID para todos) e confirmar que cada processo recebe corretamente todos os dados.",
                                  "estimatedTime": "3 hours",
                                  "materials": [
                                    "Código dos Steps 1-2",
                                    "Ferramentas de profiling como mpiP ou Vampir",
                                    "Dados de teste: arrays de 1KB por par origem-destino"
                                  ],
                                  "tips": [
                                    "Implemente recursive doubling para all-to-all em hipercube para eficiência.",
                                    "Evite deadlocks com ordem de envio consistente (ex: por rank).",
                                    "Compare com MPI_Alltoall built-in."
                                  ],
                                  "learningObjective": "Construir primitivas coletivas customizadas sobre topologias para performance tuning em hipercubos.",
                                  "commonMistakes": [
                                    "Sobrecarga de buffer em nós centrais.",
                                    "Deadlocks por ordem assimétrica de Send/Recv.",
                                    "Não limpar buffers após all-to-all."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar e depurar em emuladores de cluster",
                                  "subSteps": [
                                    "Configurar emulador como ClusterShark ou Local MPI com rede simulada (tc/netem para delay/loss).",
                                    "Executar com np=16 (4D hipercube) e injetar falhas: delay 1ms, 1% packet loss.",
                                    "Coletar métricas: tempo total, hops médios, taxa de entrega (99%+).",
                                    "Depurar falhas comuns: usar Valgrind para leaks, MPI error handlers.",
                                    "Otimizar: reduzir latência variando dimensões de roteamento."
                                  ],
                                  "verification": "Relatório de testes mostrando >95% entrega correta, hops = Hamming distance média, e performance próxima a MPI nativo.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Emulador de cluster (ex: mininet ou tc)",
                                    "Scripts de teste automatizados",
                                    "Ferramentas: perf, strace"
                                  ],
                                  "tips": [
                                    "Use MPI_Errhandler_set para capturar erros.",
                                    "Teste escalabilidade de P=4 a 64.",
                                    "Grave traces com MPI logging."
                                  ],
                                  "learningObjective": "Validar implementações paralelas em ambientes simulados realistas.",
                                  "commonMistakes": [
                                    "Ignorar overhead de emulação afetando timings.",
                                    "Não testar com topologias não-poder de 2.",
                                    "Falhar em sincronizar clocks para medições."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um hipercube 3D (8 nós), rank 0 (000) envia 'Hello from 0' para rank 7 (111): caminho 0->1 (001)->3 (011)->7 (111) via XOR bits 0,1,2. All-to-all: cada nó envia seu rank para todos, resultando em buffer completo de 0-7 em cada processo.",
                              "finalVerifications": [
                                "Topologia hipercube criada corretamente com log2(P) vizinhos por nó.",
                                "Unicast entrega 100% das mensagens em caminho minimal (Hamming distance).",
                                "All-to-all customizado completa sem deadlocks e com dados corretos.",
                                "Testes em emulador mostram robustez a 1% loss e delay 1ms.",
                                "Performance dentro de 2x de MPI_Alltoall nativo.",
                                "Nenhum memory leak ou MPI error reportado."
                              ],
                              "assessmentCriteria": [
                                "Correção: 100% entrega em unicast/all-to-all para P<=16.",
                                "Eficiência: Hops = distância Hamming exata.",
                                "Escalabilidade: Funciona para P até 32 sem crashes.",
                                "Robustez: Lida com falhas simuladas sem perda >5%.",
                                "Código limpo: Comentado, modular, sem warnings de compilação.",
                                "Documentação: README com setup, runs e métricas."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Roteamento minimal em redes torus/hipercubo.",
                                "Algoritmos e Estruturas: Bitwise operations e grafos implícitos.",
                                "Sistemas Operacionais: Gerenciamento de processos distribuídos e sincronização.",
                                "Matemática Discreta: Dimensões binárias e Hamming distance."
                              ],
                              "realWorldApplication": "Em supercomputadores como IBM Blue Gene (topologia hipercube), otimiza comunicação em simulações científicas (CFD, genômica), reduzindo latência em all-to-all para scatter/gather de dados massivos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.3.4",
                            "name": "Analisar escalabilidade e estudo de caso",
                            "description": "Aplicar em problemas como multiplicação de matrizes ou simulações N-body, calculando speedup usando Amdahl/Gustafson e referenciando Grama et al. (2003).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Leis de Escalabilidade: Amdahl e Gustafson",
                                  "subSteps": [
                                    "Estude a lei de Amdahl: speedup = 1 / (s + (1-s)/p), onde s é fração serial e p é número de processadores.",
                                    "Analise a lei de Gustafson: speedup = s + p(1-s), considerando escalabilidade forte vs fraca.",
                                    "Compare as leis com exemplos numéricos para p=4,8,16 e s=0.1,0.5.",
                                    "Referencie Grama et al. (2003) para contexto em programação paralela.",
                                    "Identifique limitações de cada lei em topologias como hipercubo."
                                  ],
                                  "verification": "Resuma as diferenças entre Amdahl e Gustafson em um diagrama ou tabela, calculando speedup para 3 cenários.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Capítulo relevante de Grama et al. (2003), calculadora ou Python para simulações numéricas, notas de aula sobre topologias.",
                                  "tips": "Use gráficos para visualizar o impacto da fração serial no speedup.",
                                  "learningObjective": "Compreender e aplicar fórmulas de escalabilidade para prever performance paralela.",
                                  "commonMistakes": "Confundir escalabilidade forte (Amdahl) com fraca (Gustafson); ignorar overhead de comunicação em hipercubo."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Mapear Problema para Topologia Hipercubo",
                                  "subSteps": [
                                    "Escolha um problema: multiplicação de matrizes NxN ou simulação N-body.",
                                    "Descreva mapeamento em hipercubo de dimensão d (p=2^d processadores): dados distribuídos por coordenadas binárias.",
                                    "Defina padrões de comunicação: shifts ao longo de dimensões para trocas de dados.",
                                    "Calcule diâmetro da topologia (d hops máximo) e impacto na latência.",
                                    "Esboce grafo hipercubo com 8-16 nós para visualização."
                                  ],
                                  "verification": "Crie um diagrama do mapeamento mostrando distribuição de dados e rotas de comunicação.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Ferramenta de desenho (Draw.io ou papel), pseudocódigo MPI para hipercubo.",
                                  "tips": "Comece com hipercubo 3D (8 nós) para simplicidade antes de escalar.",
                                  "learningObjective": "Modelar problemas paralelos otimizados para topologia hipercubo.",
                                  "commonMistakes": "Ignorar balanceamento de carga; assumir comunicação O(1) em vez de considerar hops."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Speedup e Eficiência no Hipercubo",
                                  "subSteps": [
                                    "Meça tempo sequencial T1 para o problema (ex: matriz 1024x1024).",
                                    "Simule/implemente versão paralela em hipercubo, medindo Tp para p=2,4,8,16.",
                                    "Aplique Amdahl/Gustafson para prever speedup; compare com medidas reais.",
                                    "Calcule eficiência: E = speedup / p; analise overhead de comunicação.",
                                    "Varie tamanho do problema para testar escalabilidade fraca."
                                  ],
                                  "verification": "Gere tabela com speedup medido vs previsto, gráfico de eficiência vs p.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Ambiente MPI (OpenMPI), Python/MATLAB para simulações, hardware com múltiplos cores.",
                                  "tips": "Use iscaev para medir tempos reais; normalize para fração serial estimada.",
                                  "learningObjective": "Quantificar performance e identificar gargalos em topologias distribuídas.",
                                  "commonMistakes": "Não contabilizar tempo de comunicação; usar p não-potência de 2."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Realizar Estudo de Caso e Análise Crítica",
                                  "subSteps": [
                                    "Aplique a simulação N-body em hipercubo: forças gravitacionais com trocas all-to-all.",
                                    "Compare resultados com literatura (Grama et al. 2003): speedup observado vs teórico.",
                                    "Discuta limitações do hipercubo vs outras topologias (mesh, torus).",
                                    "Proponha otimizações: reduzir hops com mapeamento linearizado.",
                                    "Escreva relatório resumindo achados e lições aprendidas."
                                  ],
                                  "verification": "Relatório de 1-2 páginas com gráficos, cálculos e referências.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": "Código fonte de exemplo N-body (GitHub), PDF de Grama et al. (2003).",
                                  "tips": "Foque em um estudo de caso específico para profundidade, não amplitude.",
                                  "learningObjective": "Integrar teoria e prática em análise de escalabilidade real.",
                                  "commonMistakes": "Generalizar resultados sem dados empíricos; omitir referências acadêmicas."
                                }
                              ],
                              "practicalExample": "Implemente multiplicação de matrizes 2048x2048 em hipercubo de 16 nós (d=4): cada nó possui submatriz, shifts dimensionais para produtos parciais, redução final. Meça speedup de 12.5x vs sequencial, analisando overhead de 20% devido a 4 hops máximos.",
                              "finalVerifications": [
                                "Cálculos de speedup Amdahl/Gustafson coincidem com simulações em ±10%.",
                                "Diagrama de mapeamento hipercubo está correto e rotas otimizadas.",
                                "Eficiência >70% para p≤16 em problema escalável.",
                                "Relatório referencia Grama et al. (2003) com citações precisas.",
                                "Identificados 2+ gargalos específicos do hipercubo.",
                                "Gráficos mostram tendências claras de escalabilidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos de speedup (90%+ correção).",
                                "Qualidade do mapeamento e análise de comunicação (completo e otimizado).",
                                "Profundidade da comparação teórica vs empírica.",
                                "Clareza e profissionalismo do relatório/diagramas.",
                                "Integração de referências acadêmicas e insights críticos.",
                                "Criatividade em otimizações propostas."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear em multiplicação de matrizes e grafos hipercubo.",
                                "Física: Simulações N-body para dinâmica gravitacional.",
                                "Engenharia de Software: Design de algoritmos paralelos e MPI.",
                                "Análise de Dados: Visualização de performance com gráficos e métricas."
                              ],
                              "realWorldApplication": "Em supercomputadores como IBM Blue Gene (topologia hipercubo-like), otimiza simulações climáticas ou genômica, permitindo escalar de 1k a 1M núcleos com speedup previsível, reduzindo tempo de semanas para horas em pesquisa científica."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.5",
                    "name": "Bibliotecas para Programação com Memória Distribuída",
                    "description": "Ferramentas como MPI para implementação de modelos de troca de mensagens em plataformas paralelas.",
                    "individualConcepts": [
                      {
                        "id": "10.1.2.5.1",
                        "name": "Message Passing Interface (MPI)",
                        "description": "Biblioteca padrão e portátil para programação paralela em sistemas de memória distribuída, baseada no modelo de troca de mensagens, permitindo comunicação entre processos independentes em clusters ou plataformas paralelas.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.5.1.1",
                            "name": "Instalar e configurar ambiente MPI",
                            "description": "Configurar e instalar implementações de MPI como OpenMPI ou MPICH em sistemas Linux, incluindo verificação de instalação com comandos como mpirun e mpicc.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente Linux",
                                  "subSteps": [
                                    "Abra o terminal e execute 'sudo apt update' para atualizar a lista de pacotes.",
                                    "Execute 'sudo apt upgrade -y' para atualizar pacotes instalados.",
                                    "Instale dependências básicas: 'sudo apt install build-essential wget gcc g++ -y'.",
                                    "Verifique a instalação do GCC com 'gcc --version'.",
                                    "Crie um diretório de trabalho: 'mkdir ~/mpi_install && cd ~/mpi_install'."
                                  ],
                                  "verification": "Comando 'gcc --version' retorna versão válida e diretório ~/mpi_install existe.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Terminal Linux (Ubuntu/Debian recomendado)",
                                    "Acesso sudo",
                                    "Conexão à internet"
                                  ],
                                  "tips": "Execute comandos como usuário regular e use sudo apenas quando necessário para evitar riscos de segurança.",
                                  "learningObjective": "Configurar um sistema Linux pronto para compilação e instalação de software.",
                                  "commonMistakes": [
                                    "Esquecer 'sudo' em comandos de instalação",
                                    "Não atualizar pacotes antes de instalar",
                                    "Usar distribuição não baseada em Debian sem adaptação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Baixar e instalar OpenMPI",
                                  "subSteps": [
                                    "Navegue para o diretório: 'cd ~/mpi_install'.",
                                    "Baixe a versão estável do OpenMPI: 'wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.5.tar.gz'.",
                                    "Extraia o arquivo: 'tar -xzf openmpi-4.1.5.tar.gz'.",
                                    "Entre no diretório: 'cd openmpi-4.1.5' e configure: './configure --prefix=/usr/local'.",
                                    "Compile e instale: 'make -j$(nproc) && sudo make install'."
                                  ],
                                  "verification": "Verifique se 'mpicc --showme:version' exibe informações da instalação.",
                                  "estimatedTime": "30-45 minutos (dependendo da máquina)",
                                  "materials": [
                                    "Conexão à internet",
                                    "Espaço em disco ~500MB"
                                  ],
                                  "tips": "Use '-j$(nproc)' para compilação paralela acelerada; monitore com 'top' se necessário.",
                                  "learningObjective": "Instalar OpenMPI do código-fonte, entendendo o processo de configure-make-install.",
                                  "commonMistakes": [
                                    "Pular './configure'",
                                    "Não usar sudo em 'make install'",
                                    "Baixar versão errada ou corrompida"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar variáveis de ambiente",
                                  "subSteps": [
                                    "Adicione ao ~/.bashrc: 'export PATH=/usr/local/bin:$PATH'.",
                                    "Adicione também: 'export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH'.",
                                    "Recarregue o bashrc: 'source ~/.bashrc'.",
                                    "Verifique PATH: 'echo $PATH | grep mpi'.",
                                    "Teste mpicc: 'which mpicc' deve retornar /usr/local/bin/mpicc."
                                  ],
                                  "verification": "'mpicc --version' e 'mpirun --version' funcionam sem erros.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Editor de texto (nano ou vim)",
                                    "Arquivo ~/.bashrc"
                                  ],
                                  "tips": "Use 'nano ~/.bashrc' para edição fácil; teste em novo terminal após source.",
                                  "learningObjective": "Configurar PATH e LD_LIBRARY_PATH para acesso global aos binários MPI.",
                                  "commonMistakes": [
                                    "Esquecer de source ~/.bashrc",
                                    "Caminho errado no prefixo",
                                    "Não reiniciar terminal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e testar a instalação",
                                  "subSteps": [
                                    "Crie um arquivo hello.c com código MPI Hello World básico.",
                                    "Compile: 'mpicc hello.c -o hello'.",
                                    "Execute: 'mpirun -np 4 ./hello' (deve imprimir saudações de 4 processos).",
                                    "Teste mpirun em host único: 'mpirun --host localhost -np 2 hostname'.",
                                    "Limpe arquivos: 'rm hello.c hello'."
                                  ],
                                  "verification": "Programa Hello World roda sem erros e mostra output de múltiplos processos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto",
                                    "Código fonte MPI Hello World"
                                  ],
                                  "tips": "Copie um Hello World padrão de documentação oficial para teste rápido.",
                                  "learningObjective": "Validar funcionalidade completa do MPI com compilação e execução distribuída.",
                                  "commonMistakes": [
                                    "Erros de sintaxe no código teste",
                                    "Executar mpirun sem -np",
                                    "Problemas de PATH não resolvidos"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um arquivo 'mpi_pi.c' que calcula Pi usando método de Monte Carlo com MPI. Compile com 'mpicc mpi_pi.c -o mpi_pi' e execute 'mpirun -np 8 ./mpi_pi'. O programa deve distribuir tarefas entre 8 processos e imprimir Pi aproximado, demonstrando paralelismo.",
                              "finalVerifications": [
                                "'mpicc --version' retorna versão OpenMPI instalada.",
                                "'mpirun --version' funciona e lista opções.",
                                "Compilação de programa C simples com mpicc sem warnings/erros.",
                                "Execução 'mpirun -np 4 ./hello' produz output correto de 4 ranks.",
                                "'ldd $(which mpirun)' mostra bibliotecas MPI carregadas.",
                                "Instalação persiste após reboot (PATH configurado corretamente)."
                              ],
                              "assessmentCriteria": [
                                "Instalação completa sem erros de compilação ou configuração.",
                                "Variáveis de ambiente persistentes e corretas.",
                                "Execução bem-sucedida de programas MPI em múltiplos processos.",
                                "Compreensão demonstrada ao explicar passos e troubleshooting.",
                                "Adaptação para MPICH se solicitado.",
                                "Limpeza de arquivos temporários e boas práticas de segurança."
                              ],
                              "crossCurricularConnections": [
                                "Administração de Sistemas Linux (gerenciamento de pacotes e ambiente).",
                                "Programação em C (compilação com mpicc e bibliotecas).",
                                "Redes de Computadores (comunicação via mpirun em hosts).",
                                "Computação de Alto Desempenho (preparação para clusters).",
                                "Matemática Computacional (testes com algoritmos paralelizáveis)."
                              ],
                              "realWorldApplication": "Configuração de ambientes MPI é essencial em supercomputadores e clusters para simulações científicas (ex.: modelagem climática, física de partículas no CERN), processamento de big data em HPC e desenvolvimento de software paralelo em indústrias como óleo/gás e finanças."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.5.1.2",
                            "name": "Compilar e executar programas MPI básicos",
                            "description": "Usar compiladores MPI (mpicc, mpif90) para compilar programas C/Fortran com MPI e executar com mpirun, especificando número de processos e hosts.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar um programa MPI básico em C",
                                  "subSteps": [
                                    "Inclua os cabeçalhos necessários: #include <mpi.h> e #include <stdio.h>.",
                                    "Use MPI_Init(&argc, &argv) no início e MPI_Finalize() no final.",
                                    "Obtenha o rank com MPI_Comm_rank(MPI_COMM_WORLD, &rank) e o tamanho com MPI_Comm_size(MPI_COMM_WORLD, &size).",
                                    "Use printf para imprimir uma mensagem única por processo, como 'Hello from process %d of %d'.",
                                    "Salve o arquivo como hello_mpi.c."
                                  ],
                                  "verification": "Abra o arquivo e confirme que contém MPI_Init, MPI_Comm_rank, MPI_Comm_size e MPI_Finalize sem erros de sintaxe.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto (VS Code, Vim ou nano)",
                                    "Conhecimento básico de C"
                                  ],
                                  "tips": "Sempre inicialize MPI no main e finalize no final para evitar hangs.",
                                  "learningObjective": "Criar um programa MPI funcional que demonstre comunicação básica entre processos.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init ou MPI_Finalize",
                                    "Não incluir <mpi.h>",
                                    "Usar printf sem flush em ambientes paralelos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compilar o programa usando mpicc",
                                  "subSteps": [
                                    "Abra o terminal no diretório do arquivo hello_mpi.c.",
                                    "Execute 'mpicc -o hello_mpi hello_mpi.c' para compilar em C.",
                                    "Verifique erros de compilação com 'ls -l hello_mpi' para confirmar o executável foi gerado.",
                                    "Para Fortran, use 'mpif90 -o hello_mpi hello_mpi.f90' se aplicável.",
                                    "Adicione flags opcionais como '-Wall -g' para warnings e debug."
                                  ],
                                  "verification": "O comando 'ls -l hello_mpi' mostra um executável com tamanho >0 e permissões de execução.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Terminal/Linux ou cluster com MPI instalado (OpenMPI ou MPICH)",
                                    "Compilador MPI (mpicc)"
                                  ],
                                  "tips": "Use 'mpicc' em vez de 'gcc' para linkar automaticamente bibliotecas MPI.",
                                  "learningObjective": "Dominar o uso de compiladores MPI para gerar executáveis paralelos.",
                                  "commonMistakes": [
                                    "Usar gcc em vez de mpicc (falha no link)",
                                    "Esquecer o nome de saída -o",
                                    "Ignorar warnings de compilação"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o programa com mpirun especificando processos",
                                  "subSteps": [
                                    "Execute 'mpirun -np 4 ./hello_mpi' para 4 processos.",
                                    "Observe a saída: deve mostrar mensagens de 4 processos únicos.",
                                    "Teste com diferentes números: 'mpirun -np 2 ./hello_mpi' e 'mpirun -np 8 ./hello_mpi'.",
                                    "Em clusters, use 'mpirun -np 4 -host node1,node2 ./hello_mpi' para hosts específicos.",
                                    "Redirecione saída para arquivo: 'mpirun -np 4 ./hello_mpi > output.txt'."
                                  ],
                                  "verification": "Saída mostra exatamente 'np' linhas únicas com ranks de 0 a np-1 sem duplicatas ou erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Terminal com MPI runtime",
                                    "Acesso a múltiplos cores ou máquina virtual"
                                  ],
                                  "tips": "Use -np <= número de cores disponíveis para evitar oversubscription.",
                                  "learningObjective": "Executar programas MPI controlando número de processos e hosts.",
                                  "commonMistakes": [
                                    "Executar sem mpirun (roda como serial)",
                                    "np maior que recursos disponíveis (hangs)",
                                    "Não especificar hosts em multi-nó"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e debugar execução MPI básica",
                                  "subSteps": [
                                    "Compare saídas esperadas vs reais para diferentes np.",
                                    "Use 'mpirun -np 4 -v ./hello_mpi' para verbose output se suportado.",
                                    "Teste em ambiente multi-host se disponível: edite hostsfile e use '-hostfile hostsfile'.",
                                    "Analise erros comuns como 'No such file' ou 'MPI not initialized'.",
                                    "Limpe com 'rm hello_mpi' após testes."
                                  ],
                                  "verification": "Execuções múltiplas produzem saídas consistentes e sem erros de runtime.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Hostsfile simples (opcional)",
                                    "Documentação MPI local (man mpirun)"
                                  ],
                                  "tips": "Sempre verifique $PATH inclui binários MPI com 'which mpirun'.",
                                  "learningObjective": "Diagnosticar e validar execuções MPI corretas.",
                                  "commonMistakes": [
                                    "Ignorar ordem não determinística de prints",
                                    "Executar em nó único como multi-host",
                                    "Não limpar variáveis de ambiente MPI antigas"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa hello_mpi.c: #include <mpi.h> #include <stdio.h> int main(int argc, char** argv) { int rank, size; MPI_Init(&argc, &argv); MPI_Comm_rank(MPI_COMM_WORLD, &rank); MPI_Comm_size(MPI_COMM_WORLD, &size); printf(\"Hello from process %d of %d\\n\", rank, size); MPI_Finalize(); return 0; }. Compile: mpicc -o hello_mpi hello_mpi.c. Execute: mpirun -np 4 ./hello_mpi. Saída esperada: Hello from process 0 of 4\nHello from process 1 of 4\n etc.",
                              "finalVerifications": [
                                "Compilação sem erros usando mpicc/mpif90.",
                                "Execução com mpirun -np N produz N mensagens únicas.",
                                "Especificação de hosts funciona sem falhas.",
                                "Saídas são consistentes em múltiplas runs.",
                                "Debug básico identifica erros comuns.",
                                "Executável roda em diferentes np (2-8)."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos comandos de compilação e execução (100% correto).",
                                "Compreensão de opções -np e -host (explicação clara).",
                                "Identificação de 3+ erros comuns e soluções.",
                                "Programa MPI básico funcional e verificado.",
                                "Tempo de execução dentro dos estimados.",
                                "Aplicação correta em C e noções em Fortran."
                              ],
                              "crossCurricularConnections": [
                                "Computação de Alto Desempenho (HPC): Base para simulações paralelas.",
                                "Redes e Sistemas Distribuídos: Conceitos de comunicação entre hosts.",
                                "Algoritmos e Estruturas de Dados: Paralelização de algoritmos.",
                                "Engenharia de Software: Build systems e automação (Makefiles com MPI)."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas, modelagem molecular em farmacêutica ou processamento de big data em finanças, onde mpicc/mpirun compila e lança jobs paralelos em milhares de nós para acelerar cálculos em horas ao invés de dias."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.1.1"
                            ]
                          },
                          {
                            "id": "10.1.2.5.1.3",
                            "name": "Inicializar e finalizar programas MPI",
                            "description": "Implementar MPI_Init() para inicializar o ambiente MPI e MPI_Finalize() para finalização limpa, gerenciando ranks e tamanhos de comunicadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento MPI",
                                  "subSteps": [
                                    "Instale uma implementação MPI como OpenMPI ou MPICH via gerenciador de pacotes (ex: sudo apt install openmpi-bin libopenmpi-dev no Ubuntu).",
                                    "Verifique a instalação executando 'mpirun --version' no terminal.",
                                    "Crie um diretório de projeto e um arquivo fonte simples em C (ex: hello_mpi.c).",
                                    "Compile um programa de teste não-MPI para garantir que o compilador (gcc ou mpicc) funcione.",
                                    "Configure variáveis de ambiente se necessário (ex: export PATH=$PATH:/usr/local/mpich/bin)."
                                  ],
                                  "verification": "Comando 'mpirun --version' retorna versão válida e gcc/mpicc compila um hello world sequencial sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Computador com Linux/Mac/Windows WSL",
                                    "Implementação MPI (OpenMPI/MPICH)",
                                    "Editor de texto (VS Code/vim)",
                                    "Compilador C (gcc)"
                                  ],
                                  "tips": "Use mpicc como wrapper para gcc, ele cuida das flags MPI automaticamente.",
                                  "learningObjective": "Preparar o ambiente para compilar e executar programas MPI.",
                                  "commonMistakes": [
                                    "Não instalar headers de desenvolvimento (libopenmpi-dev)",
                                    "Esquecer de usar mpicc ao invés de gcc",
                                    "Ignorar dependências de sistema operacional"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Init() e obter informações básicas do processo",
                                  "subSteps": [
                                    "Inclua os headers necessários: #include <mpi.h>.",
                                    "Na função main(), chame MPI_Init(&argc, &argv); no início.",
                                    "Declare variáveis int rank, size;.",
                                    "Chame MPI_Comm_rank(MPI_COMM_WORLD, &rank); e MPI_Comm_size(MPI_COMM_WORLD, &size);.",
                                    "Adicione um printf para exibir rank e size: printf('Processo %d de %d\\n', rank, size);."
                                  ],
                                  "verification": "Código compila com mpicc -o teste hello_mpi.c sem warnings sobre MPI.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Arquivo hello_mpi.c",
                                    "Documentação MPI oficial (mpi-forum.org)",
                                    "Terminal com MPI instalado"
                                  ],
                                  "tips": "Sempre chame MPI_Init ANTES de qualquer função MPI; argc/argv devem ser passados por referência.",
                                  "learningObjective": "Inicializar MPI corretamente e acessar rank e tamanho do comunicador.",
                                  "commonMistakes": [
                                    "Chamar MPI functions antes de Init",
                                    "Esquecer & em MPI_Init(&argc, &argv)",
                                    "Usar MPI_COMM_WORLD sem inicializar"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Adicionar MPI_Finalize() e estrutura completa do programa",
                                  "subSteps": [
                                    "Adicione MPI_Finalize(); no final da main(), após todos os prints.",
                                    "Garanta que MPI_Finalize seja chamado por TODOS os processos.",
                                    "Estruture o código com ifs condicionais baseados em rank (ex: root process faz algo diferente).",
                                    "Salve o arquivo e compile: mpicc -o hello_mpi hello_mpi.c -Wall -std=c99.",
                                    "Teste execução sequencial: ./hello_mpi (deve rodar como 1 processo)."
                                  ],
                                  "verification": "Programa executa sem crashes e MPI_Finalize retorna 0 em todos os processos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código do step 2 expandido",
                                    "Compilador mpicc"
                                  ],
                                  "tips": "MPI_Finalize bloqueia até todos os processos chamarem; evite código após Finalize.",
                                  "learningObjective": "Finalizar o ambiente MPI de forma limpa, garantindo sincronização.",
                                  "commonMistakes": [
                                    "Chamar Finalize antes de todos os processos estarem prontos",
                                    "Código após Finalize (ignorado)",
                                    "Não tratar erros de retorno das funções MPI"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar e depurar programa MPI com múltiplos processos",
                                  "subSteps": [
                                    "Execute com múltiplos processos: mpirun -np 4 ./hello_mpi.",
                                    "Verifique saída: deve mostrar 4 linhas únicas (Processo 0 de 4, etc.).",
                                    "Teste com diferentes np (2, 8) e observe size mudando.",
                                    "Adicione verificação de erros: int ierr = MPI_Init(...); if(ierr != MPI_SUCCESS) exit(1);.",
                                    "Depure problemas comuns como --oversubscribe se faltarem slots no launcher."
                                  ],
                                  "verification": "mpirun -np 4 ./hello_mpi produz saída correta sem erros de MPI ou segmentação.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Executável hello_mpi",
                                    "Terminal",
                                    "mpirun/mpiexec"
                                  ],
                                  "tips": "Use -np para número de processos; em clusters, configure hosts file.",
                                  "learningObjective": "Executar programas MPI distribuídos e validar comportamento.",
                                  "commonMistakes": [
                                    "Executar sem mpirun (roda como 1 processo)",
                                    "np maior que núcleos disponíveis sem oversubscribe",
                                    "Ignorar warnings de MPI no output"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa hello_mpi.c que inicializa MPI, cada processo imprime 'Olá do processo [rank] de [size]!', e finaliza. Compile com mpicc e rode mpirun -np 4 ./hello_mpi. Saída esperada: Olá do processo 0 de 4!\nOlá do processo 1 de 4!\netc.",
                              "finalVerifications": [
                                "Programa compila sem erros ou warnings com mpicc -Wall.",
                                "Executa com mpirun -np N (N=1 a 8) mostrando ranks corretos de 0 a N-1.",
                                "MPI_Finalize retorna sem erros (verificar com mpirun -v).",
                                "Nenhum processo trava ou leak de memória em execuções múltiplas.",
                                "Saída é idêntica independentemente da ordem de processos.",
                                "Root (rank 0) pode ser distinguido corretamente em condicionais."
                              ],
                              "assessmentCriteria": [
                                "Correta colocação de MPI_Init no início e MPI_Finalize no fim.",
                                "Uso apropriado de MPI_Comm_rank e MPI_Comm_size com MPI_COMM_WORLD.",
                                "Tratamento básico de erros de retorno MPI (ierr).",
                                "Execução bem-sucedida com 1 e múltiplos processos sem crashes.",
                                "Código limpo, comentado e indentado corretamente.",
                                "Demonstração de prints únicos por rank sem sobreposição."
                              ],
                              "crossCurricularConnections": [
                                "Programação em C: Uso de argc/argv, pointers e funções.",
                                "Sistemas Operacionais: Processos, execução paralela e gerenciadores de jobs.",
                                "Algoritmos Paralelos: Conceitos de rank e comunicador em modelos distribuídos.",
                                "Engenharia de Software: Boas práticas de inicialização e cleanup.",
                                "Computação de Alto Desempenho: Introdução a clusters e supercomputadores."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática no NASA), jogos multiplayer distribuídos ou big data processing (HPC clusters), onde milhares de processos precisam inicializar/finalizar sincronizadamente para evitar deadlocks e leaks em jobs de horas/dias."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.5.2",
                        "name": "Comunicação Pontual em MPI",
                        "description": "Primitivas de envio e recebimento bloqueante e não-bloqueante de mensagens entre pares específicos de processos, suportando buffers e tags para identificação.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.5.2.1",
                            "name": "Implementar MPI_Send e MPI_Recv",
                            "description": "Codificar envio bloqueante (MPI_Send) e recebimento bloqueante (MPI_Recv) de dados primitivos e derivados entre dois processos, especificando rank, tag e contadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente MPI e identificar processos",
                                  "subSteps": [
                                    "Incluir as bibliotecas necessárias: #include <mpi.h> e #include <stdio.h>",
                                    "No main, inicializar MPI com MPI_Init(&argc, &argv);",
                                    "Obter o número total de processos com MPI_Comm_size(MPI_COMM_WORLD, &num_processes);",
                                    "Obter o rank do processo atual com MPI_Comm_rank(MPI_COMM_WORLD, &rank);",
                                    "Imprimir o rank e número de processos para verificação inicial"
                                  ],
                                  "verification": "Compilar com mpicc e executar com mpirun -np 2; verificar se ranks 0 e 1 são impressos corretamente sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de texto (VS Code ou similar)",
                                    "Terminal com MPI instalado"
                                  ],
                                  "tips": "Sempre chame MPI_Init no início do main e verifique se num_processes >= 2 para evitar erros em execuções com poucos processos.",
                                  "learningObjective": "Dominar a inicialização do MPI e a identificação única de processos em um ambiente distribuído.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes de qualquer função MPI",
                                    "Não declarar variáveis para rank e size",
                                    "Executar com -np 1, causando falha em comunicações ponto-a-ponto"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Send para dados primitivos no processo remetente",
                                  "subSteps": [
                                    "Declarar variáveis para dados a enviar, ex: int data = 42; ou int buffer[10];",
                                    "Usar if (rank == 0) para identificar o remetente.",
                                    "Chamar MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); especificando buffer, count=1, datatype=MPI_INT, dest=1, tag=0, communicator.",
                                    "Adicionar printf para logar o valor enviado após o Send.",
                                    "Sincronizar com MPI_Barrier(MPI_COMM_WORLD); para evitar deadlocks prematuros"
                                  ],
                                  "verification": "Executar o programa parcial; o processo 0 deve imprimir o envio sem travar indefinidamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código do step 1",
                                    "Documentação MPI para MPI_Send (mpi-forum.org)"
                                  ],
                                  "tips": "Lembre-se que MPI_Send é bloqueante: só retorna após o dado ser enviado com segurança.",
                                  "learningObjective": "Codificar corretamente o envio bloqueante de dados primitivos, especificando todos os parâmetros obrigatórios.",
                                  "commonMistakes": [
                                    "Especificar destino incorreto (ex: enviar para si mesmo)",
                                    "Usar count=0 ou datatype errado",
                                    "Esquecer o tag, que é obrigatório para matching com Recv"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Recv para dados primitivos e derivados no processo receptor",
                                  "subSteps": [
                                    "Declarar variáveis para receber dados, ex: int received_data; ou struct MyType {int x; double y;}; MyType recv_struct;",
                                    "Usar if (rank == 1) para o receptor.",
                                    "Definir tipo derivado se necessário: MPI_Datatype mytype; MPI_Type_contiguous(1, MPI_INT, &mytype); MPI_Type_commit(&mytype);",
                                    "Chamar MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);",
                                    "Imprimir o valor recebido para confirmação e chamar MPI_Barrier"
                                  ],
                                  "verification": "Executar com mpirun -np 2; processo 1 deve imprimir o valor enviado pelo 0 corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Referência de MPI_Datatype"
                                  ],
                                  "tips": "Use MPI_STATUS_IGNORE para simplicidade inicial; ignore wildcards como MPI_ANY_SOURCE só após dominar basics.",
                                  "learningObjective": "Implementar recebimento bloqueante matching com Send, incluindo tipos derivados via MPI_Type_contiguous.",
                                  "commonMistakes": [
                                    "Tag ou source mismatch causando bloqueio eterno",
                                    "Não commitar tipo derivado antes de usar",
                                    "Buffer de recepção com tamanho insuficiente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar programa, compilar, executar e depurar",
                                  "subSteps": [
                                    "Adicionar MPI_Finalize(); no final do main, após todas as operações.",
                                    "Compilar com mpicc -o programa programa.c -Wall para warnings.",
                                    "Executar com mpirun -np 2 ./programa e verificar saídas.",
                                    "Testar com dados derivados: enviar struct e imprimir campos recebidos.",
                                    "Depurar deadlocks adicionando mais MPI_Barrier ou logs com MPI_Wtime"
                                  ],
                                  "verification": "Programa termina normalmente, dados primitivos e derivados são trocados corretamente em múltiplas execuções.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "mpirun",
                                    "gdb ou mpirun com --oversubscribe para testes locais"
                                  ],
                                  "tips": "Use -np exatamente 2 para este exemplo; escale depois.",
                                  "learningObjective": "Integrar Send/Recv em um programa completo MPI funcional e robusto.",
                                  "commonMistakes": [
                                    "Chamar MPI_Finalize antes de todas as comunicações",
                                    "Não sincronizar com Barrier levando a deadlocks",
                                    "Ignorar status de erro em MPI calls"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa em C onde processo 0 envia int 42 e array[3] de doubles para rank 1 usando MPI_Send com tag=99; rank 1 recebe com MPI_Recv matching e imprime 'Recebido: 42 e [1.1, 2.2, 3.3]' corretamente.",
                              "finalVerifications": [
                                "Programa compila sem erros/warnings com mpicc",
                                "Executa com mpirun -np 2 e termina sem deadlocks",
                                "Dados primitivos (int, double) são enviados/recebidos idênticos",
                                "Tipos derivados (ex: MPI_Type_vector para array) funcionam sem perda de dados",
                                "Logs mostram ranks corretos e tags matching",
                                "Múltiplas execuções produzem saídas consistentes"
                              ],
                              "assessmentCriteria": [
                                "Uso correto de parâmetros em MPI_Send: buf, count, datatype, dest, tag, comm",
                                "Uso correto de parâmetros em MPI_Recv: buf, count, datatype, source, tag, comm, status",
                                "Inicialização/finalização MPI presentes e posicionadas adequadamente",
                                "Definição e commit de tipos derivados quando aplicável",
                                "Verificações de rank e num_processes para robustez",
                                "Ausência de deadlocks via barriers ou ordem correta"
                              ],
                              "crossCurricularConnections": [
                                "Programação em C/C++: ponteiros, structs e passagem de buffers",
                                "Sistemas Operacionais: conceitos de processos e comunicação inter-processo",
                                "Redes de Computadores: modelo cliente-servidor ponto-a-ponto similar a sockets",
                                "Algoritmos e Estruturas de Dados: serialização de tipos compostos",
                                "Computação de Alto Desempenho: basics de paralelismo distribuído"
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: modelagem climática no NASA), onde nós de cluster trocam sub-matrizes de dados via MPI_Send/Recv para computações distribuídas como multiplicação de matrizes paralela."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.1.3"
                            ]
                          },
                          {
                            "id": "10.1.2.5.2.2",
                            "name": "Usar comunicações não-bloqueantes",
                            "description": "Aplicar MPI_Isend e MPI_Irecv para comunicações assíncronas, combinadas com MPI_Wait e MPI_Test para completar operações e evitar deadlocks.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos de comunicações não-bloqueantes em MPI",
                                  "subSteps": [
                                    "Estudar a documentação oficial do MPI para MPI_Isend, MPI_Irecv, MPI_Wait e MPI_Test.",
                                    "Comparar operações bloqueantes (MPI_Send/Recv) com não-bloqueantes, focando em retornos imediatos.",
                                    "Analisar o ciclo de vida de um request MPI (MPI_Request).",
                                    "Identificar cenários onde não-bloqueantes evitam deadlocks e permitem sobreposição de comunicação/computação.",
                                    "Assistir a tutoriais ou vídeos sobre assincronia em MPI."
                                  ],
                                  "verification": "Criar um resumo escrito com definições e diferenças chave, incluindo um diagrama de fluxo.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação MPI oficial (man pages)",
                                    "Livro 'Using MPI' de Gropp et al.",
                                    "Tutoriais online como MPI Tutorial da Lawrence Livermore National Lab"
                                  ],
                                  "tips": "Use diagramas para visualizar o que acontece entre Isend e Wait.",
                                  "learningObjective": "Dominar os fundamentos teóricos das primitivas não-bloqueantes e seus benefícios.",
                                  "commonMistakes": [
                                    "Confundir não-bloqueante com assíncrono sem sincronização posterior.",
                                    "Ignorar que Isend/Irecv postam operações mas não garantem completude."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Isend e MPI_Irecv em um programa básico",
                                  "subSteps": [
                                    "Configurar um programa MPI com dois processos (rank 0 e 1).",
                                    "No rank 0, preparar buffer de envio e chamar MPI_Isend para o rank 1.",
                                    "No rank 1, preparar buffer de recebimento e chamar MPI_Irecv do rank 0.",
                                    "Compilar e executar o programa sem sincronização para observar comportamento.",
                                    "Registrar requests retornados por Isend/Irecv em variáveis MPI_Request."
                                  ],
                                  "verification": "Programa compila e executa sem erros de compilação, imprimindo confirmação de postagem das operações.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou similar)",
                                    "Ambiente de execução MPI (mpirun)"
                                  ],
                                  "tips": "Sempre inicialize MPI com MPI_Init e finalize com MPI_Finalize.",
                                  "learningObjective": "Aplicar corretamente MPI_Isend e MPI_Irecv para postar comunicações assíncronas.",
                                  "commonMistakes": [
                                    "Esquecer de declarar MPI_Request para armazenar handles.",
                                    "Usar tamanhos de buffer incorretos, causando MPI_ERR_TRUNCATE."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerenciar completude das operações com MPI_Wait e MPI_Test",
                                  "subSteps": [
                                    "Implementar MPI_Wait em cada processo para aguardar completude do request correspondente.",
                                    "Alternativamente, usar MPI_Test em um loop para polling não-bloqueante.",
                                    "Combinar com MPI_Waitall para múltiplos requests.",
                                    "Imprimir buffers após wait para verificar dados transferidos.",
                                    "Executar e validar que os dados são corretamente trocados."
                                  ],
                                  "verification": "Programa completa sem pendências, buffers mostram dados corretos em ambos os ranks.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código do Step 2 modificado",
                                    "Documentação MPI para MPI_Wait/MPI_Test"
                                  ],
                                  "tips": "Prefira MPI_Waitall para múltiplas operações para simplicidade.",
                                  "learningObjective": "Sincronizar operações não-bloqueantes de forma segura usando Wait e Test.",
                                  "commonMistakes": [
                                    "Chamar Wait em request inválido, causando erros.",
                                    "Não testar completude antes de acessar buffers, levando a dados inconsistentes."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar cenários avançados e evitar deadlocks",
                                  "subSteps": [
                                    "Simular cenário de deadlock com Send/Recv cruzados e convertê-lo para não-bloqueante.",
                                    "Implementar sobreposição: computação entre Isend e Wait.",
                                    "Executar com múltiplos processos (mpirun -np 4) e medir tempo vs. versão bloqueante.",
                                    "Usar MPI_Barrier opcionalmente para sincronização global se necessário.",
                                    "Debugar com ferramentas como TotalView ou printf para logs de status."
                                  ],
                                  "verification": "Programa roda sem deadlocks em configurações múltiplas, com performance melhorada.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Código expandido",
                                    "Timer MPI (MPI_Wtime)",
                                    "Debugger MPI"
                                  ],
                                  "tips": "Meça tempo total para quantificar ganho de performance.",
                                  "learningObjective": "Aplicar não-bloqueantes em cenários reais, evitando deadlocks e otimizando.",
                                  "commonMistakes": [
                                    "Criar dependências circulares nos requests sem Waitall adequado.",
                                    "Esquecer MPI_Wait antes de MPI_Finalize, causando perda de mensagens."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa com 2 processos, rank 0 usa MPI_Isend para enviar um array de 100 floats para rank 1, enquanto rank 1 usa MPI_Irecv para receber. Ambos postam as operações, realizam uma computação local (ex: soma de elementos), então chamam MPI_Wait nos requests. Resultado: buffers sincronizados e computação sobreposta, impresso 'Troca concluída com sucesso'.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros ou deadlocks em múltiplos ranks.",
                                "Dados enviados são recebidos corretamente em buffers de destino.",
                                "Requests são completados (MPI_Wait retorna MPI_SUCCESS).",
                                "Performance mostra redução de tempo vs. versão bloqueante.",
                                "Nenhum vazamento de requests (todos waited antes de finalizar).",
                                "Execução escalável com mpirun -np 4 ou mais."
                              ],
                              "assessmentCriteria": [
                                "Código usa corretamente MPI_Isend/Irecv com parâmetros válidos (buf, count, datatype, dest/src, tag, comm, request).",
                                "Implementa sincronização adequada com MPI_Wait/Test sem busy-waiting excessivo.",
                                "Evita deadlocks em trocas bidirecionais ou multi-etapa.",
                                "Inclui tratamento de erros (MPI_SUCCESS checks).",
                                "Demonstra sobreposição comunicação/computação.",
                                "Código limpo, comentado e reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Programação assíncrona em linguagens como JavaScript (async/await) ou Python (asyncio).",
                                "Redes de computadores: Protocolos TCP não-bloqueantes (select/poll/epoll).",
                                "Sistemas operacionais: I/O assíncrono e multiplexing.",
                                "Algoritmos paralelos: Modelos BSP vs. assíncronos.",
                                "Otimização de performance: Análise de bottlenecks em HPC."
                              ],
                              "realWorldApplication": "Em simulações científicas em supercomputadores, como modelagem climática (troca de grids entre subdomínios) ou processamento de big data em machine learning distribuído, onde comunicações não-bloqueantes permitem sobrepor I/O de rede com computação CPU/GPU, maximizando throughput em clusters de milhares de nós."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.2.1"
                            ]
                          },
                          {
                            "id": "10.1.2.5.2.3",
                            "name": "Gerenciar tipos de dados derivados em MPI",
                            "description": "Criar e usar tipos de dados personalizados com MPI_Type_contiguous, MPI_Type_vector e MPI_Type_commit para enviar estruturas complexas como arrays multidimensionais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Fundamentos de Tipos de Dados Derivados em MPI",
                                  "subSteps": [
                                    "Estude a documentação oficial do MPI sobre tipos derivados (MPI_Datatype).",
                                    "Identifique cenários onde tipos básicos não bastam, como arrays multidimensionais ou estruturas não contíguas.",
                                    "Revise funções chave: MPI_Type_contiguous, MPI_Type_vector, MPI_Type_commit.",
                                    "Analise exemplos simples de código fonte para envio de arrays 1D e 2D.",
                                    "Discuta com pares ou tutor as vantagens em eficiência de comunicação."
                                  ],
                                  "verification": "Resuma em um documento os propósitos das três funções principais e forneça um exemplo de uso inadequado de tipos básicos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação MPI (mpich.org ou open-mpi.org)",
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Sempre compare o overhead de comunicação com tipos derivados vs. loops manuais.",
                                  "learningObjective": "Explicar o conceito de tipos derivados e suas funções principais.",
                                  "commonMistakes": [
                                    "Confundir tipos derivados com alocações de memória",
                                    "Ignorar a necessidade de MPI_Type_commit"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Criar e Testar Tipos Contíguos com MPI_Type_contiguous",
                                  "subSteps": [
                                    "Declare um array contíguo de inteiros ou doubles.",
                                    "Chame MPI_Type_contiguous(count, oldtype, newtype) para criar o tipo derivado.",
                                    "Use MPI_Type_commit para finalizar o tipo.",
                                    "Implemente MPI_Send e MPI_Recv usando o novo tipo.",
                                    "Compile e execute em múltiplos processos para validar."
                                  ],
                                  "verification": "O programa envia e recebe corretamente um array de 100 elementos sem erros de segmentação.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código template MPI Hello World",
                                    "mpirun com 2-4 processos",
                                    "Debugger (gdb ou totalview)"
                                  ],
                                  "tips": "Use MPI_Get_count para verificar bytes transferidos pós-recv.",
                                  "learningObjective": "Construir e commitar um tipo contíguo para comunicação eficiente.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Type_free após uso",
                                    "Usar count incorreto levando a sobrescrita de memória"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Tipos Vetoriais com MPI_Type_vector para Dados Não Contíguos",
                                  "subSteps": [
                                    "Prepare um array 2D representado como 1D com stride (ex: matriz NxM).",
                                    "Aplique MPI_Type_vector(count, blocklength, stride, oldtype, newtype).",
                                    "Commit o tipo e integre em MPI_Sendrecv para trocas entre processos.",
                                    "Teste com diferentes strides para simular subamostragem.",
                                    "Valide recebimento comparando buffers original e recebido."
                                  ],
                                  "verification": "Matriz 10x10 enviada como vetor com stride 2 é recebida intacta em processo destino.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Exemplos de código MPI de repositórios GitHub (mpi4py ou similares)",
                                    "Valgrind para detecção de leaks"
                                  ],
                                  "tips": "Stride deve ser em elementos, não bytes; ajuste oldtype adequadamente.",
                                  "learningObjective": "Manipular arrays multidimensionais não contíguos via tipos vetoriais.",
                                  "commonMistakes": [
                                    "Confundir stride com blocklength",
                                    "Não converter índices 2D para 1D corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Tipos Derivados em Estruturas Complexas e Verificar Integração",
                                  "subSteps": [
                                    "Crie uma struct C com arrays e tipos primitivos (ex: struct {double mat[10][10]; int id;}).",
                                    "Combine MPI_Type_contiguous e MPI_Type_vector em MPI_Type_struct para hibridar.",
                                    "Commit e use em comunicação coletiva ou pontual.",
                                    "Execute em cluster pequeno (4 nós) e profile performance com MPI_Wtime.",
                                    "Refatore código para reutilizar tipos em múltiplas comunicações."
                                  ],
                                  "verification": "Estrutura complexa é enviada/ recebida corretamente, com tempos de comunicação < 1ms para dados pequenos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Cluster ou máquina multi-core com MPI",
                                    "Ferramentas de profiling (TAU ou Vampir)"
                                  ],
                                  "tips": "Sempre free tipos não usados para evitar vazamentos em runs longos.",
                                  "learningObjective": "Integrar múltiplos tipos derivados para dados reais complexos.",
                                  "commonMistakes": [
                                    "Offsets incorretos em MPI_Type_struct",
                                    "Não sincronizar com MPI_Barrier antes de commits"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de imagem médica, use MPI_Type_vector para enviar apenas pixels pares de uma matriz 512x512 entre processos, reduzindo tráfego de rede em 50% sem perda de dados.",
                              "finalVerifications": [
                                "Código compila e executa sem warnings ou erros em 4 processos.",
                                "Tipos derivados são corretamente committed e freed.",
                                "Comunicação de array 2D via vector mantém integridade de dados (checksum igual).",
                                "Performance melhora >20% vs. envio elemento-por-elemento.",
                                "Valgrind reporta zero leaks ou invalid reads/writes.",
                                "MPI_Get_elements confirma contagens corretas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de parâmetros (count, stride, blocklength).",
                                "Eficiência: redução mensurável no tempo de comunicação.",
                                "Robustez: funciona com tamanhos variáveis e múltiplos ranks.",
                                "Legibilidade: comentários explicando cada tipo derivado.",
                                "Correção: buffers pós-recv idênticos aos originais.",
                                "Escalabilidade: performance linear com tamanho de dados."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear para manipulação de vetores e matrizes.",
                                "Física: Simulações numéricas distribuídas (CFD, Monte Carlo).",
                                "Engenharia de Software: Abstrações de dados em linguagens C/Fortran.",
                                "Computação de Alto Desempenho: Otimização de bandwidth em HPC."
                              ],
                              "realWorldApplication": "Em supercomputadores para modelagem climática, tipos derivados permitem envio eficiente de grids 3D multidimensionais entre milhares de nós, acelerando simulações em ordens de magnitude."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.5.3",
                        "name": "Operações Coletivas em MPI",
                        "description": "Funções de comunicação coletiva que envolvem todos ou um subgrupo de processos em um comunicador, otimizando padrões comuns como difusão e redução.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.5.3.1",
                            "name": "Implementar MPI_Bcast e MPI_Reduce",
                            "description": "Usar MPI_Bcast para transmitir dados de um processo raiz para todos os outros e MPI_Reduce para computar reduções como soma ou máximo em um processo raiz.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambiente MPI e Entender MPI_Bcast",
                                  "subSteps": [
                                    "Instale e verifique a instalação do MPI (ex: OpenMPI) com 'mpirun --version'.",
                                    "Revise conceitos: MPI_Bcast transmite buffer do processo raiz para todos em um comunicador.",
                                    "Escreva um programa MPI básico com MPI_Init, MPI_Comm_rank, MPI_Comm_size e MPI_Finalize.",
                                    "Inclua MPI_Bcast com parâmetros: buffer, count, datatype, root, communicator.",
                                    "Compile com 'mpicc' e execute com 'mpirun -np 4 ./programa'."
                                  ],
                                  "verification": "Execute o programa e confirme que todos os processos recebem o mesmo valor broadcasted do root.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "OpenMPI ou MPICH instalado",
                                    "Editor de código (VS Code ou Vim)",
                                    "Terminal Linux/Mac"
                                  ],
                                  "tips": [
                                    "Use MPI_INT para inteiros simples; defina root como 0 inicialmente."
                                  ],
                                  "learningObjective": "Configurar MPI e implementar transmissão unidirecional de dados via Bcast.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init antes de chamadas coletivas.",
                                    "Buffer não alocado corretamente no root.",
                                    "Executar sem mpirun ou com np=1."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e Testar MPI_Bcast Isoladamente",
                                  "subSteps": [
                                    "Crie um array no processo root e inicialize com valores únicos.",
                                    "Chame MPI_Bcast para transmitir o array inteiro para todos os processos.",
                                    "Cada processo imprime seu rank e o valor recebido do array.",
                                    "Teste com diferentes tamanhos de np (2, 4, 8) e verifique sincronia.",
                                    "Adicione tratamento de erro com MPI_Bcast return code."
                                  ],
                                  "verification": "Output mostra que todos os processos têm o array idêntico ao do root, sem discrepâncias.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código do Step 1",
                                    "Compilador mpicc"
                                  ],
                                  "tips": [
                                    "Garanta que count e datatype combinem com o buffer para evitar overflows."
                                  ],
                                  "learningObjective": "Codificar e depurar MPI_Bcast para transmissão eficiente de dados.",
                                  "commonMistakes": [
                                    "Datatype incorreto (ex: MPI_FLOAT em vez de MPI_INT).",
                                    "Root não inicializando buffer.",
                                    "Falta de barreira implícita em collectives."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar e Implementar MPI_Reduce",
                                  "subSteps": [
                                    "Entenda MPI_Reduce: cada processo envia buffer para root, que aplica operação (ex: MPI_SUM).",
                                    "Inicialize buffers locais em cada processo com valores únicos (ex: rank * 10).",
                                    "Chame MPI_Reduce com sendbuf, recvbuf (no root), count, datatype, op, root, comm.",
                                    "Use MPI_Op como MPI_SUM ou MPI_MAX; root recebe o resultado.",
                                    "Imprima o resultado apenas no root e transmita via Bcast se necessário."
                                  ],
                                  "verification": "Root imprime soma ou máximo correto de todos os valores locais.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código expandido dos steps anteriores",
                                    "Documentação MPI (man mpi_reduce)"
                                  ],
                                  "tips": [
                                    "Recvbuf só é usado no root; outros ignoram."
                                  ],
                                  "learningObjective": "Aplicar reduções coletivas para agregar dados distribuídos.",
                                  "commonMistakes": [
                                    "Op não pré-definida (use MPI_SUM diretamente).",
                                    "Sendbuf e recvbuf sobrepostos incorretamente.",
                                    "Contar count errado para múltiplos elementos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar MPI_Bcast e MPI_Reduce em um Programa Completo",
                                  "subSteps": [
                                    "Combine: Bcast distribui workload (ex: array de números), cada processo computa parcial, Reduce soma totais.",
                                    "Teste com array grande: root broadcasts, processos somam locais, reduce global sum.",
                                    "Adicione timing com MPI_Wtime para medir performance.",
                                    "Execute com np=4-16 e valide escalabilidade.",
                                    "Debug com printf condicional por rank e finalize corretamente."
                                  ],
                                  "verification": "Programa produz soma global correta independentemente de np, com tempos razoáveis.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Códigos anteriores",
                                    "mpirun para testes paralelos"
                                  ],
                                  "tips": [
                                    "Use MPI_IN_PLACE para otimizar quando possível em Reduce."
                                  ],
                                  "learningObjective": "Desenvolver programa funcional usando ambas as operações coletivas.",
                                  "commonMistakes": [
                                    "Deadlocks por ordem errada de chamadas.",
                                    "Não limpar buffers antes de Bcast.",
                                    "Ignorar erros de retorno das funções MPI."
                                  ]
                                }
                              ],
                              "practicalExample": "Programa que simula soma paralela de vetor: root broadcasts vetor de 1000 elementos, cada processo soma sua porção atribuída por rank, então MPI_Reduce soma parciais no root, que imprime total.",
                              "finalVerifications": [
                                "Código compila sem warnings com mpicc -Wall.",
                                "Execução com np=1 a 16 produz output idêntico e correto.",
                                "Valgrind ou gdb não detecta leaks ou erros em execuções paralelas.",
                                "Timing mostra speedup com mais processos.",
                                "Documentação inline explica parâmetros de cada chamada MPI.",
                                "Teste unitário: altere valores e confirme reduções (sum, max)."
                              ],
                              "assessmentCriteria": [
                                "Sintaxe correta e parâmetros exatos para MPI_Bcast e MPI_Reduce.",
                                "Gerenciamento adequado de buffers e alocações dinâmicas.",
                                "Tratamento de erros e verificação de retornos MPI.",
                                "Eficiência: uso de collectives sem loops manuais desnecessários.",
                                "Comentários claros e estrutura modular do código.",
                                "Validação em múltiplos cenários (diferentes np, ops)."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados: reduções em prefix sums paralelos.",
                                "Redes de Computadores: conceitos de broadcast e all-reduce em redes.",
                                "Computação de Alto Desempenho: padrões em HPC como em supercomputadores.",
                                "Matemática Computacional: agregações em simulações numéricas.",
                                "Engenharia de Software: programação paralela e depuração distribuída."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: CFD com OpenFOAM), MPI_Bcast distribui grades iniciais para nós de cluster, MPI_Reduce agrega estatísticas de erro ou energia total para monitoramento global em supercomputadores."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.2.2"
                            ]
                          },
                          {
                            "id": "10.1.2.5.3.2",
                            "name": "Aplicar MPI_Scatter e MPI_Gather",
                            "description": "Distribuir dados de um processo para todos (MPI_Scatter) e coletar dados de todos para um processo (MPI_Gather), útil em decomposição de domínio.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos e sintaxe de MPI_Scatter e MPI_Gather",
                                  "subSteps": [
                                    "Estude a definição: MPI_Scatter distribui dados do processo root para todos os processos em blocos iguais; MPI_Gather coleta dados de todos os processos para o root.",
                                    "Analise os parâmetros: sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, root, comm.",
                                    "Compare com outras coletivas: Diferente de MPI_Bcast (broadcast para todos) e MPI_Reduce (redução).",
                                    "Revise requisitos: Todos os processos devem chamar as funções; tamanhos devem ser consistentes.",
                                    "Leia documentação oficial do MPI (man mpi_scatter e man mpi_gather)."
                                  ],
                                  "verification": "Resuma em suas palavras as diferenças entre Scatter, Gather e Bcast, e liste os 8 parâmetros obrigatórios.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI (OpenMPI ou MPICH)",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Use diagramas para visualizar o fluxo de dados entre processos.",
                                  "learningObjective": "Entender o funcionamento conceitual e parâmetros das funções MPI_Scatter e MPI_Gather.",
                                  "commonMistakes": [
                                    "Confundir Scatter com Bcast",
                                    "Esquecer que sendcount/recvcount deve ser o tamanho por processo",
                                    "Não especificar root corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente MPI e implementar MPI_Scatter",
                                  "subSteps": [
                                    "Instale MPI se necessário (ex: sudo apt install openmpi-bin libopenmpi-dev).",
                                    "Crie um programa C simples com MPI_Init, MPI_Comm_size, MPI_Comm_rank e MPI_Finalize.",
                                    "No processo root (rank 0), prepare um array sendbuf com dados para N processos (ex: 1 a 100).",
                                    "Chame MPI_Scatter com sendcount=10 (para 10 processos), sendtype=MPI_INT.",
                                    "No recvbuf de cada processo, imprima os dados recebidos."
                                  ],
                                  "verification": "Compile com mpicc e execute com mpirun -np 4; verifique se cada processo recebe sua porção correta.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VSCode ou similar)",
                                    "Terminal"
                                  ],
                                  "tips": "Use MPI_Get_processor_name para identificar processos durante debug.",
                                  "learningObjective": "Implementar corretamente MPI_Scatter em um programa distribuído.",
                                  "commonMistakes": [
                                    "Não alocar memória suficiente para sendbuf/recvbuf",
                                    "Chamar Scatter sem todos os processos sincronizados",
                                    "Usar tamanho total em sendcount ao invés de por processo"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Gather e testar individualmente",
                                  "subSteps": [
                                    "Modifique o código: Cada processo preenche recvbuf local com dados próprios (ex: rank*10 + i).",
                                    "Chame MPI_Gather para coletar todos os recvbuf no sendbuf do root.",
                                    "No root, imprima o array completo coletado.",
                                    "Compile e execute com diferentes números de processos (4, 8).",
                                    "Verifique se a ordem dos dados está correta (processo 0 primeiro, etc.)."
                                  ],
                                  "verification": "Saída no root deve mostrar array completo ordenado por rank dos processos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Mesmo código base do Step 2",
                                    "mpirun"
                                  ],
                                  "tips": "Garanta que recvcount == sendcount para consistência.",
                                  "learningObjective": "Dominar a implementação de MPI_Gather e validar resultados.",
                                  "commonMistakes": [
                                    "Inverter sendbuf e recvbuf",
                                    "Não inicializar dados locais corretamente",
                                    "Executar com np incompatível com sendcount"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Combinar MPI_Scatter e MPI_Gather em decomposição de domínio",
                                  "subSteps": [
                                    "Crie um array global no root (ex: vetor de 100 elementos para soma local).",
                                    "Use Scatter para distribuir partes iguais; cada processo compute soma local.",
                                    "Use Gather para coletar somas locais no root.",
                                    "No root, compute soma total e compare com versão serial.",
                                    "Adicione MPI_Barrier para sincronização e teste com np=5,10."
                                  ],
                                  "verification": "Soma total deve coincidir com soma serial; tempo de execução escalável.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Código combinado",
                                    "mpirun -np <varia>",
                                    "Calculadora para soma serial"
                                  ],
                                  "tips": "Monitore com mpirun -np 4 -hostfile hosts ./a.out para multi-nó se possível.",
                                  "learningObjective": "Aplicar Scatter e Gather em um problema real de decomposição de domínio.",
                                  "commonMistakes": [
                                    "Perder sincronização entre Scatter e Gather",
                                    "Off-by-one em tamanhos de array",
                                    "Não tratar root recebendo/enviando corretamente"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de soma paralela de vetor: Root tem vetor [1..100]; Scatter distribui 10 elementos por processo (np=10); cada processo soma localmente; Gather coleta somas para root calcular total (5050).",
                              "finalVerifications": [
                                "Programa compila sem warnings com mpicc -Wall.",
                                "Executa corretamente com 4, 8 e 16 processos.",
                                "Dados distribuídos/coletados estão na ordem correta por rank.",
                                "Soma ou resultado final idêntico à versão serial.",
                                "Nenhum deadlock ou crash em múltiplas execuções.",
                                "Tempo de execução diminui com mais processos (escalabilidade)."
                              ],
                              "assessmentCriteria": [
                                "Correção: Implementação segue sintaxe MPI exata.",
                                "Eficiência: Uso ótimo de buffers e counts.",
                                "Robustez: Funciona com diferentes np e tamanhos.",
                                "Clareza: Código comentado e legível.",
                                "Validação: Inclui prints de debug e comparação serial.",
                                "Escalabilidade: Demonstra speedup com np crescente."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos Paralelos: Decomposição de dados em domínios.",
                                "Computação Científica: Simulações numéricas distribuídas (ex: CFD).",
                                "Big Data: Processamento distribuído similar a MapReduce.",
                                "Sistemas Operacionais: Gerenciamento de processos e memória compartilhada vs. distribuída."
                              ],
                              "realWorldApplication": "Em simulações climáticas (distribuir grade do planeta para nós e coletar resultados), processamento de imagens em clusters (Scatter pixels, Gather features) ou machine learning distribuído (Scatter batches de dados para treinamento local e Gather gradientes)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.3.1"
                            ]
                          },
                          {
                            "id": "10.1.2.5.3.3",
                            "name": "Usar MPI_Allreduce e topologias",
                            "description": "Implementar MPI_Allreduce para reduções globais acessíveis por todos os processos e criar topologias virtuais com MPI_Cart_create para grids lógicos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos de MPI_Allreduce",
                                  "subSteps": [
                                    "Estudar a documentação oficial do MPI sobre MPI_Allreduce e suas assinaturas.",
                                    "Identificar os parâmetros principais: buffers de entrada e saída, contagem, tipo de dado, operação (ex: MPI_SUM) e comunicador.",
                                    "Entender que é uma operação coletiva bloqueante onde todos os processos contribuem e recebem o resultado da redução global.",
                                    "Comparar MPI_Allreduce com MPI_Reduce, destacando que Allreduce difunde o resultado para todos.",
                                    "Analisar exemplos de operações suportadas como soma, máximo, mínimo e lógico AND/OR."
                                  ],
                                  "verification": "Explicar em suas palavras o funcionamento de MPI_Allreduce e listar 3 diferenças para MPI_Reduce.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação MPI oficial (man mpi_allreduce)",
                                    "Livro 'Using MPI' de Gropp et al.",
                                    "Ambiente MPI instalado"
                                  ],
                                  "tips": "Use diagramas para visualizar o fluxo de dados entre processos.",
                                  "learningObjective": "Dominar os fundamentos teóricos de MPI_Allreduce para reduções globais.",
                                  "commonMistakes": [
                                    "Confundir buffers de entrada e saída",
                                    "Esquecer que a operação deve ser comutativa e associativa",
                                    "Ignorar o alinhamento de tipos de dados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Allreduce em um programa básico",
                                  "subSteps": [
                                    "Inicializar o ambiente MPI com MPI_Init e obter rank e size com MPI_Comm_rank e MPI_Comm_size.",
                                    "Definir um array ou valor local único por processo (ex: rank * 10).",
                                    "Chamar MPI_Allreduce com MPI_SUM para somar valores globais em um buffer de saída.",
                                    "Imprimir o resultado da redução em todos os processos para verificação.",
                                    "Finalizar com MPI_Finalize e compilar com mpicc."
                                  ],
                                  "verification": "Executar com 'mpirun -np 4 ./programa' e confirmar que todos os processos imprimem a soma correta (ex: 0+10+20+30=60).",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou Vim)",
                                    "Terminal com MPI instalado (OpenMPI ou MPICH)"
                                  ],
                                  "tips": "Inicie com poucos processos (2-4) para depuração fácil.",
                                  "learningObjective": "Aplicar MPI_Allreduce em código para realizar reduções globais simples.",
                                  "commonMistakes": [
                                    "Não inicializar/finalizar MPI corretamente",
                                    "Usar tipo de dado incompatível na operação",
                                    "Esquecer de alocar buffers do tamanho correto"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Entender topologias virtuais em MPI",
                                  "subSteps": [
                                    "Estudar conceitos de topologias lógicas vs. físicas no MPI.",
                                    "Revisar funções como MPI_Graph_create e MPI_Cart_create para criar comunicadores derivados.",
                                    "Compreender parâmetros de topologias cartesianas: dimensões (dims), períodos (periods) e reorder.",
                                    "Aprender a mapear ranks para coordenadas com MPI_Cart_coords e obter vizinhos com MPI_Cart_shift.",
                                    "Analisar benefícios: otimização de comunicação em grids ou grafos."
                                  ],
                                  "verification": "Desenhar um diagrama de uma topologia 2D 2x2 e explicar o mapeamento de ranks 0-3 para coordenadas (0,0), (0,1), (1,0), (1,1).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI (man mpi_cart_create)",
                                    "Tutoriais online MPI topology",
                                    "Papel e caneta para diagramas"
                                  ],
                                  "tips": "Pense em topologias como abstrações para padrões comuns como grids em simulações.",
                                  "learningObjective": "Compreender como topologias virtuais organizam comunicação entre processos.",
                                  "commonMistakes": [
                                    "Confundir reorder=true (otimiza mapeamento) com false",
                                    "Definir dims cuja multiplicação não iguale o número de processos",
                                    "Ignorar periods para topologias não-toroidais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar topologias com MPI_Cart_create",
                                  "subSteps": [
                                    "Inicializar MPI e criar um array dims[2] = {2,2} para grid 2x2 e periods[2] = {0,0}.",
                                    "Chamar MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, 1, &cart_comm) e verificar se válido.",
                                    "Obter coordenadas do rank com MPI_Cart_coords e imprimir para verificação.",
                                    "Integrar com MPI_Allreduce no novo comunicador cart_comm.",
                                    "Executar e depurar com mpirun -np 4."
                                  ],
                                  "verification": "Verificar saídas: todos recebem soma via Allreduce e coordenadas corretas (ex: rank 0: (0,0)).",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "mpicc",
                                    "Editor de código",
                                    "mpirun para execução distribuída"
                                  ],
                                  "tips": "Use MPI_COMM_NULL para processos fora da topologia se size > produto de dims.",
                                  "learningObjective": "Criar e usar topologias cartesianas virtuais com MPI_Cart_create.",
                                  "commonMistakes": [
                                    "Não tratar retorno de MPI_Cart_create adequadamente",
                                    "Usar comunicador original após derivação sem verificar",
                                    "Erro em alocação de arrays dims/periods"
                                  ]
                                }
                              ],
                              "practicalExample": "Desenvolva um programa onde 4 processos (grid 2x2) calculam a soma local de um array pequeno, usam MPI_Allreduce no comunicador cartesiano para redução global de soma e máximo, imprimem coordenadas e resultados. Exemplo: Processo (0,0) soma=5, (0,1)=3 → global sum=14, max=5.",
                              "finalVerifications": [
                                "Programa compila sem erros com mpicc -o programa programa.c.",
                                "Execução com mpirun -np 4 mostra soma e máximo corretos em todos os processos.",
                                "Coordenadas de cada rank são impressas corretamente via MPI_Cart_coords.",
                                "MPI_Allreduce no comunicador derivado funciona sem deadlocks.",
                                "Nenhum vazamento de memória ou erro MPI detectado com ferramentas como Valgrind.",
                                "Teste com np=8 falha graciosamente se topologia 2x2 não acomodar todos."
                              ],
                              "assessmentCriteria": [
                                "Uso correto de parâmetros em MPI_Allreduce (buffers, op=MPI_SUM, comm).",
                                "Criação bem-sucedida de topologia com MPI_Cart_create (dims válidos, periods).",
                                "Verificação adequada do comunicador cartesiano (MPI_COMM_NULL check).",
                                "Integração correta entre Allreduce e topologia (uso de cart_comm).",
                                "Código limpo, comentado e com tratamento de erros MPI.",
                                "Resultados consistentes em múltiplas execuções e tamanhos de mundo."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Operações de redução associativas/comutativas (álgebra linear).",
                                "Ciência da Computação: Teoria de grafos e redes de comunicação.",
                                "Engenharia de Software: Design de padrões de comunicação escaláveis.",
                                "Física/Engenharia: Modelagem de grids em simulações numéricas (CFD, FEM)."
                              ],
                              "realWorldApplication": "Em simulações científicas como dinâmica de fluidos computacional (CFD), onde MPI_Allreduce computa estatísticas globais (energia total, forças) e topologias cartesianas definem grids lógicos para trocas eficientes entre células vizinhas em supercomputadores."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.2.5.3.1",
                              "10.1.2.5.2.3"
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.3",
                "name": "Modelos de Programação Paralela para Memória Compartilhada",
                "description": "Aborda decomposição de domínio e exclusão mútua como técnicas para programação em memória compartilhada.",
                "totalSkills": 48,
                "atomicTopics": [
                  {
                    "id": "10.1.3.1",
                    "name": "Taxonomia de Flynn",
                    "description": "Classificação de arquiteturas paralelas, com ênfase em modelos SIMD e MIMD para memória compartilhada.",
                    "individualConcepts": [
                      {
                        "id": "64.1.1.1",
                        "name": "Fundamentos da Taxonomia de Flynn",
                        "description": "Classificação das arquiteturas de computadores paralelos baseada nos fluxos de instruções e dados, dividida em quatro categorias principais: SISD, SIMD, MISD e MIMD.",
                        "specificSkills": [
                          {
                            "id": "64.1.1.1.1",
                            "name": "Identificar os eixos de classificação da Taxonomia de Flynn",
                            "description": "Explicar os dois eixos principais (fluxo de instruções: Single Instruction ou Multiple Instructions; fluxo de dados: Single Data ou Multiple Data) e como eles geram as quatro classes de arquiteturas paralelas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Pesquise a definição histórica da Taxonomia de Flynn, criada por Michael J. Flynn em 1966.",
                                    "Identifique o propósito principal: classificar arquiteturas de computadores com base em paralelismo.",
                                    "Visualize um diagrama geral dos dois eixos de classificação.",
                                    "Anote as abreviações principais: SI (Single Instruction), MI (Multiple Instructions), SD (Single Data), MD (Multiple Data).",
                                    "Compare com classificações anteriores para contextualizar."
                                  ],
                                  "verification": "Crie um resumo de 1 parágrafo explicando o que é a Taxonomia e seus eixos principais.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Artigo original de Flynn (PDF online)",
                                    "Diagrama da Taxonomia de Flynn (imagem ou vídeo do YouTube)"
                                  ],
                                  "tips": "Use mnemônicos como 'Instruções vs. Dados' para lembrar os eixos.",
                                  "learningObjective": "Entender o contexto e propósito da Taxonomia de Flynn como base para classificação de arquiteturas paralelas.",
                                  "commonMistakes": [
                                    "Confundir com outras taxonomias como Gustafson ou Amdahl.",
                                    "Ignorar o ano histórico (1966)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o Eixo de Fluxo de Instruções",
                                  "subSteps": [
                                    "Defina 'Single Instruction (SI)': uma única stream de instruções executada simultaneamente em múltiplos dados.",
                                    "Defina 'Multiple Instructions (MI)': múltiplas streams de instruções independentes.",
                                    "Estude exemplos: SI em processadores vetoriais, MI em multiprocessadores.",
                                    "Desenhe um fluxograma ilustrando o fluxo SI vs. MI.",
                                    "Compare o impacto no paralelismo de instruções."
                                  ],
                                  "verification": "Classifique 3 exemplos de arquiteturas como SI ou MI com justificativa.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Vídeo explicativo sobre streams de instruções (Khan Academy ou similar)",
                                    "Papel e caneta para fluxogramas"
                                  ],
                                  "tips": "Pense em 'uma receita (SI) vs. várias receitas independentes (MI)' para visualizar.",
                                  "learningObjective": "Dominar a distinção entre Single Instruction e Multiple Instructions, identificando seu papel na taxonomia.",
                                  "commonMistakes": [
                                    "Confundir fluxo de instruções com fluxo de dados.",
                                    "Achar que SI significa sempre serial."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar o Eixo de Fluxo de Dados",
                                  "subSteps": [
                                    "Defina 'Single Data (SD)': uma única stream de dados processada por instruções.",
                                    "Defina 'Multiple Data (MD)': múltiplas streams de dados processadas em paralelo.",
                                    "Examine exemplos: SD em processadores escalares, MD em arrays de processamento.",
                                    "Crie uma tabela comparativa de SD vs. MD com prós e contras.",
                                    "Integre com o eixo anterior para prever combinações."
                                  ],
                                  "verification": "Explique em áudio de 1 minuto a diferença entre SD e MD com um exemplo diário.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tabela em branco no Excel ou papel",
                                    "Vídeo sobre SIMD (ex: GPUs)"
                                  ],
                                  "tips": "Associe MD a 'processar várias fotos ao mesmo tempo' em editores de imagem.",
                                  "learningObjective": "Identificar e diferenciar Single Data e Multiple Data, compreendendo seu impacto no paralelismo.",
                                  "commonMistakes": [
                                    "Invertir SD com SISD.",
                                    "Subestimar o papel de MD em aplicações modernas como IA."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Combinar Eixos e Identificar as Quatro Classes",
                                  "subSteps": [
                                    "Liste as 4 classes: SISD (SI+SD), SIMD (SI+MD), MISD (MI+SD), MIMD (MI+MD).",
                                    "Classifique arquiteturas reais: CPU clássica (SISD), GPU (SIMD), pipeline fault-tolerant (MISD), cluster (MIMD).",
                                    "Crie uma matriz 2x2 visualizando as combinações.",
                                    "Discuta raridade de MISD e dominância de MIMD hoje.",
                                    "Teste identificando classes em cenários hipotéticos."
                                  ],
                                  "verification": "Preencha uma matriz 2x2 corretamente com definições e exemplos para cada classe.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramenta de desenho como Draw.io ou papel quadriculado",
                                    "Lista de arquiteturas modernas (Wikipedia)"
                                  ],
                                  "tips": "Use a matriz como 'mapa mental' para memorizar combinações rapidamente.",
                                  "learningObjective": "Aplicar os dois eixos para classificar corretamente as quatro arquiteturas paralelas.",
                                  "commonMistakes": [
                                    "Confundir SIMD com MIMD.",
                                    "Esquecer MISD como classe válida apesar de rara."
                                  ]
                                }
                              ],
                              "practicalExample": "Classifique uma GPU NVIDIA como SIMD: ela executa uma única instrução (kernel) em múltiplos dados (pixels ou vetores em shaders paralelos). Em contraste, um cluster de servidores é MIMD, com múltiplas instruções independentes em múltiplos dados distribuídos.",
                              "finalVerifications": [
                                "Corretamente desenhe e label a matriz 2x2 da Taxonomia.",
                                "Classifique 5 arquiteturas reais sem erros (ex: CPU, GPU, DSP, supercomputador).",
                                "Explique verbalmente os dois eixos em menos de 2 minutos.",
                                "Identifique MISD em um exemplo obscuro como fault-tolerant systems.",
                                "Compare Flynn com uma taxonomia moderna sem confusões."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição dos eixos (100% correto).",
                                "Capacidade de classificar exemplos reais (mínimo 4/5 corretos).",
                                "Clareza na explicação das combinações (sem ambiguidades).",
                                "Uso correto de terminologia (SI, MI, SD, MD).",
                                "Criatividade em analogias práticas para ensino."
                              ],
                              "crossCurricularConnections": [
                                "Hardware: Design de processadores e GPUs.",
                                "Programação: Modelos como OpenMP (SIMD-like) vs. MPI (MIMD).",
                                "Matemática: Vetores e operações paralelas em álgebra linear.",
                                "Engenharia de Software: Escalabilidade em sistemas distribuídos."
                              ],
                              "realWorldApplication": "Em design de GPUs para jogos e IA, SIMD acelera processamento de gráficos; em supercomputadores como TOP500, MIMD permite simulações climáticas complexas com instruções independentes em dados massivos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.1.1.1.2",
                            "name": "Listar e diferenciar as quatro classes da taxonomia",
                            "description": "Descrever SISD (sequencial), SIMD (vetorizado), MISD (pipeline) e MIMD (multiprocessador), com exemplos de arquiteturas reais como Cray para SIMD.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Ler a definição original de Michael J. Flynn (1966) sobre classificação de arquiteturas de computadores.",
                                    "Identificar os dois eixos de classificação: fluxo de instruções (Single Instruction - SI ou Multiple Instruction - MI) e fluxo de dados (Single Data - SD ou Multiple Data - MD).",
                                    "Desenhar um diagrama 2x2 mostrando as quatro classes resultantes.",
                                    "Memorizar as siglas: SISD, SIMD, MISD, MIMD.",
                                    "Explicar em suas palavras o propósito da taxonomia."
                                  ],
                                  "verification": "Criar e revisar um diagrama pessoal das quatro classes com rótulos corretos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Artigo original de Flynn (disponível online), papel e caneta ou ferramenta de diagrama como Draw.io.",
                                  "tips": "Use cores diferentes para instruções e dados no diagrama para visualização clara.",
                                  "learningObjective": "Dominar a estrutura conceitual da taxonomia.",
                                  "commonMistakes": "Confundir fluxo de instruções com fluxo de dados; sempre diferencie os eixos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar a classe SISD (Single Instruction, Single Data)",
                                  "subSteps": [
                                    "Descrever SISD como arquitetura sequencial tradicional.",
                                    "Exemplificar com processadores von Neumann convencionais como Intel x86.",
                                    "Explicar como uma única instrução é aplicada a um único dado por ciclo.",
                                    "Comparar com programação serial simples.",
                                    "Identificar limitações para computação paralela."
                                  ],
                                  "verification": "Escrever um parágrafo definindo SISD e dando um exemplo real.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Diagramas de processadores von Neumann, exemplos de código sequencial em C.",
                                  "tips": "Pense em um loop simples for(i=0; i<n; i++) como execução SISD.",
                                  "learningObjective": "Diferenciar SISD de arquiteturas paralelas.",
                                  "commonMistakes": "Achar que SISD é obsoleto; ainda é base para computadores pessoais."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar SIMD (Single Instruction, Multiple Data) e MISD (Multiple Instruction, Single Data)",
                                  "subSteps": [
                                    "Para SIMD: Descrever aplicação de uma instrução a múltiplos dados (vetorização), exemplo Cray-1 ou GPUs modernas.",
                                    "Para MISD: Explicar processamento pipeline ou fault-tolerant, exemplos raros como máquinas pipeline especializadas.",
                                    "Desenhar fluxogramas comparativos para cada.",
                                    "Listar vantagens: SIMD para processamento de imagens, MISD para redundância.",
                                    "Pesquisar um exemplo moderno para cada (ex: Intel SSE para SIMD)."
                                  ],
                                  "verification": "Criar tabela comparativa SIMD vs MISD com colunas: definição, exemplo, uso.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Vídeos sobre Cray-1 no YouTube, documentação de instruções vetoriais SIMD.",
                                  "tips": "Visualize SIMD como uma instrução 'add' aplicada a um vetor inteiro de uma vez.",
                                  "learningObjective": "Entender paralelizações em fluxo de dados e instruções.",
                                  "commonMistakes": "Confundir SIMD com vetores em linguagens; foque na arquitetura hardware."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar MIMD (Multiple Instruction, Multiple Data) e diferenciar todas as classes",
                                  "subSteps": [
                                    "Descrever MIMD como multiprocessadores com instruções e dados independentes, exemplos clusters ou multi-core CPUs.",
                                    "Criar matriz de diferenciação: linhas para classes, colunas para instruções/dados/exemplos.",
                                    "Comparar eficiência em tarefas paralelas vs sequenciais.",
                                    "Discutir exemplos reais: Cray para SIMD, Beowulf clusters para MIMD.",
                                    "Simular classificação de uma arquitetura dada (ex: GPU é SIMD)."
                                  ],
                                  "verification": "Classificar corretamente 3 arquiteturas dadas em uma das 4 classes.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Lista de arquiteturas (Wikipedia Taxonomia de Flynn), simulador online de arquiteturas.",
                                  "tips": "Use mnemônicos: 'SImples Sequencial' para SISD, 'Muitos Membros' para MIMD.",
                                  "learningObjective": "Diferenciar todas as classes com exemplos precisos.",
                                  "commonMistakes": "Classificar GPUs como MIMD; GPUs são principalmente SIMD."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Praticar e consolidar o conhecimento",
                                  "subSteps": [
                                    "Resolver quiz com 10 perguntas sobre definições e exemplos.",
                                    "Explicar a taxonomia para um colega ou gravar um vídeo de 2 minutos.",
                                    "Aplicar em um caso: classificar modelo de programação OpenMP (MIMD).",
                                    "Revisar erros comuns das classes.",
                                    "Criar flashcards para revisão rápida."
                                  ],
                                  "verification": "Atingir 100% em quiz auto-aplicado.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Quiz online (Kahoot ou Quizlet sobre Flynn), flashcards app como Anki.",
                                  "tips": "Ensine para aprender: explique como se fosse para um iniciante.",
                                  "learningObjective": "Consolidar diferenciação prática.",
                                  "commonMistakes": "Ignorar raridade do MISD; saiba que é teórico na prática."
                                }
                              ],
                              "practicalExample": "Classifique a arquitetura de uma GPU NVIDIA como SIMD: uma única instrução (kernel) aplicada a milhares de threads de dados em paralelo para renderização gráfica.",
                              "finalVerifications": [
                                "Listar corretamente as siglas e nomes completos das 4 classes.",
                                "Descrever diferenças nos fluxos de instruções e dados para cada classe.",
                                "Fornecer pelo menos um exemplo real por classe (ex: Cray para SIMD).",
                                "Classificar uma arquitetura desconhecida corretamente.",
                                "Explicar limitações de cada classe em computação paralela.",
                                "Desenhar diagrama preciso da taxonomia 2x2."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições (100% das siglas e fluxos corretos).",
                                "Qualidade dos exemplos reais e relevância (pelo menos 4 exemplos válidos).",
                                "Profundidade nas diferenciações (comparações claras entre classes).",
                                "Clareza na explicação verbal ou escrita.",
                                "Uso correto de terminologia técnica.",
                                "Capacidade de aplicação prática em classificações."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Ligação direta com von Neumann e Harvard.",
                                "Programação Paralela: Modelos como OpenMP (MIMD) e CUDA (SIMD).",
                                "Engenharia de Software: Design de sistemas distribuídos.",
                                "Matemática: Processamento vetorial em álgebra linear.",
                                "História da Computação: Evolução de supercomputadores como Cray."
                              ],
                              "realWorldApplication": "Em supercomputação, GPUs usam SIMD para IA e machine learning, enquanto clusters MIMD rodam simulações climáticas em data centers como os do TOP500."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.1.1.1.3",
                            "name": "Relacionar taxonomia com modelos de memória compartilhada",
                            "description": "Analisar como SIMD e MIMD se aplicam a sistemas de memória compartilhada, destacando o controle unificado de instruções em SIMD e a independência em MIMD.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude a definição de Taxonomia de Flynn e suas quatro categorias: SISD, SIMD, MISD e MIMD.",
                                    "Identifique características chave de SIMD: controle unificado de instruções e dados paralelos.",
                                    "Identifique características chave de MIMD: múltiplos fluxos independentes de instruções e dados.",
                                    "Anote exemplos clássicos para cada categoria.",
                                    "Crie um diagrama simples comparando os fluxos de instruções e dados."
                                  ],
                                  "verification": "Confirme compreensão respondendo a perguntas como: 'Qual a diferença principal entre SIMD e MIMD?' com explicações corretas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notas de aula sobre Taxonomia de Flynn, diagrama da Wikipedia ou livro de arquitetura de computadores.",
                                  "tips": "Use mnemônicos como 'SIMD: Same Instruction, Multiple Data' para memorizar.",
                                  "learningObjective": "Compreender as bases conceituais da Taxonomia de Flynn, focando em SIMD e MIMD.",
                                  "commonMistakes": "Confundir SIMD com paralelismo de dados vs. MIMD como totalmente independente; lembre que ambos podem usar memória compartilhada."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Modelos de Memória Compartilhada",
                                  "subSteps": [
                                    "Defina memória compartilhada: todos os processadores acessam um espaço de endereçamento único.",
                                    "Discuta tipos: UMA (Uniform Memory Access) e NUMA (Non-Uniform Memory Access).",
                                    "Explique desafios como contenção de cache e sincronização.",
                                    "Compare brevemente com memória distribuída.",
                                    "Liste exemplos de hardware: multiprocessadores SMP."
                                  ],
                                  "verification": "Desenhe um diagrama de um sistema de memória compartilhada com múltiplos processadores.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Artigos sobre arquiteturas SMP/NUMA, simulador online de multiprocessadores.",
                                  "tips": "Pense em memória compartilhada como uma 'cozinha compartilhada' onde todos acessam os mesmos ingredientes.",
                                  "learningObjective": "Dominar o conceito de memória compartilhada e suas implicações para paralelismo.",
                                  "commonMistakes": "Assumir que memória compartilhada elimina todos os problemas de comunicação; contenção ainda existe."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar SIMD em Sistemas de Memória Compartilhada",
                                  "subSteps": [
                                    "Descreva como SIMD opera em memória compartilhada: uma única unidade de controle envia instruções idênticas a múltiplos processadores de dados.",
                                    "Estude exemplos: extensões SSE/AVX em CPUs ou unidades vetoriais em Cray.",
                                    "Explique acesso à memória: todos os elementos vetoriais acessam dados alinhados na memória compartilhada.",
                                    "Discuta limitações: dados devem ser regulares e alinhados.",
                                    "Simule um exemplo simples com pseudocódigo vetorizado."
                                  ],
                                  "verification": "Implemente um loop vetorizado simples e verifique se usa memória compartilhada implicitamente.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Documentação Intel SSE/AVX, compilador com flags de vetorização.",
                                  "tips": "Ative vetorização no compilador com -O3 -march=native para ver SIMD em ação.",
                                  "learningObjective": "Relacionar o controle unificado de SIMD com acessos coordenados em memória compartilhada.",
                                  "commonMistakes": "Ignorar alinhamento de dados, causando falhas de performance em SIMD."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar MIMD em Sistemas de Memória Compartilhada",
                                  "subSteps": [
                                    "Descreva MIMD em memória compartilhada: cada processador executa instruções independentes, sincronizando via locks/barreiras.",
                                    "Estude exemplos: clusters SMP como em servidores multi-core.",
                                    "Explique gerenciamento de memória: threads compartilham heap, mas stacks privados.",
                                    "Discuta programação: OpenMP para threads em memória compartilhada.",
                                    "Compare overheads: sincronização vs. eficiência SIMD."
                                  ],
                                  "verification": "Escreva um programa OpenMP simples com threads independentes acessando memória compartilhada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "OpenMP tutorial, ambiente com múltiplos cores (gcc com -fopenmp).",
                                  "tips": "Use #pragma omp parallel para criar threads MIMD rapidamente.",
                                  "learningObjective": "Entender a independência de instruções em MIMD dentro de memória compartilhada.",
                                  "commonMistakes": "Race conditions por falta de sincronização em acessos compartilhados."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Relacionar e Comparar SIMD e MIMD em Memória Compartilhada",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: controle de instruções, flexibilidade, casos de uso.",
                                    "Analise quando usar SIMD (dados regulares) vs. MIMD (tarefas irregulares).",
                                    "Discuta hibridizações modernas como SIMT em GPUs.",
                                    "Resuma vantagens: escalabilidade em memória compartilhada.",
                                    "Responda a cenários: 'Qual modelo para processamento de imagem?'"
                                  ],
                                  "verification": "Explique verbalmente ou por escrito como a taxonomia se aplica a um sistema específico.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Tabela em branco, exemplos de benchmarks.",
                                  "tips": "Use setas em diagramas para mostrar fluxos unificados (SIMD) vs. paralelos (MIMD).",
                                  "learningObjective": "Sintetizar a relação entre taxonomia de Flynn e modelos de memória compartilhada.",
                                  "commonMistakes": "Generalizar MIMD como sempre melhor; SIMD é ótimo para vetorização."
                                }
                              ],
                              "practicalExample": "Implemente um programa em C com OpenMP (MIMD) para somar matrizes irregulares e compare com versão vetorizada SSE (SIMD), medindo tempo em memória compartilhada multi-core, destacando controle unificado vs. independente.",
                              "finalVerifications": [
                                "Explicar corretamente o controle unificado em SIMD vs. independência em MIMD.",
                                "Desenhar diagramas precisos de fluxos em memória compartilhada.",
                                "Identificar exemplos reais como AVX para SIMD e OpenMP para MIMD.",
                                "Discutir limitações de cada em cenários compartilhados.",
                                "Comparar performance em um benchmark simples.",
                                "Relacionar à taxonomia sem erros conceituais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção de SIMD/MIMD (90% correto).",
                                "Profundidade na análise de memória compartilhada (inclui UMA/NUMA).",
                                "Qualidade de diagramas e exemplos práticos.",
                                "Capacidade de relacionar conceitos à programação real.",
                                "Identificação de erros comuns e soluções.",
                                "Clareza na síntese comparativa."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Estudo de caches e coerência em SMP.",
                                "Programação Paralela: Aplicação em OpenMP e pragmas vetorizados.",
                                "Sistemas Operacionais: Gerenciamento de threads e sincronização.",
                                "Engenharia de Software: Design de algoritmos paralelos escaláveis."
                              ],
                              "realWorldApplication": "Em supercomputadores como os da Cray (SIMD vetorial) ou servidores AWS multi-core (MIMD com OpenMP), otimizando processamento de big data, IA e simulações científicas onde eficiência em memória compartilhada acelera workloads massivos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "64.1.1.2",
                        "name": "Modelo SIMD para Memória Compartilhada",
                        "description": "Arquiteturas onde múltiplos processadores executam a mesma instrução sobre diferentes dados, com memória compartilhada acessível por todos os processadores.",
                        "specificSkills": [
                          {
                            "id": "64.1.1.2.1",
                            "name": "Caracterizar o modelo SIMD em memória compartilhada",
                            "description": "Descrever o controle único de instruções, sincronização implícita e máscaras de dados para desabilitar processadores inativos em operações SIMD.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos do Modelo SIMD em Memória Compartilhada",
                                  "subSteps": [
                                    "Revise a taxonomia de Flynn e identifique SIMD como Single Instruction Multiple Data.",
                                    "Explique como o SIMD opera em memória compartilhada com múltiplos processadores/ALUs executando a mesma instrução.",
                                    "Diferencie SIMD de SISD e MISD em termos de paralelismo de dados.",
                                    "Estude exemplos históricos como Cray vector processors.",
                                    "Anote as vantagens: eficiência em dados regulares e vetorizados."
                                  ],
                                  "verification": "Resuma em 3-5 frases os fundamentos do SIMD e compare com outros modelos de Flynn.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro: 'Introduction to Parallel Computing' de Grama et al.",
                                    "Artigo: Taxonomia de Flynn na Wikipedia.",
                                    "Vídeo: 'Flynn's Taxonomy Explained' no YouTube."
                                  ],
                                  "tips": "Use diagramas para visualizar lanes de processamento paralelas.",
                                  "learningObjective": "Dominar a definição e contexto histórico do SIMD em memória compartilhada.",
                                  "commonMistakes": "Confundir SIMD com MIMD; lembre-se que SIMD tem uma única instrução."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Controle Único de Instruções",
                                  "subSteps": [
                                    "Descreva o fluxo: uma única unidade de controle envia a mesma instrução para todos os processadores de dados.",
                                    "Analise pseudocódigo: for each vector element, execute same op.",
                                    "Compare com escalar: uma instrução SIMD processa N elementos de uma vez.",
                                    "Estude implementações modernas como SSE/AVX no x86.",
                                    "Registre como isso reduz overhead de controle."
                                  ],
                                  "verification": "Escreva um pseudocódigo simples de soma vetorial SIMD e explique o controle único.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação Intel: Intrinsics Guide (intrinsics-guide.com).",
                                    "Capítulo sobre vetorização em 'Computer Architecture: A Quantitative Approach' de Hennessy & Patterson."
                                  ],
                                  "tips": "Pense em SIMD como uma 'máquina de fotocópia' para instruções.",
                                  "learningObjective": "Explicar precisamente como o controle único habilita paralelismo SIMD.",
                                  "commonMistakes": "Achar que cada processador tem seu próprio PC; é único."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar a Sincronização Implícita no SIMD",
                                  "subSteps": [
                                    "Defina sincronização implícita: todas as lanes executam lockstep, sem barreiras explícitas.",
                                    "Discuta implicações: divergência não suportada, todos avançam juntos.",
                                    "Exemplo: em uma adição vetorial, todos elementos processados simultaneamente.",
                                    "Compare com sincronização explícita em OpenMP.",
                                    "Identifique limitações em fluxos condicionais."
                                  ],
                                  "verification": "Descreva um cenário onde sincronização implícita é vantajosa e crie um diagrama de timeline.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação NVIDIA CUDA: SIMD Warp Execution Model.",
                                    "Tutorial: 'SIMD Programming' no Agner Fog's guides."
                                  ],
                                  "tips": "Visualize como um pelotão marchando em sincronia.",
                                  "learningObjective": "Compreender como lockstep elimina necessidade de sincronização manual.",
                                  "commonMistakes": "Confundir com sincronização assíncrona; SIMD é rigidamente síncrono."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Descrever Máscaras de Dados para Desabilitação de Processadores Inativos",
                                  "subSteps": [
                                    "Explique máscaras: bits que ativam/desativam lanes individuais sem branching.",
                                    "Exemplo: em AVX-512, k-mask registers predizem operações.",
                                    "Pseudocódigo: if mask[i]==0, result[i] unchanged.",
                                    "Benefícios: evita penalidades de branch em loops irregulares.",
                                    "Integre com controle único: instrução executa, mas lanes masked ignoradas."
                                  ],
                                  "verification": "Implemente um exemplo simples de masked add em pseudocódigo e teste com dados irregulares.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Intel AVX-512 Programmer's Guide.",
                                    "Exemplos em C++ com _mm512_mask_add_ps intrinsics."
                                  ],
                                  "tips": "Máscaras são como 'interruptores' por lane, mantendo lockstep.",
                                  "learningObjective": "Dominar o uso de máscaras para lidar com dados irregulares em SIMD.",
                                  "commonMistakes": "Usar branches condicionais em vez de masks; causa serialização."
                                }
                              ],
                              "practicalExample": "Em processamento de imagem com AVX2: carregue vetor de pixels RGB (8 pixels), aplique filtro de brilho com máscara para ignorar pixels transparentes (alpha=0), usando controle único para a operação de multiplicação e soma implícita sincronizada.",
                              "finalVerifications": [
                                "Explique controle único de instruções com um diagrama.",
                                "Descreva sincronização implícita vs. explícita em 2 cenários.",
                                "Forneça pseudocódigo de operação masked SIMD.",
                                "Compare SIMD memória compartilhada com GPU SIMT.",
                                "Liste 3 vantagens e 2 limitações do modelo.",
                                "Resuma a caracterização completa em um parágrafo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição do controle único (20%)",
                                "Clareza na explicação de sincronização implícita (20%)",
                                "Correta representação de máscaras e desabilitação (25%)",
                                "Uso de exemplos/diagramas relevantes (15%)",
                                "Integração coerente dos elementos em caracterização (10%)",
                                "Identificação de limitações e comparações (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Estudo de pipelines vetoriais e unidades de execução.",
                                "Otimização de Software: Auto-vetorização em compiladores como GCC/LLVM.",
                                "Inteligência Artificial: Aceleração de tensores em deep learning (TensorFlow SIMD kernels).",
                                "Engenharia de Software: Paralelismo em bibliotecas como Eigen ou BLAS."
                              ],
                              "realWorldApplication": "Em supercomputadores como os da Cray para simulações climáticas, processando grids massivos de dados meteorológicos com operações vetoriais masked para regiões inválidas, ou em smartphones para edição de vídeo em tempo real usando NEON SIMD."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.2.2",
                            "name": "Exemplificar aplicações e linguagens SIMD",
                            "description": "Citar exemplos como vetores em GPUs ou Intel SSE/AVX, e discutir programação com pragmas OpenMP SIMD ou intrinsics.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de SIMD",
                                  "subSteps": [
                                    "Defina SIMD na taxonomia de Flynn e explique memória compartilhada.",
                                    "Compare SIMD com SISD e MISD, destacando paralelismo de dados.",
                                    "Liste vantagens: throughput alto para operações vetoriais idênticas.",
                                    "Identifique limitações: desvio de fluxo e alinhamento de dados.",
                                    "Revise exemplos históricos como Cray vector processors."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando SIMD e suas diferenças com outros modelos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação Intel sobre SIMD (https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/simd-programming.html)",
                                    "Artigo Wikipedia sobre Taxonomia de Flynn"
                                  ],
                                  "tips": "Use diagramas para visualizar lanes de processamento SIMD.",
                                  "learningObjective": "Entender os princípios básicos de SIMD para contextualizar aplicações.",
                                  "commonMistakes": "Confundir SIMD com MIMD; ignorar requisitos de memória compartilhada."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Aplicações Reais de SIMD",
                                  "subSteps": [
                                    "Descreva uso de SIMD em GPUs para processamento vetorial em shaders.",
                                    "Exemplifique em computação científica: multiplicação de matrizes vetoriais.",
                                    "Discuta aplicações em multimídia: processamento de áudio/vídeo (ex: codecs H.264).",
                                    "Cite casos em IA: aceleração de convoluções em redes neurais.",
                                    "Pesquise benchmarks reais como SPEC CPU com workloads SIMD."
                                  ],
                                  "verification": "Liste 5 aplicações específicas de SIMD com uma frase justificando cada uma.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "NVIDIA CUDA Programming Guide (seção sobre vector lanes)",
                                    "Papers sobre GPU SIMD em ACM Digital Library"
                                  ],
                                  "tips": "Associe aplicações a domínios: jogos (GPUs), simulações (vetores).",
                                  "learningObjective": "Reconhecer cenários onde SIMD é aplicado no mundo real.",
                                  "commonMistakes": "Generalizar demais sem exemplos concretos; ignorar overheads em cargas irregulares."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Extensões SIMD como SSE/AVX",
                                  "subSteps": [
                                    "Estude SSE (128-bit) vs AVX (256/512-bit) em processadores Intel/AMD.",
                                    "Liste instruções chave: _mm_add_ps para floats, _mm256_fmadd_ps para fused multiply-add.",
                                    "Compile e rode um programa simples usando intrinsics SSE.",
                                    "Compare performance com código escalar usando ferramentas como perf.",
                                    "Discuta auto-vetorização pelo compilador vs programação explícita."
                                  ],
                                  "verification": "Execute um benchmark comparando SSE/AVX com escalar e registre speedup.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "GCC/Clang com flags -msse4 -mavx2",
                                    "Intel Intrinsics Guide (https://software.intel.com/sites/landingpage/IntrinsicsGuide/)"
                                  ],
                                  "tips": "Sempre alinhe dados a 32/64 bytes para AVX.",
                                  "learningObjective": "Dominar instruções SIMD específicas de hardware.",
                                  "commonMistakes": "Usar intrinsics sem verificar suporte CPU; esquecer de incluir <immintrin.h>."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar Programação com OpenMP SIMD e Intrinsics",
                                  "subSteps": [
                                    "Implemente pragma #pragma omp simd em loop for simples.",
                                    "Converta código para intrinsics AVX e compare.",
                                    "Otimize com máscaras para handling de tamanhos não múltiplos.",
                                    "Teste em workloads reais como soma de vetores ou filtro de imagem.",
                                    "Analise assembly gerado com objdump para validar vetorização."
                                  ],
                                  "verification": "Desenvolva e execute um programa que demonstre speedup >2x com SIMD.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Compilador GCC com OpenMP (-fopenmp -march=native)",
                                    "Exemplos OpenMP SIMD da documentação oficial (openmp.org)"
                                  ],
                                  "tips": "Combine pragmas com #pragma omp declare simd para funções.",
                                  "learningObjective": "Aplicar linguagens SIMD em código prático.",
                                  "commonMistakes": "Ignorar dependências de dados em loops; não testar em hardware compatível."
                                }
                              ],
                              "practicalExample": "Implemente um filtro de imagem simples (ex: grayscale) usando AVX intrinsics: carregue pixels em registradores 256-bit, aplique transformações simultâneas em 8 pixels RGBA, armazene resultados. Código exemplo: usar _mm256_loadu_ps para input, operações aritméticas vetoriais, _mm256_storeu_ps para output, medindo speedup de 4-8x em imagens 1080p.",
                              "finalVerifications": [
                                "Pode citar pelo menos 3 aplicações reais de SIMD (GPUs, multimídia, IA).",
                                "Explica diferenças entre SSE/AVX e pragmas OpenMP SIMD.",
                                "Executa código com intrinsics sem erros de compilação/runtime.",
                                "Demonstra speedup mensurável em benchmark simples.",
                                "Descreve limitações como alinhamento e masks corretamente.",
                                "Gera assembly vetorizado via objdump."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições e comparações corretas (30%).",
                                "Exemplos relevantes: aplicações e códigos práticos (25%).",
                                "Profundidade técnica: uso correto de intrinsics/pragmas (20%).",
                                "Análise de performance: benchmarks e limitações (15%).",
                                "Clareza na explicação: estrutura lógica e diagramas (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: estudo de registradores vetoriais e pipelines.",
                                "Inteligência Artificial: aceleração de tensores em ML frameworks como TensorFlow.",
                                "Processamento de Sinais: filtros FIR/IIR vetorizados em DSP.",
                                "Gráficos Computacionais: shaders SIMD em OpenGL/Vulkan."
                              ],
                              "realWorldApplication": "Em jogos e renderização 3D, GPUs usam SIMD para processar vértices/pixels em paralelo, acelerando ray tracing em engines como Unreal; em supercomputação, acelera simulações climáticas processando grids vetoriais, reduzindo tempo de horas para minutos em clusters como Frontier."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.2.3",
                            "name": "Analisar limitações do SIMD em memória compartilhada",
                            "description": "Explicar problemas como divergência de fluxo de controle e dependências de dados em loops irregulares, com estratégias de mitigação.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Fundamentos de SIMD em Memória Compartilhada",
                                  "subSteps": [
                                    "Estude a taxonomia de Flynn e defina SIMD como Single Instruction Multiple Data.",
                                    "Explique como SIMD opera em arquiteturas de memória compartilhada, como GPUs com warps ou SIMT.",
                                    "Identifique unidades de execução SIMD, como warps de 32 threads em CUDA.",
                                    "Revise conceitos de sincronização e acesso compartilhado em memória.",
                                    "Compare SIMD com SISD e MIMD para contextualizar limitações."
                                  ],
                                  "verification": "Resuma em 3-5 frases os princípios de SIMD em memória compartilhada e liste 2 diferenças chave com outros modelos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação CUDA/OpenCL",
                                    "Livro 'Programming Massively Parallel Processors' (Kirk e Hwu)",
                                    "Vídeos introdutórios sobre taxonomia de Flynn"
                                  ],
                                  "tips": "Use diagramas para visualizar warps e lanes para melhor retenção visual.",
                                  "learningObjective": "Dominar os conceitos básicos de SIMD para identificar limitações subsequentes.",
                                  "commonMistakes": "Confundir SIMD com threads independentes; ignorar o modelo SIMT em GPUs modernas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Divergência de Fluxo de Controle",
                                  "subSteps": [
                                    "Defina divergência: quando threads em um warp tomam caminhos condicionais diferentes.",
                                    "Simule um exemplo de if-else em um kernel SIMD com dados irregulares.",
                                    "Meça o impacto: execução serializada de branches, reduzindo throughput.",
                                    "Use ferramentas como Nsight para visualizar divergência em código real.",
                                    "Discuta predicação como alternativa em alguns arquiteturas."
                                  ],
                                  "verification": "Escreva um kernel CUDA simples com if divergente e explique por que ele é ineficiente.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "CUDA Toolkit",
                                    "Nsight Compute/Systems",
                                    "Exemplos de código de divergência online (NVIDIA docs)"
                                  ],
                                  "tips": "Teste com dados uniformes vs. irregulares para observar diferenças de performance.",
                                  "learningObjective": "Reconhecer e quantificar o custo de divergência em desempenho SIMD.",
                                  "commonMistakes": "Assumir que branches são executados em paralelo; subestimar impacto em warps inteiros."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Investigar Dependências de Dados em Loops Irregulares",
                                  "subSteps": [
                                    "Explique dependências: raw/waw/war entre iterações ou threads em loops com bounds variáveis.",
                                    "Analise loops onde número de iterações varia por thread (e.g., processamento de listas ligadas).",
                                    "Discuta problemas de coalescência de memória e banco de registradores exaurido.",
                                    "Meça stalls devido a dependências usando perf counters.",
                                    "Compare com loops regulares para isolar o problema."
                                  ],
                                  "verification": "Identifique dependências em um loop fornecido e proponha uma métrica de impacto (e.g., occupancy reduction).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Compilador NVCC com --ptxas-options=-v",
                                    "Documentação sobre PTX e SASS",
                                    "Exemplos de loops irregulares em repositórios GitHub"
                                  ],
                                  "tips": "Use printf em kernels para debugar bounds de loops por thread.",
                                  "learningObjective": "Diagnosticar como dependências irregulares degradam eficiência SIMD.",
                                  "commonMistakes": "Ignorar dependências intra-warp; confundir com problemas de memória global."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Desenvolver Estratégias de Mitigação",
                                  "subSteps": [
                                    "Liste técnicas: reordenação de dados para uniformidade, loop peeling, unrolling condicional.",
                                    "Implemente mitigação para divergência: usar __syncthreads() ou predicação.",
                                    "Para dependências: tiling, prefetching, ou migração para MIMD híbrido.",
                                    "Avalie trade-offs: overhead vs. ganho de performance.",
                                    "Teste e compare kernels antes/depois em benchmarks."
                                  ],
                                  "verification": "Modifique um kernel problemático, execute benchmark e demonstre melhoria >20% em tempo de execução.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Ambiente CUDA completo",
                                    "Benchmark tools como nvprof",
                                    "Papers sobre otimização SIMD (e.g., NVIDIA GTC talks)"
                                  ],
                                  "tips": "Comece com dados sintéticos controlados para isolar variáveis.",
                                  "learningObjective": "Aplicar soluções práticas para superar limitações SIMD identificadas.",
                                  "commonMistakes": "Aplicar soluções genéricas sem medir impacto específico; ignorar custo de sincronização."
                                }
                              ],
                              "practicalExample": "Em um kernel CUDA para redução de soma em array irregular: threads processam sub-arrays de tamanhos variados, causando divergência no loop while(i < len). Mitigação: pad arrays para comprimentos uniformes e usar atomicAdd para dependências.",
                              "finalVerifications": [
                                "Explique divergência e dependências em termos próprios sem consultar notas.",
                                "Identifique limitações em um kernel SIMD fornecido em <5 minutos.",
                                "Proponha 2-3 mitigações viáveis com justificativa de performance.",
                                "Execute um benchmark comparativo mostrando impacto quantitativo.",
                                "Discuta quando SIMD não é adequado e sugerir alternativas.",
                                "Desenhe um diagrama de warp divergente vs. uniforme."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas de SIMD, divergência e dependências (30%).",
                                "Análise quantitativa: uso de métricas como occupancy e stalls (25%).",
                                "Soluções práticas: implementações funcionais e otimizadas (20%).",
                                "Compreensão de trade-offs: discussão equilibrada de custos/benefícios (15%).",
                                "Clareza de comunicação: explicações concisas e diagramas (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: estudo de pipelines e execução out-of-order.",
                                "Matemática Computacional: vetores e operações matriciais em álgebra linear.",
                                "Otimização de Algoritmos: análise de complexidade em paralelo.",
                                "Engenharia de Software: profiling e debugging de performance."
                              ],
                              "realWorldApplication": "Em processamento de imagens com OpenCV/CUDA (e.g., filtros em pixels irregulares), simulações científicas em GPUs (e.g., N-body com partículas variáveis), ou ML inference onde batches têm sequências de comprimentos variados, mitigando para throughput máximo em data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "64.1.1.3",
                        "name": "Modelo MIMD para Memória Compartilhada",
                        "description": "Arquiteturas com múltiplas instruções independentes executadas em múltiplos dados, utilizando memória compartilhada com mecanismos de sincronização.",
                        "specificSkills": [
                          {
                            "id": "64.1.1.3.1",
                            "name": "Descrever características do MIMD em memória compartilhada",
                            "description": "Explicar a independência de fluxos de instruções, necessidade de sincronização (barreiras, locks) e modelos como UMA/NUMA para acesso à memória.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Fundamentos do Modelo MIMD e Memória Compartilhada",
                                  "subSteps": [
                                    "Revise a Taxonomia de Flynn e identifique MIMD como Multiple Instruction Multiple Data.",
                                    "Defina memória compartilhada: todos os processadores acessam o mesmo espaço de endereço.",
                                    "Compare brevemente com memória distribuída para contextualizar diferenças.",
                                    "Liste as principais características gerais do MIMD em memória compartilhada.",
                                    "Anote exemplos de arquiteturas que usam esse modelo."
                                  ],
                                  "verification": "Crie um diagrama simples mostrando múltiplos processadores acessando memória compartilhada.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre Taxonomia de Flynn",
                                    "Diagrama em branco ou ferramenta como Draw.io"
                                  ],
                                  "tips": "Use analogias como uma cozinha compartilhada onde chefs (processadores) usam ingredientes comuns (memória).",
                                  "learningObjective": "Compreender a definição e contexto básico do MIMD em memória compartilhada.",
                                  "commonMistakes": [
                                    "Confundir MIMD com SIMD",
                                    "Ignorar que MIMD permite instruções independentes por processador"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explicar a Independência dos Fluxos de Instruções",
                                  "subSteps": [
                                    "Descreva como cada processador executa seu próprio fluxo de instruções independentes.",
                                    "Explique que dados podem ser processados de forma assíncrona por diferentes processadores.",
                                    "Ilustre com um exemplo de dois processadores processando tarefas diferentes no mesmo dataset.",
                                    "Discuta vantagens: flexibilidade para workloads heterogêneos.",
                                    "Diferencie de modelos síncronos como SIMD."
                                  ],
                                  "verification": "Escreva uma descrição em 3-5 frases sobre independência de fluxos e valide com um colega.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Exemplos de código pseudocódigo MIMD",
                                    "Vídeo curto sobre Flynn's Taxonomy (YouTube)"
                                  ],
                                  "tips": "Pense em threads em uma aplicação multithreaded rodando funções diferentes.",
                                  "learningObjective": "Dominar o conceito de independência de instruções em MIMD.",
                                  "commonMistakes": [
                                    "Assumir sincronia obrigatória",
                                    "Confundir independência de instruções com independência de dados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar a Necessidade de Sincronização",
                                  "subSteps": [
                                    "Identifique problemas como race conditions e inconsistências de dados sem sincronização.",
                                    "Explique mecanismos: locks (mutex) para seções críticas.",
                                    "Descreva barreiras para sincronizar todos os processadores em pontos específicos.",
                                    "Compare locks vs. barreiras: granularidade e overhead.",
                                    "Estude semáforos e condition variables como extensões."
                                  ],
                                  "verification": "Simule um cenário de race condition e resolva com pseudocódigo de lock.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação OpenMP ou Pthreads",
                                    "Editor de código para pseudocódigo"
                                  ],
                                  "tips": "Visualize locks como portas trancadas que só um usa por vez.",
                                  "learningObjective": "Entender por que e como sincronizar em MIMD compartilhado.",
                                  "commonMistakes": [
                                    "Subestimar overhead de sincronização",
                                    "Usar sincronização desnecessária em tarefas independentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Descrever Modelos de Acesso à Memória: UMA e NUMA",
                                  "subSteps": [
                                    "Defina UMA (Uniform Memory Access): tempo de acesso uniforme para todos processadores.",
                                    "Explique NUMA (Non-Uniform Memory Access): memória local mais rápida que remota.",
                                    "Discuta impactos em performance: localidade em NUMA.",
                                    "Liste exemplos: UMA em multiprocessadores simétricos, NUMA em clusters de nós.",
                                    "Compare prós e contras de cada modelo."
                                  ],
                                  "verification": "Crie uma tabela comparativa UMA vs. NUMA com tempos de acesso e exemplos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Artigos sobre arquiteturas UMA/NUMA",
                                    "Planilha ou tabela em Markdown"
                                  ],
                                  "tips": "Em NUMA, priorize dados locais para otimizar performance.",
                                  "learningObjective": "Diferenciar e explicar modelos UMA/NUMA no contexto MIMD.",
                                  "commonMistakes": [
                                    "Confundir UMA com total uniformidade em sistemas reais",
                                    "Ignorar NUMA em arquiteturas modernas"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa OpenMP para processamento de imagem, um processador aplica filtro de nitidez (instruções independentes) enquanto outro aplica suavização na mesma memória compartilhada. Use #pragma omp parallel para criar threads MIMD, locks para atualizar pixels compartilhados e barreiras para sincronizar iterações.",
                              "finalVerifications": [
                                "Defina corretamente MIMD e memória compartilhada sem erros.",
                                "Explique independência de fluxos com um exemplo válido.",
                                "Liste e descreva pelo menos dois mecanismos de sincronização.",
                                "Diferencie UMA de NUMA com impactos em performance.",
                                "Desenhe um diagrama completo das características.",
                                "Responda a perguntas hipotéticas sobre cenários reais."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas e sem confusões com outros modelos.",
                                "Completude: cobre independência, sincronização e UMA/NUMA.",
                                "Clareza na explicação: usa linguagem acessível e exemplos.",
                                "Profundidade: discute prós, contras e mecanismos específicos.",
                                "Aplicação prática: relaciona a cenários reais como OpenMP.",
                                "Estrutura lógica: apresentação organizada e sequencial."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: gerenciamento de threads e scheduling em multiprocessadores.",
                                "Arquitetura de Computadores: cache coherence e protocolos de consistência.",
                                "Algoritmos e Estruturas de Dados: design de algoritmos paralelos eficientes.",
                                "Redes de Computadores: extensão para clusters NUMA em computação distribuída."
                              ],
                              "realWorldApplication": "Em supercomputadores como os usados pela NASA para simulações climáticas, MIMD com memória compartilhada (NUMA) permite que núcleos processem dados independentes com sincronização para resultados precisos, otimizando simulações em tempo real."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.3.2",
                            "name": "Implementar mecanismos de exclusão mútua em MIMD",
                            "description": "Discutir primitivas como mutex, semáforos e seções críticas em linguagens como OpenMP ou Pthreads para evitar condições de corrida em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Fundamentos de Exclusão Mútua e Condições de Corrida",
                                  "subSteps": [
                                    "Estude o conceito de exclusão mútua (mutual exclusion) e por que é necessário em programação paralela MIMD com memória compartilhada.",
                                    "Analise exemplos de condições de corrida (race conditions) em cenários de múltiplas threads acessando variáveis compartilhadas.",
                                    "Identifique seções críticas (critical sections) em código paralelo como regiões onde a exclusão mútua é aplicada.",
                                    "Compare soluções busy-waiting vs bloqueantes para sincronização.",
                                    "Revise a taxonomia de Flynn e o foco em MIMD para memória compartilhada."
                                  ],
                                  "verification": "Resuma em um diagrama ou parágrafo os conceitos chave e identifique uma race condition em um exemplo simples de código.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação POSIX Threads (Pthreads)",
                                    "Livro 'Programming with POSIX Threads' ou tutoriais online sobre race conditions",
                                    "Compilador GCC com suporte a threads"
                                  ],
                                  "tips": "Use diagramas de sequência (sequence diagrams) para visualizar interações entre threads.",
                                  "learningObjective": "Compreender os problemas fundamentais que mecanismos de exclusão mútua resolvem em MIMD.",
                                  "commonMistakes": [
                                    "Confundir race conditions com deadlocks",
                                    "Ignorar overhead de sincronização em desempenho"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Mutex em Pthreads",
                                  "subSteps": [
                                    "Instale e configure ambiente para Pthreads (gcc -pthread).",
                                    "Crie um programa simples com múltiplas threads incrementando um contador compartilhado sem proteção para observar race conditions.",
                                    "Introduza pthread_mutex_t e inicialize com pthread_mutex_init().",
                                    "Proteja a seção crítica com pthread_mutex_lock() e pthread_mutex_unlock().",
                                    "Compile e execute múltiplas vezes para verificar consistência."
                                  ],
                                  "verification": "O contador final deve ser sempre o valor esperado (ex: 100000 para 10 threads x 10000 incrementos) em 100 execuções.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Biblioteca Pthreads",
                                    "Editor de código (VS Code ou Vim)",
                                    "Ferramenta de profiling como Valgrind para detectar races"
                                  ],
                                  "tips": "Sempre destrua o mutex com pthread_mutex_destroy() para evitar leaks.",
                                  "learningObjective": "Implementar mutex para sincronizar acesso a recursos compartilhados em Pthreads.",
                                  "commonMistakes": [
                                    "Esquecer de unlock() causando deadlock",
                                    "Inicializar mutex estático incorretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Usar Semáforos e Seções Críticas em Pthreads",
                                  "subSteps": [
                                    "Estude semáforos POSIX (sem_t) como generalização de mutex.",
                                    "Implemente um semáforo binário para simular mutex em um produtor-consumidor.",
                                    "Configure seções críticas com pthread_mutexattr_settype() para tipos como recursive mutex.",
                                    "Combine mutex com condition variables (pthread_cond_t) para sincronização avançada.",
                                    "Teste cenários com múltiplos recursos compartilhados."
                                  ],
                                  "verification": "Execute programa com semáforo controlando acesso limitado (ex: buffer de tamanho 5) sem overflows/underflows.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Man pages: man sem_open, man pthread_cond",
                                    "Exemplos de código de repositórios GitHub sobre Pthreads"
                                  ],
                                  "tips": "Use semáforos para controle de contagem, mutex apenas para exclusão mútua.",
                                  "learningObjective": "Aplicar semáforos e seções críticas para cenários complexos de sincronização.",
                                  "commonMistakes": [
                                    "Chamar sem_wait() sem verificar erros",
                                    "Deadlock por ordem errada de locks"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar em OpenMP",
                                  "subSteps": [
                                    "Configure compilador com suporte OpenMP (gcc -fopenmp).",
                                    "Paralelize um loop com #pragma omp parallel for e introduza race condition em redução.",
                                    "Use #pragma omp critical para seções críticas simples.",
                                    "Implemente atomic directives (#pragma omp atomic) para operações atômicas.",
                                    "Compare desempenho mutex OpenMP vs Pthreads em benchmarks."
                                  ],
                                  "verification": "Resultado da redução paralela deve coincidir com versão sequencial em múltiplas runs.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "OpenMP 5.0 specification",
                                    "Intel oneAPI ou LLVM com OpenMP",
                                    "Código base de loops paralelos"
                                  ],
                                  "tips": "Prefira atomic para operações simples; critical para blocos maiores.",
                                  "learningObjective": "Adaptar mecanismos de exclusão mútua para diretivas OpenMP em MIMD.",
                                  "commonMistakes": [
                                    "Aninhar critical sections sem nomeação",
                                    "Ignorar escalabilidade com muitas threads"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar, Depurar e Otimizar",
                                  "subSteps": [
                                    "Use ThreadSanitizer (TSan) ou Helgrind para detectar races.",
                                    "Profile com gprof ou perf para medir overhead de sincronização.",
                                    "Otimize com reader-writer locks (pthread_rwlock) para cenários de leitura majoritária.",
                                    "Implemente fairness em semáforos com prioridades.",
                                    "Documente o código com comentários sobre escolhas de sincronização."
                                  ],
                                  "verification": "Nenhuma race condition reportada por TSan em execuções estressadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Valgrind/Helgrind",
                                    "ThreadSanitizer flags: -fsanitize=thread",
                                    "Ferramentas de profiling"
                                  ],
                                  "tips": "Teste com cargas variáveis (2 a 64 threads) para robustez.",
                                  "learningObjective": "Garantir correção e eficiência em implementações paralelas.",
                                  "commonMistakes": [
                                    "Confiar apenas em testes manuais",
                                    "Omitir limpeza de recursos"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa em C com Pthreads onde 10 threads incrementam um contador compartilhado 10.000 vezes cada. Sem mutex, o resultado varia (race condition). Com mutex na seção crítica, sempre resulta em 100.000. Versão OpenMP: #pragma omp parallel for reduction(+:counter) ou com critical.",
                              "finalVerifications": [
                                "Programa Pthreads com mutex/semáforo executa sem races em 100 runs.",
                                "Versão OpenMP com critical/atomic produz resultados consistentes.",
                                "Nenhum deadlock ou starvation observado em logs.",
                                "Overhead de sincronização < 20% comparado à versão sem proteção.",
                                "Código limpo com destruição adequada de primitivas.",
                                "Relatório de testes com evidências de ferramentas como TSan."
                              ],
                              "assessmentCriteria": [
                                "Correção: Ausência de race conditions comprovada.",
                                "Eficiência: Tempo de execução escalável com #threads.",
                                "Robustez: Lida com erros (ex: EINVAL em init).",
                                "Clareza: Código comentado explicando seções críticas.",
                                "Abrangência: Implementa mutex, semáforo e OpenMP.",
                                "Documentação: Explica escolhas e trade-offs."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Primitivas de sincronização kernel-level.",
                                "Algoritmos e Estruturas: Producer-consumer com buffers.",
                                "Segurança da Informação: Evitar TOCTOU em acessos concorrentes.",
                                "Engenharia de Software: Design thread-safe.",
                                "Desempenho e Otimização: Análise de Amdahl em paralelismo."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded (ex: Nginx com worker threads), bancos de dados (MySQL InnoDB locks), ou aplicações HPC como simulações científicas onde threads atualizam grids compartilhados sem corrupção de dados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.3.3",
                            "name": "Avaliar desempenho em programas MIMD compartilhados",
                            "description": "Aplicar métricas como speedup de Amdahl/Gustafson, eficiência e overhead de sincronização, com referência a estudos de caso de Grama et al.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as Métricas Fundamentais de Desempenho",
                                  "subSteps": [
                                    "Estude a lei de Amdahl: fórmula S(p) = 1 / ((1 - f) + f/p), onde f é a fração paralelizável e p é o número de processadores.",
                                    "Analise a lei de Gustafson: S(p) = p + (1 - p)f, adaptada para escalabilidade forte vs. fraca.",
                                    "Defina eficiência: E(p) = S(p)/p.",
                                    "Identifique overhead de sincronização: tempo gasto em barreiras, locks e atomic operations em memória compartilhada.",
                                    "Revise conceitos de MIMD compartilhado na taxonomia de Flynn."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as diferenças entre Amdahl e Gustafson com exemplos numéricos simples.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Introduction to Parallel Computing' de Grama et al. (capítulos relevantes)",
                                    "Notas de aula sobre taxonomia de Flynn",
                                    "Calculadora ou planilha Excel para fórmulas"
                                  ],
                                  "tips": "Comece com exemplos pequenos (p=2,4) para visualizar o impacto do overhead.",
                                  "learningObjective": "Dominar as fórmulas e conceitos teóricos das métricas de speedup, eficiência e overhead.",
                                  "commonMistakes": [
                                    "Confundir escalabilidade forte (Amdahl) com fraca (Gustafson)",
                                    "Ignorar overhead em cálculos iniciais"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Speedup e Eficiência em Programas MIMD",
                                  "subSteps": [
                                    "Colete dados de execução serial e paralela de um programa MIMD simples (ex: soma de vetores com OpenMP).",
                                    "Aplique a lei de Amdahl para estimar speedup teórico.",
                                    "Calcule speedup real: tempo_serial / tempo_paralelo.",
                                    "Compute eficiência e isole overhead de sincronização subtraindo tempo útil.",
                                    "Compare resultados teóricos vs. reais em uma tabela."
                                  ],
                                  "verification": "Produza uma tabela com cálculos para p=1 a 8 processadores, mostrando speedup e eficiência.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador com suporte OpenMP (GCC)",
                                    "Código fonte exemplo de vetor soma MIMD",
                                    "Ferramentas de profiling como gprof ou Intel VTune"
                                  ],
                                  "tips": "Use wall-clock time para medições reais e rode múltiplas vezes para média.",
                                  "learningObjective": "Aplicar métricas quantitativamente em cenários MIMD compartilhados.",
                                  "commonMistakes": [
                                    "Usar CPU time em vez de wall-clock",
                                    "Não considerar variações de hardware"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Overhead de Sincronização",
                                  "subSteps": [
                                    "Instrumente um programa MIMD com contadores de locks/barreiras (ex: usando OpenMP pragmas).",
                                    "Meça tempo em seções críticas e compute overhead como % do tempo total.",
                                    "Simule cenários com alto/low contention (ex: matriz transposta vs. normal).",
                                    "Aplique fórmulas ajustadas: overhead = tempo_sync / tempo_total.",
                                    "Otimize removendo sincronizações desnecessárias e reavalie."
                                  ],
                                  "verification": "Gere um relatório com gráficos de overhead vs. número de threads.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Código MIMD exemplo (matrix multiply)",
                                    "Profiler como OMP Profiler ou TAU",
                                    "Gráficos com Python/Matplotlib"
                                  ],
                                  "tips": "Aumente threads gradualmente para observar escalabilidade.",
                                  "learningObjective": "Quantificar e mitigar overheads específicos de memória compartilhada MIMD.",
                                  "commonMistakes": [
                                    "Subestimar contention em acessos não-uniformes",
                                    "Não isolar overhead de comunicação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a Estudos de Caso de Grama et al.",
                                  "subSteps": [
                                    "Leia capítulos de Grama et al. sobre benchmarks MIMD (ex: FFT, LU decomposition).",
                                    "Reproduza análises de speedup e eficiência dos casos estudados.",
                                    "Compare com seus cálculos: discuta discrepâncias devido a overheads reais.",
                                    "Escreva uma análise crítica incorporando Amdahl/Gustafson.",
                                    "Proponha melhorias baseadas nos estudos."
                                  ],
                                  "verification": "Submeta um relatório de 1-2 páginas resumindo os casos com suas métricas calculadas.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "PDF do livro de Grama et al.",
                                    "Dados de benchmarks online (NAS Parallel Benchmarks)",
                                    "Ferramentas de documentação (LaTeX ou Word)"
                                  ],
                                  "tips": "Foque em 2-3 casos para profundidade, não amplitude.",
                                  "learningObjective": "Conectar teoria a evidências empíricas de literatura.",
                                  "commonMistakes": [
                                    "Copiar resultados sem recalcular",
                                    "Ignorar contexto histórico dos estudos"
                                  ]
                                }
                              ],
                              "practicalExample": "Avalie o desempenho de um programa MIMD de multiplicação de matrizes em memória compartilhada usando OpenMP: meça speedup com 1-16 threads, calcule eficiência via Amdahl (f=0.8), isole overhead de locks em acessos de linha/coluna, e compare com benchmarks de Grama et al. para LU decomposition.",
                              "finalVerifications": [
                                "Calcule corretamente speedup Amdahl/Gustafson para um caso dado com erro <5%.",
                                "Identifique e quantifique overhead de sincronização em um trace de execução.",
                                "Explique diferenças entre speedup real e teórico em um programa MIMD.",
                                "Relacione métricas a um estudo de caso de Grama et al.",
                                "Otimize um código reduzindo overhead em pelo menos 20%.",
                                "Gere gráficos de escalabilidade precisos."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de métricas (Amdahl, Gustafson, eficiência: 30%)",
                                "Análise qualitativa e quantitativa de overheads (25%)",
                                "Integração com literatura de Grama et al. (20%)",
                                "Clareza em relatórios e visualizações (15%)",
                                "Criatividade em otimizações propostas (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelagem linear e otimização numérica.",
                                "Engenharia de Software: Profiling e debugging de código paralelo.",
                                "Ciência da Computação Geral: Algoritmos paralelos e complexidade.",
                                "Física Computacional: Simulações HPC em MIMD.",
                                "Gestão de Projetos: Análise de custo-benefício em paralelismo."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, engenheiros HPC usam essas métricas para otimizar aplicações como modelagem climática ou genômica, garantindo eficiência em clusters MIMD compartilhados (ex: OpenMP em Intel Xeon), reduzindo tempo de simulação de dias para horas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.3.4",
                            "name": "Comparar MIMD compartilhado com distribuído",
                            "description": "Contrapor memória compartilhada (fácil programação, overhead de cache) vs. distribuída (troca de mensagens, decomposição de domínio), citando Pacheco e Van der Pas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender MIMD com Memória Compartilhada",
                                  "subSteps": [
                                    "Revise a Taxonomia de Flynn e confirme que MIMD permite instruções e dados independentes por processador.",
                                    "Descreva como todos os processadores acessam uma memória global única.",
                                    "Identifique vantagens: programação mais simples com sincronizações como barreiras e locks.",
                                    "Explique overheads: coerência de cache (protocolos como MESI) e contenção de memória.",
                                    "Liste exemplos de APIs: OpenMP ou Pthreads."
                                  ],
                                  "verification": "Crie um diagrama simples mostrando processadores acessando memória compartilhada e anote overheads.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Livro 'An Introduction to Parallel Programming' de Peter Pacheco (capítulos iniciais)",
                                    "Notas de aula sobre Taxonomia de Flynn",
                                    "Diagrama em papel ou ferramenta como Draw.io"
                                  ],
                                  "tips": [
                                    "Comece com um diagrama para visualizar melhor.",
                                    "Foquem em como a abstração de memória única facilita o código."
                                  ],
                                  "learningObjective": "Compreender as características fundamentais e trade-offs do modelo MIMD compartilhado.",
                                  "commonMistakes": [
                                    "Confundir com SIMD (dados síncronos).",
                                    "Ignorar problemas de escalabilidade devido a contenção."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender MIMD com Memória Distribuída",
                                  "subSteps": [
                                    "Descreva a arquitetura: cada processador tem sua própria memória local, sem acesso direto à dos outros.",
                                    "Explique comunicação via troca de mensagens (send/receive).",
                                    "Discuta decomposição de domínio: dividir dados e trabalho explicitamente entre processadores.",
                                    "Identifique APIs comuns: MPI (Message Passing Interface).",
                                    "Liste desafios: programação mais complexa, mas melhor escalabilidade em grandes clusters."
                                  ],
                                  "verification": "Esboce um diagrama de rede de processadores com setas indicando mensagens e anote decomposição de domínio.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação MPI básica",
                                    "Livro de Pacheco (capítulos sobre MPI)",
                                    "Ferramenta de desenho"
                                  ],
                                  "tips": [
                                    "Pense em clusters reais como nós conectados por rede.",
                                    "Compare com envio de cartas entre casas."
                                  ],
                                  "learningObjective": "Dominar os princípios de comunicação e decomposição no modelo MIMD distribuído.",
                                  "commonMistakes": [
                                    "Assumir acesso direto à memória remota.",
                                    "Subestimar latência de rede na troca de mensagens."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar os Dois Modelos MIMD",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: memória (compartilhada vs. local), programação (abstrações vs. mensagens), overhead (cache vs. rede).",
                                    "Analise prós/contras: compartilhado (fácil, mas não escala bem) vs. distribuído (escala, mas complexo).",
                                    "Discuta cenários: compartilhado para poucos núcleos (multicore), distribuído para muitos nós (clusters).",
                                    "Avalie portabilidade e performance em diferentes escalas.",
                                    "Resuma diferenças chave em um parágrafo conciso."
                                  ],
                                  "verification": "Preencha e revise a tabela comparativa, garantindo pelo menos 5 diferenças listadas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha ou papel para tabela",
                                    "Notas dos steps 1 e 2",
                                    "Referências Pacheco"
                                  ],
                                  "tips": [
                                    "Use categorias como 'Facilidade de Programação', 'Escalabilidade', 'Overhead'.",
                                    "Quantifique quando possível (ex: cache miss vs. mensagem latência)."
                                  ],
                                  "learningObjective": "Capacitar a contraposição clara entre os modelos, destacando trade-offs.",
                                  "commonMistakes": [
                                    "Focar só em vantagens sem contras.",
                                    "Generalizar sem considerar escala."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Incorporar Citações e Exemplos de Referências",
                                  "subSteps": [
                                    "Localize e leia trechos de Pacheco sobre modelos Flynn e MPI vs. threads.",
                                    "Pesquise visões de Van der Pas sobre overheads em memória compartilhada (ex: em OpenMP).",
                                    "Integre citações na comparação: Pacheco enfatiza decomposição em distribuído; Van der Pas discute cache em compartilhado.",
                                    "Aplique a um exemplo simples: multiplicação de matrizes em OpenMP vs. MPI.",
                                    "Escreva um resumo final citando autores."
                                  ],
                                  "verification": "Redija um parágrafo comparativo com pelo menos duas citações diretas ou parafraseadas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "PDF ou trechos de Pacheco e artigos de Ruud van der Pas",
                                    "Exemplo código OpenMP/MPI online"
                                  ],
                                  "tips": [
                                    "Use aspas para citações exatas.",
                                    "Ligue citações diretamente às diferenças."
                                  ],
                                  "learningObjective": "Fundamentar a comparação com fontes autorizadas para rigor acadêmico.",
                                  "commonMistakes": [
                                    "Citar sem contexto relevante.",
                                    "Confundir autores ou edições."
                                  ]
                                }
                              ],
                              "practicalExample": "Considere multiplicação de matrizes NxN: No MIMD compartilhado (OpenMP), declare matriz global e use #pragma parallel for com critical para atualizações; overhead de cache coherence surge em acessos concorrentes. No distribuído (MPI), decompõe linhas/colunas com MPI_Scatter/MPI_Gather e MPI_Sendrecv para bordas; requer gerenciamento explícito de dados locais, mas escala para milhares de nós sem contenção global.",
                              "finalVerifications": [
                                "Pode listar e explicar 4 diferenças principais entre os modelos?",
                                "Consegue criar uma tabela comparativa precisa?",
                                "Identifica cenários ideais para cada modelo?",
                                "Integra corretamente citações de Pacheco e Van der Pas?",
                                "Explica trade-offs de programação e performance?"
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas de memória e comunicação).",
                                "Completude da comparação (prós/contras equilibrados).",
                                "Uso apropriado de referências (citações contextualizadas).",
                                "Clareza na explicação de overheads e escalabilidade.",
                                "Aplicação em exemplos práticos.",
                                "Profundidade nos trade-offs (não superficial)."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores (coerência de cache e topologias de rede).",
                                "Redes de Computadores (latência e protocolos de mensagem como em MPI).",
                                "Sistemas Operacionais (gerenciamento de memória e threads/processos).",
                                "Algoritmos e Estruturas de Dados (decomposição de domínio e particionamento)."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, escolha MIMD compartilhado (OpenMP) para tarefas em multicore de um nó (ex: simulações CFD locais) vs. distribuído (MPI híbrido) para clusters distribuídos (ex: modelagem climática global), otimizando performance em petascale computing."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.2",
                    "name": "Modelos de Memória Compartilhada",
                    "description": "Características e classificações de modelos de memória em sistemas paralelos compartilhados.",
                    "individualConcepts": [
                      {
                        "id": "10.1.3.2.1",
                        "name": "Taxonomia de Flynn",
                        "description": "Classificação fundamental de arquiteturas paralelas, com ênfase em modelos de memória compartilhada como SIMD e MIMD.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.2.1.1",
                            "name": "Identificar as categorias da Taxonomia de Flynn",
                            "description": "Diferenciar entre SISD, SIMD, MISD e MIMD, relacionando com sistemas de memória compartilhada em programação paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Pesquise a definição da Taxonomia de Flynn proposta por Michael J. Flynn em 1966.",
                                    "Identifique os dois eixos principais: fluxo de instruções (único ou múltiplo) e fluxo de dados (único ou múltiplo).",
                                    "Visualize um diagrama da classificação em 4 categorias: SISD, SIMD, MISD e MIMD.",
                                    "Anote as características gerais de arquiteturas paralelas versus sequenciais."
                                  ],
                                  "verification": "Crie um diagrama simples reproduzindo a taxonomia e explique verbalmente os eixos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notebook ou papel para diagrama",
                                    "Acesso à internet para artigos introdutórios (ex: Wikipedia ou IEEE)",
                                    "Slides ou vídeo explicativo sobre Flynn"
                                  ],
                                  "tips": "Use mnemônicos como 'Instruções e Dados: S=Single, M=Multiple' para memorizar.",
                                  "learningObjective": "Entender a estrutura conceitual da taxonomia e seus eixos de classificação.",
                                  "commonMistakes": "Confundir fluxo de instruções com fluxo de dados; sempre relacione ambos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar cada categoria individualmente",
                                  "subSteps": [
                                    "Estude SISD: exemplo processadores uniprocessados como Intel x86 clássico.",
                                    "Estude SIMD: exemplos vetoriação em GPUs ou instruções SSE/AVX.",
                                    "Estude MISD: exemplos pipelines com tarefas independentes, como em alguns sistemas de fault-tolerance.",
                                    "Estude MIMD: multiprocessadores como clusters ou multicore com threads independentes."
                                  ],
                                  "verification": "Liste 1 exemplo real para cada categoria com breve justificativa.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação de arquiteturas (ex: NVIDIA CUDA para SIMD)",
                                    "Livro ou PDF sobre arquitetura de computadores (ex: Hennessy & Patterson)"
                                  ],
                                  "tips": "Associe cada categoria a hardware familiar para fixar conceitos.",
                                  "learningObjective": "Descrever as características únicas de cada categoria SISD, SIMD, MISD e MIMD.",
                                  "commonMistakes": "Ignorar raridade do MISD; note que é teórico e pouco prático."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar e diferenciar as categorias",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: colunas para Instruções, Dados, Paralelismo, Exemplos.",
                                    "Destaque similaridades (todas lidam com paralelismo) e diferenças (grau de independência).",
                                    "Discuta vantagens/desvantagens: SIMD eficiente para dados regulares, MIMD para tarefas irregulares.",
                                    "Pratique classificando arquiteturas modernas (ex: GPU=SIMD, CPU multicore=MIMD)."
                                  ],
                                  "verification": "Preencha a tabela e classifique corretamente 3 arquiteturas dadas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets para tabela",
                                    "Imagens de arquiteturas de processadores"
                                  ],
                                  "tips": "Use cores na tabela para destacar Single vs Multiple.",
                                  "learningObjective": "Diferenciar precisamente as 4 categorias e suas aplicações.",
                                  "commonMistakes": "Classificar erradamente MIMD como todo paralelismo; foque nos fluxos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com sistemas de memória compartilhada em programação paralela",
                                  "subSteps": [
                                    "Explique como SISD usa memória compartilhada trivial (único núcleo).",
                                    "Discuta SIMD em memória compartilhada: vetores acessados uniformemente (ex: OpenMP SIMD).",
                                    "Analise MIMD: múltiplos processadores acessando memória compartilhada (ex: threads em multicore).",
                                    "Aborde MISD: raro, mas possível em pipelines com memória global.",
                                    "Sintetize: taxonomia guia escolha de modelo em programação paralela compartilhada."
                                  ],
                                  "verification": "Escreva um parágrafo relacionando cada categoria a um cenário de memória compartilhada.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tutoriais OpenMP/Pthreads",
                                    "Diagrama de memória compartilhada vs distribuída"
                                  ],
                                  "tips": "Pense em cache coherence como desafio chave em MIMD compartilhada.",
                                  "learningObjective": "Conectar taxonomia de Flynn a programação paralela em memória compartilhada.",
                                  "commonMistakes": "Confundir memória compartilhada com distribuída; foque em acesso único vs múltiplo."
                                }
                              ],
                              "practicalExample": "Classifique uma GPU NVIDIA moderna: SIMD porque aplica a mesma instrução a múltiplos dados em shaders paralelos, usando memória compartilhada via Unified Memory.",
                              "finalVerifications": [
                                "Reproduza o diagrama da taxonomia sem consulta.",
                                "Liste exemplos corretos para cada categoria.",
                                "Explique diferenças entre SIMD e MIMD em 1 minuto.",
                                "Classifique 3 arquiteturas dadas (CPU, GPU, cluster).",
                                "Relacione MIMD a um código OpenMP simples.",
                                "Descreva por que MISD é menos comum.",
                                "Identifique aplicação em memória compartilhada."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição dos eixos (100% correto).",
                                "Correção nos exemplos (pelo menos 80% acertos).",
                                "Clareza na tabela comparativa (todos campos preenchidos).",
                                "Profundidade na relação com memória compartilhada (conexões explícitas).",
                                "Capacidade de classificação autônoma (sem erros).",
                                "Uso de terminologia técnica adequada.",
                                "Síntese coerente em explicações verbais."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: classificação de hardware.",
                                "Matemática: operações vetoriais em SIMD.",
                                "Engenharia de Software: escolha de modelos paralelos (OpenMP, MPI).",
                                "Física Computacional: simulações paralelas em GPUs.",
                                "Inteligência Artificial: aceleração SIMD em machine learning."
                              ],
                              "realWorldApplication": "Em desenvolvimento de jogos, GPUs usam SIMD para renderização paralela em memória compartilhada; em data centers, MIMD em multicore otimiza servidores web com threads independentes acessando dados compartilhados."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.1.2",
                            "name": "Explicar MIMD em memória compartilhada",
                            "description": "Descrever como o modelo MIMD suporta múltiplos processadores independentes acessando uma memória compartilhada comum.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estudar as quatro classes principais: SISD, SIMD, MISD e MIMD, definindo cada sigla.",
                                    "Analisar diagramas que ilustrem fluxos de instruções e dados em cada modelo.",
                                    "Identificar características comuns e diferenças entre modelos sequenciais e paralelos.",
                                    "Ler exemplos históricos de cada classificação."
                                  ],
                                  "verification": "Listar corretamente as 4 classes da Taxonomia de Flynn com definições breves.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Diagrama da Taxonomia de Flynn (impresso ou digital)",
                                    "Vídeo introdutório sobre Flynn's Taxonomy (YouTube ou Khan Academy)"
                                  ],
                                  "tips": "Use mnemônicos para siglas: foque em 'Instruction' vs 'Data' streams.",
                                  "learningObjective": "Compreender a classificação fundamental de arquiteturas de computadores paralelos.",
                                  "commonMistakes": "Confundir 'Multiple Instruction' com execução sequencial ou ignorar o aspecto de streams independentes."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender o modelo MIMD em geral",
                                  "subSteps": [
                                    "Definir MIMD como Multiple Instruction Multiple Data: múltiplos processadores com instruções e dados independentes.",
                                    "Explicar que cada processador pode executar programas diferentes simultaneamente.",
                                    "Diferenciar MIMD de SIMD (vetorizado) e SISD (sequencial).",
                                    "Explorar vantagens como flexibilidade em workloads heterogêneos."
                                  ],
                                  "verification": "Explicar verbalmente ou por escrito a diferença entre MIMD e SIMD com um exemplo simples.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Artigo ou slide sobre MIMD (Wikipedia ou livro de arquitetura de computadores)",
                                    "Ferramenta de desenho para fluxogramas (Draw.io)"
                                  ],
                                  "tips": "Pense em MIMD como 'cada processador faz o seu próprio programa' em paralelo.",
                                  "learningObjective": "Dominar o conceito de independência em instruções e dados no MIMD.",
                                  "commonMistakes": "Achar que MIMD requer memória distribuída; é aplicável a ambos os modelos de memória."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Detalhar MIMD com memória compartilhada",
                                  "subSteps": [
                                    "Descrever o acesso simultâneo de múltiplos processadores a uma memória comum via barramento ou interconexão.",
                                    "Explicar mecanismos de sincronização como locks, semáforos e barreiras para evitar race conditions.",
                                    "Analisar consistência de cache e protocolos como MESI em sistemas multi-core.",
                                    "Simular um cenário onde processadores leem/escrevem dados compartilhados."
                                  ],
                                  "verification": "Desenhar um diagrama mostrando processadores acessando memória compartilhada sem conflitos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Simulador de memória compartilhada (ex: gem5 ou diagramas OpenMP)",
                                    "Pseudocódigo de exemplo com threads compartilhando variáveis"
                                  ],
                                  "tips": "Visualize como uma 'sala de reuniões' onde todos acessam o quadro branco, mas precisam de 'turnos' para escrever.",
                                  "learningObjective": "Explicar como MIMD opera eficientemente em ambientes de memória compartilhada.",
                                  "commonMistakes": "Ignorar problemas de concorrência, como data races em acessos simultâneos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e comparar MIMD em memória compartilhada",
                                  "subSteps": [
                                    "Comparar MIMD compartilhada vs distribuída (ex: MPI vs OpenMP).",
                                    "Identificar APIs como OpenMP ou Pthreads para programação MIMD compartilhada.",
                                    "Discutir escalabilidade e gargalos (Amdahl's Law).",
                                    "Testar um código simples de threads compartilhando memória."
                                  ],
                                  "verification": "Implementar e executar um programa OpenMP simples que demonstre MIMD compartilhado.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Compilador com suporte OpenMP (GCC)",
                                    "Editor de código (VS Code)"
                                  ],
                                  "tips": "Comece com #pragma omp parallel para ver paralelismo imediato.",
                                  "learningObjective": "Aplicar conceitos MIMD em cenários reais de programação paralela.",
                                  "commonMistakes": "Confundir overhead de sincronização com ineficiência inerente do modelo."
                                }
                              ],
                              "practicalExample": "Em um processador multi-core como Intel Xeon, cada core (processador) executa instruções independentes de um programa de machine learning (um core treina modelo A, outro otimiza hiperparâmetros), acessando datasets compartilhados na memória RAM via cache L3 unificado, usando locks para atualizações seguras.",
                              "finalVerifications": [
                                "Definir corretamente MIMD e sua posição na Taxonomia de Flynn.",
                                "Descrever mecanismos de acesso à memória compartilhada em MIMD.",
                                "Explicar pelo menos dois problemas de concorrência e soluções.",
                                "Comparar MIMD compartilhada com distribuída.",
                                "Executar um exemplo prático sem erros de race condition."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas: 30%)",
                                "Clareza na explicação de sincronização (25%)",
                                "Uso de exemplos relevantes (20%)",
                                "Capacidade de diagramação/visualização (15%)",
                                "Aplicação prática via código (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores (multi-core designs)",
                                "Sistemas Operacionais (gerenciamento de threads e memória)",
                                "Programação Concorrente (OpenMP/Pthreads)",
                                "Inteligência Artificial (treinamento paralelo de modelos)",
                                "Redes de Computadores (interconexões em clusters)"
                              ],
                              "realWorldApplication": "Em supercomputadores como o Frontier (topo TOP500), MIMD com memória compartilhada acelera simulações científicas (ex: clima, genômica), onde múltiplos nós processam fluxos independentes de dados genéticos compartilhados para análises paralelas em tempo real."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.1.3",
                            "name": "Comparar SIMD e MIMD para aplicações paralelas",
                            "description": "Analisar vantagens e limitações de SIMD versus MIMD em contextos de memória compartilhada, com exemplos de programação.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Taxonomia de Flynn e conceitos fundamentais",
                                  "subSteps": [
                                    "Estude a definição da Taxonomia de Flynn, focando nas quatro categorias: SISD, SIMD, MISD e MIMD.",
                                    "Identifique as diferenças entre instruções únicas/múltiplas e dados únicos/múltiplos.",
                                    "Revise exemplos históricos como Cray para SIMD e clusters para MIMD.",
                                    "Anote as características principais de arquiteturas de memória compartilhada.",
                                    "Compare brevemente SISD com SIMD e MIMD para contextualizar."
                                  ],
                                  "verification": "Crie um diagrama ou tabela resumindo as quatro classes da Taxonomia de Flynn com exemplos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de arquitetura de computadores (ex: Hennessy & Patterson)",
                                    "Artigos sobre Taxonomia de Flynn",
                                    "Vídeos tutoriais no YouTube sobre Flynn's Taxonomy"
                                  ],
                                  "tips": [
                                    "Use mnemônicos: 'Single Instruction' para sincronia, 'Multiple Data' para paralelismo de dados.",
                                    "Desenhe fluxogramas para visualizar o fluxo de instruções e dados."
                                  ],
                                  "learningObjective": "Compreender a base conceitual da Taxonomia de Flynn para enquadrar SIMD e MIMD.",
                                  "commonMistakes": [
                                    "Confundir MIMD com MISD (raro, mas verifique pipeline vs múltiplas instruções independentes).",
                                    "Ignorar o contexto de memória compartilhada."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar características, vantagens e limitações do SIMD",
                                  "subSteps": [
                                    "Descreva SIMD: mesma instrução aplicada a múltiplos dados simultaneamente.",
                                    "Liste vantagens: eficiência em operações vetoriais, bom para dados regulares como imagens/vídeos.",
                                    "Discuta limitações: pouca flexibilidade para branches condicionais, lockstep execution.",
                                    "Estude exemplos de programação: instruções SSE/AVX em C++ ou CUDA.",
                                    "Implemente um código simples de soma vetorial usando SIMD intrinsics."
                                  ],
                                  "verification": "Execute e teste um programa SIMD simples, medindo speedup vs sequencial.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte SSE/AVX",
                                    "Documentação Intel Intrinsics Guide",
                                    "Exemplos de código de SIMD no GitHub"
                                  ],
                                  "tips": [
                                    "Comece com vetores pequenos para depuração.",
                                    "Use flags de compilação como -msse4 para habilitar instruções."
                                  ],
                                  "learningObjective": "Dominar as forças e fraquezas do SIMD em aplicações paralelas de memória compartilhada.",
                                  "commonMistakes": [
                                    "Assumir que SIMD é sempre mais rápido (depende de alinhamento de dados).",
                                    "Não alinhar dados em memória (use __attribute__((aligned(16)))."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar características, vantagens e limitações do MIMD",
                                  "subSteps": [
                                    "Descreva MIMD: múltiplas instruções independentes em múltiplos dados/processadores.",
                                    "Liste vantagens: alta flexibilidade, ideal para tarefas heterogêneas como simulações.",
                                    "Discuta limitações: overhead de sincronização, complexidade em gerenciamento de threads.",
                                    "Estude exemplos de programação: OpenMP ou Pthreads para memória compartilhada.",
                                    "Implemente um código MIMD simples com threads paralelas para matrix multiply."
                                  ],
                                  "verification": "Execute um programa MIMD com múltiplas threads, verificando corretude com races conditions ausentes.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Biblioteca OpenMP (compilador com suporte)",
                                    "Documentação OpenMP.org",
                                    "Ambiente Linux para testes multi-thread"
                                  ],
                                  "tips": [
                                    "Use #pragma omp parallel for para paralelização fácil.",
                                    "Monitore com tools como htop ou perf para overhead."
                                  ],
                                  "learningObjective": "Dominar as forças e fraquezas do MIMD em aplicações paralelas de memória compartilhada.",
                                  "commonMistakes": [
                                    "Race conditions por falta de mutexes ou critical sections.",
                                    "Sobrecarga excessiva de threads (limite ao número de cores)."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar SIMD e MIMD em contextos de aplicações paralelas",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: eficiência, flexibilidade, overhead, cenários ideais.",
                                    "Analise trade-offs em memória compartilhada: cache coherence em MIMD vs vetorização em SIMD.",
                                    "Discuta exemplos: SIMD para processamento de imagem (Photoshop filters), MIMD para ML training.",
                                    "Avalie quando escolher um sobre o outro baseado em workload.",
                                    "Desenvolva um caso estudo híbrido (SIMD dentro de threads MIMD)."
                                  ],
                                  "verification": "Escreva um relatório de 1 página com tabela comparativa e escolha justificada para 3 aplicações.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Ferramentas de benchmark como Google Benchmark",
                                    "Papéis acadêmicos sobre hybrid SIMD/MIMD"
                                  ],
                                  "tips": [
                                    "Classifique workloads: data-parallel (SIMD) vs task-parallel (MIMD).",
                                    "Meça performance real para validar análise."
                                  ],
                                  "learningObjective": "Capacitar análise crítica e seleção de modelo para aplicações específicas.",
                                  "commonMistakes": [
                                    "Generalizar demais: SIMD não é só GPUs, MIMD não é só clusters.",
                                    "Ignorar custos de hardware (SIMD requer vetores largos)."
                                  ]
                                }
                              ],
                              "practicalExample": "Em processamento de vídeo em memória compartilhada: use SIMD (AVX) para aplicar filtro de convolução em pixels paralelos (rápido para dados uniformes); use MIMD (OpenMP threads) para pipeline de vídeo onde uma thread decodifica, outra filtra e terceira codifica (flexível para tarefas diferentes).",
                              "finalVerifications": [
                                "Explique verbalmente as diferenças chave entre SIMD e MIMD com exemplos de código.",
                                "Identifique corretamente 3 aplicações ideais para cada modelo.",
                                "Crie e execute benchmarks comparativos mostrando speedup.",
                                "Discuta limitações em memória compartilhada sem erros conceituais.",
                                "Proponha um design híbrido para uma aplicação real.",
                                "Responda quiz com 90% acerto sobre trade-offs."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual na distinção SIMD vs MIMD (30%)",
                                "Profundidade na análise de vantagens/limitações (25%)",
                                "Qualidade de exemplos de programação e benchmarks (20%)",
                                "Clareza na tabela comparativa e análise de aplicações (15%)",
                                "Criatividade em conexões com memória compartilhada (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Estudo de pipelines e vetores.",
                                "Programação: Intrinsics, OpenMP e otimização de código.",
                                "Inteligência Artificial: Aceleração de redes neurais (SIMD em GPUs).",
                                "Engenharia de Software: Design de sistemas paralelos escaláveis.",
                                "Matemática Computacional: Operações vetoriais e lineares."
                              ],
                              "realWorldApplication": "GPUs modernas (NVIDIA CUDA) usam SIMD para ray tracing em jogos; supercomputadores como Frontier usam MIMD em nós para simulações climáticas, ambos em contextos de memória compartilhada para aceleração de workloads paralelos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.2.2",
                        "name": "Características dos Modelos de Memória Compartilhada",
                        "description": "Propriedades fundamentais como uniformidade de acesso, latência e consistência em sistemas paralelos com memória compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.2.2.1",
                            "name": "Descrever uniformidade de acesso à memória",
                            "description": "Explicar o conceito de tempo de acesso uniforme (UMA) versus não-uniforme (NUMA) em arquiteturas compartilhadas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos de Arquiteturas de Memória Compartilhada",
                                  "subSteps": [
                                    "Revise o conceito de memória compartilhada em sistemas multiprocessadores.",
                                    "Identifique os componentes principais: processadores, interconexões e módulos de memória.",
                                    "Estude o impacto do tempo de acesso à memória no desempenho geral do sistema.",
                                    "Analise diagramas básicos de arquiteturas SMP (Symmetric Multiprocessing).",
                                    "Discuta por que a uniformidade do acesso é crítica em programação paralela."
                                  ],
                                  "verification": "Desenhe um diagrama simples de memória compartilhada e explique verbalmente os componentes.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Diagramas de arquiteturas SMP (ex: Wikipedia ou slides de arquitetura de computadores)",
                                    "Vídeo introdutório sobre multiprocessadores (YouTube: 'Memory Shared Architectures')"
                                  ],
                                  "tips": "Comece com analogias cotidianas, como acessar prateleiras em uma biblioteca única vs distribuída.",
                                  "learningObjective": "Entender o papel da memória compartilhada como base para UMA e NUMA.",
                                  "commonMistakes": "Confundir memória compartilhada com distribuída; ignorar o papel das interconexões."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Modelo UMA (Uniform Memory Access)",
                                  "subSteps": [
                                    "Defina UMA: tempo de acesso idêntico a qualquer módulo de memória de qualquer processador.",
                                    "Descreva arquiteturas bus-based e crossbar que suportam UMA.",
                                    "Calcule tempos de acesso teóricos em cenários simples (ex: 100ns para todos).",
                                    "Liste vantagens: simplicidade de programação, escalabilidade limitada.",
                                    "Identifique limitações: gargalos em bus compartilhado para muitos processadores."
                                  ],
                                  "verification": "Escreva uma definição precisa de UMA e liste 3 vantagens/desvantagens em um resumo.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Artigo: 'UMA vs NUMA Architectures' (Tanenbaum ou Patterson & Hennessy)",
                                    "Simulador online de bus contention (ex: ferramentas de arquitetura como gem5)"
                                  ],
                                  "tips": "Use cronogramas para visualizar acessos simultâneos e contenda.",
                                  "learningObjective": "Dominar as características e trade-offs do modelo UMA.",
                                  "commonMistakes": "Achar que UMA é sempre mais rápida; esquecer limitações de escalabilidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar o Modelo NUMA (Non-Uniform Memory Access)",
                                  "subSteps": [
                                    "Defina NUMA: tempo de acesso varia (local vs remoto).",
                                    "Explique hierarquia: memória local (rápida) vs remota (lenta via interconexões).",
                                    "Estude arquiteturas cc-NUMA (cache-coherent NUMA).",
                                    "Calcule diferenças de tempo: ex: 50ns local, 200ns remoto.",
                                    "Discuta otimizações: afinidade de threads à memória local."
                                  ],
                                  "verification": "Crie uma tabela comparativa de tempos de acesso em um cluster NUMA hipotético.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação AMD/Intel sobre NUMA (ex: Intel Xeon manuals)",
                                    "Ferramenta numactl para Linux para demonstrar NUMA"
                                  ],
                                  "tips": "Execute 'numactl --hardware' no Linux para ver topologia real da sua máquina.",
                                  "learningObjective": "Compreender as nuances e benefícios de NUMA em sistemas escaláveis.",
                                  "commonMistakes": "Ignorar coerência de cache em NUMA; superestimar penalidades remotas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar UMA e NUMA e Discutir Implicações",
                                  "subSteps": [
                                    "Crie uma tabela de comparação: escalabilidade, custo, programação.",
                                    "Analise cenários: UMA para 4-8 CPUs, NUMA para 64+.",
                                    "Discuta impacto em programação paralela (ex: OpenMP locality hints).",
                                    "Explore ferramentas de profiling: numastat, perf.",
                                    "Sintetize quando usar cada modelo."
                                  ],
                                  "verification": "Apresente uma comparação em 1 página e responda perguntas sobre trade-offs.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Slides comparativos (ex: curso MIT 6.823)",
                                    "Exemplos de código OpenMP com pragmas de afinidade"
                                  ],
                                  "tips": "Pense em data centers: UMA para workstations, NUMA para servidores.",
                                  "learningObjective": "Capacitar a descrever diferenças e escolher modelos adequadamente.",
                                  "commonMistakes": "Generalizar UMA como obsoleta; não considerar coerência."
                                }
                              ],
                              "practicalExample": "Em um servidor web com 4 CPUs UMA, todos os processadores acessam dados de cliente em ~100ns. Em um supercomputador NUMA com 64 nodes, um thread em node A acessa memória local em 50ns, mas remota em node Z em 300ns, exigindo alocação NUMA-aware para evitar lentidão.",
                              "finalVerifications": [
                                "Explicar UMA e NUMA sem erros conceituais.",
                                "Desenhar diagramas precisos de ambas arquiteturas.",
                                "Calcular tempos de acesso em cenários dados.",
                                "Identificar quando usar UMA vs NUMA.",
                                "Demonstrar com numactl em máquina real.",
                                "Discutir impacto em performance paralela."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de UMA/NUMA (80%+ correto).",
                                "Qualidade de diagramas e tabelas comparativas.",
                                "Capacidade de calcular e justificar tempos de acesso.",
                                "Análise de trade-offs com exemplos reais.",
                                "Uso correto de terminologia técnica.",
                                "Clareza na explicação oral/escrita."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Estudo de caches e interconexões.",
                                "Sistemas Operacionais: Gerenciamento de afinidade NUMA (sched_setaffinity).",
                                "Programação Paralela: Otimizações em OpenMP/MPI híbrido.",
                                "Engenharia de Performance: Profiling com perf/numastat.",
                                "Redes de Computadores: Latência em interconexões NUMA."
                              ],
                              "realWorldApplication": "Em data centers como AWS EC2 (instâncias NUMA para workloads paralelos), otimizar alocação de memória NUMA-aware reduz latência em 30-50% para bancos de dados distribuídos como Cassandra ou aplicações HPC em supercomputadores TOP500."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.2.2",
                            "name": "Analisar modelos de consistência de memória",
                            "description": "Diferenciar consistência sequencial, forte e fraca, e seu impacto na programação paralela em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Fundamentos de Consistência de Memória em Sistemas Paralelos",
                                  "subSteps": [
                                    "Leia definições básicas de memória compartilhada e ordem de execução em programação paralela.",
                                    "Identifique o problema da reordenação de instruções por compiladores e processadores.",
                                    "Estude o conceito de 'visibilidade' de escritas entre threads.",
                                    "Revise exemplos simples de races conditions sem barreiras de memória.",
                                    "Anote as garantias mínimas que um modelo de consistência deve fornecer."
                                  ],
                                  "verification": "Crie um diagrama ilustrando uma race condition e explique como a falta de consistência causa problemas.",
                                  "estimatedTime": "1-2 hours",
                                  "materials": [
                                    "Livro 'Modern Operating Systems' de Tanenbaum (capítulo sobre threads)",
                                    "Artigo Wikipedia: Memory Consistency Model",
                                    "Slides online sobre programação paralela"
                                  ],
                                  "tips": "Use analogias como 'carta enviada mas não recebida' para visualizar visibilidade.",
                                  "learningObjective": "Compreender por que modelos de consistência são necessários em memória compartilhada.",
                                  "commonMistakes": "Confundir consistência com atomicidade; atomicidade garante indivisibilidade, consistência garante ordem/visibilidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o Modelo de Consistência Sequencial",
                                  "subSteps": [
                                    "Defina consistência sequencial: todas as operações parecem ocorrer em uma ordem sequencial global.",
                                    "Estude propriedades: ordem total programada + ordem total de memória.",
                                    "Simule com pseudocódigo: duas threads lendo/escrevendo variáveis compartilhadas.",
                                    "Compare com execução serial equivalente.",
                                    "Implemente um exemplo simples em C com pthreads sem fences para observar violações."
                                  ],
                                  "verification": "Escreva um programa que demonstre execução sequencialmente consistente e valide com múltiplas runs.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Documentação pthreads man pages",
                                    "Exemplos de código do livro 'Programming with POSIX Threads' de Butenhof",
                                    "Ferramenta ThreadSanitizer para debug"
                                  ],
                                  "tips": "Execute o código em loop para observar comportamentos não sequenciais em hardware real.",
                                  "learningObjective": "Diferenciar as garantias de ordem total no modelo sequencial.",
                                  "commonMistakes": "Assumir que SC é o mais forte; é forte mas custoso em performance."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diferenciar Consistência Forte e Fraca",
                                  "subSteps": [
                                    "Defina consistência forte: toda escrita é imediatamente visível para todas as leituras subsequentes.",
                                    "Defina consistência fraca (release-acquire, relaxed): visibilidade relaxada, sem ordem total.",
                                    "Compare com SC: forte é mais restritiva que SC em alguns cenários.",
                                    "Estude modelos como Total Store Order (TSO) vs. Partial Store Order (PSO).",
                                    "Implemente exemplos contrastando forte vs. fraca usando std::memory_order em C++11."
                                  ],
                                  "verification": "Crie tabela comparativa com exemplos de código para cada modelo e cenários onde falham.",
                                  "estimatedTime": "2-3 hours",
                                  "materials": [
                                    "Cppreference.com: std::memory_order",
                                    "Livro 'C++ Concurrency in Action' de Anthony Williams",
                                    "Compilador GCC/Clang com flags -O2 para observar otimizações"
                                  ],
                                  "tips": "Use assembly output (godbolt.org) para ver como fences afetam instruções.",
                                  "learningObjective": "Identificar trade-offs entre força da consistência e performance.",
                                  "commonMistakes": "Ignorar otimizações do compilador que quebram suposições intuitivas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar Impactos na Programação Paralela",
                                  "subSteps": [
                                    "Analise overhead: SC requer mais sincronizações que fraca.",
                                    "Discuta impactos em algoritmos: locks, barriers, work-stealing queues.",
                                    "Simule cenários: producer-consumer com diferentes modelos.",
                                    "Avalie hardware: x86 (TSO forte) vs. ARM (fraco).",
                                    "Desenvolva um caso onde escolher modelo errado causa bugs."
                                  ],
                                  "verification": "Refatore um código paralelo buggy para usar o modelo correto e meça speedup.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Benchmark tools como Google Benchmark",
                                    "Exemplos de litmus tests em herd7.laas.fr",
                                    "Paper 'Understanding Ordering Semantics' de OWASP"
                                  ],
                                  "tips": "Teste em diferentes arquiteturas via Docker ou cloud VMs.",
                                  "learningObjective": "Aplicar conhecimentos para escolher modelos adequados em cenários reais.",
                                  "commonMistakes": "Escolher modelo mais fraco sem verificar corretude do algoritmo."
                                }
                              ],
                              "practicalExample": "Em um producer-consumer com fila compartilhada em C++: Use memory_order_seq_cst para SC (lento mas correto); mude para acquire/release (fraco, mais rápido). Observe com ThreadSanitizer que relaxed falha em producer-consumer sem fences.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças entre SC, forte e fraca com diagrama de tempo.",
                                "Implementar e debugar código que viola cada modelo.",
                                "Prever comportamento de litmus tests para x86/ARM.",
                                "Escolher modelo ótimo para 3 cenários dados (ex: Dekker's algorithm).",
                                "Medir performance delta entre modelos em benchmark simples.",
                                "Discutir quando usar hardware fences vs. software."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições e propriedades de cada modelo (80% correto).",
                                "Capacidade de gerar exemplos de código funcionais e não-funcionais.",
                                "Análise correta de trade-offs performance/corretude.",
                                "Uso apropriado de ferramentas de verificação (TSan, litmus).",
                                "Conexões claras com impactos em algoritmos paralelos.",
                                "Criatividade em aplicações reais e detecção de bugs sutis."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Modelos de cache coherence (MESI).",
                                "Sistemas Distribuídos: Consistência em bancos de dados (linearizability).",
                                "Compiladores: Análise de dependências e reordenação.",
                                "Algoritmos: Corretude em locks e barriers.",
                                "Segurança: Exploração de TOCTOU via fraquezas de memória."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded (ex: Nginx), usar consistência release-acquire otimiza throughput em queues de requests; em ML training distribuído (TensorFlow), modelos fracos aceleram atualizações de gradientes sem perda de convergência."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.2.3",
                            "name": "Identificar problemas de sincronização",
                            "description": "Reconhecer race conditions e necessidade de exclusão mútua em acessos concorrentes à memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Programação Concorrente",
                                  "subSteps": [
                                    "Estude definições de thread, processo e memória compartilhada.",
                                    "Revise o modelo de execução sequencial vs. concorrente.",
                                    "Analise diagramas de timeline para acessos simultâneos à memória.",
                                    "Identifique diferenças entre leitura e escrita em variáveis compartilhadas.",
                                    "Discuta atomicidade de operações básicas como incremento."
                                  ],
                                  "verification": "Resuma em suas palavras os conceitos chave e desenhe um diagrama simples de acessos concorrentes.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro-texto de programação paralela (cap. memória compartilhada), slides introdutórios, editor de diagramas (ex: Draw.io).",
                                  "tips": "Use analogias como 'duas pessoas editando o mesmo documento ao mesmo tempo'.",
                                  "learningObjective": "Dominar terminologia e visualizar acessos concorrentes.",
                                  "commonMistakes": "Confundir threads com processos ou ignorar que leituras múltiplas podem ser seguras."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Race Conditions em Código Simples",
                                  "subSteps": [
                                    "Escreva um programa sequencial com uma variável compartilhada (ex: contador).",
                                    "Converta para versão multi-threaded sem sincronização.",
                                    "Execute múltiplas vezes e observe resultados inconsistentes.",
                                    "Use ferramentas de depuração para rastrear ordem de execução.",
                                    "Marque linhas de código vulneráveis a race conditions."
                                  ],
                                  "verification": "Execute o código 100 vezes e registre a variabilidade no valor final do contador.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Compilador C++/Java com pthread/OpenMP, IDE (VS Code ou Eclipse), terminal para execuções repetidas.",
                                  "tips": "Aumente o número de threads para amplificar o problema.",
                                  "learningObjective": "Reconhecer padrões de código suscetíveis a race conditions.",
                                  "commonMistakes": "Atribuir inconsistências a 'bugs aleatórios' em vez de concorrência."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Necessidade de Exclusão Mútua",
                                  "subSteps": [
                                    "Estude o conceito de seção crítica e suas propriedades (exclusão mútua, progresso, bounded waiting).",
                                    "Compare código com e sem mutex em cenários de leitura/escrita.",
                                    "Implemente mutex básico e compare saídas.",
                                    "Discuta overhead de sincronização vs. custo de race conditions.",
                                    "Identifique cenários onde mutex não é necessário (ex: leituras atômicas)."
                                  ],
                                  "verification": "Modifique código para incluir mutex e confirme resultados consistentes em 100 execuções.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Documentação pthread_mutex (man pages), exemplos de código online (GitHub repos de paralelismo).",
                                  "tips": "Use printf com thread IDs para visualizar bloqueios.",
                                  "learningObjective": "Determinar quando exclusão mútua é essencial.",
                                  "commonMistakes": "Aplicar mutex desnecessariamente em operações atômicas, causando gargalos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar Identificação em Cenários Complexos",
                                  "subSteps": [
                                    "Analise códigos reais de bibliotecas ou apps multi-threaded.",
                                    "Crie fluxogramas de execução para detectar potenciais races.",
                                    "Debata com pares soluções alternativas (semáforos, locks finos).",
                                    "Simule com ferramentas como ThreadSanitizer para detectar races.",
                                    "Documente 3 exemplos de problemas identificados."
                                  ],
                                  "verification": "Gere relatório com 3 códigos analisados, destacando problemas e soluções.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "ThreadSanitizer (GCC/Clang), repositórios GitHub de projetos paralelos, ferramenta de análise estática (Helgrind).",
                                  "tips": "Comece com códigos conhecidos problemáticos para ganhar confiança.",
                                  "learningObjective": "Aplicar conhecimento para diagnosticar sincronização em contextos reais.",
                                  "commonMistakes": "Ignorar races em estruturas de dados compostas como listas ligadas."
                                }
                              ],
                              "practicalExample": "Em um servidor web multi-threaded, dois threads acessam simultaneamente um contador de visitas compartilhado: Thread A lê 100, incrementa para 101 e escreve; Thread B lê 100, incrementa para 101 e escreve. Resultado final: 101 em vez de 102, perdendo uma visita devido a race condition. Solução: Envolver o incremento com mutex_lock/unlock.",
                              "finalVerifications": [
                                "Explicar race condition com diagrama de timeline.",
                                "Identificar 3 linhas vulneráveis em código fornecido.",
                                "Diferenciar cenários que precisam vs. não precisam de mutex.",
                                "Executar simulação e confirmar eliminação de inconsistências.",
                                "Discutir trade-offs de sincronização.",
                                "Analisar código real e propor correção."
                              ],
                              "assessmentCriteria": [
                                "Precisão na detecção de race conditions (90%+ acurácia).",
                                "Correta aplicação de conceitos de exclusão mútua.",
                                "Qualidade de diagramas e explicações (clareza e completude).",
                                "Evidências empíricas de testes (logs de execuções).",
                                "Profundidade na análise de trade-offs e alternativas.",
                                "Capacidade de generalizar para cenários novos."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de threads e primitivas de sincronização.",
                                "Estruturas de Dados: Thread-safety em queues e árvores.",
                                "Redes: Concorrência em protocolos de comunicação assíncrona.",
                                "Engenharia de Software: Design patterns para paralelismo (producer-consumer)."
                              ],
                              "realWorldApplication": "Em bancos de dados relacionais como PostgreSQL, identificar races em transações concorrentes para evitar perdas de dados; em apps mobile com background threads, prevenir crashes por acessos simultâneos a caches compartilhados; em jogos multiplayer, sincronizar scores globais sem inconsistências."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.2.4",
                            "name": "Exemplificar decomposição de domínio",
                            "description": "Demonstrar como dividir o domínio de dados em tarefas paralelas que compartilham memória de forma eficiente.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Decomposição de Domínio",
                                  "subSteps": [
                                    "Estude a definição de decomposição de domínio como divisão espacial do conjunto de dados em sub-regiões independentes.",
                                    "Analise exemplos clássicos, como grades 2D em simulações numéricas ou imagens em processamento paralelo.",
                                    "Identifique vantagens na memória compartilhada: acesso direto às partilhas sem comunicação explícita.",
                                    "Compare com outros tipos de decomposição (funcional ou de dados homogêneos).",
                                    "Registre anotações sobre granularidade ideal para paralelismo eficiente."
                                  ],
                                  "verification": "Explique em suas palavras o conceito e forneça um diagrama simples de divisão de uma grade 2D.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação OpenMP/Pthreads",
                                    "Vídeos tutoriais sobre modelos de memória compartilhada",
                                    "Papel e caneta para diagramas"
                                  ],
                                  "tips": "Comece com problemas visuais como matrizes para facilitar a compreensão espacial.",
                                  "learningObjective": "Dominar os fundamentos teóricos da decomposição de domínio em contextos de memória compartilhada.",
                                  "commonMistakes": [
                                    "Confundir decomposição de domínio com decomposição de tarefas funcionais.",
                                    "Subestimar o impacto da granularidade na eficiência."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e Analisar o Domínio de Dados",
                                  "subSteps": [
                                    "Selecione um problema com domínio espacial claro, como soma ou multiplicação de matrizes grandes.",
                                    "Mapeie o domínio total (ex: matriz NxN) e identifique pontos de independência entre elementos.",
                                    "Avalie dependências: verifique acessos de leitura/escrita que possam causar races conditions.",
                                    "Calcule o tamanho ideal de subdomínios baseado no número de threads disponíveis.",
                                    "Crie um diagrama representando o domínio original e possíveis divisões."
                                  ],
                                  "verification": "Produza um diagrama anotado mostrando o domínio dividido em 4 subdomínios com análise de dependências.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Editor de imagens ou ferramentas de diagrama (Draw.io)",
                                    "Exemplos de código de matrizes em C/C++"
                                  ],
                                  "tips": "Priorize divisões regulares (faixas ou blocos) para simplicidade em memória compartilhada.",
                                  "learningObjective": "Habilitar a análise precisa de domínios de dados para paralelização.",
                                  "commonMistakes": [
                                    "Ignorar bordas de subdomínios que geram dependências.",
                                    "Escolher divisões desbalanceadas que sobrecarregam threads."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Dividir o Domínio em Tarefas Paralelas Eficientes",
                                  "subSteps": [
                                    "Defina o número de tarefas paralelas alinhado ao hardware (ex: 4 threads para quad-core).",
                                    "Atribua subdomínios: use índices de linhas/colunas para mapear faixas a cada thread.",
                                    "Implemente sincronização mínima: locks apenas em regiões críticas se necessário.",
                                    "Otimize compartilhamento: garanta que dados sejam acessíveis via ponteiros compartilhados.",
                                    "Simule a execução manualmente para prever balanceamento de carga."
                                  ],
                                  "verification": "Descreva o mapeamento de subdomínios para threads e justifique a eficiência esperada.",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "Compilador C/C++ com suporte OpenMP",
                                    "Ambiente de desenvolvimento (VS Code ou similar)"
                                  ],
                                  "tips": "Use diretivas #pragma omp parallel for para automação inicial da divisão.",
                                  "learningObjective": "Capacitar a criação de divisões otimizadas para execução paralela.",
                                  "commonMistakes": [
                                    "Excesso de sincronização que anula ganhos paralelos.",
                                    "Divisões irregulares levando a load imbalance."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar, Testar e Avaliar a Decomposição",
                                  "subSteps": [
                                    "Escreva código sequencial como baseline e meça tempo de execução.",
                                    "Converta para paralelo usando OpenMP ou Pthreads, aplicando a decomposição.",
                                    "Execute testes com diferentes tamanhos de domínio e números de threads.",
                                    "Meça speedup e eficiência: compare tempos e verifique corretude dos resultados.",
                                    "Ajuste granularidade e sincronizações baseado nos resultados empíricos."
                                  ],
                                  "verification": "Forneça código funcional, resultados de timing e gráfico de speedup.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Biblioteca OpenMP instalada",
                                    "Ferramentas de profiling (time, gprof)",
                                    "Dados de teste: matrizes geradas aleatoriamente"
                                  ],
                                  "tips": "Teste com N=1024+ para evidenciar ganhos; use OMP_NUM_THREADS para variar.",
                                  "learningObjective": "Validar empiricamente a eficiência da decomposição de domínio.",
                                  "commonMistakes": [
                                    "Não medir baseline sequencial corretamente.",
                                    "Interpretar erroneamente slowdowns como falhas de hardware."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma matriz 1000x1000 para soma elemento a elemento (A[i][j] += B[i][j]), divida em 4 faixas horizontais: thread 0 processa linhas 0-249, thread 1 linhas 250-499, etc. Todas threads acessam a matriz compartilhada via ponteiros globais, com #pragma omp parallel for(i=low; i<high; i++) para iterações independentes.",
                              "finalVerifications": [
                                "Explicar verbalmente ou por escrito como a decomposição reduz o tempo de execução.",
                                "Apresentar código paralelo funcional sem race conditions.",
                                "Demonstrar speedup > 2x em hardware multi-core.",
                                "Identificar e corrigir uma dependência artificial em um exemplo dado.",
                                "Criar decomposição para um novo domínio (ex: grade 3D)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de independências (sem falsos positivos/negativos).",
                                "Eficiência medida: speedup linear com número de threads até limite hardware.",
                                "Corretude: resultados idênticos ao sequencial em múltiplas execuções.",
                                "Granularidade otimizada: subdomínios balanceados (±10% de workload).",
                                "Documentação clara: diagramas e justificativas lógicas.",
                                "Robustez: código roda sem crashes em diferentes configurações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Divisão de espaços vetoriais e álgebra linear em grades.",
                                "Algoritmos: Análise de complexidade O(N^2/p) e balanceamento de carga.",
                                "Engenharia de Software: Padrões de design para paralelismo thread-safe.",
                                "Física/Computação Científica: Modelagem de simulações em malhas espaciais."
                              ],
                              "realWorldApplication": "Em simulações climáticas (ex: modelos GCM), onde grids terrestres globais são decompostos em sub-regiões para cálculos paralelos de física atmosférica em supercomputadores com memória compartilhada, acelerando previsões meteorológicas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.2.3",
                        "name": "Classificações de Modelos de Memória Compartilhada",
                        "description": "Tipos como UMA, NUMA, COMA e PRAM, com foco em sua aplicação em programação paralela moderna.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.2.3.1",
                            "name": "Classificar UMA e NUMA",
                            "description": "Diferenciar Uniform Memory Access (UMA) de Non-Uniform Memory Access (NUMA) e suas implicações em desempenho.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos de Modelos de Memória Compartilhada",
                                  "subSteps": [
                                    "Revise o conceito de memória compartilhada em sistemas paralelos.",
                                    "Identifique as classificações principais: UMA e NUMA.",
                                    "Estude o impacto do tempo de acesso à memória no desempenho geral.",
                                    "Analise diagramas básicos de topologias de memória.",
                                    "Defina termos chave: uniformidade, latência e largura de banda."
                                  ],
                                  "verification": "Resuma em 3 frases os fundamentos e liste 5 termos chave com definições.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Diagrama de memória compartilhada (online ou livro)",
                                    "Notas de aula sobre programação paralela"
                                  ],
                                  "tips": "Use analogias como 'acesso igualitário vs. acesso hierárquico' para fixar conceitos.",
                                  "learningObjective": "Entender a base conceitual para diferenciar modelos de memória.",
                                  "commonMistakes": [
                                    "Confundir memória compartilhada com distribuída",
                                    "Ignorar o papel da topologia de hardware"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Modelo UMA (Uniform Memory Access)",
                                  "subSteps": [
                                    "Defina UMA: tempo de acesso uniforme para todos os processadores.",
                                    "Descreva características: barramento compartilhado, cache coherency.",
                                    "Identifique exemplos: sistemas SMP (Symmetric Multi-Processing) como Intel Xeon single-socket.",
                                    "Analise vantagens: simplicidade de programação, baixa latência.",
                                    "Discuta limitações: escalabilidade limitada (até ~32 núcleos)."
                                  ],
                                  "verification": "Desenhe um diagrama simples de UMA e explique suas vantagens em voz alta.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Exemplos de processadores UMA (Wikipedia ou docs Intel)",
                                    "Ferramenta de desenho como Draw.io"
                                  ],
                                  "tips": "Pense em UMA como uma 'sala de aula com quadro único acessível por todos igualmente'.",
                                  "learningObjective": "Dominar características e exemplos do modelo UMA.",
                                  "commonMistakes": [
                                    "Achar que UMA é sempre mais rápida",
                                    "Confundir com cache-only models"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar o Modelo NUMA (Non-Uniform Memory Access)",
                                  "subSteps": [
                                    "Defina NUMA: tempo de acesso varia baseado na localização da memória.",
                                    "Descreva características: nós interconectados, memória local vs. remota.",
                                    "Identifique exemplos: servidores multi-socket AMD EPYC, IBM Power systems.",
                                    "Analise vantagens: alta escalabilidade (centenas de núcleos), custo-efetivo.",
                                    "Discuta limitações: complexidade de programação, NUMA affinity."
                                  ],
                                  "verification": "Liste 3 exemplos reais de hardware NUMA e descreva latência local vs. remota.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação AMD/Intel sobre NUMA",
                                    "Ferramenta numactl para Linux"
                                  ],
                                  "tips": "'Casa com quartos': memória local rápida, mas acesso remoto mais lento.",
                                  "learningObjective": "Dominar características e exemplos do modelo NUMA.",
                                  "commonMistakes": [
                                    "Subestimar impacto da affinity",
                                    "Confundir NUMA com COMA (Cache-Only)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar UMA e NUMA e Analisar Implicações em Desempenho",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: latência, escalabilidade, programação.",
                                    "Discuta implicações: thrashing em NUMA sem affinity, gargalos em UMA.",
                                    "Simule cenários: workload balanceado vs. não-otimizado.",
                                    "Explore ferramentas: numactl, hwloc para detectar topologia.",
                                    "Conclua com quando usar cada modelo."
                                  ],
                                  "verification": "Preencha tabela comparativa e identifique cenário ideal para cada.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel/Google Sheets",
                                    "Comando 'numactl --hardware' em Linux VM"
                                  ],
                                  "tips": "Teste em VM com múltiplos núcleos para ver diferenças reais.",
                                  "learningObjective": "Diferenciar modelos e prever impactos em desempenho.",
                                  "commonMistakes": [
                                    "Ignorar overhead de interconexão em NUMA",
                                    "Generalizar desempenho sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um servidor web multi-threaded: Otimize alocação de threads em NUMA usando numactl para pinning memória local, reduzindo latência de 200ns remota para 50ns local, melhorando throughput em 30%.",
                              "finalVerifications": [
                                "Explique diferenças em 1 minuto sem consultar notas.",
                                "Identifique UMA vs NUMA em specs de 3 CPUs reais.",
                                "Preveja gargalos de desempenho em cenários dados.",
                                "Crie tabela comparativa precisa.",
                                "Demonstre uso de numactl em terminal.",
                                "Discuta trade-offs em escalabilidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas: 30%)",
                                "Compreensão de implicações (análise de desempenho: 25%)",
                                "Exemplos reais e relevantes (20%)",
                                "Comparação estruturada (tabela/diagrama: 15%)",
                                "Aplicação prática (ferramentas: 10%)"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Topologias de interconexão.",
                                "Sistemas Operacionais: Gerenciamento de memória e scheduling NUMA-aware.",
                                "Programação Paralela: OpenMP com pragmas de affinity.",
                                "Desempenho e Otimização: Profiling com perf/hwloc."
                              ],
                              "realWorldApplication": "Em data centers (ex: AWS EC2 com NUMA), otimizar bancos de dados como MySQL para NUMA reduz latência em queries distribuídas, economizando custos em escalabilidade horizontal."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.3.2",
                            "name": "Descrever o modelo PRAM",
                            "description": "Explicar o Parallel Random Access Machine (PRAM) como modelo teórico idealizado para memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender a definição e propósito do modelo PRAM",
                                  "subSteps": [
                                    "Pesquise a definição oficial do PRAM como máquina de acesso aleatório paralelo.",
                                    "Identifique os componentes principais: múltiplos processadores independentes e memória compartilhada global.",
                                    "Analise o propósito: modelo teórico idealizado para análise de algoritmos paralelos.",
                                    "Registre as suposições ideais: acesso simultâneo ilimitado à memória sem conflitos.",
                                    "Compare brevemente com modelos sequenciais como a RAM de Turing."
                                  ],
                                  "verification": "Escreva um parágrafo resumindo a definição e propósito, sem erros conceituais.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Artigo original de Fortune e Wyllie (1978)",
                                    "Livros de algoritmos paralelos (ex: Introduction to Parallel Algorithms)",
                                    "Vídeos introdutórios no YouTube sobre modelos PRAM"
                                  ],
                                  "tips": [
                                    "Comece pela definição canônica para evitar interpretações erradas.",
                                    "Use diagramas simples para visualizar processadores e memória."
                                  ],
                                  "learningObjective": "Compreender o PRAM como modelo abstrato para paralelismo idealizado.",
                                  "commonMistakes": [
                                    "Confundir PRAM com hardware real em vez de modelo teórico.",
                                    "Ignorar a memória compartilhada como elemento central."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a arquitetura e operações básicas do PRAM",
                                  "subSteps": [
                                    "Descreva a topologia: P processadores conectados a uma memória de M palavras.",
                                    "Explique as operações síncronas: em cada passo, todos processadores executam a mesma instrução.",
                                    "Detalhe o modelo de escrita: como lidar com conflitos (ex: última escrita vence).",
                                    "Simule uma operação simples de soma paralela com 4 processadores.",
                                    "Liste instruções básicas: READ, WRITE, COMPUTE."
                                  ],
                                  "verification": "Desenhe um diagrama da arquitetura e simule uma operação básica por escrito.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta para diagramas",
                                    "Simulador online de PRAM (se disponível) ou pseudocódigo",
                                    "Notas de aula sobre sincronização paralela"
                                  ],
                                  "tips": [
                                    "Use pseudocódigo para ilustrar operações em vez de código real.",
                                    "Foquem em simultaneidade: todos processadores agem ao mesmo tempo."
                                  ],
                                  "learningObjective": "Dominar a estrutura operacional do PRAM e suas instruções fundamentais.",
                                  "commonMistakes": [
                                    "Assumir assincronia quando o modelo é estritamente síncrono.",
                                    "Subestimar o impacto de conflitos de memória."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Classificar as variantes do PRAM e suas regras de conflito",
                                  "subSteps": [
                                    "Defina EREW (Exclusive Read Exclusive Write): sem acessos concorrentes.",
                                    "Explique CREW (Concurrent Read Exclusive Write): leituras simultâneas permitidas.",
                                    "Descreva CRCW (Concurrent Read Concurrent Write): acessos concorrentes com regras (ex: comum, prioridade).",
                                    "Compare eficiência entre variantes com exemplos de algoritmos.",
                                    "Analise quando usar cada uma em análises assintóticas."
                                  ],
                                  "verification": "Crie uma tabela comparativa das variantes com exemplos de conflitos resolvidos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Tabela em Excel ou papel",
                                    "Referências: capítulos sobre PRAM em livros de JaJa ou Leighton"
                                  ],
                                  "tips": [
                                    "Memorize acrônimos associando a regras específicas de read/write.",
                                    "Use exemplos numéricos para ilustrar conflitos."
                                  ],
                                  "learningObjective": "Diferenciar variantes do PRAM e suas implicações em algoritmos.",
                                  "commonMistakes": [
                                    "Confundir CREW com CRCW nas regras de escrita.",
                                    "Ignorar que EREW é o mais restritivo e eficiente em alguns casos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar vantagens, limitações e análise de complexidade",
                                  "subSteps": [
                                    "Liste vantagens: simplicidade para análise teórica (tempo T e processadores P).",
                                    "Discuta limitações: não realista para hardware (contenção de memória).",
                                    "Aprenda notação de complexidade: tempo T(P) ou work-time framework.",
                                    "Exemplo: análise do algoritmo de prefix sum no PRAM.",
                                    "Conclua com papel do PRAM na teoria de paralelismo."
                                  ],
                                  "verification": "Escreva um relatório curto (200 palavras) sobre prós, contras e um exemplo de análise.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Pseudocódigo de algoritmos PRAM padrão",
                                    "Calculadora para simular complexidades"
                                  ],
                                  "tips": [
                                    "Relacione complexidade com speedup: S = T_seq / T_par.",
                                    "Considere bridges para modelos reais como BSP."
                                  ],
                                  "learningObjective": "Avaliar o PRAM criticamente em contextos teóricos e práticos.",
                                  "commonMistakes": [
                                    "Superestimar aplicabilidade prática sem mencionar limitações.",
                                    "Erros em cálculos de complexidade paralela."
                                  ]
                                }
                              ],
                              "practicalExample": "Simule o algoritmo de busca paralela em uma lista de 8 elementos usando PRAM-CRCW: 8 processadores verificam elementos simultaneamente, resolvendo conflitos por prioridade para reportar o índice do primeiro match.",
                              "finalVerifications": [
                                "Definição precisa do PRAM incluindo processadores e memória compartilhada.",
                                "Correta distinção entre variantes EREW, CREW e CRCW.",
                                "Exemplo válido de operação com análise de conflitos.",
                                "Explicação de sincronismo e idealizações do modelo.",
                                "Comparação sucinta com modelos reais de memória compartilhada.",
                                "Uso correto da notação de complexidade paralela."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definição e componentes: 30%)",
                                "Compreensão de variantes e regras de conflito (25%)",
                                "Capacidade de análise de complexidade e exemplos (20%)",
                                "Clareza na descrição de operações e diagramas (15%)",
                                "Crítica sobre limitações e aplicações (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Teoria da Computação: extensão da Máquina de Turing para paralelismo.",
                                "Algoritmos e Estruturas de Dados: análise assintótica paralela.",
                                "Arquitetura de Computadores: inspiração para multiprocessadores SMP.",
                                "Matemática Discreta: modelos de grafos e prefix computations."
                              ],
                              "realWorldApplication": "O PRAM serve como benchmark teórico para otimizar algoritmos em supercomputadores e GPUs (ex: CUDA usa conceitos semelhantes para análise de paralelismo em memória unificada), ajudando no design de software paralelo escalável."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.2.3.3",
                            "name": "Relacionar com linguagens como OpenMP",
                            "description": "Associar classificações de memória com diretivas de OpenMP para programação em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Classificações de Modelos de Memória Compartilhada",
                                  "subSteps": [
                                    "Estude os conceitos básicos de UMA (Uniform Memory Access), onde todos os processadores acessam a memória no mesmo tempo.",
                                    "Analise NUMA (Non-Uniform Memory Access), destacando latências variáveis baseadas na proximidade da memória.",
                                    "Compare COMA (Cache-Only Memory Access) e outros modelos híbridos, focando em impactos na programação paralela.",
                                    "Identifique características chave como latência, largura de banda e localidade de dados em cada modelo.",
                                    "Crie um diagrama comparativo das classificações."
                                  ],
                                  "verification": "Crie uma tabela ou diagrama resumindo diferenças entre UMA, NUMA e COMA, com exemplos de hardware.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação de arquitetura de computadores, diagramas de UMA/NUMA online, papel e caneta para esboços.",
                                  "tips": "Use analogias como 'UMA é como uma sala de aula com prateleiras centrais; NUMA é como bibliotecas em prédios vizinhos'.",
                                  "learningObjective": "Compreender as diferenças fundamentais entre classificações de memória compartilhada e seus impactos em performance.",
                                  "commonMistakes": "Confundir latência local/remota em NUMA com falhas de cache; ignorar evoluções para CC-NUMA."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir Diretivas Básicas do OpenMP",
                                  "subSteps": [
                                    "Instale o compilador com suporte OpenMP (ex: gcc com -fopenmp).",
                                    "Aprenda diretivas principais: #pragma omp parallel, #pragma omp for, #pragma omp sections.",
                                    "Estude cláusulas de dados: shared, private, firstprivate, reduction.",
                                    "Compile e execute um programa simples de paralelização de loop.",
                                    "Analise saída com variáveis de ambiente como OMP_NUM_THREADS."
                                  ],
                                  "verification": "Compile e execute um código OpenMP que paraleliza soma de array, verificando escalabilidade com 1-8 threads.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Compilador GCC/Clang, editor de código (VS Code), exemplos de código OpenMP do site oficial.",
                                  "tips": "Sempre inicialize variáveis antes de paralelizar para evitar comportamentos indefinidos.",
                                  "learningObjective": "Dominar sintaxe e execução básica de diretivas OpenMP para gerenciamento de threads.",
                                  "commonMistakes": "Esquecer cláusula shared/private levando a races; não definir OMP_NUM_THREADS."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Associar Classificações de Memória com Diretivas OpenMP",
                                  "subSteps": [
                                    "Mapeie UMA para diretivas simples sem afinidade (ex: omp for shared).",
                                    "Explore impactos NUMA: use OMP_PROC_BIND e OMP_PLACES para pinning de threads.",
                                    "Implemente cláusulas como allocate e map em OpenMP 5.0 para controle NUMA.",
                                    "Teste performance em máquina NUMA (use numactl para simular).",
                                    "Analise relatórios de ferramentas como likwid ou Intel VTune para bottlenecks de memória."
                                  ],
                                  "verification": "Modifique código OpenMP para UMA vs NUMA, medindo tempo de execução com/ sem pinning.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Máquina multicores (ideal com numactl), ferramentas perf/likwid, documentação OpenMP 4.5/5.0.",
                                  "tips": "Em NUMA, priorize localidade: declare variáveis private ou use first-touch policy.",
                                  "learningObjective": "Relacionar modelos de memória com escolhas de diretivas OpenMP para otimização.",
                                  "commonMistakes": "Ignorar topologia NUMA, causando thrashing; usar shared sem considerar falsos compartilhamentos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e Otimizar Exemplos Práticos",
                                  "subSteps": [
                                    "Desenvolva código para matrix multiplication otimizado para UMA (chunking em omp for).",
                                    "Adapte para NUMA com omp distribute e affinity.",
                                    "Inclua sincronizações: barriers, critical, atomic para dados compartilhados.",
                                    "Meça speedup e eficiência com diferentes configurações de memória.",
                                    "Refatore código para portabilidade entre UMA/NUMA."
                                  ],
                                  "verification": "Execute benchmarks mostrando >80% eficiência em plataforma multicores, com gráficos de speedup.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Códigos fonte de benchmarks (NAS Parallel Benchmarks adaptados), gnuplot para gráficos.",
                                  "tips": "Use schedule(dynamic) em loops irregulares para balanceamento em NUMA.",
                                  "learningObjective": "Aplicar associações teóricas em códigos otimizados para diferentes modelos de memória.",
                                  "commonMistakes": "Sobrecarregar sincronizações desnecessárias; não validar com profiling."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e Refinar Conhecimento",
                                  "subSteps": [
                                    "Revise erros comuns em fóruns OpenMP.",
                                    "Crie um checklist para seleção de diretivas baseado em modelo de memória.",
                                    "Teste cenários edge-case como migração de threads.",
                                    "Documente lições aprendidas em um relatório.",
                                    "Discuta com pares ou tutor."
                                  ],
                                  "verification": "Produza relatório com 3 exemplos otimizados e análise de performance.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Fóruns OpenMP.org, template de relatório.",
                                  "tips": "Sempre profile antes/depois de otimizações para evidências quantitativas.",
                                  "learningObjective": "Sintetizar associações e desenvolver práticas para programação paralela robusta.",
                                  "commonMistakes": "Generalizar otimizações UMA para NUMA sem testes."
                                }
                              ],
                              "practicalExample": "Em uma aplicação de multiplicação de matrizes 1000x1000 em servidor NUMA (2 sockets AMD EPYC), use #pragma omp target teams distribute parallel for collapse(2) com OMP_PROC_BIND=spread para distribuir threads localmente, reduzindo tempo de 45s (sem otimiz.) para 12s, medido via numactl --membind=0.",
                              "finalVerifications": [
                                "Explicar verbalmente como UMA difere de NUMA e impacto em OpenMP.",
                                "Executar código OpenMP com pinning e mostrar logs de affinity.",
                                "Identificar race condition em código dado e corrigi-la com diretivas.",
                                "Comparar tempos de execução UMA vs NUMA em benchmark simples.",
                                "Listar 3 cláusulas OpenMP para otimização NUMA.",
                                "Criar diagrama de fluxo de decisão para escolha de diretivas por modelo de memória."
                              ],
                              "assessmentCriteria": [
                                "Precisão na associação de modelos de memória com diretivas (90%+ correto).",
                                "Eficiência de códigos implementados (speedup > 70% de threads ideais).",
                                "Uso correto de cláusulas de dados e sincronização sem erros.",
                                "Análise quantitativa com métricas de performance (tempos, profiling).",
                                "Criatividade em exemplos práticos e otimizações.",
                                "Clareza na documentação e verificações finais."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Topologias de cache e interconexões.",
                                "Otimização de Algoritmos: Balanceamento de carga em loops paralelos.",
                                "Sistemas Operacionais: Políticas de alocação de memória e scheduling.",
                                "Engenharia de Software: Portabilidade e profiling de performance.",
                                "Matemática Computacional: Paralelização de operações lineares."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500 (ex: Frontier), OpenMP com awareness NUMA acelera simulações CFD/clima em 2-5x, reduzindo tempo de jobs de dias para horas em data centers HPC."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.3",
                    "name": "Decomposição de Domínio",
                    "description": "Técnica de divisão do domínio do problema em subdomínios independentes para processamento paralelo.",
                    "individualConcepts": [
                      {
                        "id": "10.1.3.3.1",
                        "name": "Definição e Fundamentos da Decomposição de Domínio",
                        "description": "Compreensão dos princípios básicos da decomposição de domínio como técnica para dividir o espaço de dados do problema em subdomínios independentes, facilitando o processamento paralelo em arquiteturas de memória compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.3.1.1",
                            "name": "Identificar o domínio do problema",
                            "description": "Reconhecer e delimitar o domínio espacial ou lógico de um problema computacional, como grades em simulações numéricas ou arrays em processamento de imagens, preparando-o para divisão paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar o Problema Geral",
                                  "subSteps": [
                                    "Leia a descrição completa do problema computacional.",
                                    "Identifique o objetivo principal e os dados de entrada/saída.",
                                    "Liste os componentes independentes ou repetitivos no problema.",
                                    "Anote restrições como tamanho dos dados ou ambiente de execução.",
                                    "Resuma o problema em uma frase focada no aspecto computacional."
                                  ],
                                  "verification": "Criar um resumo escrito do problema com componentes chave destacados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Descrição do problema, papel e caneta ou editor de texto.",
                                  "tips": "Foquem em 'o quê' processar, não 'como' paralelizar ainda.",
                                  "learningObjective": "Compreender o escopo geral do problema para isolar o domínio.",
                                  "commonMistakes": "Confundir o domínio com a solução paralela prematuramente."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Elementos Espaciais ou Lógicos Iteráveis",
                                  "subSteps": [
                                    "Procure por estruturas de dados como arrays, matrizes ou grades.",
                                    "Detecte loops ou iterações sobre conjuntos de dados.",
                                    "Classifique se o domínio é 1D (vetor), 2D (imagem/grade) ou 3D (volume).",
                                    "Marque dependências locais entre elementos (ex: vizinhos em grade).",
                                    "Desenhe um diagrama simples representando os elementos."
                                  ],
                                  "verification": "Produzir um diagrama anotado mostrando elementos iteráveis.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Ferramenta de desenho (ex: Draw.io, papel), código fonte do problema.",
                                  "tips": "Pergunte: 'Quais partes podem ser processadas separadamente?'",
                                  "learningObjective": "Reconhecer padrões de domínio espacial/lógico em problemas.",
                                  "commonMistakes": "Ignorar dependências que afetam a independência dos elementos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Delimitar as Fronteiras do Domínio",
                                  "subSteps": [
                                    "Defina os limites exatos (ex: índices de 0 a N-1 em array).",
                                    "Identifique condições de borda (ex: pixels nas extremidades de imagem).",
                                    "Especifique dimensões e tamanho total do domínio.",
                                    "Verifique se o domínio é regular (grade uniforme) ou irregular.",
                                    "Documente regras para divisão futura (ex: blocos NxN)."
                                  ],
                                  "verification": "Escrever uma especificação formal das fronteiras com exemplos numéricos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Editor de texto, exemplos de dados do problema.",
                                  "tips": "Use notação matemática: Domínio D = { (i,j) | 0 ≤ i < rows, 0 ≤ j < cols }.",
                                  "learningObjective": "Estabelecer limites precisos para decomposição paralela.",
                                  "commonMistakes": "Definir limites vagos sem índices ou dimensões exatas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e Representar o Domínio",
                                  "subSteps": [
                                    "Simule um pequeno exemplo manualmente no domínio delimitado.",
                                    "Confirme independência parcial para paralelismo.",
                                    "Crie uma representação abstrata (ex: pseudocódigo de iteração).",
                                    "Discuta potenciais partições iniciais.",
                                    "Revise com um colega ou autoavaliação."
                                  ],
                                  "verification": "Gerar pseudocódigo que itera exatamente no domínio identificado.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Pseudocódigo editor, pequeno dataset de teste.",
                                  "tips": "Teste com N=4 para visualizar facilmente.",
                                  "learningObjective": "Garantir que o domínio esteja pronto para decomposição.",
                                  "commonMistakes": "Sobrestimar independência sem validação prática."
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão de calor em uma grade 2D de 1000x1000 células, o domínio é a grade inteira onde cada célula (i,j) atualiza seu valor baseado nos 4 vizinhos, com bordas fixas em 0. Identifique como array[1000][1000], delimitado por 0≤i<1000, 0≤j<1000.",
                              "finalVerifications": [
                                "Descrição escrita clara do domínio com dimensões e limites.",
                                "Diagrama visual do domínio com exemplos de elementos.",
                                "Pseudocódigo que itera precisamente no domínio.",
                                "Identificação correta de pelo menos um tipo de dependência local.",
                                "Exemplo pequeno simulado manualmente sem erros.",
                                "Preparação explícita para divisão em subdomínios."
                              ],
                              "assessmentCriteria": [
                                "Precisão na delimitação de limites (100% cobertura sem extrapolação).",
                                "Identificação completa de estruturas espaciais/lógicas (mín. 90% relevantes).",
                                "Clareza e formalidade na representação (notação matemática usada).",
                                "Validação prática via simulação pequena (sem discrepâncias).",
                                "Consideração de bordas e dependências (todas abordadas).",
                                "Preparação para paralelismo (independência destacada)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Geometria discreta e conjuntos em grades.",
                                "Física: Modelagem de simulações numéricas (ex: equações diferenciais).",
                                "Engenharia de Software: Análise de complexidade e estruturas de dados.",
                                "Ciência da Computação: Algoritmos de processamento paralelo em HPC."
                              ],
                              "realWorldApplication": "Em processamento de imagens no Photoshop ou GIMP, identificar o domínio como pixels de uma imagem 4K permite dividir tarefas como filtros blur em threads paralelas, acelerando renderização em GPUs para edição em tempo real."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.3.1.2",
                            "name": "Explicar independência de subdomínios",
                            "description": "Descrever como subdomínios devem ser projetados para minimizar dependências, reduzindo sincronizações e comunicações em modelos de memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Conceitos Fundamentais de Subdomínios e Dependências",
                                  "subSteps": [
                                    "Defina subdomínios como partições lógicas do domínio de problema em programação paralela para memória compartilhada.",
                                    "Explique dependências como interações entre subdomínios que requerem leitura/escrita compartilhada de dados.",
                                    "Diferencie dependências de dados (leitura/escrita) de dependências de controle (ordenação de execução).",
                                    "Ilustre com um diagrama simples de um domínio dividido em subdomínios interdependentes.",
                                    "Discuta o impacto inicial das dependências em performance."
                                  ],
                                  "verification": "Crie um diagrama anotado mostrando subdomínios com e sem dependências, e explique verbalmente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Papel e caneta ou ferramenta de diagramação como Draw.io; slides introdutórios sobre decomposição de domínio.",
                                  "tips": "Use analogias como 'ilhas independentes' vs. 'continentes conectados por pontes' para visualizar.",
                                  "learningObjective": "Compreender os termos chave e identificar dependências básicas em um domínio.",
                                  "commonMistakes": "Confundir dependências de dados com sincronizações de thread; ignorar dependências de controle."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Impactos de Dependências em Memória Compartilhada",
                                  "subSteps": [
                                    "Descreva como dependências causam sincronizações (locks, barriers) e comunicações (envio de mensagens).",
                                    "Calcule overhead: tempo de sincronização vs. tempo de computação pura.",
                                    "Compare performance: escalabilidade linear em subdomínios independentes vs. sublinear em dependentes.",
                                    "Simule um cenário simples com pseudocódigo mostrando atrasos por dependências.",
                                    "Quantifique redução de performance com métricas como speedup e eficiência."
                                  ],
                                  "verification": "Escreva um parágrafo explicando por que minimizar dependências melhora paralelismo, com exemplo numérico.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Pseudocódigo editor (VS Code); calculadora ou planilha para métricas de performance.",
                                  "tips": "Foquem em Amdahl's Law para quantificar limites de speedup devido a partes dependentes.",
                                  "learningObjective": "Explicar quantitativamente como dependências reduzem eficiência em modelos de memória compartilhada.",
                                  "commonMistakes": "Subestimar custo de comunicações em redes de alta latência; ignorar falsos compartilhamentos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Desenvolver Princípios de Design para Independência de Subdomínios",
                                  "subSteps": [
                                    "Princípio 1: Atribuir dados privados a cada subdomínio (localidade de dados).",
                                    "Princípio 2: Projetar computações autônomas com boundaries claras (ghost cells ou halos mínimos).",
                                    "Princípio 3: Usar decomposição regular (grids) para minimizar interfaces.",
                                    "Princípio 4: Aplicar técnicas como domain replication para leituras-only.",
                                    "Princípio 5: Validar independência com análise estática de dependências."
                                  ],
                                  "verification": "Liste 3-5 princípios em um mindmap e aplique a um domínio de exemplo.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Ferramenta de mindmapping (MindMeister); exemplos de código OpenMP ou MPI shared memory.",
                                  "tips": "Comece com decomposições 1D para simplicidade antes de 2D/3D.",
                                  "learningObjective": "Dominar estratégias práticas para projetar subdomínios com mínima interdependência.",
                                  "commonMistakes": "Criar subdomínios muito pequenos aumentando overhead de gerenciamento; negligenciar boundaries dinâmicos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Verificar Independência em um Exemplo Prático",
                                  "subSteps": [
                                    "Escolha um problema: multiplicação de matrizes ou simulação de difusão.",
                                    "Decomponha em subdomínios independentes usando princípios aprendidos.",
                                    "Implemente pseudocódigo paralelo minimizando sincronizações.",
                                    "Teste performance: rode com diferentes granularidades e meça comunicações.",
                                    "Refatore um design dependente para independente e compare."
                                  ],
                                  "verification": "Produza código comentado e gráfico de performance mostrando redução de sincronizações.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Compilador C++ com OpenMP; profiler como gprof ou Intel VTune.",
                                  "tips": "Use #pragma omp parallel for com private variables para demonstrar independência.",
                                  "learningObjective": "Integrar conceitos em design prático e validar independência empiricamente.",
                                  "commonMistakes": "Esquecer atualizações de boundaries levando a race conditions; over-decompor reduzindo eficiência."
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão em grade 2D (equação de calor), divida a grade em subdomínios retangulares. Cada subdomínio computa interior independentemente usando ghost cells nas bordas para trocas mínimas, reduzindo sincronizações de all-reduce para halo exchanges apenas nas bordas, permitindo speedup quase linear em 100s de threads.",
                              "finalVerifications": [
                                "Explicar verbalmente independência sem consultar notas.",
                                "Identificar dependências em um diagrama dado de subdomínios.",
                                "Projetar decomposição independente para um novo domínio simples.",
                                "Comparar overhead de dois designs (dependente vs. independente).",
                                "Listar 3 princípios chave e dar exemplos.",
                                "Simular performance com Amdahl's Law para cenários variados."
                              ],
                              "assessmentCriteria": [
                                "Clareza e precisão na definição de independência (20%)",
                                "Profundidade na explicação de impactos em sincronizações/comunicações (25%)",
                                "Criatividade e correção nos princípios de design (25%)",
                                "Qualidade do exemplo prático e verificações (15%)",
                                "Uso correto de terminologia e conceitos paralelos (10%)",
                                "Capacidade de quantificar benefícios (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Decomposição de domínios em PDEs numéricas.",
                                "Engenharia de Software: Princípios de modularidade e baixo acoplamento.",
                                "Ciência da Computação: Análise de complexidade e grafos de dependências.",
                                "Física Computacional: Simulações paralelas em grids estruturados."
                              ],
                              "realWorldApplication": "Em supercomputação para modelagem climática (ex: CESM), subdomínios independentes da atmosfera/oceano minimizam comunicações globais, permitindo escalar para exaflops em máquinas como Frontier, reduzindo tempo de simulação de meses para dias."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.3.1.3",
                            "name": "Diferenciar de outros modelos de decomposição",
                            "description": "Comparar decomposição de domínio com decomposição funcional e de tarefas, destacando sua adequação para problemas com estrutura de dados regular em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Definição e Características da Decomposição de Domínio",
                                  "subSteps": [
                                    "Leia a definição formal de decomposição de domínio: divisão do problema em subdomínios espaciais ou temporais independentes.",
                                    "Identifique características chave: adequação para dados regulares, independência de tarefas, uso em memória compartilhada.",
                                    "Anote exemplos iniciais como processamento de matrizes ou imagens.",
                                    "Registre vantagens: simplicidade em paralelização estática e escalabilidade em grids regulares.",
                                    "Compare brevemente com serialização para fixar conceitos."
                                  ],
                                  "verification": "Resuma em 3-5 frases as características principais e liste 2 exemplos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação de programação paralela (ex: OpenMP tutorial)",
                                    "Notas de aula sobre modelos de decomposição"
                                  ],
                                  "tips": "Use diagramas para visualizar divisão de domínio em grades.",
                                  "learningObjective": "Compreender os fundamentos da decomposição de domínio e suas premissas.",
                                  "commonMistakes": "Confundir com divisão de tarefas dinâmicas; foque em estrutura estática."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar Decomposição Funcional",
                                  "subSteps": [
                                    "Defina decomposição funcional: divisão baseada em funções independentes do programa.",
                                    "Liste características: tarefas heterogêneas, dependências funcionais mínimas, independência de dados.",
                                    "Examine exemplos: pipeline de processamento onde cada função é uma etapa paralelizável.",
                                    "Anote desvantagens em memória compartilhada: overhead de sincronização em funções acopladas.",
                                    "Compare superficialmente com domínio para preparar contraste."
                                  ],
                                  "verification": "Crie uma tabela com 4 características únicas da decomposição funcional.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Livro 'Introduction to Parallel Computing' (Grama et al.)",
                                    "Vídeos Khan Academy ou YouTube sobre decomposição funcional"
                                  ],
                                  "tips": "Pense em fluxos de trabalho como compiladores para exemplos intuitivos.",
                                  "learningObjective": "Dominar os princípios da decomposição funcional e suas diferenças iniciais.",
                                  "commonMistakes": "Ignorar dependências de dados; sempre verifique acoplamento funcional."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Decomposição de Tarefas",
                                  "subSteps": [
                                    "Defina decomposição de tarefas: divisão em tarefas granulares com dependências de controle.",
                                    "Descreva características: tarefas pequenas, grafo de dependências, adequação para cargas irregulares.",
                                    "Estude exemplos: busca em grafos ou simulações com eventos discretos.",
                                    "Registre limitações em memória compartilhada: alto overhead de gerenciamento de tarefas.",
                                    "Prepare anotações para comparação futura."
                                  ],
                                  "verification": "Desenhe um grafo simples de dependências de tarefas para um exemplo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tutoriais Pthreads ou Task-based parallelism em C++",
                                    "Artigos sobre OpenMP tasks"
                                  ],
                                  "tips": "Use ferramentas como draw.io para grafos de tarefas.",
                                  "learningObjective": "Entender a decomposição de tarefas e seu foco em controle dinâmico.",
                                  "commonMistakes": "Confundir com domínio; tarefas são irregulares vs. regulares em domínio."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar e Diferenciar os Modelos",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: colunas para domínio, funcional e tarefas (linhas: independência de dados, granularidade, adequação a dados regulares, overhead em memória compartilhada).",
                                    "Destaque diferenças chave: domínio para estruturas regulares vs. funcional para pipelines vs. tarefas para irregulares.",
                                    "Explique adequação de domínio: baixa sincronização em dados compartilhados regulares.",
                                    "Identifique cenários: domínio em simulações numéricas, outros em fluxos variados.",
                                    "Teste compreensão respondendo perguntas de diferenciação."
                                  ],
                                  "verification": "Preencha e revise a tabela comparativa com pelo menos 5 critérios.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Planilha Google Sheets ou papel para tabela",
                                    "Resumos dos steps anteriores"
                                  ],
                                  "tips": "Use cores na tabela para destacar forças/fracos de cada modelo.",
                                  "learningObjective": "Diferenciar precisamente os modelos e justificar escolhas.",
                                  "commonMistakes": "Generalizar demais; foque em contexto de memória compartilhada."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar Diferenciação em um Cenário Prático",
                                  "subSteps": [
                                    "Escolha um problema (ex: multiplicação de matrizes) e justifique decomposição de domínio.",
                                    "Adapte para funcional (ex: pipeline de FFT) e tarefas (ex: busca paralela).",
                                    "Avalie trade-offs em memória compartilhada: tempo, escalabilidade.",
                                    "Registre conclusão: domínio ideal para regularidade de dados.",
                                    "Autoavalie com perguntas de verificação."
                                  ],
                                  "verification": "Escreva um parágrafo justificando escolha de modelo para 2 problemas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código exemplo em OpenMP para matrizes",
                                    "Simulador online de paralelismo"
                                  ],
                                  "tips": "Implemente pseudocódigo para visualizar diferenças.",
                                  "learningObjective": "Aplicar diferenciação para seleção de modelo adequada.",
                                  "commonMistakes": "Escolher errado por viés; baseie em estrutura de dados."
                                }
                              ],
                              "practicalExample": "Em processamento de imagem (ex: filtro Gaussiano), decomposição de domínio divide a imagem em blocos de pixels independentes (paralelização estática via OpenMP sections); funcional seria pipeline de convolução-filtro-normalização; tarefas para detecção de bordas irregulares. Domínio destaca-se por grade regular sem dependências.",
                              "finalVerifications": [
                                "Explique em 100 palavras por que decomposição de domínio é superior para matrizes regulares em memória compartilhada.",
                                "Classifique 3 problemas hipotéticos (imagem, grafo, pipeline) no modelo correto e justifique.",
                                "Descreva 2 desvantagens de funcional/tarefas vs. domínio em cenários compartilhados.",
                                "Crie um fluxograma comparativo dos 3 modelos.",
                                "Responda quiz: 'Qual modelo para dados irregulares? Por quê?'",
                                "Liste 3 critérios para escolher domínio sobre os outros."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições (90% acerto em termos chave).",
                                "Clareza na tabela comparativa (todos critérios cobertos com exemplos).",
                                "Profundidade na justificativa de adequação (contexto memória compartilhada).",
                                "Uso correto de exemplos práticos e trade-offs.",
                                "Capacidade de aplicação independente em novos cenários.",
                                "Ausência de confusões entre modelos (ex: regular vs. irregular)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Divisão de domínios em grids e álgebra linear para matrizes.",
                                "Física/Engenharia: Simulações numéricas (CFD) onde domínio espacial é natural.",
                                "Ciência de Dados: Processamento paralelo de arrays em ML (ex: NumPy/OpenMP).",
                                "Algoritmos: Análise de complexidade em paralelismo vs. serial."
                              ],
                              "realWorldApplication": "Em supercomputação para modelagem climática (divisão de grade terrestre em domínios para simulações paralelas em memória compartilhada), superando funcional (para pipelines de dados meteorológicos) ou tarefas (para eventos discretos como furacões), reduzindo overhead e escalando linearmente."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.3.2",
                        "name": "Estratégias de Particionamento do Domínio",
                        "description": "Técnicas para dividir o domínio em subdomínios balanceados e eficientes, considerando carga de trabalho e overheads em plataformas multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.3.2.1",
                            "name": "Aplicar particionamento geométrico",
                            "description": "Implementar divisão em blocos ou tiras para domínios regulares, como em métodos de diferenças finitas, garantindo equilíbrio de carga em threads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos do particionamento geométrico",
                                  "subSteps": [
                                    "Estudar domínios regulares como grades 2D ou 3D.",
                                    "Diferenciar particionamento em blocos (2D) e tiras (1D).",
                                    "Analisar vantagens: simplicidade em métodos de diferenças finitas.",
                                    "Revisar conceitos de equilíbrio de carga em threads.",
                                    "Explorar exemplos visuais de divisão de malhas."
                                  ],
                                  "verification": "Resumir em um diagrama as diferenças entre blocos e tiras.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação OpenMP",
                                    "Artigos sobre decomposição de domínio",
                                    "Ferramenta de desenho como Draw.io"
                                  ],
                                  "tips": "Use diagramas para visualizar a divisão do domínio.",
                                  "learningObjective": "Identificar tipos de particionamento geométrico e suas aplicações em programação paralela.",
                                  "commonMistakes": [
                                    "Confundir blocos com tiras",
                                    "Ignorar overhead de comunicação entre partições"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o domínio e projetar o particionamento",
                                  "subSteps": [
                                    "Definir dimensões do domínio (ex: grid NxM).",
                                    "Escolher estratégia: tiras para pouca comunicação ou blocos para escalabilidade.",
                                    "Calcular tamanho de cada partição para equilíbrio (divisão uniforme).",
                                    "Mapear partições para threads disponíveis.",
                                    "Desenhar esquema de índices para acesso aos dados."
                                  ],
                                  "verification": "Criar um esboço manual da divisão para um grid 100x100 com 4 threads.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Papel e lápis ou software de diagramação",
                                    "Exemplos de código de diferenças finitas"
                                  ],
                                  "tips": "Priorize tiras para domínios com dependências locais em uma dimensão.",
                                  "learningObjective": "Projetar um particionamento equilibrado para um domínio dado.",
                                  "commonMistakes": [
                                    "Partições desiguais levando a desbalanceamento",
                                    "Esquecer ghost cells nas bordas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar o particionamento em código paralelo",
                                  "subSteps": [
                                    "Configurar loop paralelo com OpenMP (schedule static ou dynamic).",
                                    "Implementar cálculo de início e fim de índices por thread.",
                                    "Gerenciar trocas de dados nas bordas (halo exchange).",
                                    "Codificar iterações do método de diferenças finitas.",
                                    "Compilar e executar com diferentes números de threads."
                                  ],
                                  "verification": "Código executa sem erros e produz saída correta para caso serial vs paralelo.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador GCC com suporte OpenMP",
                                    "Editor de código (VS Code)",
                                    "Exemplo base de stencil 2D"
                                  ],
                                  "tips": "Use #pragma omp parallel for com bounds calculados dinamicamente.",
                                  "learningObjective": "Codificar particionamento geométrico funcional em memória compartilhada.",
                                  "commonMistakes": [
                                    "Race conditions em bordas compartilhadas",
                                    "Índices off-by-one nas partições"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar equilíbrio de carga e otimizar",
                                  "subSteps": [
                                    "Medir tempo por thread com omp_get_wtime().",
                                    "Analisar speedup e eficiência com mais threads.",
                                    "Ajustar particionamento para irregularidades no domínio.",
                                    "Comparar com versão serial para corretude.",
                                    "Perfilhar com ferramentas como gprof ou VTune."
                                  ],
                                  "verification": "Gráfico de speedup linear ou próximo com aumento de threads.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Ferramenta de profiling OpenMP",
                                    "Planilhas para gráficos de performance"
                                  ],
                                  "tips": "Monitore variância no tempo de threads para detectar desbalanceamento.",
                                  "learningObjective": "Avaliar e otimizar o particionamento para performance paralela.",
                                  "commonMistakes": [
                                    "Otimizar sem validar corretude numérica",
                                    "Ignorar overhead de sincronização"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de difusão de calor em um grid 512x512 usando método de diferenças finitas explícito, divida em 8 tiras horizontais para 8 threads OpenMP, calculando índices start = (thread_id * rows)/num_threads e end = ((thread_id+1) * rows)/num_threads, com troca de halos nas bordas.",
                              "finalVerifications": [
                                "Código compila e executa corretamente com múltiplos threads.",
                                "Solução numérica converge para o mesmo resultado serial.",
                                "Tempo por thread varia <10% entre partições.",
                                "Speedup próximo de linear até número de threads disponíveis.",
                                "Ausência de data races detectada por ferramentas como ThreadSanitizer.",
                                "Perfil de performance mostra balanceamento de carga."
                              ],
                              "assessmentCriteria": [
                                "Precisão na divisão de índices e gerenciamento de bordas (90%+ corretude).",
                                "Eficiência de balanceamento (variância de tempo <15%).",
                                "Corretude numérica comparada à versão sequencial (erro <1e-6).",
                                "Escalabilidade demonstrada com 2-16 threads.",
                                "Código limpo com comentários e estrutura modular.",
                                "Análise de performance documentada com gráficos."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Métodos numéricos e álgebra linear para diferenças finitas.",
                                "Física: Simulações de equações diferenciais parciais (calor, onda).",
                                "Engenharia de Computação: Arquitetura de paralelismo em memória compartilhada.",
                                "Análise de Algoritmos: Complexidade e otimização de workloads.",
                                "Visualização de Dados: Geração de heatmaps para validação."
                              ],
                              "realWorldApplication": "Usado em simulações CFD (dinâmica de fluidos computacional) para previsão meteorológica, processamento de imagens médicas (segmentação paralela) e modelagem climática, onde grids regulares são divididos em blocos/tiras para aceleração em clusters multi-core."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.3.3.2.2",
                            "name": "Gerenciar fronteiras entre subdomínios",
                            "description": "Tratar regiões de halo ou ghost cells para resolver dependências locais em iterações paralelas, minimizando falsos compartilhamentos em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Problema de Fronteiras em Decomposição de Domínio",
                                  "subSteps": [
                                    "Analise uma grade 2D dividida entre processos paralelos e identifique dependências locais nas bordas adjacentes.",
                                    "Estude iterações paralelas onde atualizações em um subdomínio afetam vizinhos devido a operações stencil.",
                                    "Identifique falsos compartilhamentos: regiões onde threads/processos acessam memória não própria desnecessariamente.",
                                    "Desenhe diagramas de uma grade particionada mostrando regiões de fronteira problemáticas.",
                                    "Compare abordagens sem gerenciamento (race conditions) vs. com gerenciamento (halo cells)."
                                  ],
                                  "verification": "Crie um diagrama anotado da grade mostrando dependências de fronteira e explique em um relatório curto.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Papel e caneta ou ferramenta de diagramação (Draw.io), documentação de MPI/OpenMP sobre decomposição.",
                                  "tips": "Comece com uma grade pequena (4x4) para visualizar claramente as dependências.",
                                  "learningObjective": "Reconhecer dependências locais nas fronteiras e impactos em paralelismo.",
                                  "commonMistakes": "Ignorar dependências diagonais em stencils 2D; assumir independência total entre subdomínios."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir Conceito de Halo ou Ghost Cells",
                                  "subSteps": [
                                    "Defina halo cells como camadas extras ao redor de cada subdomínio para armazenar valores vizinhos.",
                                    "Calcule o tamanho do halo baseado no raio do stencil (ex: raio 1 = 1 célula em cada direção).",
                                    "Planeje alocação de memória: subdomínio real + halo em todas as bordas.",
                                    "Discuta diferenças entre memória compartilhada (OpenMP) e distribuída (MPI).",
                                    "Implemente alocação estática de arrays com halo em código sequencial primeiro."
                                  ],
                                  "verification": "Escreva um código sequencial que aloca e inicializa uma grade com halo cells, imprimindo dimensões.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Compilador C/C++ com OpenMP/MPI, editor de código (VS Code), tutoriais de halo cells em stencil computations.",
                                  "tips": "Use índices offset para acessar halo: halo_width para bordas esquerda/direita, etc.",
                                  "learningObjective": "Dominar alocação e conceituação de regiões halo para resolver dependências.",
                                  "commonMistakes": "Erro no tamanho do halo (ex: esquecer bordas opostas); overflow de índices."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Troca de Dados de Halo Cells em Paralelo",
                                  "subSteps": [
                                    "Configure decomposição de domínio em blocos 1D/2D usando MPI_Sendrecv ou OpenMP com seções críticas.",
                                    "Implemente troca: envie bordas para vizinhos e receba em halo regions.",
                                    "Sincronize com MPI_Barrier ou #pragma omp barrier após trocas.",
                                    "Teste em grade 2D com stencil de Laplace (atualização baseada em 4/8 vizinhos).",
                                    "Minimize falsos compartilhamentos: evite locks desnecessários usando trocas explícitas."
                                  ],
                                  "verification": "Execute código paralelo em 4 processos; verifique se valores de halo correspondem a subdomínios vizinhos via dumps.",
                                  "estimatedTime": "4 horas",
                                  "materials": "Cluster ou multi-core com MPI/OpenMP instalado, debugger (gdb ou TotalView), grade de teste 100x100.",
                                  "tips": "Use MPI_Cart_create para topologias regulares; teste com padrões conhecidos (ex: seno wave).",
                                  "learningObjective": "Executar trocas eficientes de halo para manter corretude em iterações paralelas.",
                                  "commonMistakes": "Enviar/receber tamanhos errados; deadlocks em trocas não simétricas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar e Verificar Performance de Fronteiras",
                                  "subSteps": [
                                    "Meça overhead de trocas com timers (MPI_Wtime) e compare com versão sem halo.",
                                    "Otimize: use buffers não-bloqueantes (MPI_Isend/Irecv) e reduza largura de halo se possível.",
                                    "Profile com ferramentas (Intel VTune ou mpiP) para detectar falsos compartilhamentos.",
                                    "Implemente condições de parada (ex: convergência em stencil) e verifique escalabilidade.",
                                    "Corrija erros: valide resultados contra versão sequencial com grids pequenas."
                                  ],
                                  "verification": "Gere relatório de performance mostrando speedup e corretude (erro < 1e-6) em múltiplos cores.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Ferramentas de profiling (VTune, gprof), scripts para validação (diff ou L2 norm).",
                                  "tips": "Aumente tamanho da grade para isolar overhead de fronteira do compute.",
                                  "learningObjective": "Avaliar e otimizar gerenciamento de fronteiras para eficiência paralela.",
                                  "commonMistakes": "Ignorar overhead de comunicação em grids pequenas; não validar numericamente."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar em Caso Real e Refinar",
                                  "subSteps": [
                                    "Adapte código para um problema real (ex: difusão 2D ou heat equation).",
                                    "Experimente variações: decomposição irregular, 3D grids.",
                                    "Integre com load balancing para subdomínios desiguais.",
                                    "Documente código com comentários sobre gerenciamento de fronteiras.",
                                    "Compartilhe código em repositório e revise com pares."
                                  ],
                                  "verification": "Execute simulação completa, compare com solução analítica/referência, e speedup > 80% eficiência.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Repositório Git, problemas de teste (heat equation datasets).",
                                  "tips": "Use ghost cells para condições de Dirichlet/Neumann nas bordas globais.",
                                  "learningObjective": "Integrar gerenciamento de fronteiras em aplicações paralelas robustas.",
                                  "commonMistakes": "Não tratar bordas do domínio global; escalabilidade falha em alta dimensão."
                                }
                              ],
                              "practicalExample": "Em uma simulação de equação de calor 2D em grade 256x256 dividida em 4 processos (2x2), cada processo aloca halo de largura 1. Após computar stencil internamente, troca bordas: processo (0,0) envia direita para (1,0) halo esquerdo, recebe de (0,1) para halo superior. Isso garante atualizações corretas sem race conditions, com overhead de ~5% em 100 iterações.",
                              "finalVerifications": [
                                "Valores em halo cells coincidem exatamente com subdomínios vizinhos após troca.",
                                "Código executa sem erros de MPI/OpenMP (deadlocks, overflows) em até 16 processos.",
                                "Erro L2 global < 1e-10 comparado a versão sequencial.",
                                "Speedup linear ou próximo em profiling para grids grandes.",
                                "Nenhum falso compartilhamento detectado em ferramentas de race detection (ThreadSanitizer).",
                                "Convergência correta em problemas com solução conhecida (ex: seno inicial)."
                              ],
                              "assessmentCriteria": [
                                "Corretude: Resultados idênticos à serial em fronteiras.",
                                "Eficiência: Overhead de halo < 10% do tempo total.",
                                "Escalabilidade: Funciona e escala para 8+ processos.",
                                "Robustez: Trata bordas globais e topologias variadas.",
                                "Clareza: Código comentado e modular (funções para troca).",
                                "Otimização: Uso de non-blocking comms onde aplicável."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Numérica: Stencils e métodos de diferenças finitas.",
                                "Física Computacional: Simulações de difusão, CFD com domínios decompostos.",
                                "Engenharia de Software: Design de APIs paralelas (ex: PETSc com ghosts).",
                                "Análise de Performance: Modelagem de comunicação em grafos.",
                                "Segurança de Sistemas: Evitar data races em memória compartilhada."
                              ],
                              "realWorldApplication": "Em simulações CFD (ex: OpenFOAM com decomposição domain), onde malhas são particionadas em milhões de células; halo exchanges garantem precisão em turbulência sem overhead excessivo, usado em design de aviões na Boeing ou previsão climática no IPCC."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.1.2"
                            ]
                          },
                          {
                            "id": "10.1.3.3.2.3",
                            "name": "Balancear carga de trabalho",
                            "description": "Calcular e ajustar tamanhos de subdomínios para equalizar o tempo de execução entre processadores/threads, considerando irregularidades no domínio.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Avaliar o Domínio e Medir Desbalanceamento Inicial",
                                  "subSteps": [
                                    "Execute o código paralelo atual em todos os processadores/threads e registre os tempos de execução individuais.",
                                    "Calcule estatísticas básicas: tempo médio, desvio padrão e tempo máximo/mínimo.",
                                    "Identifique processadores/threads com cargas desproporcionais usando logs ou profiling tools.",
                                    "Visualize o domínio particionado com ferramentas como Paraview ou matplotlib para mapear irregularidades.",
                                    "Documente os fatores contribuintes, como densidade de dados ou complexidade computacional."
                                  ],
                                  "verification": "Tempos de execução individuais logados e desvio padrão calculado menor que 20% do tempo médio inicial.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Código fonte paralelo (OpenMP/MPI), profiler (gprof, VTune), planilha para cálculos (Excel/Google Sheets).",
                                  "tips": "Use wall-clock time em vez de CPU time para capturar overheads reais.",
                                  "learningObjective": "Compreender como medir desbalanceamento quantitativamente em aplicações paralelas.",
                                  "commonMistakes": "Ignorar overheads de comunicação; medir apenas iterações em vez de tempo real."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Irregularidades no Domínio",
                                  "subSteps": [
                                    "Mapeie o domínio (ex: grade 2D/3D) e identifique regiões com workloads variáveis (densidade de pontos, complexidade).",
                                    "Colete métricas locais: número de elementos, operações por célula, dependências de dados.",
                                    "Estime o custo computacional por subdomínio usando amostragem ou modelo analítico.",
                                    "Classifique irregularidades: estáticas (geometria) vs. dinâmicas (cargas variáveis no tempo).",
                                    "Crie um histograma de workloads para visualizar distribuição."
                                  ],
                                  "verification": "Relatório com mapa de irregularidades e estimativas de custo por subdomínio gerado.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "Ferramentas de visualização (Matplotlib, Gnuplot), dados do domínio (arquivos mesh/grid).",
                                  "tips": "Amostre sub-regiões pequenas primeiro para validar modelo de custo.",
                                  "learningObjective": "Identificar fontes de desbalanceamento em domínios irregulares.",
                                  "commonMistakes": "Assumir uniformidade sem análise; ignorar comunicações halo em grades."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Tamanhos de Subdomínios Balanceados",
                                  "subSteps": [
                                    "Defina o workload total e o número de processadores P; alvo: workload por proc = total / P.",
                                    "Aplique algoritmo de balanceamento: método de pesos (ex: recursive bisection) ou otimização (linear programming).",
                                    "Ajuste tamanhos considerando overheads: fator de correção para comunicações (ex: +10% para bordas).",
                                    "Simule partições candidatas offline e selecione a com menor desvio padrão projetado.",
                                    "Gere coordenadas ou índices de partição para implementação."
                                  ],
                                  "verification": "Cálculos mostram desvio padrão de workload < 5%; simulação offline confirma balanceamento.",
                                  "estimatedTime": "4-5 horas",
                                  "materials": "Bibliotecas de particionamento (Metis, Scotch), Python/MATLAB para simulações.",
                                  "tips": "Inclua um fator de segurança de 1.1-1.2 para overheads desconhecidos.",
                                  "learningObjective": "Dominar algoritmos matemáticos para partição balanceada.",
                                  "commonMistakes": "Esquecer comunicações; usar partição uniforme em domínios irregulares."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar, Testar e Refinar Particionamento",
                                  "subSteps": [
                                    "Integre partição calculada no código: defina bounds dinâmicos por thread/processador.",
                                    "Execute em hardware alvo, meça tempos e compare com baseline.",
                                    "Analise speedup e eficiência: speedup = T_serial / T_parallel; eficiência = speedup / P.",
                                    "Itere ajustes se desbalanceamento > 10%: reanalise e recalcule.",
                                    "Otimize para escalabilidade testando com mais processadores."
                                  ],
                                  "verification": "Tempos de execução equalizados (desvio < 10%); speedup > 0.8 * P.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "Compilador paralelo (g++ com OpenMP, mpicc), cluster ou multicore machine.",
                                  "tips": "Use #pragma omp for schedule(dynamic) como fallback inicial.",
                                  "learningObjective": "Aplicar e validar balanceamento em código real.",
                                  "commonMistakes": "Não testar em escala real; ignorar gargalos de memória."
                                }
                              ],
                              "practicalExample": "Em uma simulação de fluxo de fluidos em grade 2D irregular (ex: tubo com obstruções), o domínio tem regiões densas perto de obstáculos. Inicialmente, threads 1-4 levam 10s, 20s, 15s, 30s. Após análise, recalcule tamanhos: thread1=25% (alta densidade), thread4=15%. Pós-ajuste: todos ~18s, speedup de 1.8x para 4 threads.",
                              "finalVerifications": [
                                "Desvio padrão dos tempos de execução < 10% do tempo médio.",
                                "Speedup linear próximo de ideal (eficiência > 80%).",
                                "Escalabilidade confirmada com +50% processadores.",
                                "Sem overheads excessivos de comunicação (>20% do tempo total).",
                                "Código roda estável sem deadlocks ou race conditions.",
                                "Validação numérica: resultados idênticos ao serial."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos de workload (erro < 5%).",
                                "Efetividade do balanceamento (redução > 30% no tempo máximo).",
                                "Qualidade da análise de irregularidades (cobertura completa).",
                                "Robustez da implementação (funciona em diferentes tamanhos de domínio).",
                                "Documentação clara de métodos e resultados.",
                                "Capacidade de iterar baseado em testes reais."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Otimização e programação linear para partição.",
                                "Física: Simulações numéricas (CFD, FEM) com domínios irregulares.",
                                "Engenharia de Software: Profiling e otimização de performance.",
                                "Estatística: Análise de variância em workloads.",
                                "Ciência de Dados: Particionamento em big data distribuído (Spark)."
                              ],
                              "realWorldApplication": "Em simulações climáticas (modelos GCM), balancear grids globais irregulares entre milhares de CPUs no supercomputador para reduzir tempo de simulação de dias para horas, essencial para previsões precisas e urgentes."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.3.3",
                        "name": "Implementação e Avaliação em Memória Compartilhada",
                        "description": "Prática de codificação e análise de desempenho usando decomposição de domínio em linguagens como OpenMP para plataformas multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.3.3.1",
                            "name": "Codificar decomposição com OpenMP",
                            "description": "Escrever loops paralelos com cláusulas schedule e private para distribuir subdomínios em threads, aplicando em exemplos como multiplicação de matrizes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento para OpenMP",
                                  "subSteps": [
                                    "Instalar um compilador compatível com OpenMP, como GCC ou Clang.",
                                    "Verificar o suporte a OpenMP com a flag -fopenmp.",
                                    "Criar um programa de teste simples com #pragma omp parallel para confirmar múltiplas threads.",
                                    "Configurar variáveis de ambiente como OMP_NUM_THREADS para controlar o número de threads.",
                                    "Executar o teste e observar a saída com omp_get_thread_num()."
                                  ],
                                  "verification": "Compilar e executar um programa OpenMP básico que imprima o número de threads sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte OpenMP",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' para testes consistentes.",
                                  "learningObjective": "Entender e configurar o ambiente para programação paralela com OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp ao compilar",
                                    "Não definir OMP_NUM_THREADS",
                                    "Confundir threads com processos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar loop paralelo básico com cláusula private",
                                  "subSteps": [
                                    "Escrever um loop for simples que soma elementos de um array.",
                                    "Adicionar #pragma omp parallel for com cláusula private para variáveis locais.",
                                    "Garantir que cada thread tenha sua própria cópia de variáveis de iteração.",
                                    "Compilar e executar com diferentes números de threads.",
                                    "Verificar se o resultado é correto comparado à versão sequencial."
                                  ],
                                  "verification": "O programa paralelo produz o mesmo resultado da versão sequencial para soma de array.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código fonte de exemplo sequencial",
                                    "Compilador com -fopenmp"
                                  ],
                                  "tips": "Sempre inicialize variáveis private explicitamente para evitar lixo de memória.",
                                  "learningObjective": "Dominar a cláusula private para evitar race conditions em loops paralelos.",
                                  "commonMistakes": [
                                    "Não declarar variável de loop como private",
                                    "Compartilhar acumuladores sem redução",
                                    "Ignorar dependências de dados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar cláusula schedule para distribuição de subdomínios",
                                  "subSteps": [
                                    "Identificar loops com carga desbalanceada, como em decomposição de domínio.",
                                    "Experimentar schedules: static, dynamic e guided.",
                                    "Implementar schedule(dynamic) em um loop com iterações de tamanhos variados.",
                                    "Medir tempo de execução com omp_get_wtime() para diferentes schedules.",
                                    "Analisar overheads e escolher o schedule ideal baseado no workload."
                                  ],
                                  "verification": "Comparar tempos de execução: dynamic reduz tempo em workloads desbalanceados vs static.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Códigos dos steps anteriores",
                                    "Ferramentas de timing como omp_get_wtime()"
                                  ],
                                  "tips": "Use chunk size pequeno em dynamic para workloads irregulares.",
                                  "learningObjective": "Otimizar distribuição de trabalho entre threads com schedule.",
                                  "commonMistakes": [
                                    "Usar static em loops desbalanceados",
                                    "Chunk size muito pequeno causando overhead",
                                    "Esquecer de medir performance"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar decomposição em multiplicação de matrizes e avaliar",
                                  "subSteps": [
                                    "Implementar multiplicação de matrizes sequencial como baseline.",
                                    "Decompor o loop externo em subdomínios com #pragma omp parallel for private.",
                                    "Adicionar schedule para balancear linhas de matrizes.",
                                    "Compilar, executar com múltiplas threads e medir speedup.",
                                    "Analisar scalability plotando speedup vs número de threads."
                                  ],
                                  "verification": "Speedup linear próximo ao número de threads sem perda de precisão numérica.",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "Arrays/matrizes grandes (ex: 1000x1000)",
                                    "Compilador e profiler básico"
                                  ],
                                  "tips": "Use tipos double para precisão; teste com matrizes não quadradas.",
                                  "learningObjective": "Codificar e avaliar decomposição de domínio em problema real com OpenMP.",
                                  "commonMistakes": [
                                    "False sharing em acessos de matriz",
                                    "Não alinhar memória",
                                    "Ignorar overhead de criação de threads"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente multiplicação C = A * B (matrizes 1024x1024):\n#pragma omp parallel for private(i,j,k) schedule(dynamic, 32)\nfor(int i=0; i<N; i++) {\n  for(int j=0; j<N; j++) {\n    C[i][j] = 0;\n    for(int k=0; k<N; k++) C[i][j] += A[i][k] * B[k][j];\n  }\n}\nCompile: g++ -fopenmp -O3 matmul.cpp -o matmul\nExecute: OMP_NUM_THREADS=8 ./matmul",
                              "finalVerifications": [
                                "Compilação sem warnings de OpenMP.",
                                "Resultado idêntico à versão sequencial (verificação elemento a elemento).",
                                "Execução com 2-8 threads sem crashes.",
                                "Medição de speedup > 2x com 4 threads.",
                                "Análise de schedule impactando performance em workloads desbalanceados.",
                                "Uso correto de private evitando race conditions."
                              ],
                              "assessmentCriteria": [
                                "Cláusula private aplicada corretamente em todas variáveis de thread-local.",
                                "Schedule escolhido e justificado com base em balanceamento de carga.",
                                "Decomposição de domínio em subdomínios independentes.",
                                "Medição precisa de performance com timing correto.",
                                "Código limpo, comentado e escalável.",
                                "Tratamento de erros como divisão de matrizes incompatíveis."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra Linear e operações matriciais.",
                                "Física Computacional: Simulações numéricas paralelas.",
                                "Engenharia de Software: Otimização de performance e profiling.",
                                "Ciência de Dados: Processamento paralelo de grandes datasets."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (ex: multiplicação de matrizes em GCMs), processamento de imagens em visão computacional e treinamento de modelos de ML em HPC clusters, onde decomposição de domínio acelera computações intensivas em memória compartilhada."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.3.3.3.2",
                            "name": "Avaliar speedup e eficiência",
                            "description": "Medir speedup, eficiência e escalabilidade de programas decomposados, usando ferramentas como OMP_NUM_THREADS e análise de overheads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Estabelecer Baseline Sequencial e Configurar Ambiente Paralelo",
                                  "subSteps": [
                                    "Implemente ou obtenha o código sequencial do programa decomposado (ex: multiplicação de matrizes).",
                                    "Compile e execute o código sequencial múltiplas vezes para medir o tempo médio de execução (T_seq).",
                                    "Instale e configure bibliotecas OpenMP (ex: g++ com -fopenmp).",
                                    "Defina variáveis de ambiente como OMP_NUM_THREADS=1 para simular baseline.",
                                    "Registre hardware specs: número de cores, memória disponível."
                                  ],
                                  "verification": "Tempos sequenciais consistentes (desvio <5%) e ambiente OpenMP funcional (omp_get_num_threads() retorna valor correto).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Compilador GCC com OpenMP",
                                    "Código fonte sequencial",
                                    "Timer de alta precisão (gettimeofday ou omp_get_wtime)",
                                    "Terminal/Linux/Mac"
                                  ],
                                  "tips": "Execute em máquina dedicada para evitar interferências; use pelo menos 10 runs para média.",
                                  "learningObjective": "Compreender a importância de um baseline confiável para comparações paralelas.",
                                  "commonMistakes": [
                                    "Ignorar variações de cache",
                                    "Não usar timer preciso",
                                    "Executar em ambiente com outros processos pesados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar Versão Paralela com Variação de Threads",
                                  "subSteps": [
                                    "Adicione pragmas OpenMP ao código decomposado (ex: #pragma omp parallel for).",
                                    "Varie OMP_NUM_THREADS de 1 até o número máximo de cores (ex: 1,2,4,8,16).",
                                    "Meça tempo de execução paralela (T_p) para cada configuração, com múltiplas runs.",
                                    "Registre uso de CPU e memória para cada thread count.",
                                    "Salve dados em tabela/CSV: threads, T_p médio, desvio padrão."
                                  ],
                                  "verification": "Dados coletados para pelo menos 5 configurações de threads com tempos decrescentes iniciais.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código OpenMP",
                                    "Script bash para automação de runs",
                                    "Ferramentas como htop ou top para monitorar CPU"
                                  ],
                                  "tips": "Use export OMP_NUM_THREADS=N em loop; aqueça cache com runs iniciais descartados.",
                                  "learningObjective": "Executar medições sistemáticas para capturar comportamento de scaling.",
                                  "commonMistakes": [
                                    "Não sincronizar threads adequadamente",
                                    "Medir tempo wall-clock vs CPU-time incorreto",
                                    "Threads excedendo cores físicos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Speedup e Eficiência",
                                  "subSteps": [
                                    "Calcule speedup: S(p) = T_seq / T_p para cada p (número de threads).",
                                    "Calcule eficiência: E(p) = S(p) / p * 100%.",
                                    "Plote gráficos: Speedup vs Threads, Eficiência vs Threads (use Python/Matplotlib ou Excel).",
                                    "Identifique Amdahl's law limit e superlinear speedup se ocorrer.",
                                    "Valide cálculos com fórmulas teóricas."
                                  ],
                                  "verification": "Gráficos mostram speedup sublinear esperado; eficiência <100%; valores numéricos precisos até 2 casas decimais.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com numpy/matplotlib ou Excel",
                                    "Dados CSV dos steps anteriores"
                                  ],
                                  "tips": "Log scale para threads; inclua linha ideal S(p)=p para referência.",
                                  "learningObjective": "Aplicar métricas padrão de performance paralela.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Usar T_seq incorreto",
                                    "Ignorar overhead de paralelização"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Overheads e Escalabilidade",
                                  "subSteps": [
                                    "Meça overheads: tempo em critical sections, barriers, thread creation.",
                                    "Use ferramentas como Intel VTune ou gprof para profiling.",
                                    "Analise escalabilidade: iso-efficiency ou scaled speedup.",
                                    "Compare com teoria: overhead dominante causa perda de eficiência.",
                                    "Documente limitações e otimizações sugeridas (ex: reduzir sincronizações)."
                                  ],
                                  "verification": "Relatório identifica pelo menos 2 overheads principais com evidências numéricas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Profiler OpenMP (ex: omp_get_wtick)",
                                    "Intel VTune ou likwid",
                                    "Documentação Amdahl/Gustafson"
                                  ],
                                  "tips": "Foquem em hotspots; teste balanceamento de load.",
                                  "learningObjective": "Diagnosticar gargalos em programação paralela.",
                                  "commonMistakes": [
                                    "Atribuir slowdown só a overhead sem medição",
                                    "Não considerar NUMA effects",
                                    "Overfitting dados sem repetições"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes NxN (N=2048), meça T_seq=10s. Com OMP_NUM_THREADS=8, T_p=2s → Speedup=5, Eficiência=62.5%. Análise revela overhead de 20% em barriers devido a decomposição irregular.",
                              "finalVerifications": [
                                "Speedup calculado corretamente para todas configurações de threads.",
                                "Gráficos de speedup e eficiência gerados e interpretados.",
                                "Overheads identificados com pelo menos 10% de impacto quantificado.",
                                "Escalabilidade avaliada até limite prático de hardware.",
                                "Relatório resume findings com sugestões de melhoria.",
                                "Reprodutibilidade confirmada com nova run (±5% variance)."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos de speedup/eficiência (erro <1%).",
                                "Qualidade dos gráficos e visualizações (legendas, escalas corretas).",
                                "Profundidade da análise de overheads (quantitativa).",
                                "Interpretação correta de limites teóricos (Amdahl).",
                                "Clareza do relatório e sugestões acionáveis.",
                                "Uso apropriado de ferramentas e boas práticas de medição."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Estatística descritiva para análise de variância em tempos.",
                                "Arquitetura de Computadores: Entendimento de multi-core e memória cache.",
                                "Engenharia de Software: Profiling e otimização de performance.",
                                "Física/Engenharia: Modelagem de leis de scaling em simulações.",
                                "Gestão de Projetos: Avaliação de ROI em paralelização."
                              ],
                              "realWorldApplication": "Em data centers de cloud (AWS/Google Cloud), otimizar jobs de ML como treinamento de redes neurais para reduzir custos de computação em 50%; em HPC para simulações climáticas, escalar de horas para minutos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.3.1"
                            ]
                          },
                          {
                            "id": "10.1.3.3.3.3",
                            "name": "Analisar estudo de caso",
                            "description": "Estudar aplicações reais, como simulações CFD ou processamento de imagens, identificando benefícios e limitações da decomposição de domínio.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e Compreender o Estudo de Caso",
                                  "subSteps": [
                                    "Escolha um estudo de caso relevante, como uma simulação CFD usando decomposição de domínio ou processamento de imagens paralelas.",
                                    "Leia o resumo, introdução e seções de metodologia para captar o contexto geral.",
                                    "Identifique os objetivos do estudo, o problema resolvido e o ambiente de hardware/software usado.",
                                    "Anote os principais componentes: domínio problemático, método de decomposição (ex: particionamento 1D/2D) e modelo de programação (ex: OpenMP).",
                                    "Resuma em 1-2 parágrafos o que o estudo aborda."
                                  ],
                                  "verification": "Criar um resumo escrito de 200-300 palavras do estudo, cobrindo contexto e componentes chave.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Artigo ou paper acadêmico (ex: 'Parallel CFD using Domain Decomposition' via Google Scholar), notebook para anotações, acesso à internet.",
                                  "tips": "Priorize estudos com dados experimentais reais para facilitar análises posteriores.",
                                  "learningObjective": "Compreender o escopo e setup de um estudo de caso real em decomposição de domínio.",
                                  "commonMistakes": "Ignorar detalhes de hardware, assumindo que são irrelevantes para a análise de performance."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Mapear a Implementação da Decomposição de Domínio",
                                  "subSteps": [
                                    "Descreva como o domínio foi decomposto (ex: blocos regulares em grid para CFD ou tiles em imagens).",
                                    "Identifique estratégias de balanceamento de carga e comunicação entre domínios (ex: trocas de fronteira).",
                                    "Analise o código ou pseudocódigo fornecido, destacando diretivas paralelas como #pragma omp parallel for.",
                                    "Registre métricas iniciais: número de threads, tamanho do domínio, overhead de comunicação.",
                                    "Desenhe um diagrama simples da decomposição (ex: grid 2D dividido em subgrids)."
                                  ],
                                  "verification": "Produzir um diagrama anotado e descrição escrita da decomposição usada.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Ferramenta de desenho (ex: Draw.io ou papel), código fonte do estudo se disponível, ampliador de PDF para figuras.",
                                  "tips": "Use cores no diagrama para diferenciar domínios e fluxos de comunicação.",
                                  "learningObjective": "Mapear tecnicamente como a decomposição de domínio é aplicada na prática.",
                                  "commonMistakes": "Confundir decomposição lógica com física, sem considerar granularidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Avaliar Benefícios e Performance",
                                  "subSteps": [
                                    "Colete métricas de performance: speedup, eficiência, tempo de execução serial vs. paralelo.",
                                    "Calcule speedup manualmente para pelo menos 2 configurações de threads.",
                                    "Identifique ganhos específicos da decomposição (ex: redução de tempo em iterações CFD devido a paralelismo local).",
                                    "Compare com baselines (ex: sem decomposição) e discuta escalabilidade.",
                                    "Liste benefícios qualitativos: portabilidade, facilidade de implementação."
                                  ],
                                  "verification": "Tabela comparativa de métricas com cálculos de speedup e gráfico simples de performance.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Planilha (Excel/Google Sheets) para tabelas e gráficos, calculadora ou Python para plots rápidos.",
                                  "tips": "Ame law de Gustafson ou Amdahl para contextualizar limites teóricos.",
                                  "learningObjective": "Quantificar e qualificar os benefícios da decomposição de domínio.",
                                  "commonMistakes": "Focar apenas em speedup sem considerar eficiência ou overhead real."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar Limitações e Sintetizar Lições",
                                  "subSteps": [
                                    "Liste limitações: overhead de comunicação em domínios irregulares, imbalance de carga em CFD não-uniforme.",
                                    "Discuta cenários onde a decomposição falha (ex: imagens com bordas complexas).",
                                    "Proponha melhorias alternativas (ex: decomposição dinâmica ou híbrida MPI+OpenMP).",
                                    "Sintetize lições aprendidas em bullet points: quando usar, trade-offs.",
                                    "Conclua com aplicabilidade geral para problemas similares."
                                  ],
                                  "verification": "Relatório final de 1 página com limitações, melhorias e lições, revisado por pares.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Editor de texto (Word/Google Docs), exemplos de estudos alternativos para comparação.",
                                  "tips": "Pergunte: 'O que aconteceria se dobrássemos o número de threads?' para explorar limites.",
                                  "learningObjective": "Criticar construtivamente e extrair insights acionáveis do estudo.",
                                  "commonMistakes": "Ser superficial nas limitações, ignorando dependências de dados."
                                }
                              ],
                              "practicalExample": "Analise o paper 'Parallel Domain Decomposition for CFD Simulations using OpenMP' (disponível no IEEE Xplore). Foque na decomposição 2D de um grid de fluxo de ar em torno de um aerofólio, medindo speedup de 4x com 8 threads, mas com 20% overhead em trocas de fronteira.",
                              "finalVerifications": [
                                "Pode explicar verbalmente a decomposição usada e seu impacto na performance?",
                                "Tabela de métricas speedup/eficiência calculada corretamente?",
                                "Lista de 5+ benefícios e 5+ limitações identificadas com evidências do estudo?",
                                "Diagrama da decomposição reproduzido com precisão?",
                                "Propostas de melhorias viáveis baseadas na análise?",
                                "Síntese de lições aplicáveis a outros domínios como processamento de imagens."
                              ],
                              "assessmentCriteria": [
                                "Profundidade na compreensão do contexto do estudo (20%)",
                                "Precisão no mapeamento técnico da decomposição (25%)",
                                "Análise quantitativa rigorosa de performance (25%)",
                                "Identificação crítica de limitações e trade-offs (15%)",
                                "Síntese clara e acionável de lições (10%)",
                                "Qualidade visual de diagramas e tabelas (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Métodos numéricos em PDEs e particionamento de malhas.",
                                "Física/Engenharia: Modelagem de fluidos em CFD e simulações multiphysics.",
                                "Engenharia de Software: Padrões de design paralelo e profiling de performance.",
                                "Ciência de Dados: Processamento paralelo de imagens e big data em grids distribuídos."
                              ],
                              "realWorldApplication": "Em indústrias como aeroespacial (simulações CFD para design de aviões na Boeing), automotiva (análise de fluxo em motores) e médica (processamento acelerado de imagens MRI para diagnósticos rápidos), onde decomposição de domínio reduz tempo de simulação de dias para horas, otimizando designs e reduzindo custos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.1.3",
                              "10.1.3.3.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.4",
                    "name": "Exclusão Mútua",
                    "description": "Mecanismos de sincronização para acesso seguro a seções críticas em memória compartilhada.",
                    "individualConcepts": [
                      {
                        "id": "64.2.1.1",
                        "name": "Seção Crítica e Requisitos da Exclusão Mútua",
                        "description": "Definição de seção crítica em programas paralelos com memória compartilhada e os requisitos fundamentais para soluções de exclusão mútua: exclusão mútua, progresso e espera limitada (bounded waiting).",
                        "specificSkills": [
                          {
                            "id": "64.2.1.1.1",
                            "name": "Identificar Seções Críticas",
                            "description": "Analisar código sequencial e paralelo para identificar trechos que acessam recursos compartilhados e devem ser protegidos como seções críticas, considerando variáveis globais e estruturas de dados mutáveis.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar Recursos Compartilhados no Código",
                                  "subSteps": [
                                    "Examine o código sequencial para localizar variáveis globais, arrays ou estruturas de dados mutáveis acessadas por múltiplas funções ou threads.",
                                    "Liste todos os recursos que podem ser modificados (escrita) ou lidos de forma dependente por diferentes partes do programa.",
                                    "Anote os tipos de dados (ex: int global, lista compartilhada) e seus escopos.",
                                    "Destaque linhas de código que realizam leitura ou escrita nesses recursos.",
                                    "Crie um mapa simples dos recursos e suas localizações no código."
                                  ],
                                  "verification": "Verifique se a lista de recursos compartilhados cobre todas as variáveis mutáveis acessadas fora do escopo local.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código fonte sequencial em C ou Java",
                                    "Editor de texto ou IDE como VS Code",
                                    "Papel e caneta para anotações"
                                  ],
                                  "tips": "Comece pelas declarações globais e siga referências com Ctrl+F; ignore variáveis locais estritamente.",
                                  "learningObjective": "Reconhecer todos os recursos compartilhados que demandam proteção em ambientes paralelos.",
                                  "commonMistakes": [
                                    "Confundir variáveis locais com globais",
                                    "Ignorar estruturas de dados compostas como vetores ou objetos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Fluxo de Execução Sequencial",
                                  "subSteps": [
                                    "Trace o fluxo de controle sequencial, identificando todas as operações de leitura e escrita nos recursos compartilhados.",
                                    "Marque sequências atômicas de operações em um único thread (ex: incremento de contador).",
                                    "Identifique pontos onde múltiplas operações em um recurso formam uma unidade lógica indivisível.",
                                    "Registre o contexto de cada acesso (função, linha, tipo de operação: read/write).",
                                    "Valide se o código sequencial preserva consistência nos acessos."
                                  ],
                                  "verification": "Confirme que cada acesso a recurso compartilhado está mapeado com linha e operação exata.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código fonte anotado do Step 1",
                                    "Ferramenta de depuração estática ou fluxograma simples"
                                  ],
                                  "tips": "Use setas para traçar o fluxo; foque em operações não-idiotempotentes como ++ ou push.",
                                  "learningObjective": "Mapear acessos precisos a recursos compartilhados no contexto sequencial.",
                                  "commonMistakes": [
                                    "Sobrestimar atomicidade de operações compostas",
                                    "Ignorar acessos condicionais em loops"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Simular Execução Paralela e Detectar Concorrência",
                                  "subSteps": [
                                    "Identifique pontos de criação de threads ou processos paralelos no código.",
                                    "Simule interleaving de execuções: liste ordens possíveis de acessos concorrentes aos recursos.",
                                    "Detecte condições de corrida (race conditions) onde ordem de execução altera o resultado.",
                                    "Marque trechos onde acessos concorrentes podem violar consistência (ex: dois threads incrementando simultaneamente).",
                                    "Priorize seções com escrita concorrente ou read-modify-write."
                                  ],
                                  "verification": "Descreva pelo menos um cenário de race condition para cada recurso compartilhado identificado.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código paralelo exemplo",
                                    "Simulador manual ou ferramenta como ThreadGraph"
                                  ],
                                  "tips": "Pense em 'what if two threads hit the same line at once?'; desenhe timelines.",
                                  "learningObjective": "Prever problemas de concorrência ao analisar código paralelo.",
                                  "commonMistakes": [
                                    "Assumir atomicidade de instruções de alto nível",
                                    "Subestimar impactos de leituras concorrentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Delimitar e Validar Seções Críticas",
                                  "subSteps": [
                                    "Defina as seções críticas como os trechos mínimos contendo todos os acessos atômicos a recursos compartilhados.",
                                    "Desenhe limites exatos (início/fim) para cada seção crítica identificada.",
                                    "Verifique se a seção é mínima: não inclui código desnecessário fora do acesso.",
                                    "Confirme que proteger a seção previne race conditions simuladas no Step 3.",
                                    "Documente cada seção com justificativa e recurso protegido."
                                  ],
                                  "verification": "As seções críticas delimitadas eliminam todas as race conditions identificadas quando protegidas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código anotado dos steps anteriores",
                                    "Modelo de seção crítica template"
                                  ],
                                  "tips": "Mantenha seções curtas; teste mentalmente com locks imaginários.",
                                  "learningObjective": "Definir precisamente seções críticas acionáveis para sincronização.",
                                  "commonMistakes": [
                                    "Fazer seções muito amplas incluindo código irrelevante",
                                    "Esquecer acessos aninhados em estruturas"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere um código C com pthreads: uma variável global 'contador' incrementada por 10 threads em loop. A seção crítica é o trecho 'contador++;' dentro do loop de cada thread, pois múltiplos acessos concorrentes causam perda de updates (race condition). Identifique: recurso=contador (global int), acessos=read-modify-write na linha 15 de cada thread function.",
                              "finalVerifications": [
                                "Liste corretamente todos os recursos compartilhados em um código dado.",
                                "Simule e descreva race conditions potenciais em execução paralela.",
                                "Delimite seções críticas mínimas com linhas exatas.",
                                "Justifique por que cada seção precisa de proteção mútua.",
                                "Valide que proteção das seções resolve inconsistências simuladas.",
                                "Identifique ausência de seções críticas quando não há compartilhamento."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de recursos compartilhados (100% cobertura).",
                                "Correta simulação de cenários concorrentes com race conditions.",
                                "Delimitação mínima e exata das seções críticas.",
                                "Justificativas claras e lógicas para cada seção.",
                                "Completude: tratamento de todos acessos read/write.",
                                "Clareza na documentação e anotações no código."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Mecanismos de sincronização como semáforos e mutex.",
                                "Algoritmos e Estruturas de Dados: Análise de complexidade em acessos concorrentes.",
                                "Segurança da Informação: Prevenção de vulnerabilidades por race conditions.",
                                "Engenharia de Software: Design thread-safe e padrões de programação paralela."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded (ex: Apache com worker threads), identificar seções críticas em atualizações de contadores de sessões ou caches compartilhados previne perdas de dados e inconsistências, garantindo escalabilidade e confiabilidade em aplicações de alto tráfego."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.2.1.1.2",
                            "name": "Explicar Requisitos de Exclusão Mútua",
                            "description": "Descrever detalhadamente os três requisitos (exclusão mútua, progresso e bounded waiting), com exemplos de violações em cenários de execução concorrente.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Requisito de Exclusão Mútua",
                                  "subSteps": [
                                    "Defina o conceito de seção crítica em programação concorrente.",
                                    "Explique que apenas um processo deve executar a seção crítica por vez.",
                                    "Discuta o que acontece se múltiplos processos acessarem simultaneamente (ex: corrupção de dados).",
                                    "Ilustre com um diagrama simples de dois processos competindo por um recurso.",
                                    "Relacione com o problema do produtor-consumidor."
                                  ],
                                  "verification": "Descreva em suas palavras o que é exclusão mútua e dê um exemplo de violação.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Diagrama de seção crítica (papel e caneta ou ferramenta como Draw.io)",
                                    "Capítulo sobre sincronização em livro de Sistemas Operacionais (ex: Tanenbaum)"
                                  ],
                                  "tips": [
                                    "Use timelines para visualizar execuções concorrentes.",
                                    "Compare com uma fila de banco onde só uma pessoa atende por vez."
                                  ],
                                  "learningObjective": "Identificar e explicar o requisito de exclusão mútua, reconhecendo sua importância para integridade de dados.",
                                  "commonMistakes": [
                                    "Confundir exclusão mútua com atomicidade de instruções.",
                                    "Ignorar que threads em multi-core violam sem sincronização.",
                                    "Achar que busy-waiting resolve automaticamente."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender o Requisito de Progresso",
                                  "subSteps": [
                                    "Defina progresso: se nenhum processo estiver na seção crítica, um processo interessado deve entrar eventualmente.",
                                    "Explique por que sem progresso, o sistema trava (deadlock-like).",
                                    "Analise um cenário onde um algoritmo falha nesse requisito (ex: dois processos esperando um pelo outro).",
                                    "Discuta implicações para throughput em sistemas reais.",
                                    "Compare com semáforos que garantem progresso."
                                  ],
                                  "verification": "Forneça um exemplo de execução onde o progresso é violado e explique por quê.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Exemplos de código pseudocódigo para Peterson's algorithm",
                                    "Simulador online de execuções concorrentes (ex: ferramentas Java Concurrency)"
                                  ],
                                  "tips": [
                                    "Pense em um sinal de trânsito: deve permitir passagem quando livre.",
                                    "Teste com pseudocódigo manualmente."
                                  ],
                                  "learningObjective": "Explicar o requisito de progresso e suas violações, entendendo seu papel na eficiência do sistema.",
                                  "commonMistakes": [
                                    "Confundir progresso com starvation.",
                                    "Achar que qualquer lock garante progresso automaticamente.",
                                    "Ignorar dependências circulares como causa."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Compreender o Requisito de Bounded Waiting",
                                  "subSteps": [
                                    "Defina bounded waiting: existe um limite no número de vezes que outros processos entram antes de um interessado.",
                                    "Explique starvation vs. bounded waiting (ausência de fome ilimitada).",
                                    "Calcule um bound simples para um algoritmo como Dekker.",
                                    "Discuta métricas: número máximo de esperas.",
                                    "Relacione com fairness em escalonadores."
                                  ],
                                  "verification": "Calcule o bounded waiting para um cenário dado com 3 processos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Pseudocódigo de algoritmos de exclusão mútua",
                                    "Calculadora ou planilha para contar entradas na seção crítica"
                                  ],
                                  "tips": [
                                    "Conte entradas em uma tabela para visualização.",
                                    "Use o conceito de 'turno' em algoritmos de software."
                                  ],
                                  "learningObjective": "Descrever bounded waiting e diferenciá-lo de outros requisitos, aplicando em análises.",
                                  "commonMistakes": [
                                    "Confundir com progresso (progresso é eventual, bounded é limitado).",
                                    "Achar que FCFS garante sem locks.",
                                    "Subestimar em cenários com muitos processos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Exemplos de Violações em Cenários Concorrentes",
                                  "subSteps": [
                                    "Crie um cenário com dois processos sem sincronização e mostre violação de exclusão mútua.",
                                    "Simule uma execução que viola progresso (ex: disable interrupts falhando).",
                                    "Gere um exemplo de violação de bounded waiting com algoritmo defeituoso.",
                                    "Use diagramas de Lamport para representar interleavings.",
                                    "Compare com soluções corretas como mutexes."
                                  ],
                                  "verification": "Desenhe e explique um diagrama de violação para cada requisito.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Ferramenta de diagramação (Lucidchart ou papel)",
                                    "Exemplos de código em C/Pthreads para teste"
                                  ],
                                  "tips": [
                                    "Varie as interleavings para cobrir casos.",
                                    "Execute simulações mentais passo a passo."
                                  ],
                                  "learningObjective": "Identificar e ilustrar violações dos três requisitos em execuções reais.",
                                  "commonMistakes": [
                                    "Usar exemplos irreais (ex: single-thread).",
                                    "Não considerar não-determinismo de scheduling.",
                                    "Confundir violações lógicas com bugs de código."
                                  ]
                                }
                              ],
                              "practicalExample": "Dois processos bancários (P1 deposita R$100, P2 retira R$50) acessam saldo compartilhado. Sem exclusão mútua: leem saldo=100, ambos atualizam para 100+100-50=150 (errado, deveria ser 150). Com progresso violado: P1 espera eternamente após P2 sair. Bounded waiting violado: P3 entra indefinidamente antes de P1.",
                              "finalVerifications": [
                                "Liste e defina os três requisitos com precisão.",
                                "Forneça um exemplo de violação para cada um.",
                                "Explique diferenças entre eles em um parágrafo.",
                                "Desenhe diagrama de execução válida vs. inválida.",
                                "Aplique a um cenário real como impressora compartilhada.",
                                "Discuta por que todos são necessários juntos."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas sem omissões).",
                                "Uso de exemplos relevantes e corretos.",
                                "Clareza na explicação de violações com diagramas.",
                                "Diferenciação clara entre os três requisitos.",
                                "Profundidade: inclusão de implicações práticas.",
                                "Completude: cobertura de todos os aspectos solicitados."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Discreta: Modelos de estados e transições não-determinísticas.",
                                "Algoritmos e Estruturas de Dados: Análise de complexidade em concorrência.",
                                "Sistemas Operacionais: Sincronização de processos e threads.",
                                "Redes de Computadores: Protocolos distribuídos como Paxos.",
                                "Engenharia de Software: Design thread-safe e testes de race conditions."
                              ],
                              "realWorldApplication": "Em aplicativos bancários (ex: apps de mobile banking garantindo transações atômicas), servidores web (controle de sessões compartilhadas), sistemas embarcados (controle de motores em robótica) e bases de dados (locks em transações ACID para evitar lost updates)."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.2.1.1.3",
                            "name": "Avaliar Violações de Requisitos",
                            "description": "Dado um pseudocódigo ou programa, detectar e justificar violações dos requisitos de exclusão mútua em execuções interleavadas de múltiplos threads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os Requisitos de Exclusão Mútua",
                                  "subSteps": [
                                    "Estude a definição formal de exclusão mútua: apenas um thread na seção crítica por vez (safety).",
                                    "Identifique os outros requisitos: progresso (alguém entra se possível) e espera limitada (sem starvation).",
                                    "Liste os três requisitos principais em um diagrama ou tabela para referência rápida.",
                                    "Compare com exemplos de violações comuns, como dois threads lendo/escrevendo simultaneamente.",
                                    "Anote exemplos de execuções corretas vs. incorretas."
                                  ],
                                  "verification": "Criar um resumo escrito com os três requisitos e um exemplo de violação para cada um.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Documentação de algoritmos de sincronização (ex: slides de aula), papel ou editor de texto.",
                                  "tips": "Use mnemônicos como 'SPE' (Safety, Progress, Exclusion) para memorizar.",
                                  "learningObjective": "Compreender precisamente os requisitos de exclusão mútua para basear análises.",
                                  "commonMistakes": "Confundir safety com liveness (progresso); focar só em safety inicialmente."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o Pseudocódigo e Identificar Seções Críticas",
                                  "subSteps": [
                                    "Leia o pseudocódigo linha por linha e marque entradas/saídas da seção crítica (ex: do {} while).",
                                    "Identifique variáveis compartilhadas e operações atômicas assumidas.",
                                    "Desenhe um diagrama de fluxo de controle para cada thread.",
                                    "Anote pontos de não-atomicidade (ex: lock/unlock não pareados).",
                                    "Liste suposições do modelo de memória compartilhada."
                                  ],
                                  "verification": "Produzir um diagrama anotado do código com seções críticas destacadas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Pseudocódigo fornecido, ferramenta de diagramação (ex: Draw.io ou papel).",
                                  "tips": "Destaque seções críticas em negrito ou cor para visualização rápida.",
                                  "learningObjective": "Mapear precisamente as regiões críticas no código para análise de interleaving.",
                                  "commonMistakes": "Ignorar operações compostas que parecem atômicas mas não são."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerar e Simular Execuções Interleavadas",
                                  "subSteps": [
                                    "Crie cenários de interleaving: liste sequências possíveis de instruções de múltiplos threads.",
                                    "Use notação de trace (ex: T1: lock(); T2: lock();).",
                                    "Simule 5-10 interleavings manualmente, rastreando estado de variáveis.",
                                    "Priorize interleavings que testem bordas (ex: dois locks simultâneos).",
                                    "Registre estados em uma tabela (colunas: tempo, thread, ação, estado compartilhado)."
                                  ],
                                  "verification": "Gerar pelo menos 3 traces de interleaving com tabelas de estado completas.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Planilha ou tabela em editor de texto, pseudocódigo anotado.",
                                  "tips": "Comece com 2 threads para simplicidade; use setas para ordem de execução.",
                                  "learningObjective": "Dominar simulação de concorrência para expor raças condições.",
                                  "commonMistakes": "Assumir atomicidade de blocos grandes; não considerar todas as ordens possíveis."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Detectar e Justificar Violações",
                                  "subSteps": [
                                    "Para cada interleaving, verifique se >1 thread está na seção crítica simultaneamente.",
                                    "Cheque progresso: se threads querem entrar mas ninguém entra.",
                                    "Avalie espera limitada: ciclos de starvation em interleavings longos.",
                                    "Escreva justificativas claras: 'Em trace X, T1 e T2 na CS no tempo Y devido a falta de lock'.",
                                    "Classifique violações por requisito afetado."
                                  ],
                                  "verification": "Relatório com violações detectadas, traces e justificativas para cada uma.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Traces gerados, template de relatório.",
                                  "tips": "Use 'contrafactual': prove que NÃO viola mostrando ausência de sobreposição.",
                                  "learningObjective": "Identificar violações com evidências irrefutáveis de traces.",
                                  "commonMistakes": "Falsos positivos por não simular completamente; justificativas vagas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Refinar a Análise",
                                  "subSteps": [
                                    "Reveja todos os traces para violações perdidas ou falsos negativos.",
                                    "Teste com variações (ex: mais threads, diferentes tamanhos de CS).",
                                    "Compare com soluções conhecidas (ex: se algoritmo de Dekker viola?).",
                                    "Documente casos onde NÃO há violações e por quê.",
                                    "Auto-avaliação: pode explicar a um par?"
                                  ],
                                  "verification": "Checklist assinado confirmando revisão completa e ausência de erros óbvios.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Relatório inicial, soluções de referência.",
                                  "tips": "Troque análises com um colega para feedback cruzado.",
                                  "learningObjective": "Garantir robustez da análise através de validação iterativa.",
                                  "commonMistakes": "Parar após primeira violação; ignorar requisitos de liveness."
                                }
                              ],
                              "practicalExample": "Considere dois threads com código sem lock: Thread1: while(true){ CS: x++; } Thread2: while(true){ CS: x--; }. Interleaving: T1 entra CS, T2 entra CS simultaneamente → x alterado por ambos sem exclusão, violando safety. Justificativa: No tempo t=2, ambos em CS, x++ e x-- atomizados incorretamente.",
                              "finalVerifications": [
                                "Identifica corretamente seções críticas em 100% dos códigos testados.",
                                "Gera pelo menos 5 interleavings relevantes por análise.",
                                "Justificativas incluem traces exatos com estados.",
                                "Detecta violações de safety, progresso e bounded waiting quando presentes.",
                                "Explica ausência de violações com contra-exemplos.",
                                "Análise é reproduzível por terceiros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de violações (90%+ acurácia em traces).",
                                "Qualidade das justificativas (claras, baseadas em evidências).",
                                "Cobertura de interleavings (diversidade e relevância).",
                                "Uso correto de terminologia de concorrência.",
                                "Profundidade na análise de todos os requisitos.",
                                "Clareza e organização do relatório."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Sincronização de processos.",
                                "Debugging de Software: Análise de raças condições.",
                                "Lógica e Verificação Formal: Model checking de propriedades.",
                                "Algoritmos: Correção de algoritmos distribuídos."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded (ex: Apache), detectar violações previne corrupções de dados em bancos compartilhados; em apps Android/iOS, garante UI thread não sobreponha com workers, evitando crashes."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "64.2.1.2",
                        "name": "Algoritmos de Software para Exclusão Mútua",
                        "description": "Algoritmos clássicos baseados apenas em software para garantir exclusão mútua entre dois ou mais processos, como os algoritmos de Dekker e Peterson.",
                        "specificSkills": [
                          {
                            "id": "64.2.1.2.1",
                            "name": "Implementar Algoritmo de Peterson",
                            "description": "Codificar e simular o algoritmo de Peterson para dois processos, demonstrando como ele satisfaz exclusão mútua, progresso e bounded waiting usando variáveis de turno e flag.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Princípios do Algoritmo de Peterson",
                                  "subSteps": [
                                    "Estude a definição de exclusão mútua (EM), progresso e bounded waiting.",
                                    "Analise as variáveis compartilhadas: flags[2] para intenção de entrada e turn para arbitragem.",
                                    "Desenhe o pseudocódigo para processo 0 e processo 1, destacando a seção crítica.",
                                    "Identifique como o algoritmo garante EM via busy-waiting e concessão de turno.",
                                    "Compare com outros algoritmos como Dekker para contextualizar."
                                  ],
                                  "verification": "Crie um diagrama de fluxo manual do algoritmo e explique verbalmente as três propriedades.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação do algoritmo de Peterson (Wikipedia ou livro texto), papel e caneta para diagramas, editor de texto.",
                                  "tips": "Use animações online de Peterson para visualização intuitiva.",
                                  "learningObjective": "Entender os mecanismos lógicos que garantem as propriedades de sincronização.",
                                  "commonMistakes": "Confundir flag com turn; ignorar a simetria entre processos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar o Código em Pseudocódigo ou Linguagem de Programação",
                                  "subSteps": [
                                    "Defina as variáveis globais: boolean flag[2] = {false, false}; int turn;",
                                    "Codifique a função enter_region(int process) para cada processo (0 ou 1).",
                                    "Implemente a seção crítica com uma ação simulada (ex: incrementar contador).",
                                    "Codifique a função leave_region(int process) para resetar flag[process] = false.",
                                    "Adicione prints para logging de estados durante execução."
                                  ],
                                  "verification": "Compilar ou validar sintaxe do pseudocódigo; executar simulação sequencial sem erros.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Editor de código (VS Code, Jupyter), linguagem como Python ou C para threads.",
                                  "tips": "Comece com pseudocódigo para focar na lógica antes da sintaxe.",
                                  "learningObjective": "Traduzir teoria em código funcional com variáveis compartilhadas.",
                                  "commonMistakes": "Esquecer de copiar flag[j] = true antes do loop; erro no índice de processo oposto (1-process)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Simular Execução Concorrente Manual e Automatizada",
                                  "subSteps": [
                                    "Simule manualmente cenários: ambos tentam entrar simultaneamente.",
                                    "Execute simulação automatizada com threads ou fork() para intercalar execuções.",
                                    "Registre logs de flag, turn e acessos à seção crítica em múltiplas runs.",
                                    "Varie sementes de randomização para timing não-determinístico.",
                                    "Analise traces para um processo esperando o outro ceder turno."
                                  ],
                                  "verification": "Logs mostram no máximo um processo na seção crítica por vez; todos os processos eventualmente progridem.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Simulador de threads (Python threading ou pthreads em C), ferramenta de logging.",
                                  "tips": "Use sleep() randômico para simular concorrência realista.",
                                  "learningObjective": "Demonstrar comportamento em execuções não-determinísticas.",
                                  "commonMistakes": "Não intercalar execuções corretamente; ignorar starvation em simulações longas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e Documentar as Propriedades de Sincronização",
                                  "subSteps": [
                                    "Colete evidências de EM: nenhum overlap de seção crítica em 100+ runs.",
                                    "Verifique progresso: todo processo que quer entrar eventualmente entra.",
                                    "Confirme bounded waiting: máximo 1 espera por concessão de turno.",
                                    "Documente violações potenciais e por que o algoritmo as previne.",
                                    "Escreva relatório com traces e conclusões."
                                  ],
                                  "verification": "Relatório com métricas quantitativas (ex: % de runs com EM violada = 0).",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Planilha para análise de logs (Excel/Google Sheets), relatório template.",
                                  "tips": "Automatize contadores de violações com asserts no código.",
                                  "learningObjective": "Avaliar rigorosamente se o algoritmo satisfaz requisitos teóricos.",
                                  "commonMistakes": "Contar acessos errados; confundir bounded waiting com fairness absoluta."
                                }
                              ],
                              "practicalExample": "Em Python: Use threading para dois threads simulando processos 0 e 1 acessando um contador compartilhado na seção crítica. Exemplo: flag = [False, False]; turn = 0; def enter_region(p): flag[p] = True; flag[1-p] = False; while flag[1-p] and turn == 1-p: pass; ... Logs mostram alternância correta.",
                              "finalVerifications": [
                                "Código implementa corretamente enter_region e leave_region para ambos processos.",
                                "Simulações em 50+ execuções mostram exclusão mútua sem violações.",
                                "Progresso garantido: nenhum deadlock em tentativas de entrada.",
                                "Bounded waiting: máximo 1 ciclo de espera por processo.",
                                "Documentação inclui traces e análise de propriedades.",
                                "Código é simétrico e livre de race conditions lógicas."
                              ],
                              "assessmentCriteria": [
                                "Correção lógica do código (100% match com algoritmo padrão).",
                                "Qualidade da simulação (cobertura de cenários concorrentes).",
                                "Análise precisa das três propriedades com evidências.",
                                "Clareza da documentação e traces legíveis.",
                                "Eficiência: sem loops infinitos ou overhead desnecessário.",
                                "Robustez: funciona com timings variáveis."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Discreta: Lógica proposicional e invariantes.",
                                "Sistemas Operacionais: Primitivas de sincronização como semáforos.",
                                "Teoria da Computação: Autômatos e modelos concorrentes.",
                                "Engenharia de Software: Testes unitários para código paralelo."
                              ],
                              "realWorldApplication": "Usado em sistemas embarcados ou kernels leves para sincronização sem hardware (ex: mutex de software em RTOS como FreeRTOS para tarefas críticas em IoT)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.2.1.2.2",
                            "name": "Analisar Algoritmo de Dekker",
                            "description": "Explicar o funcionamento do algoritmo de Dekker para dois processos, destacando o uso de flags compartilhadas e a resolução de dependências lógicas para evitar starvation.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos de Exclusão Mútua e Problemas em Programação Paralela",
                                  "subSteps": [
                                    "Revise os conceitos de seção crítica, mutual exclusion, progress e bounded waiting.",
                                    "Identifique problemas como race conditions e starvation em acessos concorrentes sem sincronização.",
                                    "Estude o modelo de dois processos com memória compartilhada.",
                                    "Discuta por que soluções como busy-waiting são usadas em algoritmos de software.",
                                    "Anote as propriedades que um algoritmo de exclusão mútua deve satisfazer."
                                  ],
                                  "verification": "Resuma em um parágrafo as quatro propriedades de Peterson/Dekker e liste exemplos de falhas sem elas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas de aula sobre programação paralela",
                                    "Pseudocódigo de algoritmos simples como Peterson"
                                  ],
                                  "tips": "Use diagramas de tempo para visualizar race conditions entre processos.",
                                  "learningObjective": "Entender as necessidades básicas que o algoritmo de Dekker atende.",
                                  "commonMistakes": "Confundir progress com fairness; assumir hardware support desnecessário."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Examinar a Estrutura e Variáveis do Algoritmo de Dekker",
                                  "subSteps": [
                                    "Analise as variáveis compartilhadas: flags[2] (booleanos indicando desejo de entrar na SC) e turn (inteiro indicando preferência).",
                                    "Leia o pseudocódigo para processo 0 e 1, focando no loop de busy-waiting.",
                                    "Explique o papel de flag[i] = true (processo i quer entrar) e flag[i] = false (libera).",
                                    "Descreva como turn resolve empates quando ambos flags são true.",
                                    "Trace a lógica condicional: while (flag[other] && (turn == other || flag[i] == false))."
                                  ],
                                  "verification": "Desenhe um fluxograma do pseudocódigo para cada processo e rotule as condições de saída do loop.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Pseudocódigo do algoritmo de Dekker (impresso ou digital)",
                                    "Ferramenta de desenho como Draw.io"
                                  ],
                                  "tips": "Compare flag com 'turno solicitado' e turn com 'árbitro imparcial'.",
                                  "learningObjective": "Mapear variáveis e lógica condicional para entender dependências.",
                                  "commonMistakes": "Ignorar que turn só é checado se flag[other] é true; confundir turn=0 com preferência para P1."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Simular Execuções Passo a Passo do Algoritmo",
                                  "subSteps": [
                                    "Simule cenário 1: P0 tenta entrar primeiro (flag[0]=true, turn=0), P1 idle.",
                                    "Simule cenário 2: Ambos tentam simultaneamente (flags true), variando turn.",
                                    "Simule cenário 3: Um processo dentro da SC, o outro esperando (verificar no starvation).",
                                    "Use uma tabela de estados: colunas para flag[0], flag[1], turn, estado de cada P.",
                                    "Execute 5 simulações variando interleavings para observar saídas."
                                  ],
                                  "verification": "Preencha tabelas de simulação mostrando que apenas um entra na SC por vez.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Planilha Excel ou papel para tabelas de estados",
                                    "Simulador online de concorrência se disponível"
                                  ],
                                  "tips": "Intercale passos atomicamente: assuma que flag= e turn= são atômicos.",
                                  "learningObjective": "Visualizar como flags e turn resolvem dependências lógicas.",
                                  "commonMistakes": "Assumir ordem de execução fixa; esquecer de resetar flag após SC."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Propriedades e Resolução de Dependências Lógicas",
                                  "subSteps": [
                                    "Verifique mutual exclusion: prove que não ambos podem estar na SC (caso flags true, turn decide).",
                                    "Verifique progress: se um quer e o outro não, entra imediatamente.",
                                    "Verifique no starvation/bounded waiting: processo esperando eventualmente entra devido a turn flips.",
                                    "Explique dependências: flags para intenção, turn para quebra de simetria e fairness.",
                                    "Discuta limitações: apenas 2 processos, busy-waiting ineficiente."
                                  ],
                                  "verification": "Escreva provas formais curtas para cada propriedade usando casos exaustivos.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Papel para provas lógicas",
                                    "Referências teóricas como Tanenbaum ou Silberschatz"
                                  ],
                                  "tips": "Use contra-exemplos para propriedades falhas em algoritmos piores.",
                                  "learningObjective": "Dominar análise formal evitando starvation via lógica de turn.",
                                  "commonMistakes": "Confundir starvation com deadlock; ignorar que Dekker garante fairness para 2 Ps."
                                }
                              ],
                              "practicalExample": "Implemente o algoritmo de Dekker em Python usando threading para dois threads acessando um contador compartilhado na seção crítica. Rode simulações com prints de estados para observar flags e turn em ação, confirmando que o contador incrementa corretamente sem perda de updates.",
                              "finalVerifications": [
                                "Explicar corretamente o papel de flags e turn em 30 segundos.",
                                "Simular manualmente um cenário de conflito sem starvation.",
                                "Identificar onde Dekker falharia se estendido para 3 processos.",
                                "Provar mutual exclusion via lógica condicional.",
                                "Listar 3 diferenças vs. algoritmo de Peterson."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição de variáveis e condições (80% correto).",
                                "Qualidade das simulações: cobre casos críticos sem erros (4/5 cenários).",
                                "Profundidade na análise de propriedades: inclui provas lógicas.",
                                "Clareza em diagramas/fluxogramas: legíveis e completos.",
                                "Compreensão de dependências: destaca resolução de starvation.",
                                "Criatividade no exemplo prático: funcional e ilustrativo."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Discreta: Lógica proposicional e tabelas de verdade para condições.",
                                "Sistemas Operacionais: Sincronização de threads e semáforos.",
                                "Teoria da Computação: Autômatos e modelos concorrentes.",
                                "Engenharia de Software: Design de protocolos distribuídos."
                              ],
                              "realWorldApplication": "Usado em kernels de SO antigos ou bibliotecas de sincronização leves para microcontroladores; inspira locks spinlock em sistemas embedded onde overhead de hardware é evitado, como em RTOS para acesso a periféricos compartilhados."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.2.1.2.3",
                            "name": "Comparar Algoritmos de Software",
                            "description": "Comparar limitações e vantagens de algoritmos como Peterson e Bakery em termos de escalabilidade para n processos e complexidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Algoritmo de Peterson para Exclusão Mútua",
                                  "subSteps": [
                                    "Estude o pseudocódigo do algoritmo de Peterson para dois processos.",
                                    "Identifique as variáveis compartilhadas (flags e turn) e seu papel na garantia de exclusão mútua.",
                                    "Simule execuções passo a passo com diagramas de execução para cenários de contenção.",
                                    "Verifique propriedades: exclusão mútua, progresso e starvation-freedom.",
                                    "Analise o overhead: número de acessos à memória por entrada na seção crítica."
                                  ],
                                  "verification": "Crie um diagrama de execução manual mostrando dois processos entrando na seção crítica sem violação.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Pseudocódigo de Peterson (livro Tanenbaum ou slides de SO)",
                                    "Ferramenta de simulação como TLA+ ou papel e caneta",
                                    "Vídeo explicativo no YouTube sobre Peterson"
                                  ],
                                  "tips": "Desenhe timelines para visualizar busy-waiting; foque em como o 'turn' resolve starvation.",
                                  "learningObjective": "Compreender o funcionamento detalhado do algoritmo de Peterson e suas garantias para 2 processos.",
                                  "commonMistakes": [
                                    "Confundir flags com turn; ignorar o loop de busy-waiting; assumir escalabilidade sem análise."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar o Algoritmo de Bakery para n Processos",
                                  "subSteps": [
                                    "Analise o pseudocódigo do algoritmo de Bakery, destacando tickets e o array de números.",
                                    "Explique como o algoritmo simula uma fila de padaria com tickets mínimos.",
                                    "Simule para 3-4 processos, rastreando escolha de tickets e comparações.",
                                    "Verifique propriedades para múltiplos processos: ausência de starvation via tickets crescentes.",
                                    "Calcule acessos à memória: O(n) por entrada na seção crítica."
                                  ],
                                  "verification": "Simule uma execução com 4 processos e liste a ordem de entrada na seção crítica.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Pseudocódigo de Bakery (artigo original ou livro Silberschatz)",
                                    "Simulador online de algoritmos de sincronização",
                                    "Folhas para diagramas de tickets"
                                  ],
                                  "tips": "Pense nos tickets como números de senha em uma padaria; sempre pegue o menor disponível.",
                                  "learningObjective": "Dominar o mecanismo de tickets do Bakery e suas propriedades para n processos.",
                                  "commonMistakes": [
                                    "Esquecer de resetar ticket após seção crítica; subestimar comparações O(n²) em casos ruins."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Escalabilidade e Complexidade de Cada Algoritmo",
                                  "subSteps": [
                                    "Para Peterson: discuta limitação a 2 processos; complexidade O(1) mas não generaliza.",
                                    "Para Bakery: avalie escalabilidade O(n) espaço e O(n) tempo por entrada.",
                                    "Compare complexidade espacial: Peterson O(1), Bakery O(n).",
                                    "Discuta busy-waiting: ambos spin-locks, mas Bakery piora com n.",
                                    "Calcule throughput aproximado em cenários de alta contenção."
                                  ],
                                  "verification": "Tabela comparativa com métricas de tempo/espaço para n=2,10,100.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Planilha Excel para tabelas de complexidade",
                                    "Artigos acadêmicos sobre análise de algoritmos de EM",
                                    "Ferramenta como LaTeX para tabelas"
                                  ],
                                  "tips": "Use notação Big-O rigorosa; considere cache misses em hardware moderno.",
                                  "learningObjective": "Quantificar limitações em termos de escalabilidade e complexidade assintótica.",
                                  "commonMistakes": [
                                    "Ignorar que Peterson não escala; confundir tempo com espaço no Bakery."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar Vantagens, Limitações e Alternativas",
                                  "subSteps": [
                                    "Liste vantagens: Peterson simples para 2, Bakery generaliza para n.",
                                    "Limitações: Peterson não escala, Bakery ineficiente para n grande.",
                                    "Compare com hardware (Test-and-Set) ou outros software (Dekker).",
                                    "Discuta trade-offs: simplicidade vs. performance.",
                                    "Proponha cenários onde cada um é preferível."
                                  ],
                                  "verification": "Escreva um relatório de 1 página resumindo prós/contras com exemplos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Modelos de relatório em Markdown",
                                    "Referências comparativas de livros de SO"
                                  ],
                                  "tips": "Estruture como matriz de decisão: use Peterson para binário, Bakery para pequeno n.",
                                  "learningObjective": "Sintetizar comparação holística para tomada de decisões em design de sistemas.",
                                  "commonMistakes": [
                                    "Generalizar Peterson para n; ignorar overhead prático do Bakery."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema multi-threaded de banco de dados com 4 threads atualizando saldos, implemente Peterson para pares e Bakery para todos; meça latência de transações sob alta contenção usando pthread em C.",
                              "finalVerifications": [
                                "Explicar verbalmente como Bakery evita starvation para n>2.",
                                "Listar 3 limitações do Peterson em sistemas reais.",
                                "Criar tabela comparando complexidade O() para ambos.",
                                "Simular falha se Bakery usasse tickets não crescentes.",
                                "Discutir por que Bakery é preferível a múltiplos Peterson.",
                                "Identificar cenário onde Peterson é mais eficiente."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição de mecanismos (exata vs. vaga).",
                                "Profundidade na análise de complexidade (assintótica e prática).",
                                "Correção em simulações e verificações de propriedades.",
                                "Clareza na comparação de vantagens/limitações.",
                                "Criatividade em exemplos reais e trade-offs.",
                                "Uso correto de terminologia (busy-wait, escalabilidade)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise assintótica Big-O e teoria de filas.",
                                "Sistemas Operacionais: Sincronização em geral e deadlocks.",
                                "Engenharia de Software: Design de algoritmos concorrentes.",
                                "Arquitetura de Computadores: Impacto de cache em spin-locks."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded (ex: Nginx) ou bancos de dados distribuídos (ex: MySQL InnoDB), esses algoritmos inspiram locks user-space para reduzir overhead de kernel, otimizando performance em workloads de alta concorrência."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.2.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "64.2.1.3",
                        "name": "Primitivas de Hardware e Estruturas de Sincronização",
                        "description": "Uso de instruções atômicas de hardware (como Test-and-Set e Compare-and-Swap) e estruturas de alto nível (mutex, semáforos) em linguagens como pthreads e OpenMP para exclusão mútua.",
                        "specificSkills": [
                          {
                            "id": "64.2.1.3.1",
                            "name": "Utilizar Instruções Test-and-Set",
                            "description": "Implementar um spinlock simples usando a instrução atômica Test-and-Set (TAS) em pseudocódigo ou assembly, explicando busy-waiting e overhead.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Instrução Test-and-Set (TAS)",
                                  "subSteps": [
                                    "Estude a definição de TAS: operação atômica que lê o valor de uma variável e a define como 1 (set), retornando o valor original.",
                                    "Analise exemplos em pseudocódigo: TAS(var) { old = var; var = 1; return old; } destacando a indivisibilidade.",
                                    "Compare TAS com operações não atômicas (load + store) para entender race conditions.",
                                    "Pesquise implementações em assembly (ex: x86 'lock bts' ou 'xchg') e verifique documentação oficial.",
                                    "Discuta atomicidade em contextos multi-core e garantia de hardware."
                                  ],
                                  "verification": "Escreva uma explicação em 3-5 frases sobre como TAS previne race conditions e recite pseudocódigo correto.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação Intel x86 (instruções atômicas)",
                                    "Pseudocódigo de sincronização básica",
                                    "Simulador de assembly online"
                                  ],
                                  "tips": "Visualize TAS como uma 'porta giratória' que só uma thread passa por vez; foque na atomicidade.",
                                  "learningObjective": "Dominar o conceito e mecânica da instrução TAS como primitiva de hardware para exclusão mútua.",
                                  "commonMistakes": [
                                    "Confundir TAS com Compare-and-Swap (CAS)",
                                    "Ignorar que TAS sempre seta para 1, independentemente do valor anterior",
                                    "Subestimar a dependência de suporte hardware"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a Instrução TAS em Pseudocódigo",
                                  "subSteps": [
                                    "Escreva a função TAS em pseudocódigo: função que recebe ponteiro para lock e retorna booleano (0 se livre, 1 se ocupado).",
                                    "Teste TAS em ambiente single-threaded para validar lógica básica (lock inicia em 0, TAS retorna 0 e seta para 1).",
                                    "Simule execução com múltiplas chamadas sequenciais e verifique estado final da variável.",
                                    "Adapte para assembly simples (ex: usando xchg em x86) e compile/teste em ferramenta online.",
                                    "Documente o código com comentários explicando cada linha e atomicidade assumida."
                                  ],
                                  "verification": "Execute simulação manual ou código e confirme que TAS altera lock corretamente sem falhas lógicas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Editor de código (VS Code ou online como Replit)",
                                    "Compilador assembly (NASM ou Godbolt)",
                                    "Pseudocódigo template"
                                  ],
                                  "tips": "Use variáveis globais para lock e pause com breakpoints para inspecionar mudanças atômicas.",
                                  "learningObjective": "Implementar TAS funcional em pseudocódigo e assembly básico, validando sua corretude.",
                                  "commonMistakes": [
                                    "Esquecer de retornar o valor original lido",
                                    "Não tratar ponteiro corretamente em pseudocódigo",
                                    "Testar apenas em single-thread sem simular concorrência"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir um Spinlock Completo Usando TAS",
                                  "subSteps": [
                                    "Defina estrutura spinlock: variável lock inicializada em 0; acquire(): while(TAS(lock) == 1) busy-wait; release(): lock = 0.",
                                    "Implemente funções acquire e release em pseudocódigo completo.",
                                    "Crie exemplo de uso: seção crítica protegida (ex: incrementar contador compartilhado).",
                                    "Simule concorrência com 2-3 'threads' manuais (sequência de chamadas acquire/release).",
                                    "Adicione timeout ou yield opcional para mitigar busy-waiting em simulações."
                                  ],
                                  "verification": "Simule 10 iterações com múltiplas threads e confirme ausência de race conditions no contador.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Pseudocódigo ou C simulado",
                                    "Ferramenta de threading como pthreads para teste real",
                                    "Debugger para inspecionar locks"
                                  ],
                                  "tips": "Use printf ou logs para rastrear quem adquire/release o lock; mantenha release simples (não atômico em TAS básico).",
                                  "learningObjective": "Desenvolver spinlock funcional com TAS, integrando acquire/release para exclusão mútua.",
                                  "commonMistakes": [
                                    "Busy-wait sem TAS (loop simples causa races)",
                                    "Esquecer release, causando deadlock",
                                    "Usar TAS em release (desnecessário e ineficiente)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Busy-Waiting e Overhead do Spinlock TAS",
                                  "subSteps": [
                                    "Explique busy-waiting: loop while consome CPU até lock livre, sem bloqueio no SO.",
                                    "Meça overhead: conte iterações em loop falho, discuta cache misses e consumo energético.",
                                    "Compare com semáforos/mutex: TAS é leve mas ineficiente em contenção alta.",
                                    "Simule cenários: baixa/alta contenção e registre métricas (tempo, CPU%).",
                                    "Proponha otimizações: PAUSE instruction (x86) ou exponential backoff."
                                  ],
                                  "verification": "Escreva relatório curto (200 palavras) comparando overhead TAS vs. bloqueante, com métricas simuladas.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Benchmark tools (perf em Linux)",
                                    "Simulador de threads (Java ou Python multiprocessing)",
                                    "Artigos sobre spinlocks"
                                  ],
                                  "tips": "Use 'PAUSE' em assembly para reduzir overhead em loops; teste em multi-core real.",
                                  "learningObjective": "Avaliar limitações de spinlocks TAS, incluindo busy-waiting e quando usá-los.",
                                  "commonMistakes": [
                                    "Ignorar overhead em baixa contenção (bom para short critical sections)",
                                    "Confundir com locks bloqueantes",
                                    "Não considerar arquiteturas sem PAUSE"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um spinlock TAS para proteger um contador compartilhado em um programa multi-threaded: 4 threads incrementam um inteiro 1000x cada. Sem lock: valor final incorreto (~4000); com spinlock: 4000 exato. Código em C: #include <pthread.h>; int counter=0; int lock=0; int tas(int* l){int old=*l; *l=1; return old;} void acquire(){while(tas(&lock));} void release(){lock=0;}",
                              "finalVerifications": [
                                "Implementou TAS corretamente em pseudocódigo/assembly sem erros lógicos.",
                                "Spinlock acquire/release previne race conditions em simulação multi-thread.",
                                "Explicou busy-waiting com exemplo de overhead (CPU loops desnecessários).",
                                "Identificou cenários ideais para spinlocks (baixa contenção, short CS).",
                                "Propôs pelo menos uma otimização (PAUSE ou backoff).",
                                "Simulou/testou código com resultados verificáveis (contador exato)."
                              ],
                              "assessmentCriteria": [
                                "Corretude da implementação TAS (atomicidade simulada perfeita).",
                                "Funcionalidade completa do spinlock (adquire/release sem deadlocks).",
                                "Análise precisa de busy-waiting e overhead com métricas.",
                                "Clareza no pseudocódigo/assembly com comentários.",
                                "Profundidade na discussão de limitações e otimizações.",
                                "Criatividade no exemplo prático e simulações."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Instruções atômicas e barramento de memória.",
                                "Sistemas Operacionais: Primitivas de sincronização no kernel (ex: Linux spinlocks).",
                                "Programação Concorrente: Comparação com mutex/semáforos em linguagens como Java/C++.",
                                "Engenharia de Software: Trade-offs performance vs. escalabilidade em multi-core."
                              ],
                              "realWorldApplication": "Spinlocks TAS são usados em kernels de SO (Linux scheduler locks), sistemas embedded (RTOS como FreeRTOS) e bibliotecas de alto desempenho (ex: Intel TBB) para seções críticas curtas em alta contenção, minimizando latência de context switch."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.2.1.3.2",
                            "name": "Implementar Mutex com pthreads",
                            "description": "Criar um programa em C com pthreads que use mutex_lock/unlock para proteger uma seção crítica, incluindo inicialização e verificação de deadlocks.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente e esqueleto do programa",
                                  "subSteps": [
                                    "Instale as bibliotecas pthread se necessário (geralmente inclusas no gcc Linux).",
                                    "Crie um arquivo C novo (ex: mutex_example.c).",
                                    "Inclua os headers: #include <stdio.h>, #include <pthread.h>, #include <unistd.h>.",
                                    "Defina o main() e declare variáveis globais para contador compartilhado (int counter = 0;) e mutex (pthread_mutex_t mutex;).",
                                    "Compile com: gcc -o mutex_example mutex_example.c -lpthread."
                                  ],
                                  "verification": "O programa compila sem erros de sintaxe ou linking usando gcc -lpthread.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Editor de texto (VS Code, Vim)",
                                    "Compilador GCC com suporte a pthread",
                                    "Terminal Linux/Mac"
                                  ],
                                  "tips": "Sempre use -lpthread no final do comando gcc para linkar a biblioteca.",
                                  "learningObjective": "Entender os pré-requisitos e estrutura básica para programas pthread.",
                                  "commonMistakes": [
                                    "Esquecer #include <pthread.h>",
                                    "Não linkar com -lpthread causando erro 'undefined reference'"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Inicializar mutex e criar threads",
                                  "subSteps": [
                                    "No main(), inicialize o mutex: pthread_mutex_init(&mutex, NULL);",
                                    "Defina o número de threads (ex: 2).",
                                    "Declare array de pthread_t: pthread_t threads[2];",
                                    "Crie as threads: pthread_create(&threads[0], NULL, thread_func, NULL); e pthread_create(&threads[1], NULL, thread_func, NULL);",
                                    "Salve o código e compile novamente para verificar."
                                  ],
                                  "verification": "Compilação bem-sucedida e ausência de warnings sobre inicialização.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Mesmo ambiente do step 1"
                                  ],
                                  "tips": "Use NULL para atributos padrão do mutex e thread.",
                                  "learningObjective": "Dominar a criação e inicialização de mutex e threads em pthread.",
                                  "commonMistakes": [
                                    "Chamar pthread_create sem argumentos corretos",
                                    "Esquecer pthread_mutex_init causando comportamento indefinido"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar função da thread com seção crítica protegida",
                                  "subSteps": [
                                    "Defina void* thread_func(void* arg) { ... }",
                                    "Dentro da função: for(int i=0; i<1000; i++) { pthread_mutex_lock(&mutex); counter++; pthread_mutex_unlock(&mutex); }",
                                    "Adicione sleep(1) ou usleep para simular trabalho e evidenciar race sem mutex.",
                                    "Retorne NULL no final da função.",
                                    "Teste compilação."
                                  ],
                                  "verification": "Código compila e, ao executar sem lock/unlock, observe race condition (counter < 2000).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Ambiente anterior"
                                  ],
                                  "tips": "Sempre unlock após lock para evitar deadlock; use o mesmo mutex em todas threads.",
                                  "learningObjective": "Proteger seção crítica corretamente para evitar race conditions.",
                                  "commonMistakes": [
                                    "Unlock sem lock prévio",
                                    "Lock/unlock em ordem errada",
                                    "Variáveis locais em vez de globais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar threads, mutex e testar",
                                  "subSteps": [
                                    "No main(), após criar threads: for(int i=0; i<2; i++) pthread_join(threads[i], NULL);",
                                    "Imprima o counter final: printf(\"Counter final: %d\\n\", counter);",
                                    "Destrua mutex: pthread_mutex_destroy(&mutex);",
                                    "Execute: ./mutex_example e verifique counter == 2000 sem deadlock.",
                                    "Teste removendo unlock para simular deadlock (programa trava)."
                                  ],
                                  "verification": "Programa executa em <5s, counter=2000, sem travamentos; com unlock removido, trava confirmando proteção.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Ambiente anterior"
                                  ],
                                  "tips": "pthread_join garante que main espere threads terminarem.",
                                  "learningObjective": "Gerenciar ciclo de vida completo de threads e mutex.",
                                  "commonMistakes": [
                                    "Esquecer pthread_join causando saída prematura",
                                    "Destroy mutex antes de joins"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa onde duas threads incrementam um contador compartilhado 1000 vezes cada. Sem mutex, resulta em valor <2000 devido a race condition. Com mutex_lock/unlock na seção counter++, obtém exatamente 2000, demonstrando proteção correta.",
                              "finalVerifications": [
                                "Programa compila sem erros ou warnings com gcc -lpthread.",
                                "Execução resulta em counter final exatamente 2000 para 2 threads x 1000 incrementos.",
                                "Não ocorre deadlock (executa em segundos).",
                                "Removendo unlock, programa trava confirmando mecanismo de proteção.",
                                "Valgrind ou gdb não detecta leaks de memória ou erros de thread.",
                                "Counter varia <2000 se mutex removido, provando necessidade."
                              ],
                              "assessmentCriteria": [
                                "Uso correto e balanceado de pthread_mutex_lock/unlock em todas seções críticas.",
                                "Inicialização com pthread_mutex_init e destruição com pthread_mutex_destroy.",
                                "Criação e join de threads com pthread_create e pthread_join.",
                                "Tratamento adequado de variáveis compartilhadas (apenas acesso dentro de lock).",
                                "Compilação e execução sem erros, com saída determinística.",
                                "Evidência de teste de race condition e deadlock."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Conceitos de processos, threads e primitivas de sincronização.",
                                "Algoritmos e Estruturas de Dados: Análise de complexidade em ambientes paralelos (O(1) para mutex).",
                                "Segurança da Informação: Prevenção de race conditions que podem levar a vulnerabilidades.",
                                "Engenharia de Software: Boas práticas em programação concorrente e debugging multi-thread."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded como Nginx ou Apache, para proteger contadores de acessos ou queues de requisições; em bancos de dados como PostgreSQL para sincronizar transações concorrentes; em simuladores ou jogos para gerenciar recursos compartilhados sem corrupção de dados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.2.1.1"
                            ]
                          },
                          {
                            "id": "64.2.1.3.3",
                            "name": "Aplicar Semáforos para Exclusão Mútua",
                            "description": "Usar semáforos binários (mutex semáforos) em código paralelo para sincronizar acesso a recursos compartilhados, comparando com mutex nativos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Semáforos Binários e Mutex",
                                  "subSteps": [
                                    "Estude a definição de semáforo binário como um mutex implementado via operações wait (P) e signal (V).",
                                    "Compare semáforos binários com mutex nativos: ambos garantem exclusão mútua, mas semáforos permitem contadores gerais.",
                                    "Analise operações atômicas subjacentes (test-and-set ou compare-and-swap) usadas em implementações de semáforos.",
                                    "Revise problemas de sincronização como race conditions em acessos compartilhados.",
                                    "Examine pseudocódigo para wait/signal em semáforos binários."
                                  ],
                                  "verification": "Escreva um resumo de 100 palavras explicando a diferença entre semáforo binário e mutex nativo, sem erros conceituais.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação POSIX semáforos (man sem), Livro 'Modern Operating Systems' de Tanenbaum (cap. sincronização), Pseudocódigo online de semáforos"
                                  ],
                                  "tips": "Visualize wait/signal como travar/destravar uma porta: só um passa por vez.",
                                  "learningObjective": "Dominar as operações fundamentais de semáforos binários e sua equivalência a mutex para exclusão mútua.",
                                  "commonMistakes": [
                                    "Confundir semáforo geral (contador >1) com binário (0 ou 1)",
                                    "Ignorar busy-waiting em implementações spinlock",
                                    "Achar que signal pode ser chamado antes de wait"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar um Semáforo Binário Simples",
                                  "subSteps": [
                                    "Defina a estrutura do semáforo: variável inteira 'value' inicializada em 1 e lock para proteção.",
                                    "Implemente operação wait(P): enquanto value==0, espere; decrementar value atomicamente.",
                                    "Implemente operação signal(V): incrementar value atomicamente e notificar threads.",
                                    "Use primitivas atômicas como __sync_lock_test_and_set em GCC ou std::atomic em C++.",
                                    "Teste unitariamente com thread única para verificar inicialização."
                                  ],
                                  "verification": "Execute testes unitários: wait/signal alternados não causam deadlock ou overflow.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte pthreads",
                                    "Editor de código (VS Code)",
                                    "Exemplos de atomic operations no site do GCC"
                                  ],
                                  "tips": "Sempre proteja a verificação de value com spinlock para evitar race conditions na própria implementação.",
                                  "learningObjective": "Construir um semáforo binário funcional usando operações atômicas básicas.",
                                  "commonMistakes": [
                                    "Não usar atomicidade no decremento/incremento",
                                    "Esquecer de inicializar value=1",
                                    "Implementar busy-wait infinito sem yield"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Semáforo Binário em Programa Paralelo",
                                  "subSteps": [
                                    "Crie um recurso compartilhado, como um contador global.",
                                    "Inicie múltiplas threads (ex: 10) que incrementam o contador 1000 vezes cada, protegendo com wait/signal.",
                                    "Compile e execute com pthread_create/join.",
                                    "Monitore saídas com printf para verificar ordem e correção.",
                                    "Adicione sleep randômico para simular cargas reais."
                                  ],
                                  "verification": "Contador final deve ser exatamente 10*1000=10000, sem variações em múltiplas runs.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Biblioteca pthreads (libpthread)",
                                    "GDB para debug de threads",
                                    "Código base de threads simples"
                                  ],
                                  "tips": "Use gdb com 'thread apply all bt' para inspecionar deadlocks.",
                                  "learningObjective": "Sincronizar acessos concorrentes a recursos compartilhados usando semáforo binário.",
                                  "commonMistakes": [
                                    "Chamar signal sem wait pareado",
                                    "Deadlock por forget signal",
                                    "Não joinar threads, perdendo atualizações"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com Mutex Nativos e Avaliar",
                                  "subSteps": [
                                    "Refatore o código para usar pthread_mutex_t nativo no lugar do semáforo.",
                                    "Meça tempos de execução com clock_gettime para ambas versões (1000 runs).",
                                    "Analise overhead: mutex nativo vs. semáforo customizado.",
                                    "Teste cenários de alta contenda adicionando mais threads.",
                                    "Documente diferenças em precisão, performance e portabilidade."
                                  ],
                                  "verification": "Relatório comparativo mostra mutex nativo mais eficiente em contenda baixa; semáforo custom ok em baixa carga.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Função clock_gettime",
                                    "Script para múltiplas execuções e média de tempos"
                                  ],
                                  "tips": "Use pthread_mutexattr_settype para mutex recursivo se necessário, mas foque fair mutex.",
                                  "learningObjective": "Comparar eficácia prática de semáforos binários versus mutex nativos em cenários reais.",
                                  "commonMistakes": [
                                    "Medir tempo sem aquecimento de cache",
                                    "Ignorar variância em runs únicas",
                                    "Confundir spinlock com mutex sleeping"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa C com pthreads, 5 threads competem para incrementar um contador compartilhado de 0 a 5000. Use semáforo binário para proteger: cada thread faz wait antes de ++contador e signal após. Resultado correto: 5000 sem race conditions, demonstrado via múltiplas execuções.",
                              "finalVerifications": [
                                "Código compila e executa sem segfaults ou deadlocks em 10 runs.",
                                "Contador compartilhado atinge valor exato esperado (sem under/over-count).",
                                "Valgrind mostra zero race conditions ou memory leaks.",
                                "Tempo de execução estável e comparável a mutex nativo.",
                                "Explicação oral demonstra compreensão de wait/signal vs. lock/unlock.",
                                "Testes com alta contenda (20 threads) mantêm correção."
                              ],
                              "assessmentCriteria": [
                                "Inicialização correta do semáforo (value=1).",
                                "Operações wait/signal usadas simetricamente e atomicamente.",
                                "Ausência total de race conditions no recurso compartilhado.",
                                "Comparação precisa com mutex nativo (performance e API).",
                                "Código limpo, comentado e com tratamento de erros (ex: EINVAL).",
                                "Análise de cenários edge como interrupção de threads."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de processos e escalonamento.",
                                "Matemática Discreta: Lógica booleana e invariantes em algoritmos concorrentes.",
                                "Algoritmos e Estruturas de Dados: Análise de complexidade O(1) para operações atômicas.",
                                "Engenharia de Software: Padrões de design para thread-safety."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded como Apache, semáforos binários protegem pools de conexões ao banco de dados, evitando acessos simultâneos que corromperiam transações financeiras; similar a mutex em bibliotecas como OpenSSL para criptografia compartilhada."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.2.1.2"
                            ]
                          },
                          {
                            "id": "64.2.1.3.4",
                            "name": "Usar Critical em OpenMP",
                            "description": "Escrever diretivas #pragma omp critical em programas OpenMP para garantir exclusão mútua em loops paralelos com atualizações compartilhadas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender race conditions e necessidade de critical sections",
                                  "subSteps": [
                                    "Estude o conceito de race condition em ambientes paralelos com memória compartilhada.",
                                    "Analise um exemplo simples de soma paralela sem sincronização e observe resultados inconsistentes.",
                                    "Identifique seções críticas onde variáveis compartilhadas são atualizadas por múltiplas threads.",
                                    "Compare com mutexes tradicionais para entender o papel da diretiva critical em OpenMP.",
                                    "Revise a documentação oficial do OpenMP sobre exclusão mútua."
                                  ],
                                  "verification": "Explique em suas palavras o que é uma race condition e por que critical é necessário, com um diagrama simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação OpenMP (openmp.org), compilador GCC com -fopenmp, editor de código (VS Code).",
                                  "tips": "Use printf para visualizar acessos concorrentes e reproduzir o problema.",
                                  "learningObjective": "Identificar problemas de concorrência e justificar o uso de critical sections.",
                                  "commonMistakes": "Confundir critical com atomic (critical é para blocos maiores); ignorar overhead de sincronização."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender a sintaxe da diretiva #pragma omp critical",
                                  "subSteps": [
                                    "Memorize a sintaxe básica: #pragma omp critical [nome]",
                                    "Entenda o parâmetro opcional 'nome' para critical sections nomeadas.",
                                    "Escreva um esboço de código com parallel region e critical dentro de um loop.",
                                    "Compile um programa mínimo com omp_get_thread_num() para verificar execução.",
                                    "Experimente sem nome e com nome para ver compatibilidade."
                                  ],
                                  "verification": "Compile e execute um código skeleton que imprime o ID da thread dentro de critical.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "GCC com suporte OpenMP, terminal para compilar (g++ -fopenmp arquivo.cpp -o exec).",
                                  "tips": "Sempre inicialize variáveis compartilhadas fora do parallel para evitar falsos compartilhamentos.",
                                  "learningObjective": "Dominar a sintaxe e colocação correta da diretiva critical.",
                                  "commonMistakes": "Colocar critical fora do parallel; esquecer de incluir <omp.h>."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar critical em loop paralelo com atualização compartilhada",
                                  "subSteps": [
                                    "Crie um array grande e uma variável sum compartilhada.",
                                    "Estruture um #pragma omp parallel for para processar o array.",
                                    "Insira #pragma omp critical ao redor da atualização sum += array[i].",
                                    "Execute com diferentes números de threads (omp_set_num_threads(4)) e valide o resultado.",
                                    "Compare tempo e resultado com versão sem critical."
                                  ],
                                  "verification": "O soma final deve ser idêntica ao serial, independentemente de OMP_NUM_THREADS.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Código base serial de soma, perf para medir performance opcional.",
                                  "tips": "Minimize o escopo da critical: só proteja a linha de atualização.",
                                  "learningObjective": "Aplicar critical para resolver race conditions em loops reais.",
                                  "commonMistakes": "Atualizar variáveis locais dentro de critical (desnecessário); usar critical em loops inteiros (baixa paralelização)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, otimizar e aplicar boas práticas",
                                  "subSteps": [
                                    "Teste com named critical para múltiplas seções independentes.",
                                    "Meça overhead com omp_get_wtime() e otimize movendo computações para fora.",
                                    "Integre em um programa maior, como redução de histograma.",
                                    "Debugue usando OMP_WAIT_POLICY=active para observar bloqueios.",
                                    "Documente o código com comentários explicativos."
                                  ],
                                  "verification": "Código roda corretamente com 1, 4 e 8 threads; performance aceitável (speedup >1).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Ambiente de teste com múltiplos cores, valgrind para checar threads.",
                                  "tips": "Prefira reductions quando possível em vez de critical para somas simples.",
                                  "learningObjective": "Otimizar e validar implementações com critical em cenários complexos.",
                                  "commonMistakes": "Deadlocks com criticals aninhados; ignorar escalabilidade com muitas threads."
                                }
                              ],
                              "practicalExample": "```c\n#include <omp.h>\n#include <stdio.h>\nint main() {\n    int N = 1000000;\n    float *a = malloc(N*sizeof(float));\n    float sum = 0.0;\n    #pragma omp parallel for\n    for(int i=0; i<N; i++) {\n        a[i] = 1.0f;\n        #pragma omp critical\n        sum += a[i];\n    }\n    printf(\"Soma: %f (esperado: %d)\\n\", sum, N);\n    return 0;\n}\n``` Compile com `gcc -fopenmp exemplo.c -o exemplo`. Resultado deve ser sempre 1000000.0.",
                              "finalVerifications": [
                                "Programa compila sem warnings de OpenMP.",
                                "Resultado correto com OMP_NUM_THREADS=1,4,8.",
                                "Não há race conditions (verificado com múltiplas execuções).",
                                "Tempo de execução melhora com mais threads vs serial.",
                                "Nenhuma violação de memória (valgrind clean).",
                                "Código comentado explica cada diretiva."
                              ],
                              "assessmentCriteria": [
                                "Correto uso de #pragma omp critical apenas na seção de atualização.",
                                "Identificação precisa de variáveis compartilhadas.",
                                "Eficiência: critical não engloba computações pesadas.",
                                "Validação empírica com diferentes configurações de threads.",
                                "Comparação com alternativa (ex: omp atomic ou reduction).",
                                "Código limpo, legível e bem documentado."
                              ],
                              "crossCurricularConnections": [
                                "Programação Concorrente e Threads (fundamentos de sincronização).",
                                "Algoritmos e Estruturas de Dados (reduções paralelas).",
                                "Sistemas Operacionais (primitivas de exclusão mútua como mutex).",
                                "Computação de Alto Desempenho (HPC e escalabilidade).",
                                "Engenharia de Software (debugging de código paralelo)."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática ou física de partículas), onde threads paralelas atualizam contadores ou estatísticas compartilhadas em loops de Monte Carlo, garantindo precisão dos resultados agregados sem perda de paralelismo."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.5",
                    "name": "Implementação em Linguagens Paralelas",
                    "description": "Uso de linguagens como OpenMP para modelos de programação em memória compartilhada.",
                    "individualConcepts": [
                      {
                        "id": "10.1.3.5.1",
                        "name": "Fundamentos do OpenMP",
                        "description": "Introdução aos conceitos básicos da linguagem OpenMP para programação paralela em memória compartilhada, incluindo compilação, execução e criação de threads paralelas.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.5.1.1",
                            "name": "Compilar e executar um programa OpenMP",
                            "description": "Configurar ambiente de compilação com flags como -fopenmp no GCC, compilar um programa simples e executar variando o número de threads com OMP_NUM_THREADS, verificando saída paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de compilação com suporte a OpenMP",
                                  "subSteps": [
                                    "Verifique se o GCC está instalado com suporte a OpenMP (versão 4.2 ou superior).",
                                    "Instale bibliotecas necessárias via gerenciador de pacotes (ex: sudo apt install gcc libomp-dev no Ubuntu).",
                                    "Confirme o suporte executando 'gcc -fopenmp --version'.",
                                    "Crie um diretório de trabalho para o projeto.",
                                    "Teste a flag -fopenmp em um comando simples de compilação vazio."
                                  ],
                                  "verification": "Comando 'gcc -fopenmp -v' mostra suporte sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Terminal Linux/Mac",
                                    "GCC instalado",
                                    "Gerenciador de pacotes (apt/brew)"
                                  ],
                                  "tips": "Use Docker com imagem Ubuntu se em ambiente restrito para isolamento.",
                                  "learningObjective": "Entender e preparar ferramentas para compilação paralela.",
                                  "commonMistakes": [
                                    "Ignorar dependências de libomp",
                                    "Usar GCC antigo sem suporte OpenMP"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Escrever um programa OpenMP simples",
                                  "subSteps": [
                                    "Inclua as diretivas #include <omp.h> e #pragma omp parallel.",
                                    "Crie uma seção paralela que imprima o ID da thread e número total de threads.",
                                    "Adicione main() com omp_set_num_threads(4) para teste fixo.",
                                    "Salve o arquivo como hello_omp.c.",
                                    "Adicione comentários explicando cada diretiva."
                                  ],
                                  "verification": "Código compila sem erros sintáticos e tem pelo menos uma região paralela.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto (VS Code, Vim)",
                                    "Conhecimento básico de C"
                                  ],
                                  "tips": "Comece com Hello World para visualizar paralelismo imediatamente.",
                                  "learningObjective": "Dominar diretivas básicas de paralelização em OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer #include <omp.h>",
                                    "Não inicializar omp_set_num_threads"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Compilar o programa usando flags OpenMP",
                                  "subSteps": [
                                    "Execute 'gcc -fopenmp -o hello_omp hello_omp.c'.",
                                    "Verifique warnings ou erros com -Wall flag adicional.",
                                    "Confirme que o executável foi gerado com 'ls -la hello_omp'.",
                                    "Teste compilação otimizada com -O2 para performance.",
                                    "Documente o comando em um script Makefile simples."
                                  ],
                                  "verification": "Executável 'hello_omp' é criado e tem tamanho >0 bytes.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Terminal",
                                    "Arquivo hello_omp.c compilável"
                                  ],
                                  "tips": "Sempre use -fopenmp; sem ela, diretivas são ignoradas.",
                                  "learningObjective": "Aplicar flags corretas para linkar runtime OpenMP.",
                                  "commonMistakes": [
                                    "Omitir -fopenmp",
                                    "Ignorar warnings de thread-safety"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar o programa variando o número de threads",
                                  "subSteps": [
                                    "Execute './hello_omp' com OMP_NUM_THREADS=1 e observe saída sequencial.",
                                    "Defina export OMP_NUM_THREADS=4 e execute novamente.",
                                    "Teste valores como 2, 8, 16 variando com export ou --export OMP_NUM_THREADS=N.",
                                    "Registre saídas em um log para comparação.",
                                    "Use 'taskset' para fixar threads em núcleos específicos se disponível."
                                  ],
                                  "verification": "Saída mostra número correto de threads paralelas sem crashes.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Executável hello_omp",
                                    "Terminal com export"
                                  ],
                                  "tips": "Monitore uso de CPU com 'top' durante execução para ver paralelismo.",
                                  "learningObjective": "Controlar e observar escalabilidade com threads variáveis.",
                                  "commonMistakes": [
                                    "Não exportar OMP_NUM_THREADS",
                                    "Exceder núcleos disponíveis causando thrashing"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar e verificar a saída paralela",
                                  "subSteps": [
                                    "Compare saídas para diferentes OMP_NUM_THREADS.",
                                    "Confirme que ordem de threads varia entre runs (não determinístico).",
                                    "Meça tempo de execução com 'time ./hello_omp' para 1 vs múltiplas threads.",
                                    "Identifique speedup básico (tempo_seq / tempo_par).",
                                    "Adicione redução em código para somar thread IDs e valide."
                                  ],
                                  "verification": "Análise mostra paralelismo efetivo com speedup >1 para múltiplas threads.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Comando 'time'",
                                    "Logs de execução anteriores"
                                  ],
                                  "tips": "Use OMP_DISPLAY_ENV=true para debug de variáveis ambiente.",
                                  "learningObjective": "Interpretar resultados de execução paralela vs sequencial.",
                                  "commonMistakes": [
                                    "Assumir ordem determinística de threads",
                                    "Ignorar overhead de criação de threads"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa Hello World OpenMP: #include <omp.h> int main() { #pragma omp parallel { printf(\"Hello from thread %d of %d\\n\", omp_get_thread_num(), omp_get_num_threads()); } return 0; }. Compile com gcc -fopenmp -o hello hello.c, execute com OMP_NUM_THREADS=4 ./hello, observe 4 linhas de saída variando ordem.",
                              "finalVerifications": [
                                "Compilação sem erros com -fopenmp.",
                                "Execução com OMP_NUM_THREADS=1 produz saída sequencial.",
                                "Execução com OMP_NUM_THREADS=4 mostra exatamente 4 threads.",
                                "Ordem de impressão varia entre runs.",
                                "Tempo de execução diminui com mais threads (speedup observável).",
                                "Nenhum crash ou deadlocks em testes."
                              ],
                              "assessmentCriteria": [
                                "Correta configuração de ambiente e flags de compilação.",
                                "Código OpenMP válido com diretivas paralelas funcionais.",
                                "Variação controlada de threads via OMP_NUM_THREADS.",
                                "Análise qualitativa/quantitativa da saída paralela.",
                                "Documentação de comandos e resultados.",
                                "Identificação de erros comuns evitados."
                              ],
                              "crossCurricularConnections": [
                                "Programação Sequencial em C: Transição para paralelismo.",
                                "Sistemas Operacionais: Gerenciamento de processos/threads no Linux.",
                                "Arquitetura de Computadores: Exploração de múltiplos núcleos.",
                                "Análise de Performance: Métricas de speedup e eficiência."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática no IPCC), processamento de imagens em edição de vídeo (Photoshop/FFmpeg), ou machine learning distribuído (TensorFlow com OpenMP backend), onde aceleração via múltiplos núcleos reduz tempo de computação de horas para minutos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.1.2",
                            "name": "Usar a diretiva parallel",
                            "description": "Implementar a diretiva #pragma omp parallel para criar uma região paralela, utilizando omp_get_thread_num() e omp_get_num_threads() para identificar e contar threads ativas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento para OpenMP",
                                  "subSteps": [
                                    "Instalar um compilador compatível com OpenMP, como GCC (g++) versão 4.2 ou superior.",
                                    "Verificar o suporte ao OpenMP executando 'g++ --version' no terminal.",
                                    "Criar um arquivo de teste simples em C/C++ incluindo <omp.h>.",
                                    "Compilar um programa de teste com a flag -fopenmp para confirmar o ambiente.",
                                    "Definir a variável de ambiente OMP_NUM_THREADS=4 para testes iniciais."
                                  ],
                                  "verification": "Compilação bem-sucedida de um programa de teste sem erros relacionados a OpenMP.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador GCC instalado",
                                    "Editor de texto (VS Code ou similar)",
                                    "Terminal/Linux ou WSL no Windows"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' no bash para definir threads temporariamente.",
                                  "learningObjective": "Preparar o ambiente para compilar e executar códigos OpenMP sem falhas de configuração.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp na compilação",
                                    "Não incluir <omp.h>",
                                    "Usar compilador sem suporte OpenMP"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Escrever a estrutura básica de uma região paralela com #pragma omp parallel",
                                  "subSteps": [
                                    "Incluir a biblioteca <omp.h> no início do programa C/C++.",
                                    "Criar a função main() e inserir #pragma omp parallel { } logo após.",
                                    "Adicionar uma instrução printf('Hello World from thread!\\n'); dentro da região.",
                                    "Fechar corretamente a região paralela com }.",
                                    "Salvar o arquivo como parallel_basic.c."
                                  ],
                                  "verification": "Código compila e executa imprimindo 'Hello World' múltiplas vezes (uma por thread).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Arquivo parallel_basic.c",
                                    "Compilador g++"
                                  ],
                                  "tips": "Sempre use chaves {} na região paralela para delimitar o escopo claramente.",
                                  "learningObjective": "Dominar a sintaxe básica da diretiva #pragma omp parallel para criar threads.",
                                  "commonMistakes": [
                                    "Falta de #include <omp.h>",
                                    "Não usar chaves na região paralela",
                                    "printf sem \\n causando buffer issues"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Integrar omp_get_thread_num() e omp_get_num_threads() na região paralela",
                                  "subSteps": [
                                    "Dentro da região #pragma omp parallel, declarar variáveis int thread_id = omp_get_thread_num(); e int num_threads = omp_get_num_threads();.",
                                    "Usar printf para exibir: 'Thread %d de %d\\n', thread_id, num_threads.",
                                    "Adicionar um loop simples para cada thread imprimir seu ID múltiplas vezes.",
                                    "Testar com diferentes valores de OMP_NUM_THREADS (ex: 2, 4, 8).",
                                    "Compilar e executar para observar a saída."
                                  ],
                                  "verification": "Saída do programa mostra IDs de threads únicos de 0 a N-1 e total correto de threads.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código do Step 2 expandido",
                                    "Documentação OpenMP para funções omp_*"
                                  ],
                                  "tips": "Thread 0 é o master; num_threads reflete OMP_NUM_THREADS ou hardware.",
                                  "learningObjective": "Utilizar funções OpenMP para identificar e gerenciar threads ativas.",
                                  "commonMistakes": [
                                    "Chamar omp_get_* fora da região paralela (retorna 0)",
                                    "Confundir thread_num com num_threads",
                                    "Não flushar output com fflush(stdout)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Compilar, executar, depurar e analisar o programa paralelo",
                                  "subSteps": [
                                    "Compilar com: g++ -fopenmp -o parallel_app parallel.c.",
                                    "Executar: OMP_NUM_THREADS=4 ./parallel_app e observar saída.",
                                    "Analisar se todas threads executam e IDs são corretos.",
                                    "Depurar erros comuns como race conditions em printf adicionando omp_set_num_threads().",
                                    "Variar OMP_NUM_THREADS e registrar mudanças na saída."
                                  ],
                                  "verification": "Programa executa consistentemente com saída prevendo número de threads e IDs únicos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Executável compilado",
                                    "Terminal para execução"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' antes de executar para consistência.",
                                  "learningObjective": "Executar e validar programas OpenMP, identificando comportamentos paralelos.",
                                  "commonMistakes": [
                                    "Compilação sem -fopenmp causando linker errors",
                                    "Ignorar warnings de depreciação",
                                    "Executar sem definir OMP_NUM_THREADS (usa 1 por default)"
                                  ]
                                }
                              ],
                              "practicalExample": "#include <omp.h>\n#include <stdio.h>\nint main() {\n#pragma omp parallel\n{\nint id = omp_get_thread_num();\nint nt = omp_get_num_threads();\nprintf(\"Hello from thread %d of %d\\n\", id, nt);\n}\nreturn 0;\n}\n/* Compile: g++ -fopenmp exemplo.c -o exemplo */\n/* Execute: OMP_NUM_THREADS=4 ./exemplo */",
                              "finalVerifications": [
                                "Compilação sem erros usando -fopenmp.",
                                "Execução imprime mensagens de múltiplas threads com IDs corretos (0 a N-1).",
                                "omp_get_num_threads() retorna valor igual a OMP_NUM_THREADS.",
                                "Saída é não-determinística na ordem, mas consistente no conteúdo.",
                                "Alteração de OMP_NUM_THREADS afeta o número de saídas.",
                                "Nenhum erro de runtime ou segmentação."
                              ],
                              "assessmentCriteria": [
                                "Correta sintaxe da diretiva #pragma omp parallel.",
                                "Uso preciso de omp_get_thread_num() e omp_get_num_threads() dentro da região.",
                                "Compilação e execução bem-sucedidas com flags corretas.",
                                "Interpretação correta da saída (identificação de threads).",
                                "Capacidade de variar e analisar impacto de OMP_NUM_THREADS.",
                                "Código limpo, comentado e sem erros comuns."
                              ],
                              "crossCurricularConnections": [
                                "Programação Sequencial: Comparar execução serial vs. paralela.",
                                "Arquitetura de Computadores: Entender núcleos de CPU e escalabilidade.",
                                "Matemática Computacional: Base para paralelização de algoritmos numéricos.",
                                "Engenharia de Software: Boas práticas em programação paralela."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática), acelera processamento de grandes datasets dividindo tarefas entre threads em servidores multi-core, reduzindo tempo de computação de horas para minutos em aplicações HPC."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.1.3",
                            "name": "Definir número de threads",
                            "description": "Controlar o número de threads com omp_set_num_threads() e cláusula num_threads, comparando impactos no desempenho em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender e Implementar omp_set_num_threads()",
                                  "subSteps": [
                                    "Incluir a biblioteca OpenMP com #include <omp.h>",
                                    "Chamar omp_set_num_threads(N) no início da função main() antes de qualquer diretiva paralela",
                                    "Compilar o código usando gcc com a flag -fopenmp",
                                    "Executar o programa e usar omp_get_num_threads() dentro de uma região paralela para imprimir o número de threads ativo",
                                    "Testar com valores de N variando de 1 a número de cores disponíveis na máquina"
                                  ],
                                  "verification": "O programa imprime consistentemente o número de threads definido por omp_set_num_threads() em todas as execuções.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Compilador GCC com suporte a OpenMP",
                                    "Editor de texto ou IDE (VS Code, CLion)",
                                    "Terminal/Linux ou WSL no Windows"
                                  ],
                                  "tips": "Chame a função o mais cedo possível no main() para evitar configurações padrão do ambiente.",
                                  "learningObjective": "Configurar o número de threads de forma global usando a API de runtime do OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp na compilação, resultando em erros de link",
                                    "Chamar omp_set_num_threads() após a primeira diretiva paralela, sem efeito",
                                    "Definir N maior que os cores físicos, causando thrashing"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a Cláusula num_threads em Diretivas Paralelas",
                                  "subSteps": [
                                    "Identificar diretivas paralelas como #pragma omp parallel ou #pragma omp parallel for",
                                    "Adicionar a cláusula num_threads(N), ex: #pragma omp parallel num_threads(4) { ... }",
                                    "Compilar e executar, verificando com omp_get_num_threads() dentro da região",
                                    "Testar cenários onde a cláusula sobrescreve omp_set_num_threads()",
                                    "Experimentar em loops paralelos com redução para validar funcionalidade"
                                  ],
                                  "verification": "A região paralela usa exatamente N threads, mesmo se omp_set_num_threads() foi chamado com valor diferente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador GCC com suporte a OpenMP",
                                    "Editor de texto ou IDE",
                                    "Terminal"
                                  ],
                                  "tips": "A cláusula num_threads tem precedência sobre configurações globais, ideal para testes localizados.",
                                  "learningObjective": "Controlar o número de threads de forma local e específica para regiões paralelas.",
                                  "commonMistakes": [
                                    "Erro de sintaxe na cláusula (espaços ou parênteses errados)",
                                    "Confundir num_threads com schedule ou collapse",
                                    "Não testar sobrescrita para entender precedência"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Desenvolver um Programa de Benchmark para Testes de Desempenho",
                                  "subSteps": [
                                    "Criar um programa que paralelize a soma de um array grande (ex: 1e8 elementos) com #pragma omp parallel for reduction(+:sum)",
                                    "Implementar medição de tempo usando omp_get_wtime() antes e após a região paralela",
                                    "Variar o número de threads com omp_set_num_threads() e/ou num_threads(1,2,4,8,16)",
                                    "Executar cada configuração 10 vezes e calcular média e desvio padrão dos tempos",
                                    "Registrar resultados em uma tabela ou arquivo CSV"
                                  ],
                                  "verification": "O programa gera uma tabela com tempos médios para cada configuração de threads.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Compilador GCC",
                                    "Editor de código",
                                    "Terminal",
                                    "Planilha (Excel/Google Sheets) para análise de dados"
                                  ],
                                  "tips": "Use arrays alocados dinamicamente com malloc para tamanhos grandes e evite inicializações custosas dentro do loop.",
                                  "learningObjective": "Construir e executar benchmarks para quantificar o impacto do número de threads.",
                                  "commonMistakes": [
                                    "Arrays pequenos onde overhead domina o tempo de computação",
                                    "Não usar repetições para médias, levando a resultados não confiáveis",
                                    "Ignorar aquecimento de cache nas primeiras execuções"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e Comparar Impactos no Desempenho Multicores",
                                  "subSteps": [
                                    "Plotar gráfico de tempo de execução vs. número de threads usando ferramentas como gnuplot ou Python matplotlib",
                                    "Calcular speedup como tempo_serial / tempo_parallel para cada configuração",
                                    "Identificar o número ótimo de threads (pico de speedup)",
                                    "Discutir razões para saturação ou degradação (overhead, contenção de memória, lei de Amdahl)",
                                    "Comparar resultados em diferentes plataformas (ex: laptop vs. servidor multicores)"
                                  ],
                                  "verification": "Relatório escrito ou gráfico com análise conclusiva sobre configurações ótimas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Ferramenta de plotagem (gnuplot, Python com matplotlib)",
                                    "Planilha para cálculos",
                                    "Acesso a múltiplas máquinas se possível"
                                  ],
                                  "tips": "Monitore uso de CPU com htop ou top para correlacionar com número de threads.",
                                  "learningObjective": "Interpretar dados de benchmark para otimizar configurações de threads em hardware multicores.",
                                  "commonMistakes": [
                                    "Interpretação errada de speedup linear além dos cores físicos",
                                    "Não considerar efeitos de hyper-threading ou affinity de threads",
                                    "Falta de discussão sobre limitações teóricas"
                                  ]
                                }
                              ],
                              "practicalExample": "Desenvolva um programa que some 100 milhões de elementos de um array float usando #pragma omp parallel for reduction(+:sum) num_threads(4). Meça o tempo com 1, 2, 4 e 8 threads: observe aceleração até 4 threads (ótimo em quad-core), saturação depois devido a overhead e contenção.",
                              "finalVerifications": [
                                "omp_set_num_threads() define threads globalmente de forma correta e persistente.",
                                "Cláusula num_threads() sobrescreve configurações globais em regiões específicas.",
                                "Benchmark executa sem erros e gera dados repetíveis.",
                                "Análise identifica número ótimo de threads baseado em hardware.",
                                "Speedup é calculado corretamente e discute limitações como overhead."
                              ],
                              "assessmentCriteria": [
                                "Código compila e executa corretamente com todas as flags OpenMP.",
                                "Controle preciso de threads é demonstrado em saídas.",
                                "Medições de tempo são precisas, com médias e múltiplas runs.",
                                "Gráficos e tabelas mostram tendências claras de desempenho.",
                                "Relatório inclui conclusões fundamentadas em dados e teoria."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Relação com núcleos, cache e hyper-threading.",
                                "Algoritmos: Paralelização de operações de redução e prefix sum.",
                                "Sistemas Operacionais: Scheduling de threads e affinity pelo SO.",
                                "Matemática Computacional: Lei de Gustafson e Amdahl para limites de speedup.",
                                "Engenharia de Software: Benchmarking e profiling de performance."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática no NASA), processamento de imagens médicas (aceleração de filtros em CPUs multi-core) ou big data analytics (otimização de jobs Spark em clusters compartilhados), onde escolher o número certo de threads maximiza throughput sem sobrecarregar recursos hardware."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.5.2",
                        "name": "Paralelização de Loops e Decomposição de Domínio",
                        "description": "Técnicas para paralelizar loops em OpenMP, aplicando decomposição de domínio para distribuição de trabalho entre threads em memória compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.5.2.1",
                            "name": "Aplicar diretiva for",
                            "description": "Usar #pragma omp for para paralelizar loops independentes, garantindo que iterações sejam distribuídas entre threads sem dependências de dados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de programação OpenMP",
                                  "subSteps": [
                                    "Instalar um compilador compatível com OpenMP, como GCC ou Clang.",
                                    "Compilar um programa de teste simples com a flag -fopenmp para habilitar suporte a OpenMP.",
                                    "Verificar a detecção de threads usando omp_get_num_threads() em um parallel region básico.",
                                    "Executar o programa e confirmar que múltiplas threads são criadas.",
                                    "Configurar variáveis de ambiente como OMP_NUM_THREADS=4 para controlar o número de threads."
                                  ],
                                  "verification": "Compilar e executar um hello world OpenMP que imprime o número de threads corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal"
                                  ],
                                  "tips": "Sempre use -fopenmp no gcc para linkar a biblioteca OpenMP.",
                                  "learningObjective": "Configurar corretamente o ambiente para desenvolvimento com OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp",
                                    "Não definir OMP_NUM_THREADS",
                                    "Usar compilador sem suporte OpenMP"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar loops independentes para paralelização",
                                  "subSteps": [
                                    "Analisar o código sequencial e identificar loops for com iterações independentes (sem dependências de dados entre iterações).",
                                    "Verificar ausência de dependências: cada iteração lê/escreve apenas suas próprias variáveis locais.",
                                    "Mapear variáveis compartilhadas vs. privadas: identificar o que é lido por todas threads e o que é local.",
                                    "Testar manualmente dividindo o loop em partes para simular independência.",
                                    "Documentar potenciais race conditions ou falsos compartilhamentos."
                                  ],
                                  "verification": "Criar um diagrama ou lista confirmando independência das iterações do loop escolhido.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código fonte sequencial",
                                    "Papel ou ferramenta de diagramação (Draw.io)"
                                  ],
                                  "tips": "Use a regra: 'pode eu executar iterações em qualquer ordem sem mudar o resultado?' Se sim, é independente.",
                                  "learningObjective": "Reconhecer loops adequados para a diretiva for, evitando erros de paralelização.",
                                  "commonMistakes": [
                                    "Ignorar dependências cumulativas como soma parcial",
                                    "Confundir loops aninhados",
                                    "Assumir independência sem análise"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a diretiva #pragma omp for",
                                  "subSteps": [
                                    "Adicionar #pragma omp parallel antes do loop para criar o bloco paralelo.",
                                    "Inserir #pragma omp for imediatamente antes do loop for, garantindo cláusulas como private() se necessário.",
                                    "Definir cláusulas essenciais: schedule(static) para loops regulares, ou dynamic para cargas irregulares.",
                                    "Compilar com -fopenmp e executar com diferentes OMP_NUM_THREADS.",
                                    "Adicionar prints para visualizar distribuição de iterações por thread."
                                  ],
                                  "verification": "Executar e confirmar via output que iterações são distribuídas entre threads.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código fonte do Step 2",
                                    "Compilador com -fopenmp"
                                  ],
                                  "tips": "Sempre combine com #pragma omp parallel; use nowait se houver múltiplos loops.",
                                  "learningObjective": "Aplicar sintaxe correta da diretiva for para distribuir iterações de forma segura.",
                                  "commonMistakes": [
                                    "Usar omp for sem parallel pai",
                                    "Esquecer private para variáveis de iteração",
                                    "Loop com stride !=1"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, depurar e otimizar a paralelização",
                                  "subSteps": [
                                    "Medir tempo de execução sequencial vs. paralelo com diferentes números de threads.",
                                    "Usar ferramentas como omp_get_wtime() para benchmark preciso.",
                                    "Verificar corretude: comparar resultados sequencial e paralelo.",
                                    "Depurar race conditions com cláusulas ordered ou critical se necessário.",
                                    "Otimizar com schedule(runtime) e analisar speedup via gráfico."
                                  ],
                                  "verification": "Resultados idênticos ao sequencial e speedup >1 com mais threads.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Cronômetro ou função omp_get_wtime()",
                                    "Gráficos (Excel ou Python Matplotlib)"
                                  ],
                                  "tips": "Teste com OMP_NUM_THREADS=1 para simular sequencial e validar.",
                                  "learningObjective": "Validar eficácia da paralelização e otimizar performance.",
                                  "commonMistakes": [
                                    "Overhead com poucos dados",
                                    "Não medir speedup corretamente",
                                    "Ignorar falsos compartilhamentos"
                                  ]
                                }
                              ],
                              "practicalExample": "Exemplo: Paralelizar soma de array em C.\nCódigo sequencial:\nint sum = 0;\nfor(int i=0; i<N; i++) sum += array[i];\nParalelo:\n#pragma omp parallel\n{\n  #pragma omp for reduction(+:sum)\n  for(int i=0; i<N; i++) sum += array[i];\n}\nIsso distribui iterações entre threads, usando reduction para soma segura.",
                              "finalVerifications": [
                                "O programa compila e executa sem erros com múltiplas threads.",
                                "omp_get_num_threads() retorna valor >1 configurado.",
                                "Distribuição de iterações é observada via prints por thread.",
                                "Resultados são idênticos ao código sequencial.",
                                "Tempo de execução reduz proporcionalmente ao número de threads.",
                                "Ausência de race conditions confirmada por testes repetidos."
                              ],
                              "assessmentCriteria": [
                                "Sintaxe da diretiva omp for correta e combinada com parallel.",
                                "Identificação precisa de independência do loop.",
                                "Uso apropriado de cláusulas (private, reduction, schedule).",
                                "Benchmark demonstra speedup linear ou próximo.",
                                "Código livre de erros comuns como dependências não resolvidas.",
                                "Documentação clara de análise e otimizações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Computacional: Análise de complexidade e speedup de Amdahl.",
                                "Sistemas Operacionais: Gerenciamento de threads e sincronização.",
                                "Análise de Algoritmos: Decomposição de domínio e paralelismo.",
                                "Engenharia de Software: Boas práticas em programação paralela.",
                                "Física Computacional: Aplicações em simulações numéricas."
                              ],
                              "realWorldApplication": "Usado em simulações científicas (ex: modelagem climática), processamento de imagens (filtros paralelos), big data (análise em clusters HPC) e machine learning (treinamento de redes neurais em loops de epochs independentes), acelerando computações em até 10-100x em multicore."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.2.2",
                            "name": "Configurar schedules em loops",
                            "description": "Implementar cláusulas schedule(static), schedule(dynamic) e schedule(guided) em loops paralelos, analisando balanceamento de carga em diferentes cenários.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Básicos de Scheduling em Loops Paralelos",
                                  "subSteps": [
                                    "Estude a cláusula 'schedule' no OpenMP: static, dynamic e guided.",
                                    "Analise como o static distribui iterações em blocos fixos no início.",
                                    "Compare com dynamic, que atribui iterações sob demanda.",
                                    "Revise guided, que usa blocos decrescentes.",
                                    "Identifique cenários de balanceamento: cargas uniformes vs. desbalanceadas."
                                  ],
                                  "verification": "Resuma em um documento as diferenças entre os três tipos de schedule e cenários ideais para cada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação OpenMP (openmp.org), editor de código (VS Code), compilador GCC com suporte OpenMP.",
                                  "tips": "Use diagramas para visualizar distribuição de chunks entre threads.",
                                  "learningObjective": "Diferenciar os mecanismos de scheduling e seus impactos no balanceamento de carga.",
                                  "commonMistakes": "Confundir static com dynamic; ignorar overhead de dynamic em cargas uniformes."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar schedule(static) em um Loop Paralelo",
                                  "subSteps": [
                                    "Crie um loop for paralelo simples para somar elementos de um array grande.",
                                    "Adicione #pragma omp parallel for schedule(static).",
                                    "Compile com -fopenmp e execute com OMP_NUM_THREADS=4.",
                                    "Meça tempo de execução com omp_get_wtime().",
                                    "Teste com chunk size específico: schedule(static, chunk_size)."
                                  ],
                                  "verification": "Execute o código e confirme distribuição uniforme via prints de thread ID por iteração.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código base em C (array de 1e6 elementos), terminal com GCC.",
                                  "tips": "Use omp_get_thread_num() para logar atribuições e visualizar balanceamento.",
                                  "learningObjective": "Aplicar schedule(static) e observar performance em cargas uniformes.",
                                  "commonMistakes": "Esquecer de inicializar array ou não definir OMP_NUM_THREADS."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar schedule(dynamic) e schedule(guided)",
                                  "subSteps": [
                                    "Modifique o código para schedule(dynamic) e teste com cargas desbalanceadas (ex: iterações com delays variáveis).",
                                    "Implemente schedule(guided) e compare overheads.",
                                    "Adicione delays artificiais em algumas iterações para simular desbalanceamento.",
                                    "Registre tempos de execução para cada schedule.",
                                    "Experimente chunk sizes diferentes (ex: schedule(dynamic,1) vs. schedule(dynamic,100))."
                                  ],
                                  "verification": "Compare tempos de execução e logs de thread para confirmar adaptação dinâmica.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código do Step 2 modificado, cronômetro ou função omp_get_wtime().",
                                  "tips": "Introduza usleep() ou loops vazios para simular cargas irregulares.",
                                  "learningObjective": "Implementar schedules adaptativos e medir overhead em cenários reais.",
                                  "commonMistakes": "Não sincronizar threads adequadamente; ignorar overhead de locks em dynamic."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Balanceamento de Carga em Diferentes Cenários",
                                  "subSteps": [
                                    "Crie cenários: uniforme (sem delays), desbalanceado (delays aleatórios), híbrido.",
                                    "Colete métricas: tempo total, tempo por thread (via barriers e timers).",
                                    "Gere gráficos de speedup e eficiência usando ferramentas como Gnuplot.",
                                    "Compare os três schedules em cada cenário.",
                                    "Documente recomendações: static para uniforme, dynamic/guided para irregular."
                                  ],
                                  "verification": "Produza um relatório com tabelas/gráficos mostrando qual schedule é melhor por cenário.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Códigos anteriores, Python/Matplotlib para gráficos, dados de execução.",
                                  "tips": "Use múltiplas runs para médias confiáveis; fixe seed para reprodutibilidade.",
                                  "learningObjective": "Avaliar empiricamente o impacto de schedules no balanceamento e performance.",
                                  "commonMistakes": "Amostras insuficientes; não considerar cache effects em arrays."
                                }
                              ],
                              "practicalExample": "Em um loop paralelo para processar pixels de uma imagem (ex: filtro de convolução), use schedule(static) para imagens uniformes (rápido), mas schedule(dynamic) quando regiões variam em complexidade (ex: bordas vs. fundo), reduzindo tempo total de 10s para 4s com 8 threads.",
                              "finalVerifications": [
                                "Código compila e executa sem erros para todos os schedules.",
                                "Logs mostram distribuição correta de iterações por thread.",
                                "Tempos de execução variam conforme esperado por cenário de carga.",
                                "Relatório inclui gráficos de speedup >1 para paralelização.",
                                "Recomendações justificadas com dados empíricos.",
                                "Nenhum race condition ou deadlock detectado."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação das cláusulas schedule (100% funcional).",
                                "Análise quantitativa completa com métricas de tempo e balanceamento.",
                                "Identificação correta de cenários ideais para cada schedule.",
                                "Qualidade dos gráficos e relatório (clareza, legibilidade).",
                                "Uso adequado de timers e logs para verificação.",
                                "Consideração de overheads e chunk sizes."
                              ],
                              "crossCurricularConnections": [
                                "Otimização de Algoritmos: Análise de complexidade e heurísticas de chunk size.",
                                "Sistemas Operacionais: Gerenciamento de threads e scheduling do SO.",
                                "Engenharia de Software: Profiling e tuning de performance.",
                                "Matemática Computacional: Modelagem de speedup (lei de Amdahl)."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (Monte Carlo com iterações irregulares), schedule(guided) equilibra cargas em clusters HPC, reduzindo tempo de simulação de horas para minutos em aplicações como CFD ou processamento de big data em finanças."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.2.3",
                            "name": "Combinar parallel e for",
                            "description": "Estruturar regiões com #pragma omp parallel for para otimizar paralelização de tarefas iterativas, medindo speedup em aplicações de decomposição de domínio.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de #pragma omp parallel e #pragma omp for",
                                  "subSteps": [
                                    "Estude a sintaxe de #pragma omp parallel para criar múltiplas threads.",
                                    "Analise #pragma omp for para distribuir iterações de loop entre threads.",
                                    "Compreenda como combinar ambos em #pragma omp parallel for para paralelizar loops de forma eficiente.",
                                    "Identifique cláusulas essenciais como num_threads e schedule.",
                                    "Revise diretivas de redução para evitar race conditions em operações como soma."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre parallel e parallel for, com exemplos de código compiláveis.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação OpenMP oficial, compilador GCC com flag -fopenmp, editor de código como VS Code.",
                                  "tips": "Use omp_get_num_threads() para verificar o número de threads ativas.",
                                  "learningObjective": "Dominar os fundamentos teóricos da combinação parallel e for para evitar erros conceituais.",
                                  "commonMistakes": "Ignorar race conditions em loops sem cláusula reduction; assumir distribuição uniforme sem schedule."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar #pragma omp parallel for em um Loop Simples",
                                  "subSteps": [
                                    "Crie um programa sequencial para somar elementos de um array grande (ex: 1 milhão de elementos).",
                                    "Insira #pragma omp parallel for com cláusula reduction(+:soma) no loop de soma.",
                                    "Compile e execute com diferentes números de threads usando OMP_NUM_THREADS.",
                                    "Meça o tempo de execução sequencial e paralelo com gettimeofday() ou omp_get_wtime().",
                                    "Compare resultados para garantir correção numérica."
                                  ],
                                  "verification": "O programa paralelo produz o mesmo resultado que o sequencial e executa mais rápido (speedup >1).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Compilador GCC (-fopenmp -O2), terminal para export OMP_NUM_THREADS=4, arrays de teste gerados dinamicamente.",
                                  "tips": "Sempre inicialize sementes para rand() fora do loop paralelo para reprodutibilidade.",
                                  "learningObjective": "Aplicar parallel for em loops independentes, garantindo thread-safety.",
                                  "commonMistakes": "Esquecer reduction em operações acumulativas; usar variáveis compartilhadas sem proteção."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar em Decomposição de Domínio com Paralelização de Loops",
                                  "subSteps": [
                                    "Escolha uma aplicação como multiplicação de matrizes ou stencil em grade 2D.",
                                    "Divida o domínio em blocos (decomposição de domínio) atribuídos a threads via parallel for.",
                                    "Implemente cláusulas private para variáveis locais e shared para dados globais.",
                                    "Adicione schedule(dynamic) para cargas desbalanceadas em decomposições irregulares.",
                                    "Teste com tamanhos variados de domínio para observar escalabilidade."
                                  ],
                                  "verification": "Execute o código com decomposição e verifique resultados contra versão sequencial usando diff ou soma de resíduos.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Código base de matriz (ex: 1000x1000), profiler como gprof ou Intel VTune, hardware multi-core.",
                                  "tips": "Use nowait em for inner loops para sobreposição de comunicação e computação.",
                                  "learningObjective": "Estruturar paralelização eficiente para problemas de domínio decomposto.",
                                  "commonMistakes": "Acessos falsos compartilhados em arrays privados; overhead excessivo com threads demais."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Medir Speedup e Otimizar a Paralelização",
                                  "subSteps": [
                                    "Colete tempos médios de N=10 execuções para sequencial, parallel for com 2,4,8 threads.",
                                    "Calcule speedup = tempo_seq / tempo_par e eficiência = speedup / num_threads.",
                                    "Analise gráfico de speedup vs threads para identificar gargalos (ex: Amdahl's law).",
                                    "Otimize com cláusulas como collapse para loops aninhados ou threadprivate.",
                                    "Documente observações em relatório com tabelas e gráficos."
                                  ],
                                  "verification": "Gere relatório com speedup mensurável (>2x em 4 cores) e gráficos plotados (ex: com gnuplot).",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Ferramentas de timing (omp_get_wtime), gnuplot ou Python matplotlib para gráficos, processador multi-core.",
                                  "tips": "Fixe affinity de threads com OMP_PROC_BIND=spread para melhor performance.",
                                  "learningObjective": "Quantificar ganhos de paralelização e aplicar otimizações baseadas em medições.",
                                  "commonMistakes": "Médias de uma única execução; ignorar cache effects em tamanhos pequenos de domínio."
                                }
                              ],
                              "practicalExample": "Paralelize a decomposição de domínio em uma simulação de difusão em grade 2D (1024x1024): use #pragma omp parallel for no loop externo para distribuir linhas da grade entre threads, com reduction para estatísticas globais, medindo speedup de 3.5x em 4 cores.",
                              "finalVerifications": [
                                "Implementar corretamente #pragma omp parallel for sem race conditions ou deadlocks.",
                                "Obter speedup mensurável (>2x) em hardware multi-core para loops iterativos.",
                                "Verificar resultados idênticos entre versões sequencial e paralela.",
                                "Aplicar cláusulas como schedule e reduction adequadamente em decomposição de domínio.",
                                "Gerar relatório com gráficos de performance e análise de eficiência.",
                                "Otimizar código para eficiência >70% em 4 threads."
                              ],
                              "assessmentCriteria": [
                                "Correção do código: compilação sem warnings e resultados numéricos precisos (tolerância 1e-6).",
                                "Eficiência de paralelização: speedup linear até limite de cores disponíveis.",
                                "Uso apropriado de cláusulas OpenMP: private, shared, reduction, schedule.",
                                "Análise de performance: cálculos corretos de speedup e identificação de gargalos.",
                                "Documentação: código comentado, relatório com evidências empíricas.",
                                "Escalabilidade: bom comportamento em diferentes tamanhos de domínio e threads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Métodos numéricos e álgebra linear em decomposição de matrizes.",
                                "Física: Simulações computacionais como dinâmica de fluidos ou propagação de ondas.",
                                "Engenharia de Software: Otimização de performance e profiling em sistemas distribuídos.",
                                "Ciência de Dados: Processamento paralelo de big data em arrays multidimensionais."
                              ],
                              "realWorldApplication": "Em supercomputação para simulações climáticas (modelos GCM com decomposição espacial), processamento de imagens médicas (filtros em grids paralelizáveis) e machine learning (treinamento distribuído de redes neurais em loops de épocas), alcançando acelerações de 10x+ em clusters HPC."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.5.3",
                        "name": "Sincronização e Exclusão Mútua",
                        "description": "Mecanismos de sincronização em OpenMP para gerenciar acesso concorrente a dados compartilhados, incluindo exclusão mútua e barreiras.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.5.3.1",
                            "name": "Implementar seções critical",
                            "description": "Usar #pragma omp critical para proteger regiões de código com acessos compartilhados, evitando condições de corrida em atualizações de variáveis globais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos fundamentais de seções critical no OpenMP",
                                  "subSteps": [
                                    "Estudar a sintaxe e semântica de #pragma omp critical na documentação oficial do OpenMP",
                                    "Identificar condições de corrida em acessos compartilhados por threads",
                                    "Analisar exemplos de variáveis globais atualizadas em loops paralelos",
                                    "Diferenciar seções critical de diretivas atomic e locks",
                                    "Explicar o overhead de critical em comparação a atomic"
                                  ],
                                  "verification": "Escrever um resumo de 200 palavras explicando quando usar #pragma omp critical",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação OpenMP (openmp.org)",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Sempre priorize atomic para operações simples antes de critical",
                                  "learningObjective": "Dominar a teoria por trás da exclusão mútua com seções critical",
                                  "commonMistakes": [
                                    "Confundir critical com paralelização total do loop",
                                    "Ignorar que critical serializa apenas a região protegida"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente de desenvolvimento OpenMP",
                                  "subSteps": [
                                    "Instalar compilador com suporte OpenMP (gcc com -fopenmp ou icc)",
                                    "Criar um programa C/C++ básico com #include <omp.h>",
                                    "Compilar e executar um hello world paralelo com OMP_NUM_THREADS=4",
                                    "Verificar variáveis de ambiente OpenMP (OMP_NUM_THREADS, OMP_PROC_BIND)",
                                    "Testar detecção de race condition em um contador global simples"
                                  ],
                                  "verification": "Executar código paralelo e confirmar saída consistente sem sincronização",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "GCC/Clang com OpenMP",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal"
                                  ],
                                  "tips": "Use export OMP_NUM_THREADS=4 para testes reproducíveis",
                                  "learningObjective": "Preparar ambiente funcional para experimentação com sincronização",
                                  "commonMistakes": [
                                    "Esquecer flag -fopenmp na compilação",
                                    "Não definir número de threads"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar seções critical em código paralelo",
                                  "subSteps": [
                                    "Criar um loop paralelo que atualize uma variável global compartilhada (ex: soma de elementos)",
                                    "Envolver a região crítica de atualização com #pragma omp critical",
                                    "Nomear a seção critical opcionalmente (ex: critical(soma)) para granularidade",
                                    "Adicionar prints para visualizar ordem de execução das threads",
                                    "Comparar execução sem e com critical para observar race conditions"
                                  ],
                                  "verification": "Compilar e executar: sem critical (resultados variam), com critical (soma sempre correta)",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código base sequencial",
                                    "Compilador OpenMP"
                                  ],
                                  "tips": "Mantenha regiões critical o mais curtas possível para minimizar overhead",
                                  "learningObjective": "Aplicar #pragma omp critical para proteger acessos compartilhados",
                                  "commonMistakes": [
                                    "Colocar todo o loop dentro de critical (anula paralelismo)",
                                    "Usar critical em variáveis privadas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, debugar e otimizar seções critical",
                                  "subSteps": [
                                    "Executar com múltiplos threads e seeds aleatórias para simular cargas reais",
                                    "Usar ferramentas como Valgrind ou ThreadSanitizer para detectar races residuais",
                                    "Medir tempo de execução com/ sem critical usando omp_get_wtime()",
                                    "Otimizar substituindo critical por atomic quando possível",
                                    "Documentar o código com comentários explicando a sincronização"
                                  ],
                                  "verification": "Resultados consistentes em 10 execuções e tempo de execução registrado",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "ThreadSanitizer (TSan)",
                                    "Cronômetro OpenMP"
                                  ],
                                  "tips": "Para debugar, reduza threads para 2 inicialmente",
                                  "learningObjective": "Validar corretude e performance de implementações critical",
                                  "commonMistakes": [
                                    "Não testar com cargas altas de threads",
                                    "Ignorar overhead em benchmarks"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar em exemplo prático complexo",
                                  "subSteps": [
                                    "Implementar um histograma paralelo onde threads atualizam buckets compartilhados",
                                    "Proteger atualizações de histograma com critical nomeada",
                                    "Paralelizar leitura de dados de arquivo ou array grande",
                                    "Verificar histograma contra versão sequencial",
                                    "Analisar escalabilidade variando número de threads"
                                  ],
                                  "verification": "Histograma idêntico à versão sequencial em múltiplas runs",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Dataset de números (array ou arquivo)",
                                    "Código histograma sequencial"
                                  ],
                                  "tips": "Use critical apenas nas atualizações, não na computação local",
                                  "learningObjective": "Generalizar uso de critical para cenários reais de dados compartilhados",
                                  "commonMistakes": [
                                    "Sobrecarregar critical com computações pesadas",
                                    "Não normalizar histograma"
                                  ]
                                }
                              ],
                              "practicalExample": "Código C: int global_sum = 0; #pragma omp parallel for for(int i=0; i<1000000; i++) { #pragma omp critical { global_sum += array[i]; } } // Sem critical, soma varia; com critical, sempre 499999500000",
                              "finalVerifications": [
                                "Código compila com -fopenmp sem warnings",
                                "Execução com 2-8 threads produz resultados idênticos",
                                "Não há detecções de race condition por TSan/Valgrind",
                                "Tempo de execução é razoável (<2x sequencial)",
                                "Comentários explicam cada uso de critical",
                                "Testes com dados aleatórios confirmam corretude"
                              ],
                              "assessmentCriteria": [
                                "Regiões critical são mínimas e focadas em acessos compartilhados",
                                "Código demonstra speedup paralelo mensurável",
                                "Tratamento correto de variáveis compartilhadas vs privadas",
                                "Uso apropriado de nomes em critical para evitar deadlocks",
                                "Análise de performance inclui comparação com atomic",
                                "Documentação clara de race conditions evitadas"
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Conceitos de exclusão mútua e semáforos",
                                "Algoritmos: Paralelização de reduce operations",
                                "Engenharia de Software: Thread-safety em programação concorrente",
                                "Matemática Computacional: Sincronização em simulações numéricas"
                              ],
                              "realWorldApplication": "Em aplicações científicas como simulações Monte Carlo, onde threads atualizam estatísticas globais (médias, desvios) em processamento de big data, evitando erros em relatórios de performance de servidores ou modelagem financeira paralela."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.3.2",
                            "name": "Usar atomic e reductions",
                            "description": "Aplicar #pragma omp atomic para operações atômicas simples e cláusula reduction para somas, produtos ou lógicas em loops paralelos, otimizando desempenho.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos fundamentais de #pragma omp atomic",
                                  "subSteps": [
                                    "Estudar a documentação oficial do OpenMP sobre a diretiva atomic (openmp.org).",
                                    "Identificar operações simples suportadas: ++, --, +=, *= com escalares.",
                                    "Analisar exemplo de race condition em loop paralelo sem atomicidade.",
                                    "Explicar em pseudocódigo como atomic garante serialização atômica.",
                                    "Discutir limitações: apenas para expressões simples, não condicionais."
                                  ],
                                  "verification": "Resumir em 3 frases a diferença entre atomic e critical, testando conhecimento com quiz mental.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Documentação OpenMP online, notebook para anotações, código base paralelo simples.",
                                  "tips": "Foquem em operações que são atomicas em hardware (como add em x86).",
                                  "learningObjective": "Dominar quando e por quê usar atomic para evitar race conditions em atualizações compartilhadas simples.",
                                  "commonMistakes": [
                                    "Confundir atomic com critical (atomic é mais eficiente para ops simples)",
                                    "Aplicar atomic a expressões complexas não suportadas pelo compilador"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e testar #pragma omp atomic em código prático",
                                  "subSteps": [
                                    "Criar programa C que inicializa contador compartilhado e loop paralelo com incrementos.",
                                    "Compilar com gcc -fopenmp e executar com OMP_NUM_THREADS=4 sem atomic (observar resultados errados).",
                                    "Adicionar #pragma omp atomic antes da operação de incremento.",
                                    "Executar múltiplas vezes com diferentes números de threads e validar consistência.",
                                    "Medir tempo de execução com omp_get_wtime() para baseline."
                                  ],
                                  "verification": "Contador final deve ser sempre igual ao número esperado de iterações, sem variações.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "GCC com suporte OpenMP, terminal, editor VSCode ou similar.",
                                  "tips": "Use -O2 para otimização e omp_set_num_threads() para controle preciso.",
                                  "learningObjective": "Aplicar atomic para corrigir race conditions em loops paralelos reais.",
                                  "commonMistakes": [
                                    "Esquecer #include <omp.h>",
                                    "Colocar atomic fora do escopo paralelo",
                                    "Ignorar overhead em muitas threads"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar cláusula reduction para agregações paralelas",
                                  "subSteps": [
                                    "Ler specs de reduction no OpenMP: operadores +, *, -, &, |, ^, &&, ||.",
                                    "Entender que reduction usa cópias privadas por thread e combina no final.",
                                    "Identificar operações associativas/comutativas ideais para reduction.",
                                    "Comparar pseudocódigo: soma com atomic vs. reduction(+).",
                                    "Discutir quando reduction é preferível (agregações em loops for)."
                                  ],
                                  "verification": "Listar 5 operadores suportados e explicar por quê min/max precisam de user-defined reductions.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Documentação OpenMP, exemplos de código de repositórios GitHub (openmp examples).",
                                  "tips": "Reduction é otimizado pelo compilador, evite atomic para somas grandes.",
                                  "learningObjective": "Compreender como reduction elimina necessidade de locks em reduções.",
                                  "commonMistakes": [
                                    "Usar reduction em variáveis não inicializadas",
                                    "Aplicar a loops sem agregação",
                                    "Confundir com atomic para ops não-reduzíveis"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar reductions e comparar com atomic",
                                  "subSteps": [
                                    "Modificar código anterior: adicionar array grande e loop for paralelo somando elementos.",
                                    "Implementar versão com atomic em soma compartilhada.",
                                    "Converter para #pragma omp parallel for reduction(+:sum).",
                                    "Executar benchmarks com 2, 4, 8 threads, medindo tempo e corretude.",
                                    "Estender para produto (*) e lógico (&&), validando resultados."
                                  ],
                                  "verification": "Resultados idênticos nas duas versões, mas reduction 2-5x mais rápida em loops longos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Mesmo ambiente do step 2, array de 1e6 elementos para benchmark real.",
                                  "tips": "Use gettimeofday() ou omp_get_wtime() para precisão; teste em multi-core.",
                                  "learningObjective": "Otimizar desempenho escolhendo reduction sobre atomic quando aplicável.",
                                  "commonMistakes": [
                                    "Inicializar reduction var com valor errado",
                                    "Usar reduction em non-associative ops",
                                    "Não verificar serial equivalence"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Melhores práticas, otimização e cenários avançados",
                                  "subSteps": [
                                    "Combinar atomic e reduction no mesmo código (ex: contador + soma).",
                                    "Explorar atomic update/capture/read para ops mais complexas.",
                                    "Analisar overheads: profile com gprof ou Intel VTune.",
                                    "Testar em cenários reais: soma condicional com atomic inner + reduction outer.",
                                    "Documentar diretrizes: prefira reduction para agregações, atomic para updates simples."
                                  ],
                                  "verification": "Código híbrido executa corretamente e speedup observável vs. versão serial.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Profiler tools (perf ou gprof), códigos dos steps anteriores.",
                                  "tips": "Atomic é para <10 ops/thread; reduction escala melhor.",
                                  "learningObjective": "Integrar atomic/reduction para programação paralela otimizada.",
                                  "commonMistakes": [
                                    "Overuse de atomic reduzindo paralelismo",
                                    "Ignorar alinhamento de memória para atomic"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa C para somar array de 1e6 floats em paralelo:\n#include <omp.h>\nfloat sum = 0.0;\n#pragma omp parallel for reduction(+:sum)\nfor(int i=0; i<N; i++) sum += array[i];\n// Vs. atomic: #pragma omp atomic sum += array[i]; (mais lento). Compile: gcc -fopenmp -O3 ex.c -o ex && OMP_NUM_THREADS=8 ./ex",
                              "finalVerifications": [
                                "Códigos com atomic e reduction produzem resultados serialmente equivalentes em 10 execuções com 1-16 threads.",
                                "Tempo de reduction é pelo menos 2x menor que atomic para N=1e7 em 8 threads.",
                                "Nenhum data race detectado por ferramentas como ThreadSanitizer (-fsanitize=thread).",
                                "Operadores lógicos como reduction(&&:flag) funcionam corretamente em cenários condicionais.",
                                "Código compila sem warnings com -Wall -fopenmp em GCC/Clang.",
                                "Overhead de atomic é mensurável e justifica escolha de reduction."
                              ],
                              "assessmentCriteria": [
                                "Explicar corretamente race condition e como atomic/reduction resolvem.",
                                "Implementar código funcional com ambos mecanismos em <30min.",
                                "Identificar cenários onde reduction é inválido (non-associative ops).",
                                "Benchmark demonstra speedup >1.5x com reduction vs. atomic.",
                                "Aplicar corretamente em exemplo novo (ex: produto ou bitwise).",
                                "Discutir trade-offs: atomic para ops raras, reduction para agregações frequentes."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Instruções atômicas CMPXCHG/LOCK em x86 e cache coherence.",
                                "Algoritmos e Estruturas de Dados: Reduções paralelas em prefix-sum e MapReduce.",
                                "Otimização de Software: Profiling de paralelismo e análise de Amdahl.",
                                "Matemática Computacional: Operações associativas em álgebra linear paralela.",
                                "Sistemas Operacionais: Primitivas de sincronização em threads POSIX."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: soma de forças em MD simulations via GROMACS), processamento de dados em machine learning (reduções em gradients no TensorFlow/PyTorch paralelos), e análise de big data (agregações em Spark ou Dask para estatísticas em clusters multi-node)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.3.3",
                            "name": "Gerenciar barreiras e locks",
                            "description": "Inserir barreiras implícitas ou explícitas com #pragma omp barrier e usar omp_init_lock/omp_set_lock para sincronização fina em cenários de memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de barreiras em OpenMP",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP sobre barreiras implícitas e explícitas.",
                                    "Identifique diferenças entre barreiras implícitas (fim de loops paralelos) e explícitas (#pragma omp barrier).",
                                    "Analise exemplos simples de código onde barreiras garantem sincronização de threads.",
                                    "Simule mentalmente o fluxo de execução de threads com e sem barreiras.",
                                    "Registre em um diagrama o comportamento de threads em uma barreira."
                                  ],
                                  "verification": "Crie um diagrama de fluxo mostrando sincronização de 4 threads em uma barreira e explique verbalmente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação OpenMP (openmp.org)",
                                    "Editor de texto ou IDE com suporte OpenMP (ex: VS Code com C/C++ extension)",
                                    "Papel e caneta para diagramas"
                                  ],
                                  "tips": "Lembre-se: barreiras bloqueiam todas as threads até que todas cheguem, ideal para sincronização global.",
                                  "learningObjective": "Explicar o papel das barreiras na sincronização de threads em memória compartilhada.",
                                  "commonMistakes": [
                                    "Confundir barreiras com critical sections (barreiras sincronizam todas, critical só uma)",
                                    "Ignorar que barreiras implícitas já existem em #pragma omp for",
                                    "Usar barreiras desnecessariamente, causando overhead"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar barreiras explícitas em código OpenMP",
                                  "subSteps": [
                                    "Compile um programa OpenMP simples com #pragma omp parallel.",
                                    "Adicione #pragma omp barrier em pontos estratégicos para sincronizar threads.",
                                    "Execute com diferentes números de threads (omp_set_num_threads(4)) e observe saídas.",
                                    "Modifique o código para demonstrar problemas sem barreira (ex: race condition em soma global).",
                                    "Teste com variável de ambiente OMP_BARRIER para depuração."
                                  ],
                                  "verification": "Execute o código e capture saída mostrando sincronização correta (todas threads esperam).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com -fopenmp",
                                    "Terminal para execução (export OMP_NUM_THREADS=4)",
                                    "Código base: parallel loop com soma compartilhada"
                                  ],
                                  "tips": "Use printf com thread ID para visualizar ordem de execução antes/depois da barreira.",
                                  "learningObjective": "Implementar e depurar barreiras explícitas para resolver problemas de sincronização global.",
                                  "commonMistakes": [
                                    "Colocar barreira dentro de critical (redundante)",
                                    "Esquecer de incluir <omp.h>",
                                    "Não definir número de threads, levando a execução serial"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Inicializar e usar locks básicos em OpenMP",
                                  "subSteps": [
                                    "Declare variáveis omp_lock_t no escopo global ou compartilhado.",
                                    "Use omp_init_lock(&lock) antes do parallel region.",
                                    "Implemente omp_set_lock(&lock) para adquirir e omp_unset_lock(&lock) para liberar.",
                                    "Teste em uma seção crítica simulando acesso concorrente a uma variável compartilhada.",
                                    "Adicione omp_destroy_lock(&lock) após o parallel region."
                                  ],
                                  "verification": "Código executa sem race conditions em contador compartilhado, verificado com múltiplas runs.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Mesmo compilador e terminal do step 2",
                                    "Código exemplo com contador thread-safe"
                                  ],
                                  "tips": "Locks são para exclusão mútua fina; use nestable locks (omp_nest_lock_t) se necessário.",
                                  "learningObjective": "Gerenciar ciclo de vida de locks para proteger seções críticas em memória compartilhada.",
                                  "commonMistakes": [
                                    "Esquecer omp_destroy_lock, causando leaks",
                                    "Deadlock por esquecer unset_lock",
                                    "Usar locks em loops sem necessidade (prefira reduction)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Combinar barreiras e locks em cenários avançados",
                                  "subSteps": [
                                    "Crie um programa onde threads processam dados em etapas: produção (com locks), barreira, consumo (com locks).",
                                    "Simule producer-consumer com array compartilhado, usando locks para updates e barreira para fases.",
                                    "Otimize código medindo tempo com omp_get_wtime().",
                                    "Depure com ferramentas como omp_get_thread_num() e condicionais.",
                                    "Compare performance com e sem sincronizações."
                                  ],
                                  "verification": "Programa completa tarefas corretamente com 8 threads, sem erros de dados e tempo < threshold.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Compilador, terminal",
                                    "Código base producer-consumer",
                                    "Relógio para timing"
                                  ],
                                  "tips": "Locks para granularidade fina, barreiras para sincronização coletiva; evite overuse.",
                                  "learningObjective": "Integrar barreiras e locks para sincronização eficiente em aplicações paralelas.",
                                  "commonMistakes": [
                                    "Barreira dentro de lock (ineficiente)",
                                    "Locks desbalanceados causando starvation",
                                    "Ignorar ordem: init antes parallel"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e otimizar sincronizações",
                                  "subSteps": [
                                    "Profile o código com ferramentas como gprof ou Intel VTune.",
                                    "Identifique bottlenecks em barreiras/locks.",
                                    "Substitua locks por atomic onde possível.",
                                    "Teste escalabilidade variando threads.",
                                    "Documente trade-offs em um relatório curto."
                                  ],
                                  "verification": "Relatório com métricas mostrando otimização (ex: speedup > 2x).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Profiler (gprof ou similar)",
                                    "Gráficos de performance (matplotlib ou Excel)"
                                  ],
                                  "tips": "Prefira atomic directives sobre locks para operações simples.",
                                  "learningObjective": "Otimizar uso de barreiras e locks para performance em cenários reais.",
                                  "commonMistakes": [
                                    "Over-sincronização reduzindo paralelismo",
                                    "Não testar com alto número de threads"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um simulador de Monte Carlo para estimar Pi, threads geram pontos aleatórios em paralelo (lock para atualizar contador de acertos compartilhado), barreira para sincronizar após 1000 iterações por thread, então próxima fase. Código: omp_lock_t count_lock; omp_init_lock(&count_lock); #pragma omp parallel { /* gerar pontos */ omp_set_lock(&count_lock); hits++; omp_unset_lock(&count_lock); } #pragma omp barrier;",
                              "finalVerifications": [
                                "Implementa barreira explícita corretamente em loop paralelo sem erros de compilação.",
                                "Programa com locks executa sem race conditions em 10 runs com 8 threads.",
                                "Explica diferença entre barreira global e lock para exclusão mútua.",
                                "Combina ambos em producer-consumer sem deadlocks ou starvation.",
                                "Otimiza código reduzindo tempo de execução em 20%.",
                                "Debuga problemas comuns como forgotten destroy_lock."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação: 0 race conditions ou deadlocks (40%)",
                                "Eficiência: Uso mínimo de sincronizações com bom speedup (30%)",
                                "Compreensão conceitual: Explicação clara de conceitos (20%)",
                                "Código limpo e comentado: Boas práticas OpenMP (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Conceitos de semáforos e mutex semelhantes a locks.",
                                "Algoritmos e Estruturas de Dados: Producer-consumer e buffers circulares.",
                                "Engenharia de Software: Thread-safety e design concurrente.",
                                "Matemática Computacional: Aplicações em simulações paralelas."
                              ],
                              "realWorldApplication": "Em processamento de imagens paralelas (ex: Photoshop filters), locks protegem pixels compartilhados durante blends, barreiras sincronizam camadas de processamento; ou em bancos de dados in-memory (Redis clusters) para updates atômicos em cenários multi-threaded."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.4",
                "name": "Linguagens de Programação Paralela",
                "description": "Explora linguagens para plataformas multicores, heterogêneas e na nuvem.",
                "totalSkills": 46,
                "atomicTopics": [
                  {
                    "id": "10.1.4.1",
                    "name": "OpenMP para Plataformas Multicores",
                    "description": "Linguagem para programação paralela em memória compartilhada, com suporte a tasking, affinity e SIMD em processadores multi-core.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.1.1",
                        "name": "Diretivas Básicas de OpenMP para Memória Compartilhada",
                        "description": "Introdução às diretivas fundamentais do OpenMP para paralelização em plataformas multicores, focando em modelos de memória compartilhada, taxonomia de Flynn (SIMD/MIMD) e paralelismo em loops e seções.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.1.1.1",
                            "name": "Implementar diretiva #pragma omp parallel",
                            "description": "Criar regiões paralelas básicas utilizando a diretiva #pragma omp parallel para executar código em múltiplas threads em memória compartilhada, controlando o número de threads com omp_set_num_threads().",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento para OpenMP",
                                  "subSteps": [
                                    "Instale um compilador compatível com OpenMP, como GCC ou Clang.",
                                    "Verifique o suporte a OpenMP executando 'gcc --version' e confirme versão >= 4.2.",
                                    "Compile um programa de teste simples com flag '-fopenmp' para validar o ambiente.",
                                    "Configure um editor de texto ou IDE (ex: VS Code com extensão C/C++) com suporte a C/C++.",
                                    "Crie um diretório de projeto e um arquivo fonte básico (hello.c)."
                                  ],
                                  "verification": "Compilação bem-sucedida de um programa OpenMP de teste sem erros de linking.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang",
                                    "Editor de texto/IDE",
                                    "Terminal/Shell"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' no terminal para testar configurações iniciais.",
                                  "learningObjective": "Preparar um ambiente funcional para programação paralela com OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer de instalar libgomp",
                                    "Usar flag errada (-openmp ao invés de -fopenmp)",
                                    "Não verificar versão do compilador"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a diretiva básica #pragma omp parallel",
                                  "subSteps": [
                                    "Inclua o header '<omp.h>' no topo do arquivo C/C++.",
                                    "Escreva uma função main() com #pragma omp parallel { printf('Hello from thread %d\\n', omp_get_thread_num()); }.",
                                    "Adicione #include <stdio.h> para printf e fflush(stdout) para sincronizar saídas.",
                                    "Use omp_get_thread_num() para identificar threads e omp_get_num_threads() para contar.",
                                    "Salve o arquivo e prepare para compilação."
                                  ],
                                  "verification": "Código compila e executa imprimindo mensagens de múltiplas threads (pelo menos 2).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Arquivo fonte C/C++ (ex: parallel_basic.c)",
                                    "Compilador com -fopenmp"
                                  ],
                                  "tips": "Sempre use chaves {} na região paralela para delimitar o escopo claramente.",
                                  "learningObjective": "Criar uma região paralela básica que distribui execução para múltiplas threads.",
                                  "commonMistakes": [
                                    "Esquecer #include <omp.h>",
                                    "Não usar omp_get_thread_num() para distinção",
                                    "Saídas embaralhadas sem fflush"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Controlar o número de threads com omp_set_num_threads()",
                                  "subSteps": [
                                    "Inclua omp_set_num_threads(4); antes da região paralela para fixar 4 threads.",
                                    "Teste diferentes valores (2, 4, 8) e observe omp_get_num_threads() na saída.",
                                    "Compare execução com e sem a função para entender o padrão de comportamento.",
                                    "Adicione uma variável compartilhada (ex: int shared_var = 0;) acessada por todas threads.",
                                    "Execute com variáveis de ambiente como OMP_NUM_THREADS para override."
                                  ],
                                  "verification": "Saída confirma exatamente o número de threads definido, independentemente do hardware.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código do Step 2 modificado",
                                    "Terminal para export OMP_NUM_THREADS"
                                  ],
                                  "tips": "Chame omp_set_num_threads() antes de qualquer região paralela para efeito global.",
                                  "learningObjective": "Dominar o controle explícito do número de threads em regiões paralelas.",
                                  "commonMistakes": [
                                    "Chamar omp_set_num_threads() dentro da região paralela",
                                    "Ignorar limite de hardware",
                                    "Confundir com variável de ambiente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Compilar, executar e validar o paralelismo",
                                  "subSteps": [
                                    "Compile com 'gcc -fopenmp -o parallel_app parallel_basic.c'.",
                                    "Execute './parallel_app' e capture saídas para análise.",
                                    "Use 'time ./parallel_app' para medir speedup básico vs versão sequencial.",
                                    "Valide com 'htop' ou 'top' para ver múltiplos threads do processo.",
                                    "Debug erros comuns como race conditions em variáveis compartilhadas."
                                  ],
                                  "verification": "Programa executa em múltiplas threads confirmadas por saída e ferramentas de monitoramento.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Executável compilado",
                                    "Ferramentas: time, htop/top"
                                  ],
                                  "tips": "Compile com -O2 para otimização e compare tempos de execução.",
                                  "learningObjective": "Validar e depurar implementações paralelas básicas de OpenMP.",
                                  "commonMistakes": [
                                    "Flag de compilação errada causando linking falho",
                                    "Interpretar saídas embaralhadas como erro",
                                    "Não medir performance"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa 'pi_approx.c' que usa #pragma omp parallel com omp_set_num_threads(4) para aproximar Pi via método de Monte Carlo: cada thread gera pontos aleatórios em um quadrado e conta acertos no círculo inscrito, somando resultados em uma variável compartilhada com redução futura.",
                              "finalVerifications": [
                                "Código compila sem warnings com -fopenmp e -Wall.",
                                "Execução mostra exatamente o número de threads definido via omp_get_num_threads().",
                                "Saídas de threads são distintas e não há crashes por memória compartilhada.",
                                "Tempo de execução é menor que versão sequencial equivalente.",
                                "Monitoramento (htop) confirma uso de múltiplas threads.",
                                "omp_set_num_threads() override variável de ambiente corretamente."
                              ],
                              "assessmentCriteria": [
                                "Uso correto de #pragma omp parallel com escopo delimitado por {}.",
                                "Inclusão adequada de <omp.h> e funções OpenMP como omp_get_thread_num().",
                                "Controle preciso de threads via omp_set_num_threads() antes da região.",
                                "Verificação de paralelismo via impressões únicas por thread.",
                                "Compilação e execução sem erros em ambiente padrão.",
                                "Comentários no código explicando memória compartilhada."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Entender núcleos multicore e threads de hardware.",
                                "Algoritmos e Estruturas de Dados: Paralelização de loops e reduções.",
                                "Matemática Computacional: Aplicações em simulações numéricas paralelas.",
                                "Sistemas Operacionais: Gerenciamento de processos e threads pelo SO.",
                                "Engenharia de Software: Boas práticas em programação paralela."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática ou processamento de imagens médicas (ex: MRI), onde #pragma omp parallel acelera computações intensivas dividindo workloads em threads para reduzir tempo de execução de horas para minutos em servidores multicore."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.1.1.2",
                            "name": "Paralelizar loops com #pragma omp for",
                            "description": "Aplicar a diretiva #pragma omp for para distribuir iterações de loops entre threads, gerenciando dependências de dados e cláusulas como schedule (static/dynamic) para balanceamento de carga.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente OpenMP e preparar código sequencial",
                                  "subSteps": [
                                    "Instale um compilador compatível com OpenMP, como GCC ou Clang.",
                                    "Compile um programa simples com flag -fopenmp para ativar suporte OpenMP.",
                                    "Escreva ou obtenha um código sequencial com um loop for simples, como soma de elementos de um array.",
                                    "Execute o código sequencial e meça o tempo de execução com múltiplos tamanhos de input.",
                                    "Defina variáveis de ambiente OMP_NUM_THREADS=4 para testes iniciais."
                                  ],
                                  "verification": "Código sequencial compila e executa corretamente, exibindo tempo de execução baseline.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com OpenMP",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' no Linux/Mac ou 'set OMP_NUM_THREADS=4' no Windows para controlar threads.",
                                  "learningObjective": "Configurar corretamente o ambiente para experimentação com OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp ao compilar",
                                    "Não definir OMP_NUM_THREADS levando a uso de 1 thread por default"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar loops paralelizáveis e analisar dependências de dados",
                                  "subSteps": [
                                    "Revise o loop sequencial: verifique se as iterações são independentes (sem dependências de escrita/leitura entre iterações).",
                                    "Identifique padrões de dependências: loop com redução (ex: soma), ou loops com atualizações independentes.",
                                    "Anote potenciais problemas como race conditions em variáveis compartilhadas.",
                                    "Teste manualmente dividindo o loop em partes para simular paralelismo.",
                                    "Documente por que o loop é ou não candidato ideal para #pragma omp for."
                                  ],
                                  "verification": "Lista documentada de dependências e confirmação de independência iterativa.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código sequencial preparado",
                                    "Papel ou documento para anotações"
                                  ],
                                  "tips": "Lembre-se: loops com dependências de redução precisam de cláusula 'reduction'.",
                                  "learningObjective": "Analisar corretamente a paralelização segura de loops.",
                                  "commonMistakes": [
                                    "Ignorar dependências de leitura/escrita levando a race conditions",
                                    "Confundir independência iterativa com independência total"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar #pragma omp for básico e cláusula schedule(static)",
                                  "subSteps": [
                                    "Adicione #pragma omp parallel for antes do loop for.",
                                    "Compile e execute com diferentes OMP_NUM_THREADS, medindo speedup.",
                                    "Introduza cláusula schedule(static) para distribuição uniforme de iterações.",
                                    "Compare tempos com schedule(static, chunk_size) variando chunk_size.",
                                    "Registre métricas: tempo total, speedup e eficiência."
                                  ],
                                  "verification": "Programa acelera linearmente com mais threads sem erros de race condition.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código do Step 2",
                                    "Cronômetro ou função gettimeofday para medição"
                                  ],
                                  "tips": "Use chunk_size = número de iterações / threads para balanceamento ideal em static.",
                                  "learningObjective": "Implementar paralelização básica com distribuição estática de carga.",
                                  "commonMistakes": [
                                    "Omitir #pragma omp parallel",
                                    "Usar schedule sem testar chunk_size levando a load imbalance"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Gerenciar dependências avançadas e schedule(dynamic/guided)",
                                  "subSteps": [
                                    "Adicione cláusula reduction(+:soma) para loops de redução.",
                                    "Teste schedule(dynamic) para workloads irregulares.",
                                    "Experimente schedule(guided) e compare overhead com static/dynamic.",
                                    "Introduza private/shared clauses se houver variáveis locais/globais.",
                                    "Debugue com OMP_DISPLAY_ENV=TRUE e verifique output de threads."
                                  ],
                                  "verification": "Execução correta com reduction, speedup >1.5x em dynamic/guided para loads desbalanceados.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Código do Step 3",
                                    "Exemplos de workloads irregulares (array com tamanhos variados)"
                                  ],
                                  "tips": "Dynamic tem overhead alto; use guided para workloads com iterações de tempo variável.",
                                  "learningObjective": "Otimizar paralelização com cláusulas para dependências e balanceamento.",
                                  "commonMistakes": [
                                    "Esquecer reduction causando resultados incorretos",
                                    "Abusar de dynamic em workloads uniformes"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar, otimizar e validar performance",
                                  "subSteps": [
                                    "Execute com inputs variados (pequeno/grande) e múltiplos threads.",
                                    "Meça speedup, eficiência e strong/weak scaling.",
                                    "Use ferramentas como omp_get_wtime() para precisão.",
                                    "Otimize escolhendo melhor schedule baseado em perfil.",
                                    "Compare com versão sequencial para validar corretude numérica."
                                  ],
                                  "verification": "Speedup ≥ 2x em 4 threads, resultados idênticos ao sequencial.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Scripts de teste automatizados",
                                    "Gráficos de performance (opcional: Python/Matplotlib)"
                                  ],
                                  "tips": "Amdahl's Law: foque em frações paralelizáveis altas.",
                                  "learningObjective": "Avaliar e otimizar performance de loops paralelos.",
                                  "commonMistakes": [
                                    "Não validar corretude numérica",
                                    "Ignorar overhead de thread creation"
                                  ]
                                }
                              ],
                              "practicalExample": "Código C para calcular soma de array: for(int i=0; i<N; i++) sum += a[i]; Torna-se #pragma omp parallel for reduction(+:sum) schedule(dynamic) for(int i=0; i<N; i++) sum += a[i]; Compile: gcc -fopenmp -O2 soma.c -o soma. Execute: OMP_NUM_THREADS=4 ./soma 100000000, medindo speedup de ~3.5x em quad-core.",
                              "finalVerifications": [
                                "Código compila sem warnings OpenMP.",
                                "Execução usa múltiplas threads (verifique com top/htop).",
                                "Resultados numéricos idênticos ao sequencial.",
                                "Speedup positivo com aumento de threads.",
                                "Nenhum crash ou race condition em runs repetidos.",
                                "Escolha correta de schedule baseada em workload."
                              ],
                              "assessmentCriteria": [
                                "Identificação precisa de dependências de dados (100% corretude).",
                                "Uso correto de #pragma omp for com cláusulas essenciais.",
                                "Medição e análise de performance com speedup quantificado.",
                                "Otimização via schedule escolhendo o melhor para cenários dados.",
                                "Documentação clara de passos e lições aprendidas.",
                                "Tratamento de reduction/private/shared quando aplicável."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise de complexidade e Amdahl's Law para scaling.",
                                "Arquitetura de Computadores: Entendimento de caches e memória compartilhada em multicores.",
                                "Algoritmos: Paralelização de algoritmos clássicos como prefix sum ou Monte Carlo.",
                                "Engenharia de Software: Debugging paralelo e profiling com tools como VTune.",
                                "Física/Engenharia: Aplicações em simulações numéricas (CFD, ML)."
                              ],
                              "realWorldApplication": "Em computação científica, como aceleração de simulações climáticas (loop sobre grid cells), processamento de imagens (filtros paralelos em pixels) ou machine learning (treinamento de batches em CPUs multicores), reduzindo tempo de computação de horas para minutos em clusters HPC."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.1.1.3",
                            "name": "Gerenciar variáveis privadas e compartilhadas",
                            "description": "Utilizar cláusulas private, shared e firstprivate para controlar o escopo de variáveis em regiões paralelas, evitando condições de corrida em programas multithread.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o comportamento padrão de variáveis em regiões paralelas OpenMP",
                                  "subSteps": [
                                    "Compile e execute um programa OpenMP simples com #pragma omp parallel sem cláusulas de dados.",
                                    "Observe que variáveis declaradas fora da região paralela são compartilhadas por padrão entre threads.",
                                    "Introduza uma condição de corrida modificando uma variável compartilhada sem sincronização.",
                                    "Execute com OMP_NUM_THREADS=4 e analise saídas inconsistentes devido a race condition.",
                                    "Consulte a documentação OpenMP para confirmar regras padrão de compartilhamento."
                                  ],
                                  "verification": "Programa compila e executa mostrando resultados inconsistentes em múltiplas threads, confirmando race condition.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Compilador GCC/Clang com suporte OpenMP (g++ -fopenmp), editor de código, terminal.",
                                  "tips": "Use printf com thread ID (%d: thread %d) para visualizar acessos concorrentes.",
                                  "learningObjective": "Identificar o comportamento shared por padrão e impactos de race conditions em OpenMP.",
                                  "commonMistakes": "Assumir que variáveis locais são privadas por padrão; ignorar que escopo lexical determina visibilidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar cláusula 'private' para variáveis exclusivas por thread",
                                  "subSteps": [
                                    "Modifique o loop paralelo adicionando 'private(i)' onde i é o índice do loop.",
                                    "Compile e execute, verificando que cada thread tem sua própria cópia de i, eliminando race no índice.",
                                    "Teste com uma variável contador local adicionando 'private(contador)' e inicialize-a manualmente em cada thread.",
                                    "Compare desempenho e resultados com e sem private.",
                                    "Adicione barriers para observar isolamento de dados privados."
                                  ],
                                  "verification": "Execução com múltiplas threads produz resultados consistentes sem race conditions no índice ou contador privado.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Mesmo compilador OpenMP, código base do Step 1 modificado.",
                                  "tips": "Sempre torne índices de loop private para evitar undefined behavior em for paralelos.",
                                  "learningObjective": "Aplicar 'private' para criar cópias independentes por thread e prevenir acessos concorrentes indesejados.",
                                  "commonMistakes": "Esquecer de listar todas as variáveis que precisam ser privadas; usar private em variáveis que precisam de comunicação."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Utilizar cláusula 'shared' para variáveis globais acessíveis por todas threads",
                                  "subSteps": [
                                    "Declare uma variável soma global e use 'shared(soma)' explicitamente em #pragma omp parallel for.",
                                    "Implemente uma soma ingênua sem proteção, observe race, então adicione critical ou reduction (mas foque em shared).",
                                    "Execute com diferentes números de threads e monitore valor final de soma.",
                                    "Combine shared com private em um programa de soma de array.",
                                    "Analise saída para confirmar que todas threads leem/escrevem a mesma memória."
                                  ],
                                  "verification": "Todas threads acessam e modificam a mesma variável shared, mas com race detectável sem sincronização adicional.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Compilador OpenMP, array de teste com 1000 elementos.",
                                  "tips": "Use shared apenas quando sincronização (critical, atomic) for usada para evitar races.",
                                  "learningObjective": "Controlar explicitamente o compartilhamento de variáveis que requerem coordenação entre threads.",
                                  "commonMistakes": "Declarar variáveis shared desnecessariamente levando a overhead; confundir com private."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar cláusula 'firstprivate' para inicialização de variáveis privadas",
                                  "subSteps": [
                                    "Crie uma variável com valor inicial fora da região paralela e use 'firstprivate(var)' em parallel.",
                                    "Verifique que cada thread recebe o valor inicial correto, diferentemente de private (não inicializado).",
                                    "Teste em um cenário onde contador precisa começar com valor master, como em loop de processamento.",
                                    "Compare saída com private vs firstprivate usando gdb ou printf.",
                                    "Integre firstprivate com private e shared em um programa completo de soma paralela."
                                  ],
                                  "verification": "Cada thread inicia com o valor correto da variável firstprivate, confirmado por logs de thread.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Compilador OpenMP, debugger opcional (gdb -fopenmp).",
                                  "tips": "Use firstprivate para variáveis derivadas do master que não devem ser sobrescritas por threads.",
                                  "learningObjective": "Inicializar corretamente cópias privadas com valores do thread master.",
                                  "commonMistakes": "Usar private quando inicialização é necessária, levando a garbage values; ignorar que firstprivate copia apenas no início."
                                }
                              ],
                              "practicalExample": "Em um programa de soma paralela de array: int soma = 0; #pragma omp parallel for private(i) shared(soma) firstprivate(n) for(int i=0; i<n; i++) { soma += array[i]; } Isso torna i privado (evita race no índice), soma compartilhada (acumula resultado), n firstprivate (cada thread conhece tamanho sem race). Compile com g++ -fopenmp soma.cpp -o soma; OMP_NUM_THREADS=4 ./soma. Resultado correto: soma total do array.",
                              "finalVerifications": [
                                "Programa compila sem warnings OpenMP e executa corretamente com 2-8 threads.",
                                "Nenhuma race condition observada em soma ou índices (resultados idênticos em runs repetidos).",
                                "Logs mostram inicialização correta via firstprivate em todas threads.",
                                "Desempenho escala com mais threads sem overhead desnecessário.",
                                "Substituição por private puro causa falha na inicialização, confirmando necessidade de firstprivate.",
                                "Integração com reduction() produz mesmo resultado, validando gerenciamento manual."
                              ],
                              "assessmentCriteria": [
                                "Correta identificação e correção de race conditions usando private/shared/firstprivate.",
                                "Código compila e executa consistentemente em múltiplas configurações de threads.",
                                "Explicação clara das diferenças entre private, shared e firstprivate em relatório.",
                                "Eficiência: sem overhead desnecessário (ex: não tornar soma private).",
                                "Aplicação em exemplo real: soma paralela sem erros.",
                                "Debugging: uso de printf ou tools para verificar escopo de variáveis."
                              ],
                              "crossCurricularConnections": [
                                "Programação Sequencial: transição de loops for para parallel for com gerenciamento de estado.",
                                "Sistemas Operacionais: conceitos de threads, mutex e memória compartilhada em POSIX threads.",
                                "Algoritmos: paralelização de reduções e prefix sums.",
                                "Engenharia de Software: boas práticas de thread-safety e data races."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (NASA), onde threads compartilham grids globais (shared) mas usam contadores locais privados (private/firstprivate) para processar pixels independentes, evitando races e escalando em multicore CPUs."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.1.2",
                        "name": "Tasking em OpenMP",
                        "description": "Mecanismos de tasking para programação paralela dinâmica em OpenMP, permitindo criação e gerenciamento de tarefas independentes em árvores de tarefas para aplicações irregulares em multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.1.2.1",
                            "name": "Criar e executar tasks com #pragma omp task",
                            "description": "Implementar diretivas #pragma omp task e #pragma omp taskwait para gerar tarefas assíncronas e sincronizá-las, otimizando workloads irregulares como processamento de grafos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente e revisar conceitos básicos de tasks em OpenMP",
                                  "subSteps": [
                                    "Instale e configure um compilador com suporte a OpenMP (ex: g++ com flag -fopenmp).",
                                    "Compile e execute um programa OpenMP básico com #pragma omp parallel para revisar regiões paralelas.",
                                    "Estude a documentação oficial do OpenMP sobre tasks: tasks são unidades de trabalho assíncronas gerenciadas pelo runtime.",
                                    "Identifique cenários para tasks: workloads irregulares onde o número de iterações varia (ex: grafos).",
                                    "Crie um esqueleto de código com omp_set_num_threads(4) para testes controlados."
                                  ],
                                  "verification": "Compilar e executar o programa básico sem erros, observando saída paralela com múltiplas threads.",
                                  "estimatedTime": "30 minutes",
                                  "materials": [
                                    "Compilador g++ ou clang com OpenMP",
                                    "Documentação OpenMP 5.0+",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Use OMP_NUM_THREADS=4 no ambiente para testes reprodutíveis; visualize threads com printf.",
                                  "learningObjective": "Compreender o modelo de tasks como blocos assíncronos distintos de loops paralelos.",
                                  "commonMistakes": [
                                    "Esquecer a flag -fopenmp no compile",
                                    "Confundir tasks com sections (tasks são dinâmicas)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar #pragma omp task para criar tarefas assíncronas",
                                  "subSteps": [
                                    "Adicione #pragma omp parallel ao esqueleto e dentro dele, use #pragma omp task para uma função simples (ex: calcular fatorial).",
                                    "Defina uma função void task_func(int n) que imprima o ID da thread e compute algo.",
                                    "Chame task_func dentro de um loop: for(int i=0; i<10; i++) { #pragma omp task task_func(i); }",
                                    "Compile e execute, observando que tasks são despachadas assincronamente para threads ociosas.",
                                    "Meça tempo com omp_get_wtime() para comparar com versão sequencial."
                                  ],
                                  "verification": "Saída mostra tasks executadas em threads diferentes, fora de ordem sequencial, com speedup observável.",
                                  "estimatedTime": "45 minutes",
                                  "materials": [
                                    "Código base do Step 1",
                                    "Timer OpenMP (omp_get_wtime)",
                                    "Profiler básico como gprof"
                                  ],
                                  "tips": "Use task firstprivate para variáveis locais; evite dependências implícitas.",
                                  "learningObjective": "Criar e despachar tasks assíncronas que rodam em threads disponíveis.",
                                  "commonMistakes": [
                                    "Não usar parallel region pai",
                                    "Compartilhar variáveis sem atomic ou reduction"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Sincronizar tasks com #pragma omp taskwait",
                                  "subSteps": [
                                    "Adicione #pragma omp taskwait após o loop de tasks para aguardar conclusão de todas filhas.",
                                    "Teste sem taskwait: observe que o programa termina prematuramente sem imprimir todas tasks.",
                                    "Com taskwait: confirme que todas tasks completam antes de prosseguir.",
                                    "Experimente taskwait em pontos intermediários para sincronizações parciais.",
                                    "Meça overhead: compare performance com e sem tasks vs. parallel for."
                                  ],
                                  "verification": "Programa com taskwait imprime todas tasks completas; sem taskwait, saída incompleta.",
                                  "estimatedTime": "40 minutes",
                                  "materials": [
                                    "Código do Step 2",
                                    "Exemplos de código OpenMP tasking do site oficial"
                                  ],
                                  "tips": "Taskwait é leve; use taskgroup para subgrupos se necessário em versões avançadas.",
                                  "learningObjective": "Garantir sincronização explícita de tasks filhas antes de ações dependentes.",
                                  "commonMistakes": [
                                    "Usar barrier em vez de taskwait (barrier sincroniza todas threads, não só tasks)",
                                    "Ignorar taskwait em funções recursivas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em workload irregular: processamento de grafos",
                                  "subSteps": [
                                    "Crie uma estrutura de grafo simples (adjacency list com 100 nós aleatórios).",
                                    "Use tasks para processar vizinhos de cada nó: #pragma omp task em loop sobre nós raiz.",
                                    "Implemente uma BFS task-based: task por nó, taskwait após gerações.",
                                    "Otimize com if(0) #pragma omp task para threshold de granulosidade.",
                                    "Profile com omp_get_wtime e compare speedup em máquina multicore."
                                  ],
                                  "verification": "Grafo processado corretamente em paralelo, com speedup > 2x vs. sequencial.",
                                  "estimatedTime": "60 minutes",
                                  "materials": [
                                    "Biblioteca std::vector para grafos",
                                    "Gerador de grafos aleatórios (código simples)"
                                  ],
                                  "tips": "Ajuste threshold em task para evitar overhead em tasks minúsculas; use depend para dependências.",
                                  "learningObjective": "Otimizar workloads irregulares como grafos usando tasking dinâmico.",
                                  "commonMistakes": [
                                    "Tasks muito finas (overhead domina)",
                                    "Corrida em lista de adjacência sem locks"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um algoritmo BFS para grafo de rede social (1000 nós), use #pragma omp task para enfileirar processamento de vizinhos de cada nó descoberto, com taskwait no final de cada camada para sincronizar e evitar explosão de tasks pendentes. Isso paraleliza eficientemente o traversamento irregular.",
                              "finalVerifications": [
                                "Compilar e executar código com tasks sem warnings de OpenMP.",
                                "Todas tasks completam corretamente com taskwait, sem saídas pendentes.",
                                "Medir speedup: pelo menos 2x em 4 cores para workload de grafo.",
                                "Usar gdb ou valgrind para confirmar ausência de data races.",
                                "Adaptar código para diferentes tamanhos de grafo e observar escalabilidade.",
                                "Explicar verbalmente diferença entre task e parallel for."
                              ],
                              "assessmentCriteria": [
                                "Correta sintaxe e uso de #pragma omp task e taskwait.",
                                "Sincronização adequada sem deadlocks ou races.",
                                "Eficiência: overhead de tasks < 20% do tempo total.",
                                "Granulosidade otimizada com threshold.",
                                "Código limpo, comentado e modular.",
                                "Evidência de speedup mensurável em testes."
                              ],
                              "crossCurricularConnections": [
                                "Teoria dos Grafos: Tasking modela traversamentos paralelos (BFS/DFS).",
                                "Algoritmos e Estruturas de Dados: Paralelização de workloads dinâmicos.",
                                "Sistemas Operacionais: Gerenciamento de threads e scheduling pelo runtime OpenMP.",
                                "Engenharia de Software: Modularidade em funções task-based.",
                                "Computação de Alto Desempenho (HPC): Aplicações em clusters multicore."
                              ],
                              "realWorldApplication": "Em simulações científicas como análise de redes sociais (ex: Facebook graph traversal), processamento de imagens irregulares ou machine learning com árvores de decisão (ex: random forests), onde tasks distribuem workloads dinâmicos em CPUs multicore para aceleração real-time."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.4.1.2.2",
                            "name": "Utilizar task depend para dependências",
                            "description": "Aplicar cláusula depend (in/out/inout) em tasks para expressar dependências de dados, habilitando agendamento eficiente pelo runtime OpenMP em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de Task Depend no OpenMP",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP sobre tasking e dependências de dados.",
                                    "Identifique como tasks sem dependências são agendadas de forma independente pelo runtime.",
                                    "Aprenda os tipos de dependência: in (leitura), out (escrita), inout (leitura+escrita).",
                                    "Analise diagramas de grafo de dependências para visualizar fluxos de dados entre tasks.",
                                    "Compare task depend com taskwait para entender diferenças em sincronização."
                                  ],
                                  "verification": "Resuma em suas palavras os tipos de dependência e crie um diagrama simples de dependências entre 3 tasks.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação OpenMP 5.0+ (openmp.org)",
                                    "Editor de texto ou papel para diagramas"
                                  ],
                                  "tips": "Use analogias como 'correntes de produção' onde uma task só prossegue após a anterior fornecer dados.",
                                  "learningObjective": "Explicar como task depend modela dependências de dados para otimizar agendamento em multicores.",
                                  "commonMistakes": [
                                    "Confundir depend com sincronização explícita como taskwait",
                                    "Ignorar que dependências são baseadas em endereços de memória, não variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Dominar a Sintaxe da Cláusula Depend em Tasks",
                                  "subSteps": [
                                    "Escreva a sintaxe básica: #pragma omp task depend(out: var1) { ... }",
                                    "Pratique variações: depend(in: var2), depend(inout: var3), múltiplas variáveis (depend(in: a,b)).",
                                    "Compile códigos mínimos para testar erros de sintaxe com g++ -fopenmp.",
                                    "Explore dependências vetoriais com sink/source para arrays.",
                                    "Teste combinação com outras cláusulas como if, final."
                                  ],
                                  "verification": "Compile e execute 3 snippets de código com diferentes tipos de depend, confirmando ausência de warnings.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte OpenMP (g++ -fopenmp)",
                                    "Ambiente Linux/Mac com múltiplos cores"
                                  ],
                                  "tips": "Sempre especifique dependências explícitas para evitar ordem imprevisível de execução.",
                                  "learningObjective": "Escrever corretamente a cláusula depend para diferentes cenários de fluxo de dados.",
                                  "commonMistakes": [
                                    "Esquecer dois pontos após depend",
                                    "Usar variáveis não declaradas nas dependências",
                                    "Misturar tipos in/out incorretamente levando a races"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Task Depend em um Programa Prático",
                                  "subSteps": [
                                    "Crie um programa que divida um array em tasks produtoras/consumidoras com dependências.",
                                    "Implemente uma task que preenche um array (out), outra que soma prefixos (inout), e uma final que agrega (in).",
                                    "Adicione #pragma omp parallel para lançar tasks em múltiplos threads.",
                                    "Execute com OMP_NUM_THREADS=4 e observe ordem via prints.",
                                    "Modifique para adicionar dependências circulares intencionalmente e corrija."
                                  ],
                                  "verification": "O programa executa corretamente em paralelo, com resultados idênticos à versão serial e sem data races (valgrind --tool=helgrind).",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Código-fonte inicial fornecido ou template OpenMP",
                                    "Valgrind ou ThreadSanitizer para detecção de races"
                                  ],
                                  "tips": "Use variáveis globais ou alocadas dinamicamente para dependências claras por endereço.",
                                  "learningObjective": "Construir um programa funcional usando task depend para gerenciar fluxos de dados paralelos.",
                                  "commonMistakes": [
                                    "Não inicializar variáveis antes de depend(in)",
                                    "Dependências desnecessárias que serializam tasks",
                                    "Falta de região parallel"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e Otimizar Agendamento com Task Depend",
                                  "subSteps": [
                                    "Meça tempo de execução com/ sem depend usando omp_get_wtime().",
                                    "Visualize grafo de tasks com ferramentas como OMP Collapsing ou Intel VTune.",
                                    "Otimize removendo dependências excessivas e adicionando taskloop se aplicável.",
                                    "Teste escalabilidade variando OMP_NUM_THREADS de 1 a 16.",
                                    "Compare performance com mutexes ou critical para o mesmo problema."
                                  ],
                                  "verification": "Gráfico de speedup mostra melhoria >1.5x com depend vs. sem, e ausência de falsos compartilhamentos.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Intel VTune ou Vampir para tracing OpenMP",
                                    "Scripts para medição de tempo"
                                  ],
                                  "tips": "Foquem em dependências mínimas para maximizar paralelismo.",
                                  "learningObjective": "Avaliar e refinar o uso de task depend para eficiência em multicores.",
                                  "commonMistakes": [
                                    "Sobre-especificar dependências reduzindo paralelismo",
                                    "Ignorar overhead de tasks leves",
                                    "Não validar com ferramentas de profiling"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um pipeline de processamento de imagem: task1 (depend(out: imagem_raw)) lê e filtra imagem; task2 (depend(in: imagem_raw, out: imagem_filtrada)) aplica blur; task3 (depend(in: imagem_filtrada)) calcula histograma. Isso garante task3 só após task2, otimizando cache em multicores.",
                              "finalVerifications": [
                                "Código compila e executa sem erros ou warnings OpenMP.",
                                "Execução paralela produz resultados corretos idênticos à serial.",
                                "Ferramentas de race detection (helgrind) confirmam ausência de data races.",
                                "Ordem de tasks respeita dependências via logs de execução.",
                                "Speedup mensurável >1.2x com múltiplos threads.",
                                "Grafo de dependências pode ser desenhado corretamente."
                              ],
                              "assessmentCriteria": [
                                "Correto uso de depend(in/out/inout) alinhado ao fluxo de dados.",
                                "Dependências mínimas sem serialização desnecessária.",
                                "Implementação dentro de região parallel/taskgroup.",
                                "Tratamento adequado de arrays e ponteiros em dependências.",
                                "Análise de performance inclui métricas quantitativas.",
                                "Código limpo com comentários explicando dependências."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Grafos: Modelagem de dependências como DAG (Directed Acyclic Graph).",
                                "Arquitetura de Computadores: Otimização de cache e locality em multicores.",
                                "Engenharia de Software: Gerenciamento de concorrência e deadlock avoidance.",
                                "Análise de Performance: Medição de speedup e profiling.",
                                "Sistemas Operacionais: Sincronização implícita vs. explícita."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (tasks para grids dependentes), processamento de big data (pipelines ETL paralelos) ou jogos (rendering de frames com dependências de assets), permitindo escalabilidade eficiente em clusters multicores sem overhead excessivo de sincronização."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.2.1"
                            ]
                          },
                          {
                            "id": "10.1.4.1.2.3",
                            "name": "Implementar taskloop",
                            "description": "Paralelizar loops irregulares com #pragma omp taskloop, combinando tasking com distribuição de iterações para melhorar escalabilidade em aplicações com tamanhos variáveis.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de #pragma omp taskloop",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP sobre tasking e taskloop, focando em seções 2.9.3 e 2.11.",
                                    "Identifique diferenças chave: omp parallel for distribui iterações de forma estática/dinâmica vs. taskloop gera tasks independentes para iterações irregulares.",
                                    "Analise cenários de uso: loops com tamanhos de iteração variáveis, dependências condicionais ou workloads desbalanceados.",
                                    "Revise cláusulas básicas: grainsize, num_tasks, nogroup.",
                                    "Compare com exemplos seriais para visualizar ganhos de escalabilidade."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando quando usar taskloop em vez de parallel for, com pelo menos 3 exemplos de loops irregulares.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação OpenMP 5.0+ (openmp.org)",
                                    "Editor de código (VS Code ou similar)",
                                    "Compilador GCC/Clang com suporte OpenMP"
                                  ],
                                  "tips": [
                                    "Priorize exemplos de workloads desbalanceados como processamento de árvores ou grafos.",
                                    "Use diagramas mentais para visualizar task generation."
                                  ],
                                  "learningObjective": "Dominar os princípios de taskloop para paralelização de loops irregulares, entendendo sua integração com tasking.",
                                  "commonMistakes": [
                                    "Confundir taskloop com worksharing constructs como parallel for.",
                                    "Subestimar overhead de task creation em loops pequenos."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente e Implementar Sintaxe Básica",
                                  "subSteps": [
                                    "Instale/verifique suporte OpenMP: gcc -fopenmp ou icc.",
                                    "Escreva um programa C/C++ simples com #pragma omp parallel e inclua #pragma omp taskloop em um loop for básico (ex: soma de array).",
                                    "Compile e execute com OMP_NUM_THREADS=4: g++ -fopenmp code.cpp -o exec.",
                                    "Adicione cláusula grainsize(100) e teste variação.",
                                    "Debug erros comuns como missing parallel region."
                                  ],
                                  "verification": "Execute o código serial vs. taskloop e confirme output idêntico com speedup >1.5x em 4 threads.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "GCC/Clang 8+ com -fopenmp",
                                    "Terminal/Linux ou WSL",
                                    "Código template: array de 1M elementos"
                                  ],
                                  "tips": [
                                    "Sempre use if(0) em taskloop para desabilitar serialmente durante debug.",
                                    "Monitore com OMP_DISPLAY_ENV=true."
                                  ],
                                  "learningObjective": "Configurar e codificar sintaxe correta de taskloop em ambiente OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer #include <omp.h> ou -fopenmp na compilação.",
                                    "Usar taskloop fora de região task ou parallel."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Taskloop em Loop Irregular Real",
                                  "subSteps": [
                                    "Crie um exemplo irregular: vetor de workloads variáveis (ex: processar sub-vetores com tamanhos randômicos simulando árvore/grafo).",
                                    "Aplique #pragma omp taskloop com bounds dinâmicos: for(int i=start; i<end; i++).",
                                    "Incorpore dependências leves com taskwait se necessário.",
                                    "Paralelize dentro de região omp parallel { #pragma omp single { taskloop } }.",
                                    "Teste com OMP_NUM_THREADS=8, variando tamanhos."
                                  ],
                                  "verification": "Meça tempo serial vs. parallel; confirme balanceamento via logs de thread ID por iteração.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código base do step 2 expandido",
                                    "Relógio de alta resolução: std::chrono",
                                    "Valgrind para leaks (opcional)",
                                    "Dados sintéticos: rand() para tamanhos irregulares"
                                  ],
                                  "tips": [
                                    "Simule irregularidade com inner loops de tamanho rand(10-1000).",
                                    "Use collapse(2) se loop aninhado."
                                  ],
                                  "learningObjective": "Aplicar taskloop para paralelizar efetivamente loops com iterações desbalanceadas.",
                                  "commonMistakes": [
                                    "Definir grainsize muito pequeno causando overhead excessivo.",
                                    "Ignorar race conditions em shared data sem atomic/reduction."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar e Avaliar Escalabilidade",
                                  "subSteps": [
                                    "Experimente cláusulas: num_tasks(32), grainsize(dynamic), priority.",
                                    "Profile performance: use likwid ou gprof para medir load balance e overhead.",
                                    "Compare speedup/scalability em 2/4/8 threads vs. serial e vs. parallel for.",
                                    "Ajuste para workloads variáveis: teste com distribuições diferentes (uniforme vs. power-law).",
                                    "Documente thresholds para taskloop viável (ex: >10k iterações)."
                                  ],
                                  "verification": "Gere gráfico de speedup (matplotlib ou gnuplot) mostrando escalabilidade superlinear em casos irregulares.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Ferramentas de profiling: likwid-pin, perf",
                                    "Scripts Python para plotar timings",
                                    "Máquina multicore (4+ cores)"
                                  ],
                                  "tips": [
                                    "Fixe seed rand para reprodutibilidade.",
                                    "Considere nowait para reduzir sincronizações."
                                  ],
                                  "learningObjective": "Otimizar taskloop para máxima escalabilidade em aplicações reais com variabilidade.",
                                  "commonMistakes": [
                                    "Overhead domina em pequenos loops: sempre benchmark.",
                                    "Não considerar NUMA effects em >8 cores."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um simulador de Monte Carlo para finanças, paralelize loop sobre 10k caminhos de preços de ativos com comprimentos variáveis (100-10k passos cada). Use #pragma omp taskloop grainsize(50) dentro de omp parallel single para distribuir tasks, alcançando speedup de 6x em 8 cores vs. serial, lidando com desbalanceamento natural dos caminhos.",
                              "finalVerifications": [
                                "Código compila e executa sem erros ou crashes em múltiplos threads.",
                                "Output serial e paralelo idênticos (teste com checksum).",
                                "Speedup >2x em 4 threads para workload irregular de 1M iterações.",
                                "Load balance >80% (medido por tempo/thread logs).",
                                "Escalabilidade mantida com tamanhos variáveis (teste 3 distribuições).",
                                "Cláusulas grainsize/num_tasks ajustadas corretamente sem overhead excessivo.",
                                "Sem data races detectadas por ThreadSanitizer."
                              ],
                              "assessmentCriteria": [
                                "Correção: taskloop gera tasks independentes corretamente.",
                                "Eficiência: overhead de tasking <20% do tempo total.",
                                "Escalabilidade: speedup linear até #threads disponíveis em irregular.",
                                "Robustez: lida com bounds variáveis e dependências opcionais.",
                                "Clareza: código comentado com explicação de cláusulas.",
                                "Otimização: uso efetivo de grainsize/num_tasks baseado em profiling.",
                                "Documentação: relatório com benchmarks e gráficos."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados: paralelização de traversals em árvores/grafos irregulares.",
                                "Computação de Alto Desempenho (HPC): task-based parallelism em clusters.",
                                "Engenharia de Software: design de código escalável e thread-safe.",
                                "Matemática Computacional: aceleração de simulações Monte Carlo desbalanceadas.",
                                "Inteligência Artificial: paralelismo em processamento de batches variáveis em ML."
                              ],
                              "realWorldApplication": "Em aplicações HPC como simulações climáticas (grids irregulares de células), processamento de imagens médicas (regiões de interesse variáveis) ou finanças quantitativas (caminhos estocásticos de comprimentos desiguais), taskloop melhora escalabilidade em multicore/GPUs híbridos, reduzindo tempo de computação de horas para minutos em supercomputadores."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.1.3",
                        "name": "Affinity e Controle de Localidade em OpenMP",
                        "description": "Técnicas de affinity para pinning de threads a núcleos específicos, otimizando locality e reduzindo overhead de migração em processadores multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.1.3.1",
                            "name": "Configurar thread affinity com OMP_PROC_BIND",
                            "description": "Usar variáveis de ambiente como OMP_PROC_BIND e OMP_PLACES para controlar a afinidade de threads a núcleos físicos, melhorando desempenho em NUMA e multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Thread Affinity e NUMA",
                                  "subSteps": [
                                    "Estude o conceito de thread affinity: associação de threads lógicas a núcleos físicos para minimizar migrações.",
                                    "Aprenda sobre arquitetura NUMA: Non-Uniform Memory Access, onde latência varia por nó de memória.",
                                    "Identifique problemas de performance sem affinity: thrashing de cache e falsos compartilhamentos.",
                                    "Explore ferramentas de diagnóstico: lstopo (hwloc) para visualizar topologia de hardware.",
                                    "Compare affinity vs. scheduling do SO: affinity é controle explícito do programador."
                                  ],
                                  "verification": "Desenhe um diagrama simples da topologia NUMA do seu sistema e explique em 3 frases por que affinity melhora performance.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação OpenMP 5.0+ (seção Affinity)",
                                    "hwloc/lstopo instalado",
                                    "Artigo 'NUMA Awareness in OpenMP'"
                                  ],
                                  "tips": "Execute 'lstopo --of pdf' para gerar um mapa visual da topologia do seu CPU.",
                                  "learningObjective": "Explicar o impacto de affinity em performance paralela em sistemas multicores/NUMA.",
                                  "commonMistakes": [
                                    "Ignorar topologia NUMA e assumir uniformidade de memória.",
                                    "Confundir affinity de threads com pinning de processos."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Sintaxe e Opções de OMP_PROC_BIND",
                                  "subSteps": [
                                    "Leia a sintaxe: export OMP_PROC_BIND={false|true|spread|close|master|primary|none}.",
                                    "Teste OMP_PROC_BIND=spread: distribui threads uniformemente por sockets/nós NUMA.",
                                    "Teste OMP_PROC_BIND=close: agrupa threads próximas para locality de dados.",
                                    "Experimente OMP_PROC_BIND=master: todas threads bindadas ao núcleo do master.",
                                    "Verifique valores válidos com 'omp_get_proc_bind()' em um código simples."
                                  ],
                                  "verification": "Crie um programa OpenMP que imprima o proc_bind mode e confirme via saída esperada.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador com OpenMP (gcc -fopenmp)",
                                    "Script bash para exportar variáveis",
                                    "Exemplo código de diagnóstico OpenMP"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' antes de rodar para testes controlados.",
                                  "learningObjective": "Selecionar e aplicar opções de OMP_PROC_BIND para cenários específicos de locality.",
                                  "commonMistakes": [
                                    "Esquecer de exportar a variável para subshells.",
                                    "Usar OMP_PROC_BIND sem considerar OMP_PLACES."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar OMP_PLACES para Controle Fino de Localidade",
                                  "subSteps": [
                                    "Estude sintaxe OMP_PLACES: '{0}: {0-3}, {1}: {4-7}' para mapear threads a núcleos específicos.",
                                    "Defina lugares lógicos: sockets, cores, PUs usando notação hwloc (ex: {0}%socket:0%core).",
                                    "Combine com OMP_PROC_BIND: OMP_PLACES define 'onde', BIND define 'como' bindar.",
                                    "Teste em sistema NUMA: OMP_PLACES='{0}%socket:0,{1}%socket:1' para balanceamento.",
                                    "Valide com 'numactl --hardware' e 'taskset -p <pid>' durante execução."
                                  ],
                                  "verification": "Rode um programa com OMP_PLACES setado e confirme binding com 'htop' ou 'ps -eo pid,psr,comm'.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "hwloc tools (numactl, taskset)",
                                    "Exemplo código OpenMP com omp_get_place_num_threads()"
                                  ],
                                  "tips": "Use OMP_PLACES em aspas para evitar expansão shell; teste com poucos threads primeiro.",
                                  "learningObjective": "Definir placements personalizados para otimizar locality em topologias complexas.",
                                  "commonMistakes": [
                                    "Notação errada em OMP_PLACES causando fallback para default.",
                                    "Ignorar hierarquia socket/core/PU na definição."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar, Testar e Otimizar Afinidade em Programa Prático",
                                  "subSteps": [
                                    "Desenvolva um programa OpenMP com workload NUMA-sensível (ex: matrix multiply com dados por socket).",
                                    "Meça performance baseline sem vars, depois com OMP_PROC_BIND=spread e OMP_PLACES otimizado.",
                                    "Use timers OpenMP (omp_get_wtime()) e ferramentas como likwid-perf para métricas de cache/migração.",
                                    "Ajuste vars baseado em resultados: compare speedup e overhead de binding.",
                                    "Documente configurações ótimas para seu hardware específico."
                                  ],
                                  "verification": "Gere relatório com tempos de execução e bindings confirmados, mostrando melhoria >10%.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código fonte exemplo (matrix_mult_omp.c)",
                                    "Likwid ou perf para profiling",
                                    "Sistema multicores/NUMA"
                                  ],
                                  "tips": "Rode múltiplas iterações com OMP_DYNAMIC=false para resultados reprodutíveis.",
                                  "learningObjective": "Aplicar affinity para melhorar performance mensurável em aplicações reais.",
                                  "commonMistakes": [
                                    "Não isolar variáveis (ex: deixar OMP_SCHEDULE interferir).",
                                    "Testar só em single-socket, ignorando NUMA."
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa OpenMP para multiplicação de matrizes NxN (N=4096). Inicialize matriz A em memória de socket 0 e B em socket 1. Rode sem affinity (baseline ~5s), depois export OMP_PROC_BIND=close; OMP_PLACES='{0-7}%socket:0{8-15}%socket:1' (~2.5s). Verifique com 'likwid-pin -c 0-15 ./prog' e timers internos.",
                              "finalVerifications": [
                                "Threads bindadas corretamente: confirmado por taskset -p ou hwloc-ps.",
                                "omp_get_proc_bind() e omp_get_place_num_procs() retornam valores esperados.",
                                "Performance melhorada: speedup >=15% em workload NUMA vs. baseline.",
                                "Sem migrações excessivas: likwid-topology ou perf stat mostra baixa taxa de migração.",
                                "Configurações persistem em múltiplas runs: export verificado via env | grep OMP.",
                                "Compatibilidade cross-plataforma: testado em pelo menos 2 arquiteturas (Intel/AMD)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na configuração: vars setadas corretamente sem erros de sintaxe.",
                                "Análise de performance: gráficos/tabelas comparando tempos e métricas.",
                                "Compreensão conceitual: explicação clara de escolhas de BIND/PLACES.",
                                "Diagnóstico robusto: uso de >=3 ferramentas para verificação.",
                                "Otimização iterativa: ajustes baseados em testes com evidências.",
                                "Documentação completa: relatório com código, comandos e resultados reprodutíveis."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Topologias NUMA e hierarquia cache.",
                                "Sistemas Operacionais: Schedulers CFS e cpusets para pinning.",
                                "Otimização de Performance: Profiling com perf/likwid em HPC.",
                                "Programação Paralela: Integração com MPI para hybrid MPI+OpenMP.",
                                "Engenharia de Software: Configurações via arquivos .bashrc para portabilidade."
                              ],
                              "realWorldApplication": "Em data centers e supercomputadores (ex: TOP500), configurações de OMP_PROC_BIND/PLACES otimizam workloads como simulações CFD ou ML training, reduzindo tempo de execução em 20-50% e consumo energético em ambientes NUMA escaláveis."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.4.1.3.2",
                            "name": "Aplicar cláusula proc_bind em parallel",
                            "description": "Especificar affinity com cláusulas proc_bind (master/close/spread) em diretivas parallel, otimizando alocação de threads para minimizar falsos compartilhamentos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos de Affinity e Cláusula proc_bind",
                                  "subSteps": [
                                    "Estude o conceito de thread affinity e como ele relaciona com locality em OpenMP.",
                                    "Aprenda as opções da cláusula proc_bind: master (threads ligadas ao mestre), close (threads próximas umas das outras), spread (threads espalhadas pelos processadores).",
                                    "Entenda falsos compartilhamentos (false sharing) causados por alocação inadequada de threads em caches compartilhados.",
                                    "Leia a especificação OpenMP 5.0+ sobre proc_bind em seções de parallel regions.",
                                    "Compare proc_bind com bind e place para diferenciar controles de affinity."
                                  ],
                                  "verification": "Explique em suas palavras as diferenças entre master, close e spread, e dê um exemplo de false sharing.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação oficial OpenMP (openmp.org)",
                                    "Artigo sobre false sharing em multicore systems"
                                  ],
                                  "tips": "Use diagramas de cache hierarchy para visualizar impactos de affinity.",
                                  "learningObjective": "Dominar o propósito e opções da cláusula proc_bind para otimização de locality.",
                                  "commonMistakes": [
                                    "Confundir proc_bind com omp_set_affinity (APIs runtime), ignorar que proc_bind é compile-time."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Sintaxe Básica da Cláusula proc_bind em Diretiva parallel",
                                  "subSteps": [
                                    "Escreva um programa OpenMP simples com #pragma omp parallel num_threads(4).",
                                    "Adicione proc_bind(master), compile com g++ -fopenmp e execute.",
                                    "Modifique para proc_bind(close) e proc_bind(spread), salvando versões separadas.",
                                    "Inclua omp_get_thread_num() e omp_get_num_threads() para logar binding.",
                                    "Use taskset ou hwloc para inspecionar affinity real das threads."
                                  ],
                                  "verification": "Código compila e executa sem erros, produzindo output mostrando binding correto.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte OpenMP",
                                    "Editor de código (VSCode com C++ extension)",
                                    "Ferramenta hwloc ou lstopo para topology"
                                  ],
                                  "tips": "Defina OMP_NUM_THREADS=4 no ambiente para consistência.",
                                  "learningObjective": "Aplicar sintaxe correta de proc_bind em regiões parallel.",
                                  "commonMistakes": [
                                    "Esquecer num_threads, usar sintaxe inválida como proc_bind=spread sem parênteses."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Testar e Comparar Configurações de proc_bind",
                                  "subSteps": [
                                    "Execute o programa com cada proc_bind e meça tempo de execução com omp_get_wtime().",
                                    "Adicione prints de affinity usando omp_get_proc_bind() se disponível.",
                                    "Use perf ou Intel VTune para monitorar cache misses e false sharing.",
                                    "Registre tempos e métricas para master, close e spread em um log.",
                                    "Analise como spread minimiza contenda em cenários de alta locality."
                                  ],
                                  "verification": "Tabela comparativa mostra diferenças em performance e cache metrics entre configurações.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Ferramentas de profiling: perf (Linux), omp_get_wtime()",
                                    "Planilha para logs (Google Sheets)"
                                  ],
                                  "tips": "Execute múltiplas vezes (n=10) e calcule média para precisão.",
                                  "learningObjective": "Avaliar empiricamente o impacto de proc_bind na alocação de threads.",
                                  "commonMistakes": [
                                    "Não isolar variáveis como hyper-threading, ignorar overhead de binding."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar um Caso de False Sharing com proc_bind",
                                  "subSteps": [
                                    "Crie um array global com updates adjacentes por threads para induzir false sharing.",
                                    "Implemente loop parallel sem proc_bind e meça alto cache miss rate.",
                                    "Aplique proc_bind(spread) para espalhar threads e remeça performance.",
                                    "Compare speedup e verifique redução em falsos compartilhamentos.",
                                    "Refatore para um exemplo realista como redução paralela ou matrix multiply."
                                  ],
                                  "verification": "Demonstração mostra melhoria de 20-50% em tempo com proc_bind(spread) vs default.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código base de false sharing (exemplo online OpenMP)",
                                    "Profiler como likwid ou perf para L1/L2 misses"
                                  ],
                                  "tips": "Padronize array size para 1M elementos para impacto visível.",
                                  "learningObjective": "Usar proc_bind para resolver problemas reais de performance por locality.",
                                  "commonMistakes": [
                                    "Atualizações não-adjacentes no array, não normalizar dados de timing."
                                  ]
                                }
                              ],
                              "practicalExample": "#include <omp.h>\n#include <stdio.h>\nint main() {\n  double start = omp_get_wtime();\n  #pragma omp parallel proc_bind(spread) num_threads(4)\n  {\n    int id = omp_get_thread_num();\n    for(int i=0; i<1000000; i++) { /* Trabalho simulando false sharing */ }\n    printf(\"Thread %d bound\\n\", id);\n  }\n  printf(\"Tempo: %f\\n\", omp_get_wtime() - start);\n}",
                              "finalVerifications": [
                                "Código compila e executa com todas as opções proc_bind sem warnings.",
                                "Logs confirmam binding correto (ex: todas threads no mesmo core para master).",
                                "Medição mostra redução em cache misses com spread vs master.",
                                "Explicação correta de quando usar cada opção.",
                                "Aplicação em false sharing demonstra speedup mensurável.",
                                "Uso correto de ferramentas de profiling."
                              ],
                              "assessmentCriteria": [
                                "Sintaxe precisa e conformidade com OpenMP 5.0.",
                                "Análise quantitativa de performance (tempos, misses).",
                                "Seleção apropriada de proc_bind baseada em cenário.",
                                "Código limpo, legível e comentado.",
                                "Compreensão demonstrada via explicações ou relatório.",
                                "Reprodutibilidade dos resultados em diferentes runs."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Hierarquia de caches e locality principles.",
                                "Algoritmos e Estruturas de Dados: Otimização paralela de loops.",
                                "Sistemas Operacionais: Thread scheduling e processor affinity.",
                                "Engenharia de Software: Profiling e tuning de performance."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: CFD com OpenFOAM), proc_bind(spread) reduz falsos compartilhamentos em matrizes densas, melhorando throughput em 30-60% em clusters multicore como AWS c5 instances."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.3.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.1.4",
                        "name": "SIMD em OpenMP para Vetorização",
                        "description": "Suporte a instruções SIMD em OpenMP para explorar paralelismo fino em vetores e arrays em processadores multicores com extensões vetoriais como AVX.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.1.4.1",
                            "name": "Implementar #pragma omp simd",
                            "description": "Aplicar diretiva #pragma omp simd para vetorizar loops independentes, utilizando cláusulas como simdlen e aligned para otimizar vetorização automática pelo compilador.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente e revisar conceitos de vetorização SIMD",
                                  "subSteps": [
                                    "Instale um compilador compatível com OpenMP 4.0+ (GCC 4.9+, Clang ou Intel ICC).",
                                    "Compile um programa OpenMP simples com `gcc -fopenmp test.c -o test` para verificar suporte.",
                                    "Leia a seção 2.8 da especificação OpenMP sobre `!OMP SIMD` e entenda independência de iterações.",
                                    "Estude instruções SIMD do hardware alvo (AVX2/AVX512 para x86).",
                                    "Anote exemplos de loops vetorizáveis (sem dependências de dados)."
                                  ],
                                  "verification": "Compilador gera executável OpenMP sem erros e você pode listar 3 critérios para loops vetorizáveis.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Compilador GCC/Clang com suporte OpenMP",
                                    "Especificação OpenMP 5.0 PDF",
                                    "Documentação do compilador (man gcc)"
                                  ],
                                  "tips": "Use flags como `-march=native` para habilitar SIMD do hardware local.",
                                  "learningObjective": "Compreender fundamentos de vetorização e requisitos do #pragma omp simd.",
                                  "commonMistakes": [
                                    "Ignorar versão do OpenMP no compilador",
                                    "Confundir SIMD com paralelismo em múltiplos cores",
                                    "Não verificar suporte hardware"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e preparar um loop candidato para vetorização",
                                  "subSteps": [
                                    "Escreva um loop for simples com operações independentes (ex: soma de arrays a[i] += b[i]).",
                                    "Verifique ausência de dependências: cada iteração usa/escrita dados distintos.",
                                    "Alinhe arrays manualmente com `__attribute__((aligned(32)))` ou `posix_memalign`.",
                                    "Compile com `-O3 -fopt-info-vec-optimized` e analise output para ver se vetoriza automaticamente.",
                                    "Meça tempo base sem pragma usando `omp_get_wtime()`."
                                  ],
                                  "verification": "Loop identificado compila e roda sem vetorização automática confirmada no log do compilador.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Editor de código (VSCode com C/C++ extension)",
                                    "Timer OpenMP functions"
                                  ],
                                  "tips": "Comece com N=1e6 elementos para medir performance realista.",
                                  "learningObjective": "Selecionar loops adequados e preparar memória alinhada para SIMD.",
                                  "commonMistakes": [
                                    "Loops com dependências recorrentes como a[i] = a[i-1] + 1",
                                    "Arrays não alinhados causando falhas de vetorização",
                                    "Tamanhos pequenos de array mascarando ganhos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar diretiva básica #pragma omp simd",
                                  "subSteps": [
                                    "Adicione `#pragma omp simd` imediatamente antes do loop for.",
                                    "Compile com `-fopenmp -O3 -fopt-info-vec` e confirme vetorização no output.",
                                    "Execute e compare tempos com/sem pragma usando múltiplas runs.",
                                    "Ajuste tamanho do loop se necessário para observar speedup.",
                                    "Adicione collapse(2) se loop aninhado (2 níveis)."
                                  ],
                                  "verification": "Output do compilador mostra 'loop vectorized' e speedup >=1.2x medido.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Flags de compilação: -fopenmp -O3 -fopt-info-vec-all",
                                    "Script para runs múltiplas"
                                  ],
                                  "tips": "Use `perf stat` ou VTune para métricas detalhadas de instruções SIMD.",
                                  "learningObjective": "Aplicar #pragma omp simd para forçar vetorização de loops independentes.",
                                  "commonMistakes": [
                                    "Posicionar pragma incorretamente (não antes do loop)",
                                    "Esquecer -fopenmp na compilação",
                                    "Interpretar speedup sem normalizar por runs"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar com cláusulas simdlen e aligned",
                                  "subSteps": [
                                    "Adicione `aligned(a:32,b:32)` assumindo alinhamento de 32 bytes (AVX).",
                                    "Especifique `simdlen(8)` para vetores de 256-bit (8 floats).",
                                    "Compile e verifique com `-fopt-info-vec-missed` para erros de alinhamento.",
                                    "Teste com diferentes simdlen (4,8,16) e meça impacto na performance.",
                                    "Gere relatório final comparando baseline, simd básico e otimizado."
                                  ],
                                  "verification": "Compilação sem warnings de misalignment e speedup adicional >=1.5x total.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Documentação cláusulas OpenMP SIMD",
                                    "Hardware com AVX support"
                                  ],
                                  "tips": "Verifique alinhamento real com `printf(\"%p\", a)` múltiplo de 32.",
                                  "learningObjective": "Usar cláusulas para controle fino de vetorização e alinhamento.",
                                  "commonMistakes": [
                                    "simdlen incompatível com hardware (ex: 16 em SSE)",
                                    "aligned sem verificação real",
                                    "Ignorar overhead de máscaras em loops não múltiplos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar, testar e depurar a implementação",
                                  "subSteps": [
                                    "Rode com valgrind ou AddressSanitizer para detectar issues de memória.",
                                    "Compare resultados numéricos com versão serial (tolerância 1e-6).",
                                    "Profile com `gprof` ou `perf` para confirmar uso de instruções SIMD.",
                                    "Teste em diferentes tamanhos de input e arquiteturas.",
                                    "Documente speedup e lições aprendidas em um relatório curto."
                                  ],
                                  "verification": "Código correto numericamente, performance otimizada e relatório completo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Valgrind/ASan flags",
                                    "Perf tool no Linux"
                                  ],
                                  "tips": "Sempre teste edge cases: N=0, N pequeno, N não múltiplo de simdlen.",
                                  "learningObjective": "Garantir robustez e performance sustentável da vetorização.",
                                  "commonMistakes": [
                                    "Resultados incorretos por race conditions mascaradas",
                                    "Overfitting em um tamanho de input",
                                    "Não documentar flags usadas"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente soma de dois arrays grandes: `for(int i=0; i<N; i++) c[i] = a[i] + b[i];`. Sem pragma: ~1.2s. Com `#pragma omp simd aligned(a,b:32) simdlen(8)`: ~0.3s (4x speedup em AVX2).",
                              "finalVerifications": [
                                "Compilador confirma vetorização completa sem misses.",
                                "Speedup medido >=2x em hardware moderno.",
                                "Resultados idênticos à versão serial.",
                                "Sem warnings ou erros de runtime.",
                                "Alinhamento e simdlen respeitados no assembly (objdump -d).",
                                "Funciona em múltiplos tamanhos de input."
                              ],
                              "assessmentCriteria": [
                                "Identificação correta de loops independentes (100%).",
                                "Código compila e executa sem erros (pass/fail).",
                                "Uso apropriado de cláusulas simdlen/aligned (manual review).",
                                "Speedup quantificado e >1.5x (métricas).",
                                "Relatório explica escolhas e lições (qualitativo).",
                                "Tratamento de edge cases demonstrado."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Instruções SIMD (AVX/SVE).",
                                "Otimização de Algoritmos: Análise assintótica e profiling.",
                                "Matemática Computacional: Operações vetorizadas em álgebra linear.",
                                "Engenharia de Software: Boas práticas de portabilidade e depuração."
                              ],
                              "realWorldApplication": "Acelerar kernels numéricos em simulações científicas (CFD, ML training), processamento de imagens (filtros convolução) e big data analytics, reduzindo tempo de computação em HPC clusters."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.1.2"
                            ]
                          },
                          {
                            "id": "10.1.4.1.4.2",
                            "name": "Usar declare simd para funções vetorizáveis",
                            "description": "Declarar funções como vetorizáveis com #pragma omp declare simd, especificando mapings de argumentos para aceleração SIMD em kernels computacionais intensivos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos e Sintaxe Básica de #pragma omp declare simd",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP sobre declare simd, focando em funções vetorizáveis.",
                                    "Identifique funções candidatas: loops simples com operações independentes em arrays.",
                                    "Aprenda a sintaxe básica: #pragma omp declare simd [clauses] função(protótipo);",
                                    "Revise pré-requisitos: conhecimento de OpenMP e vetorização automática do compilador.",
                                    "Compile um exemplo mínimo sem erros usando flags como -fopenmp -O3."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a sintaxe básica e identifique uma função candidata em código existente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação OpenMP 5.0+",
                                    "Compilador GCC/Clang com suporte OpenMP (versão 4.5+)",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Sempre posicione a pragma antes da declaração da função; teste com funções inline para melhor performance.",
                                  "learningObjective": "Entender quando e como usar declare simd para forçar vetorização em funções.",
                                  "commonMistakes": [
                                    "Colocar pragma após a definição da função",
                                    "Ignorar alinhamento de dados",
                                    "Não usar otimizações -O2/-O3"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Declarar Função Simples com Sintaxe Básica",
                                  "subSteps": [
                                    "Crie uma função simples, como soma de elementos em array: void soma(float *a, float *b, int n).",
                                    "Adicione #pragma omp declare simd antes da declaração.",
                                    "Compile e execute sem clauses avançadas, medindo tempo base.",
                                    "Compare assembly gerado com/ sem pragma usando objdump ou -S flag.",
                                    "Ajuste para função inline se necessário."
                                  ],
                                  "verification": "Código compila e executa; assembly mostra instruções SIMD (AVX/SSE).",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código-fonte exemplo (array de 1M floats)",
                                    "Compilador com -fopt-info-vec",
                                    "Timer de performance (gettimeofday ou similar)"
                                  ],
                                  "tips": "Use simdlen(8) para AVX-256 se souber o hardware; teste em loop chamando a função.",
                                  "learningObjective": "Aplicar declare simd básico em uma função e observar vetorização inicial.",
                                  "commonMistakes": [
                                    "Função com dependências de dados",
                                    "Argumentos não lineares",
                                    "Falta de -march=native"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Especificar Mapeamentos de Argumentos e Clauses Avançadas",
                                  "subSteps": [
                                    "Identifique tipos de mapeamentos: linear(val), uniform, aligned(N).",
                                    "Adicione clauses: #pragma omp declare simd linear(a:1,b:1) aligned(a:32,b:32) simdlen(8).",
                                    "Ajuste para kernels intensivos, como multiplicação de vetores (SAXPY).",
                                    "Compile com relatórios de vetorização (-fopt-info-loop-optimized).",
                                    "Teste com dados desalinhados para validar aligned clause."
                                  ],
                                  "verification": "Relatório do compilador confirma mapeamentos e vetorização completa.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Exemplo SAXPY código",
                                    "Ferramentas de profiling (perf ou VTune)",
                                    "Dados de teste desalinhados"
                                  ],
                                  "tips": "linear(ref) para índices incrementais; use notinbranch para condições raras.",
                                  "learningObjective": "Configurar argumentos corretamente para aceleração SIMD otimizada.",
                                  "commonMistakes": [
                                    "Mapeamento linear em argumentos não iterados",
                                    "Aligned com N incompatível com hardware",
                                    "Esquecer simdlen máximo"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar em Kernel Computacional e Verificar Performance",
                                  "subSteps": [
                                    "Integre a função vetorizada em um kernel maior (ex: stencil computation).",
                                    "Meça speedup com/ sem declare simd em múltiplas chamadas.",
                                    "Use ferramentas como Intel VTune ou LLVM reports para confirmar uso SIMD.",
                                    "Otimize iterações: reduza overhead de chamadas com inlining.",
                                    "Documente métricas: speedup, % de vetorização."
                                  ],
                                  "verification": "Speedup > 2x em hardware SIMD; relatórios mostram 100% vetorização.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Kernel exemplo (1D heat diffusion)",
                                    "Hardware com AVX2+",
                                    "Profiler (perf record/report)"
                                  ],
                                  "tips": "Combine com #pragma omp simd no loop caller; teste em diferentes arquiteturas.",
                                  "learningObjective": "Aplicar e validar declare simd em contexto real de computação intensiva.",
                                  "commonMistakes": [
                                    "Overhead de chamada > ganho SIMD",
                                    "Dados não cache-friendly",
                                    "Ignorar verificação de vetorização"
                                  ]
                                }
                              ],
                              "practicalExample": "Para função SAXPY (y = a*x + y): #pragma omp declare simd linear(x:1,y:1) uniform(a) aligned(x:32,y:32) simdlen(8) void saxpy(float a, float *x, float *y, int n) { for(int i=0; i<n; i++) y[i] += a*x[i]; }. Isso vetoriza perfeitamente em AVX-256.",
                              "finalVerifications": [
                                "Código compila sem warnings de vetorização com -fopenmp -O3 -march=native.",
                                "Relatórios do compilador (ex: -Rpass=loop-vectorize) confirmam uso de declare simd.",
                                "Assembly contém instruções VMOVAPS/VFMADD (SIMD).",
                                "Teste unitário passa com dados aleatórios (diferença < 1e-6).",
                                "Speedup mensurável > 3x em loop de 1M iterações.",
                                "Nenhum crash com dados desalinhados quando aligned especificado."
                              ],
                              "assessmentCriteria": [
                                "Sintaxe da pragma 100% correta com clauses apropriadas.",
                                "Mapeamentos de argumentos precisos para o tipo de função.",
                                "Evidência de vetorização via relatórios ou assembly.",
                                "Melhoria de performance quantificada e reproduzível.",
                                "Função integrada corretamente em kernel sem perda de precisão.",
                                "Documentação de testes e métricas incluída."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Instruções SIMD (SSE/AVX) e registradores vetoriais.",
                                "Matemática Computacional: Operações em vetores e álgebra linear.",
                                "Otimização de Algoritmos: Análise de complexidade e profiling.",
                                "Engenharia de Software: Boas práticas em programação paralela e portabilidade.",
                                "Física Computacional: Aceleração de simulações numéricas."
                              ],
                              "realWorldApplication": "Em simulações HPC como modelagem climática (kernels de convolução), processamento de imagens médicas (filtros vetoriais) e treinamento de ML (operações em tensores), onde declare simd acelera loops intensivos em até 8-16x em CPUs modernas, reduzindo tempo de computação em data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.1.4.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.2",
                    "name": "MPI para Memória Distribuída",
                    "description": "Padrão para troca de mensagens em sistemas distribuídos, aplicado em clusters e computação paralela na nuvem.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.2.1",
                        "name": "Introdução ao MPI e Modelo de Memória Distribuída",
                        "description": "Conceitos fundamentais do Message Passing Interface (MPI) como padrão para troca de mensagens em sistemas de memória distribuída, incluindo taxonomia de Flynn (MIMD) e aplicações em clusters e nuvem.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.2.1.1",
                            "name": "Entender o modelo de programação por troca de mensagens",
                            "description": "Explicar o paradigma de mensagem passing em memória distribuída, diferenciando de memória compartilhada, e identificar cenários de uso em clusters e computação paralela na nuvem.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Memória Compartilhada versus Memória Distribuída",
                                  "subSteps": [
                                    "Estude a definição de memória compartilhada: múltiplos processadores acessam uma memória comum via barramento ou interconexões.",
                                    "Analise as limitações da memória compartilhada em escalabilidade, como contenção e latência em grandes clusters.",
                                    "Defina memória distribuída: cada processador tem sua própria memória local, sem acesso direto à memória de outros.",
                                    "Compare os dois modelos em termos de comunicação: compartilhada usa leitura/escrita direta; distribuída requer troca explícita de dados.",
                                    "Identifique trade-offs: compartilhada é simples mas não escalável; distribuída é escalável mas requer gerenciamento de comunicação."
                                  ],
                                  "verification": "Crie um diagrama comparativo das arquiteturas e explique verbalmente as diferenças para um colega.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Slides ou vídeo sobre arquiteturas paralelas (ex: YouTube: 'Shared vs Distributed Memory'), papel e caneta para diagramas"
                                  ],
                                  "tips": "Use analogias: compartilhada como uma família compartilhando uma geladeira; distribuída como vizinhos enviando pacotes.",
                                  "learningObjective": "Diferenciar com clareza os modelos de memória e suas implicações em programação paralela.",
                                  "commonMistakes": [
                                    "Confundir escalabilidade com simplicidade",
                                    "Ignorar overhead de sincronização na compartilhada"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir o Paradigma de Programação por Troca de Mensagens",
                                  "subSteps": [
                                    "Defina message passing: processos se comunicam enviando e recebendo mensagens explícitas (dados + controle).",
                                    "Estude operações básicas: send (envio bloqueante/não-bloqueante) e receive (bloqueante/não-bloqueante).",
                                    "Aprenda sobre sincronia: bloqueante espera conclusão; não-bloqueante permite sobreposição com computação.",
                                    "Compare com memória compartilhada: sem locks ou races, mas overhead de cópia de dados.",
                                    "Explore padrões: point-to-point (um-para-um), collective (broadcast, reduce)."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando send/receive e dê exemplos de sincronia.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação MPI oficial (mpi-forum.org), tutorial online 'Message Passing Basics'"
                                  ],
                                  "tips": "Pense em mensagens como cartas: remetente envia, destinatário recebe; sem compartilhamento direto.",
                                  "learningObjective": "Explicar os mecanismos fundamentais de message passing e contrastá-los com shared memory.",
                                  "commonMistakes": [
                                    "Assumir comunicação implícita",
                                    "Confundir bloqueante com assíncrono"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar MPI como Implementação de Message Passing",
                                  "subSteps": [
                                    "Instale ambiente MPI (ex: OpenMPI ou MPICH em Linux/Windows).",
                                    "Compile e execute um programa 'Hello World' MPI com MPI_Init, MPI_Comm_rank, MPI_Finalize.",
                                    "Implemente MPI_Send e MPI_Recv para troca simples entre dois processos.",
                                    "Teste comunicações coletivas: MPI_Bcast e MPI_Reduce em um array.",
                                    "Analise deadlocks comuns em padrões de comunicação bidirecional."
                                  ],
                                  "verification": "Execute um código MPI que troque mensagens entre processos e capture saída com mpirun -np 4.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Compilador MPI instalado, editor de código (VS Code), exemplos de código de mpi4py ou C/MPI"
                                  ],
                                  "tips": "Use mpirun -np N para simular múltiplos nós; debugue com printf antes de MPI_Barrier.",
                                  "learningObjective": "Implementar e depurar programas básicos usando MPI para message passing.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init/Finalize",
                                    "Mismatch em tags ou contadores de mensagens"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar Cenários de Uso em Clusters e Nuvem",
                                  "subSteps": [
                                    "Pesquise aplicações: simulações científicas (CFD, clima), machine learning distribuído (Horovod sobre MPI).",
                                    "Analise clusters HPC (ex: TOP500 supercomputadores usam MPI).",
                                    "Estude computação paralela na nuvem: AWS ParallelCluster, Google Cloud HPC com MPI.",
                                    "Compare com alternativas: shared memory (OpenMP) para intra-nó; MPI para inter-nó.",
                                    "Discuta portabilidade: MPI roda em qualquer rede (Ethernet, InfiniBand)."
                                  ],
                                  "verification": "Liste 3 cenários reais com justificativa de por que message passing é adequado.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Site TOP500.org, papers sobre MPI em nuvens (ex: 'MPI on AWS')"
                                  ],
                                  "tips": "Foque em escalabilidade: MPI brilha em milhares de nós onde shared memory falha.",
                                  "learningObjective": "Reconhecer contextos onde message passing é preferível e suas vantagens práticas.",
                                  "commonMistakes": [
                                    "Subestimar latência de rede",
                                    "Ignorar híbridos MPI+OpenMP"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 4 nós, use MPI para simular um 'echo server': processo 0 envia 'Olá' para processo 1 via MPI_Send, que responde com MPI_Recv/MPI_Send. Código C: MPI_Init, rank=0 envia para rank=1, rank=1 recebe e ecoa de volta. Execute com mpirun -np 4 para verificar troca bidirecional sem deadlock usando tags.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças entre shared e distributed memory sem hesitação.",
                                "Desenhar fluxograma de send/receive em MPI.",
                                "Executar e modificar um programa MPI básico com sucesso.",
                                "Identificar 2 cenários onde message passing é essencial (ex: simulações em 1000+ nós).",
                                "Diferenciar point-to-point de collective communications.",
                                "Prever e evitar um deadlock comum em código MPI."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção de paradigmas (90% acerto em quiz comparativo).",
                                "Capacidade de codificar e executar MPI send/recv (compila e roda sem erros).",
                                "Profundidade em cenários de uso (cita exemplos reais com justificativa).",
                                "Clareza em diagramas e explicações (rubrica de comunicação 4/5).",
                                "Identificação de erros comuns (lista 3+ pitfalls corretos).",
                                "Tempo de conclusão dentro do estimado (±20%)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação (TCP/IP vs MPI sobre UDP).",
                                "Sistemas Operacionais: Gerenciamento de processos distribuídos e IPC.",
                                "Computação em Nuvem: Orquestração em Kubernetes com MPI jobs.",
                                "Algoritmos e Estruturas: Paralelização de algoritmos (MapReduce via message passing).",
                                "Engenharia de Software: Debugging distribuído e testes em clusters."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier (TOP500 #1), MPI é usado para simulações climáticas globais, onde milhares de nós trocam dados de grade para prever furacões, escalando para exaflops sem gargalos de memória compartilhada."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.2.1.2",
                            "name": "Configurar e inicializar ambiente MPI",
                            "description": "Instalar MPI (ex: OpenMPI ou MPICH), compilar programas com mpicc/mpicxx e utilizar MPI_Init() e MPI_Finalize() para gerenciar processos paralelos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Instalar o MPI no sistema operacional",
                                  "subSteps": [
                                    "Atualize o gerenciador de pacotes: sudo apt update (para Ubuntu/Debian) ou equivalente para outros sistemas.",
                                    "Instale OpenMPI: sudo apt install openmpi-bin openmpi-common libopenmpi-dev (ou MPICH: sudo apt install mpich libmpich-dev).",
                                    "Verifique privilégios de administrador se necessário.",
                                    "Reinicie o terminal ou atualize o PATH.",
                                    "Confirme a instalação com mpirun --version."
                                  ],
                                  "verification": "Execute 'mpicc --version' ou 'mpirun --version' e veja se exibe informações da versão sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Terminal Linux/Mac (WSL no Windows)",
                                    "Acesso root/sudo",
                                    "Documentação OpenMPI: https://www.open-mpi.org/"
                                  ],
                                  "tips": "Prefira OpenMPI para compatibilidade ampla; use MPICH se o foco for em clusters HPE.",
                                  "learningObjective": "Selecionar e instalar corretamente uma implementação MPI padrão.",
                                  "commonMistakes": [
                                    "Esquecer de instalar headers de desenvolvimento (libopenmpi-dev)",
                                    "Não atualizar pacotes antes da instalação",
                                    "Instalar versão errada para a arquitetura (32/64 bits)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar variáveis de ambiente para MPI",
                                  "subSteps": [
                                    "Adicione ao ~/.bashrc ou ~/.profile: export PATH=/usr/lib/x86_64-linux-gnu/openmpi/bin:$PATH (ajuste o caminho).",
                                    "export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/openmpi/lib:$LD_LIBRARY_PATH.",
                                    "Recarregue o shell: source ~/.bashrc.",
                                    "Teste com which mpicc e which mpirun.",
                                    "Crie um alias se necessário para facilitar chamadas."
                                  ],
                                  "verification": "Digite 'echo $PATH' e confirme que inclui diretórios MPI; 'mpicc --showme' deve mostrar flags corretas.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Editor de texto (nano/vim)",
                                    "Shell bash/zsh"
                                  ],
                                  "tips": "Use 'module load mpi/openmpi' em clusters HPC para gerenciar ambientes.",
                                  "learningObjective": "Configurar o ambiente para acessar compiladores e executores MPI seamless.",
                                  "commonMistakes": [
                                    "PATH incorreto levando a 'command not found'",
                                    "LD_LIBRARY_PATH ausente causando erros em runtime",
                                    "Não recarregar o shell após edições"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Escrever e compilar um programa Hello World MPI",
                                  "subSteps": [
                                    "Crie hello_mpi.c com #include <mpi.h>, int main(int argc, char** argv) { MPI_Init(&argc, &argv); int rank; MPI_Comm_rank(MPI_COMM_WORLD, &rank); printf('Hello from rank %d\\n', rank); MPI_Finalize(); return 0; }.",
                                    "Compile com mpicc hello_mpi.c -o hello_mpi.",
                                    "Verifique erros de compilação.",
                                    "Inspecione o executável com file hello_mpi.",
                                    "Adicione flags de otimização se desejado: -O2."
                                  ],
                                  "verification": "Compilação termina com 'success' sem warnings/erros; ls -l hello_mpi mostra executável.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Editor de código (VS Code, vim)",
                                    "Compilador GCC/Clang instalado"
                                  ],
                                  "tips": "Sempre inclua MPI_Init no início e MPI_Finalize no final para gerenciamento correto de processos.",
                                  "learningObjective": "Implementar estrutura básica de programa MPI com inicialização e finalização.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init antes de chamadas MPI",
                                    "Não passar argc/argv corretamente",
                                    "Usar gcc em vez de mpicc, perdendo flags MPI"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar e depurar o programa MPI",
                                  "subSteps": [
                                    "Execute com mpirun -np 4 ./hello_mpi (4 processos).",
                                    "Observe saídas de ranks 0-3.",
                                    "Teste com diferentes np (1, 2, 8).",
                                    "Use --hostfile ou -host para multi-nó se disponível.",
                                    "Depure com mpirun -np 4 valgrind ./hello_mpi para leaks."
                                  ],
                                  "verification": "Todas as saídas 'Hello from rank X' aparecem sem crashes; saída ordenada ou identificável por rank.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Máquina com múltiplos cores",
                                    "Valgrind opcional"
                                  ],
                                  "tips": "Comece com -np 1 para depuração serial; use --oversubscribe em laptops.",
                                  "learningObjective": "Executar programas MPI em modo paralelo e validar comportamento.",
                                  "commonMistakes": [
                                    "mpirun sem -np causando 1 processo padrão",
                                    "Executar em rede sem SSH keys",
                                    "Ignorar ordem de saída não determinística"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie hello_mpi.c como descrito no Step 3, compile e execute 'mpirun -np 4 ./hello_mpi'. Esperado: 'Hello from rank 0\nHello from rank 1\n...' (ordem pode variar).",
                              "finalVerifications": [
                                "mpicc e mpirun acessíveis via PATH.",
                                "Programa Hello World compila sem erros.",
                                "Execução com múltiplos processos produz saídas corretas de todos ranks.",
                                "MPI_Init e MPI_Finalize gerenciam processos sem leaks (verificado com valgrind).",
                                "Ambiente persistente após logout/login.",
                                "Compatibilidade com C/C++ confirmada."
                              ],
                              "assessmentCriteria": [
                                "Instalação completa sem dependências quebradas (100% sucesso).",
                                "Configuração de ambiente funcional em novo terminal (teste automatizado).",
                                "Código fonte correto com Init/Finalize (revisão de código).",
                                "Execução paralela bem-sucedida com 4+ processos (logs limpos).",
                                "Identificação e correção de 2+ erros comuns demonstrada.",
                                "Tempo total dentro de 1.5h com qualidade alta."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de processos e shells Unix.",
                                "Programação em C/C++: Wrappers de compiladores e bibliotecas.",
                                "Redes de Computadores: Comunicação inter-processo em clusters.",
                                "Computação de Alto Desempenho: Ambientes HPC e job schedulers como SLURM.",
                                "Administração de Sistemas: Instalação de pacotes e configuração de ambientes."
                              ],
                              "realWorldApplication": "Configuração essencial para simulações científicas em supercomputadores (ex: modelagem climática no ICMPD ou processamento de big data em bancos como Itaú), onde milhares de processos MPI rodam em clusters para acelerar cálculos paralelos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.2.1.3",
                            "name": "Identificar comunicadores e ranks em MPI",
                            "description": "Utilizar MPI_Comm_size(), MPI_Comm_rank() e MPI_COMM_WORLD para gerenciar grupos de processos e identificar posições em topologias distribuídas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de comunicadores e ranks em MPI",
                                  "subSteps": [
                                    "Estude a definição de comunicador: um objeto que define um grupo de processos que podem se comunicar.",
                                    "Aprenda o que é um rank: identificador único (de 0 a size-1) para cada processo no comunicador.",
                                    "Conheça MPI_COMM_WORLD: comunicador padrão que inclui todos os processos iniciados.",
                                    "Revise o modelo de memória distribuída em MPI, onde cada processo tem seu próprio endereço.",
                                    "Leia a documentação oficial do MPI sobre MPI_Comm_rank() e MPI_Comm_size()."
                                  ],
                                  "verification": "Resuma em suas palavras os conceitos de comunicador, rank e MPI_COMM_WORLD em um parágrafo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Documentação MPI oficial (mpitutorial.com ou man pages)",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Use diagramas para visualizar processos em um grupo, com ranks numerados.",
                                  "learningObjective": "Entender os papéis de comunicadores, ranks e MPI_COMM_WORLD no modelo MPI.",
                                  "commonMistakes": [
                                    "Confundir rank com processo (rank é ID lógico)",
                                    "Ignorar que ranks são relativos ao comunicador"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar o ambiente de desenvolvimento para MPI",
                                  "subSteps": [
                                    "Instale o MPI (OpenMPI ou MPICH) no seu sistema (ex: sudo apt install openmpi-bin libopenmpi-dev).",
                                    "Verifique a instalação com mpicc --version e mpirun --version.",
                                    "Crie um diretório de projeto e prepare um editor de código (VS Code, Vim).",
                                    "Compile um 'Hello World' MPI básico para testar: inclua <mpi.h>, MPI_Init e MPI_Finalize.",
                                    "Execute com mpirun -np 4 ./programa para testar múltiplos processos."
                                  ],
                                  "verification": "Execute mpirun -np 2 ./hello e confirme que roda sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Terminal Linux/Mac",
                                    "Compilador MPI (mpicc)",
                                    "Editor de texto"
                                  ],
                                  "tips": "Use -np para controlar o número de processos; comece com 2-4 para testes.",
                                  "learningObjective": "Configurar e validar ambiente MPI funcional.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init() antes de usar funções MPI",
                                    "Não chamar MPI_Finalize()"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Comm_rank() e MPI_Comm_size() em um programa",
                                  "subSteps": [
                                    "Inclua <mpi.h> e inicie com MPI_Init(NULL, NULL).",
                                    "Declare variáveis int rank, size; use MPI_Comm_rank(MPI_COMM_WORLD, &rank); e MPI_Comm_size(MPI_COMM_WORLD, &size);.",
                                    "Use printf para imprimir: 'Processo %d de %d' com rank e size.",
                                    "Adicione MPI_Barrier(MPI_COMM_WORLD) para sincronizar antes de finalizar.",
                                    "Salve como rank_size.c."
                                  ],
                                  "verification": "Compile com mpicc -o rank_size rank_size.c e execute mpirun -np 4 ./rank_size; veja saídas únicas por rank.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código fonte rank_size.c",
                                    "Compilador mpicc"
                                  ],
                                  "tips": "Sempre verifique erros com MPI_SUCCESS após chamadas MPI.",
                                  "learningObjective": "Codificar e usar funções para obter rank e tamanho do comunicador.",
                                  "commonMistakes": [
                                    "Passar MPI_COMM_WORLD incorretamente",
                                    "Não inicializar variáveis rank/size"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar, depurar e analisar resultados em topologias distribuídas",
                                  "subSteps": [
                                    "Compile e execute com diferentes -np (2, 4, 8) e observe padrões nos ranks.",
                                    "Use mpirun -hostfile hosts para simular topologias distribuídas em múltiplas máquinas.",
                                    "Adicione logs para depuração: fprintf(stderr, ...).",
                                    "Analise saídas: confirme que ranks são 0 a size-1 e únicos.",
                                    "Modifique para outro comunicador customizado (opcional, usando MPI_Comm_split)."
                                  ],
                                  "verification": "Gere relatório com saídas de execuções np=4 e np=8, explicando consistência.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Terminal",
                                    "Arquivo hosts.txt para multi-máquina (opcional)"
                                  ],
                                  "tips": "Redirecione saída para arquivo: mpirun -np 4 ./rank_size > output.txt.",
                                  "learningObjective": "Aplicar e validar funções em cenários distribuídos reais.",
                                  "commonMistakes": [
                                    "Executar sem -np levando a 1 processo",
                                    "Ignorar ordem não determinística de saída"
                                  ]
                                }
                              ],
                              "practicalExample": "#include <mpi.h>\n#include <stdio.h>\nint main(int argc, char** argv) {\n  MPI_Init(NULL, NULL);\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  printf(\"Olá do processo rank %d de %d processos\\n\", rank, size);\n  MPI_Finalize();\n  return 0;\n}\n/* Compile: mpicc -o exemplo exemplo.c */\n/* Execute: mpirun -np 4 ./exemplo */",
                              "finalVerifications": [
                                "Explicar verbalmente a diferença entre MPI_Comm_rank() e MPI_Comm_size().",
                                "Executar programa com 5 processos e listar saídas esperadas para cada rank.",
                                "Identificar rank e size em uma saída de log MPI real.",
                                "Descrever o papel de MPI_COMM_WORLD em um cluster de 10 nós.",
                                "Criar diagrama de 4 processos mostrando ranks e comunicador."
                              ],
                              "assessmentCriteria": [
                                "Código compila e executa sem erros de MPI.",
                                "Saídas mostram ranks corretos e únicos de 0 a size-1.",
                                "Explicação precisa de conceitos em relatório.",
                                "Uso correto de MPI_Init, Finalize e Barrier.",
                                "Análise de resultados em diferentes configurações np.",
                                "Identificação de erros comuns evitados."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Topologias distribuídas semelhantes a clusters.",
                                "Algoritmos e Estruturas de Dados: Gerenciamento de IDs em grupos paralelos.",
                                "Sistemas Operacionais: Processos e comunicação inter-processo (IPC).",
                                "Matemática Computacional: Indexação em arrays distribuídos por rank."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: modelagem climática no supercomputador), onde cada processo (rank) computa uma porção de dados em nós distribuídos, usando size para balancear carga e rank para coordenar trocas via MPI."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.2.2",
                        "name": "Comunicação Ponto-a-Ponto em MPI",
                        "description": "Operações básicas e avançadas de envio e recebimento de mensagens entre processos específicos em arquiteturas distribuídas.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.2.2.1",
                            "name": "Implementar MPI_Send e MPI_Recv bloqueantes",
                            "description": "Codificar envio síncrono e recebimento bloqueante de dados primitivos e derivados entre dois processos, gerenciando tags e contadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e inicializar processos",
                                  "subSteps": [
                                    "Instale o MPI se necessário (ex: OpenMPI via apt install openmpi-bin libopenmpi-dev)",
                                    "Crie um arquivo C com inclusão de <mpi.h>",
                                    "Implemente MPI_Init(&argc, &argv) no main",
                                    "Obtenha o número de processos com MPI_Comm_size(MPI_COMM_WORLD, &size)",
                                    "Obtenha o rank do processo atual com MPI_Get_rank(MPI_COMM_WORLD, &rank)",
                                    "Adicione verificação básica: if (rank == 0) printf('Processo 0 iniciado');"
                                  ],
                                  "verification": "Compile com mpicc -o init_test programa.c e execute com mpirun -np 2 ./init_test; verifique se ambos os processos imprimem sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou vim)",
                                    "Terminal Linux/Mac"
                                  ],
                                  "tips": "Sempre inicialize MPI no início do main e use MPI_COMM_WORLD para comunicação básica.",
                                  "learningObjective": "Configurar corretamente o ambiente MPI e identificar processos individuais.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes de MPI_Get_rank",
                                    "Usar printf sem fflush(stdout) em ambientes paralelos",
                                    "Executar sem mpirun -np N"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Send no processo remetente (rank 0)",
                                  "subSteps": [
                                    "Declare variáveis: int data = 42; int tag = 123; MPI_Status status;",
                                    "No if (rank == 0): prepare o contador de elementos (count = 1 para primitivo)",
                                    "Chame MPI_Send(&data, 1, MPI_INT, 1, tag, MPI_COMM_WORLD); // destino rank 1",
                                    "Adicione printf('Dados enviados: %d com tag %d', data, tag);",
                                    "Garanta que o envio seja bloqueante (padrão MPI_Send)"
                                  ],
                                  "verification": "Compile e execute; verifique se o processo 0 imprime 'Dados enviados' sem travar.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código do Step 1",
                                    "Documentação MPI_Send (man MPI_Send ou mpi-forum.org)"
                                  ],
                                  "tips": "Use tags únicas para diferenciar mensagens; comece com dados primitivos como int.",
                                  "learningObjective": "Codificar envio síncrono bloqueante de dados primitivos com tags e contadores.",
                                  "commonMistakes": [
                                    "Especificar destino incorreto (não rank 1)",
                                    "Omitir contador de elementos (deve ser 1 para single int)",
                                    "Confundir MPI_Send com não-bloqueante"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Recv no processo receptor (rank 1)",
                                  "subSteps": [
                                    "Declare variáveis no receptor: int received_data; int tag = 123; MPI_Status status;",
                                    "No if (rank == 1): chame MPI_Recv(&received_data, 1, MPI_INT, 0, tag, MPI_COMM_WORLD, &status);",
                                    "Verifique o status: int count; MPI_Get_count(&status, MPI_INT, &count); printf('Recebido %d de %d elementos', received_data, count);",
                                    "Adicione MPI_Barrier(MPI_COMM_WORLD) para sincronização opcional",
                                    "Teste com dados derivados: struct {int a; double b;} deriv; ajuste count e MPI_BYTE se necessário"
                                  ],
                                  "verification": "Execute mpirun -np 2 ./programa; confirme se rank 1 imprime dados corretos recebidos.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Código dos Steps anteriores",
                                    "Referência MPI_Datatypes para derivados"
                                  ],
                                  "tips": "Sempre use MPI_Status para verificar contadores pós-recv; especifique tag exata no recv.",
                                  "learningObjective": "Implementar recebimento bloqueante gerenciando tags, contadores e status.",
                                  "commonMistakes": [
                                    "Tag mismatch entre send/recv",
                                    "Não usar &status em MPI_Recv",
                                    "Esquecer MPI_Get_count para validar recebimento"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Finalizar programa, testar com dados derivados e depurar",
                                  "subSteps": [
                                    "Adicione MPI_Finalize() no final do main após todos os prints",
                                    "Expanda para dados derivados: defina MPI_Datatype para struct ou array (ex: MPI_Type_contiguous)",
                                    "Compile e teste com mpirun -np 2 -host localhost ./programa",
                                    "Use mpirun --oversubscribe se necessário; adicione gdb para debug (mpirun -np 2 gdb ./programa)",
                                    "Valide com múltiplas mensagens variando tags e contadores"
                                  ],
                                  "verification": "Programa executa sem deadlocks, dados primitivos e derivados são transferidos corretamente em ambos sentidos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "mpirun, gdb para debug",
                                    "Documentação MPI_Finalize e MPI_Datatype"
                                  ],
                                  "tips": "MPI_Send/Recv bloqueantes podem causar deadlock se ambos enviarem sem recv; teste sender->receiver primeiro.",
                                  "learningObjective": "Integrar comunicação completa, lidar com tipos derivados e finalizar MPI adequadamente.",
                                  "commonMistakes": [
                                    "Chamar MPI_Finalize antes de todas comunicações",
                                    "Deadlock por ordem send/recv invertida",
                                    "Não sincronizar com barrier se necessário"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa com 2 processos: rank 0 envia um array de 10 inteiros [1,2,...,10] usando MPI_Send(array, 10, MPI_INT, 1, 99, MPI_COMM_WORLD); rank 1 recebe com MPI_Recv(buf, 10, MPI_INT, 0, 99, MPI_COMM_WORLD, &status); rank 1 soma e imprime o total (55).",
                              "finalVerifications": [
                                "Programa compila sem warnings com mpicc",
                                "Executa com mpirun -np 2 sem deadlocks ou crashes",
                                "Dados primitivos (int, double) são enviados/recebidos corretamente",
                                "Tags e contadores são gerenciados e validados via MPI_Get_count",
                                "Dados derivados (array/struct) transferem sem corrupção",
                                "MPI_Init e MPI_Finalize são chamados corretamente"
                              ],
                              "assessmentCriteria": [
                                "Uso correto de sintaxe MPI_Send/Recv com todos parâmetros (buf, count, datatype, dest/src, tag, comm)",
                                "Gerenciamento preciso de tags únicas e contadores de elementos",
                                "Verificação de status pós-recv com MPI_Get_count",
                                "Tratamento de processos por rank (if rank==0/1)",
                                "Ausência de deadlocks em execuções bloqueantes",
                                "Código limpo com comentários e prints de debug"
                              ],
                              "crossCurricularConnections": [
                                "Programação em C: ponteiros, structs e alocação dinâmica para buffers",
                                "Sistemas Operacionais: conceitos de processos, sincronização e comunicação inter-processo",
                                "Redes de Computadores: modelo cliente-servidor e protocolos de mensagens",
                                "Algoritmos Paralelos: decomposição de tarefas e distribuição de dados"
                              ],
                              "realWorldApplication": "Em simulações científicas HPC como modelagem climática (troca de grids entre processos) ou processamento de imagens paralelas (distribuição de pixels), onde MPI_Send/Recv bloqueantes garantem sincronização simples em clusters distribuídos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.2.1.2"
                            ]
                          },
                          {
                            "id": "10.1.4.2.2.2",
                            "name": "Usar comunicações não-bloqueantes MPI_Isend e MPI_Irecv",
                            "description": "Implementar operações assíncronas com MPI_Wait() e MPI_Test() para sobreposição de comunicação e computação, melhorando desempenho em clusters.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos de comunicação bloqueante vs. não-bloqueante em MPI",
                                  "subSteps": [
                                    "Estude a diferença entre MPI_Send/MPI_Recv (bloqueantes) e MPI_Isend/MPI_Irecv (não-bloqueantes).",
                                    "Aprenda sobre objetos MPI_Request para rastrear operações pendentes.",
                                    "Revise funções de sincronização: MPI_Wait (bloqueante), MPI_Test (não-bloqueante).",
                                    "Analise diagramas de timeline mostrando sobreposição de comunicação e computação.",
                                    "Leia exemplos na documentação oficial do MPI."
                                  ],
                                  "verification": "Explique em suas palavras como a sobreposição melhora o desempenho em clusters.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação MPI oficial (mpi-forum.org)",
                                    "Tutorial OpenMPI sobre não-bloqueante",
                                    "Livro 'Using MPI' de Gropp et al."
                                  ],
                                  "tips": "Visualize fluxos com desenhos: desenhe timelines de execução bloqueante vs. assíncrona.",
                                  "learningObjective": "Dominar os princípios teóricos das comunicações assíncronas para otimizar desempenho.",
                                  "commonMistakes": [
                                    "Confundir MPI_Send com MPI_Isend",
                                    "Ignorar que Isend/Irecv retornam imediatamente sem completar a operação",
                                    "Esquecer que requests precisam ser gerenciadas explicitamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Isend e MPI_Irecv em um programa básico",
                                  "subSteps": [
                                    "Configure um programa MPI com MPI_Init e dois ranks (0 e 1).",
                                    "No rank 0, prepare um buffer de envio e chame MPI_Isend com MPI_Request.",
                                    "No rank 1, prepare buffer de recebimento e chame MPI_Irecv com MPI_Request.",
                                    "Compile com mpicc e execute com mpirun -np 2.",
                                    "Verifique saída inicial sem sincronização completa."
                                  ],
                                  "verification": "O programa compila e executa sem erros imediatos ou deadlocks prematuros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador MPI (OpenMPI ou MPICH)",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal com MPI instalado"
                                  ],
                                  "tips": "Use buffers pequenos (ex: int buf[10]) para testes iniciais e sempre inicialize com valores conhecidos.",
                                  "learningObjective": "Executar corretamente as primitivas não-bloqueantes em código.",
                                  "commonMistakes": [
                                    "Não inicializar buffers adequadamente",
                                    "Usar tamanhos incorretos em contadores",
                                    "Esquecer MPI_Comm_rank e MPI_Comm_size"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Sincronizar operações com MPI_Wait e MPI_Test",
                                  "subSteps": [
                                    "Adicione MPI_Wait(&request, MPI_STATUS_IGNORE) após Isend/Irecv em ambos os ranks.",
                                    "Teste com MPI_Test em loop para polling não-bloqueante.",
                                    "Imprima buffers após espera para verificar troca de dados.",
                                    "Execute e confirme que dados são trocados corretamente.",
                                    "Compare tempo de execução com versão bloqueante (MPI_Send/Recv)."
                                  ],
                                  "verification": "Dados enviados no rank 0 são recebidos corretamente no rank 1 e vice-versa.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Mesmo ambiente do step anterior",
                                    "Relógio de alta resolução: MPI_Wtime()"
                                  ],
                                  "tips": "Sempre ignore status com MPI_STATUS_IGNORE inicialmente; avance para análise posterior.",
                                  "learningObjective": "Gerenciar e completar operações assíncronas de forma segura.",
                                  "commonMistakes": [
                                    "Chamar Wait em request não inicializada",
                                    "Não tratar erros com MPI_ERROR_CHECK",
                                    "Usar MPI_Test sem loop adequado levando a busy-waiting"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar sobreposição de comunicação e computação",
                                  "subSteps": [
                                    "Após postar Isend/Irecv, insira computação local (ex: soma de array grande).",
                                    "Use loop com MPI_Test para checar conclusão enquanto computa.",
                                    "Chame MPI_Wait apenas se Test falhar, permitindo sobreposição.",
                                    "Meça tempos com MPI_Wtime() e compare com versão sem sobreposição.",
                                    "Profile com ferramentas como mpiP ou gprof para validar ganhos."
                                  ],
                                  "verification": "Tempo total de execução é menor que na versão sem sobreposição (ganho mensurável).",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Ferramentas de profiling MPI (mpiP)",
                                    "Arrays grandes para computação (ex: 1e6 elementos)"
                                  ],
                                  "tips": "Ajuste tamanho da computação para equilibrar com latência de rede simulada.",
                                  "learningObjective": "Aplicar sobreposição para otimizar desempenho em cenários reais.",
                                  "commonMistakes": [
                                    "Computação muito curta não sobrepõe efetivamente",
                                    "Busy-waiting ineficiente sem yield",
                                    "Não medir tempos corretamente"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa onde rank 0 envia um vetor de números via MPI_Isend, ambos os ranks computam a soma parcial de um array local grande (ex: 1e6 elementos) usando MPI_Test em loop, e então recebem via MPI_Irecv + Wait. Compare tempo com versão bloqueante: deve haver redução de até 30-50% em clusters.",
                              "finalVerifications": [
                                "Programa compila sem warnings com mpicc -Wall.",
                                "Execução com mpirun -np 4 mostra troca correta de dados em todos ranks.",
                                "MPI_Wtime() confirma sobreposição (tempo_computacao + tempo_comunicacao < tempo_total).",
                                "Sem leaks de requests (valgrind mpirun mostra clean).",
                                "Ganho de performance mensurável vs. versão bloqueante.",
                                "Funciona em cluster real sem deadlocks."
                              ],
                              "assessmentCriteria": [
                                "Correto uso de MPI_Isend/MPI_Irecv com requests válidas.",
                                "Sincronização apropriada via MPI_Wait/MPI_Test sem race conditions.",
                                "Demonstração clara de sobreposição com medições de tempo.",
                                "Tratamento robusto de erros e status MPI.",
                                "Código limpo, comentado e modular.",
                                "Escalabilidade testada com múltiplos processos."
                              ],
                              "crossCurricularConnections": [
                                "Otimização de algoritmos em Computação Científica.",
                                "Arquitetura de Computadores (pipelining e paralelismo).",
                                "Redes de Computadores (latência e throughput).",
                                "Análise de Desempenho e Profiling.",
                                "Programação em C com gerenciamento de memória."
                              ],
                              "realWorldApplication": "Em simulações HPC como modelagem climática (ex: CESM), dinâmica molecular (GROMACS) ou física de partículas (CERN), onde sobrepor comunicação em clusters de milhares de nós reduz tempo de simulação de dias para horas, otimizando uso de supercomputadores."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.2.2.1"
                            ]
                          },
                          {
                            "id": "10.1.4.2.2.3",
                            "name": "Criar tipos de dados derivados em MPI",
                            "description": "Definir estruturas personalizadas com MPI_Type_contiguous(), MPI_Type_vector() e MPI_Type_commit() para transmissão eficiente de arrays e structs.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Conceitos Fundamentais de Tipos Derivados em MPI",
                                  "subSteps": [
                                    "Estude a documentação oficial do MPI sobre tipos de dados derivados (MPI_Type_contiguous, MPI_Type_vector).",
                                    "Identifique diferenças entre tipos básicos e derivados, focando em eficiência para arrays e structs.",
                                    "Compile e execute um programa MPI simples de 'hello world' para verificar o ambiente.",
                                    "Revise exemplos de comunicação ponto-a-ponto básica (MPI_Send, MPI_Recv) sem tipos derivados.",
                                    "Anote casos de uso: arrays multidimensionais e estruturas compostas."
                                  ],
                                  "verification": "Resuma em um documento os conceitos chave e liste 3 benefícios de tipos derivados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação MPI (mpich.org ou open-mpi.org)",
                                    "Compilador MPI (mpicc)",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Use o modo interativo do mpirun para testes rápidos com poucos processos.",
                                  "learningObjective": "Compreender o propósito e a sintaxe básica de tipos derivados para otimizar comunicações.",
                                  "commonMistakes": [
                                    "Confundir contíguo com vetorizado",
                                    "Esquecer de incluir <mpi.h>"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Type_contiguous para Arrays Contíguos",
                                  "subSteps": [
                                    "Defina um array simples (ex: int array[100]).",
                                    "Crie um tipo derivado com MPI_Type_contiguous(100, MPI_INT, &newtype).",
                                    "Commit o tipo com MPI_Type_commit(&newtype).",
                                    "Use o tipo em MPI_Send e MPI_Recv entre dois processos.",
                                    "Compile com mpicc e execute com mpirun -np 2."
                                  ],
                                  "verification": "Execute o programa e confirme que dados são transmitidos corretamente sem erros de contagem.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código-fonte MPI básico",
                                    "mpirun para execução paralela"
                                  ],
                                  "tips": "Sempre free o tipo com MPI_Type_free após uso para evitar vazamentos.",
                                  "learningObjective": "Criar e usar tipos contíguos para transmissão eficiente de blocos de dados.",
                                  "commonMistakes": [
                                    "Não chamar MPI_Type_commit",
                                    "Usar tamanho incorreto no contiguous"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Type_vector para Arrays Não-Contíguos",
                                  "subSteps": [
                                    "Crie um array 2D representado como 1D (ex: int matrix[10][10]).",
                                    "Defina MPI_Type_vector(count, blocklength, stride, oldtype, &newtype). Ex: count=10, block=1, stride=10 para linhas.",
                                    "Commit e use em comunicação para enviar apenas linhas pares.",
                                    "Teste com MPI_Sendrecv para troca entre processos.",
                                    "Valide recebendo e imprimindo os dados."
                                  ],
                                  "verification": "Compare dados enviados e recebidos; confirme que apenas elementos selecionados foram transmitidos.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Exemplos de código de matrizes em C",
                                    "Debugger como gdb com MPI"
                                  ],
                                  "tips": "Stride é em elementos do oldtype, não bytes; teste com valores pequenos primeiro.",
                                  "learningObjective": "Manipular dados dispersos eficientemente com vetorização.",
                                  "commonMistakes": [
                                    "Erro no cálculo de stride",
                                    "Esquecer de commit antes de usar"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Criar Tipos Derivados para Structs e Integrar em Comunicação",
                                  "subSteps": [
                                    "Defina uma struct em C (ex: struct Particle { double pos[3]; int id; }).",
                                    "Use MPI_Type_create_struct com arrays de lengths, displacements e types.",
                                    "Calcule displacements com MPI_Aint e MPI_Get_address.",
                                    "Commit e envie structs completos via MPI_Send/MPI_Recv.",
                                    "Execute com múltiplos processos e verifique consistência."
                                  ],
                                  "verification": "Imprima structs enviados/recebidos em todos processos; confirme igualdade.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Structs em C/MPI exemplos da documentação",
                                    "Valgrind para checar memória"
                                  ],
                                  "tips": "Alinhe structs com MPI_UB se necessário para padding.",
                                  "learningObjective": "Construir tipos compostos para dados heterogêneos reais.",
                                  "commonMistakes": [
                                    "Displacements incorretos devido a padding",
                                    "Não usar MPI_BYTE para addresses"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar e Otimizar Tipos Derivados em Cenário Realista",
                                  "subSteps": [
                                    "Combine contiguous, vector e struct em um programa de simulação (ex: scatter de partículas).",
                                    "Meça performance com MPI_Wtime antes/depois de usar tipos derivados vs. loops manuais.",
                                    "Adicione error handling com MPI_Error_string.",
                                    "Execute com np=4-8 e analise output.",
                                    "Documente ganhos de performance."
                                  ],
                                  "verification": "Relatório com tempos de execução mostrando melhoria >20%.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "MPI_Wtime exemplos",
                                    "Cluster local ou cloud para testes escalados"
                                  ],
                                  "tips": "Use --oversubscribe em mpirun se faltarem cores.",
                                  "learningObjective": "Aplicar e validar tipos derivados em fluxos de trabalho paralelos.",
                                  "commonMistakes": [
                                    "Não inicializar MPI adequadamente",
                                    "Ignorar erros de comunicação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de N-body, crie um tipo derivado para struct Particle {double x,y,z,vx,vy,vz; int id;} usando MPI_Type_create_struct. Rank 0 espalha partículas para ranks 1-N com MPI_Scatterv usando MPI_Type_vector para subconjuntos não-contíguos, atualiza localmente e reduz com MPI_Reduce.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros MPI_ERR_TYPE.",
                                "Dados transmitidos com tipos derivados coincidem com cópias byte-a-byte.",
                                "Performance melhora em pelo menos 15% vs. comunicação básica.",
                                "Tipos são commitados e freeados corretamente.",
                                "Funciona com np=2 a 8 processos.",
                                "Structs com padding são tratados via displacements precisos."
                              ],
                              "assessmentCriteria": [
                                "Correta definição e commit de pelo menos 3 tipos derivados distintos.",
                                "Uso efetivo em Send/Recv sem overhead desnecessário.",
                                "Cálculo preciso de strides/displacements com validação.",
                                "Tratamento de erros e limpeza de recursos.",
                                "Demonstração de otimização mensurável.",
                                "Código limpo, comentado e reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Programação em C: Structs e ponteiros.",
                                "Computação de Alto Desempenho (HPC): Otimização de bandwidth.",
                                "Algoritmos Paralelos: Scatter/gather patterns.",
                                "Engenharia de Software: Abstrações de dados.",
                                "Matemática Computacional: Vetores e matrizes dispersas."
                              ],
                              "realWorldApplication": "Em simulações científicas como dinâmica molecular (GROMACS) ou modelagem climática (MPAS), tipos derivados reduzem overhead de comunicação em clusters HPC, permitindo escalabilidade para milhares de processos em supercomputadores como Frontier ou Fugaku."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.2.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.2.3",
                        "name": "Comunicação Coletiva e Avaliação de Desempenho",
                        "description": "Operações de grupo em MPI para sincronização e redução de dados, além de métricas para análise de programas paralelos em memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.2.3.1",
                            "name": "Aplicar operações coletivas básicas",
                            "description": "Implementar MPI_Bcast(), MPI_Scatter() e MPI_Gather() para distribuição e coleta de dados entre múltiplos processos em topologias distribuídas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e revisar conceitos de comunicação coletiva",
                                  "subSteps": [
                                    "Instalar e verificar MPI (OpenMPI ou MPICH) no sistema local ou cluster.",
                                    "Compilar e executar um programa MPI 'Hello World' para validar o ambiente.",
                                    "Estudar documentação oficial do MPI para MPI_Bcast, MPI_Scatter e MPI_Gather, focando em assinaturas, parâmetros e topologias.",
                                    "Identificar diferenças entre comunicação ponto-a-ponto e coletiva.",
                                    "Criar um diagrama mental ou sketch de como dados fluem em broadcasts, scatters e gathers."
                                  ],
                                  "verification": "Programa Hello World executa corretamente com mpirun -np 4 e exibe saídas sincronizadas de todos os processos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Instalador MPI (OpenMPI/MPICH)",
                                    "Compilador C/C++ (gcc/mpicc)",
                                    "Documentação MPI oficial (mpi-forum.org)",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Use mpirun -np <num> para testar com múltiplos processos; inicie com 4 processos para simplicidade.",
                                  "learningObjective": "Compreender pré-requisitos e diferenças fundamentais de operações coletivas em MPI.",
                                  "commonMistakes": [
                                    "Não inicializar/finalizar MPI corretamente",
                                    "Confundir rank e size de processos",
                                    "Ignorar verificação de erros em chamadas MPI"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e testar MPI_Bcast para distribuição global de dados",
                                  "subSteps": [
                                    "Criar um programa que inicializa um array no processo root (rank 0).",
                                    "Chamar MPI_Bcast para transmitir o array para todos os processos.",
                                    "Cada processo imprime seu rank e o valor recebido para verificação.",
                                    "Testar com diferentes tamanhos de dados e números de processos.",
                                    "Adicionar tratamento de erros com MPI_SUCCESS."
                                  ],
                                  "verification": "Todos os processos recebem e imprimem o mesmo array corretamente, sem discrepâncias.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código base MPI_Bcast.c",
                                    "mpicc para compilar",
                                    "mpirun para executar"
                                  ],
                                  "tips": "Sempre especifique MPI_COMM_WORLD como comunicador; verifique tamanhos de buffer com MPI_INT.",
                                  "learningObjective": "Dominar broadcast para sincronizar dados iniciais em aplicações paralelas.",
                                  "commonMistakes": [
                                    "Buffer não alocado corretamente no receptor",
                                    "Root incorreto ou não definido",
                                    "Mismatch de tipos de dados no buffer"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Scatter e MPI_Gather para distribuição e coleta de arrays",
                                  "subSteps": [
                                    "No processo root, preparar um array grande e buffers de envio/recebimento.",
                                    "Usar MPI_Scatter para distribuir porções do array para cada processo.",
                                    "Cada processo processa sua porção (ex: soma elementos).",
                                    "Usar MPI_Gather para coletar resultados de volta no root.",
                                    "Root imprime soma total para validação."
                                  ],
                                  "verification": "Soma total coletada no root matches a soma esperada do array original.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código MPI_Scatter_Gather.c",
                                    "mpicc",
                                    "mpirun -np 8"
                                  ],
                                  "tips": "Garanta que count seja o mesmo para sendcount/recvcount; use MPI_IN_PLACE se aplicável.",
                                  "learningObjective": "Aplicar scatter-gather para divisão de trabalho e agregação de resultados.",
                                  "commonMistakes": [
                                    "Tamanhos inconsistentes em sendbuf/recvbuf",
                                    "Não calcular offsets corretamente para root",
                                    "Esquecer de alocar buffers em todos os processos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar operações em um programa completo e otimizar",
                                  "subSteps": [
                                    "Combinar Bcast, Scatter e Gather em um pipeline: broadcast config, scatter dados, gather resultados.",
                                    "Medir tempo de execução com MPI_Wtime para comparar desempenho.",
                                    "Testar com topologias variadas (np=2,4,8) e detectar gargalos.",
                                    "Refatorar código para reutilização e adicionar comentários.",
                                    "Executar em cluster remoto se disponível para validar escalabilidade."
                                  ],
                                  "verification": "Programa executa corretamente em múltiplos np, com tempos decrescentes e resultados precisos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código integrado MPI_Collective.c",
                                    "MPI_Wtime docs",
                                    "Cluster SSH se aplicável"
                                  ],
                                  "tips": "Use MPI_Barrier para sincronizar medições; profile com ferramentas como mpiP.",
                                  "learningObjective": "Integrar coletivas em fluxos reais e avaliar desempenho inicial.",
                                  "commonMistakes": [
                                    "Deadlocks por ordem errada de chamadas",
                                    "Vazamentos de memória em buffers grandes",
                                    "Não finalizar MPI_Finalize"
                                  ]
                                }
                              ],
                              "practicalExample": "Programa que simula computação de soma de vetores distribuída: root broadcast tamanho N, scatter vetor para processos que computam somas parciais, gather retorna soma global. Exemplo: mpirun -np 4 ./programa 1000 -> todos recebem N=1000, cada soma sua fatia, root imprime total correto.",
                              "finalVerifications": [
                                "Programa compila sem warnings com mpicc -Wall.",
                                "Executa corretamente com np=2,4,8 sem crashes ou deadlocks.",
                                "Outputs de todos processos são idênticos para dados broadcasted.",
                                "Scatter/Gather preserva dados originais (verificados por checksum).",
                                "Tempo de execução escala linearmente com np.",
                                "Nenhum erro MPI reportado (MPI_SUCCESS em todas chamadas)."
                              ],
                              "assessmentCriteria": [
                                "Correção funcional: dados distribuídos/coletados precisamente.",
                                "Eficiência: uso correto de buffers e minimização de cópias.",
                                "Robustez: tratamento de erros e validação de parâmetros.",
                                "Escalabilidade: funciona com np variável sem modificações.",
                                "Clareza de código: comentários e estrutura modular.",
                                "Desempenho: medição e análise básica de speedup."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Operações vetoriais e redução paralela (álgebra linear).",
                                "Redes de Computadores: Protocolos de multicast e agregação de dados.",
                                "Algoritmos: Divide-and-conquer aplicado a computação distribuída.",
                                "Engenharia de Software: Design de APIs paralelas e padrões de comunicação."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (distribuir grids de dados), machine learning distribuído (scatter batches de treinamento, gather gradientes), ou processamento de big data (HPC clusters no CERN ou supercomputadores para física de partículas)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.2.2.1"
                            ]
                          },
                          {
                            "id": "10.1.4.2.3.2",
                            "name": "Utilizar reduções coletivas MPI_Reduce e MPI_Allreduce",
                            "description": "Codificar operações de soma, máximo e outras reduções com MPI_Op para computar resultados globais a partir de dados locais em aplicações paralelas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de MPI_Reduce e MPI_Allreduce",
                                  "subSteps": [
                                    "Estude a documentação oficial do MPI para MPI_Reduce: root process recebe o resultado da redução.",
                                    "Analise MPI_Allreduce: todos os processos recebem o resultado da redução.",
                                    "Identifique parâmetros comuns: buffer de envio, buffer de recebimento, contagem, datatype, operação (MPI_Op), comm.",
                                    "Revise operações pré-definidas: MPI_SUM, MPI_MAX, MPI_MIN.",
                                    "Compare com point-to-point: reduções coletivas são mais eficientes para operações globais."
                                  ],
                                  "verification": "Resuma em um diagrama ou parágrafo as diferenças entre MPI_Reduce e MPI_Allreduce, incluindo fluxos de dados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação MPI oficial (man pages para MPI_Reduce e MPI_Allreduce)",
                                    "Ambiente MPI instalado (OpenMPI ou MPICH)"
                                  ],
                                  "tips": [
                                    "Use diagramas de processos para visualizar o fluxo de dados.",
                                    "Teste conceitos com 2-4 processos para simplicidade inicial."
                                  ],
                                  "learningObjective": "Explicar semanticamente MPI_Reduce e MPI_Allreduce, incluindo quando usar cada um.",
                                  "commonMistakes": [
                                    "Confundir root em MPI_Reduce com broadcast.",
                                    "Ignorar que buffers de envio/recebimento podem ser o mesmo."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar MPI_Reduce para operações de soma e máximo",
                                  "subSteps": [
                                    "Escreva um programa simples: cada processo inicializa um valor local (ex: rank * 10).",
                                    "Configure MPI_Init, MPI_Comm_size, MPI_Comm_rank.",
                                    "Chame MPI_Reduce com MPI_SUM no processo root (rank 0).",
                                    "No root, imprima o resultado global; outros processos finalizam.",
                                    "Compile e execute com mpirun -np 4; verifique saídas."
                                  ],
                                  "verification": "Execute o código com 4 processos e confirme que root recebe soma correta (ex: soma de 0+10+20+30=60).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Editor de código (VSCode ou similar)",
                                    "Compilador MPI (mpicc)",
                                    "Terminal para mpirun"
                                  ],
                                  "tips": [
                                    "Use MPI_IN_PLACE para otimizar buffers quando possível.",
                                    "Adicione prints condicionais por rank para debug."
                                  ],
                                  "learningObjective": "Codificar corretamente MPI_Reduce para reduções básicas como soma e máximo.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Finalize.",
                                    "Usar datatype incorreto (ex: MPI_INT para floats)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar MPI_Allreduce e comparar desempenho com MPI_Reduce",
                                  "subSteps": [
                                    "Modifique o código anterior para usar MPI_Allreduce com MPI_SUM e MPI_MAX.",
                                    "Meça tempo de execução com MPI_Wtime antes/depois da chamada coletiva.",
                                    "Execute com diferentes np (2,4,8) e compare tempos entre Reduce e Allreduce.",
                                    "Analise overhead: Allreduce tipicamente mais lento, mas útil para sincronização.",
                                    "Adicione vetores: reduza arrays de 100 elementos."
                                  ],
                                  "verification": "Confirme que todos os processos imprimem o mesmo resultado global e registre tempos médios.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Código do Step 2",
                                    "Relógio de alta resolução (MPI_Wtick para precisão)"
                                  ],
                                  "tips": [
                                    "Execute múltiplas rodadas e tire média para medições confiáveis.",
                                    "Use --oversubscribe se necessário para mais processos."
                                  ],
                                  "learningObjective": "Aplicar MPI_Allreduce em cenários distribuídos e avaliar diferenças de desempenho.",
                                  "commonMistakes": [
                                    "Não sincronizar com MPI_Barrier antes de medir.",
                                    "Ignorar escalabilidade com mais processos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Criar e utilizar MPI_Op personalizado para reduções avançadas",
                                  "subSteps": [
                                    "Defina uma função de redução customizada (ex: soma de pares ímpar+par).",
                                    "Registre com MPI_Op_create(assoc|commute, &op).",
                                    "Use o MPI_Op customizado em MPI_Allreduce sobre um array estruturado.",
                                    "Teste com dados variados e libere com MPI_Op_free.",
                                    "Integre em um exemplo de estatísticas: média ponderada global."
                                  ],
                                  "verification": "Execute e valide que o resultado customizado é correto em todos processos (ex: média exata).",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Documentação MPI_Op_create",
                                    "Código dos steps anteriores"
                                  ],
                                  "tips": [
                                    "Garanta que a função custom seja associativa e comutativa.",
                                    "Debug com valores pequenos primeiro."
                                  ],
                                  "learningObjective": "Desenvolver operações de redução personalizadas com MPI_Op para aplicações específicas.",
                                  "commonMistakes": [
                                    "Não marcar função como static.",
                                    "Esquecer MPI_Op_free causando leaks."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de simulação distribuída de Monte Carlo, cada processo calcula somas parciais de estimativas locais de pi; use MPI_Allreduce(MPI_SUM) para obter a soma global precisa, dividida pelo número total de trials para pi final em todos nós.",
                              "finalVerifications": [
                                "Explicar verbalmente ou por escrito a diferença chave entre MPI_Reduce e MPI_Allreduce.",
                                "Executar código MPI_Reduce com 4 processos e confirmar resultado no root.",
                                "Demonstrar MPI_Allreduce produzindo o mesmo resultado em todos processos.",
                                "Implementar MPI_Op customizado e validar com input/output esperados.",
                                "Medir e relatar tempos de execução para np=8, comparando SUM vs MAX.",
                                "Identificar cenário onde Allreduce é preferível a Reduce + Bcast."
                              ],
                              "assessmentCriteria": [
                                "Código compila sem warnings e executa corretamente com múltiplos np.",
                                "Resultados numéricos exatos para reduções SUM, MAX e custom.",
                                "Medições de tempo precisas com variação <5% em rodadas repetidas.",
                                "Função MPI_Op customizada é associativa, comutativa e liberada corretamente.",
                                "Comentários no código explicam parâmetros e lógica de redução.",
                                "Análise escrita de desempenho e trade-offs entre Reduce/Allreduce."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Operações de redução em álgebra linear e estatística descritiva.",
                                "Física Computacional: Agregação de dados em simulações paralelas (ex: forças totais).",
                                "Ciência de Dados: All-reduce em treinamento distribuído de ML (gradientes).",
                                "Engenharia de Software: Padrões de design para comunicação coletiva em sistemas distribuídos."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas (ex: somar contribuições de precipitação por grid distribuído) ou em frameworks de ML como Horovod/TensorFlow, onde MPI_Allreduce sincroniza gradientes em clusters de GPUs para treinamento escalável."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.2.3.1"
                            ]
                          },
                          {
                            "id": "10.1.4.2.3.3",
                            "name": "Avaliar desempenho de programas MPI",
                            "description": "Medir speedup, eficiência e overhead de comunicação usando ferramentas como MPI_Wtime() e análise de decomposição de domínio em estudos de caso.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e o programa MPI de teste",
                                  "subSteps": [
                                    "Instalar e configurar ambiente MPI (OpenMPI ou MPICH).",
                                    "Selecionar ou criar um programa MPI simples com comunicação coletiva (ex: MPI_Reduce ou MPI_Allreduce).",
                                    "Compilar o programa usando mpicc com flags de otimização (-O2).",
                                    "Executar testes básicos com mpirun -np 1 até 8 para validar funcionalidade.",
                                    "Documentar configuração da máquina (núcleos, memória)."
                                  ],
                                  "verification": "Programa compila sem erros e executa corretamente com diferentes números de processos, produzindo saídas esperadas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Terminal ou ambiente cluster (ex: SLURM)",
                                    "Código fonte exemplo de comunicação coletiva"
                                  ],
                                  "tips": [
                                    "Use hosts locais multi-core para simular cluster.",
                                    "Habilite logging de erros MPI com -v."
                                  ],
                                  "learningObjective": "Configurar um ambiente reprodutível para experimentos de desempenho em MPI.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init() ou MPI_Finalize().",
                                    "Executar sem mpirun ou com np incompatível com hardware."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Instrumentar o código com MPI_Wtime() para medições de tempo",
                                  "subSteps": [
                                    "Identificar seções críticas: inicialização, comunicação coletiva, computação local e finalização.",
                                    "Inserir chamadas MPI_Wtime() antes e depois de cada seção para capturar timestamps.",
                                    "Calcular tempos locais (delta = end - start) em cada processo.",
                                    "Coletar estatísticas globais com MPI_Reduce (min, max, média de tempos).",
                                    "Recompilar, executar e validar saídas de tempo impressas."
                                  ],
                                  "verification": "Programa imprime tempos detalhados (total, comm, compute) para cada número de processos sem crashes ou valores inválidos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação MPI (man MPI_Wtime)",
                                    "Editor de código (VSCode ou similar)",
                                    "Código fonte instrumentado"
                                  ],
                                  "tips": [
                                    "Use double para alta precisão em MPI_Wtime().",
                                    "Sincronize processos com MPI_Barrier() antes de medições críticas."
                                  ],
                                  "learningObjective": "Instrumentar programas MPI para medições precisas de tempo wall-clock.",
                                  "commonMistakes": [
                                    "Não sincronizar processos, causando races em timers.",
                                    "Ignorar overhead de MPI_Reduce nas medições."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar experimentos variando número de processos e coletar dados",
                                  "subSteps": [
                                    "Definir escalonamento: executar com 1, 2, 4, 8, 16 processos (limitado por hardware).",
                                    "Realizar múltiplas runs (ex: 10 iterações) por configuração para calcular médias e desvios.",
                                    "Registrar tempos: T_total, T_comm, T_compute para cada np.",
                                    "Salvar dados em formato estruturado (CSV ou JSON).",
                                    "Verificar consistência dos dados (ex: T_total decrescente ou não)."
                                  ],
                                  "verification": "Arquivo de dados com tabelas completas de tempos médios, min/max e desvios para todos np testados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Script de automação (bash ou Python para mpirun loops)",
                                    "Planilha ou ferramenta CSV (Excel, Pandas)"
                                  ],
                                  "tips": [
                                    "Aqueça o sistema com runs iniciais descartados.",
                                    "Monitore uso de CPU/rede com ferramentas como top ou nvidia-smi."
                                  ],
                                  "learningObjective": "Coletar dados empíricos robustos para análise de escalabilidade.",
                                  "commonMistakes": [
                                    "Poucas runs, levando a variância alta.",
                                    "Não considerar limitações de hardware (oversubscription)."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular métricas e analisar decomposição de domínio",
                                  "subSteps": [
                                    "Calcular Speedup: S(p) = T(1) / T(p).",
                                    "Calcular Eficiência: E(p) = S(p) / p.",
                                    "Estimar Overhead de comunicação: (T_total - T_compute) / T_total * 100%.",
                                    "Analisar decomposição: verificar balanceamento de carga via T_compute por processo.",
                                    "Gerar gráficos (speedup, eficiência vs np) e interpretar bottlenecks em estudo de caso."
                                  ],
                                  "verification": "Relatório com fórmulas aplicadas, gráficos plotados e conclusões sobre desempenho (ex: lei de Amdahl).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python com Matplotlib/Seaborn ou Gnuplot",
                                    "Dados CSV coletados",
                                    "Referências: Lei de Gustafson/Amdahl"
                                  ],
                                  "tips": [
                                    "Use log-scale para np em gráficos.",
                                    "Compare T_compute ideal vs real para detectar imbalance."
                                  ],
                                  "learningObjective": "Interpretar métricas de desempenho e otimizar decomposição de domínio.",
                                  "commonMistakes": [
                                    "Erro em baseline T(1).",
                                    "Ignorar overhead em p=1."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes distribuída (NxN), use MPI_Bcast para matriz A, MPI_Scatter para linhas de B, compute local C[i] = A * B[i], e MPI_Reduce para somar resultados. Meça T_bcast, T_scatter, T_compute e T_reduce, calculando speedup ao variar np de 1 a 16.",
                              "finalVerifications": [
                                "Medições precisas com MPI_Wtime() em seções críticas.",
                                "Cálculo correto de speedup, eficiência e overhead (>90% acurácia).",
                                "Identificação de bottlenecks de comunicação vs computação.",
                                "Análise qualitativa de decomposição de domínio (balanceamento).",
                                "Gráficos de escalabilidade com interpretação alinhada à lei de Amdahl.",
                                "Relatório reproduzível com dados e código."
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições e cálculos matemáticos (erro <5%).",
                                "Cobertura completa de métricas (speedup, eficiência, overhead).",
                                "Qualidade visual e interpretativa dos gráficos.",
                                "Profundidade na análise de decomposição e bottlenecks.",
                                "Clareza e estrutura do relatório final.",
                                "Reprodutibilidade dos experimentos."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo de médias, desvios e funções de escalabilidade.",
                                "Algoritmos: Decomposição de problemas e análise de complexidade.",
                                "Sistemas Operacionais: Comunicação inter-processo e scheduling.",
                                "Engenharia de Software: Profiling, benchmarking e otimização.",
                                "Estatística: Análise de variância em experimentos empíricos."
                              ],
                              "realWorldApplication": "Otimizar simulações científicas em supercomputadores (ex: modelagem climática no ICMPD ou processamento de genomas em clusters HPC), reduzindo tempo de horas para minutos via identificação de overheads de comunicação."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.2.1.1",
                              "10.1.4.2.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.3",
                    "name": "CUDA e OpenCL para Plataformas Heterogêneas",
                    "description": "Linguagens para programação de GPUs e aceleradores, lidando com arquiteturas heterogêneas.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.3.1",
                        "name": "CUDA para Programação de GPUs",
                        "description": "CUDA é uma plataforma de computação paralela e modelo de programação desenvolvido pela NVIDIA para programação de GPUs, permitindo o desenvolvimento de aplicações que utilizam arquiteturas heterogêneas com foco em memória compartilhada e decomposição de domínio.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.3.1.1",
                            "name": "Entender a arquitetura e taxonomia de Flynn em CUDA",
                            "description": "Identificar como CUDA se enquadra na taxonomia de Flynn (SIMD/MIMD) e modelos de memória hierárquicos (global, compartilhada, registradores), relacionando com plataformas heterogêneas CPU-GPU.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude os quatro quadrantes da taxonomia de Flynn: SISD, SIMD, MISD e MIMD, com definições e exemplos clássicos.",
                                    "Identifique características principais de cada classe, focando em instruções e dados paralelos.",
                                    "Compare SIMD (vetorizado) com MIMD (múltiplos fluxos independentes).",
                                    "Anote exemplos de hardware: CPU como SISD/MIMD, GPUs como SIMD em larga escala.",
                                    "Crie um diagrama simples mapeando Flynn para arquiteturas modernas."
                                  ],
                                  "verification": "Crie um mapa mental ou tabela resumindo a taxonomia com pelo menos um exemplo por classe.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação NVIDIA CUDA: seção de arquitetura",
                                    "Artigo original de Flynn (1966)",
                                    "Vídeo introdutório sobre taxonomia de Flynn no YouTube"
                                  ],
                                  "tips": "Use analogias como SIMD como uma orquestra tocando a mesma nota vs. MIMD como solistas independentes.",
                                  "learningObjective": "Compreender os fundamentos da taxonomia de Flynn e suas categorias principais.",
                                  "commonMistakes": [
                                    "Confundir SIMD com SISD",
                                    "Ignorar que MIMD pode conter SIMD internamente",
                                    "Não relacionar com paralelismo de dados vs. instruções"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a Arquitetura CUDA e Mapeamento para Flynn",
                                  "subSteps": [
                                    "Analise a hierarquia CUDA: grids, blocks, warps, threads.",
                                    "Identifique CUDA como MIMD no nível de blocks/threads, mas SIMD dentro de warps (32 threads lockstep).",
                                    "Estude o SIMT (Single Instruction Multiple Threads) como extensão SIMD.",
                                    "Compare com CPU: CPU MIMD fino, GPU MIMD grosso com SIMD warp-level.",
                                    "Desenhe um diagrama de um grid CUDA mostrando mapeamento Flynn.",
                                    "Leia docs NVIDIA sobre execução de warps e divergência."
                                  ],
                                  "verification": "Explique em 200 palavras como CUDA é classificado em Flynn, citando warps e SIMT.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "NVIDIA CUDA Programming Guide (capítulo 3: Arquitetura)",
                                    "Diagramaas de arquitetura Kepler/Ampere",
                                    "Ferramenta Nsight para visualização"
                                  ],
                                  "tips": "Lembre-se: warps executam SIMD; threads independentes são MIMD em nível superior.",
                                  "learningObjective": "Mapear precisamente a arquitetura CUDA na taxonomia de Flynn.",
                                  "commonMistakes": [
                                    "Classificar CUDA puramente como SIMD",
                                    "Ignorar divergência de warps",
                                    "Confundir threads com instruções únicas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Entender Modelos de Memória Hierárquicos em CUDA",
                                  "subSteps": [
                                    "Descreva a hierarquia: registradores (rápidos, por thread), memória compartilhada (por block), global (por grid), constante e textura.",
                                    "Compare latências e bandwidths: registradores < shared << global.",
                                    "Relacione com Flynn: memória compartilhada habilita comunicação MIMD eficiente.",
                                    "Simule acesso: thread acessa registrador, block usa shared para redução.",
                                    "Identifique coalescing de memória global para performance SIMD.",
                                    "Crie tabela de hierarquia com tamanhos, escopos e usos."
                                  ],
                                  "verification": "Monte uma tabela comparativa de memórias CUDA com latências aproximadas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "CUDA Programming Guide (capítulo 3.2: Memória)",
                                    "Blog NVIDIA sobre otimização de memória",
                                    "Exemplos de código kernel com shared memory"
                                  ],
                                  "tips": "Pense em pirâmide: base lenta/global, topo rápido/registradores.",
                                  "learningObjective": "Dominar a hierarquia de memória CUDA e seu impacto na classificação Flynn.",
                                  "commonMistakes": [
                                    "Confundir shared com global",
                                    "Subestimar overhead de bank conflicts",
                                    "Ignorar limite de registradores por thread"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar CUDA com Plataformas Heterogêneas CPU-GPU",
                                  "subSteps": [
                                    "Descreva heterogeneidade: CPU MIMD sequencial, GPU MIMD/SIMD massivo.",
                                    "Discuta offloading: CPU orquestra, GPU computa kernels paralelos.",
                                    "Analise memória unificada (Unified Memory) em Pascal+ para abstrair hierarquia.",
                                    "Exemplo: CPU aloca dados, GPU processa em paralelo (Flynn MIMD heterogêneo).",
                                    "Crie fluxograma de execução CPU-GPU com mapeamento Flynn.",
                                    "Estude casos de estudo como matrix multiply heterogêneo."
                                  ],
                                  "verification": "Desenhe fluxograma de um programa CPU-GPU simples anotado com classificações Flynn.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "CUDA Guide: Heterogeneous Programming",
                                    "Exemplos GitHub CUDA samples",
                                    "Documentação Unified Memory"
                                  ],
                                  "tips": "Heterogeneidade explora forças: CPU controle, GPU throughput.",
                                  "learningObjective": "Integrar CUDA em contextos heterogêneos CPU-GPU via taxonomia Flynn.",
                                  "commonMistakes": [
                                    "Tratar CPU-GPU como monolítico",
                                    "Ignorar custos de transferência H2D/D2H",
                                    "Não considerar pinning de memória"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um kernel de multiplicação de matrizes em CUDA, warps executam SIMD para multiplicações vetorizadas (shared memory para tiles), enquanto blocks MIMD independentes computam sub-matrizes; CPU orquestra alocação global e chama kernel, ilustrando heterogeneidade Flynn.",
                              "finalVerifications": [
                                "Explique verbalmente ou por escrito como warps CUDA exemplificam SIMD dentro de MIMD.",
                                "Desenhe hierarquia de memória e classifique acessos por tipo Flynn.",
                                "Identifique 3 diferenças Flynn entre CPU e GPU em código simples.",
                                "Simule divergência de warp e seu impacto SIMD.",
                                "Compare memória shared vs. global em contexto heterogêneo."
                              ],
                              "assessmentCriteria": [
                                "Precisão no mapeamento CUDA para SIMD/MIMD (90% correto).",
                                "Compreensão detalhada de hierarquia memória com latências relativas.",
                                "Capacidade de relacionar conceitos a exemplos práticos heterogêneos.",
                                "Identificação correta de divergência e bank conflicts.",
                                "Uso de terminologia precisa (SIMT, warp, coalescing).",
                                "Diagramaas claros e fluxogramas lógicos."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Pipelines e caches semelhantes a registradores/shared.",
                                "Programação Paralela: MPI/OpenMP vs. CUDA em taxonomia Flynn.",
                                "Sistemas Operacionais: Gerenciamento de memória unificada como virtual memory.",
                                "Inteligência Artificial: Aceleração GPU em DL via SIMD warps.",
                                "Engenharia de Software: Otimização performance em heterogeneidade."
                              ],
                              "realWorldApplication": "Em machine learning, frameworks como TensorFlow/PyTorch usam CUDA para treinar redes neurais, explorando SIMD warps para convoluções e MIMD blocks para batches, otimizando memória hierárquica para acelerar inferência em produção (ex: recomendadores Netflix)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.1.2",
                            "name": "Gerenciar memória e threads em CUDA",
                            "description": "Implementar alocação de memória (cudaMalloc, cudaMemcpy), configuração de grids e blocos de threads, e sincronização para evitar condições de corrida e exclusão mútua em kernels CUDA.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Alocação e Transferência de Memória em CUDA",
                                  "subSteps": [
                                    "Inclua o cabeçalho <cuda_runtime.h> no código fonte.",
                                    "Declare ponteiros para memória host (CPU) e device (GPU).",
                                    "Use cudaMalloc para alocar memória no device.",
                                    "Use cudaMemcpy para copiar dados do host para o device (cudaMemcpyHostToDevice).",
                                    "Verifique erros com cudaGetLastError após cada chamada CUDA."
                                  ],
                                  "verification": "Compilar e executar o código sem erros de alocação ou cópia; confirme com cudaGetLastError retornando cudaSuccess.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Compilador NVCC",
                                    "GPU NVIDIA compatível",
                                    "Documentação CUDA Toolkit"
                                  ],
                                  "tips": "Sempre libere memória com cudaFree no final para evitar vazamentos.",
                                  "learningObjective": "Dominar alocação dinâmica de memória GPU e transferência eficiente de dados.",
                                  "commonMistakes": [
                                    "Esquecer de verificar erros CUDA",
                                    "Usar cudaMemcpy na direção errada",
                                    "Não inicializar memória host"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configuração de Grids e Blocos de Threads",
                                  "subSteps": [
                                    "Defina dimensões de bloco (ex: dim3 block(256)) com múltiplos de 32 para eficiência.",
                                    "Calcule dimensões de grid (ex: dim3 grid((N + block.x - 1) / block.x)) para cobrir todos os elementos.",
                                    "Declare kernel com <<<grid, block>>> antes da chamada.",
                                    "Passe argumentos do kernel usando sintaxe correta.",
                                    "Teste com tamanhos pequenos de array para validar configuração."
                                  ],
                                  "verification": "Execute kernel e verifique se todos os elementos são processados sem segmentação fault.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Exemplos de código CUDA básicos",
                                    "Nsight Compute para profiling",
                                    "Calculadora para dims de grid"
                                  ],
                                  "tips": "Use occupancy calculator da NVIDIA para otimizar tamanhos de bloco.",
                                  "learningObjective": "Configurar hierarquia de threads CUDA para paralelismo ótimo.",
                                  "commonMistakes": [
                                    "Bloco maior que 1024 threads",
                                    "Grid mal calculado causando underflow",
                                    "Ignorar alinhamento warp"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementação de Sincronização em Kernels CUDA",
                                  "subSteps": [
                                    "Identifique pontos potenciais de race condition no kernel (ex: escrita compartilhada).",
                                    "Use __syncthreads() para barreiras intra-bloco.",
                                    "Implemente atomicAdd ou atomicCAS para operações atômicas em memória global.",
                                    "Para exclusão mútua, use variáveis locais de thread com __threadfence() se necessário.",
                                    "Copie resultados de volta com cudaMemcpyDeviceToHost e valide."
                                  ],
                                  "verification": "Execute múltiplas vezes com dados randômicos; resultados consistentes sem corrupção.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Código de kernel vetor soma com race conditions intencional",
                                    "CUDA Debugger (cuda-gdb)"
                                  ],
                                  "tips": "Prefira atômicos a mutex para performance; teste com cuda-memcheck para detectar races.",
                                  "learningObjective": "Aplicar primitivas de sincronização para programação thread-safe em CUDA.",
                                  "commonMistakes": [
                                    "__syncthreads() em blocos independentes",
                                    "Uso incorreto de atômicos sem alinhamento",
                                    "Falta de barreira após redução"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integração Completa e Otimização",
                                  "subSteps": [
                                    "Combine alocação, configuração de threads e sincronização em um programa completo.",
                                    "Adicione gerenciamento de erros abrangente com macros CUDA.",
                                    "Profile com nvprof ou Nsight para medir occupancy e tempo de kernel.",
                                    "Otimize transferências de memória coalescindo acessos.",
                                    "Libere todos os recursos e finalize com cudaDeviceReset."
                                  ],
                                  "verification": "Programa executa corretamente em dataset grande; performance mensurável.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "nvprof ou Nsight Systems",
                                    "Datasets de teste (arrays grandes)"
                                  ],
                                  "tips": "Minimize transferências H2D/D2H usando streams para overlap.",
                                  "learningObjective": "Construir e otimizar programa CUDA completo com gerenciamento seguro de memória e threads.",
                                  "commonMistakes": [
                                    "Não coalescer acessos de memória",
                                    "Vazamentos de memória GPU",
                                    "Sobrecarga de lançamento de kernel"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um kernel CUDA para soma de dois vetores grandes (N=1M elementos) usando cudaMalloc para alocar vetores no device, configure grid(1024,1) e block(256,1), use atomicAdd para soma thread-safe, e cudaMemcpy para resultados de volta à CPU. Verifique soma total contra versão serial.",
                              "finalVerifications": [
                                "cudaMalloc e cudaMemcpy executam sem erros (cudaSuccess).",
                                "Kernel lança sem invalid config args.",
                                "Nenhum race condition detectado por cuda-memcheck.",
                                "Resultados coincidem com implementação sequencial.",
                                "Memória GPU liberada (nvidia-smi mostra uso zero).",
                                "Tempo de execução < 10ms para N=1M."
                              ],
                              "assessmentCriteria": [
                                "Precisão na alocação e transferência de memória (sem leaks ou erros).",
                                "Eficiência na configuração de grid/block (occupancy > 50%).",
                                "Correta aplicação de sincronização (resultados consistentes).",
                                "Gerenciamento de erros robusto em todas chamadas CUDA.",
                                "Otimização básica (coalescing e minimal transfers).",
                                "Código limpo, comentado e modular."
                              ],
                              "crossCurricularConnections": [
                                "Programação Paralela Geral (OpenMP, MPI para comparação).",
                                "Sistemas Operacionais (conceitos de threads e mutex).",
                                "Estruturas de Dados (arrays e reduções paralelas).",
                                "Otimização de Performance (profiling e análise de bottlenecks)."
                              ],
                              "realWorldApplication": "Em machine learning, gerenciar memória e threads CUDA acelera treinamento de redes neurais no TensorFlow/PyTorch; em simulações científicas, permite processar dados geofísicos em GPUs para previsão climática em tempo real."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.1.3",
                            "name": "Lançar e otimizar kernels CUDA",
                            "description": "Escrever e lançar kernels CUDA para computação paralela, aplicando decomposição de domínio e avaliando desempenho com ferramentas como NVIDIA Nsight, considerando overhead de transferência de dados em arquiteturas heterogêneas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Desenvolver um kernel CUDA básico",
                                  "subSteps": [
                                    "Inclua os headers necessários: <cuda_runtime.h> e <device_launch_parameters.h>.",
                                    "Defina uma função __global__ kernel, como vectorAdd(float *A, float *B, float *C, int N), com loop paralelo usando threadIdx.x e blockIdx.x.",
                                    "Implemente a lógica de indexação: int i = blockIdx.x * blockDim.x + threadIdx.x; if (i < N) C[i] = A[i] + B[i];.",
                                    "Compile o código com nvcc para gerar o executável CUDA.",
                                    "Teste compilação sem erros de sintaxe CUDA."
                                  ],
                                  "verification": "Compilação bem-sucedida sem warnings de kernel; inspecione o código assembly PTX gerado com nvdisasm.",
                                  "estimatedTime": "1-2 hours",
                                  "materials": [
                                    "CUDA Toolkit instalado",
                                    "Editor de código (VS Code com CUDA extension)",
                                    "NVIDIA GPU acessível"
                                  ],
                                  "tips": "Use blocos de tamanho múltiplo de 32 (warp size) para eficiência inicial.",
                                  "learningObjective": "Compreender sintaxe e execução paralela básica em kernels CUDA.",
                                  "commonMistakes": [
                                    "Ignorar verificação de bounds (i < N)",
                                    "Esquecer __global__ qualifier",
                                    "Não sincronizar threads implicitamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar memória e preparar dados no host",
                                  "subSteps": [
                                    "Declare arrays no host: float h_A[N], h_B[N], h_C[N]; inicialize com valores teste.",
                                    "Alocar memória no device: cudaMalloc(&d_A, N*sizeof(float)); similar para d_B e d_C.",
                                    "Copie dados do host para device: cudaMemcpy(d_A, h_A, N*sizeof(float), cudaMemcpyHostToDevice);",
                                    "Verifique erros de alocação com cudaGetLastError().",
                                    "Prepare variáveis de lançamento: dim3 blockSize(256,1,1); dim3 gridSize((N + blockSize.x -1)/blockSize.x);"
                                  ],
                                  "verification": "Memória alocada sem erros (cudaGetLastError() == cudaSuccess); tamanhos corretos com cudaMemGetInfo().",
                                  "estimatedTime": "45 minutes - 1 hour",
                                  "materials": [
                                    "CUDA samples de referência",
                                    "Documentação CUDA Memory Management"
                                  ],
                                  "tips": "Use cudaMallocManaged() para simplicidade inicial em arquiteturas modernas.",
                                  "learningObjective": "Gerenciar memória unificada em arquiteturas heterogêneas.",
                                  "commonMistakes": [
                                    "Não verificar erros de cudaMalloc",
                                    "Tamanhos incorretos em cudaMemcpy",
                                    "Esquecer alinhamento de memória"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Lançar o kernel e recuperar resultados",
                                  "subSteps": [
                                    "Chame o kernel: vectorAdd<<<gridSize, blockSize>>>(d_A, d_B, d_C, N);",
                                    "Sincronize: cudaDeviceSynchronize(); verifique erros com cudaGetLastError().",
                                    "Copie resultados de volta: cudaMemcpy(h_C, d_C, N*sizeof(float), cudaMemcpyDeviceToHost);",
                                    "Libere memória: cudaFree(d_A); etc.",
                                    "Valide resultados: compare h_C com soma esperada usando loop ou thrust::equal."
                                  ],
                                  "verification": "Resultados h_C coincidem com computação serial; tempo de execução < 1ms para N=1M.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Código de validação serial",
                                    "CUDA debugger (cuda-gdb)"
                                  ],
                                  "tips": "Sempre sincronize após lançamento para capturar erros de kernel.",
                                  "learningObjective": "Executar lançamento de kernel e gerenciar fluxos de dados.",
                                  "commonMistakes": [
                                    "Lançamento assíncrono sem sync",
                                    "Ordem errada de memcpy",
                                    "Não liberar memória (memory leaks)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar parâmetros de lançamento e desempenho",
                                  "subSteps": [
                                    "Ajuste blockSize (128-1024) e gridSize para maximizar occupancy; use cudaOccupancyMaxActiveBlocksPerMultiprocessor().",
                                    "Minimize overhead de transferência: use pinned memory (cudaMallocHost()) e streams para overlap.",
                                    "Implemente coalescing de memória: acesse elementos consecutivos em memória global.",
                                    "Profile com nvprof ou Nsight: colete métricas de occupancy, memory throughput.",
                                    "Itere otimizações: reduza global memory accesses com shared memory."
                                  ],
                                  "verification": "Occupancy > 50%; throughput > 100 GB/s; speedup > 10x vs CPU.",
                                  "estimatedTime": "2-3 hours",
                                  "materials": [
                                    "NVIDIA Nsight Compute/Systems",
                                    "CUDA Occupancy Calculator online"
                                  ],
                                  "tips": "Comece com blockSize=256; evite gridSize muito grande (>65535).",
                                  "learningObjective": "Aplicar decomposição de domínio e otimização para arquiteturas GPU.",
                                  "commonMistakes": [
                                    "Block size não múltiplo de warp",
                                    "Ignorar bank conflicts em shared mem",
                                    "Sobrecarga de launch sem streams"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar overhead e otimizações finais com Nsight",
                                  "subSteps": [
                                    "Instale e configure NVIDIA Nsight Systems/Compute.",
                                    "Profile sessão completa: capture kernel launch, memcpy, occupancy, roofline.",
                                    "Analise bottlenecks: identifique tempo em memcpy vs kernel.",
                                    "Otimize transferências: use cudaMemcpyAsync com streams; unifique memória onde possível.",
                                    "Compare métricas pré/pós-otimização; documente speedup e overhead reduzido."
                                  ],
                                  "verification": "Relatório Nsight mostra kernel >80% do tempo total; overhead memcpy <20%.",
                                  "estimatedTime": "1-2 hours",
                                  "materials": [
                                    "Nsight Systems/Compute",
                                    "GPU com driver >= 535"
                                  ],
                                  "tips": "Use --set full para profiling detalhado; foque em SM throughput.",
                                  "learningObjective": "Usar ferramentas de profiling para otimização em heterogêneo.",
                                  "commonMistakes": [
                                    "Profiling sem baseline",
                                    "Ignorar CPU-GPU transfer latency",
                                    "Não considerar múltiplas GPUs"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um kernel para multiplicação de matrizes densas (GEMM) de 1024x1024: otimize para C=AB, usando tiled shared memory, launch com occupancy >70%, profile overhead de H2D/D2H <10% do tempo total, speedup >50x vs CPU serial.",
                              "finalVerifications": [
                                "Kernel executa corretamente para inputs variados (N=1K a 1M).",
                                "Nsight report: occupancy >=60%, memory coalescing eficiente.",
                                "Overhead de transferência <15% do tempo total.",
                                "Speedup >=20x vs implementação serial CPU.",
                                "Sem memory leaks (valscan ou cuda-memcheck).",
                                "Resultados numéricos precisos (erro relativo <1e-6)."
                              ],
                              "assessmentCriteria": [
                                "Correção funcional: resultados idênticos à referência.",
                                "Eficiência de lançamento: grid/block otimizados via occupancy calc.",
                                "Desempenho: throughput GPU >80% peak; overhead minimizado.",
                                "Qualidade de código: error handling completo, comentários.",
                                "Análise de profiling: relatório Nsight com insights acionáveis.",
                                "Escalabilidade: bom desempenho para tamanhos variados."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: compreensão de SIMT e multiprocessadores.",
                                "Matemática Computacional: decomposição de domínio em álgebra linear.",
                                "Otimização Numérica: análise de complexidade e roofline model.",
                                "Engenharia de Software: profiling e debugging em sistemas paralelos.",
                                "Inteligência Artificial: aceleração de workloads de ML em GPUs."
                              ],
                              "realWorldApplication": "Desenvolvimento de frameworks de deep learning como TensorFlow/PyTorch, onde kernels CUDA otimizados aceleram treinamento de modelos em GPUs, reduzindo tempo de epochs de dias para horas em data centers heterogêneos."
                            },
                            "estimatedTime": "4 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.3.2",
                        "name": "OpenCL para Plataformas Heterogêneas",
                        "description": "OpenCL é um padrão aberto para programação paralela em dispositivos heterogêneos (GPUs, CPUs, aceleradores), suportando modelos de memória distribuída e compartilhada com abstrações portáteis.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.3.2.1",
                            "name": "Configurar o modelo de plataforma OpenCL",
                            "description": "Inicializar contexto, fila de comandos e dispositivos em OpenCL, identificando plataformas heterogêneas e relacionando com taxonomia de Flynn para seleção de dispositivos SIMD/MIMD.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento OpenCL",
                                  "subSteps": [
                                    "Instale os drivers OpenCL apropriados para CPU (Intel/AMD) e GPU (NVIDIA/AMD) no seu sistema operacional.",
                                    "Baixe e instale o SDK OpenCL (ex: POCL para CPU, CUDA Toolkit para NVIDIA GPUs).",
                                    "Configure o compilador C/C++ (GCC ou MSVC) com headers OpenCL incluídos (ex: -lOpenCL).",
                                    "Teste a instalação compilando um programa de hello world OpenCL simples.",
                                    "Verifique variáveis de ambiente como LIBRARY_PATH e LD_LIBRARY_PATH."
                                  ],
                                  "verification": "Compilar e executar um programa de teste OpenCL sem erros de linking ou runtime.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Drivers OpenCL",
                                    "SDK OpenCL (POCL/CUDA/ROCm)",
                                    "Compilador GCC/Clang",
                                    "Editor de código (VS Code)"
                                  ],
                                  "tips": [
                                    "Use gerenciadores de pacotes como apt (Linux) ou vcpkg (Windows) para instalação fácil.",
                                    "Teste em máquina virtual se hardware GPU não disponível."
                                  ],
                                  "learningObjective": "Preparar o ambiente para desenvolvimento OpenCL sem falhas de configuração.",
                                  "commonMistakes": [
                                    "Esquecer de instalar drivers GPU.",
                                    "Paths incorretos para bibliotecas OpenCL.",
                                    "Misturar SDKs incompatíveis (ex: CUDA com AMD)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e enumerar plataformas e dispositivos OpenCL",
                                  "subSteps": [
                                    "Inclua <CL/cl.h> e chame clGetPlatformIDs para obter número de plataformas.",
                                    "Para cada plataforma, use clGetPlatformInfo para nome e versão.",
                                    "Para cada plataforma, chame clGetDeviceIDs com CL_DEVICE_TYPE_ALL para listar dispositivos.",
                                    "Use clGetDeviceInfo para propriedades como CL_DEVICE_TYPE (CPU/GPU), max compute units.",
                                    "Imprima lista de plataformas e dispositivos em console para verificação."
                                  ],
                                  "verification": "Programa lista pelo menos uma plataforma e dispositivos sem erros CL_PLATFORM_NOT_FOUND_KHR.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código fonte C com OpenCL headers",
                                    "Compilador com -lOpenCL"
                                  ],
                                  "tips": [
                                    "Filtre por CL_DEVICE_TYPE_GPU para focar em aceleração.",
                                    "Use clGetPlatformIDs(0, NULL, &num_platforms) primeiro para sizing."
                                  ],
                                  "learningObjective": "Detectar hardware heterogêneo disponível via APIs OpenCL.",
                                  "commonMistakes": [
                                    "Não liberar memória alocada para IDs.",
                                    "Ignorar clReleaseContext cedo.",
                                    "Não checar retornos de API (cl_int err)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Inicializar o contexto OpenCL",
                                  "subSteps": [
                                    "Selecione dispositivos do step anterior (ex: primeiro GPU).",
                                    "Crie array de cl_device_id com dispositivos selecionados.",
                                    "Chame clCreateContext(NULL, num_devices, devices, NULL, NULL, &err) para contexto.",
                                    "Verifique err == CL_SUCCESS e retenha com clRetainContext se necessário.",
                                    "Imprima propriedades do contexto com clGetContextInfo."
                                  ],
                                  "verification": "Contexto criado (context != NULL) e clReleaseContext não falha.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código do step 2 estendido",
                                    "Documentação OpenCL 1.2/2.0"
                                  ],
                                  "tips": [
                                    "Use propriedades como CL_CONTEXT_PLATFORM para associar plataforma específica.",
                                    "Sempre cheque err após cada chamada cl*."
                                  ],
                                  "learningObjective": "Criar contexto que gerencia dispositivos heterogêneos.",
                                  "commonMistakes": [
                                    "Passar devices NULL.",
                                    "Não especificar callback de erro no clCreateContext.",
                                    "Contexto criado sem dispositivos válidos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Criar fila de comandos (command queue)",
                                  "subSteps": [
                                    "Para um dispositivo selecionado, chame clCreateCommandQueue(context, device, 0, &err).",
                                    "Configure propriedades como CL_QUEUE_PROFILING_ENABLE para profiling.",
                                    "Verifique queue != NULL e err == CL_SUCCESS.",
                                    "Teste fila enviando um evento simples (clEnqueueMarker).",
                                    "Libere fila com clReleaseCommandQueue no final."
                                  ],
                                  "verification": "Fila criada e clFinish(queue) retorna sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Header CL/cl.h"
                                  ],
                                  "tips": [
                                    "Use CL_QUEUE_OUT_OF_ORDER_EXEC_MODE_ENABLE para execução assíncrona avançada.",
                                    "Monitore eventos para debug."
                                  ],
                                  "learningObjective": "Estabelecer canal para submissão de comandos aos dispositivos.",
                                  "commonMistakes": [
                                    "Queue criada com contexto inválido.",
                                    "Esquecer clFinish antes de liberar.",
                                    "Propriedades inválidas causando CL_INVALID_QUEUE_PROPERTIES."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Relacionar dispositivos com taxonomia de Flynn e validar configuração",
                                  "subSteps": [
                                    "Use clGetDeviceInfo para CL_DEVICE_EXECUTION_CAPABILITIES e tipo.",
                                    "Classifique: GPUs como SIMD (Single Instruction Multiple Data), CPUs como MIMD (Multiple Instruction Multiple Data).",
                                    "Selecione dispositivos baseado em classificação (ex: GPU para SIMD workloads).",
                                    "Execute teste: buffer simples + kernel echo via queue.",
                                    "Valide saída e limpe todos recursos (clRelease*)."
                                  ],
                                  "verification": "Programa classifica corretamente dispositivos e executa kernel sem crashes.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Kernel OpenCL simples",
                                    "Livro sobre taxonomia Flynn (opcional)"
                                  ],
                                  "tips": [
                                    "GPUs: alta paralelismo SIMD; CPUs: flexibilidade MIMD.",
                                    "Teste workloads diferentes por classificação."
                                  ],
                                  "learningObjective": "Integrar conceitos teóricos de arquitetura com configuração prática OpenCL.",
                                  "commonMistakes": [
                                    "Confundir SIMD/MIMD.",
                                    "Selecionar GPU sem suporte OpenCL.",
                                    "Kernel não compilado corretamente."
                                  ]
                                }
                              ],
                              "practicalExample": "Escreva um programa C que lista plataformas/dispositivos, cria contexto e queue para primeiro GPU (SIMD), compila kernel 'kernel void test(global float* data) { data[get_global_id(0)] *= 2; }', aloca buffer de 1024 floats, enfileira NDRange kernel, lê de volta e verifica multiplicação por 2. Imprima classificação Flynn.",
                              "finalVerifications": [
                                "Todas APIs retornam CL_SUCCESS.",
                                "Lista completa de plataformas/dispositivos impressa.",
                                "Contexto e queue criados e liberados sem leaks (use valgrind).",
                                "Kernel executa corretamente em dispositivo selecionado.",
                                "Classificação Flynn correta (GPU=SIMD, CPU=MIMD).",
                                "Programa compila em diferentes plataformas (CPU/GPU)."
                              ],
                              "assessmentCriteria": [
                                "Código modular com funções separadas por step.",
                                "Tratamento completo de erros em todas chamadas cl*.",
                                "Liberação correta de recursos (contexto, queue, devices).",
                                "Classificação precisa via taxonomia Flynn com justificativa.",
                                "Execução bem-sucedida em hardware heterogêneo.",
                                "Comentários explicando escolhas de dispositivos."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Taxonomia de Flynn (SIMD/MIMD/SISD/MISD).",
                                "Programação em C: Ponteiros, alocação dinâmica, bibliotecas.",
                                "Sistemas Operacionais: Drivers de dispositivos e bibliotecas compartilhadas.",
                                "Computação Gráfica: GPUs como plataformas OpenCL.",
                                "Algoritmos Paralelos: Seleção de hardware para workloads."
                              ],
                              "realWorldApplication": "Configuração essencial para aplicações de alto desempenho como processamento de imagens em tempo real (Photoshop filters), simulações físicas em jogos (Unity/Unreal com OpenCL), machine learning (treinamento em GPUs heterogêneas) e computação científica (modelagem climática em clusters HPC)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.2.2",
                            "name": "Gerenciar buffers e kernels em OpenCL",
                            "description": "Criar buffers de memória, compilar kernels de fontes e executá-los com argumentos, implementando troca de mensagens implícita e controle de exclusão mútua via barreiras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o Contexto, Plataforma e Dispositivo OpenCL",
                                  "subSteps": [
                                    "Obtenha a plataforma OpenCL usando clGetPlatformIDs.",
                                    "Selecione o dispositivo (GPU ou CPU) com clGetDeviceIDs.",
                                    "Crie o contexto com clCreateContext.",
                                    "Crie a fila de comandos (command queue) com clCreateCommandQueue."
                                  ],
                                  "verification": "Execute clGetPlatformInfo e clGetDeviceInfo para listar plataformas e dispositivos disponíveis; verifique se contexto e queue são válidos (não NULL).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Header OpenCL (CL/cl.h)",
                                    "Compilador C/C++ com suporte OpenCL (ex: clang)",
                                    "Dispositivo compatível (GPU NVIDIA/AMD ou CPU)"
                                  ],
                                  "tips": "Sempre armazene o código de erro de cada chamada cl* e verifique com clGetErrorInfo para depuração rápida.",
                                  "learningObjective": "Entender e implementar a inicialização básica do ambiente OpenCL para plataformas heterogêneas.",
                                  "commonMistakes": [
                                    "Não selecionar a plataforma correta (ex: ignorar múltiplas GPUs)",
                                    "Esquecer de liberar contexto ao final",
                                    "Usar dispositivo inválido sem verificação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Criar e Gerenciar Buffers de Memória",
                                  "subSteps": [
                                    "Defina tamanhos de buffers baseados em dados de entrada (ex: vetores de float).",
                                    "Crie buffers com clCreateBuffer, especificando flags como CL_MEM_READ_WRITE ou CL_MEM_COPY_HOST_PTR.",
                                    "Copie dados do host para o device usando clEnqueueWriteBuffer.",
                                    "Configure propriedades de memória compartilhada se aplicável (ex: CL_MEM_USE_HOST_PTR)."
                                  ],
                                  "verification": "Escreva dados no buffer e leia de volta com clEnqueueReadBuffer; compare valores para confirmar integridade.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Exemplo de dados de teste (arrays em C)",
                                    "Header OpenCL",
                                    "Ferramenta de depuração como gdb ou printf para erros"
                                  ],
                                  "tips": "Use CL_MEM_COPY_HOST_PTR para inicializar buffers com dados do host, evitando cópias extras.",
                                  "learningObjective": "Dominar alocação e transferência de memória entre host e device em OpenCL.",
                                  "commonMistakes": [
                                    "Alinhamento incorreto de dados levando a crashes",
                                    "Não sincronizar transfers antes de usar no kernel",
                                    "Buffer size menor que dados reais"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Compilar Kernels de Fontes e Criar Programas",
                                  "subSteps": [
                                    "Carregue o código fonte do kernel como string (ex: soma de vetores).",
                                    "Crie o programa com clCreateProgramWithSource.",
                                    "Compile o programa usando clBuildProgram, especificando opções como -cl-opt-disable.",
                                    "Crie kernels específicos com clCreateKernel do programa compilado."
                                  ],
                                  "verification": "Verifique status de build com clGetProgramBuildInfo; busque erros de compilação no log.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Arquivo .cl com código kernel",
                                    "Editor de texto para fontes",
                                    "Documentação OpenCL para opções de build"
                                  ],
                                  "tips": "Inclua '#pragma OPENCL EXTENSION cl_khr_fp64 : enable' para suporte a double se necessário.",
                                  "learningObjective": "Aprender a compilar e gerenciar kernels dinamicamente de fontes texto.",
                                  "commonMistakes": [
                                    "Erros de sintaxe no kernel não detectados (use logs)",
                                    "Não especificar dispositivos no build",
                                    "Kernel name incorreto em clCreateKernel"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar Kernels com Argumentos, Barreiras e Controle de Exclusão Mútua",
                                  "subSteps": [
                                    "Defina argumentos do kernel com clSetKernelArg (buffers, índices, etc.).",
                                    "Enfileire o kernel na queue com clEnqueueNDRangeKernel, definindo work-groups e sizes.",
                                    "Implemente barreiras com clEnqueueBarrier para sincronização implícita entre work-items.",
                                    "Use atomic operations ou local memory para troca de mensagens e exclusão mútua."
                                  ],
                                  "verification": "Execute o kernel e verifique resultados em buffers lidos; confirme sincronização sem race conditions.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Kernel fonte com barreiras e atomics",
                                    "Dados de teste para validação paralela",
                                    "Profiler OpenCL para medir performance"
                                  ],
                                  "tips": "Para exclusão mútua, prefira atomics como atomic_add em vez de busy-waiting em barreiras.",
                                  "learningObjective": "Implementar execução de kernels com gerenciamento de argumentos e sincronização via barreiras.",
                                  "commonMistakes": [
                                    "Work-group size incompatível com dispositivo",
                                    "Argumentos em ordem errada",
                                    "Barreiras sem escopo correto (global vs local)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sincronizar Execução, Ler Resultados e Limpeza de Recursos",
                                  "subSteps": [
                                    "Sincronize a queue com clFinish ou clEnqueueReadBuffer com eventos.",
                                    "Leia resultados dos buffers com clEnqueueReadBuffer.",
                                    "Libere recursos: clReleaseKernel, clReleaseProgram, clReleaseMemObject, clReleaseCommandQueue, clReleaseContext.",
                                    "Verifique vazamentos de memória com ferramentas como Valgrind."
                                  ],
                                  "verification": "Confirme que todos os valores de saída batem com expectativa; rode múltiplas vezes sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código completo do programa",
                                    "Validador de resultados (diff ou soma checksum)",
                                    "Documentação de release functions"
                                  ],
                                  "tips": "Sempre use eventos (cl_event) para sincronização assíncrona em aplicações reais.",
                                  "learningObjective": "Garantir conclusão correta e limpeza eficiente de sessões OpenCL.",
                                  "commonMistakes": [
                                    "Esquecer clFinish causando resultados inconsistentes",
                                    "Não liberar buffers levando a memory leaks",
                                    "Ler buffer antes de kernel completar"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um kernel OpenCL para soma paralela de dois vetores grandes (1M elementos), usando buffers para entrada/saída, barreiras para sincronizar work-groups e atomic_add para redução final sem race conditions. Copie vetores A e B para buffers, execute kernel em NDRange, leia resultado C e valide soma.",
                              "finalVerifications": [
                                "Programa compila e executa sem erros CL_*.",
                                "Resultados de buffers de saída coincidem com versão sequencial.",
                                "Tempo de execução escala com tamanho de work-group.",
                                "Nenhuma race condition detectada em execuções múltiplas.",
                                "Todos os recursos são liberados (verificado por logs ou profiler).",
                                "Kernel build log sem warnings/erros."
                              ],
                              "assessmentCriteria": [
                                "Correta alocação e transferência de buffers (sem overflows).",
                                "Compilação bem-sucedida de kernels com argumentos válidos.",
                                "Implementação funcional de barreiras e exclusão mútua.",
                                "Sincronização adequada com verificação de resultados.",
                                "Código limpo com tratamento de erros e limpeza.",
                                "Eficiência: performance próxima do ótimo para dispositivo."
                              ],
                              "crossCurricularConnections": [
                                "Programação Paralela Geral: Similaridades com CUDA (buffers vs unified memory).",
                                "Sistemas Operacionais: Conceitos de memória compartilhada e sincronização (semáforos vs barreiras).",
                                "Estruturas de Dados: Uso de buffers como arrays paralelos eficientes.",
                                "Otimização de Performance: Profiling e tuning de work-groups como em HPC.",
                                "Computação Heterogênea: Integração com APIs como SYCL ou oneAPI."
                              ],
                              "realWorldApplication": "Em processamento de imagens GPU-accelerated (ex: filtros em Photoshop-like apps), simulações científicas (ex: modelagem climática com buffers para grids), ou machine learning (ex: buffers para batches de dados em treinamento distribuído), onde gerenciamento eficiente de memória e kernels garante escalabilidade em clusters heterogêneos."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.2.3",
                            "name": "Otimizar execução em dispositivos heterogêneos",
                            "description": "Configurar NDRanges para decomposição de domínio, medir desempenho com profiling OpenCL e comparar com CUDA em cenários de nuvem e multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar NDRange para Decomposição de Domínio em OpenCL",
                                  "subSteps": [
                                    "Estude conceitos de decomposição de domínio e NDRange (global e local work sizes).",
                                    "Escreva um kernel OpenCL simples, como soma de vetores, identificando dimensões de trabalho.",
                                    "Configure clEnqueueNDRangeKernel com work sizes apropriados para CPU e GPU heterogêneas.",
                                    "Ajuste local work size para otimizar ocupação de wavefront/warp.",
                                    "Execute e valide distribuição de trabalho em múltiplos dispositivos."
                                  ],
                                  "verification": "Verifique logs de execução e distribuição de work-items via clGetKernelWorkGroupInfo e ferramentas de debug como clinfo.",
                                  "estimatedTime": "2 horas",
                                  "materials": "OpenCL SDK (Intel/AMD/NVIDIA), compilador C++, hardware heterogêneo (CPU+GPU), código-fonte de exemplo de kernel.",
                                  "tips": "Comece com work sizes múltiplos do tamanho do grupo de trabalho para evitar overhead de sincronização.",
                                  "learningObjective": "Dominar configuração de NDRange para balancear carga em plataformas heterogêneas.",
                                  "commonMistakes": "Ignorar alinhamento de work sizes com capacidades do dispositivo, levando a subutilização."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Profiling de Desempenho em OpenCL",
                                  "subSteps": [
                                    "Integre bibliotecas de profiling como clProfiler ou CodeXL/RenderDoc.",
                                    "Adicione chamadas clGetEventProfilingInfo para medir tempo de kernel e transferência de dados.",
                                    "Colete métricas: tempo de execução, ocupação de compute units, uso de memória global/local.",
                                    "Execute em cenários variados: CPU-only, GPU-only, heterogêneo.",
                                    "Gere relatórios com gráficos de timeline e bottlenecks identificados."
                                  ],
                                  "verification": "Confirme métricas coletadas mostrando tempos < threshold esperado (ex: <100ms para soma de 1M elementos).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Ferramentas de profiling OpenCL (CodeXL, NVIDIA Nsight), scripts Python para análise de dados.",
                                  "tips": "Use eventos OpenCL para profiling preciso, evitando clFinish desnecessário.",
                                  "learningObjective": "Adquirir habilidades para medir e identificar gargalos em aplicações OpenCL.",
                                  "commonMistakes": "Não sincronizar eventos corretamente, resultando em métricas imprecisas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Desenvolver e Configurar Versão Equivalente em CUDA",
                                  "subSteps": [
                                    "Porte o kernel OpenCL para CUDA, definindo grids e blocks análogos a NDRange.",
                                    "Configure execução em dispositivos CUDA (GPU) com cudaLaunchKernel ou <<<grid,block>>>.",
                                    "Implemente profiling CUDA com nvprof ou Nsight Compute para métricas comparáveis.",
                                    "Adapte para cenários multicores usando CUDA Unified Memory.",
                                    "Teste em ambiente de nuvem (ex: AWS EC2 com GPU)."
                                  ],
                                  "verification": "Valide resultados idênticos ao OpenCL e perfil gerado com métricas CUDA.",
                                  "estimatedTime": "2 horas",
                                  "materials": "CUDA Toolkit 11+, NVIDIA GPU, conta AWS/GCP para instâncias de nuvem.",
                                  "tips": "Use streams CUDA para sobreposição de computação e transferência em heterogêneos.",
                                  "learningObjective": "Comparar sintaxe e configuração de paralelismo entre OpenCL e CUDA.",
                                  "commonMistakes": "Não alinhar block sizes com SMs, causando baixa ocupação."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar Desempenhos e Otimizar em Cenários Heterogêneos",
                                  "subSteps": [
                                    "Colete dados de profiling de ambos (OpenCL vs CUDA) em multicores e nuvem.",
                                    "Calcule speedup, eficiência e overhead de comunicação.",
                                    "Identifique otimizações: ajuste NDRange/block sizes, pinning de memória.",
                                    "Crie relatório comparativo com tabelas e gráficos.",
                                    "Itere otimizações até speedup >1.5x em heterogêneo."
                                  ],
                                  "verification": "Relatório mostra comparação quantitativa com ganhos mensuráveis em pelo menos 2 cenários.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": "Planilhas Excel/Python Pandas para análise, instâncias de nuvem (GCP/AWS com CPU+GPU).",
                                  "tips": "Normalize benchmarks por flops para comparação justa entre arquiteturas.",
                                  "learningObjective": "Avaliar e otimizar performance cross-plataforma em ambientes reais.",
                                  "commonMistakes": "Comparar em hardware não equivalente, invalidando resultados."
                                }
                              ],
                              "practicalExample": "Otimizar um kernel de multiplicação de matrizes 1024x1024 em cluster heterogêneo (CPU Intel + GPU NVIDIA): configure NDRange com 1024x1024 global e 16x16 local em OpenCL, profile tempo de 150ms na GPU vs 500ms CPU; porte para CUDA com <<<64,256>>> alcançando 120ms; compare em AWS EC2 g4dn.xlarge mostrando OpenCL 10% mais flexível em multi-dispositivo.",
                              "finalVerifications": [
                                "NDRange configurado com work sizes otimizados para >80% ocupação.",
                                "Relatórios de profiling OpenCL e CUDA gerados com métricas detalhadas.",
                                "Resultados numéricos idênticos entre implementações.",
                                "Comparação mostra speedup relativo >1.2x em pelo menos um cenário.",
                                "Otimização aplicada reduz tempo total em 20%.",
                                "Execução bem-sucedida em nuvem e multicores sem crashes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na configuração de NDRange/block sizes (alinhamento com hardware).",
                                "Qualidade das métricas de profiling (cobertura de kernel/memória/comunicação).",
                                "Correção da porte OpenCL->CUDA (resultados bit-iguais).",
                                "Análise comparativa quantitativa (speedup, eficiência calculados).",
                                "Identificação e aplicação de pelo menos 2 otimizações específicas.",
                                "Relatório claro com visualizações e conclusões acionáveis."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Decomposição de domínio e análise de complexidade O(n).",
                                "Sistemas Operacionais: Gerenciamento de memória unificada e scheduling em heterogêneos.",
                                "Redes/Computação em Nuvem: Deploy em AWS/GCP com balanceamento de carga.",
                                "Engenharia de Software: Profiling, benchmarking e refatoração de código paralelo."
                              ],
                              "realWorldApplication": "Em data centers de IA (ex: treinamento de modelos em clusters CPU+GPU no Google Cloud), otimizando workloads como convoluções em visão computacional para reduzir custos de computação em 30% via escolha dinâmica OpenCL/CUDA."
                            },
                            "estimatedTime": "4 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.3.3",
                        "name": "Aplicações e Avaliação em Plataformas Heterogêneas",
                        "description": "Integração de CUDA e OpenCL em arquiteturas heterogêneas, com estudos de caso, avaliação de desempenho e considerações para memória distribuída/compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.3.3.1",
                            "name": "Implementar estudos de caso com CUDA e OpenCL",
                            "description": "Desenvolver aplicações paralelas como multiplicação de matrizes ou simulações físicas usando CUDA/OpenCL, aplicando decomposição de domínio em GPUs heterogêneas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambiente de Desenvolvimento para CUDA e OpenCL",
                                  "subSteps": [
                                    "Instalar drivers NVIDIA CUDA Toolkit e verificar compatibilidade com GPUs heterogêneas.",
                                    "Configurar OpenCL SDK (como POCL ou vendor-specific) e testar detecção de dispositivos.",
                                    "Criar um projeto de teste com compiladores nvcc para CUDA e cl para OpenCL.",
                                    "Verificar suporte a múltiplas GPUs via cudaGetDeviceCount() e clGetDeviceIDs().",
                                    "Configurar IDE (VS Code ou CLion) com extensões para debugging paralelo."
                                  ],
                                  "verification": "Executar comandos de teste (deviceQuery para CUDA, clinfo para OpenCL) e confirmar detecção de pelo menos duas GPUs heterogêneas.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "CUDA Toolkit 12+, OpenCL 3.0 SDK, GPU NVIDIA/AMD/Intel, Linux/Windows com drivers atualizados"
                                  ],
                                  "tips": "Use containers Docker com NVIDIA runtime para reproducibilidade em ambientes heterogêneos.",
                                  "learningObjective": "Entender e configurar plataformas paralelas heterogêneas para desenvolvimento.",
                                  "commonMistakes": [
                                    "Ignorar verificação de compatibilidade de drivers",
                                    "Não testar detecção de múltiplas GPUs",
                                    "Usar versões desatualizadas do toolkit"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Multiplicação de Matrizes em CUDA",
                                  "subSteps": [
                                    "Definir kernels CUDA para multiplicação de matrizes (C = A * B) com grid/block otimizado.",
                                    "Alocar memória GPU com cudaMalloc e copiar dados via cudaMemcpy.",
                                    "Lançar kernel com <<<blocks, threads>>> considerando decomposição de domínio.",
                                    "Sincronizar e copiar resultados de volta à CPU para validação.",
                                    "Compilar e executar com nvcc, medindo tempo com cudaEvents."
                                  ],
                                  "verification": "Comparar resultado CPU vs GPU com tolerância de 1e-6 e speedup > 10x em GPU.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Código base de multiplicação sequencial em C",
                                    "Matrizes de teste 1024x1024",
                                    "nvcc compiler"
                                  ],
                                  "tips": "Use shared memory para tiles de matrizes para otimizar coalescência de memória.",
                                  "learningObjective": "Desenvolver e otimizar kernels CUDA para computação paralela básica.",
                                  "commonMistakes": [
                                    "Race conditions em acessos de memória",
                                    "Blocos/threads mal dimensionados",
                                    "Esquecer cudaDeviceSynchronize()"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Multiplicação de Matrizes Equivalente em OpenCL",
                                  "subSteps": [
                                    "Escrever kernel OpenCL similar ao CUDA, usando clCreateProgramWithSource.",
                                    "Configurar contextos e queues para múltiplos dispositivos heterogêneos.",
                                    "Gerenciar buffers com clCreateBuffer e mapear eventos para sincronização.",
                                    "Compilar programa com clBuildProgram e executar com clEnqueueNDRangeKernel.",
                                    "Validar resultados e comparar performance com CUDA."
                                  ],
                                  "verification": "Resultados idênticos ao CUDA com erro < 1e-6 e execução bem-sucedida em GPUs diferentes.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Código CUDA como referência",
                                    "OpenCL headers",
                                    "Ferramenta clinfo"
                                  ],
                                  "tips": "Use clGetPlatformInfo para selecionar plataformas corretas em setups heterogêneos.",
                                  "learningObjective": "Portar aplicações CUDA para OpenCL, destacando portabilidade em hardware variado.",
                                  "commonMistakes": [
                                    "Não definir work-group size corretamente",
                                    "Erros em gerenciamento de eventos OpenCL",
                                    "Ignorar vendor extensions"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Decomposição de Domínio em GPUs Heterogêneas",
                                  "subSteps": [
                                    "Dividir domínio computacional (ex: matriz) em partições balanceadas por capacidade de GPU.",
                                    "Implementar multi-GPU com cudaSetDevice() ou múltiplas cl_command_queue.",
                                    "Comunicar dados entre GPUs via peer-to-peer (cudaMemcpyPeer) ou host staging.",
                                    "Balancear workload baseado em flops/GPU usando profiling.",
                                    "Executar estudo de caso completo: simulação física como N-body com decomposição."
                                  ],
                                  "verification": "Execução distribuída com speedup linear em número de GPUs e balanceamento < 20% desvio.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Múltiplas GPUs (NVIDIA+AMD)",
                                    "Código de multiplicação anterior",
                                    "nvprof ou CodeXL para profiling"
                                  ],
                                  "tips": "Monitore occupancy e utilization com nvidia-smi durante execução.",
                                  "learningObjective": "Dominar decomposição de domínio para escalabilidade em plataformas heterogêneas.",
                                  "commonMistakes": [
                                    "Desbalanceamento de carga",
                                    "Overhead alto em comunicações P2P",
                                    "Não resetar device context"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar Performance e Otimizar Estudos de Caso",
                                  "subSteps": [
                                    "Coletar métricas: tempo, throughput, occupancy com nvprof/rocprof.",
                                    "Comparar CUDA vs OpenCL em heterogeneidade.",
                                    "Otimizar: tuning de launch parameters, uso de unified memory.",
                                    "Documentar trade-offs e gerar relatório com gráficos.",
                                    "Testar escalabilidade com tamanhos variados."
                                  ],
                                  "verification": "Relatório com speedup > 50x vs CPU e análise de bottlenecks identificados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de profiling (nvprof, clProfiler)",
                                    "Python/Matplotlib para gráficos"
                                  ],
                                  "tips": "Foquem em métricas como GFLOPS para normalizar hardware diferente.",
                                  "learningObjective": "Avaliar e otimizar aplicações paralelas em cenários reais heterogêneos.",
                                  "commonMistakes": [
                                    "Métricas enviesadas por warm-up insuficiente",
                                    "Ignorar overhead de transferência",
                                    "Não considerar variância em runs"
                                  ]
                                }
                              ],
                              "practicalExample": "Implementar uma simulação de partículas N-body onde cada GPU heterogênea (NVIDIA RTX + AMD Radeon) processa uma partição do domínio espacial, computando forças gravitacionais em paralelo e sincronizando via P2P, alcançando speedup de 100x vs CPU.",
                              "finalVerifications": [
                                "Códigos CUDA e OpenCL compilam e executam sem erros em GPUs heterogêneas.",
                                "Resultados numéricos coincidem com implementação sequencial (erro < 1e-5).",
                                "Decomposição de domínio demonstra balanceamento de carga (<15% desvio).",
                                "Medições de performance mostram speedup significativo (>20x por GPU).",
                                "Relatório inclui profiling e gráficos de escalabilidade.",
                                "Aplicação roda em cluster multi-GPU sem crashes."
                              ],
                              "assessmentCriteria": [
                                "Correção funcional: resultados precisos em todos os casos de teste.",
                                "Eficiência paralela: uso ótimo de threads/blocos e memória.",
                                "Portabilidade: funciona em CUDA e OpenCL com hardware heterogêneo.",
                                "Escalabilidade: speedup linear com mais GPUs.",
                                "Documentação: código comentado e relatório claro.",
                                "Otimização: identificação e mitigação de bottlenecks."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e decomposição de domínios para multiplicação de matrizes.",
                                "Física: Simulações numéricas de dinâmica de partículas e forças.",
                                "Engenharia de Software: Design de APIs portáteis e profiling de performance.",
                                "Ciência de Dados: Processamento paralelo para big data em ML.",
                                "Sistemas Operacionais: Gerenciamento de recursos em ambientes multi-GPU."
                              ],
                              "realWorldApplication": "Desenvolvimento de simulações climáticas, treinamento de redes neurais em data centers heterogêneos (ex: AWS com GPUs mistas), renderização em tempo real para jogos/VR, e computação científica em supercomputadores como Frontier que usam OpenCL/CUDA para workloads híbridos."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.3.2",
                            "name": "Avaliar desempenho de programas paralelos",
                            "description": "Medir speedup, eficiência e escalabilidade usando métricas como tempo de execução, uso de memória e ferramentas de profiling, comparando modelos de troca de mensagens e compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambiente e Programa de Teste",
                                  "subSteps": [
                                    "Instalar CUDA/OpenCL toolkit e drivers compatíveis.",
                                    "Selecionar ou criar um programa paralelo simples (ex: multiplicação de matrizes).",
                                    "Implementar versões para memória compartilhada e troca de mensagens (MPI-like).",
                                    "Compilar e testar execução sequencial e paralela básica.",
                                    "Configurar ferramentas de profiling como nvprof ou gprof."
                                  ],
                                  "verification": "Programa compila e executa sem erros em modo sequencial e paralelo com 1 thread/bloco.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "CUDA/OpenCL toolkit",
                                    "Compilador NVIDIA/AMD",
                                    "Editor de código (VS Code)",
                                    "Hardware com GPU"
                                  ],
                                  "tips": "Use configurações de grid/block iniciais conservadoras para evitar crashes.",
                                  "learningObjective": "Preparar ambiente reprodutível para medições precisas.",
                                  "commonMistakes": [
                                    "Ignorar sincronização de memória",
                                    "Não verificar compatibilidade de hardware",
                                    "Usar tamanhos de dados muito pequenos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Medir Métricas Básicas de Desempenho",
                                  "subSteps": [
                                    "Executar programa sequencial múltiplas vezes (média de 10 runs) e registrar tempo de execução.",
                                    "Executar versão paralela variando número de threads/blocos (ex: 1, 4, 16, 64).",
                                    "Medir uso de memória com ferramentas como nvidia-smi ou top.",
                                    "Usar profiler para capturar tempo GPU/CPU, ocupação e tráfego de memória.",
                                    "Registrar dados em planilha para análise."
                                  ],
                                  "verification": "Dados coletados para pelo menos 5 configurações paralelas com tempos médios e desvios padrão.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "nvprof/nsys",
                                    "nvidia-smi",
                                    "Planilha (Excel/Google Sheets)",
                                    "Programa de teste"
                                  ],
                                  "tips": "Aqueça a GPU com runs iniciais para estabilizar medições.",
                                  "learningObjective": "Coletar dados brutos confiáveis de tempo e recursos.",
                                  "commonMistakes": [
                                    "Runs insuficientes levando a variância alta",
                                    "Não considerar overhead de inicialização",
                                    "Medir apenas tempo wall-clock sem breakdown"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Speedup, Eficiência e Escalabilidade",
                                  "subSteps": [
                                    "Calcular speedup: S(p) = T(1)/T(p), onde T(1) é tempo sequencial.",
                                    "Calcular eficiência: E(p) = S(p)/p, com p = número de processadores/threads.",
                                    "Avaliar escalabilidade plotando S(p) vs p e verificando lei de Gustafson/Amdahl.",
                                    "Analisar uso de memória escalável e gargalos identificados no profiler.",
                                    "Comparar métricas entre modelos compartilhada e mensagens."
                                  ],
                                  "verification": "Tabelas e gráficos gerados mostrando speedup >1, eficiência >0.5 para configurações ideais.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python/MATLAB para plots",
                                    "Bibliotecas como Matplotlib/NumPy",
                                    "Dados da planilha"
                                  ],
                                  "tips": "Use log-scale para plots de escalabilidade em grandes p.",
                                  "learningObjective": "Aplicar fórmulas padrão para quantificar ganhos paralelos.",
                                  "commonMistakes": [
                                    "Confundir speedup forte vs fraco",
                                    "Ignorar overhead de comunicação em mensagens",
                                    "Não normalizar tempos por tamanho de problema"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e Comparar Modelos de Memória",
                                  "subSteps": [
                                    "Comparar tempos e uso de memória entre compartilhada (CUDA shared mem) e mensagens (MPI send/recv).",
                                    "Identificar trade-offs: latência em mensagens vs contenção em compartilhada.",
                                    "Otimizar uma versão baseada em profiling (ex: ajustar coalescência).",
                                    "Documentar conclusões com gráficos comparativos.",
                                    "Testar em plataforma heterogênea (CPU+GPU)."
                                  ],
                                  "verification": "Relatório com tabelas comparativas e recomendação de modelo por workload.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Profiler avançado (Nsight)",
                                    "Código otimizado",
                                    "Documentador (Markdown)"
                                  ],
                                  "tips": "Foquem em workloads onde um modelo brilha (ex: mensagens para dados esparsos).",
                                  "learningObjective": "Discernir quando usar cada modelo baseado em evidências empíricas.",
                                  "commonMistakes": [
                                    "Não considerar custo de sincronização",
                                    "Testes só em dados pequenos",
                                    "Ignorar heterogeneidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Avalie um kernel CUDA de multiplicação de matrizes 1024x1024: meça speedup de 1 a 1024 threads em shared memory vs simulação MPI para troca de blocos, identificando que shared memory é 3x mais eficiente para dados densos.",
                              "finalVerifications": [
                                "Speedup calculado corretamente para múltiplos p com S(p) >=1.",
                                "Eficiência média >40% demonstrada em gráficos.",
                                "Uso de memória escalável sem vazamentos.",
                                "Comparação quantitativa entre modelos com pelo menos 20% diferença mensurável.",
                                "Relatório com plots e conclusões acionáveis.",
                                "Testes reprodutíveis em hardware heterogêneo."
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições (desvio <5%).",
                                "Correta aplicação de fórmulas de speedup/eficiência.",
                                "Análise profunda de gargalos via profiling.",
                                "Comparação equilibrada de modelos de memória.",
                                "Gráficos claros e interpretáveis.",
                                "Recomendações práticas baseadas em dados."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Estatística descritiva e modelagem (Amdahl/Gustafson).",
                                "Hardware: Arquitetura de GPUs e memória hierárquica.",
                                "Otimização: Algoritmos e análise de complexidade.",
                                "Ciência de Dados: Visualização e análise empírica.",
                                "Engenharia de Software: Testes e profiling automatizados."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas ou treinamento de IA, onde otimizar speedup em CUDA/OpenCL reduz tempo de iterações de dias para horas, economizando energia e custos em data centers."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.4",
                    "name": "Pthreads e Modelos de Memória Compartilhada",
                    "description": "Threads POSIX para decomposição de domínio e exclusão mútua em plataformas multicores.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.4.1",
                        "name": "Modelos de Memória Compartilhada",
                        "description": "Entender os principais modelos de programação paralela baseados em memória compartilhada, incluindo a taxonomia de Flynn e suas implicações para plataformas multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.4.1.1",
                            "name": "Classificar arquiteturas paralelas pela taxonomia de Flynn",
                            "description": "Identificar e diferenciar os quatro quadrantes da taxonomia de Flynn (SISD, SIMD, MISD, MIMD) e relacioná-los com modelos de memória compartilhada em processadores multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude a definição da taxonomia de Flynn proposta por Michael J. Flynn em 1966.",
                                    "Identifique os dois eixos principais: fluxo de instruções (único ou múltiplo) e fluxo de dados (único ou múltiplo).",
                                    "Desenhe um diagrama 2x2 representando os quatro quadrantes: SISD, SIMD, MISD, MIMD.",
                                    "Revise exemplos históricos iniciais para cada quadrante.",
                                    "Anote as limitações da taxonomia em arquiteturas modernas."
                                  ],
                                  "verification": "Crie um diagrama manual ou digital dos quatro quadrantes e explique verbalmente ou por escrito os eixos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta ou ferramenta de diagramação como Draw.io",
                                    "Artigo original de Flynn (PDF ou resumo online)",
                                    "Vídeo introdutório sobre taxonomia de Flynn (YouTube ou Khan Academy)"
                                  ],
                                  "tips": "Use cores diferentes para cada quadrante no diagrama para facilitar a memorização visual.",
                                  "learningObjective": "Entender a estrutura conceitual da taxonomia de Flynn e seus eixos de classificação.",
                                  "commonMistakes": [
                                    "Confundir fluxo de instruções com fluxo de dados",
                                    "Ignorar que MIMD é o mais comum em multicores modernos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar as Classes SISD e SIMD",
                                  "subSteps": [
                                    "Descreva SISD: processador sequencial tradicional (ex: processadores von Neumann clássicos).",
                                    "Explique SIMD: instruções únicas aplicadas a múltiplos dados (ex: vetores em GPUs ou SSE/AVX em CPUs).",
                                    "Compare eficiência em tarefas vetoriais vs. escalares.",
                                    "Pesquise exemplos reais: Intel Pentium (SISD) vs. NVIDIA CUDA cores (SIMD).",
                                    "Liste vantagens e desvantagens de cada uma."
                                  ],
                                  "verification": "Escreva um parágrafo comparando SISD e SIMD com exemplos de hardware específicos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Documentação Intel/AMD sobre instruções SIMD",
                                    "Simulador online de SIMD (ex: Godbolt Compiler Explorer)",
                                    "Notas do step 1"
                                  ],
                                  "tips": "Pense em SIMD como 'broadcasting' de instruções para arrays de dados, como em processamento de imagens.",
                                  "learningObjective": "Diferenciar SISD e SIMD, identificando aplicações típicas.",
                                  "commonMistakes": [
                                    "Achar que todos os processadores modernos são puramente SISD",
                                    "Confundir SIMD com paralelismo de threads"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar MISD e MIMD e suas Características",
                                  "subSteps": [
                                    "Defina MISD: múltiplas instruções em um único fluxo de dados (raro, ex: pipeplines fault-tolerant).",
                                    "Detalhe MIMD: múltiplas instruções e dados independentes (ex: clusters, multicores com threads).",
                                    "Discuta por que MISD é teórico e pouco prático.",
                                    "Identifique MIMD em processadores multicores como AMD Ryzen ou Intel Xeon.",
                                    "Crie uma tabela comparativa de todas as quatro classes."
                                  ],
                                  "verification": "Complete uma tabela com colunas para cada classe, incluindo definição, exemplos e uso comum.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Planilha Google Sheets ou Excel para tabela",
                                    "Livro 'Computer Architecture: A Quantitative Approach' (capítulo relevante)",
                                    "Sites como Wikipedia para exemplos MISD"
                                  ],
                                  "tips": "Lembre-se: MIMD é o 'padrão ouro' para programação paralela geral em memória compartilhada.",
                                  "learningObjective": "Dominar MISD e MIMD, destacando predominância do MIMD.",
                                  "commonMistakes": [
                                    "Confundir MISD com pipeline tradicional",
                                    "Subestimar MIMD em smartphones multicores"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar Taxonomia com Modelos de Memória Compartilhada em Multicores",
                                  "subSteps": [
                                    "Explique como multicores (ex: Intel Core i7) são MIMD com memória compartilhada (UMA/NUMA).",
                                    "Classifique arquiteturas dadas: GPU (SIMD), cluster Beowulf (MIMD distribuída), etc.",
                                    "Simule classificação de 5 arquiteturas reais usando a taxonomia.",
                                    "Discuta implicações para Pthreads: sincronização em MIMD compartilhado.",
                                    "Resolva exercícios de classificação prática."
                                  ],
                                  "verification": "Classifique corretamente 5 arquiteturas fornecidas (ex: em um quiz autoavaliado).",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Lista de arquiteturas para classificar (preparada ou online)",
                                    "Documentação Pthreads man pages",
                                    "Ferramenta de quiz como Quizlet"
                                  ],
                                  "tips": "Foco em MIMD para multicores: cada core executa instruções independentes acessando memória compartilhada.",
                                  "learningObjective": "Aplicar a taxonomia para classificar arquiteturas modernas e relacionar com programação paralela.",
                                  "commonMistakes": [
                                    "Classificar GPUs como MIMD em vez de SIMD",
                                    "Ignorar nuances de memória em MIMD"
                                  ]
                                }
                              ],
                              "practicalExample": "Dado um processador Intel Core i9 com 16 cores e suporte a AVX-512: Classifique como MIMD (múltiplas instruções por core) com elementos SIMD nas instruções vetoriais, usando modelo UMA de memória compartilhada para Pthreads.",
                              "finalVerifications": [
                                "Liste e defina corretamente os quatro quadrantes da taxonomia de Flynn sem consulta.",
                                "Classifique 5 arquiteturas reais (ex: CPU single-core, GPU, cluster) com justificativa.",
                                "Explique relação entre MIMD e memória compartilhada em multicores.",
                                "Desenhe diagrama da taxonomia com exemplos em cada quadrante.",
                                "Identifique limitações da taxonomia em arquiteturas híbridas modernas.",
                                "Resolva um problema: 'É um supercomputador TOP500 MIMD?' com raciocínio."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição dos eixos e quadrantes (90% correto).",
                                "Capacidade de classificar arquiteturas com exemplos reais e justificadas.",
                                "Compreensão de relação com memória compartilhada e Pthreads.",
                                "Uso correto de terminologia técnica sem erros comuns.",
                                "Profundidade em comparações e limitações da taxonomia.",
                                "Criatividade em exemplos práticos e diagramas claros."
                              ],
                              "crossCurricularConnections": [
                                "Programação Paralela: Aplicação em Pthreads e OpenMP para MIMD.",
                                "Arquitetura de Computadores: Evolução de SISD para MIMD em hardware moderno.",
                                "Processamento de Imagens: SIMD em GPUs para aceleração.",
                                "Redes de Computadores: MIMD distribuída em clusters.",
                                "Engenharia de Software: Design de sistemas paralelos escaláveis."
                              ],
                              "realWorldApplication": "Em design de supercomputadores (ex: Frontier, MIMD massivo), otimização de software para CPUs/GPUs (SIMD em IA), e desenvolvimento de apps multithreaded em servidores cloud usando memória compartilhada para eficiência em big data."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.1.2",
                            "name": "Descrever modelos de memória compartilhada vs. distribuída",
                            "description": "Comparar modelos de memória compartilhada (uniforme e não-uniforme) com memória distribuída, destacando vantagens como simplicidade de programação e desafios como contenção de cache.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Básicos de Modelos de Memória",
                                  "subSteps": [
                                    "Defina memória compartilhada como um modelo onde múltiplos processadores acessam uma única memória comum.",
                                    "Defina memória distribuída como um modelo onde cada processador tem sua própria memória local, comunicando via mensagens.",
                                    "Identifique as categorias de memória compartilhada: Uniforme (UMA) e Não-Uniforma (NUMA).",
                                    "Liste as principais diferenças arquitetônicas entre compartilhada e distribuída.",
                                    "Crie um diagrama simples ilustrando cada modelo."
                                  ],
                                  "verification": "Crie um diagrama ou tabela resumindo definições e diferenças básicas; revise se cobre UMA, NUMA e distribuída.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta ou ferramenta de diagramação como Draw.io",
                                    "Artigos introdutórios sobre arquitetura de computadores"
                                  ],
                                  "tips": "Use analogias: compartilhada como uma família compartilhando uma geladeira; distribuída como casas separadas com entregas.",
                                  "learningObjective": "Compreender as definições fundamentais e diferenças arquitetônicas dos modelos de memória.",
                                  "commonMistakes": [
                                    "Confundir UMA com NUMA sem notar latências variáveis",
                                    "Ignorar que distribuída não tem memória global única"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Modelos de Memória Compartilhada (UMA e NUMA)",
                                  "subSteps": [
                                    "Descreva UMA: acesso uniforme a toda memória, cache coerência centralizada.",
                                    "Descreva NUMA: memória local rápida, remota mais lenta; escalável para muitos processadores.",
                                    "Explique mecanismos de cache coerência (ex: MSI, MESI).",
                                    "Discuta contenção de cache como desafio em compartilhada.",
                                    "Compare simplicidade de programação em UMA vs. NUMA."
                                  ],
                                  "verification": "Escreva um parágrafo comparando UMA e NUMA, incluindo um exemplo de contenção de cache.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Livro ou slides sobre Sistemas Paralelos",
                                    "Vídeos sobre cache coherence no YouTube"
                                  ],
                                  "tips": "Visualize NUMA como prédios conectados: andares locais rápidos, elevador para outros.",
                                  "learningObjective": "Dominar características, vantagens e desafios da memória compartilhada.",
                                  "commonMistakes": [
                                    "Achar que NUMA é sempre mais lenta que UMA sem contexto de escala",
                                    "Esquecer impacto na programação paralela"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Modelos de Memória Distribuída",
                                  "subSteps": [
                                    "Descreva arquitetura: nós independentes com memória local, comunicação via MPI ou redes.",
                                    "Explique ausência de contenção de cache, mas overhead de mensagens.",
                                    "Discuta escalabilidade para milhares de nós.",
                                    "Compare programação: explicitar trocas de mensagens vs. acesso compartilhado implícito.",
                                    "Liste paradigmas como message-passing vs. shared-memory."
                                  ],
                                  "verification": "Crie pseudocódigo de um 'hello world' em memória distribuída usando MPI.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Documentação MPI básica",
                                    "Simulador ou ambiente com MPICH"
                                  ],
                                  "tips": "Pense em distribuída como times esportivos: cada jogador tem bola própria, passa quando precisa.",
                                  "learningObjective": "Compreender estrutura, comunicação e trade-offs da memória distribuída.",
                                  "commonMistakes": [
                                    "Subestimar latência de rede em distribuída",
                                    "Confundir com cluster sem nós locais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar Modelos e Destacar Vantagens/Desafios",
                                  "subSteps": [
                                    "Tabela comparativa: simplicidade programação (compartilhada >), escalabilidade (distribuída >).",
                                    "Vantagens compartilhada: código mais simples, sem sincronização mensagens.",
                                    "Desafios compartilhada: contenção cache, escalabilidade limitada.",
                                    "Vantagens distribuída: sem contenção, custo-efetiva em commodity hardware.",
                                    "Desafios distribuída: complexidade de debugging mensagens, latência rede.",
                                    "Conclua com cenários ideais para cada."
                                  ],
                                  "verification": "Elabore uma tabela de prós/contras e explique verbalmente para um par.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets para tabela",
                                    "Notas dos steps anteriores"
                                  ],
                                  "tips": "Use métricas quantitativas: latência cache vs. rede (ns vs. µs).",
                                  "learningObjective": "Sintetizar comparações, identificando quando usar cada modelo.",
                                  "commonMistakes": [
                                    "Ignorar híbridos CC-NUMA",
                                    "Generalizar sem considerar hardware moderno"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de matriz multiplicação: Na compartilhada (Pthreads), threads acessam matriz global com locks para evitar contenção; na distribuída (MPI), cada nó computa sub-matriz e envia resultados via Send/Recv, evitando cache thrashing mas adicionando comunicação.",
                              "finalVerifications": [
                                "Explicar diferença entre UMA e NUMA com exemplo de latência.",
                                "Descrever contenção de cache e como afeta performance compartilhada.",
                                "Comparar simplicidade de código em Pthreads vs. MPI.",
                                "Identificar cenário onde distribuída é preferível (ex: 1000+ nós).",
                                "Listar 3 vantagens e 3 desafios de cada modelo.",
                                "Desenhar diagrama comparativo."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas de UMA, NUMA e distribuída.",
                                "Completude da comparação: cobre vantagens, desafios e programação.",
                                "Uso de exemplos concretos: inclui cenários reais ou pseudocódigo.",
                                "Clareza na explicação: linguagem acessível, sem jargões não explicados.",
                                "Profundidade técnica: menciona cache coherence e message-passing.",
                                "Capacidade de síntese: tabela ou resumo organizado."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: cache coherence protocols.",
                                "Redes de Computadores: latência e topologias em distribuída.",
                                "Sistemas Operacionais: gerenciamento de memória multiprocessador.",
                                "Algoritmos Paralelos: impacto nos designs de algoritmos.",
                                "Engenharia de Software: trade-offs em programação paralela."
                              ],
                              "realWorldApplication": "Em supercomputadores como o Frontier (distribuída para escalabilidade em exaflops) vs. multicore servers como Intel Xeon (compartilhada NUMA para apps de banco de dados), onde contenção de cache é mitigada por NUMA-aware scheduling."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.1.3",
                            "name": "Explicar consistência e sincronização em memória compartilhada",
                            "description": "Analisar modelos de consistência de memória (sequencial, forte, fraca) e sua relevância para programação paralela em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos de memória compartilhada e problemas de consistência",
                                  "subSteps": [
                                    "Explicar o conceito de memória compartilhada em programação paralela.",
                                    "Identificar problemas como data races e reordenação de instruções.",
                                    "Discutir o papel da consistência de memória em threads concorrentes.",
                                    "Analisar exemplos simples de acessos concorrentes sem sincronização.",
                                    "Revisar o modelo de execução sequencial como referência ideal."
                                  ],
                                  "verification": "O aluno resume em 3 frases os problemas de consistência e fornece um exemplo de data race.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação Pthreads",
                                    "Artigo 'Memory Consistency Models: A Tutorial' de Sorin et al.",
                                    "Compilador GCC com suporte a multithreading"
                                  ],
                                  "tips": "Use diagramas de tempo para visualizar reordenações de memória.",
                                  "learningObjective": "Entender os desafios básicos da memória compartilhada em ambientes multithread.",
                                  "commonMistakes": "Confundir reordenação de CPU com bugs lógicos no código."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o modelo de consistência sequencial",
                                  "subSteps": [
                                    "Definir consistência sequencial como todas as threads vendo operações em ordem total.",
                                    "Comparar com execuções sequenciais não concorrentes.",
                                    "Estudar garantias: ordem de escrita-leitura e escrita-escrita por thread.",
                                    "Implementar um exemplo simples em Pthreads simulando SC.",
                                    "Verificar propriedades com ferramentas como ThreadSanitizer."
                                  ],
                                  "verification": "Implementar e testar um programa que demonstra ordem sequencial em acessos compartilhados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código fonte Pthreads básico",
                                    "ThreadSanitizer (TSan)",
                                    "Livro 'Programming with POSIX Threads' de Butenhof"
                                  ],
                                  "tips": "Sempre isole operações atômicas para aproximar SC.",
                                  "learningObjective": "Dominar as propriedades e implementações do modelo de consistência sequencial.",
                                  "commonMistakes": "Achar que SC é o padrão mais fraco; é o mais forte."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar modelos de consistência forte e fraca",
                                  "subSteps": [
                                    "Definir consistência forte (linearizabilidade) e suas relaxações.",
                                    "Contrastar com consistência fraca (eventual, causal).",
                                    "Analisar trade-offs: performance vs. corretude em multicores.",
                                    "Comparar implementações em arquiteturas x86 (TSO) vs. ARM (fraca).",
                                    "Discutir quando usar cada modelo em aplicações reais."
                                  ],
                                  "verification": "Criar uma tabela comparativa dos três modelos com exemplos de violações.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Especificação Intel x86-TSO",
                                    "Documentação ARM Weak Memory",
                                    "Ferramenta herdslax para testes"
                                  ],
                                  "tips": "Use assembly simples para demonstrar diferenças arquiteturais.",
                                  "learningObjective": "Diferenciar e avaliar modelos de consistência forte e fraca.",
                                  "commonMistakes": "Ignorar variações por arquitetura de CPU."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Estudar sincronização para garantir consistência em memória compartilhada",
                                  "subSteps": [
                                    "Explicar mutex, semáforos e barreiras em Pthreads.",
                                    "Implementar sincronização para restaurar SC em cenários fracos.",
                                    "Analisar custos de sincronização (overhead de cache coherence).",
                                    "Testar programas com e sem sincronização em múltiplos cores.",
                                    "Discutir alternativas como atomic operations (C11 stdatomic)."
                                  ],
                                  "verification": "Corrigir um programa com data race usando mutex e medir performance.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Biblioteca Pthreads",
                                    "Perf tool para profiling",
                                    "Código de exemplo com contadores compartilhados"
                                  ],
                                  "tips": "Minimize regiões críticas para reduzir contenção.",
                                  "learningObjective": "Aplicar mecanismos de sincronização para enforcing de consistência desejada.",
                                  "commonMistakes": "Usar locks desnecessariamente, degradando performance."
                                }
                              ],
                              "practicalExample": "Implemente um contador compartilhado em Pthreads: sem sincronização (data race, ordem fraca), com mutex (aproxima SC), e compare saídas em 4 threads rodando 1M iterações em um quad-core. Meça tempo e verifique contagem final.",
                              "finalVerifications": [
                                "Definir corretamente consistência sequencial e suas propriedades.",
                                "Explicar diferenças entre SC, forte e fraca com exemplos.",
                                "Implementar sincronização em Pthreads para evitar data races.",
                                "Analisar impacto de modelos em performance multicores.",
                                "Identificar violações de consistência em código dado.",
                                "Propor solução otimizada para cenário real."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual nos modelos de consistência (30%)",
                                "Correção e funcionalidade do código Pthreads (25%)",
                                "Análise de trade-offs performance/corretude (20%)",
                                "Uso adequado de sincronização (15%)",
                                "Clareza na explicação e diagramas (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Protocolos de coerência de cache (MESI).",
                                "Sistemas Operacionais: Primitivas de sincronização kernel-level.",
                                "Algoritmos e Estruturas de Dados: Estruturas lock-free.",
                                "Engenharia de Software: Design de APIs thread-safe.",
                                "Redes de Computadores: Consistência em sistemas distribuídos (Paxos)."
                              ],
                              "realWorldApplication": "Em servidores web como Nginx ou Apache com worker threads multicores, garantindo contadores de sessões e caches compartilhados sem data races, otimizando throughput em data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.4.2",
                        "name": "Pthreads (POSIX Threads)",
                        "description": "Dominar a API Pthreads para criação e gerenciamento de threads em sistemas Unix-like, focando em programação paralela para multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.4.2.1",
                            "name": "Criar e gerenciar threads com pthread_create e pthread_join",
                            "description": "Implementar criação de múltiplas threads, passando argumentos via estruturas e aguardando término com pthread_join para sincronização básica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento para Pthreads",
                                  "subSteps": [
                                    "Instale o compilador GCC e verifique a disponibilidade da biblioteca pthread com 'man pthread_create'.",
                                    "Crie um novo arquivo fonte .c e inclua o cabeçalho <pthread.h>.",
                                    "Compile um programa de teste simples usando a flag -pthread: gcc -o teste teste.c -pthread.",
                                    "Execute o programa e confirme que não há erros de linkage ou runtime.",
                                    "Configure um editor ou IDE (como VS Code com C/C++ extension) para highlighting de pthread."
                                  ],
                                  "verification": "Compilação e execução bem-sucedidas de um hello world sem threads.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "GCC compiler",
                                    "Terminal/Linux ou WSL no Windows",
                                    "Editor de texto"
                                  ],
                                  "tips": "Sempre use -pthread ou -lpthread na compilação para linkar a biblioteca corretamente.",
                                  "learningObjective": "Preparar o ambiente para programação segura com threads POSIX.",
                                  "commonMistakes": [
                                    "Esquecer a flag -pthread levando a erros de 'undefined reference'",
                                    "Não incluir <pthread.h> causando erros de compilação",
                                    "Executar em ambiente sem suporte POSIX como Windows nativo sem WSL"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Criar uma thread simples com pthread_create",
                                  "subSteps": [
                                    "Defina a função da thread como void* thread_func(void* arg) que imprime uma mensagem e retorna NULL.",
                                    "Na main, declare pthread_t thread_id e chame pthread_create(&thread_id, NULL, thread_func, NULL).",
                                    "Compile e execute, observando a saída da thread junto com a main.",
                                    "Verifique o retorno de pthread_create para erros com if (ret != 0) perror().",
                                    "Adicione um sleep na main para dar tempo à thread executar."
                                  ],
                                  "verification": "Programa cria uma thread que executa em paralelo à main, visível na saída misturada.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código fonte do Step 1",
                                    "GCC com -pthread"
                                  ],
                                  "tips": "O arg é void* para flexibilidade; comece com NULL para simplicidade.",
                                  "learningObjective": "Implementar criação básica de thread e entender execução concorrente.",
                                  "commonMistakes": [
                                    "Não verificar retorno de pthread_create ignorando falhas",
                                    "Retornar int em vez de void* na função thread",
                                    "Falta de sleep causando saída prematura da main"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Passar argumentos para threads via estruturas",
                                  "subSteps": [
                                    "Defina uma struct ThreadArg { int id; char* message; };",
                                    "Alocar memória para ThreadArg com malloc e preencha os campos.",
                                    "Passe &arg para pthread_create e acesse via (ThreadArg*)arg na função thread.",
                                    "Imprima os argumentos recebidos e libere memória com free(arg) na thread.",
                                    "Teste com diferentes valores para múltiplas chamadas (ainda uma thread por vez)."
                                  ],
                                  "verification": "Thread recebe e usa corretamente os argumentos passados via struct.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código anterior",
                                    "stdlib.h para malloc/free"
                                  ],
                                  "tips": "Use typedef para struct para legibilidade; sempre libere memória para evitar leaks.",
                                  "learningObjective": "Transmitir dados customizados para threads de forma segura.",
                                  "commonMistakes": [
                                    "Não dereferenciar arg com (ThreadArg*)arg",
                                    "Free na main em vez da thread",
                                    "Passar struct diretamente sem ponteiro"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Criar múltiplas threads e sincronizar com pthread_join",
                                  "subSteps": [
                                    "Crie um array de pthread_t threads[5] e loop para pthread_create para cada.",
                                    "Preencha um array de ThreadArg para cada thread com IDs únicos.",
                                    "Use loop para pthread_join(threads[i], NULL) aguardando cada thread.",
                                    "Compile e execute, confirmando que main espera todas threads terminarem.",
                                    "Adicione contadores globais para demonstrar compartilhamento (sem locks ainda)."
                                  ],
                                  "verification": "Todas threads executam e main só termina após pthread_join de todas.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Código completo anterior"
                                  ],
                                  "tips": "pthread_join bloqueia até a thread terminar; use para sincronização básica.",
                                  "learningObjective": "Gerenciar e aguardar múltiplas threads para ordem de término.",
                                  "commonMistakes": [
                                    "pthread_join com índice errado no loop",
                                    "Não aguardar threads causando saída prematura",
                                    "Race condition em variáveis globais sem proteção"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar e depurar o programa completo",
                                  "subSteps": [
                                    "Execute com valgrind para checar memory leaks: valgrind --tool=memcheck ./programa.",
                                    "Adicione prints com thread ID via pthread_self() para rastrear execução.",
                                    "Teste cenários de erro: crie mais threads que limite do sistema.",
                                    "Meça tempo de execução com múltiplas threads vs sequencial.",
                                    "Refatore código em funções modulares para reutilização."
                                  ],
                                  "verification": "Programa roda sem leaks, erros ou crashes; saída ordenada por joins.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Valgrind instalado",
                                    "time command no terminal"
                                  ],
                                  "tips": "Use pthread_self() para logging único por thread.",
                                  "learningObjective": "Depurar e validar programas multi-threaded.",
                                  "commonMistakes": [
                                    "Ignorar warnings de compilador sobre unused variables",
                                    "Não testar com valgrind revelando leaks",
                                    "Assumir ordem de execução determinística"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie um programa que gera 4 threads, cada uma recebendo via struct um ID e um número N. Cada thread calcula a soma dos primeiros N inteiros e imprime 'Thread ID: X, Soma: Y'. A main cria todas, aguarda com pthread_join e imprime 'Todas threads concluídas'. Compile com gcc -o soma_threads soma_threads.c -pthread e execute ./soma_threads.",
                              "finalVerifications": [
                                "Compilação sem erros usando -pthread.",
                                "Execução mostra saídas de todas threads antes do término da main.",
                                "Valgrind confirma ausência de memory leaks ou invalid reads/writes.",
                                "pthread_join impede main de terminar prematuramente.",
                                "Args são passados e usados corretamente em cada thread.",
                                "Múltiplas threads (ex: 10) executam sem crashes."
                              ],
                              "assessmentCriteria": [
                                "Código usa corretamente pthread_create com args via struct.",
                                "pthread_join aplicado a todas threads criadas.",
                                "Verificação de retornos de funções pthread.",
                                "Gerenciamento adequado de memória (malloc/free).",
                                "Saída demonstra paralelismo (ordem não determinística).",
                                "Código limpo, comentado e modular."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de processos e escalonamento de threads.",
                                "Algoritmos e Estruturas de Dados: Paralelismo em computação numérica.",
                                "Matemática Computacional: Dividir tarefas como somas em threads.",
                                "Redes e Sistemas Distribuídos: Base para servidores multi-threaded.",
                                "Engenharia de Software: Práticas de depuração com tools como Valgrind."
                              ],
                              "realWorldApplication": "Desenvolvimento de servidores web multi-threaded (ex: Nginx ou Apache), onde cada requisição HTTP é tratada por uma thread separada, passando dados da conexão via structs e aguardando processamento com join para logging ou cleanup."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.2.2",
                            "name": "Usar pthread_exit e atributos de thread",
                            "description": "Configurar atributos de threads (como detached ou joinable) e finalizar threads corretamente com pthread_exit, evitando vazamentos de recursos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar e configurar atributos de thread (pthread_attr_t)",
                                  "subSteps": [
                                    "Inclua as bibliotecas necessárias: <pthread.h> e compile com -pthread.",
                                    "Declare uma variável pthread_attr_t attr; e inicialize com pthread_attr_init(&attr);",
                                    "Configure atributos específicos, como pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED); para detached ou PTHREAD_CREATE_JOINABLE para joinable.",
                                    "Verifique erros com if (ret != 0) para cada chamada pthread.",
                                    "Defina tamanho da stack se necessário com pthread_attr_setstacksize(&attr, tamanho);"
                                  ],
                                  "verification": "Execute pthread_attr_getdetachstate(&attr, &estado) para confirmar o estado configurado e imprima o valor.",
                                  "estimatedTime": "15-20 minutos",
                                  "materials": [
                                    "Compilador GCC com suporte a pthread",
                                    "Man page de pthread_attr_init(3)"
                                  ],
                                  "tips": "Sempre inicialize atributos antes de usar e destrua com pthread_attr_destroy(&attr) ao final.",
                                  "learningObjective": "Compreender e aplicar a inicialização e configuração básica de atributos de threads POSIX.",
                                  "commonMistakes": [
                                    "Esquecer de chamar pthread_attr_init",
                                    "Não verificar códigos de retorno de erros",
                                    "Configurar atributos sem destruir depois"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Criar thread utilizando atributos personalizados",
                                  "subSteps": [
                                    "Defina a função da thread: void* thread_func(void* arg) { ... return NULL; }",
                                    "No main, chame pthread_create(&thread_id, &attr, thread_func, NULL); passando os atributos.",
                                    "Armazene o pthread_t thread_id para gerenciamento futuro.",
                                    "Verifique o retorno de pthread_create e trate erros.",
                                    "Libere os atributos com pthread_attr_destroy(&attr); após criação."
                                  ],
                                  "verification": "Confirme criação bem-sucedida imprimindo thread_id e verificando se a thread inicia execução.",
                                  "estimatedTime": "20-25 minutos",
                                  "materials": [
                                    "Código base de thread simples",
                                    "Editor de texto/IDE como VS Code ou Vim"
                                  ],
                                  "tips": "Use argumentos void* para passar dados para a thread de forma genérica.",
                                  "learningObjective": "Criar threads com atributos customizados, garantindo configuração correta.",
                                  "commonMistakes": [
                                    "Passar NULL como atributos, usando defaults",
                                    "Não destruir atributos após pthread_create",
                                    "Ignorar pthread_t retornado"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Finalizar thread com pthread_exit e gerenciar recursos",
                                  "subSteps": [
                                    "Na função da thread, realize o trabalho e finalize com pthread_exit((void*)valor_retorno); em vez de return.",
                                    "Evite chamadas de exit() ou return direto se precisar de cleanup específico.",
                                    "No main, para threads joinable: pthread_join(thread_id, &retval); para aguardar término.",
                                    "Para detached: não chame join, mas garanta que não haja vazamentos verificando com valgrind.",
                                    "Implemente cleanup handlers com pthread_cleanup_push/pop se necessário para ações em cancelamento."
                                  ],
                                  "verification": "Use valgrind --tool=memcheck para verificar ausência de vazamentos de threads e memória.",
                                  "estimatedTime": "25-30 minutos",
                                  "materials": [
                                    "Valgrind instalado",
                                    "Exemplos de código com pthread_exit"
                                  ],
                                  "tips": "pthread_exit permite retorno de valor sem join em detached threads.",
                                  "learningObjective": "Implementar finalização correta de threads evitando deadlocks e vazamentos.",
                                  "commonMistakes": [
                                    "Usar exit() na thread, terminando todo o processo",
                                    "Esquecer pthread_join em joinable threads",
                                    "Não usar pthread_exit em funções de thread longas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar e depurar o ciclo completo de vida da thread",
                                  "subSteps": [
                                    "Compile com gcc -o programa programa.c -pthread -Wall.",
                                    "Execute múltiplas vezes criando várias threads e observe comportamento.",
                                    "Use gdb ou printf para depurar estados de thread (join/detach).",
                                    "Teste cenários de erro: falha na criação, cancelamento com pthread_cancel.",
                                    "Analise saída com strace ou ltrace para chamadas de sistema pthread."
                                  ],
                                  "verification": "Programa roda sem crashes, valgrind limpo, e valor de retorno correto via join.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "GDB debugger",
                                    "Valgrind",
                                    "strace"
                                  ],
                                  "tips": "Teste com PTHREAD_CREATE_DETACHED para apps de alta performance onde join não é necessário.",
                                  "learningObjective": "Validar o gerenciamento completo de threads com atributos e exit.",
                                  "commonMistakes": [
                                    "Não testar com múltiplas threads",
                                    "Ignorar warnings de compilação",
                                    "Assumir detached sem verificar detachstate"
                                  ]
                                }
                              ],
                              "practicalExample": "Exemplo C: Crie uma thread detached que conta de 1 a 10 e usa pthread_exit(0);. No main: pthread_attr_t attr; pthread_attr_init(&attr); pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED); pthread_t tid; pthread_create(&tid, &attr, contador, NULL); pthread_attr_destroy(&attr); sleep(1); // Sem join.",
                              "finalVerifications": [
                                "Compilação sem erros ou warnings com -Wall -pthread.",
                                "Execução sem vazamentos detectados por valgrind.",
                                "Thread termina corretamente sem zombie processes (ver ps aux).",
                                "Valor de retorno acessível via pthread_join em threads joinable.",
                                "Configuração de atributos confirmada via get functions.",
                                "Múltiplas threads coexistem sem race conditions básicas."
                              ],
                              "assessmentCriteria": [
                                "Código usa pthread_attr_* corretamente para detached/joinable.",
                                "pthread_exit aplicado na função da thread, não return direto.",
                                "Tratamento de erros em todas chamadas pthread_*.",
                                "Atributos inicializados e destruídos adequadamente.",
                                "Testes demonstram ausência de vazamentos de recursos.",
                                "Comentários explicam escolhas de detached vs joinable."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de processos e threads no kernel Linux.",
                                "Programação em C: Ponteiros, funções void* e gerenciamento de memória.",
                                "Arquitetura de Computadores: Modelos de memória compartilhada e sincronização.",
                                "Engenharia de Software: Boas práticas em programação concorrente.",
                                "Segurança da Informação: Evitar vazamentos que levem a DoS."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx com worker threads, onde threads detached processam requisições HTTP simultâneas e finalizam com pthread_exit para liberar recursos CPU/memória rapidamente, evitando escalabilidade limitada por threads zumbis."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.2.3",
                            "name": "Implementar variáveis específicas de thread com pthread_key_create",
                            "description": "Criar chaves de thread para armazenamento de dados específicos por thread, utilizando pthread_setspecific e pthread_getspecific.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente e criar a chave de thread com pthread_key_create",
                                  "subSteps": [
                                    "Inclua as headers necessárias: <pthread.h> e <stdio.h>.",
                                    "Declare uma variável global pthread_key_t key; para armazenar a chave.",
                                    "Na função main, chame pthread_key_create(&key, NULL); para criar a chave sem destructor inicialmente.",
                                    "Verifique o retorno de pthread_key_create para erros com if (ret != 0) { perror(\"pthread_key_create\"); }.",
                                    "Compile o código com gcc -o programa programa.c -lpthread."
                                  ],
                                  "verification": "Compile e execute o programa sem erros; confirme que pthread_key_create retorna 0.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto (VS Code ou Vim)",
                                    "Compilador GCC",
                                    "Man pages: man pthread_key_create"
                                  ],
                                  "tips": "Sempre verifique retornos de funções pthread para depuração precoce.",
                                  "learningObjective": "Compreender e implementar a criação de chaves TLS em pthreads.",
                                  "commonMistakes": [
                                    "Esquecer de linkar -lpthread",
                                    "Não inicializar a chave antes de usar",
                                    "Ignorar códigos de erro"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar pthread_setspecific para armazenar dados específicos por thread",
                                  "subSteps": [
                                    "Crie uma função de thread void* thread_func(void* arg) { ... }.",
                                    "Dentro da thread_func, aloque memória para dados específicos, ex: char* thread_id = malloc(20); sprintf(thread_id, \"Thread %ld\", (long)pthread_self());.",
                                    "Chame pthread_setspecific(key, thread_id); para associar o valor à thread atual.",
                                    "Adicione printf para logar o set: printf(\"Thread %ld setou ID: %s\\n\", (long)pthread_self(), (char*)pthread_getspecific(key));.",
                                    "Crie 3-5 threads com pthread_create e junte com pthread_join."
                                  ],
                                  "verification": "Execute e veja logs confirmando que cada thread seta seu próprio ID sem interferência.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código base do Step 1",
                                    "Documentação pthread_self"
                                  ],
                                  "tips": "Use pthread_self() para IDs únicos; valores devem ser alocados por thread para evitar vazamentos.",
                                  "learningObjective": "Aplicar pthread_setspecific para armazenamento TLS isolado por thread.",
                                  "commonMistakes": [
                                    "Usar dados globais em vez de TLS",
                                    "Não alocar memória para o valor",
                                    "Race conditions no set antes do get"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Recuperar e utilizar dados com pthread_getspecific",
                                  "subSteps": [
                                    "Na thread_func, após setspecific, chame char* my_id = (char*)pthread_getspecific(key);.",
                                    "Use o valor recuperado: printf(\"Thread %ld recuperou: %s\\n\", (long)pthread_self(), my_id);.",
                                    "Teste isolamento criando múltiplas threads e verificando que cada uma recupera seu próprio valor.",
                                    "Adicione uma segunda chamada a getspecific após um delay (sleep(1)) para confirmar persistência.",
                                    "Implemente um loop simples na thread para múltiplos gets/sets simulando uso contínuo."
                                  ],
                                  "verification": "Logs mostram que cada thread recupera corretamente seu valor único, sem mistura.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Timer para sleep (unistd.h)"
                                  ],
                                  "tips": "pthread_getspecific retorna NULL se não setado; sempre caste corretamente o ponteiro.",
                                  "learningObjective": "Dominar recuperação segura de dados TLS com pthread_getspecific.",
                                  "commonMistakes": [
                                    "Não castar o retorno para o tipo correto",
                                    "Assumir valor sem checar NULL",
                                    "Misturar com variáveis globais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Adicionar destructor, testar cleanup e validar isolamento completo",
                                  "subSteps": [
                                    "Defina uma função de destructor void destructor(void* ptr) { free(ptr); printf(\"Limpando %s\\n\", (char*)ptr); }.",
                                    "Recrie a chave com pthread_key_create(&key, destructor);.",
                                    "Execute múltiplas threads, finalize com pthread_join e observe chamadas ao destructor.",
                                    "Teste cenários de erro: kill uma thread abruptamente e verifique cleanup.",
                                    "Compile, rode com valgrind para checar leaks: valgrind --tool=memcheck ./programa."
                                  ],
                                  "verification": "Valgrind mostra no leaks; destructors são chamados corretamente por thread.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Valgrind instalado",
                                    "Man pthread_key_create para destructors"
                                  ],
                                  "tips": "Destructors rodam na exit da thread; úteis para cleanup automático.",
                                  "learningObjective": "Implementar gerenciamento completo de lifecycle de TLS com destructors.",
                                  "commonMistakes": [
                                    "Free duplo no destructor",
                                    "Não chamar pthread_key_delete no final",
                                    "Ignorar leaks em multi-thread"
                                  ]
                                }
                              ],
                              "practicalExample": "Desenvolva um servidor multi-threaded simulado onde cada thread cliente armazena seu 'session ID' via TLS. Threads processam requests, acessam seu ID com getspecific para log personalizado, e limpam automaticamente no fim.",
                              "finalVerifications": [
                                "Programa compila e roda sem warnings ou erros pthread.",
                                "Múltiplas threads mostram valores TLS isolados nos logs.",
                                "pthread_getspecific retorna valores corretos e persistentes.",
                                "Destructors executam sem crashes ou leaks (valgrind clean).",
                                "Isolamento confirmado: matar uma thread não afeta outras.",
                                "Código lida com erros de pthread functions."
                              ],
                              "assessmentCriteria": [
                                "Correta criação e uso de pthread_key_create com destructor opcional.",
                                "Implementação precisa de setspecific e getspecific sem vazamentos.",
                                "Demonstração de isolamento TLS entre threads via testes.",
                                "Código limpo, com verificações de erro e comentários.",
                                "Uso de valgrind confirma ausência de memory issues.",
                                "Exemplo prático funcional e escalável."
                              ],
                              "crossCurricularConnections": [
                                "Programação Concorrente: Similar a __thread em C ou ThreadLocal em Java/Python.",
                                "Gerenciamento de Memória: Integra com malloc/free e detecção de leaks.",
                                "Design de Software: Padrões para estado por thread em apps escaláveis.",
                                "Sistemas Operacionais: Conceitos de TLS no kernel Linux.",
                                "Debugging: Uso de ferramentas como gdb/valgrind em multi-thread."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx multi-threaded, armazenar contexto de requisição por thread (ex: user session, connection handle) sem locks globais, melhorando performance e escalabilidade."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.2.4",
                            "name": "Compilar e executar programas Pthreads",
                            "description": "Configurar Makefiles ou comandos gcc com -pthread para compilar e depurar programas multi-threaded em ambientes Linux.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Verificar e Configurar Ambiente Linux com Suporte a Pthreads",
                                  "subSteps": [
                                    "Abra o terminal em uma distribuição Linux (ex: Ubuntu).",
                                    "Execute 'gcc --version' para confirmar instalação do GCC.",
                                    "Execute 'man pthread_create' ou 'ldd --version' para verificar bibliotecas pthread.",
                                    "Se necessário, instale com 'sudo apt update && sudo apt install build-essential libc6-dev'.",
                                    "Crie um diretório de trabalho: 'mkdir pthread_lab && cd pthread_lab'."
                                  ],
                                  "verification": "Comandos executam sem erros e pthread.h é encontrado via 'find /usr -name pthread.h'.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Terminal Linux",
                                    "Acesso sudo (se necessário)",
                                    "Editor de texto (vim/nano)"
                                  ],
                                  "tips": "Use distribuições como Ubuntu ou Fedora para compatibilidade máxima.",
                                  "learningObjective": "Configurar corretamente o ambiente de desenvolvimento para Pthreads.",
                                  "commonMistakes": [
                                    "Esquecer de atualizar pacotes antes de instalar",
                                    "Não verificar versão do GCC (precisa ser >=4.0)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Escrever um Programa Pthreads Simples",
                                  "subSteps": [
                                    "Crie um arquivo 'hello_pthread.c' com includes: #include <pthread.h>, <stdio.h>, <unistd.h>.",
                                    "Defina uma função thread: void* thread_func(void* arg) { printf('Hello from thread %ld\\n', (long)arg); return NULL; }.",
                                    "No main: pthread_t threads[3]; for(int i=0; i<3; i++) pthread_create(&threads[i], NULL, thread_func, (void*)i);",
                                    "Adicione pthread_join para sincronizar: for(int i=0; i<3; i++) pthread_join(threads[i], NULL);",
                                    "Salve e verifique sintaxe com 'gcc -Wall -c hello_pthread.c' (não linka ainda)."
                                  ],
                                  "verification": "Arquivo compila sem erros de sintaxe e código inclui pthread_create/join corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto",
                                    "Conhecimento básico de C"
                                  ],
                                  "tips": "Sempre inicialize pthread_t e use casts corretos em argumentos.",
                                  "learningObjective": "Criar um programa multi-threaded funcional com criação e join de threads.",
                                  "commonMistakes": [
                                    "Esquecer #include <pthread.h>",
                                    "Não chamar pthread_join levando a threads zumbis",
                                    "Passar argumentos sem cast para void*"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Compilar o Programa Usando GCC com Flag -pthread",
                                  "subSteps": [
                                    "Execute 'gcc -pthread -o hello_pthread hello_pthread.c' no terminal.",
                                    "Verifique erros de linkagem; a flag -pthread habilita bibliotecas e defines.",
                                    "Se erro, teste 'gcc -pthread -Wall -g -o hello_pthread hello_pthread.c'.",
                                    "Confirme binário: 'ls -la hello_pthread' e 'file hello_pthread' (deve ser ELF executable).",
                                    "Teste compilação estática opcional: 'gcc -static -pthread -o hello_pthread_static hello_pthread.c'."
                                  ],
                                  "verification": "Binário 'hello_pthread' é gerado sem warnings/erros e tamanho >0.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "GCC instalado",
                                    "Terminal"
                                  ],
                                  "tips": "A flag -pthread é essencial; -lpthread sozinho pode falhar em sistemas modernos.",
                                  "learningObjective": "Compilar programas Pthreads corretamente com flags apropriadas.",
                                  "commonMistakes": [
                                    "Usar -lpthread em vez de -pthread",
                                    "Ignorar warnings de thread-safety",
                                    "Compilar sem -Wall para depuração"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar, Depurar e Verificar o Programa Multi-threaded",
                                  "subSteps": [
                                    "Execute './hello_pthread' e observe saídas das 3 threads em ordem não-determinística.",
                                    "Para depuração: 'gdb ./hello_pthread', set breakpoint em thread_func, 'run'.",
                                    "Use 'ps aux | grep hello_pthread' para ver processos/threads durante execução.",
                                    "Teste race conditions adicionando variáveis compartilhadas e mutex se aplicável.",
                                    "Mate processo com Ctrl+C e analise output para paralelismo."
                                  ],
                                  "verification": "Programa roda, imprime mensagens de múltiplas threads e termina sem segfault.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "GDB instalado (sudo apt install gdb)",
                                    "Terminal"
                                  ],
                                  "tips": "Use -g na compilação para símbolos de debug; observe ordem não-linear das threads.",
                                  "learningObjective": "Executar e depurar programas Pthreads identificando comportamentos paralelos.",
                                  "commonMistakes": [
                                    "Executar sem permissões (chmod +x)",
                                    "Não usar gdb para crashes",
                                    "Esperar ordem sequencial nas prints"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Criar e Utilizar um Makefile para Compilação Automatizada",
                                  "subSteps": [
                                    "Crie 'Makefile' com: CC=gcc, CFLAGS=-pthread -Wall -g, hellop: hello_pthread.c \t $(CC) $(CFLAGS) -o hellop hello_pthread.c",
                                    "Adicione targets: clean: rm -f hellop *.o, all: hellop.",
                                    "Execute 'make' para compilar, 'make clean' para limpar.",
                                    "Teste variáveis: edite CFLAGS para -O2 e recompile com 'make clean && make'.",
                                    "Verifique dependências implícitas funcionam."
                                  ],
                                  "verification": "'make' compila sem erros, gera binário e 'make clean' remove arquivos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto",
                                    "Conhecimento básico de Make"
                                  ],
                                  "tips": "Use tabs para comandos no Makefile; evite espaços.",
                                  "learningObjective": "Automatizar compilação de Pthreads com Makefiles profissionais.",
                                  "commonMistakes": [
                                    "Usar espaços em vez de tabs",
                                    "Esquecer dependências em targets",
                                    "Não definir CFLAGS com -pthread"
                                  ]
                                }
                              ],
                              "practicalExample": "Crie 'hello_pthread.c' com 3 threads imprimindo 'Hello from thread X'. Compile: 'gcc -pthread -o hello hello_pthread.c'. Execute: './hello' (veja saídas embaralhadas). Makefile: CFLAGS=-pthread; hellop: $(CC) $(CFLAGS) -o $@ $<.",
                              "finalVerifications": [
                                "Programa compila sem erros usando gcc -pthread.",
                                "Execução mostra múltiplas threads rodando em paralelo (output não-sequencial).",
                                "GDB depura threads individualmente sem crashes.",
                                "Makefile automatiza build e clean corretamente.",
                                "Binário roda em diferentes terminais sem linkagem dinâmica falha.",
                                "Nenhum warning de thread-unsafe é gerado com -Wall."
                              ],
                              "assessmentCriteria": [
                                "Correto uso da flag -pthread na compilação.",
                                "Programa demonstra paralelismo real (joins e creates).",
                                "Makefile é funcional e idempotente.",
                                "Depuração básica com GDB é demonstrada.",
                                "Ambiente Linux configurado sem dependências pendentes.",
                                "Código limpo, sem leaks óbvios ou races simples."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Gerenciamento de processos e threads pelo kernel Linux.",
                                "Programação em C: Ponteiros, funções e estruturas de controle avançadas.",
                                "Depuração e Ferramentas: Uso de GDB e Make em fluxos DevOps.",
                                "Arquitetura de Computadores: Exploração de multi-core e escalabilidade.",
                                "Engenharia de Software: Automatização de builds e boas práticas."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx multi-threaded, processadores de dados paralelos em bancos (ex: PostgreSQL threads), ou aplicações de alto desempenho como renderização 3D e simulações científicas no Linux."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.4.3",
                        "name": "Decomposição de Domínio e Exclusão Mútua com Pthreads",
                        "description": "Aplicar técnicas de decomposição de domínio e mecanismos de exclusão mútua usando Pthreads para resolver problemas paralelos em memória compartilhada.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.4.3.1",
                            "name": "Implementar decomposição de domínio em tarefas paralelas",
                            "description": "Dividir um problema computacional (ex: matriz ou imagem) em domínios independentes atribuídos a threads, otimizando para plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar o Problema Sequencial e Identificar Oportunidades de Paralelização",
                                  "subSteps": [
                                    "Selecione um problema computacional intensivo, como o processamento de uma matriz NxN (ex: soma ou filtro simples).",
                                    "Implemente e execute a versão sequencial, medindo o tempo de execução com funções como clock() ou gettimeofday().",
                                    "Identifique loops aninhados ou regiões de computação independente sem dependências de dados entre iterações.",
                                    "Documente o tamanho da matriz (ex: 4096x4096) e o tempo baseline sequencial.",
                                    "Verifique a corretude do resultado sequencial como referência ouro."
                                  ],
                                  "verification": "Código sequencial executa corretamente, tempo baseline registrado (ex: >1s) e regiões paralelizáveis anotadas em um diagrama.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Compilador GCC",
                                    "Editor de código (VS Code ou similar)",
                                    "Matriz de teste em C (array 2D alocado dinamicamente)"
                                  ],
                                  "tips": "Escolha N grande o suficiente para overhead de threads ser desprezível; use alocação dinâmica para evitar limites de stack.",
                                  "learningObjective": "Compreender a estrutura do problema para mapear dependências e identificar domínios independentes.",
                                  "commonMistakes": [
                                    "Não medir tempo sequencial preciso",
                                    "Ignorar dependências de escrita em arrays compartilhados",
                                    "Usar matrizes muito pequenas que mascaram benefícios de paralelismo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Projetar a Decomposição do Domínio",
                                  "subSteps": [
                                    "Defina o número de threads (ex: 4, baseado em núcleos disponíveis via sysconf(_SC_NPROCESSORS_ONLN)).",
                                    "Divida o domínio em blocos independentes: para matriz, atribua faixas horizontais (linhas start-end por thread).",
                                    "Calcule tamanhos de blocos para balanceamento de carga (ex: linhas_por_thread = N / num_threads).",
                                    "Desenhe um diagrama mostrando domínios (ex: Thread 0: linhas 0-1023, Thread 1: 1024-2047).",
                                    "Planeje argumentos para threads: ponteiro para matriz, índices start/end, ID da thread."
                                  ],
                                  "verification": "Diagrama de decomposição criado sem overlaps ou gaps, e cálculos de blocos validados manualmente para N=4096 e 4 threads.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Papel ou ferramenta de diagrama (Draw.io)",
                                    "Código sequencial do Step 1",
                                    "Documentação Pthreads (man pthread)"
                                  ],
                                  "tips": "Priorize decomposição estática para problemas regulares; ajuste para divisões não-uniformes se N % num_threads != 0.",
                                  "learningObjective": "Dominar divisão espacial de domínios em sub-regiões independentes otimizadas para multicores.",
                                  "commonMistakes": [
                                    "Overlaps em índices causando recomputação",
                                    "Desbalanceamento de carga (blocos desiguais)",
                                    "Ignorar alinhamento de cache em blocos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar as Tarefas Paralelas com Pthreads",
                                  "subSteps": [
                                    "Inclua <pthread.h> e defina uma função worker(void* arg) que processe seu domínio (ex: somar linhas atribuídas).",
                                    "Crie estrutura de argumentos com matriz, start_row, end_row, thread_id e ponteiro para resultado parcial.",
                                    "No main: aloque matriz, crie array de pthread_t[num_threads], passe argumentos e chame pthread_create().",
                                    "Use pthread_join() para sincronizar e some resultados parciais no resultado global.",
                                    "Compile com gcc -o prog prog.c -pthread e teste com 1 thread para validar igualdade com sequencial."
                                  ],
                                  "verification": "Programa compila sem warnings, executa com 1 thread produzindo resultado idêntico ao sequencial.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Código base sequencial",
                                    "GCC com suporte pthread",
                                    "Exemplo de matriz 4096x4096 (use malloc)"
                                  ],
                                  "tips": "Use structs para argumentos thread-safe; evite globals sem locks (não necessário aqui por domínios independentes).",
                                  "learningObjective": "Implementar corretamente criação, execução e join de threads para decomposição de domínio.",
                                  "commonMistakes": [
                                    "Esquecer pthread_exit() ou return na worker",
                                    "Argumentos não passados corretamente (casting void*)",
                                    "Não chamar pthread_join() causando race em soma final"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar, Medir Performance e Otimizar",
                                  "subSteps": [
                                    "Execute com múltiplas threads (ex: 2,4,8) e meça tempos com múltiplas runs (média de 10).",
                                    "Calcule speedup (tempo_seq / tempo_par) e eficiência (speedup / num_threads).",
                                    "Perfilhe com tools como time ou gprof para identificar bottlenecks.",
                                    "Otimize: ajuste afinidade de threads (pthread_setaffinity_np) ou padding para cache lines.",
                                    "Compare resultados com sequencial e documente speedup observado."
                                  ],
                                  "verification": "Speedup >2x com 4 threads, resultados corretos (diff zero com sequencial), gráficos de speedup plotados.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "taskset ou numactl para pinning",
                                    "GNUPlot para gráficos",
                                    "Scripts bash para runs múltiplas"
                                  ],
                                  "tips": "Rode em máquina com hyper-threading off para medições puras; normalize por clock speed.",
                                  "learningObjective": "Avaliar e otimizar performance de decomposição paralela em hardware real.",
                                  "commonMistakes": [
                                    "Overhead de threads domina em matrizes pequenas",
                                    "Não average múltiplas runs ignorando variância",
                                    "Esquecer validação de corretude pós-paralelização"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente soma de elementos em uma matriz 4096x4096: versão sequencial soma todas entradas. Paralelize dividindo em 4 faixas horizontais (1024 linhas cada), cada thread soma sua faixa e main soma parciais. Meça speedup em quad-core.",
                              "finalVerifications": [
                                "Programa compila e executa sem segfaults ou erros de pthread.",
                                "Resultados paralelos idênticos ao sequencial (erro <1e-6).",
                                "Speedup linear até número de cores físicos.",
                                "Nenhum data race detectado (use ThreadSanitizer: -fsanitize=thread).",
                                "Tempo total <50% do sequencial com 4 threads.",
                                "Diagrama de decomposição e medições documentados."
                              ],
                              "assessmentCriteria": [
                                "Decomposição cobre todo domínio sem gaps/overlaps.",
                                "Balanceamento de carga com variação <10% entre threads.",
                                "Uso correto de pthread_create/join sem leaks (valgrind).",
                                "Medição de performance rigorosa com speedup quantificado.",
                                "Otimização aplicada (ex: cache-friendly access).",
                                "Código limpo, comentado e modular."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Impacto de caches L1/L2 em acesso a domínios.",
                                "Matemática Computacional: Divisão de grids em álgebra linear.",
                                "Algoritmos e Estruturas: Balanceamento de carga em divide-and-conquer.",
                                "Sistemas Operacionais: Scheduling de threads e afinidade NUMA.",
                                "Engenharia de Software: Modularidade em código paralelo."
                              ],
                              "realWorldApplication": "Em processamento de imagens (ex: filtros em Photoshop dividem pixels em tiles para GPUs/CPUs multicores), simulações científicas (CFD dividindo malhas espaciais em domínios por processo), e big data (processamento distribuído de grids em Hadoop/Spark)."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.3.2",
                            "name": "Usar mutex para exclusão mútua com pthread_mutex_init e lock",
                            "description": "Proteger seções críticas compartilhadas com pthread_mutex_lock/unlock, incluindo inicialização dinâmica e destruição de mutexes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Conceitos Fundamentais de Mutex e Seções Críticas",
                                  "subSteps": [
                                    "Leia a documentação do man pthread_mutex_init, pthread_mutex_lock e pthread_mutex_unlock.",
                                    "Identifique o que é uma seção crítica em um programa multi-threaded.",
                                    "Explique em suas palavras o problema de condição de corrida (race condition) sem proteção.",
                                    "Desenhe um diagrama simples mostrando threads acessando uma variável compartilhada sem e com mutex.",
                                    "Compile e execute um exemplo básico de race condition para observar o problema."
                                  ],
                                  "verification": "Você pode descrever verbalmente ou por escrito o que é uma seção crítica e por que mutex é necessário, e demonstrar um race condition rodando.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Editor de texto (VS Code ou similar), GCC com suporte a pthreads (-pthread), terminal, man pages (man pthread_mutex).",
                                  "tips": "Use pthread_create para criar threads simples que incrementam um contador compartilhado sem proteção primeiro.",
                                  "learningObjective": "Compreender o papel do mutex na prevenção de acessos concorrentes a recursos compartilhados.",
                                  "commonMistakes": "Confundir mutex com semáforos ou assumir que variáveis locais são seguras em threads."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Inicializar Mutex Dinamicamente com pthread_mutex_init",
                                  "subSteps": [
                                    "Inclua <pthread.h> e declare um pthread_mutex_t *mutex dinamicamente com malloc.",
                                    "Chame pthread_mutex_init(mutex, NULL) para inicialização básica (default attributes).",
                                    "Verifique o retorno de pthread_mutex_init (deve ser 0 para sucesso).",
                                    "Crie duas threads que acessem uma seção crítica simulada.",
                                    "Compile com gcc -o programa programa.c -pthread."
                                  ],
                                  "verification": "O programa compila sem erros e pthread_mutex_init retorna 0, confirmado por printf ou logs.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "GCC, terminal, código-fonte inicial com threads básicas.",
                                  "tips": "Sempre inicialize mutex antes de usá-lo; use atributos NULL para simplicidade inicial.",
                                  "learningObjective": "Dominar a alocação e inicialização dinâmica de mutexes em Pthreads.",
                                  "commonMistakes": "Esquecer de alocar memória para o mutex ou não verificar erros de inicialização."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Proteção de Seção Crítica com pthread_mutex_lock e unlock",
                                  "subSteps": [
                                    "Na seção crítica de cada thread, chame pthread_mutex_lock(mutex) antes de acessar o recurso compartilhado.",
                                    "Execute operações críticas (ex: incrementar contador).",
                                    "Chame pthread_mutex_unlock(mutex) imediatamente após a seção crítica.",
                                    "Adicione prints para visualizar a ordem de lock/unlock entre threads.",
                                    "Execute o programa múltiplas vezes para confirmar saída consistente (sem race conditions)."
                                  ],
                                  "verification": "O contador compartilhado atinge o valor esperado (ex: 1000 após 1000 incrementos) em todas as execuções.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código do step anterior, debugger como gdb (opcional).",
                                  "tips": "Mantenha seções críticas o mais curtas possível para minimizar deadlock risks.",
                                  "learningObjective": "Aplicar lock e unlock corretamente para sincronizar acesso a seções críticas.",
                                  "commonMistakes": "Esquecer unlock (causa deadlock), ou unlock antes de lock."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Destruir Mutex e Gerenciar Erros Completos",
                                  "subSteps": [
                                    "Após join das threads, chame pthread_mutex_destroy(mutex).",
                                    "Libere a memória alocada para o mutex com free(mutex).",
                                    "Adicione tratamento de erros para todas as chamadas pthread (if(ret != 0) perror).",
                                    "Teste cenários de erro, como inicializar mutex já inicializado.",
                                    "Documente o código com comentários explicando cada mutex call."
                                  ],
                                  "verification": "Programa executa sem leaks (verifique com valgrind) e mutex é destruído sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Valgrind (valgrind --tool=memcheck ./programa), código completo.",
                                  "tips": "Nunca destrua mutex locked; use pthread_mutex_trylock para diagnósticos avançados.",
                                  "learningObjective": "Gerenciar ciclo de vida completo do mutex, incluindo cleanup e error handling.",
                                  "commonMistakes": "Destruir mutex ainda em uso ou esquecer free após destroy."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar e Validar a Implementação em Cenário Realista",
                                  "subSteps": [
                                    "Aumente o número de threads (ex: 10) e iterações para estressar o mutex.",
                                    "Use gdb ou printf para depurar deadlocks potenciais.",
                                    "Compare performance com e sem mutex (use clock_gettime para timing).",
                                    "Refatore para usar mutex em uma estrutura de dados compartilhada (ex: lista ligada).",
                                    "Escreva um teste unitário simples para verificar atomicidade."
                                  ],
                                  "verification": "Sem race conditions em 100 execuções, performance degradada esperada com mutex (overhead normal).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "GDB, Valgrind, código estressado.",
                                  "tips": "Monitore com strace para syscalls de futex (base do mutex).",
                                  "learningObjective": "Validar robustez da sincronização em cenários multi-threaded complexos.",
                                  "commonMistakes": "Ignorar overhead do mutex ou não testar com cargas altas."
                                }
                              ],
                              "practicalExample": "Implemente um contador global compartilhado entre 5 threads, cada uma incrementando 2000 vezes. Sem mutex, resultado varia (ex: 8500-9500); com mutex, sempre 10000. Código: pthread_mutex_t *mutex = malloc(sizeof(pthread_mutex_t)); pthread_mutex_init(mutex, NULL); em thread: lock -> counter++ -> unlock.",
                              "finalVerifications": [
                                "Compilação bem-sucedida com -pthread sem warnings.",
                                "Execução consistente sem race conditions em múltiplas runs.",
                                "Valgrind mostra no memory leaks ou erros de mutex.",
                                "Tratamento de erros cobre todos retornos !=0.",
                                "Deadlock ausente em testes estressados.",
                                "Documentação no código explica fluxo de sincronização."
                              ],
                              "assessmentCriteria": [
                                "Correta inicialização/destruição dinâmica do mutex (20%).",
                                "Uso preciso de lock/unlock delimitando seção crítica (30%).",
                                "Tratamento de erros e verificações de retorno (15%).",
                                "Consistência de resultados em execuções multi-threaded (20%).",
                                "Eficiência: seção crítica mínima e sem deadlocks (10%).",
                                "Clareza do código com comentários (5%)."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Entendimento de primitivas de sincronização kernel-level (futex).",
                                "Algoritmos e Estruturas de Dados: Sincronização em ADTs thread-safe.",
                                "Engenharia de Software: Princípios de thread-safety e design concurrente.",
                                "Desempenho e Otimização: Análise de overhead de locking."
                              ],
                              "realWorldApplication": "Em servidores web multi-threaded como Apache ou Nginx, mutexes protegem estruturas compartilhadas como pools de conexões ou caches, evitando corrupção de dados em ambientes de alta concorrência."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.3.3",
                            "name": "Aplicar condições com pthread_cond_wait e signal",
                            "description": "Implementar sincronização produtor-consumidor usando pthread_cond_wait, signal e broadcast junto com mutex para coordenação entre threads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar estruturas de sincronização básicas",
                                  "subSteps": [
                                    "Incluir cabeçalhos necessários: #include <pthread.h>, #include <stdio.h>, #include <unistd.h> e #include <stdlib.h>",
                                    "Definir constantes como TAM_BUFFER = 5 e variáveis globais para buffer (int buffer[TAM_BUFFER]), int count = 0, int in = 0, int out = 0",
                                    "Declarar pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; e pthread_cond_t notFull = PTHREAD_COND_INITIALIZER;, pthread_cond_t notEmpty = PTHREAD_COND_INITIALIZER;",
                                    "No main(), inicializar explicitamente com pthread_mutex_init(&mutex, NULL); pthread_cond_init(&notFull, NULL); pthread_cond_init(&notEmpty, NULL);",
                                    "Verificar retornos de inicialização (if (ret != 0) { perror(\"Init falhou\"); exit(1); })"
                                  ],
                                  "verification": "Compilar e executar um programa de teste simples que inicializa e destrói as estruturas sem erros (pthread_mutex_destroy e pthread_cond_destroy no final).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Editor de texto (VS Code ou Vim)",
                                    "Compilador GCC com flag -lpthread",
                                    "Terminal para compilar: gcc -o prodcons prodcons.c -lpthread"
                                  ],
                                  "tips": "Use PTHREAD_MUTEX_INITIALIZER para simplicidade inicial, mas prefira pthread_mutex_init para controle de atributos.",
                                  "learningObjective": "Dominar a inicialização correta de mutex e variáveis de condição em Pthreads.",
                                  "commonMistakes": [
                                    "Esquecer de incluir <pthread.h>",
                                    "Não verificar códigos de retorno das funções init",
                                    "Inicializar variáveis estáticas sem PTHREAD_..._INITIALIZER"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a lógica do produtor",
                                  "subSteps": [
                                    "Definir void* producer(void* arg) com loop while(1) ou por N iterações",
                                    "pthread_mutex_lock(&mutex);",
                                    "while (count == TAM_BUFFER) { pthread_cond_wait(&notFull, &mutex); } // Espera buffer não cheio",
                                    "buffer[in] = rand() % 100; in = (in + 1) % TAM_BUFFER; count++; printf(\"Produzido: %d\\n\", buffer[(in-1)%TAM_BUFFER]);",
                                    "pthread_cond_signal(&notEmpty); // Acorda consumidor",
                                    "pthread_mutex_unlock(&mutex);",
                                    "usleep(100000); // Simula tempo de produção"
                                  ],
                                  "verification": "Executar produtor isolado com buffer mock: deve produzir até encher e parar sem erros de segmentação.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código base do Step 1",
                                    "Ferramenta de debug como gdb: gdb ./prodcons"
                                  ],
                                  "tips": "O wait libera o mutex automaticamente e o readquire ao retornar; signal só acorda um thread.",
                                  "learningObjective": "Aplicar pthread_cond_wait para aguardar condição e signal para notificar.",
                                  "commonMistakes": [
                                    "Fazer signal antes de unlock",
                                    "Usar broadcast em vez de signal desnecessariamente",
                                    "Esquecer de incrementar count após produzir"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a lógica do consumidor",
                                  "subSteps": [
                                    "Definir void* consumer(void* arg) similar ao produtor",
                                    "pthread_mutex_lock(&mutex);",
                                    "while (count == 0) { pthread_cond_wait(&notEmpty, &mutex); } // Espera buffer não vazio",
                                    "int item = buffer[out]; out = (out + 1) % TAM_BUFFER; count--; printf(\"Consumido: %d\\n\", item);",
                                    "pthread_cond_signal(&notFull); // Acorda produtor",
                                    "pthread_mutex_unlock(&mutex);",
                                    "usleep(150000); // Simula tempo de consumo"
                                  ],
                                  "verification": "Rodar com produtor e consumidor: saída deve mostrar produção e consumo alternados sem perda de itens ou deadlocks.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código completo até Step 2",
                                    "Valgrind para checar memory leaks: valgrind --tool=memcheck ./prodcons"
                                  ],
                                  "tips": "Use while em vez de if no wait para spurious wakeups (condição pode não valer ao acordar).",
                                  "learningObjective": "Implementar coordenação simétrica entre produtor e consumidor com condições.",
                                  "commonMistakes": [
                                    "Signal na condição errada (ex: signal notFull no produtor)",
                                    "Não usar buffer circular corretamente",
                                    "Unlock antes de signal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Criar threads, executar e finalizar",
                                  "subSteps": [
                                    "No main(), criar pthread_t prod_thread, cons_thread;",
                                    "pthread_create(&prod_thread, NULL, producer, NULL); pthread_create(&cons_thread, NULL, consumer, NULL);",
                                    "pthread_join(prod_thread, NULL); pthread_join(cons_thread, NULL); // Ou sleep para teste",
                                    "Finalizar: pthread_mutex_destroy(&mutex); pthread_cond_destroy(&notFull, NULL); pthread_cond_destroy(&notEmpty, NULL);",
                                    "Compilar e executar múltiplas vezes, observando saídas"
                                  ],
                                  "verification": "Programa roda por 10s sem crashes, deadlocks ou race conditions (use printf com timestamps).",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Código completo",
                                    "strace para tracear syscalls de threads"
                                  ],
                                  "tips": "Use pthread_join para sincronizar finalização; adicione args para número de itens.",
                                  "learningObjective": "Gerenciar ciclo de vida de threads com criação, join e cleanup de sincronizadores.",
                                  "commonMistakes": [
                                    "Não chamar destroy nas estruturas",
                                    "Criar threads sem join (zumbis)",
                                    "Ignorar erros de pthread_create"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um produtor-consumidor com buffer circular de 5 posições. O produtor gera números aleatórios (0-99) e os insere; o consumidor os remove e imprime. Execute por 10 segundos: saída deve mostrar ~50 produções/consumos sem overflows/underflows ou impressões duplicadas.",
                              "finalVerifications": [
                                "O programa compila e executa sem warnings ou erros de runtime por pelo menos 30 execuções",
                                "Não há deadlocks: threads alternam corretamente sem travar",
                                "Buffer nunca excede capacidade (count <= TAM_BUFFER) nem vai negativo",
                                "Todos os signals e waits são pareados corretamente (use contadores de debug)",
                                "Valgrind relata zero leaks ou invalid accesses",
                                "Saída mostra produção/consumo balanceados (aprox. mesmo número de cada)"
                              ],
                              "assessmentCriteria": [
                                "Uso correto de pthread_cond_wait com mutex (liberação/readquire automática)",
                                "Condições checadas em loop while (proteção contra spurious wakeups)",
                                "Signals enviados na condição apropriada (notFull pelo consumidor, notEmpty pelo produtor)",
                                "Mutex locked antes de acessar buffer e unlocked após signal",
                                "Inicialização e destruição adequadas de todas as primitivas",
                                "Tratamento de erros em funções pthread (checagem de retornos)"
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Primitivas de sincronização e escalonamento de threads",
                                "Estruturas de Dados: Buffers circulares e filas thread-safe",
                                "Algoritmos: Padrão Produtor-Consumidor e decomposição de tarefas paralelas",
                                "Segurança da Informação: Evitar race conditions em acessos compartilhados"
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx multi-threaded, queues de tarefas em bancos de dados (ex: PostgreSQL connection pools) ou simuladores de sistemas embarcados para processar sensores em tempo real sem perda de dados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.3.4",
                            "name": "Avaliar desempenho com speedup e eficiência",
                            "description": "Medir tempo de execução serial vs. paralelo usando clock_gettime, calcular speedup e eficiência, identificando gargalos como overhead de threads.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Implementar e cronometrar a versão sequencial do programa",
                                  "subSteps": [
                                    "Escreva um programa sequencial em C que realize uma tarefa computacional intensiva, como soma de elementos de um grande array (ex: 1e8 elementos).",
                                    "Inclua as chamadas clock_gettime(CLOCK_MONOTONIC, &start) antes da seção crítica e clock_gettime(CLOCK_MONOTONIC, &end) após, calculando o tempo em segundos: (end.tv_sec - start.tv_sec) + (end.tv_nsec - start.tv_nsec) / 1e9.",
                                    "Compile com gcc -o serial serial.c e execute múltiplas vezes (pelo menos 10) em ambiente controlado (sem outras cargas).",
                                    "Registre os tempos e calcule a média para tempo_serial.",
                                    "Salve o resultado em um arquivo log com timestamp."
                                  ],
                                  "verification": "O programa compila sem erros, executa corretamente produzindo o resultado esperado (ex: soma correta) e gera tempo_serial médio acima de 0.1s.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Editor de código (VSCode ou similar)",
                                    "Compilador GCC",
                                    "Terminal Linux",
                                    "Código base serial.c"
                                  ],
                                  "tips": [
                                    "Desabilite otimizações do compilador (-O0) para medições realistas.",
                                    "Execute em CPU isolada com taskset para evitar migração de threads."
                                  ],
                                  "learningObjective": "Dominar o uso preciso de clock_gettime para medição de tempo de CPU em código sequencial.",
                                  "commonMistakes": [
                                    "Usar time() em vez de clock_gettime, perdendo precisão em nanossegundos.",
                                    "Não zerar o array ou variáveis acumuladoras, afetando resultados."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Desenvolver a versão paralela com Pthreads",
                                  "subSteps": [
                                    "Modifique o código sequencial para dividir o array em chunks iguais para N threads (ex: N=4).",
                                    "Crie uma função thread_worker que processe um chunk, usando pthread_create para lançar threads e pthread_join para sincronizar.",
                                    "Inclua proteção de dados compartilhados com mutex se necessário (ex: para soma global).",
                                    "Compile com gcc -o parallel parallel.c -pthread e teste funcionalidade sem timing.",
                                    "Ajuste alocação de chunks dinamicamente com base em array_size / num_threads."
                                  ],
                                  "verification": "Programa compila com -pthread, todas as threads executam e pthread_join completa sem erros, produzindo soma correta.",
                                  "estimatedTime": "30-40 minutos",
                                  "materials": [
                                    "Código serial.c como base",
                                    "Documentação Pthreads (man pthread_create)",
                                    "Compilador GCC com pthread",
                                    "Terminal"
                                  ],
                                  "tips": [
                                    "Use argumentos de thread com struct para passar chunk_start e chunk_end.",
                                    "Inicialize mutex com PTHREAD_MUTEX_INITIALIZER."
                                  ],
                                  "learningObjective": "Implementar decomposição de domínio em Pthreads com divisão de trabalho estática.",
                                  "commonMistakes": [
                                    "Race conditions na soma global sem mutex.",
                                    "Não chamar pthread_join, causando saída prematura do programa."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Cronometrar a versão paralela e coletar dados",
                                  "subSteps": [
                                    "Adicione clock_gettime antes de pthread_create e após pthread_join para capturar tempo_paralelo total.",
                                    "Execute o programa paralelo 10+ vezes variando num_threads (2,4,8) e registre tempos médios para cada.",
                                    "Meça também com diferentes tamanhos de array para observar escalabilidade.",
                                    "Salve todos os tempos_paralelo[num_threads] em log.",
                                    "Compare visualmente se tempo_paralelo < tempo_serial."
                                  ],
                                  "verification": "Tempos_paralelo medidos para múltiplos num_threads, com valores menores que tempo_serial e sem crashes de threads.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Código parallel.c atualizado",
                                    "GCC",
                                    "Scripts bash para automação de runs (opcional)",
                                    "Planilha para logs"
                                  ],
                                  "tips": [
                                    "Warm-up run antes de medições para encher caches.",
                                    "Fixe affinity de threads com pthread_setaffinity_np."
                                  ],
                                  "learningObjective": "Medir overhead de criação/sincronização de threads em execuções paralelas.",
                                  "commonMistakes": [
                                    "Medir tempo por thread em vez de wall-clock total.",
                                    "Ignorar overhead de pthread_create em workloads pequenos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular speedup e eficiência",
                                  "subSteps": [
                                    "Calcule speedup[num_threads] = tempo_serial / tempo_paralelo[num_threads].",
                                    "Calcule efficiency[num_threads] = speedup[num_threads] / num_threads * 100%.",
                                    "Crie uma tabela ou gráfico simples (com gnuplot ou Excel) plotando speedup e efficiency vs num_threads.",
                                    "Interprete: speedup deve aproximar num_threads idealmente, efficiency cair devido a overhead.",
                                    "Salve cálculos em relatório com fórmulas explícitas."
                                  ],
                                  "verification": "Tabela com speedup >1 para num_threads>1 e efficiency entre 0-100%, com fórmulas corretas.",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Logs de tempos",
                                    "Calculadora ou Python para fórmulas",
                                    "Gnuplot ou LibreOffice Calc"
                                  ],
                                  "tips": [
                                    "Use média de múltiplas runs para robustez.",
                                    "Normalize por workload size."
                                  ],
                                  "learningObjective": "Aplicar métricas padrão de performance paralela: speedup de Amdahl e eficiência.",
                                  "commonMistakes": [
                                    "Inverter fórmula de speedup (paralelo/serial).",
                                    "Esquecer de dividir por num_threads na efficiency."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Identificar e analisar gargalos de performance",
                                  "subSteps": [
                                    "Compare tempos: identifique quando speedup satura (ex: overhead de threads domina).",
                                    "Meça overhead isolado: tempo para criar/join N threads sem workload.",
                                    "Analise eficiência baixa: liste causas como contenção de mutex, falsos compartilhamentos, balanceamento de load.",
                                    "Sugira otimizações: decomposição dinâmica, redução de sincronizações.",
                                    "Documente em relatório com evidências numéricas."
                                  ],
                                  "verification": "Relatório lista pelo menos 3 gargalos com métricas de suporte (ex: overhead >20% do tempo total).",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Logs e tabelas anteriores",
                                    "Profiler como gprof ou perf (opcional)",
                                    "Papel para diagrama de gargalos"
                                  ],
                                  "tips": [
                                    "Use strace para overhead de syscalls.",
                                    "Teste com workloads variados (memory-bound vs compute-bound)."
                                  ],
                                  "learningObjective": "Diagnosticar limitações de paralelismo em Pthreads, como overhead e escalabilidade.",
                                  "commonMistakes": [
                                    "Atribuir queda de efficiency só a 'overhead' sem quantificar.",
                                    "Ignorar impacto de cache em multi-threading."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de soma de array de 1e9 doubles: serial leva 3.2s (média 10 runs). Com 4 threads: 1.1s (speedup=2.91, efficiency=72.75%). Gargalo: overhead de pthread_create (~0.05s) e contenção em mutex de soma (~15% do tempo).",
                              "finalVerifications": [
                                "Códigos serial e paralelo produzem resultados idênticos.",
                                "Tempos medidos com clock_gettime para pelo menos 3 configurações de threads.",
                                "Speedup calculado corretamente >1 em casos paralelizáveis.",
                                "Efficiency <100% com análise de原因.",
                                "Relatório identifica pelo menos 2 gargalos quantificados.",
                                "Gráfico de speedup vs threads mostra tendência realista."
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições: variância <5% entre runs.",
                                "Correção matemática: fórmulas de speedup/efficiency exatas.",
                                "Profundidade de análise: gargalos quantificados com evidências.",
                                "Qualidade do código: sem leaks de threads, compilação limpa.",
                                "Relatório claro: tabelas, gráficos e conclusões acionáveis.",
                                "Escalabilidade testada: múltiplos num_threads e workloads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo de razões, médias e análise estatística de dados experimentais.",
                                "Arquitetura de Computadores: Compreensão de caches, pipelines e overhead de context switch.",
                                "Algoritmos e Estruturas: Decomposição de problemas e balanceamento de carga.",
                                "Sistemas Operacionais: Gerenciamento de threads, sincronização e escalonamento."
                              ],
                              "realWorldApplication": "Otimização de aplicações em servidores multicore como bancos de dados (ex: MySQL parallel queries), processamento de big data (HPC clusters), treinamento de ML (distribuição de workloads em GPUs/TPUs) e simulações científicas, onde speedup >2x justifica complexidade de paralelismo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.5",
                    "name": "Abordagens Paralelas na Nuvem",
                    "description": "Linguagens e frameworks para programação paralela em ambientes de nuvem, incluindo estudo de casos.",
                    "individualConcepts": [
                      {
                        "id": "64.1.1.1",
                        "name": "Modelos de Programação Paralela para Memória Distribuída na Nuvem",
                        "description": "Compreensão dos principais modelos de programação paralela adaptados para ambientes de nuvem com memória distribuída, incluindo troca de mensagens, decomposição de domínio e relação com taxonomia de Flynn e modelos de memória.",
                        "specificSkills": [
                          {
                            "id": "64.1.1.1.1",
                            "name": "Identificar a Taxonomia de Flynn em Contextos de Nuvem",
                            "description": "Explicar as classes da taxonomia de Flynn (SISD, SIMD, MISD, MIMD) e exemplificar sua aplicação em arquiteturas de nuvem distribuídas, como clusters MIMD.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Pesquise a origem da Taxonomia de Flynn, criada por Michael J. Flynn em 1966.",
                                    "Defina os eixos principais: número de instruções (Single Instruction - SI, Multiple Instructions - MI) e número de dados (Single Data - SD, Multiple Data - MD).",
                                    "Crie um diagrama 2x2 representando as quatro classes: SISD, SIMD, MISD, MIMD.",
                                    "Compare com arquiteturas sequenciais tradicionais para destacar a transição para paralelismo.",
                                    "Anote definições chave em um glossário pessoal."
                                  ],
                                  "verification": "Você pode desenhar o diagrama 2x2 corretamente e explicar cada quadrante em voz alta.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Acesso à internet para artigos sobre Flynn (Wikipedia, IEEE papers)",
                                    "Papel e caneta ou ferramenta de diagrama como Draw.io"
                                  ],
                                  "tips": "Use mnemônicos como 'SI-SD é sequencial, MI-MD é massivamente paralelo' para memorizar.",
                                  "learningObjective": "Dominar a estrutura conceitual da taxonomia e seus eixos classificatórios.",
                                  "commonMistakes": [
                                    "Confundir instruções com dados",
                                    "Ignorar o contexto histórico",
                                    "Não visualizar o diagrama 2x2"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Detalhar Cada Classe da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude SISD: Exemplo von Neumann, uma instrução processa um dado por vez.",
                                    "Analise SIMD: Instrução única em múltiplos dados, como vetores em GPUs.",
                                    "Explore MISD: Múltiplas instruções em um dado, raro, como fault-tolerant systems.",
                                    "Descreva MIMD: Múltiplas instruções em múltiplos dados, comum em multicore e clusters.",
                                    "Crie uma tabela comparativa com características, vantagens e desvantagens de cada."
                                  ],
                                  "verification": "Preencha um quiz autoavaliativo listando definições e um exemplo para cada classe.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Tabela em Excel ou Google Sheets",
                                    "Vídeos tutoriais no YouTube sobre Flynn's Taxonomy"
                                  ],
                                  "tips": "Associe SIMD a processadores gráficos (ex: pixels em imagem) e MIMD a servidores independentes.",
                                  "learningObjective": "Diferenciar precisamente as quatro classes com exemplos clássicos.",
                                  "commonMistakes": [
                                    "Confundir SIMD com MIMD",
                                    "Subestimar raridade do MISD",
                                    "Não listar exemplos concretos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Relacionar a Taxonomia com Arquiteturas de Nuvem Distribuídas",
                                  "subSteps": [
                                    "Identifique como nuvens usam memória distribuída (não compartilhada).",
                                    "Mapeie SISD para instâncias únicas em nuvem (ex: VM básica).",
                                    "Exemplifique SIMD em serviços como Apache Spark para processamento vetorial.",
                                    "Discuta MIMD em clusters como Kubernetes ou AWS EC2 fleets.",
                                    "Analise por que MIMD domina nuvens: escalabilidade e independência de nós."
                                  ],
                                  "verification": "Crie um mapa mental ligando cada classe a um serviço de nuvem específico.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Documentação AWS/Google Cloud sobre clusters",
                                    "Ferramenta de mind mapping como MindMeister"
                                  ],
                                  "tips": "Pense em nuvens como 'fazendas de MIMD' onde cada nó é independente.",
                                  "learningObjective": "Conectar teoricamente a taxonomia a ambientes de computação distribuída na nuvem.",
                                  "commonMistakes": [
                                    "Assumir compartilhamento de memória em nuvens",
                                    "Ignorar latência de rede em MIMD"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Identificar a Taxonomia em Cenários Práticos de Nuvem",
                                  "subSteps": [
                                    "Escolha um cluster MIMD real (ex: Hadoop em AWS EMR) e classifique seus componentes.",
                                    "Simule identificação: 'Qual classe para workers processando dados independentes?'",
                                    "Compare com SIMD em ML training (ex: TensorFlow distributed).",
                                    "Debata limitações: Quando MISD poderia ser útil em nuvens fault-tolerant?",
                                    "Documente um caso de estudo curto (1 página)."
                                  ],
                                  "verification": "Apresente seu caso de estudo a um colega ou grave um vídeo explicando a classificação.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Conta gratuita AWS/GCP para visualizar clusters",
                                    "Templates de caso de estudo"
                                  ],
                                  "tips": "Use comandos como 'kubectl get pods' em Minikube para visualizar MIMD na prática.",
                                  "learningObjective": "Identificar autonomamente a taxonomia em arquiteturas de nuvem reais.",
                                  "commonMistakes": [
                                    "Classificar erroneamente clusters como SISD",
                                    "Não considerar rede distribuída"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster Hadoop no AWS EMR (MIMD), o NameNode gerencia metadados (SISD-like), enquanto DataNodes processam blocos independentes com instruções variadas (MIMD), permitindo escalabilidade para big data.",
                              "finalVerifications": [
                                "Liste e defina corretamente SISD, SIMD, MISD e MIMD.",
                                "Classifique um cluster Kubernetes como MIMD com justificativa.",
                                "Desenhe o diagrama 2x2 da taxonomia.",
                                "Forneça um exemplo de SIMD em nuvem (ex: GPU instances).",
                                "Explique por que MIMD é dominante em nuvens distribuídas.",
                                "Identifique um cenário onde SISD ainda é usado na nuvem."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições (90% correto).",
                                "Uso correto de exemplos em contexto de nuvem.",
                                "Profundidade na análise de MIMD vs. outras classes.",
                                "Clareza no diagrama e mapeamentos.",
                                "Capacidade de relacionar a cenários reais sem erros comuns.",
                                "Criatividade em aplicações práticas."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Latência e comunicação em MIMD distribuído.",
                                "Big Data: Paralelismo SIMD/MIMD em Spark/Hadoop.",
                                "Inteligência Artificial: Treinamento distribuído em GPUs (SIMD).",
                                "Sistemas Operacionais: Gerenciamento de processos paralelos em clusters.",
                                "Engenharia de Software: Modelos de programação para memória distribuída."
                              ],
                              "realWorldApplication": "Profissionais de DevOps usam essa taxonomia para otimizar clusters em AWS/GCP, escolhendo MIMD para workloads escaláveis como ML training ou ETL em big data, reduzindo custos e tempo de processamento em até 70%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.1.1.1.2",
                            "name": "Descrever Troca de Mensagens em Ambientes Distribuídos",
                            "description": "Detalhar o modelo de troca de mensagens (Message Passing) usando padrões como MPI, e sua implementação em plataformas de nuvem para comunicação entre nós independentes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos de Message Passing em Ambientes Distribuídos",
                                  "subSteps": [
                                    "Defina Message Passing como um modelo de comunicação assíncrona entre processos independentes sem memória compartilhada.",
                                    "Compare com modelos de memória compartilhada, destacando independência de nós e escalabilidade em nuvem.",
                                    "Identifique componentes chave: processos, mensagens (dados + tags), buffers de envio/recebimento.",
                                    "Estude primitivas básicas: send (envio bloqueante/não-bloqueante), receive (recebimento seletivo/poliado).",
                                    "Analise desafios como latência de rede, deadlocks e ordenação de mensagens."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando message passing vs. memória compartilhada, com exemplos de primitivas.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Documentação MPI oficial (mpi-forum.org), slides introdutórios sobre programação paralela distribuída.",
                                  "tips": "Use diagramas para visualizar fluxos de mensagens entre nós.",
                                  "learningObjective": "Entender o paradigma de message passing e suas vantagens em ambientes distribuídos.",
                                  "commonMistakes": "Confundir com RPC (síncrono) ou assumir memória compartilhada em nós independentes."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a Interface MPI (Message Passing Interface)",
                                  "subSteps": [
                                    "Instale MPICH ou OpenMPI localmente para testes iniciais.",
                                    "Aprenda inicializadores: MPI_Init(), MPI_Comm_size(), MPI_Comm_rank(), MPI_Finalize().",
                                    "Implemente MPI_Send() e MPI_Recv() em um programa simples de 'hello world' distribuído.",
                                    "Estude coletivos: MPI_Bcast(), MPI_Reduce(), MPI_Scatter(), MPI_Gather().",
                                    "Compile e execute com mpirun para múltiplos processos."
                                  ],
                                  "verification": "Compile e execute um programa MPI que imprima ranks e troque mensagens simples entre 4 processos.",
                                  "estimatedTime": "3 horas",
                                  "materials": "OpenMPI ou MPICH instaladores, editor de código (VS Code), terminal com mpirun.",
                                  "tips": "Sempre verifique erros com MPI_SUCCESS e use tags em mensagens para seletividade.",
                                  "learningObjective": "Dominar as primitivas básicas e coletivas do MPI para comunicação ponto-a-ponto e grupal.",
                                  "commonMistakes": "Esquecer MPI_Init/Finalize, causando crashes; não especificar contadores em MPI_Send/Recv."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar MPI em Plataformas de Nuvem",
                                  "subSteps": [
                                    "Escolha uma plataforma (ex: AWS EC2, Google Cloud Compute Engine) e crie instâncias multi-nós.",
                                    "Instale MPI em cluster de VMs (use scripts de bootstrap como cloud-init).",
                                    "Configure rede: abra portas para MPI (geralmente SSH e portas dinâmicas), use hostsfile para mpirun.",
                                    "Teste conectividade com ping e MPI ping-pong benchmark.",
                                    "Integre com orquestradores como Kubernetes para escalabilidade (MPI operators)."
                                  ],
                                  "verification": "Execute mpirun em múltiplas VMs na nuvem, confirmando comunicação entre nós remotos.",
                                  "estimatedTime": "4 horas",
                                  "materials": "Conta AWS/GCP gratuita, imagens de VM Ubuntu, chaves SSH, script de instalação MPI.",
                                  "tips": "Use instâncias spot para economia; monitore logs de firewall e MPI para erros de rede.",
                                  "learningObjective": "Configurar e validar ambientes distribuídos na nuvem para execução MPI.",
                                  "commonMistakes": "Ignorar firewalls de nuvem bloqueando portas; hostsfile incorreto causando falhas de rank."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e Otimizar Troca de Mensagens em Aplicações Distribuídas",
                                  "subSteps": [
                                    "Desenvolva um exemplo de redução paralela (soma de vetores distribuídos via MPI_Reduce).",
                                    "Implemente não-bloqueante: MPI_Isend() / MPI_Irecv() com MPI_Waitall().",
                                    "Otimize para nuvem: use MPI-IO para I/O paralelo, gerencie topologias com MPI_Cart_create().",
                                    "Profile performance com ferramentas como TAU ou mpiP para latência/bandwidth.",
                                    "Teste escalabilidade variando número de nós."
                                  ],
                                  "verification": "Execute e profile um programa de soma distribuída em 8 nós na nuvem, medindo speedup.",
                                  "estimatedTime": "5 horas",
                                  "materials": "Código-fonte MPI exemplos (GitHub repos), ferramentas de profiling (perf, mpiP).",
                                  "tips": "Prefira coletivos sobre ponto-a-ponto para eficiência; teste em diferentes topologias de rede.",
                                  "learningObjective": "Aplicar MPI em cenários reais de nuvem, otimizando comunicação distribuída.",
                                  "commonMistakes": "Deadlocks em padrões circulares de send/recv; buffers mal alocados causando overflows."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e Aplicar Padrões Avançados de Message Passing",
                                  "subSteps": [
                                    "Estude padrões: publish-subscribe com MPI_Comm_split(), fault-tolerance com checkpoints.",
                                    "Integre com frameworks nuvem: AWS Batch ou GCP AI Platform para jobs MPI.",
                                    "Simule falhas de nó e implemente recovery com MPI_Errhandler.",
                                    "Compare MPI com alternativas como ZeroMQ ou gRPC em cenários distribuídos.",
                                    "Documente um caso de uso completo."
                                  ],
                                  "verification": "Crie e demonstre um programa tolerante a falhas com checkpointing em nuvem.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Documentação AWS Batch para MPI, exemplos de fault-tolerance em MPI.",
                                  "tips": "Use MPI_Wtime() para medir tempos reais em nuvem volátil.",
                                  "learningObjective": "Mestre padrões avançados e resiliência em message passing distribuído.",
                                  "commonMistakes": "Subestimar impacto de latência nuvem em algoritmos síncronos."
                                }
                              ],
                              "practicalExample": "Implemente um programa MPI em AWS EC2 cluster que distribua a computação de Pi usando método de Monte Carlo: cada nó gera pontos aleatórios, envia via MPI_Gather para o root calcular a aproximação final, demonstrando escalabilidade de 1 a 16 nós.",
                              "finalVerifications": [
                                "Explique verbalmente ou por escrito as diferenças entre MPI_Send bloqueante e não-bloqueante.",
                                "Execute e debugue um programa MPI com deadlock intencional, corrigindo-o.",
                                "Configure um cluster de 4 VMs na nuvem e rode um benchmark de bandwidth com MPI.",
                                "Descreva um coletivo MPI para um problema real (ex: soma global em ML distribuído).",
                                "Profile um código MPI identificando gargalos de comunicação.",
                                "Compare performance de MPI vs. sockets raw em latência."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: Correta distinção de primitivas e modelos (30%)",
                                "Implementação prática: Código funcional e otimizado em nuvem (25%)",
                                "Análise de performance: Identificação correta de bottlenecks (20%)",
                                "Resolução de problemas: Debug de erros comuns como deadlocks (15%)",
                                "Documentação: Relatório claro com diagramas e métricas (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos TCP/UDP subjacentes ao MPI.",
                                "Computação em Nuvem: Orquestração com Kubernetes e serviços gerenciados.",
                                "Algoritmos Paralelos: Mapeamento de problemas para coletivos MPI.",
                                "Segurança: Autenticação SSH e criptografia em comunicações distribuídas.",
                                "Big Data: Integração com Spark/Hadoop para processing distribuído."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, MPI é usado para simulações climáticas (ex: NASA models) e treinamento de ML distribuído (ex: TensorFlow com Horovod sobre MPI), processando petabytes de dados em milhares de nós na nuvem para previsões precisas e rápidas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.1.3",
                            "name": "Aplicar Decomposição de Domínio na Nuvem",
                            "description": "Explicar a técnica de decomposição de domínio para dividir problemas em subdomínios independentes, com exemplos de distribuição em clusters de nuvem.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Decomposição de Domínio",
                                  "subSteps": [
                                    "Estude o conceito de domínio espacial em problemas computacionais contínuos, como grades 2D ou 3D.",
                                    "Aprenda como a decomposição divide o domínio em subdomínios independentes para processamento paralelo.",
                                    "Revise exemplos clássicos, como equação de calor ou simulações de fluidos.",
                                    "Identifique vantagens: escalabilidade e independência de subdomínios.",
                                    "Analise desvantagens: overhead de comunicação nas bordas."
                                  ],
                                  "verification": "Resuma em um diagrama os componentes chave da decomposição de domínio e explique independência de subdomínios.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de MPI/OpenMP para nuvem",
                                    "Vídeos tutoriais sobre decomposição de domínio (Coursera/Khan Academy)",
                                    "Artigo: 'Domain Decomposition Methods'"
                                  ],
                                  "tips": "Use analogias visuais, como dividir um mapa em quadrantes para equipes paralelas.",
                                  "learningObjective": "Entender os princípios teóricos da decomposição de domínio em contextos de memória distribuída.",
                                  "commonMistakes": [
                                    "Confundir com decomposição de tarefas",
                                    "Ignorar dependências de borda",
                                    "Subestimar custos de comunicação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o Problema e Definir o Domínio Espacial",
                                  "subSteps": [
                                    "Escolha um problema contínuo, como simulação de difusão em uma grade 2D.",
                                    "Defina as dimensões do domínio (ex: grade NxN pixels).",
                                    "Identifique condições de contorno e equações governantes.",
                                    "Modele o domínio em código ou diagrama.",
                                    "Avalie granularidade: tamanho ideal de subdomínio para balanceamento de carga."
                                  ],
                                  "verification": "Crie um esboço do domínio com dimensões e condições de contorno documentadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Ferramenta de desenho como Draw.io",
                                    "Python/MATLAB para protótipo de grade",
                                    "Exemplos de problemas de PDEs"
                                  ],
                                  "tips": "Comece com domínios regulares (grades retangulares) antes de irregulares.",
                                  "learningObjective": "Mapear problemas reais para representações de domínio espacial.",
                                  "commonMistakes": [
                                    "Definir domínio muito pequeno para paralelismo",
                                    "Ignorar assimetrias no problema",
                                    "Esquecer condições de contorno"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Dividir o Domínio em Subdomínios Independentes",
                                  "subSteps": [
                                    "Escolha método de partição: blocos 1D, 2D ou recursivo bipartido.",
                                    "Divida o domínio em 4-16 subdomínios balanceados.",
                                    "Defina interfaces de borda para trocas de dados (ghost cells).",
                                    "Implemente alocação de subdomínios em pseudocódigo.",
                                    "Verifique independência: cada subdomínio computa localmente."
                                  ],
                                  "verification": "Gere um diagrama de partição mostrando subdomínios numerados e bordas.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Biblioteca ParMETIS ou METIS para partição",
                                    "Jupyter Notebook para visualização",
                                    "Código exemplo em C++/Python"
                                  ],
                                  "tips": "Garanta balanceamento: subdomínios de tamanho similar para eficiência.",
                                  "learningObjective": "Executar partições que minimizem comunicação entre subdomínios.",
                                  "commonMistakes": [
                                    "Partições desbalanceadas levando a gargalos",
                                    "Esquecer ghost regions para atualizações",
                                    "Partições que aumentam superfície de borda"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Distribuir Subdomínios em Clusters de Nuvem e Testar",
                                  "subSteps": [
                                    "Configure um cluster na nuvem (AWS EC2, Google Cloud).",
                                    "Mapeie subdomínios para nós/workers usando MPI ou Spark.",
                                    "Implemente comunicação assíncrona para bordas (AllReduce ou Send/Recv).",
                                    "Execute simulação e meça speedup/scalability.",
                                    "Otimize: ajuste partição baseado em métricas de performance."
                                  ],
                                  "verification": "Execute simulação em cluster e compare tempo serial vs paralelo (speedup > 80% esperado).",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Conta AWS/GCP com cluster (ex: 4 instâncias t3.medium)",
                                    "MPI instalado (OpenMPI)",
                                    "Código boilerplate para domínio decomposição"
                                  ],
                                  "tips": "Use contêineres Docker para deploy rápido em nuvem.",
                                  "learningObjective": "Aplicar decomposição em ambiente distribuído real de nuvem.",
                                  "commonMistakes": [
                                    "Sobrecarga de rede por comunicação excessiva",
                                    "Falha em sincronizar iterações",
                                    "Ignorar latência de nuvem em testes locais"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de propagação de calor em uma grade 1000x1000, divida em 16 subdomínios 250x250 distribuídos em 16 workers EC2. Cada worker computa localmente e troca valores de borda via MPI_Sendrecv, alcançando speedup de 12x.",
                              "finalVerifications": [
                                "Diagrama de partição mostra subdomínios independentes com ghost cells.",
                                "Simulação roda em cluster sem deadlocks ou erros de sincronização.",
                                "Speedup linear com número de nós até 16.",
                                "Balanceamento de carga: variância de tempo de computação < 5%.",
                                "Comunicação representa < 10% do tempo total.",
                                "Resultado converge para solução serial conhecida."
                              ],
                              "assessmentCriteria": [
                                "Precisão da partição: subdomínios balanceados e independentes (90%).",
                                "Eficiência de comunicação: volume mínimo nas bordas (80%).",
                                "Scalabilidade demonstrada: speedup > N/2 para N nós (85%).",
                                "Implementação correta de ghost cells e condições de contorno (95%).",
                                "Documentação clara de domínio, partição e métricas (100%).",
                                "Otimização baseada em profiling (bônus)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Métodos numéricos para PDEs (diferenças finitas).",
                                "Física: Simulações de dinâmica de fluidos ou difusão.",
                                "Engenharia de Software: Design de sistemas distribuídos e escaláveis.",
                                "Ciência de Dados: Processamento paralelo de grids em big data.",
                                "Administração: Gerenciamento de custos em clusters de nuvem."
                              ],
                              "realWorldApplication": "Usado em modelagem climática (dividir grid global da Terra em regiões para supercomputadores em nuvem como AWS), processamento de imagens médicas (segmentação paralela de scans 3D) e simulações automotivas (aerodinâmica em CFD distribuída)."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "64.1.1.2",
                        "name": "Linguagens e Frameworks para Plataformas na Nuvem",
                        "description": "Análise de linguagens e frameworks específicos para programação paralela em ambientes multicores, heterogêneos e de nuvem, como adaptações de MPI, OpenMP e ferramentas distribuídas.",
                        "specificSkills": [
                          {
                            "id": "64.1.1.2.1",
                            "name": "Comparar MPI e OpenMP em Nuvem",
                            "description": "Diferenciar o uso de MPI para memória distribuída e OpenMP para compartilhada em nuvem, com exemplos de configuração em serviços como AWS ou Google Cloud.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Fundamentos de MPI e OpenMP",
                                  "subSteps": [
                                    "Estude a arquitetura de memória distribuída do MPI e como ele gerencia comunicação entre processos independentes.",
                                    "Analise a arquitetura de memória compartilhada do OpenMP e suas diretivas para paralelização em threads.",
                                    "Identifique cenários ideais: MPI para clusters distribuídos, OpenMP para multi-core em um nó.",
                                    "Revise diferenças chave: comunicação explícita (MPI) vs. implícita (OpenMP).",
                                    "Leia documentação oficial: MPI standard e OpenMP specification."
                                  ],
                                  "verification": "Resuma em um diagrama comparativo as diferenças de memória e comunicação.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação MPI (mpi-forum.org)",
                                    "Documentação OpenMP (openmp.org)",
                                    "Livro 'Using MPI' ou 'Using OpenMP' (PDF gratuito)"
                                  ],
                                  "tips": "Use tabelas para mapear conceitos lado a lado para facilitar a memorização.",
                                  "learningObjective": "Diferenciar conceitualmente MPI e OpenMP em termos de modelo de programação e gerenciamento de memória.",
                                  "commonMistakes": [
                                    "Confundir MPI com OpenMP como 'iguais' para paralelismo",
                                    "Ignorar overhead de comunicação no MPI"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente de Nuvem para MPI e OpenMP",
                                  "subSteps": [
                                    "Crie uma conta gratuita em AWS EC2 ou Google Cloud Compute Engine e lance uma instância Ubuntu multi-core.",
                                    "Instale compilador GCC, MPICH ou OpenMPI para MPI, e bibliotecas OpenMP (geralmente inclusas no GCC).",
                                    "Configure firewall e SSH para acesso remoto.",
                                    "Teste instalação: compile e rode 'hello world' para MPI (mpirun) e OpenMP (#pragma omp parallel).",
                                    "Escalone para múltiplos nós se usando cluster (ex: AWS ParallelCluster para MPI)."
                                  ],
                                  "verification": "Execute comandos de teste e capture saídas mostrando paralelismo funcionando.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Conta AWS/GCP gratuita",
                                    "Guia AWS EC2: docs.aws.amazon.com/ec2",
                                    "Tutorial MPICH: mpich.org",
                                    "Google Cloud SDK"
                                  ],
                                  "tips": "Use instâncias t3.medium ou e2-standard-4 para custo-benefício em testes iniciais.",
                                  "learningObjective": "Preparar infraestrutura de nuvem compatível com ambas as tecnologias.",
                                  "commonMistakes": [
                                    "Esquecer de ativar OpenMP no compilador (flag -fopenmp)",
                                    "Não configurar chaves SSH corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Exemplos Práticos com MPI em Nuvem",
                                  "subSteps": [
                                    "Escreva um programa MPI simples: soma de vetor distribuído entre processos.",
                                    "Compile com mpicc e execute com mpirun -np 4 ./programa.",
                                    "Adapte para nuvem: use mpirun com --hostfile listando IPs de instâncias.",
                                    "Meça tempo de execução com múltiplos nós via AWS/GCP.",
                                    "Registre métricas: tempo de comunicação e escalabilidade."
                                  ],
                                  "verification": "Programa roda corretamente em 2+ nós na nuvem com output correto.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Editor VS Code ou Jupyter",
                                    "Código exemplo MPI de github.com/pmodels/mpi-examples"
                                  ],
                                  "tips": "Comece com single-node para debug antes de multi-nó.",
                                  "learningObjective": "Aplicar MPI em ambiente distribuído na nuvem.",
                                  "commonMistakes": [
                                    "Não sincronizar processos adequadamente (MPI_Barrier)",
                                    "Ignorar falhas de rede em nuvem"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar o Mesmo Exemplo com OpenMP em Nuvem",
                                  "subSteps": [
                                    "Reescreva o programa de soma de vetor usando diretivas OpenMP (parallel for, reduction).",
                                    "Compile com gcc -fopenmp e execute com OMP_NUM_THREADS=4 ./programa.",
                                    "Execute na mesma instância de nuvem multi-core.",
                                    "Meça tempo de execução e compare com MPI (mesmo hardware).",
                                    "Analise overhead: OpenMP deve ser mais rápido em shared memory."
                                  ],
                                  "verification": "Output idêntico ao MPI, mas com speedup em single-node.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código exemplo OpenMP de openmp.org",
                                    "Ferramenta gprof ou time para profiling"
                                  ],
                                  "tips": "Use export OMP_NUM_THREADS para controlar threads sem recompilar.",
                                  "learningObjective": "Demonstrar paralelismo shared memory com OpenMP na nuvem.",
                                  "commonMistakes": [
                                    "Race conditions sem critical/reduction",
                                    "Exceder núcleos disponíveis"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Comparar e Analisar MPI vs OpenMP na Nuvem",
                                  "subSteps": [
                                    "Colete métricas: tempo total, speedup, eficiência para cargas shared vs distribuída.",
                                    "Crie tabela comparativa: prós/contras, custos AWS/GCP, escalabilidade.",
                                    "Teste hybrid: MPI + OpenMP em cluster.",
                                    "Discuta trade-offs: latência rede (MPI) vs overhead thread (OpenMP).",
                                    "Documente em relatório com gráficos (matplotlib ou Excel)."
                                  ],
                                  "verification": "Relatório com tabela e gráficos mostrando quando usar cada um.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Python/Matplotlib para plots",
                                    "Ferramentas de benchmark como mpiBLAST"
                                  ],
                                  "tips": "Use instâncias spot no AWS para reduzir custos em benchmarks.",
                                  "learningObjective": "Sintetizar comparação prática em contextos de nuvem.",
                                  "commonMistakes": [
                                    "Comparar apples-to-oranges: ignore rede em testes shared"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um programa de multiplicação de matrizes: use MPI para distribuir linhas entre 4 nós EC2 (comunicação via MPI_Send/Recv), e OpenMP para paralelizar colunas em threads dentro de um nó e2-standard-4 no GCP. Meça tempo: MPI ~15s em 4 nós, OpenMP ~3s em single-node.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças de memória e quando usar cada API.",
                                "Configurar e rodar MPI multi-nó em AWS com hostfile correto.",
                                "Executar OpenMP com speedup linear em 8 threads.",
                                "Apresentar tabela comparativa com métricas reais de tempo/custo.",
                                "Identificar cenário hybrid MPI+OpenMP para workloads HPC.",
                                "Debugar erro comum de deadlocks em MPI."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: 90% acerto em definições de memória distribuída/shared.",
                                "Funcionalidade prática: Códigos compilam e rodam na nuvem sem erros.",
                                "Análise quantitativa: Métricas de performance com gráficos comparativos.",
                                "Compreensão de trade-offs: Explicação contextualizada para nuvem.",
                                "Criatividade: Sugestão de uso hybrid ou otimização.",
                                "Documentação: Relatório claro com passos reproduzíveis."
                              ],
                              "crossCurricularConnections": [
                                "Cloud Computing: Integração com orquestradores como Kubernetes para escalabilidade.",
                                "Big Data: Paralelismo em Spark/Hadoop vs MPI para processamento distribuído.",
                                "Sistemas Operacionais: Gerenciamento de processos/threads no Linux.",
                                "Matemática Computacional: Algoritmos paralelizáveis como Monte Carlo.",
                                "Segurança: Configuração segura de clusters na nuvem (IAM, VPC)."
                              ],
                              "realWorldApplication": "Em simulações científicas na AWS HPC ou Google Cloud AI Platform, use MPI para grandes clusters em modelagem climática distribuída e OpenMP para aceleração em GPUs multi-core, otimizando custos e performance em supercomputação como serviço (HPCaaS)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1.1"
                            ]
                          },
                          {
                            "id": "64.1.1.2.2",
                            "name": "Explorar Frameworks como Spark para Paralelismo na Nuvem",
                            "description": "Descrever o framework Apache Spark para processamento paralelo distribuído em nuvem, incluindo RDDs e sua aplicação em big data.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Instalação e Configuração Inicial do Apache Spark",
                                  "subSteps": [
                                    "Baixe a versão mais recente do Apache Spark do site oficial (spark.apache.org).",
                                    "Verifique pré-requisitos: Java 8 ou superior, Scala ou Python instalado.",
                                    "Extraia o arquivo e configure variáveis de ambiente (SPARK_HOME, PATH).",
                                    "Inicie o Spark Shell localmente com 'spark-shell' ou 'pyspark'.",
                                    "Execute um comando simples como 'sc.version' para testar."
                                  ],
                                  "verification": "Spark Shell inicia sem erros e exibe a versão corretamente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Computador com Linux/Mac/Windows",
                                    "Java JDK 8+",
                                    "Spark download",
                                    "Editor de texto"
                                  ],
                                  "tips": "Use Docker para setup rápido em ambientes isolados.",
                                  "learningObjective": "Configurar ambiente Spark funcional para experimentação local.",
                                  "commonMistakes": [
                                    "Esquecer de setar SPARK_HOME",
                                    "Usar versão incompatível de Java",
                                    "Não adicionar ao PATH"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreensão de Conceitos Fundamentais: RDDs e Paralelismo",
                                  "subSteps": [
                                    "Estude a arquitetura do Spark: Driver, Executors, Cluster Manager.",
                                    "Aprenda sobre RDDs: Resilient Distributed Datasets, lazy evaluation e fault-tolerance.",
                                    "Explore operações em RDDs: transformations (map, filter) vs actions (collect, count).",
                                    "Analise como Spark distribui dados em partições para paralelismo.",
                                    "Leia documentação oficial sobre lineage e recomputation."
                                  ],
                                  "verification": "Explique em suas palavras como RDDs garantem resiliência e paralelismo.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação Spark (RDD Programming Guide)",
                                    "Vídeos tutoriais no YouTube (Databricks channel)",
                                    "Notebook Jupyter"
                                  ],
                                  "tips": "Desenhe diagramas da arquitetura Spark para fixar conceitos.",
                                  "learningObjective": "Dominar os pilares do Spark: RDDs, distribuições e execução paralela.",
                                  "commonMistakes": [
                                    "Confundir transformations com actions",
                                    "Ignorar lazy evaluation",
                                    "Subestimar overhead de serialização"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementação de Jobs Básicos com Spark",
                                  "subSteps": [
                                    "Crie um RDD a partir de dados locais ou HDFS.",
                                    "Implemente um exemplo clássico: WordCount em um arquivo de texto.",
                                    "Aplique filter, map e reduceByKey em um dataset.",
                                    "Execute em modo local e salve resultados.",
                                    "Monitore jobs via Spark UI (porta 4040)."
                                  ],
                                  "verification": "Job WordCount executa e produz contagem correta de palavras.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Spark Shell ou IntelliJ/VSCode com Scala/Python",
                                    "Arquivo de texto grande (>1MB)",
                                    "Spark UI acessível"
                                  ],
                                  "tips": "Comece com datasets pequenos para depuração rápida.",
                                  "learningObjective": "Desenvolver e executar pipelines de dados paralelos com RDDs.",
                                  "commonMistakes": [
                                    "Não paralelizar adequadamente (poucas partições)",
                                    "Coletar dados grandes com .collect()",
                                    "Ignorar Spark UI para debugging"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicação em Big Data e Deploy na Nuvem",
                                  "subSteps": [
                                    "Integre Spark com armazenamento em nuvem (S3, GCS).",
                                    "Configure cluster Spark em EMR (AWS) ou Databricks.",
                                    "Processe um dataset real de big data (ex: Kaggle logs).",
                                    "Otimize com caching, partitioning e broadcast variables.",
                                    "Compare performance local vs cluster."
                                  ],
                                  "verification": "Job roda em cluster nuvem processando >1GB de dados sem falhas.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Conta AWS/Google Cloud gratuita",
                                    "Dataset Kaggle (ex: NASA logs)",
                                    "Databricks Community Edition"
                                  ],
                                  "tips": "Use Spark 3+ para suporte nativo a cloud storage.",
                                  "learningObjective": "Aplicar Spark em cenários distribuídos de big data na nuvem.",
                                  "commonMistakes": [
                                    "Configurar cluster sem autenticação",
                                    "Não otimizar partições para cluster size",
                                    "Subestimar custos de nuvem"
                                  ]
                                }
                              ],
                              "practicalExample": "Processar logs de acesso de um site (arquivo 10GB): use Spark para contar IPs mais frequentes, filtrar erros 404 e agregar por hora, distribuindo em cluster AWS EMR para análise em minutos.",
                              "finalVerifications": [
                                "Explicar RDDs, transformations e actions com exemplos.",
                                "Executar WordCount em dataset >100MB.",
                                "Configurar e rodar Spark em cluster nuvem.",
                                "Identificar bottlenecks via Spark UI.",
                                "Otimizar job com cache e repartition.",
                                "Descrever fault-tolerance do Spark."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual sobre RDDs e paralelismo (80%+ correto).",
                                "Código funcional sem erros em jobs básicos.",
                                "Performance otimizada (tempo < esperado).",
                                "Uso correto de UI e monitoring.",
                                "Integração nuvem com autenticação segura.",
                                "Relatório de aplicação real com métricas."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Estatística e álgebra linear em agregações Spark.",
                                "Banco de Dados: Integração com Hive/SQL para queries distribuídas.",
                                "Redes: Conceitos de cluster computing e latência em nuvem.",
                                "Engenharia de Software: Design de pipelines escaláveis."
                              ],
                              "realWorldApplication": "Empresas como Netflix usam Spark para análise de recomendações em petabytes de dados de streaming, processando logs em tempo real para otimizar conteúdo personalizado."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1.2"
                            ]
                          },
                          {
                            "id": "64.1.1.2.3",
                            "name": "Implementar Exclusão Mútua em Plataformas Heterogêneas",
                            "description": "Analisar mecanismos de exclusão mútua em linguagens paralelas para plataformas heterogêneas na nuvem, como tasking no OpenMP.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Fundamentos de Exclusão Mútua em Ambientes Paralelos Heterogêneos",
                                  "subSteps": [
                                    "Estude os conceitos básicos de race conditions, deadlocks e starvation em programação paralela.",
                                    "Analise diferenças entre plataformas homogêneas (apenas CPU) e heterogêneas (CPU + GPU + nuvem).",
                                    "Revise mecanismos de sincronização como locks, semáforos e barreiras.",
                                    "Explore tasking no OpenMP e sua extensão para offload heterogêneo.",
                                    "Identifique desafios específicos na nuvem, como latência de rede e migração de tasks."
                                  ],
                                  "verification": "Resuma em um diagrama os problemas de sincronização e soluções em heterogêneos; valide com um peer review.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Documentação OpenMP 5.0+",
                                    "Livro 'Parallel Programming with OpenMP' (Chaplin)",
                                    "Ferramentas de diagramação como Draw.io"
                                  ],
                                  "tips": [
                                    "Comece com exemplos simples em CPU antes de heterogêneos.",
                                    "Use analogias como 'trânsito em rodovias multi-faixas' para visualizar."
                                  ],
                                  "learningObjective": "Compreender os princípios teóricos e desafios de exclusão mútua em plataformas heterogêneas.",
                                  "commonMistakes": [
                                    "Confundir locks locais com globais em multi-nós.",
                                    "Ignorar overhead de sincronização em GPUs."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente de Desenvolvimento para OpenMP Heterogêneo",
                                  "subSteps": [
                                    "Instale compiladores suportando OpenMP 5.0+ (GCC 10+, Intel oneAPI, NVIDIA HPC SDK).",
                                    "Configure ambiente nuvem (AWS EC2 com GPU, Azure Batch ou Google Cloud).",
                                    "Compile e teste um programa OpenMP básico com target offload para GPU.",
                                    "Integre bibliotecas como MPI para multi-nós heterogêneos.",
                                    "Verifique suporte a tasks dependentes e locks omp_init_lock."
                                  ],
                                  "verification": "Execute 'omp_get_num_devices()' e confirme detecção de CPU/GPU; gere relatório de configuração.",
                                  "estimatedTime": "3 hours",
                                  "materials": [
                                    "GCC/Clang com OpenMP",
                                    "NVIDIA CUDA Toolkit",
                                    "Contas em clouds (AWS free tier)",
                                    "Exemplos do OpenMP GitHub repo"
                                  ],
                                  "tips": [
                                    "Use Docker containers para reproducibilidade.",
                                    "Teste flags como -fopenmp -foffload=-target=nvptx64."
                                  ],
                                  "learningObjective": "Configurar um ambiente funcional para experimentação com exclusão mútua heterogênea.",
                                  "commonMistakes": [
                                    "Esquecer de linkar bibliotecas offload.",
                                    "Não habilitar suporte GPU no compilador."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Primitivas Básicas de Exclusão Mútua com OpenMP Tasking",
                                  "subSteps": [
                                    "Crie tasks paralelas com #pragma omp task que acessam uma variável compartilhada.",
                                    "Aplique critical sections (#pragma omp critical) para regiões exclusivas.",
                                    "Implemente locks explícitos com omp_lock_t para granularidade fina.",
                                    "Adicione dependências de tasks (depend(in,out)) para ordenação.",
                                    "Teste em CPU multi-core para validar ausência de races."
                                  ],
                                  "verification": "Use ferramentas como Intel Inspector ou Valgrind para detectar data races; confirme zero violações.",
                                  "estimatedTime": "4 hours",
                                  "materials": [
                                    "Editor IDE (VS Code com C/C++ extension)",
                                    "Intel Inspector ou ThreadSanitizer",
                                    "Código base OpenMP examples"
                                  ],
                                  "tips": [
                                    "Sempre inicialize locks com omp_init_lock antes de uso.",
                                    "Monitore com omp_set_lock/omp_unset_lock em pares."
                                  ],
                                  "learningObjective": "Dominar implementação de mutual exclusion usando tasking e locks no OpenMP.",
                                  "commonMistakes": [
                                    "Forgetar omp_destroy_lock ao final.",
                                    "Usar critical em loops quentes, causando serialização excessiva."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Estender para Plataformas Heterogêneas com Offload",
                                  "subSteps": [
                                    "Defina regiões target (#pragma omp target) para offload tasks para GPU.",
                                    "Implemente locks compartilhados acessíveis entre host (CPU) e device (GPU).",
                                    "Crie um cenário com tasks CPU acessando dados offloaded e vice-versa.",
                                    "Gerencie migração de dados com map(to,from) e nowait para async.",
                                    "Integre com nuvem multi-nós usando MPI + OpenMP hybrid."
                                  ],
                                  "verification": "Execute em cluster heterogêneo e confirme output correto sem races via logs e profiling.",
                                  "estimatedTime": "5 hours",
                                  "materials": [
                                    "NVIDIA Nsight Systems para profiling",
                                    "SLURM para job submission em cluster",
                                    "Hybrid MPI-OpenMP templates"
                                  ],
                                  "tips": [
                                    "Use atomic directives para operações simples em GPU.",
                                    "Evite locks pesados em device; prefira reductions."
                                  ],
                                  "learningObjective": "Aplicar exclusão mútua em cenários reais de CPU-GPU-nuvem heterogêneos.",
                                  "commonMistakes": [
                                    "Mapear locks incorretamente entre host/device.",
                                    "Ignorar latência de sincronização cross-device."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar, Debugar e Otimizar a Implementação",
                                  "subSteps": [
                                    "Desenvolva testes unitários com múltiplas execuções randômicas.",
                                    "Profile performance com ferramentas como TAU ou Vampir.",
                                    "Otimize reduzindo contenda com reader-writer locks ou fine-grained tasks.",
                                    "Analise escalabilidade variando núcleos/GPUs/nós.",
                                    "Documente lições aprendidas e edge cases."
                                  ],
                                  "verification": "Alcance speedup linear e zero falhas em 1000 runs; gere relatório com métricas.",
                                  "estimatedTime": "3 hours",
                                  "materials": [
                                    "Nsight Compute, gprof",
                                    "JUnit-like para C++ (Google Test)",
                                    "Scripts bash para stress testing"
                                  ],
                                  "tips": [
                                    "Use #pragma omp atomic para updates simples.",
                                    "Monitore contenda com lock statistics."
                                  ],
                                  "learningObjective": "Garantir robustez, performance e corretude em implementações heterogêneas.",
                                  "commonMistakes": [
                                    "Testar apenas em setups ideais, ignorando falhas de rede.",
                                    "Otimizar prematuramente sem profiling."
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um sistema de fila compartilhada onde tasks CPU enfileiram jobs e tasks GPU processam em paralelo, usando omp_lock_t para acesso exclusivo à fila head/tail, testado em AWS EC2 com A100 GPU.",
                              "finalVerifications": [
                                "Programa compila e roda sem erros em CPU+GPU+nuvem.",
                                "Ferramentas de race detection reportam zero violações.",
                                "Output é determinístico em múltiplas runs com seeds randômicas.",
                                "Performance escala com mais devices sem degradação.",
                                "Locks são destruídos corretamente, sem leaks.",
                                "Documentação inclui código fonte e profiling graphs."
                              ],
                              "assessmentCriteria": [
                                "Corretude: Ausência comprovada de data races e deadlocks.",
                                "Eficiência: Overhead de sincronização <10% do tempo total.",
                                "Escalabilidade: Speedup >80% do ideal em 4+ devices.",
                                "Robustez: Lida com falhas de device e rede.",
                                "Clareza: Código comentado e modular.",
                                "Documentação: Relatório com análise e otimizações."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Semáforos e monitores clássicos.",
                                "Redes e Computação Distribuída: Consensus como Paxos em multi-nós.",
                                "Segurança da Informação: Atomicidade em transações seguras.",
                                "Engenharia de Software: Design patterns para paralelismo.",
                                "Inteligência Artificial: Sincronização em training distribuído (ex: Horovod)."
                              ],
                              "realWorldApplication": "Em serviços de cloud como Kubernetes com GPU pods para ML workloads, garantindo que múltiplos containers acessem bancos de dados compartilhados sem corrupção, ou em simulações científicas HPC onde tasks migram entre CPU/GPU em clusters como Summit."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "64.1.1.3",
                        "name": "Avaliação de Desempenho e Estudos de Caso",
                        "description": "Métodos para avaliar o desempenho de programas paralelos na nuvem e análise de aplicações reais através de estudos de caso.",
                        "specificSkills": [
                          {
                            "id": "64.1.1.3.1",
                            "name": "Calcular Métricas de Desempenho Paralelo",
                            "description": "Aplicar conceitos de speedup, eficiência e escalabilidade para avaliar programas paralelos em ambientes de nuvem, usando ferramentas como MPI profiling.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Conceitos Fundamentais de Métricas de Desempenho Paralelo",
                                  "subSteps": [
                                    "Estude a definição de speedup: S(p) = T(1) / T(p), onde T(1) é o tempo sequencial e T(p) o tempo com p processadores.",
                                    "Aprenda eficiência: E(p) = S(p) / p, medindo overhead de paralelização.",
                                    "Explore escalabilidade forte (tempo fixo, problema fixo) e fraca (problema escala com processadores).",
                                    "Revise lei de Amdahl e lei de Gustafson para limites teóricos.",
                                    "Identifique ferramentas de profiling como MPI's built-in timers ou TAU/Score-P."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as fórmulas de speedup e eficiência com exemplos numéricos simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação MPI oficial",
                                    "Artigos sobre Leis de Amdahl e Gustafson",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Use exemplos numéricos pequenos para internalizar fórmulas antes de codificar.",
                                  "learningObjective": "Dominar definições matemáticas e limitações teóricas de métricas paralelas.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Ignorar overhead de comunicação em cálculos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente de Nuvem para Programação Paralela com MPI",
                                  "subSteps": [
                                    "Crie uma instância EC2 na AWS com suporte a MPI (ex: Ubuntu com OpenMPI).",
                                    "Instale OpenMPI: sudo apt install openmpi-bin libopenmpi-dev.",
                                    "Configure chaves SSH para execução multi-nó e inicie cluster com mpirun.",
                                    "Teste instalação com programa 'hello world' MPI em 2-4 processos.",
                                    "Integre ferramentas de profiling: compile com -fprofile-arcs ou use mpiP."
                                  ],
                                  "verification": "Execute 'mpirun -np 4 hostname' e confirme saída de múltiplos nós.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Conta AWS free tier",
                                    "Guia OpenMPI installation",
                                    "Editor de código como VS Code"
                                  ],
                                  "tips": "Use instâncias spot para reduzir custos em testes de escalabilidade.",
                                  "learningObjective": "Preparar infraestrutura de nuvem escalável para medições precisas.",
                                  "commonMistakes": [
                                    "Falhar em configurar firewall para MPI ports",
                                    "Usar MPI em single-node sem simular multi-nó"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar Profiling em um Programa Paralelo de Exemplo",
                                  "subSteps": [
                                    "Implemente ou baixe um programa MPI exemplo (ex: multiplicação de matrizes paralela).",
                                    "Meça tempos sequencial (p=1) e paralelo (p=2,4,8) usando MPI_Wtime().",
                                    "Colete dados de profiling com mpirun -mca mpi_pfirmpi 1 ou ferramentas como Vampir.",
                                    "Registre tempos de comunicação (MPI_Bcast, MPI_Reduce) e computação.",
                                    "Repita execuções múltiplas (5+) para médias e desvios padrão."
                                  ],
                                  "verification": "Gere log com tempos T(1), T(2), T(4) para pelo menos 3 execuções.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Código fonte MPI matrix_multiply.c",
                                    "Ferramenta Vampir ou mpiP",
                                    "Cluster AWS com 4+ núcleos"
                                  ],
                                  "tips": "Fixe seed de gerador aleatório para reprodutibilidade em matrizes.",
                                  "learningObjective": "Coletar dados empíricos de desempenho em ambiente real de nuvem.",
                                  "commonMistakes": [
                                    "Não aquecer cache antes de medições",
                                    "Ignorar variabilidade de rede na nuvem"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e Analisar Métricas de Speedup, Eficiência e Escalabilidade",
                                  "subSteps": [
                                    "Calcule speedup S(p) e eficiência E(p) para cada p usando planilhas ou Python (numpy).",
                                    "Plote curvas de speedup e eficiência vs. número de processadores.",
                                    "Avalie escalabilidade: compare speedup real vs. lei de Amdahl predita.",
                                    "Identifique gargalos (ex: comunicação >50% do tempo) e sugira otimizações.",
                                    "Documente relatório com tabelas, gráficos e conclusões."
                                  ],
                                  "verification": "Produza gráfico de speedup com S(8) > 4 e eficiência > 0.5, com análise escrita.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python com matplotlib e pandas",
                                    "Planilha Google Sheets",
                                    "Dados de profiling do step 3"
                                  ],
                                  "tips": "Use log-scale em plots para melhor visualização de escalabilidade.",
                                  "learningObjective": "Aplicar fórmulas para análise quantitativa e interpretação crítica.",
                                  "commonMistakes": [
                                    "Usar tempo wall-clock sem subtrair init/finalize",
                                    "Sobrepor curvas sem legenda clara"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster AWS EC2 com 8 instâncias c5.xlarge, execute um programa MPI para multiplicação de matriz 4096x4096. Meça T_seq = 120s, T_8 = 18s → Speedup=6.67, Eficiência=0.83. Analise que comunicação em MPI_Allreduce limita escalabilidade além de 16 cores.",
                              "finalVerifications": [
                                "Calcula corretamente speedup e eficiência para dados dados.",
                                "Interpreta plots de escalabilidade identificando gargalos.",
                                "Configura MPI profiling em nuvem sem erros.",
                                "Compara resultados empíricos com predições teóricas (Amdahl).",
                                "Gera relatório com gráficos e conclusões acionáveis.",
                                "Repete medições para estatísticas confiáveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas fórmulas matemáticas (100% correto).",
                                "Qualidade dos dados coletados (mínimo 5 runs por configuração).",
                                "Análise de gargalos com evidências quantitativas.",
                                "Clareza em plots e relatório (legendas, escalas adequadas).",
                                "Criatividade em otimizações sugeridas baseadas em métricas.",
                                "Eficiência no uso de recursos de nuvem (custo < $1)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Aplicação de funções lineares e limites assintóticos.",
                                "Estatística: Cálculo de médias, desvios e análise de variância em medições.",
                                "Computação em Nuvem: Gerenciamento de clusters escaláveis (AWS EC2).",
                                "Engenharia de Software: Profiling e otimização de código.",
                                "Física/Engenharia: Modelagem de desempenho em sistemas distribuídos."
                              ],
                              "realWorldApplication": "Em data centers de empresas como Google ou Netflix, engenheiros usam essas métricas para otimizar jobs de ML distribuído (ex: TensorFlow com Horovod), reduzindo custos de computação em nuvem em até 50% ao escalar eficientemente workloads paralelos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.1.3"
                            ]
                          },
                          {
                            "id": "64.1.1.3.2",
                            "name": "Analisar Estudos de Caso de Aplicações na Nuvem",
                            "description": "Estudar casos reais de programação paralela na nuvem, como processamento de imagens com Spark ou simulações científicas com MPI em clusters AWS.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e Pesquisar Estudos de Caso Relevantes",
                                  "subSteps": [
                                    "Identifique 2-3 estudos de caso reais envolvendo programação paralela na nuvem, como processamento de imagens com Apache Spark no AWS EMR ou simulações científicas com MPI em clusters EC2.",
                                    "Pesquise fontes confiáveis como blogs da AWS, papers do IEEE, repositórios GitHub ou documentação oficial do Spark/MPI.",
                                    "Registre metadados iniciais: empresa/projeto, escala do problema, tecnologias usadas e resultados declarados.",
                                    "Crie um resumo inicial de 200-300 palavras para cada caso selecionado.",
                                    "Verifique a acessibilidade dos dados e diagramas do caso."
                                  ],
                                  "verification": "Lista de 2-3 estudos de caso selecionados com resumos iniciais e links para fontes originais.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Acesso à internet",
                                    "Navegador web",
                                    "Ferramentas de anotações como Notion ou Google Docs",
                                    "Documentação AWS/Spark/MPI"
                                  ],
                                  "tips": "Priorize casos recentes (últimos 5 anos) com métricas quantificáveis para maior relevância.",
                                  "learningObjective": "Desenvolver habilidade em sourcing e triagem de casos reais de aplicações paralelas na nuvem.",
                                  "commonMistakes": [
                                    "Escolher casos irrelevantes ou desatualizados",
                                    "Ignorar fontes primárias como relatórios oficiais",
                                    "Não registrar metadados desde o início"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Dissecar Arquitetura e Implementação Paralela",
                                  "subSteps": [
                                    "Mapeie a arquitetura: identifique nós de cluster, serviços de nuvem (EC2, EMR, S3) e frameworks (Spark, MPI).",
                                    "Descreva o problema sequencial vs. paralelo: como a paralelização foi aplicada (map-reduce, broadcast, etc.).",
                                    "Analise fluxos de dados: entrada, processamento distribuído e saída.",
                                    "Identifique otimizações específicas, como particionamento de dados ou tolerância a falhas.",
                                    "Desenhe um diagrama simples da arquitetura usando ferramentas como Draw.io."
                                  ],
                                  "verification": "Diagrama arquitetural e tabela comparativa sequencial vs. paralelo para cada caso.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Ferramenta de diagramação (Draw.io ou Lucidchart)",
                                    "Documentos dos casos selecionados",
                                    "Conhecimento básico de Spark/MPI"
                                  ],
                                  "tips": "Use cores no diagrama para diferenciar componentes de computação, armazenamento e rede.",
                                  "learningObjective": "Compreender como arquiteturas paralelas na nuvem resolvem problemas em escala.",
                                  "commonMistakes": [
                                    "Confundir conceitos sequenciais com paralelos",
                                    "Omitir detalhes de integração com serviços de nuvem",
                                    "Diagramas muito genéricos sem especificidades do caso"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Métricas de Desempenho e Escalabilidade",
                                  "subSteps": [
                                    "Extraia métricas chave: tempo de execução, throughput, speedup, eficiência, custo na nuvem (EC2 hours, S3 storage).",
                                    "Calcule ou estime speedup (tempo sequencial / tempo paralelo) e eficiência (speedup / número de nós).",
                                    "Compare escalabilidade: desempenho vs. tamanho do cluster e tamanho dos dados.",
                                    "Identifique gargalos reportados (latência de rede, I/O, CPU-bound).",
                                    "Crie gráficos de desempenho usando Excel ou Python (Matplotlib)."
                                  ],
                                  "verification": "Tabelas/gráficos de métricas com cálculos de speedup e eficiência para cada caso.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Planilha Excel/Google Sheets",
                                    "Python com Pandas/Matplotlib (opcional)",
                                    "Dados métricos dos casos"
                                  ],
                                  "tips": "Normalise métricas por unidade de dado processado para comparações justas.",
                                  "learningObjective": "Avaliar quantitativamente o impacto da paralelização na nuvem.",
                                  "commonMistakes": [
                                    "Ignorar custos de nuvem nas análises",
                                    "Usar métricas sem contexto (ex: sem baseline sequencial)",
                                    "Erros em cálculos de speedup"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Extrair Lições Aprendidas e Sintetizar Insights",
                                  "subSteps": [
                                    "Liste lições: sucessos, falhas, trade-offs (custo vs. performance).",
                                    "Compare casos: similaridades/diferenças em abordagens e resultados.",
                                    "Proponha melhorias hipotéticas baseadas em melhores práticas atuais.",
                                    "Discuta implicações para aplicações semelhantes (ex: ML em escala).",
                                    "Escreva relatório final de 800-1000 palavras com referências."
                                  ],
                                  "verification": "Relatório sintetizado com lições, comparações e recomendações.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Editor de texto (Google Docs/Word)",
                                    "Referências bibliográficas"
                                  ],
                                  "tips": "Estruture o relatório com seções claras: Introdução, Análise, Lições, Conclusão.",
                                  "learningObjective": "Sintetizar análises para gerar insights acionáveis em programação paralela.",
                                  "commonMistakes": [
                                    "Focar só em sucessos, ignorar falhas",
                                    "Não comparar casos",
                                    "Relatório superficial sem quantificação"
                                  ]
                                }
                              ],
                              "practicalExample": "Analise o caso do NASA Earthdata usando Spark no AWS EMR para processamento paralelo de imagens de satélite: identifique como Spark Streaming lidou com petabytes de dados, speedup de 10x em 100 nós EC2, gargalos de shuffle e lições sobre tuning de partições.",
                              "finalVerifications": [
                                "Pode mapear arquitetura completa de um caso real com diagramas precisos.",
                                "Calcula corretamente speedup, eficiência e custos de nuvem.",
                                "Identifica pelo menos 3 gargalos e otimizações em cada estudo.",
                                "Sintetiza lições comparativas entre múltiplos casos.",
                                "Propõe melhorias viáveis baseadas em análise.",
                                "Relatório final é claro, quantificado e referenciado."
                              ],
                              "assessmentCriteria": [
                                "Profundidade da análise arquitetural (30%)",
                                "Precisão das métricas de desempenho (25%)",
                                "Qualidade da síntese e lições aprendidas (20%)",
                                "Uso de evidências e referências (15%)",
                                "Clareza e visualizações (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Big Data e Analytics (Spark para ML pipelines)",
                                "Arquitetura de Nuvem (AWS services como EMR/EC2)",
                                "Otimização de Performance (algoritmos paralelos)",
                                "Gestão de Projetos (escalabilidade e custos)",
                                "Ciência de Dados (processamento de imagens/simulações)"
                              ],
                              "realWorldApplication": "Profissionais em empresas como Netflix ou NASA usam essa análise para otimizar workloads paralelos na nuvem, reduzindo custos em 50-70% e acelerando processamento de dados massivos para IA, simulações climáticas ou finanças em tempo real."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.1.1.2.2",
                              "64.1.1.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.5",
                "name": "Avaliação de Desempenho",
                "description": "Discute métodos para avaliar o desempenho de programas paralelos.",
                "totalSkills": 41,
                "atomicTopics": [
                  {
                    "id": "10.1.5.1",
                    "name": "Métricas de Desempenho: Speedup e Eficiência",
                    "description": "Definições e fórmulas para speedup linear e eficiência em programas paralelos.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.1.1.1",
                        "name": "Speedup",
                        "description": "O speedup mede a melhoria no tempo de execução de um programa paralelo em comparação com sua versão sequencial, utilizando p processadores. Inclui definições, fórmula básica S(p) = T(1)/T(p) e o conceito de speedup linear ideal.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.1.1.1.1",
                            "name": "Definir o conceito de speedup",
                            "description": "Explicar o speedup como a razão entre o tempo de execução sequencial T(1) e o tempo de execução paralelo T(p) com p processadores, destacando sua importância na avaliação de desempenho de algoritmos paralelos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Básicos de Tempo Sequencial e Paralelo",
                                  "subSteps": [
                                    "Revise o que é execução sequencial: um único processador executa tarefas uma de cada vez.",
                                    "Entenda execução paralela: múltiplos processadores (p) trabalham simultaneamente em partes da tarefa.",
                                    "Identifique T(1) como o tempo total para execução sequencial com 1 processador.",
                                    "Defina T(p) como o tempo total para execução paralela com p processadores.",
                                    "Compare exemplos simples, como somar 100 números sequencial vs. paralelo."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre T(1) e T(p), com um diagrama simples.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Papel e caneta para diagramas; vídeo introdutório sobre paralelismo (ex: YouTube 'Parallel Computing Basics').",
                                  "tips": "Use analogias cotidianas, como cozinhar sozinho (sequencial) vs. com amigos (paralelo).",
                                  "learningObjective": "Diferenciar tempos de execução sequencial e paralelo.",
                                  "commonMistakes": "Confundir T(p) com tempo por processador em vez de tempo total."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender a Fórmula do Speedup",
                                  "subSteps": [
                                    "Memorize a fórmula: Speedup = T(1) / T(p), onde p é o número de processadores.",
                                    "Entenda que speedup mede quanto mais rápido o paralelo é comparado ao sequencial.",
                                    "Discuta que speedup ideal é p (lei de Gustafson ou Amdahl em contexto básico).",
                                    "Escreva a fórmula em notação matemática e verbalize seu significado.",
                                    "Resolva uma equação simbólica simples: se T(1)=100s e T(2)=60s, qual speedup?"
                                  ],
                                  "verification": "Escreva a fórmula corretamente e calcule speedup para valores dados (ex: T(1)=10, T(4)=3 → speedup=3.33).",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Calculadora; quadro branco ou editor de texto para anotações.",
                                  "tips": "Sempre normalize pelo sequencial; speedup >1 indica ganho.",
                                  "learningObjective": "Definir e expressar matematicamente o conceito de speedup.",
                                  "commonMistakes": "Inverter a fórmula (T(p)/T(1)) ou esquecer que é uma razão."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar a Fórmula em um Exemplo Prático",
                                  "subSteps": [
                                    "Escolha um algoritmo simples: multiplicação de matrizes NxN.",
                                    "Calcule T(1): tempo sequencial aproximado como O(N^2).",
                                    "Estime T(p) para p=4: divida matriz em quadrantes, T(4) ≈ O(N^2)/4.",
                                    "Compute speedup: ex. T(1)=400s, T(4)=120s → speedup=3.33.",
                                    "Registre variações se houver overhead de comunicação."
                                  ],
                                  "verification": "Realize o cálculo em papel ou código simples e confira se speedup < p devido a overhead.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Planilha Excel ou Python básico para simular tempos; pseudocódigo de matriz.",
                                  "tips": "Assuma divisão perfeita de trabalho para speedup ideal inicial.",
                                  "learningObjective": "Calcular speedup numericamente em cenários reais.",
                                  "commonMistakes": "Ignorar overheads de comunicação, levando a speedup irreal >p."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Importância e Limitações do Speedup",
                                  "subSteps": [
                                    "Explique importância: benchmark para algoritmos paralelos e hardware.",
                                    "Discuta lei de Amdahl: speedup limitado por fração sequencial.",
                                    "Analise cenários onde speedup=1 (sem ganho) ou superlinear (>p).",
                                    "Relacione com eficiência: Eficiência = Speedup / p.",
                                    "Pesquise um paper ou artigo curto sobre speedup em GPUs."
                                  ],
                                  "verification": "Resuma em 3 frases a importância e uma limitação, com exemplo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Artigo online 'Amdahl's Law Explained'; timer para leitura.",
                                  "tips": "Foco em por que speedup não é sempre linear.",
                                  "learningObjective": "Compreender o papel do speedup na avaliação de desempenho.",
                                  "commonMistakes": "Achar que mais processadores sempre dão speedup proporcional."
                                }
                              ],
                              "practicalExample": "Para somar 1 bilhão de números: T(1)=10 segundos em 1 CPU. Com 4 CPUs, T(4)=3 segundos (overhead incluso). Speedup = 10/3 ≈ 3.33, mostrando ganho sub-linear devido a sincronização.",
                              "finalVerifications": [
                                "Define corretamente speedup como T(1)/T(p).",
                                "Calcula speedup em exemplo numérico com precisão.",
                                "Explica importância na avaliação de paralelos.",
                                "Identifica limitação por lei de Amdahl.",
                                "Distingue speedup de eficiência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na fórmula e cálculo (80% peso).",
                                "Compreensão conceitual via explicação clara.",
                                "Uso correto de exemplos práticos.",
                                "Reconhecimento de limitações reais.",
                                "Aplicação em contexto de desempenho.",
                                "Clareza na comunicação escrita/oral."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo de razões e limites (lei de Amdahl).",
                                "Física: Analogia com trabalho em sistemas dinâmicos paralelos.",
                                "Engenharia de Software: Métricas de performance em sistemas distribuídos.",
                                "Estatística: Análise de variância em benchmarks de tempo."
                              ],
                              "realWorldApplication": "Em data centers como Google Cloud, speedup avalia se usar 1000 CPUs para treinar modelos de IA é custo-efetivo, otimizando energia e tempo em aplicações de machine learning e simulações científicas."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.1.1.1.2",
                            "name": "Calcular speedup a partir de tempos de execução",
                            "description": "Aplicar a fórmula S(p) = T(1)/T(p) para calcular o speedup dado tempos sequencial e paralelo, interpretando valores como superlinear (>p), linear (=p) ou sublinear (<p).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Básicos de Tempo Sequencial e Paralelo",
                                  "subSteps": [
                                    "Defina tempo sequencial T(1) como o tempo de execução em um único processador.",
                                    "Defina tempo paralelo T(p) como o tempo de execução com p processadores.",
                                    "Explique a relação: speedup mede quanto mais rápido o paralelo é comparado ao sequencial.",
                                    "Discuta limitações ideais: speedup máximo é p (Lei de Amdahl aproximada).",
                                    "Identifique cenários onde speedup pode exceder p (superlinear)."
                                  ],
                                  "verification": "Resuma em suas palavras os conceitos de T(1), T(p) e speedup, com um diagrama simples.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta para diagramas",
                                    "Vídeo introdutório sobre programação paralela (ex: YouTube - 'What is Speedup')"
                                  ],
                                  "tips": "Use analogias como cozinhar sozinho (sequencial) vs. com amigos (paralelo).",
                                  "learningObjective": "Diferenciar tempos sequencial e paralelo e seu papel no speedup.",
                                  "commonMistakes": [
                                    "Confundir T(1) com T(p)",
                                    "Ignorar que p é o número de processadores"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender a Fórmula de Speedup e Seus Componentes",
                                  "subSteps": [
                                    "Memorize a fórmula S(p) = T(1) / T(p).",
                                    "Identifique variáveis: T(1) em unidades de tempo (segundos), T(p) similar, p como inteiro.",
                                    "Calcule exemplos simples manualmente: T(1)=100s, T(2)=50s → S(2)=2.",
                                    "Entenda interpretações: S(p)=p (linear), S(p)>p (superlinear), S(p)<p (sublinear).",
                                    "Anote a fórmula em um cartão de estudo."
                                  ],
                                  "verification": "Escreva a fórmula corretamente e calcule S(2) para T(1)=80s, T(2)=40s.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Cartão de estudo",
                                    "Calculadora simples"
                                  ],
                                  "tips": "Sempre verifique unidades de tempo iguais antes de dividir.",
                                  "learningObjective": "Aplicar corretamente a fórmula S(p) = T(1)/T(p).",
                                  "commonMistakes": [
                                    "Dividir ao contrário: T(p)/T(1)",
                                    "Esquecer de especificar p"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Praticar Cálculos de Speedup Passo a Passo",
                                  "subSteps": [
                                    "Colete dados: Escolha T(1) e T(p) de um benchmark real (ex: matrix multiplication).",
                                    "Calcule: Divida T(1) por T(p), arredonde para 2 casas decimais.",
                                    "Repita com 3 exemplos variados: um linear, um sublinear, um superlinear.",
                                    "Registre resultados em tabela: p | T(1) | T(p) | S(p) | Interpretação.",
                                    "Use software como Excel para validar cálculos."
                                  ],
                                  "verification": "Complete tabela com 3 cálculos corretos sem erros aritméticos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Dados de benchmark (ex: de artigos sobre OpenMP)"
                                  ],
                                  "tips": "Teste com números grandes para praticar precisão decimal.",
                                  "learningObjective": "Executar cálculos precisos de speedup manualmente e com ferramentas.",
                                  "commonMistakes": [
                                    "Arredondamento prematuro",
                                    "Erro de divisão simples"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar e Analisar Resultados de Speedup",
                                  "subSteps": [
                                    "Compare S(p) com p: =p (ideal linear), <p (overhead comum), >p (cache effects).",
                                    "Explique causas: sublinear (comunicação), superlinear (localidade de dados).",
                                    "Crie gráfico: eixo X=p, Y=S(p) para múltiplos p.",
                                    "Discuta implicações: quando aumentar p não vale a pena.",
                                    "Aplique a um caso: 'Por que S(4)=2.5 é bom?'"
                                  ],
                                  "verification": "Interprete 2 speedups: um sublinear e um superlinear, justificando.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Ferramenta de gráficos como Desmos ou Excel",
                                    "Exemplos de papers sobre speedup"
                                  ],
                                  "tips": "Busque padrões: overhead aumenta com p em redes.",
                                  "learningObjective": "Interpretar speedup em contextos reais de desempenho.",
                                  "commonMistakes": [
                                    "Achar superlinear 'ruim'",
                                    "Ignorar overheads como causa sublinear"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes: T(1) = 100 segundos (1 CPU), T(4) = 30 segundos (4 CPUs). Calcule S(4) = 100 / 30 ≈ 3.33. Interpretação: sublinear (3.33 < 4), devido a overhead de sincronização entre threads.",
                              "finalVerifications": [
                                "Calcule S(p) corretamente para 5 conjuntos de dados fornecidos.",
                                "Interprete todos como linear, sublinear ou superlinear com justificativa.",
                                "Identifique causas potenciais para desvios do ideal.",
                                "Crie tabela de speedup para p=1 a 8 com dados hipotéticos.",
                                "Explique speedup em um relatório de 1 parágrafo."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: divisão exata e arredondamento correto (100%).",
                                "Interpretação qualitativa: classificação e explicação coerentes.",
                                "Uso de exemplos reais: conexão com benchmarks paralelos.",
                                "Clareza na documentação: tabelas e gráficos legíveis.",
                                "Profundidade analítica: discussão de limitações e overheads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Divisão e análise de razões ( Álgebra básica).",
                                "Física: Analogia com trabalho e potência em sistemas paralelos.",
                                "Engenharia de Software: Otimização de algoritmos distribuídos.",
                                "Estatística: Análise de variância em tempos de execução."
                              ],
                              "realWorldApplication": "Em data centers, calcular speedup ajuda a decidir quantos núcleos usar em tarefas como machine learning, evitando desperdício de recursos e otimizando custos em clouds como AWS."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.1.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.5.1.1.1.3",
                            "name": "Identificar speedup linear",
                            "description": "Reconhecer o speedup linear como o caso ideal onde S(p) = p, sem overheads de comunicação ou sincronização, e discutir condições para alcançá-lo em programas paralelos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito Fundamental de Speedup",
                                  "subSteps": [
                                    "Revise a definição de speedup: S(p) = T(1) / T(p), onde T(1) é o tempo serial e T(p) é o tempo com p processadores.",
                                    "Analise gráficos de speedup típico versus ideal.",
                                    "Compare speedup real com speedup teórico em exemplos simples.",
                                    "Identifique fatores que desviam o speedup do ideal, como overheads.",
                                    "Calcule speedup manualmente para um programa serial simples."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula de speedup e dê um exemplo numérico correto.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Acesso a notas de aula sobre programação paralela",
                                    "Calculadora ou planilha para cálculos",
                                    "Gráficos de speedup de referências online (ex: Wikipedia Speedup)"
                                  ],
                                  "tips": "Comece com exemplos pequenos para fixar a fórmula antes de complicar.",
                                  "learningObjective": "Dominar a definição e cálculo básico de speedup.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Ignorar que T(p) pode ser maior que T(1) devido a overheads",
                                    "Usar p incorretamente na fórmula"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir e Visualizar Speedup Linear",
                                  "subSteps": [
                                    "Defina speedup linear: S(p) = p, onde o tempo paralelo é exatamente 1/p do serial.",
                                    "Desenhe o gráfico de speedup linear (linha reta y = p).",
                                    "Compare com curvas de speedup sublinear e superlinear.",
                                    "Discuta por que S(p) = p é o caso ideal sem overheads.",
                                    "Calcule exemplos onde S(p) = p para p=2,4,8."
                                  ],
                                  "verification": "Produza um gráfico manual ou digital mostrando S(p)=p e explique suas propriedades.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Papel e caneta ou ferramenta de gráficos como Desmos/GeoGebra",
                                    "Referência: Livro 'Introduction to Parallel Computing' de Grama et al."
                                  ],
                                  "tips": "Use cores coloridas para diferenciar curvas ideal vs real nos gráficos.",
                                  "learningObjective": "Reconhecer visual e matematicamente o speedup linear como ideal.",
                                  "commonMistakes": [
                                    "Achar que speedup linear é sempre alcançável",
                                    "Confundir com eficiência linear (E(p)=1)",
                                    "Desenhar gráfico não linear"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar Condições Necessárias para Speedup Linear",
                                  "subSteps": [
                                    "Liste condições: trabalho perfeitamente paralelizável (Amdahl 100%), sem overheads de comunicação/sincronização.",
                                    "Explique ausência de overheads: latência zero, largura de banda infinita.",
                                    "Discuta escalabilidade forte vs fraca para speedup linear.",
                                    "Analise impacto de granularidade de tarefas.",
                                    "Crie uma tabela resumindo condições e violações comuns."
                                  ],
                                  "verification": "Liste e justifique pelo menos 4 condições em uma tabela com exemplos de violação.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Lei de Amdahl/Gustafson em PDF",
                                    "Ferramenta de tabela como Google Sheets"
                                  ],
                                  "tips": "Relacione condições à Lei de Amdahl para maior clareza.",
                                  "learningObjective": "Entender pré-requisitos teóricos e práticos para S(p)=p.",
                                  "commonMistakes": [
                                    "Ignorar overheads de sincronização como barreiras",
                                    "Confundir paralelismo perfeito com balanceamento de carga",
                                    "Subestimar custos de memória compartilhada"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Identificação em Programas Paralelos Simples",
                                  "subSteps": [
                                    "Examine código serial de soma de array e sua versão paralela ideal (ex: OpenMP com #pragma omp parallel for).",
                                    "Simule execução com p=1,2,4 processadores assumindo zero overhead.",
                                    "Meça speedup teórico e identifique se é linear.",
                                    "Modifique código adicionando sincronização e observe perda de linearidade.",
                                    "Discuta quando speedup linear é aproximado na prática."
                                  ],
                                  "verification": "Execute simulação ou código e produza relatório com cálculos de S(p) confirmando linearidade.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Compilador com OpenMP (GCC)",
                                    "Código exemplo de soma paralela",
                                    "Cronômetro para medições simuladas"
                                  ],
                                  "tips": "Use arrays pequenos para simulações manuais rápidas.",
                                  "learningObjective": "Identificar speedup linear em contextos de programação real.",
                                  "commonMistakes": [
                                    "Não considerar tempo de inicialização paralela",
                                    "Assumir hardware infinito sem gargalos",
                                    "Erros em medições de tempo"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de soma de 1 milhão de elementos em array: serial T(1)=10s. Com 4 processadores ideais (divisão perfeita, zero comunicação), cada processador soma 250k elementos em 2.5s, S(4)=10/2.5=4 (linear). Adicionar barreira de redução quebra linearidade para S(4)=3.2.",
                              "finalVerifications": [
                                "Calcule S(p) para p=8 em exemplo dado e confirme =8.",
                                "Liste 3 condições para linearidade sem hesitação.",
                                "Desenhe gráfico correto de S(p)=p vs real.",
                                "Explique por que overheads impedem linearidade em 90% dos casos.",
                                "Identifique speedup linear em novo exemplo de matriz simples."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição S(p)=p (100% correto).",
                                "Compreensão completa de condições (cobre todos os 4 principais).",
                                "Exemplos práticos relevantes e cálculos exatos.",
                                "Análise qualitativa de overheads impactantes.",
                                "Gráficos e tabelas claros e rotulados.",
                                "Aplicação correta em código paralelo simulado."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Funções lineares e gráficos de proporcionalidade.",
                                "Física: Escalabilidade em sistemas dinâmicos e lei de escala.",
                                "Engenharia de Software: Otimização de algoritmos paralelos.",
                                "Estatística: Análise de desempenho e variância em medições."
                              ],
                              "realWorldApplication": "Em supercomputadores como o Frontier (top TOP500), speedup linear é alvo em benchmarks como HPL para ranking, alcançado em kernels matemáticos puros com MPI otimizado e redes de alta velocidade, permitindo simulações climáticas em horas ao invés de meses."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.1.1.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.1.1.2",
                        "name": "Eficiência",
                        "description": "A eficiência quantifica quão bem o speedup se aproxima do ideal, normalizando pelo número de processadores. Fórmula E(p) = S(p)/p, variando de 0 a 1, onde 1 indica uso perfeito dos recursos.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.1.1.2.1",
                            "name": "Definir o conceito de eficiência",
                            "description": "Descrever a eficiência como E(p) = S(p)/p, medindo a fração do tempo útil por processador em relação ao ideal, e sua relação com overheads em programação paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Speedup como Base para Eficiência",
                                  "subSteps": [
                                    "Revise a definição de speedup S(p) = T(1)/T(p), onde T(1) é o tempo sequencial e T(p) é o tempo com p processadores.",
                                    "Identifique que o speedup ideal é p, mas na prática é menor devido a overheads.",
                                    "Discuta limitações de Amdahl para contextualizar perdas de performance.",
                                    "Calcule um exemplo simples: T(1)=100s, T(4)=30s → S(4)=100/30≈3.33.",
                                    "Registre a diferença entre speedup ideal e real."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o que é speedup e forneça um cálculo correto de exemplo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Folha de papel, calculadora, notas sobre programação paralela básica.",
                                  "tips": "Sempre normalize pelo tempo sequencial para comparações justas.",
                                  "learningObjective": "Entender speedup como métrica fundamental antes de eficiência.",
                                  "commonMistakes": "Confundir speedup com tempo absoluto; ignorar que speedup não pode exceder p."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir a Fórmula de Eficiência E(p)",
                                  "subSteps": [
                                    "Apresente a fórmula E(p) = S(p)/p, onde E(p) é a eficiência com p processadores.",
                                    "Interprete E(p) como a fração do tempo útil por processador em relação ao ideal (máximo=1).",
                                    "Derive intuitivamente: se S(p)=p, E=1 (100% eficiente); se S(p)<p, E<1.",
                                    "Calcule exemplo: Para S(4)=3.33, E(4)=3.33/4≈0.833 ou 83.3%.",
                                    "Pratique com valores: T(1)=100s, T(8)=15s → S(8)=6.67, E(8)=0.833."
                                  ],
                                  "verification": "Escreva a fórmula E(p) e calcule corretamente para 2 exemplos dados.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Calculadora, planilha Excel ou Python para cálculos rápidos.",
                                  "tips": "Expresse eficiência em porcentagem para clareza (E*100%).",
                                  "learningObjective": "Dominar a fórmula e interpretação de eficiência.",
                                  "commonMistakes": "Dividir incorretamente (ex: p/S(p)); esquecer de normalizar por p."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Relacionar Eficiência com Overheads em Programação Paralela",
                                  "subSteps": [
                                    "Explique overheads: comunicação, sincronização, carga desbalanceada que reduzem S(p) e assim E(p).",
                                    "Discuta como overheads crescem com p, fazendo E(p) cair (lei de Gustafson como contraponto).",
                                    "Analise gráfico: plote S(p) e E(p) vs p para um programa com 90% paralelizado.",
                                    "Identifique cenários: baixa eficiência em apps com muita comunicação (ex: MPI all-reduce).",
                                    "Compare: eficiência alta em tarefas embaralháveis vs baixa em dependentes."
                                  ],
                                  "verification": "Descreva 3 tipos de overheads e como impactam E(p), com exemplo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Gráfico impresso ou ferramenta como Matplotlib/Excel para plotar curvas.",
                                  "tips": "Use lei de Amdahl para quantificar: overhead ≈ 1 - fração paralelizável.",
                                  "learningObjective": "Conectar eficiência matematicamente a causas práticas de perda.",
                                  "commonMistakes": "Atribuir toda perda a hardware; ignorar escalabilidade do código."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Interpretar Eficiência em um Caso Prático",
                                  "subSteps": [
                                    "Escolha um programa simples (ex: soma de array paralelo vs sequencial).",
                                    "Meça tempos T(1), T(p) em código real ou simulado.",
                                    "Calcule S(p) e E(p) para p=2,4,8.",
                                    "Interprete: se E cai abaixo de 50%, investigue overheads específicos.",
                                    "Documente conclusões em relatório curto."
                                  ],
                                  "verification": "Forneça cálculos completos e interpretação para um programa dado.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Ambiente de programação (Python com multiprocessing ou OpenMP).",
                                  "tips": "Teste em máquina real para overheads autênticos; use wall-clock time.",
                                  "learningObjective": "Aplicar conceito para análise crítica de performance.",
                                  "commonMistakes": "Usar CPU time em vez de wall time; não isolar variáveis."
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes NxN com OpenMP: T(1)=10s em 1 thread, T(8)=2s em 8 threads. S(8)=5, E(8)=5/8=0.625 (62.5%). Overhead de sincronização (barreiras) explica a perda de 37.5%.",
                              "finalVerifications": [
                                "Deriva corretamente E(p) = S(p)/p de definições básicas.",
                                "Calcula eficiência para dados fornecidos com precisão >99%.",
                                "Explica impacto de 3 overheads comuns na eficiência.",
                                "Interpreta E(p)<0.5 como sinal de problema escalável.",
                                "Compara E(p) para diferentes p em gráfico.",
                                "Aplica conceito a exemplo real sem erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na fórmula e cálculos (obrigatório).",
                                "Profundidade na explicação de overheads (3+ exemplos).",
                                "Clareza na interpretação (fração útil por processador).",
                                "Uso correto de exemplos práticos e gráficos.",
                                "Identificação de limitações e cenários de alta/baixo E.",
                                "Capacidade de derivar intuitivamente de speedup."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Frações e razões proporcionais (E como rendimento).",
                                "Física: Eficiência energética em motores (analogia com perda por atrito).",
                                "Economia: Eficiência alocativa de recursos (retorno por unidade investida).",
                                "Engenharia de Software: Métricas de qualidade e otimização de código."
                              ],
                              "realWorldApplication": "Em data centers, eficiência guia alocação de CPUs em jobs de ML; baixa E indica necessidade de refatorar para reduzir comunicação em frameworks como Spark ou TensorFlow distribuído, economizando custos em nuvem."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.1.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.5.1.1.2.2",
                            "name": "Calcular eficiência a partir de speedup",
                            "description": "Usar a fórmula E(p) = S(p)/p para computar a eficiência, analisando exemplos onde overheads reduzem E(p) abaixo de 1 e interpretando impactos no escalonamento.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Conceitos Fundamentais de Speedup e Eficiência",
                                  "subSteps": [
                                    "Defina speedup S(p) como T(1)/T(p), onde T(1) é tempo sequencial e T(p) é tempo com p processadores.",
                                    "Explique eficiência E(p) como medida de utilização efetiva do paralelismo.",
                                    "Discuta fatores que limitam speedup, como lei de Amdahl e overheads (comunicação, sincronização).",
                                    "Compare speedup ideal (S(p)=p) com real (S(p)<p).",
                                    "Identifique cenários onde E(p) < 1 devido a overheads crescentes."
                                  ],
                                  "verification": "Escreva definições de S(p) e E(p) e dê um exemplo onde S(p) ≠ p.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Notas de aula sobre métricas de desempenho paralelo",
                                    "Gráfico da lei de Amdahl",
                                    "Calculadora"
                                  ],
                                  "tips": [
                                    "Visualize speedup como uma curva sublinear; eficiência normaliza por p.",
                                    "Use exemplos simples com p=2 primeiro."
                                  ],
                                  "learningObjective": "Compreender definições e limitações teóricas de speedup e eficiência.",
                                  "commonMistakes": [
                                    "Confundir speedup com número de processadores.",
                                    "Ignorar que overheads crescem com p."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender e Memorizar a Fórmula de Eficiência",
                                  "subSteps": [
                                    "Memorize E(p) = S(p) / p, onde eficiência é speedup dividido pelo número de processadores.",
                                    "Derive a fórmula: se todos processadores são 100% utilizados, S(p)=p, logo E(p)=1.",
                                    "Calcule manualmente: para S(4)=2.8, E(4)=2.8/4=0.7.",
                                    "Entenda unidades: E(p) é adimensional, entre 0 e 1.",
                                    "Discuta interpretação: E(p)=0.5 significa 50% de uso efetivo."
                                  ],
                                  "verification": "Derive E(p) a partir de S(p) e p, e calcule para p=8, S=5.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Fórmulas impressas",
                                    "Planilha Excel para cálculos",
                                    "Vídeo tutorial de 5 min sobre métricas"
                                  ],
                                  "tips": [
                                    "Sempre divida S(p) por p; pratique com frações para precisão.",
                                    "Lembre: E(p) diminui se overheads dominam."
                                  ],
                                  "learningObjective": "Dominar a fórmula E(p) = S(p)/p e sua derivação intuitiva.",
                                  "commonMistakes": [
                                    "Usar E(p)=S(p)*p em vez de dividir.",
                                    "Esquecer que p é inteiro >1."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Praticar Cálculos de Eficiência a Partir de Speedup",
                                  "subSteps": [
                                    "Colete dados de exemplo: T(1)=100s, T(4)=35s → S(4)=100/35≈2.86 → E(4)=2.86/4=0.715.",
                                    "Calcule para múltiplos p: p=2,4,8 com speedups dados.",
                                    "Use ferramentas para automatizar: escreva fórmula em Python ou Excel.",
                                    "Varie cenários: speedup superlinear (raro) vs sublinear.",
                                    "Registre resultados em tabela: p | S(p) | E(p)."
                                  ],
                                  "verification": "Crie tabela com 3 cálculos corretos de E(p) para speedups fornecidos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Exemplos de dados de benchmark",
                                    "Python ou Excel",
                                    "Papel e lápis"
                                  ],
                                  "tips": [
                                    "Arredonde para 3 casas decimais; valide com S(p)=p → E=1.",
                                    "Teste com p=1: E=1 sempre."
                                  ],
                                  "learningObjective": "Executar cálculos precisos de eficiência manualmente e com ferramentas.",
                                  "commonMistakes": [
                                    "Erro aritmético em divisão.",
                                    "Usar tempo paralelo diretamente sem speedup."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Overheads e Impactos no Escalonamento",
                                  "subSteps": [
                                    "Identifique overheads: comunicação (Amdahl), load imbalance, I/O.",
                                    "Analise exemplo: S(16)=10 devido a overheads → E(16)=10/16=0.625 <1.",
                                    "Interprete: escalonamento pobre se E cai rápido com p.",
                                    "Compare curvas: plot E(p) vs p para programas ideais vs reais.",
                                    "Discuta decisão: adicionar mais processadores só se E>0.5."
                                  ],
                                  "verification": "Explique por que E(16)<1 em um exemplo e sugira otimização.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráficos de speedup real (ex: NAS benchmarks)",
                                    "Ferramenta de plot como Matplotlib",
                                    "Artigos sobre overheads paralelos"
                                  ],
                                  "tips": [
                                    "Overheads quadráticos em p destroem escalonamento; foque neles.",
                                    "Use log scale para plots de E(p)."
                                  ],
                                  "learningObjective": "Interpretar eficiência abaixo de 1 e impactos no design de sistemas paralelos.",
                                  "commonMistakes": [
                                    "Atribuir queda de E só a Amdahl, ignorando overheads variáveis.",
                                    "Achar E>1 possível (só em superlinear raro)."
                                  ]
                                }
                              ],
                              "practicalExample": "Programa de multiplicação de matrizes: T(1)=1000s. Com 16 processadores, T(16)=150s → S(16)=1000/150≈6.67 → E(16)=6.67/16=0.417. Overheads de comunicação reduziram eficiência para 41.7%, indicando necessidade de otimizar MPI_Allreduce.",
                              "finalVerifications": [
                                "Calcule E(p) corretamente para 3 cenários com S(p) e p dados.",
                                "Identifique overheads em um gráfico de speedup sublinear.",
                                "Explique verbalmente por que E(p) cai abaixo de 1 com p crescente.",
                                "Compare E para dois programas: um escalável vs um não.",
                                "Preveja E(32) baseado em tendência de E(16)."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos: erro <1% em E(p).",
                                "Correta identificação de overheads causando E<1.",
                                "Interpretação qualitativa: impacto no escalonamento forte/fraco.",
                                "Uso correto da fórmula em exemplos variados.",
                                "Análise crítica: sugestões de melhoria baseadas em E.",
                                "Apresentação clara de tabelas/plots."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise numérica, funções sublineares e otimização.",
                                "Física: Eficiência em sistemas termodinâmicos e rendimento energético.",
                                "Engenharia de Software: Design de algoritmos paralelos e profiling.",
                                "Economia: ROI em hardware paralelo (custo vs ganho de speedup)."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, engenheiros calculam eficiência para otimizar workloads de IA/ML, decidindo alocação de nós GPU e evitando overheads que desperdiçam energia em data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.1.1.1.2",
                              "10.1.5.1.1.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.1.1.2.3",
                            "name": "Analisar relação entre speedup e eficiência",
                            "description": "Comparar speedup e eficiência em cenários reais, identificando quando alta eficiência implica bom escalonamento e fatores como Lei de Amdahl que limitam ambos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar definições fundamentais de Speedup e Eficiência",
                                  "subSteps": [
                                    "Defina speedup como S(p) = T(1)/T(p), onde T(1) é tempo serial e T(p) é tempo com p processadores.",
                                    "Defina eficiência como E(p) = S(p)/p, expressando a fração útil do paralelismo.",
                                    "Compare as fórmulas em um quadro comparativo, destacando que eficiência mede overhead.",
                                    "Calcule exemplos simples: speedup=4 com 8 processadores implica eficiência=0.5.",
                                    "Discuta limites teóricos: speedup máximo = p, eficiência máxima = 1."
                                  ],
                                  "verification": "Criar um resumo escrito com definições e fórmulas corretas, validado por auto-teste com exemplos numéricos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Folha de papel ou editor de texto",
                                    "Referências: Livro de Programação Paralela (ex: Pacheco)",
                                    "Calculadora"
                                  ],
                                  "tips": "Use diagramas para visualizar T(1) vs T(p); memorize S(p) ≤ p.",
                                  "learningObjective": "Compreender precisamente as definições e fórmulas de speedup e eficiência.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Esquecer divisão por p na eficiência",
                                    "Ignorar overheads implícitos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a relação matemática entre Speedup e Eficiência",
                                  "subSteps": [
                                    "Derive E(p) = [T(1)/T(p)] / p, mostrando que eficiência cai se T(p) cresce mais que linear.",
                                    "Analise gráfico: plote S(p) e E(p) para p=1 a 16 em cenários ideais vs reais.",
                                    "Identifique quando alta eficiência implica bom escalonamento: E próximo de 1 significa S próximo de p.",
                                    "Calcule casos: se E=0.8 com p=4, S=3.2 (bom); se E=0.2, S=0.8 (ruim).",
                                    "Discuta implicações: eficiência baixa indica gargalos não paralelizáveis."
                                  ],
                                  "verification": "Produzir gráficos e cálculos corretos em uma planilha (ex: Excel/Google Sheets), com interpretação escrita.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Planilha eletrônica",
                                    "Software de plotagem (ex: Python Matplotlib ou Excel)",
                                    "Amostras de dados de benchmarks"
                                  ],
                                  "tips": "Comece com p pequeno para intuitividade; use cores diferentes para S e E nos gráficos.",
                                  "learningObjective": "Dominar a dependência matemática e gráfica entre speedup e eficiência.",
                                  "commonMistakes": [
                                    "Assumir linearidade perfeita",
                                    "Erro em derivações algébricas",
                                    "Ignorar normalização por p"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Incorporar a Lei de Amdahl na análise da relação",
                                  "subSteps": [
                                    "Estude Lei de Amdahl: S(p) ≤ 1 / (f + (1-f)/p), onde f é fração serial.",
                                    "Derive eficiência: E(p) = S(p)/p ≤ [1 / (f + (1-f)/p)] / p.",
                                    "Simule cenários: f=0.05 (5% serial) → S(100)=18.2, E=0.182 (limitado por f).",
                                    "Compare: alta eficiência requer f baixo; Amdahl explica por que E cai com p alto.",
                                    "Calcule trade-offs: reduza f para melhorar ambos S e E."
                                  ],
                                  "verification": "Implementar simulador simples em Python ou planilha para variar f e p, gerando tabela de S/E.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python ou planilha",
                                    "Código template para Lei de Amdahl",
                                    "Documentação da lei"
                                  ],
                                  "tips": "Teste extremos: f=0 (Gustafson ideal) vs f=1 (sem ganho); foque em f realista (1-10%).",
                                  "learningObjective": "Aplicar Lei de Amdahl para explicar limitações na relação speedup-eficiência.",
                                  "commonMistakes": [
                                    "Confundir f com paralelismo",
                                    "Erro na fórmula Amdahl (esquecer /p)",
                                    "Ignorar impacto assintótico"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar cenários reais e sintetizar insights",
                                  "subSteps": [
                                    "Selecione benchmark real (ex: matrix multiplication serial vs OpenMP).",
                                    "Meça T(1), T(p) em máquina multi-core, calcule S(p) e E(p).",
                                    "Identifique fatores limitantes: overhead comunicação, load imbalance (além Amdahl).",
                                    "Compare cenários: bom escalonamento (E>0.7) vs pobre (E<0.3), ligando a f e overheads.",
                                    "Conclua: alta E implica bom S só se gargalos minimizados."
                                  ],
                                  "verification": "Relatório com medições reais, gráficos S/E e análise de fatores limitantes.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Máquina multi-core",
                                    "Códigos de benchmark (ex: OpenMP matrix mult)",
                                    "Ferramentas de timing (gettimeofday)"
                                  ],
                                  "tips": "Use p powers-of-2; rode múltiplas vezes para média; compare com teoria Amdahl.",
                                  "learningObjective": "Aplicar conceitos em cenários reais para analisar trade-offs práticos.",
                                  "commonMistakes": [
                                    "Medições imprecisas (sem warm-up)",
                                    "Atribuir tudo a Amdahl ignorando overheads",
                                    "Escala errada nos eixos gráficos"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes NxN: serial T(1)=10s em 1 core; paralelo com 4 cores T(4)=3s → S(4)=3.33, E(4)=0.83 (bom, f~0.05). Com load imbalance, T(4)=6s → S=1.67, E=0.42 (ruim, eficiência baixa apesar speedup moderado). Lei de Amdahl prevê limite se f alto.",
                              "finalVerifications": [
                                "Explicar verbalmente como E = S/p e por que E diminui com p.",
                                "Calcular S e E corretos para dados fornecidos, incluindo Amdahl.",
                                "Identificar em gráfico quando alta E implica bom escalonamento.",
                                "Simular cenário com f=0.1, p=16 e validar S≤9.1, E≤0.57.",
                                "Analisar benchmark real e listar 3 fatores limitantes além Amdahl.",
                                "Discutir caso onde S alto mas E baixa (ex: overhead dominante)."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas fórmulas e cálculos (S, E, Amdahl) >95%.",
                                "Compreensão clara da relação: alta E → bom S só sem gargalos.",
                                "Uso correto de Lei de Amdahl em simulações e análises reais.",
                                "Qualidade de gráficos e exemplos práticos (legíveis, interpretados).",
                                "Identificação de fatores reais (overhead, imbalance) além teoria.",
                                "Síntese coerente: limites e melhorias para escalonamento."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Derivações algébricas, limites assintóticos e gráficos.",
                                "Física/Engenharia: Modelagem de sistemas paralelos como simulações numéricas.",
                                "Economia/Gestão: Otimização de recursos (processadores como 'capital').",
                                "Estatística: Análise de variância em benchmarks e médias de timings."
                              ],
                              "realWorldApplication": "Em design de supercomputadores (ex: TOP500), otimização de apps cloud (AWS parallel jobs) ou IA distribuída (treino de modelos em GPUs), onde analisa-se speedup/eficiência para dimensionar clusters, reduzir custos energéticos e prever escalabilidade em data centers."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.1.1.1.3",
                              "10.1.5.1.1.2.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.2",
                    "name": "Lei de Amdahl",
                    "description": "Modelo teórico que limita o speedup máximo baseado na porção sequencial do programa.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.2.1",
                        "name": "Definição e Fórmula da Lei de Amdahl",
                        "description": "Apresentação do modelo teórico proposto por Gene Amdahl que estabelece o limite superior para o ganho de desempenho (speedup) em programas paralelos, considerando a fração sequencial do código.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.1.1",
                            "name": "Compreender o conceito de speedup",
                            "description": "Explicar o que é speedup em programação paralela como a razão entre o tempo de execução sequencial e o tempo de execução paralelo, e sua importância na avaliação de desempenho.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Básicos de Tempo Sequencial e Paralelo",
                                  "subSteps": [
                                    "Defina tempo de execução sequencial como o tempo total para executar uma tarefa em um único processador.",
                                    "Defina tempo de execução paralelo como o tempo para executar a mesma tarefa usando múltiplos processadores.",
                                    "Compare os dois tempos, destacando que o paralelo geralmente é menor devido à divisão de trabalho.",
                                    "Identifique partes sequenciais que não podem ser paralelizadas.",
                                    "Discuta o impacto da paralelização no tempo total."
                                  ],
                                  "verification": "Explique em suas próprias palavras a diferença entre tempo sequencial e paralelo, com um diagrama simples.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Vídeo introdutório sobre programação paralela (ex: YouTube - 'Parallel Computing Basics'), papel e caneta para diagramas.",
                                  "tips": "Use analogias cotidianas, como cozinhar uma refeição sozinho (sequencial) vs com amigos (paralelo).",
                                  "learningObjective": "Diferenciar tempo sequencial de tempo paralelo e reconhecer limitações da paralelização.",
                                  "commonMistakes": "Confundir tempo paralelo com zero ou ignorar overheads como comunicação entre processadores."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender a Definição e Fórmula de Speedup",
                                  "subSteps": [
                                    "Estude a definição: Speedup = Tempo Sequencial / Tempo Paralelo (S = Ts / Tp).",
                                    "Memorize a fórmula e entenda que speedup ideal é igual ao número de processadores (p), mas raramente alcançado.",
                                    "Analise componentes: speedup depende da fração paralelizada (P) e overheads.",
                                    "Escreva a fórmula em notação matemática: S(p) = 1 / [(1 - P) + P/p].",
                                    "Diferencie speedup real de speedup teórico."
                                  ],
                                  "verification": "Escreva a fórmula de speedup e explique cada termo em um parágrafo curto.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Artigo ou slide sobre Lei de Amdahl (ex: Wikipedia - Amdahl's Law), calculadora.",
                                  "tips": "Anote a fórmula em um flashcard e recite-a em voz alta para fixação.",
                                  "learningObjective": "Dominar a definição precisa e a fórmula matemática de speedup.",
                                  "commonMistakes": "Invertar a fórmula (Tp/Ts em vez de Ts/Tp) ou esquecer que speedup >1 indica melhoria."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Speedup em Exemplos Simples",
                                  "subSteps": [
                                    "Escolha um programa exemplo: ordenação de 1 milhão de elementos, Ts=100s, Tp=30s com 4 processadores.",
                                    "Calcule speedup: S = 100/30 ≈ 3.33.",
                                    "Varie parâmetros: mude Tp para 25s e recalcule.",
                                    "Use a fórmula de Amdahl para prever speedup com fração P=0.9 e p=4.",
                                    "Registre resultados em uma tabela comparativa."
                                  ],
                                  "verification": "Resolva 3 problemas de cálculo de speedup e verifique com uma calculadora online.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Planilha Excel ou Google Sheets para cálculos, exemplos de código simples em Python (sequencial vs multiprocessing).",
                                  "tips": "Comece com números redondos para facilitar cálculos manuais antes de usar ferramentas.",
                                  "learningObjective": "Aplicar a fórmula de speedup em cenários numéricos para validar compreensão.",
                                  "commonMistakes": "Arredondar incorretamente ou não considerar que speedup não pode exceder p sem superlinearidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar a Importância do Speedup na Avaliação de Desempenho",
                                  "subSteps": [
                                    "Discuta como speedup mede eficiência de paralelização.",
                                    "Analise limitações: Lei de Amdahl mostra que partes sequenciais limitam speedup máximo.",
                                    "Compare com métricas como eficiência (E = S/p).",
                                    "Pesquise casos onde speedup baixo indica gargalos.",
                                    "Reflita sobre trade-offs: custo de hardware vs ganho de speedup."
                                  ],
                                  "verification": "Escreva um ensaio curto (200 palavras) sobre por que speedup é crucial para decidir paralelizar um programa.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Casos de estudo (ex: papers sobre HPC - High Performance Computing), fórum Stack Overflow sobre speedup.",
                                  "tips": "Relacione com aplicações reais como machine learning para maior engajamento.",
                                  "learningObjective": "Compreender o papel do speedup na otimização e avaliação de sistemas paralelos.",
                                  "commonMistakes": "Superestimar speedup ignorando overheads de sincronização ou memória."
                                }
                              ],
                              "practicalExample": "Em um programa de processamento de imagem que aplica filtro blur: tempo sequencial em um core = 120 segundos; com 8 cores paralelos = 20 segundos. Speedup = 120/20 = 6x. Isso mostra eficiência, mas Lei de Amdahl revela que 20% sequencial limita speedup máximo para 5x.",
                              "finalVerifications": [
                                "Defina speedup corretamente sem consultar notas.",
                                "Calcule speedup para um exemplo dado com precisão >95%.",
                                "Explique impacto de fração sequencial no speedup.",
                                "Diferencie speedup de eficiência paralela.",
                                "Identifique quando speedup não vale o custo de paralelização.",
                                "Descreva limitação da Lei de Amdahl em um diagrama."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e fórmula de speedup (30%).",
                                "Habilidade em cálculos numéricos corretos (25%).",
                                "Compreensão de limitações e importância prática (20%).",
                                "Uso correto de exemplos e analogias (15%).",
                                "Clareza na explicação escrita/oral (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo de razões e limites (Lei de Amdahl).",
                                "Física: Analogia com trabalho e potência em sistemas dinâmicos.",
                                "Economia: Análise custo-benefício de hardware paralelo.",
                                "Engenharia de Software: Métricas de desempenho e benchmarking."
                              ],
                              "realWorldApplication": "Em data centers da Google ou AWS, speedup guia a escolha entre CPUs multi-core e GPUs para tarefas como treinamento de IA, reduzindo tempo de processamento de dias para horas e economizando energia/milhoes em custos operacionais."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.2",
                            "name": "Identificar a fração sequencial (f)",
                            "description": "Reconhecer e quantificar a porção do programa que não pode ser paralelizada, representada pela fração f na fórmula da Lei de Amdahl.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Definição da Fração Sequencial (f)",
                                  "subSteps": [
                                    "Estude a Lei de Amdahl: Speedup = 1 / [(1 - f)/p + f], onde f é a fração do tempo total executada sequencialmente.",
                                    "Identifique que f representa partes do programa que não podem ser divididas em threads paralelas, como inicializações ou I/O.",
                                    "Diferencie f de (1-f): f é sequencial, (1-f) é paralelizado.",
                                    "Revise exemplos clássicos: loops independentes vs. dependências de dados.",
                                    "Anote a importância: f limita o speedup máximo, mesmo com infinitos processadores."
                                  ],
                                  "verification": "Explique em suas palavras o que é f e dê um exemplo simples de código sequencial.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Documentação da Lei de Amdahl (Wikipedia ou slides do curso), caderno para anotações.",
                                  "tips": "Use analogias: f é como o tempo de cozinhar o arroz enquanto o resto pode ser feito em paralelo.",
                                  "learningObjective": "Definir precisamente f e seu papel na fórmula de Amdahl.",
                                  "commonMistakes": "Confundir f com a fração paralelizada; assumir que f é sempre zero em programas 'paralelizáveis'."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Estrutura de um Programa para Identificar Partes Sequenciais",
                                  "subSteps": [
                                    "Obtenha o código-fonte ou fluxograma do programa alvo.",
                                    "Marque seções com dependências: loops com redução, locks, ou operações globais.",
                                    "Ignore partes independentes: loops puros sem dependências de dados.",
                                    "Classifique instruções: sequenciais (ex: serialização de resultados) vs. candidatas a paralelo.",
                                    "Crie um diagrama destacando blocos sequenciais."
                                  ],
                                  "verification": "Produza um fluxograma anotado mostrando partes sequenciais em negrito.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Editor de código (VS Code), ferramenta de fluxograma (Draw.io), exemplo de código de programação paralela.",
                                  "tips": "Procure por 'barreiras' como MPI_Barrier ou atomic operations.",
                                  "learningObjective": "Reconhecer padrões de código que forçam execução sequencial.",
                                  "commonMistakes": "Subestimar overheads de sincronização como sequenciais; classificar erroneamente loops vetorizáveis."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Medir o Tempo de Execução Sequencial",
                                  "subSteps": [
                                    "Execute o programa em modo serial e meça tempo total (T_serial).",
                                    "Force execução sequencial das partes suspeitas e meça seu tempo (T_seq).",
                                    "Use profilers para tempos por função: gprof, perf ou Intel VTune.",
                                    "Repita medições múltiplas (média de 5 runs) para precisão.",
                                    "Calcule f preliminar: f = T_seq / T_serial."
                                  ],
                                  "verification": "Registre tabela de tempos com média e desvio padrão.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Computador com compilador (GCC com OpenMP), profiler instalado, código de exemplo.",
                                  "tips": "Aqueça o cache com runs iniciais; isole variáveis como input size.",
                                  "learningObjective": "Coletar dados empíricos para quantificar f.",
                                  "commonMistakes": "Medir apenas uma run (ruído); incluir overheads de paralelismo em T_serial."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e Validar a Fração f",
                                  "subSteps": [
                                    "Some tempos de todas partes sequenciais identificadas para T_seq total.",
                                    "Compute f = T_seq / T_total_serial.",
                                    "Valide: execute com paralelismo e compare speedup previsto vs. real.",
                                    "Ajuste f iterativamente se discrepâncias >10%.",
                                    "Documente f final com justificativa."
                                  ],
                                  "verification": "Gere relatório com f calculado, fórmula aplicada e gráfico de speedup.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Planilha (Excel/Google Sheets) para cálculos, gráfico de speedup.",
                                  "tips": "Use f ≈ 0.05-0.2 em apps reais; valores >0.5 indicam gargalos sérios.",
                                  "learningObjective": "Quantificar f de forma precisa e validada.",
                                  "commonMistakes": "Arredondar f prematuramente; ignorar escalabilidade com input size."
                                }
                              ],
                              "practicalExample": "Em um programa de processamento de imagem (ex: blur filter com OpenMP), o loop de leitura de arquivo e normalização final são sequenciais (f=0.1), enquanto o blur principal é paralelizado. Meça: T_serial=10s, T_seq=1s → f=0.1. Speedup max=1/0.1=10x.",
                              "finalVerifications": [
                                "Explicar f sem consultar notas.",
                                "Identificar corretamente partes sequenciais em código fornecido.",
                                "Calcular f de dados de tempo com erro <5%.",
                                "Prever speedup usando f em fórmula de Amdahl.",
                                "Discutir limitações de medição de f.",
                                "Aplicar em novo exemplo não visto."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de partes sequenciais (80%+ acurácia).",
                                "Correção matemática no cálculo de f (erro <2%).",
                                "Qualidade das medições (múltiplas runs, profiling usado).",
                                "Clareza na documentação e diagramas.",
                                "Validação cruzada com speedup real.",
                                "Profundidade na análise de erros comuns."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Frações, limites assintóticos (lim p→∞).",
                                "Estatística: Medição de tempos, cálculo de médias e desvios.",
                                "Engenharia de Software: Profiling e análise de performance.",
                                "Física/Computação Científica: Modelagem de workloads paralelos."
                              ],
                              "realWorldApplication": "Em data centers (ex: Google Cloud), identificar f otimiza alocação de CPUs/GPUs, reduzindo custos em 20-50%; em apps mobile, minimiza bateria em tarefas paralelas como ML inference."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.3",
                            "name": "Memorizar a fórmula da Lei de Amdahl",
                            "description": "Recitar e derivar a fórmula S(p) = 1 / (f + (1 - f)/p), onde S(p) é o speedup com p processadores e f é a fração sequencial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os componentes da fórmula da Lei de Amdahl",
                                  "subSteps": [
                                    "Identifique cada variável: S(p) como speedup, p como número de processadores, f como fração sequencial.",
                                    "Explique o significado: f representa a parte que não pode ser paralelizada.",
                                    "Analise o denominador: f + (1 - f)/p, onde (1 - f) é a fração paralelizável.",
                                    "Discuta limites: quando p→∞, S→1/f.",
                                    "Compare com speedup ideal: speedup linear seria p."
                                  ],
                                  "verification": "Escreva definições precisas de S(p), f e p em um papel e confirme com uma fonte confiável.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Folha de papel ou editor de texto",
                                    "Referência: Wikipedia ou livro de programação paralela"
                                  ],
                                  "tips": "Use mnemônicos como 'Speedup = 1 / (sequencial + paralelo/p)' para fixar.",
                                  "learningObjective": "Entender o significado matemático e conceitual de cada termo na fórmula.",
                                  "commonMistakes": "Confundir f com fração paralelizável (é sequencial); inverter S(p) e p."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Memorizar a fórmula através de repetição ativa",
                                  "subSteps": [
                                    "Escreva a fórmula 10 vezes de memória: S(p) = 1 / (f + (1 - f)/p).",
                                    "Cubra a fórmula e recite em voz alta 5 vezes.",
                                    "Associe a uma imagem: imagine f como uma barreira fixa e (1-f)/p como divisão de trabalho.",
                                    "Use flashcards: frente com 'Lei de Amdahl', verso com fórmula.",
                                    "Teste intervalado: recite após 1 min, 5 min e 10 min."
                                  ],
                                  "verification": "Recite a fórmula corretamente 3 vezes consecutivas sem olhar.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Flashcards (app como Anki ou papel)",
                                    "Cronômetro"
                                  ],
                                  "tips": "Repita em contextos diferentes: caminhando, escrevendo, falando.",
                                  "learningObjective": "Fixar a fórmula exata na memória de curto e médio prazo.",
                                  "commonMistakes": "Escrever errado o denominador como f + (1-f)*p em vez de /p."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar intuitivamente a fórmula",
                                  "subSteps": [
                                    "Comece com tempo sequencial total T = f*T + (1-f)*T.",
                                    "Tempo com p processadores: T_p = f*T + (1-f)*T / p.",
                                    "Speedup S(p) = T / T_p = 1 / (f + (1-f)/p).",
                                    "Pratique derivação em 3 exemplos numéricos simples.",
                                    "Explique para um 'aluno imaginário' os passos da derivação."
                                  ],
                                  "verification": "Derive a fórmula do zero em menos de 2 minutos e calcule um exemplo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora",
                                    "Papel para derivação"
                                  ],
                                  "tips": "Sempre normalize T=1 para simplificar: f + (1-f)/p.",
                                  "learningObjective": "Capacitar derivação lógica para reforçar memorização.",
                                  "commonMistakes": "Esquecer de dividir a parte paralela por p; confundir frações."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Reforçar com prática e autoavaliação",
                                  "subSteps": [
                                    "Calcule S para f=0.2, p=4; verifique: S≈1.6.",
                                    "Varie parâmetros: teste p=10, f=0.1; memorize padrões.",
                                    "Crie quiz: 5 perguntas sobre fórmula e valores.",
                                    "Ensine a fórmula para outra pessoa ou grave vídeo.",
                                    "Revise erros e repita steps fracos."
                                  ],
                                  "verification": "Resolva 5 problemas de speedup corretamente sem consultar.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Planilha Excel ou Python para cálculos",
                                    "Quiz impresso"
                                  ],
                                  "tips": "Use curvas de speedup para visualizar limites.",
                                  "learningObjective": "Consolidar memorização com aplicação prática.",
                                  "commonMistakes": "Arredondar errado ou ignorar limite assintótico."
                                }
                              ],
                              "practicalExample": "Para um programa onde 10% é sequencial (f=0.1) e 90% paralelizável, com 10 processadores (p=10), speedup S(10) = 1 / (0.1 + 0.9/10) = 1 / (0.1 + 0.09) = 1/0.19 ≈ 5.26x, não os 10x ideais.",
                              "finalVerifications": [
                                "Recitar a fórmula S(p) = 1 / (f + (1 - f)/p) perfeitamente.",
                                "Definir corretamente S(p), f e p.",
                                "Derivar a fórmula em menos de 1 minuto.",
                                "Calcular speedup para f=0.05, p=100 corretamente (≈9.52x).",
                                "Explicar por que speedup não é linear com p.",
                                "Identificar limite superior como 1/f."
                              ],
                              "assessmentCriteria": [
                                "Precisão na recitação: 100% correta.",
                                "Compreensão conceitual: explicar fração sequencial.",
                                "Derivação fluida sem erros matemáticos.",
                                "Aplicação numérica: acertos em ≥90% dos cálculos.",
                                "Retenção: recall imediato e após 24h.",
                                "Criatividade: gerar exemplos próprios."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra e limites assintóticos.",
                                "Física: Analogia com gargalos em sistemas físicos.",
                                "Economia: Otimização de recursos limitados.",
                                "Gestão: Análise de eficiência em projetos paralelos."
                              ],
                              "realWorldApplication": "Em data centers da AWS ou Google, arquitetos usam a Lei de Amdahl para decidir se vale adicionar mais servidores a uma aplicação, evitando gastos desnecessários em paralelização ineficaz."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.2.2",
                        "name": "Componentes do Tempo de Execução",
                        "description": "Análise dos componentes sequencial e paralelo do tempo total de execução de um programa, base para aplicação da Lei de Amdahl.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.2.1",
                            "name": "Decompor o tempo de execução total",
                            "description": "Dividir o tempo de execução T(1) em Ts (sequencial) e Tp (paralelo), onde f = Ts / T(1) e (1 - f) = Tp / T(1).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos de Ts, Tp e T(1) na Lei de Amdahl",
                                  "subSteps": [
                                    "Revise a Lei de Amdahl: speedup máximo S(p) = 1 / (f + (1-f)/p), onde f é a fração sequencial.",
                                    "Defina T(1) como o tempo total de execução com 1 processador.",
                                    "Identifique Ts como o tempo sequencial (não paralelizado) e Tp como o tempo paralelo.",
                                    "Memorize as relações: f = Ts / T(1) e (1 - f) = Tp / T(1).",
                                    "Desenhe um diagrama simples mostrando T(1) = Ts + Tp."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as definições de Ts, Tp e T(1), e desenhe o diagrama corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Papel e caneta ou ferramenta de desenho digital (ex: Draw.io), notas da Lei de Amdahl.",
                                  "tips": "Use analogias como cozinhar: parte sequencial (esperar água ferver) vs. paralela (cortar ingredientes).",
                                  "learningObjective": "Compreender os componentes fundamentais do tempo de execução na programação paralela.",
                                  "commonMistakes": "Confundir f com fração paralela; assumir que Ts é sempre pequeno sem análise."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar um Programa para Identificar Fração Sequencial f",
                                  "subSteps": [
                                    "Selecione um programa exemplo com partes sequenciais (ex: inicialização, I/O) e paralelas (loops computacionais).",
                                    "Meça ou estime T(1) executando o programa com 1 thread.",
                                    "Profile o código para medir tempos de seções sequenciais usando ferramentas como gprof ou perf.",
                                    "Calcule f aproximando Ts como soma de tempos sequenciais observados.",
                                    "Ajuste f iterativamente comparando com benchmarks conhecidos."
                                  ],
                                  "verification": "Produza um relatório com perfil de código mostrando seções e tempos estimados para f.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Compilador (GCC/Clang), profiler (perf ou gprof), código exemplo em C/MPI ou OpenMP.",
                                  "tips": "Comece com códigos simples; foque em loops e I/O como candidatos a Ts.",
                                  "learningObjective": "Desenvolver habilidade em profiling para estimar frações sequencial e paralela.",
                                  "commonMistakes": "Ignorar overheads de sincronização ao estimar Tp; superestimar paralelismo em I/O-bound codes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Ts e Tp a Partir de T(1) e f",
                                  "subSteps": [
                                    "Colete valores: T(1) medido e f estimado.",
                                    "Aplique fórmulas: Ts = f * T(1); Tp = (1 - f) * T(1).",
                                    "Verifique se Ts + Tp = T(1) (deve ser exato).",
                                    "Registre valores em uma tabela com unidades (segundos).",
                                    "Teste sensibilidade variando f em ±10% e observe impactos."
                                  ],
                                  "verification": "Mostre cálculos matemáticos corretos e tabela com Ts + Tp = T(1).",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Calculadora ou planilha (Excel/Google Sheets), valores de T(1) e f do passo anterior.",
                                  "tips": "Use precisão decimal; arredonde para 4 casas após experiments reais.",
                                  "learningObjective": "Executar decomposição quantitativa precisa de tempos de execução.",
                                  "commonMistakes": "Erro aritmético em multiplicação; esquecer de converter unidades de tempo."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e Aplicar a Decomposição em Cenários de Speedup",
                                  "subSteps": [
                                    "Calcule speedup teórico S(p) usando a Lei de Amdahl com Ts e Tp.",
                                    "Execute o programa com p=2,4 processadores e compare T(p) real vs. predito.",
                                    "Ajuste f se discrepâncias >10%.",
                                    "Documente limitações (ex: overheads não capturados em Ts).",
                                    "Discuta como reduzir Ts para melhor escalabilidade."
                                  ],
                                  "verification": "Gere gráfico de speedup medido vs. teórico com boa concordância.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Cluster ou máquina multi-core, scripts de benchmark, ferramenta de plot (Matplotlib ou Excel).",
                                  "learningObjective": "Integrar decomposição com previsão de performance paralela.",
                                  "commonMistakes": "Não considerar overheads de comunicação; assumir escalabilidade perfeita para Tp."
                                }
                              ],
                              "practicalExample": "Considere um programa de matriz multiplicação: T(1) = 10 segundos medidos. Profiling mostra 2s em inicialização sequencial (f=0.2), logo Ts=2s, Tp=8s. Com 4 processadores, speedup teórico = 1 / (0.2 + 0.8/4) ≈ 1.67x, validado por execução real em ~6s.",
                              "finalVerifications": [
                                "Ts + Tp = T(1) exatamente.",
                                "f calculado está entre 0 e 1.",
                                "Speedup teórico bate com medições reais dentro de 10%.",
                                "Perfil do código identifica corretamente seções sequenciais.",
                                "Documentação inclui fórmulas e valores numéricos.",
                                "Gráfico de speedup vs. p mostra limite de Amdahl."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos de Ts e Tp (100% match com T(1)).",
                                "Qualidade do profiling (cobertura >80% do código).",
                                "Análise de erros e ajustes em f.",
                                "Clareza da documentação e diagramas.",
                                "Aplicação correta na Lei de Amdahl para S(p).",
                                "Identificação de pelo menos 2 estratégias para reduzir Ts."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Frações, proporções e limites assintóticos.",
                                "Engenharia de Software: Profiling e análise de performance.",
                                "Física/Computação Científica: Modelagem de tempos em simulações paralelas.",
                                "Estatística: Análise de variância em benchmarks."
                              ],
                              "realWorldApplication": "Em data centers (ex: AWS), decompor workloads para decidir entre CPUs multi-core vs. GPUs, otimizando custos em treinamento de ML onde I/O sequencial limita speedup."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.2.2",
                            "name": "Calcular o tempo paralelo com múltiplos processadores",
                            "description": "Determinar o tempo de execução paralelo T(p) = Ts + Tp / p, considerando overheads ideais ausentes no modelo.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os componentes da fórmula T(p) = Ts + Tp / p",
                                  "subSteps": [
                                    "Revise a Lei de Amdahl: explique como Ts é a fração serial inalterável e Tp é a fração paralelizable.",
                                    "Defina Ts como tempo serial fixo e Tp como tempo total menos Ts em execução sequencial.",
                                    "Identifique que p representa o número de processadores e /p divide o tempo paralelo igualmente.",
                                    "Note que o modelo assume ausência de overheads ideais para simplificação.",
                                    "Escreva a fórmula em seus próprios termos para internalizar."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito os significados de Ts, Tp e p, confirmando T(1) = Ts + Tp.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Papel e caneta, diagrama da Lei de Amdahl impresso ou digital.",
                                  "tips": "Use analogias como cozinhar: Ts é lavar louça sozinho, Tp é cortar ingredientes com amigos.",
                                  "learningObjective": "Compreender conceitualmente os componentes da fórmula de tempo paralelo.",
                                  "commonMistakes": "Confundir Ts com tempo total sequencial; lembrar que Ts + Tp = T(1)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Ts e Tp a partir de um programa ou benchmark",
                                  "subSteps": [
                                    "Obtenha o tempo de execução sequencial T(1) de um programa exemplo.",
                                    "Meça ou estime a fração serial f_s (ex: 0.2 para 20% serial), então Ts = f_s * T(1).",
                                    "Calcule Tp = T(1) - Ts.",
                                    "Valide somando Ts + Tp para igualar T(1).",
                                    "Registre valores para um caso real, como um benchmark de sorting."
                                  ],
                                  "verification": "Confirme que Ts + Tp = T(1) com cálculos exatos e frações somando 1.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Benchmark de código (ex: código serial em C/Python), cronômetro ou profiler.",
                                  "tips": "Use ferramentas como time em terminal para medir T(1) precisamente.",
                                  "learningObjective": "Extrair corretamente Ts e Tp de dados de execução sequencial.",
                                  "commonMistakes": "Usar frações incorretas; sempre verificar soma das frações =1."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular T(p) para diferentes valores de p",
                                  "subSteps": [
                                    "Escolha valores de p: 1, 2, 4, 8, 16.",
                                    "Para cada p, compute Tp / p e some a Ts.",
                                    "Registre T(p) em uma tabela comparativa com T(1).",
                                    "Calcule speedup S(p) = T(1) / T(p) para validar.",
                                    "Repita com outro conjunto de Ts/Tp para prática."
                                  ],
                                  "verification": "Tabela completa com T(p) decrescente e speedup crescente, sem erros aritméticos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Calculadora ou planilha Excel/Google Sheets para tabelas.",
                                  "tips": "Automatize em Python se possível para múltiplos p.",
                                  "learningObjective": "Aplicar a fórmula numericamente com precisão para vários processadores.",
                                  "commonMistakes": "Esquecer de dividir Tp por p; arredondar prematuramente."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar resultados e limitações do modelo",
                                  "subSteps": [
                                    "Plote T(p) vs p para visualizar saturação.",
                                    "Discuta limite superior: T(p→∞) = Ts, mostrando gargalo serial.",
                                    "Considere cenários reais onde overheads (comunicação) violam o modelo ideal.",
                                    "Compare speedup real vs teórico.",
                                    "Resuma insights em um parágrafo."
                                  ],
                                  "verification": "Gráfico ou tabela mostrando convergência para Ts e discussão escrita de limitações.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Ferramenta de plotagem (Matplotlib, Excel), notas anteriores.",
                                  "tips": "Use log escala para p se speedup variar muito.",
                                  "learningObjective": "Interpretar cálculos no contexto de escalabilidade paralela.",
                                  "commonMistakes": "Ignorar que speedup máximo é 1/f_s; superestimar benefícios infinitos de p."
                                }
                              ],
                              "practicalExample": "Programa de matrix multiplication: T(1)=100s, f_s=0.1 (Ts=10s, Tp=90s). Para p=4: T(4)=10 + 90/4 = 32.5s, speedup=100/32.5≈3.08x.",
                              "finalVerifications": [
                                "T(1) corretamente igual a Ts + Tp.",
                                "T(p) diminui monotonicamente com p crescente.",
                                "Limite T(∞)=Ts identificado.",
                                "Speedup S(p) ≤ 1/f_s respeitado.",
                                "Tabela ou gráfico de T(p) vs p gerado sem erros.",
                                "Discussão de overheads ausentes incluída."
                              ],
                              "assessmentCriteria": [
                                "Precisão aritmética nos cálculos de Ts, Tp e T(p) (erro <1%).",
                                "Correta identificação e uso de frações serial/paralela.",
                                "Interpretação qualitativa de resultados (gargalo serial).",
                                "Uso adequado de ferramentas para medição e plotagem.",
                                "Clareza na tabela/gráfico e explicação escrita.",
                                "Reconhecimento de limitações do modelo ideal."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e funções (f(p)=Ts + Tp/p).",
                                "Física: Modelagem de simulações paralelas em computação científica.",
                                "Engenharia de Software: Otimização de algoritmos distribuídos.",
                                "Estatística: Análise de benchmarks e variância em tempos de execução."
                              ],
                              "realWorldApplication": "Em data centers de cloud computing (ex: AWS), calcular T(p) otimiza alocação de CPUs/GPUs para jobs de ML, reduzindo custos e tempo em treinamentos de redes neurais."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.2.3",
                            "name": "Analisar o impacto da fração paralelizável",
                            "description": "Avaliar como a fração (1 - f) afeta o speedup potencial à medida que p aumenta.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a fórmula da Lei de Amdahl e seus componentes",
                                  "subSteps": [
                                    "Estude a fórmula do speedup: S(p) = 1 / (f + (1 - f)/p), onde f é a fração serial e (1 - f) é a paralelizável.",
                                    "Identifique que f representa o tempo serial inalterado pelo paralelismo.",
                                    "Explique verbalmente o que (1 - f) representa: a porção do tempo de execução que pode ser dividida entre processadores.",
                                    "Calcule manualmente S(p) para p=1 (deve ser 1).",
                                    "Discuta o limite assintótico quando p → ∞: S(∞) = 1 / f."
                                  ],
                                  "verification": "Resuma a fórmula e seus componentes em um parágrafo coerente, confirmando que S(∞) depende inversamente de f.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Folha de papel, calculadora, referência à Lei de Amdahl (artigo ou slide).",
                                  "tips": "Desenhe um diagrama de pizza mostrando f e (1-f) para visualizar as frações.",
                                  "learningObjective": "Compreender matematicamente como a Lei de Amdahl modela o speedup em sistemas paralelos.",
                                  "commonMistakes": "Confundir f com (1-f); assumir que speedup é linear com p."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o papel da fração paralelizável (1 - f)",
                                  "subSteps": [
                                    "Fixe p em valores baixos (ex: p=2,4) e varie f de 0.1 a 0.9, calculando (1-f).",
                                    "Registre como (1-f) maior permite divisão melhor do trabalho entre processadores.",
                                    "Compare S(p) para (1-f)=0.9 vs (1-f)=0.5 com o mesmo p.",
                                    "Note que (1-f) determina o 'teto' do speedup independente de p.",
                                    "Crie uma tabela com 5 cenários variando f."
                                  ],
                                  "verification": "Tabela completa mostrando que para fixed p, S(p) aumenta monotonicamente com (1-f).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Planilha Excel ou Google Sheets para tabelas, calculadora.",
                                  "tips": "Use cores na tabela para destacar impactos: verde para alto (1-f), vermelho para baixo.",
                                  "learningObjective": "Identificar que (1-f) governa o ganho potencial de paralelismo.",
                                  "commonMistakes": "Ignorar que f pequeno (alto 1-f) ainda limita speedup se p não for suficiente."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar numericamente o impacto à medida que p aumenta",
                                  "subSteps": [
                                    "Escolha dois valores de f: 0.05 (1-f=0.95) e 0.5 (1-f=0.5).",
                                    "Calcule S(p) para p=1,2,4,8,16,32,64,128.",
                                    "Plote os resultados em um gráfico (eixo x: log(p), y: S(p)).",
                                    "Observe curvas: para alto (1-f), speedup cresce mais antes de assintotar.",
                                    "Calcule speedup relativo: quanto % de ganho extra com maior (1-f)."
                                  ],
                                  "verification": "Gráfico com curvas convergindo para 1/f, confirmando platô mais alto para menor f.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Software de plotagem (Excel, Python Matplotlib ou papel milimetrado).",
                                  "tips": "Use escala logarítmica no eixo p para melhor visualização de grandes p.",
                                  "learningObjective": "Quantificar como frações paralelizáveis altas maximizam speedup em p elevado.",
                                  "commonMistakes": "Plotar linearmente, perdendo visão de assíntotas; erro aritmético em cálculos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar implicações e limites práticos",
                                  "subSteps": [
                                    "Discuta por que mesmo com p→∞, speedup ≤ 1/f.",
                                    "Avalie cenários reais: se f=0.01, speedup máx=100x; se f=0.2, máx=5x.",
                                    "Considere overheads reais (comunicação) que aumentam f efetivo.",
                                    "Proponha estratégias para reduzir f (refatorar código serial).",
                                    "Escreva um relatório de 200 palavras resumindo achados."
                                  ],
                                  "verification": "Relatório explicando que alto (1-f) é crucial para escalabilidade em p grande.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Editor de texto, exemplos de código paralelo (snippets).",
                                  "tips": "Relacione com lei de Gustafson para contrastar (escala problema com p).",
                                  "learningObjective": "Aplicar análise para decisões de design em programação paralela.",
                                  "commonMistakes": "Superestimar speedup ignorando f; não considerar overheads reais."
                                }
                              ],
                              "practicalExample": "Em um aplicativo de processamento de vídeo (ex: filtro de bordas com OpenMP), 5% do tempo é serial (I/O de frames), f=0.05, (1-f)=0.95. Com 64 núcleos (p=64), speedup ≈ 16x (não 64x), mostrando limite imposto por f. Aumentar (1-f) para 0.99 via paralelização de I/O eleva para ≈32x.",
                              "finalVerifications": [
                                "Calcula corretamente S(p) para f=0.1, p=16 (esperado ≈7.7x).",
                                "Explica por que S(∞)=10x para f=0.1.",
                                "Identifica em gráfico que curvas para menor f assintotam mais alto.",
                                "Propõe redução de f em um exemplo de código.",
                                "Compara speedup para (1-f)=0.8 vs 0.95 em p=32."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos (90%+ correto).",
                                "Compreensão conceitual: explica limite de (1-f) claramente.",
                                "Qualidade visual/numérica de análises (gráficos/tabelas legíveis).",
                                "Profundidade de interpretação: discute implicações práticas.",
                                "Criatividade em exemplos e estratégias de mitigação.",
                                "Clareza na comunicação (relatório/verbal)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise de limites e funções assintóticas.",
                                "Física: Modelagem de simulações paralelas em computação científica.",
                                "Engenharia de Software: Otimização de algoritmos e profiling.",
                                "Estatística: Análise de dados de benchmarks de desempenho."
                              ],
                              "realWorldApplication": "Em data centers de cloud (ex: AWS), analisa-se f em workloads de ML para decidir escalabilidade; alto (1-f) justifica investimento em mais GPUs, otimizando custos em treinamento de redes neurais."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.2.3",
                        "name": "Aplicação e Interpretação do Speedup Máximo",
                        "description": "Cálculo prático do speedup e compreensão das limitações impostas pela Lei de Amdahl em cenários reais de programação paralela.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.3.1",
                            "name": "Realizar cálculos numéricos de speedup",
                            "description": "Aplicar a fórmula para calcular S(p) dado f e p, interpretando resultados em gráficos de speedup vs. processadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a fórmula da Lei de Amdahl e seus parâmetros",
                                  "subSteps": [
                                    "Revise a fórmula S(p) = 1 / (f + (1 - f)/p), onde f é a fração serial e p o número de processadores.",
                                    "Identifique exemplos de frações seriais em aplicações reais, como 10% serial em processamento de imagens.",
                                    "Defina faixas típicas para f (0 a 1) e p (1 a milhares).",
                                    "Calcule manualmente S(1) para qualquer f para verificar que resulta em 1.",
                                    "Discuta limitações: speedup não é linear devido à parte serial."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula e calcule S(1) corretamente para f=0.2.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Folha de papel, calculadora, documento com fórmula da Lei de Amdahl.",
                                  "tips": "Lembre-se: f representa o gargalo serial; quanto menor f, maior o speedup potencial.",
                                  "learningObjective": "Dominar os componentes da fórmula e seu significado físico em computação paralela.",
                                  "commonMistakes": "Confundir f com fração paralelizável (é serial); assumir p ilimitado ignora overheads reais."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar cálculos numéricos de S(p) para valores específicos",
                                  "subSteps": [
                                    "Escolha valores: f=0.1, p=1,2,4,8,16.",
                                    "Calcule passo a passo: para cada p, compute (1-f)/p, some com f, inverta.",
                                    "Registre resultados em tabela: p | S(p).",
                                    "Repita para outro f, como 0.05, comparando speedups.",
                                    "Verifique consistência: S(p) deve aumentar com p, mas assintoticamente para 1/f."
                                  ],
                                  "verification": "Tabela com cálculos corretos para pelo menos 5 valores de p, sem erros aritméticos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Calculadora científica, planilha Excel ou Google Sheets para tabela.",
                                  "tips": "Use precisão decimal alta; arredonde apenas no final para evitar erros de propagação.",
                                  "learningObjective": "Aplicar a fórmula com precisão numérica para múltiplos cenários.",
                                  "commonMistakes": "Erro em divisão: esquecer parênteses em (1-f)/p; inverter f e (1-f)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir e plotar gráfico de speedup vs. número de processadores",
                                  "subSteps": [
                                    "Prepare eixos: X = log(p) de 1 a 1024, Y = S(p).",
                                    "Plote pontos calculados para f fixo.",
                                    "Adicione curva assintótica horizontal em 1/f.",
                                    "Inclua múltiplas curvas para diferentes f (ex: 0.01, 0.1, 0.5).",
                                    "Rotule eixos, título e legenda claramente."
                                  ],
                                  "verification": "Gráfico gerado com curvas corretas, assíntota visível e legenda.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Software de plotagem (Excel, Python com Matplotlib, ou Google Sheets).",
                                  "tips": "Use escala logarítmica no eixo X para visualizar melhor grandes p.",
                                  "learningObjective": "Visualizar comportamento do speedup e limitações da Lei de Amdahl.",
                                  "commonMistakes": "Escala linear em X distorce para p altos; esquecer assíntota."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados do gráfico e cálculos",
                                  "subSteps": [
                                    "Identifique ponto onde speedup dobra (p=2).",
                                    "Analise convergência: quando S(p) atinge 90% de 1/f.",
                                    "Compare cenários: impacto de reduzir f em 1%.",
                                    "Discuta implicações: vale adicionar mais processadores?",
                                    "Relacione com overheads reais não modelados."
                                  ],
                                  "verification": "Relatório curto (3-5 frases) explicando uma observação chave do gráfico.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Gráfico gerado, folha para anotações.",
                                  "tips": "Pergunte: 'O que acontece se f=0?' (speedup linear perfeito).",
                                  "learningObjective": "Extrair insights práticos de dados numéricos e visuais.",
                                  "commonMistakes": "Ignorar que speedup máximo é 1/f; superestimar benefícios para f alto."
                                }
                              ],
                              "practicalExample": "Dado f=0.05 (5% serial em simulação numérica), calcule S(16)=1/(0.05 + 0.95/16) ≈ 9.2. Plote vs. p=1-64, mostrando convergência para 20x. Interprete: adicionar mais de 32 processadores dá pouco ganho.",
                              "finalVerifications": [
                                "Cálculos de S(p) precisos para 5+ valores de p com erro <0.01.",
                                "Gráfico com curvas corretas, assíntotas e escalas adequadas.",
                                "Interpretação identifica limite 1/f e ponto de retornos decrescentes.",
                                "Tabela organizada comparando múltiplos f.",
                                "Explicação verbal coerente sem erros conceituais.",
                                "Aplicação de tips para evitar erros comuns demonstrada."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: fórmulas e cálculos corretos (40%).",
                                "Qualidade visual do gráfico: clareza, rótulos, escalas (20%).",
                                "Profundidade de interpretação: insights sobre limitações (20%).",
                                "Estrutura e organização: tabelas, passos lógicos (10%).",
                                "Criatividade em exemplos: cenários realistas variados (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: funções racionais, limites assintóticos e logaritmos.",
                                "Estatística: plotagem de dados, análise de tendências e curvas de regressão.",
                                "Engenharia de Software: otimização de algoritmos paralelos.",
                                "Física/Computação Científica: modelagem de performance em simulações."
                              ],
                              "realWorldApplication": "Em desenvolvimento de software paralelo para IA ou simulações climáticas, calcular speedup guia decisões de hardware: ex., AWS escolhe instâncias multi-core baseadas em f estimado de benchmarks."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.3.2",
                            "name": "Interpretar o limite assintótico",
                            "description": "Explicar que o speedup máximo é 1/f quando p tende ao infinito, destacando a limitação fundamental da porção sequencial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a fórmula da Lei de Amdahl",
                                  "subSteps": [
                                    "Relembrar a fórmula do speedup: S(p) = 1 / (f + (1-f)/p), onde f é a fração sequencial e p é o número de processadores.",
                                    "Identificar os componentes: fração sequencial (f) e fração paralelizável (1-f).",
                                    "Explicar verbalmente o que cada termo representa no contexto de um programa.",
                                    "Calcular um exemplo simples com valores fixos de f e p variáveis.",
                                    "Discutir por que p afeta apenas a parte paralela."
                                  ],
                                  "verification": "Capacidade de escrever e explicar corretamente a fórmula S(p) em um papel ou quadro.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Calculadora",
                                    "Referência à Lei de Amdahl (folha impressa ou digital)"
                                  ],
                                  "tips": "Use exemplos numéricos iniciais para fixar a fórmula antes de prosseguir para limites.",
                                  "learningObjective": "Compreender a estrutura matemática da Lei de Amdahl como base para o limite assintótico.",
                                  "commonMistakes": [
                                    "Confundir f com fração paralela",
                                    "Esquecer a divisão por p na fração paralelizável"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o limite matemático quando p tende ao infinito",
                                  "subSteps": [
                                    "Reescrever a fórmula focando no denominador: f + (1-f)/p.",
                                    "Examinar o comportamento de (1-f)/p quando p → ∞, que tende a 0.",
                                    "Concluir que lim (p→∞) S(p) = 1 / f.",
                                    "Demonstrar com uma tabela de valores crescentes de p (ex: p=1,10,100,1000) aproximando o limite.",
                                    "Usar notação de limite: lim_{p→∞} S(p) = 1/f."
                                  ],
                                  "verification": "Calcular corretamente o limite para um f dado e mostrar a tabela de aproximação.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets para tabelas",
                                    "Calculadora gráfica",
                                    "Gráfico de S(p) vs p"
                                  ],
                                  "tips": "Plote um gráfico de S(p) para visualizar a assíntota horizontal em 1/f.",
                                  "learningObjective": "Dominar o cálculo e a notação do limite assintótico na Lei de Amdahl.",
                                  "commonMistakes": [
                                    "Achar que o limite é infinito",
                                    "Ignorar que f permanece constante"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar o significado do limite assintótico",
                                  "subSteps": [
                                    "Explicar que 1/f representa o speedup máximo possível, independente do número de processadores.",
                                    "Destacar a limitação fundamental: a porção sequencial (f) 'engarrafa' o desempenho.",
                                    "Discutir implicações: adicionar mais processadores não ajuda além de 1/f.",
                                    "Relacionar com eficiência: mesmo com paralelização perfeita da parte paralela, f limita.",
                                    "Formular uma frase chave: 'O gargalo sequencial define o teto do speedup'."
                                  ],
                                  "verification": "Explicar oralmente ou por escrito por que o speedup não pode exceder 1/f, com exemplo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Quadro branco ou ferramenta de desenho digital",
                                    "Exemplos de programas reais (código fonte)"
                                  ],
                                  "tips": "Use analogias como 'uma estrada com pedágio sequencial' para ilustrar o gargalo.",
                                  "learningObjective": "Interpretar o limite como uma barreira conceitual no paralelismo.",
                                  "commonMistakes": [
                                    "Pensar que f=0 permite speedup infinito (ignorar overheads reais)",
                                    "Confundir limite com valor exato para p finito"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e verificar a interpretação em cenários práticos",
                                  "subSteps": [
                                    "Escolher um programa exemplo com f estimado (ex: f=0.05 para 5% sequencial).",
                                    "Calcular speedup para p grandes e confirmar aproximação a 1/f=20.",
                                    "Analisar: 'Mesmo com 1000 processadores, speedup ≈20 devido a f'.",
                                    "Discutir estratégias para reduzir f (otimizar sequencial).",
                                    "Criar um relatório resumindo interpretação e lições."
                                  ],
                                  "verification": "Produzir um cálculo e interpretação correta para um caso dado, com gráfico.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Software de plotagem (Python/Matplotlib ou Excel)",
                                    "Exemplo de benchmark de programa paralelo"
                                  ],
                                  "tips": "Teste com ferramentas reais como OpenMP para medir f empiricamente.",
                                  "learningObjective": "Aplicar o conceito para validar limitações em contextos reais.",
                                  "commonMistakes": [
                                    "Superestimar paralelização sem medir f",
                                    "Ignorar overheads como comunicação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um algoritmo de processamento de imagem com 10% de código sequencial (f=0.1), o speedup máximo é 10x, mesmo com milhares de processadores. Teste: para p=1000, S≈9.9, confirmando o limite 1/0.1=10.",
                              "finalVerifications": [
                                "Calcula corretamente lim_{p→∞} S(p) = 1/f para valores dados de f.",
                                "Explica verbalmente a limitação da porção sequencial.",
                                "Plota e interpreta gráfico de S(p) mostrando assíntota.",
                                "Identifica em um exemplo real o impacto de f no desempenho.",
                                "Propõe forma de reduzir f para melhorar limite.",
                                "Distingue speedup teórico de prático com overheads."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo do limite assintótico (100% correto).",
                                "Clareza na explicação da interpretação conceitual.",
                                "Uso correto de notação matemática e gráficos.",
                                "Aplicação prática em exemplo com valores numéricos.",
                                "Identificação de implicações para design paralelo.",
                                "Criatividade em analogias ou estratégias de otimização."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo de limites e assíntotas em funções racionais.",
                                "Análise de Algoritmos: Complexidade assintótica e gargalos.",
                                "Física Computacional: Modelos de escalabilidade em simulações paralelas.",
                                "Estatística: Análise de benchmarks e regressão para estimar f.",
                                "Engenharia de Software: Otimização de código sequencial."
                              ],
                              "realWorldApplication": "No desenvolvimento de supercomputadores como os usados em previsão climática ou IA, arquitetos usam essa interpretação para priorizar redução da fração sequencial em códigos legados, evitando investimentos inúteis em mais processadores além do limite 1/f."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.3.3",
                            "name": "Aplicar em estudos de caso",
                            "description": "Usar exemplos de programas reais (ex.: matrizes, simulações) para medir f e prever speedup, relacionando com referências bibliográficas como Grama et al.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e Analisar um Estudo de Caso Real",
                                  "subSteps": [
                                    "Escolha um programa real, como multiplicação de matrizes ou simulação de Monte Carlo.",
                                    "Descreva o algoritmo sequencial e suas partes paralelizáveis.",
                                    "Colete dados de execução sequencial em diferentes tamanhos de entrada.",
                                    "Identifique componentes seriais e paralelos no código fonte.",
                                    "Documente o ambiente de hardware (núcleos, clock) usado."
                                  ],
                                  "verification": "Relatório inicial com descrição do caso, código fonte anotado e tempos sequenciais tabulados.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Código fonte de exemplo (ex.: MATLAB ou C para matrizes), cronômetro de benchmark (ex.: time command), referências como Grama et al. (Introdução à Programação Paralela).",
                                  "tips": "Comece com casos simples para validar medições antes de escalar.",
                                  "learningObjective": "Compreender a estrutura de um programa real para identificar frações seriais e paralelas.",
                                  "commonMistakes": "Ignorar overheads de comunicação ou assumir paralelismo total sem análise."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Medir e Estimar a Fração Serial f",
                                  "subSteps": [
                                    "Execute o programa sequencial múltiplas vezes (média de 10 runs) para tempos estáveis.",
                                    "Implemente versão paralela com p processadores (ex.: OpenMP ou MPI).",
                                    "Meça tempos paralelos para p=2,4,8,... até saturação.",
                                    "Calcule f usando regressão linear: speedup = 1 / (f + (1-f)/p).",
                                    "Valide f com plot de speedup vs 1/p."
                                  ],
                                  "verification": "Gráfico de speedup com linha ajustada e valor de f reportado (erro <5%).",
                                  "estimatedTime": "3 horas",
                                  "materials": "Compilador com suporte paralelo (GCC com OpenMP), ferramenta de plot (Matplotlib ou Excel), hardware multi-core.",
                                  "tips": "Use warm-up runs para evitar cache effects nas medições iniciais.",
                                  "learningObjective": "Determinar empiricamente a fração serial f a partir de benchmarks reais.",
                                  "commonMistakes": "Não fazer múltiplas runs, levando a variância alta; confundir f com overheads."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Prever Speedup com Lei de Amdahl e Validar",
                                  "subSteps": [
                                    "Aplique fórmula: S(p) = 1 / (f + (1-f)/p) para vários p.",
                                    "Compare predições com medições reais em tabela/gráfico.",
                                    "Analise desvios e justifique (ex.: overheads não modelados).",
                                    "Teste sensibilidade variando f em ±10%.",
                                    "Gere relatório com predições vs reais."
                                  ],
                                  "verification": "Tabela comparativa com predito vs medido (acurácia >80% para p≤8).",
                                  "estimatedTime": "2 horas",
                                  "materials": "Planilha ou script Python para cálculos e plots, dados do Step 2.",
                                  "tips": "Linearize a fórmula para melhor ajuste visual: 1/S vs 1/p.",
                                  "learningObjective": "Aplicar Lei de Amdahl para previsão e interpretação de limites de speedup.",
                                  "commonMistakes": "Usar p infinito sem calcular limite teórico S(∞)=1/f."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com Referências Bibliográficas e Concluir",
                                  "subSteps": [
                                    "Compare resultados com estudos em Grama et al. (ex.: casos de matrizes).",
                                    "Discuta limitações da Lei de Amdahl (ex.: escalabilidade, Gustafson).",
                                    "Proponha melhorias no código para reduzir f.",
                                    "Escreva conclusões sobre aplicabilidade prática.",
                                    "Cite fontes e prepare apresentação."
                                  ],
                                  "verification": "Relatório final com citações, análise comparativa e recomendações.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Livro Grama et al., artigos relacionados (ex.: IEEE sobre Amdahl), ferramenta de referências (Zotero).",
                                  "tips": "Use citações diretas para casos similares para fortalecer análise.",
                                  "learningObjective": "Conectar análise prática com teoria bibliográfica para insights profundos.",
                                  "commonMistakes": "Não contextualizar desvios com literatura, isolando o estudo."
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes NxN (N=1000), medida f=0.1 via benchmarks OpenMP em 8 cores. Predição S(8)=4.09 vs medido 3.95; limite S(∞)=10x. Comparado a Grama et al., onde f similar em LU decomposition.",
                              "finalVerifications": [
                                "f estimado empiricamente com gráfico linear ajustado (R²>0.95).",
                                "Predições de speedup coincidem com medições em 80%+ para p=2-16.",
                                "Relatório relaciona explicitamente com Grama et al. (páginas citadas).",
                                "Limite teórico S(∞)=1/f calculado e discutido.",
                                "Propostas de otimização para reduzir f identificadas.",
                                "Todos benchmarks documentados com médias e desvios."
                              ],
                              "assessmentCriteria": [
                                "Precisão na medição de f (erro <10%).",
                                "Qualidade dos gráficos e tabelas (clareza, legendas).",
                                "Profundidade da análise comparativa com literatura.",
                                "Validação rigorosa (múltiplas runs, sensibilidade).",
                                "Clareza e estrutura do relatório final.",
                                "Criatividade em propostas de melhoria."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Regressão linear e análise de curvas para ajuste de f.",
                                "Estatística: Tratamento de variância em benchmarks e testes de hipótese.",
                                "Engenharia de Software: Refatoração de código para paralelismo.",
                                "Pesquisa Científica: Leitura crítica de referências bibliográficas."
                              ],
                              "realWorldApplication": "Otimizar aplicações HPC como simulações climáticas ou processamento de imagens médicas, prevendo ganhos antes de deploy em clusters (ex.: AWS ParallelCluster), economizando custos e tempo em data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.3",
                    "name": "Lei de Gustafson",
                    "description": "Análise de escalabilidade considerando o crescimento do problema com mais processadores.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.3.1",
                        "name": "Definição e Princípios da Lei de Gustafson",
                        "description": "Compreender os fundamentos da Lei de Gustafson, que analisa a escalabilidade de programas paralelos ao considerar o crescimento proporcional do tamanho do problema com o número de processadores, diferentemente da Lei de Amdahl.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.3.1.1",
                            "name": "Explicar o conceito de escalabilidade escalada",
                            "description": "Descrever como a Lei de Gustafson permite que o tempo de execução paralelo cresça com mais processadores, mantendo o tempo serial fixo, e sua relevância para problemas grandes em computação paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender as limitações da Lei de Amdahl",
                                  "subSteps": [
                                    "Revise a fórmula da Lei de Amdahl: Speedup = 1 / (s + (1-s)/p), onde s é fração serial e p é número de processadores.",
                                    "Identifique o problema: speedup limitado pela fração serial, mesmo com problemas grandes.",
                                    "Discuta cenários onde problemas crescem com hardware disponível.",
                                    "Compare com intuição: por que Amdahl não captura escalabilidade para workloads reais grandes.",
                                    "Anote exemplos de aplicações onde serial domina (ex: pequenos problemas)."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito por que Amdahl subestima speedup em problemas escaláveis.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Acesso a notas ou slides sobre Lei de Amdahl",
                                    "Calculadora ou planilha para simulações simples"
                                  ],
                                  "tips": "Use gráficos de speedup vs. processadores para visualizar o platô da Amdahl.",
                                  "learningObjective": "Compreender por que a Lei de Amdahl é inadequada para problemas que crescem com paralelismo.",
                                  "commonMistakes": [
                                    "Confundir fração serial com tempo absoluto",
                                    "Ignorar que problemas reais frequentemente escalam tamanho"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir a motivação da Lei de Gustafson",
                                  "subSteps": [
                                    "Leia a premissa de Gustafson: tempo serial fixo (S), tempo paralelo cresce com processadores (P * (1-S)).",
                                    "Entenda 'scaled speedup': problema size escala com p, mantendo tempo total fixo.",
                                    "Defina escalabilidade escalada: eficiência = S + (1-S)/p.",
                                    "Compare fórmulas: Gustafson foca em eficiência em vez de speedup absoluto.",
                                    "Discuta contexto histórico: resposta a críticas de paralelismo nos anos 80."
                                  ],
                                  "verification": "Reescreva a fórmula de Gustafson e explique a diferença chave com Amdahl em 1 parágrafo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Artigo original de Gustafson (resumo ou PDF)",
                                    "Quadro branco ou papel para diagramas"
                                  ],
                                  "tips": "Pense em 'tempo serial fixo' como setup/inicialização que não muda.",
                                  "learningObjective": "Graspar a mudança de paradigma de speedup para eficiência escalada.",
                                  "commonMistakes": [
                                    "Confundir scaled speedup com weak scaling",
                                    "Achar que serial some com mais processadores"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar a fórmula e componentes da escalabilidade escalada",
                                  "subSteps": [
                                    "Calcule exemplos: Para p=100, S=0.01, eficiência = 0.01 + 0.99/100 = 0.0199 ou ~2%.",
                                    "Não: eficiência Gustafson é p - (p-1)S, ou scaled speedup = p / (S(p-1) + 1).",
                                    "Simule com planilha: varie p de 1 a 1024, fixe S=5%, plote eficiência.",
                                    "Analise componentes: tempo total T(p) = S + p*(1-S)/p = S + (1-S) =1 (normalizado).",
                                    "Interprete: com mais processadores, mais trabalho paralelo, tempo total constante."
                                  ],
                                  "verification": "Crie uma tabela com 3 valores de p calculando scaled speedup e eficiência.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel/Google Sheets",
                                    "Gráficos de linha para visualização"
                                  ],
                                  "tips": "Normalize tempos para 1 unidade total no p=1 para clareza.",
                                  "learningObjective": "Aplicar fórmula de Gustafson em cálculos numéricos para validar conceito.",
                                  "commonMistakes": [
                                    "Usar fórmula de Amdahl por engano",
                                    "Esquecer que (1-S) escala com p"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar conceito à relevância em computação paralela",
                                  "subSteps": [
                                    "Discuta problemas grandes: simulações climáticas, genômica onde size escala com hardware.",
                                    "Compare com strong vs weak scaling: Gustafson alinha com weak scaling.",
                                    "Avalie limitações: ainda depende de S baixa; não cobre comunicação.",
                                    "Conclua vantagens: justifica investimento em mais processadores para big data.",
                                    "Crie diagrama: tempo serial fixo vs. paralelo crescente."
                                  ],
                                  "verification": "Descreva um problema real onde Gustafson aplica melhor que Amdahl.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Exemplos de papers ou cases de supercomputação",
                                    "Ferramenta de desenho como Draw.io"
                                  ],
                                  "tips": "Relacione com HPC: TOP500 machines usam isso para justificar escala.",
                                  "learningObjective": "Reconhecer quando e por quê escalabilidade escalada é relevante.",
                                  "commonMistakes": [
                                    "Aplicar a todos problemas, ignorando overheads de rede",
                                    "Subestimar impacto de S em problemas médios"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação de clima rodando em 1000 processadores: tempo serial S=1% (leitura de dados), tempo paralelo 99%. Com Gustafson, scaled speedup ≈1000 / (999*0.01 +1) ≈ 50.5, eficiência ~5%, mostrando que problema maior usa todos processadores efetivamente, ao contrário de Amdahl que preveria speedup máximo 100.",
                              "finalVerifications": [
                                "Calcule corretamente scaled speedup para S=0.05 e p=256.",
                                "Explique diferença entre Amdahl e Gustafson em <100 palavras.",
                                "Identifique aplicação real de Gustafson (ex: big data).",
                                "Plote gráfico de eficiência vs. processadores.",
                                "Diferencie strong e weak scaling no contexto.",
                                "Liste 2 limitações da Lei de Gustafson."
                              ],
                              "assessmentCriteria": [
                                "Precisão na fórmula e cálculos (exatidão numérica >95%).",
                                "Compreensão conceitual: distinção clara Amdahl vs. Gustafson.",
                                "Uso de exemplos práticos relevantes a HPC.",
                                "Profundidade em componentes (S fixo, P escalando).",
                                "Capacidade de visualização (gráficos/diagramas corretos).",
                                "Relevância para problemas grandes demonstrada."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: análise assintótica e funções lineares em p.",
                                "Física: modelagem de simulações paralelas em dinâmica de fluidos.",
                                "Engenharia de Software: design de algoritmos escaláveis em big data.",
                                "Economia: custo-benefício de hardware em cloud computing."
                              ],
                              "realWorldApplication": "Na processação de dados genômicos no Google Cloud ou simulações em supercomputadores como Frontier, onde o tamanho do problema (sequenciamento de DNA inteiro) escala com núcleos disponíveis, permitindo eficiência alta apesar de overheads seriais fixos em pré-processamento."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.3.1.2",
                            "name": "Identificar limitações da Lei de Amdahl",
                            "description": "Comparar a visão da Lei de Amdahl (problema fixo) com a Lei de Gustafson (problema escalável), destacando cenários onde a Gustafson é mais aplicável, como simulações científicas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os Fundamentos da Lei de Amdahl",
                                  "subSteps": [
                                    "Leia a fórmula da Lei de Amdahl: Speedup = 1 / ((1 - P) + P/N), onde P é a fração paralelizável e N é o número de processadores.",
                                    "Identifique as premissas principais: tamanho do problema é fixo, parte serial limita o speedup.",
                                    "Calcule exemplos simples com P=0.9 e N variando de 1 a 100.",
                                    "Discuta o limite assintótico quando N tende ao infinito.",
                                    "Anote o impacto da fração serial (1-P) no desempenho."
                                  ],
                                  "verification": "Explique em suas palavras as premissas da lei e calcule um speedup para P=0.95 e N=10.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Fórmula da Lei de Amdahl impressa ou digital",
                                    "Calculadora ou planilha Excel",
                                    "Artigo introdutório sobre paralelismo"
                                  ],
                                  "tips": "Sempre isole a fração serial como o gargalo principal; visualize com gráficos de speedup vs. N.",
                                  "learningObjective": "Compreender as premissas de problema fixo e limitação serial da Lei de Amdahl.",
                                  "commonMistakes": [
                                    "Assumir que speedup é linear com N",
                                    "Ignorar que P deve ser <1",
                                    "Confundir P com tempo total"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir os Princípios da Lei de Gustafson",
                                  "subSteps": [
                                    "Estude a fórmula de Gustafson: Scaled Speedup = S + (1-S)*N, onde S é a fração serial escalada.",
                                    "Entenda a premissa chave: tamanho do problema escala com N, permitindo eficiência alta.",
                                    "Compare com Amdahl calculando para N=100 e S=0.05.",
                                    "Discuta como Gustafson modela workloads onde mais processadores resolvem problemas maiores.",
                                    "Exemplifique com simulações científicas que beneficiam de escalabilidade."
                                  ],
                                  "verification": "Descreva como Gustafson difere de Amdahl em termos de escalabilidade do problema e forneça um cálculo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Fórmula da Lei de Gustafson",
                                    "Gráficos comparativos das leis",
                                    "Vídeo curto sobre HPC (High-Performance Computing)"
                                  ],
                                  "tips": "Pense em 'problema escalável' como problemas reais que crescem com hardware disponível.",
                                  "learningObjective": "Explicar como a Lei de Gustafson aborda escalabilidade em problemas variáveis.",
                                  "commonMistakes": [
                                    "Confundir S com (1-P) de Amdahl",
                                    "Aplicar Gustafson a problemas fixos",
                                    "Subestimar o papel de N na escala"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar as Duas Leis e Destacar Limitações da Amdahl",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: premissas (fixo vs. escalável), fórmulas, limites assintóticos.",
                                    "Identifique limitações da Amdahl: subestima speedup em problemas escaláveis; assume serialidade fixa.",
                                    "Simule cenários: problema fixo (Amdahl ideal) vs. escalável (Gustafson melhor).",
                                    "Discuta eficiência: Amdahl bounded por 1/(1-P), Gustafson ~N.",
                                    "Registre quando Amdahl falha: workloads com P alto mas problema crescendo."
                                  ],
                                  "verification": "Preencha uma tabela comparativa e explique uma limitação chave da Amdahl com exemplo numérico.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha para tabelas e cálculos",
                                    "Artigos comparativos Amdahl vs. Gustafson",
                                    "Ferramenta de plotagem como Python Matplotlib"
                                  ],
                                  "tips": "Use gráficos para visualizar curvas de speedup; foque em N grande para ver divergências.",
                                  "learningObjective": "Comparar quantitativamente as leis e listar limitações da Amdahl.",
                                  "commonMistakes": [
                                    "Não diferenciar problema fixo de escalável",
                                    "Ignorar cálculos numéricos",
                                    "Generalizar Amdahl para todos cenários"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Cenários Reais e Concluir Limitações",
                                  "subSteps": [
                                    "Analise cenários onde Gustafson aplica: simulações científicas (clima, molecular), big data.",
                                    "Identifique quando Amdahl limita: apps com alta serialidade fixa (ex: alguns bancos de dados).",
                                    "Debata trade-offs: custo de escalar problema vs. hardware.",
                                    "Crie um fluxograma para escolher lei baseada no workload.",
                                    "Resuma: Amdahl pessimista para HPC moderno."
                                  ],
                                  "verification": "Descreva 2 cenários onde Gustafson é superior e justifique com fórmulas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Casos de estudo HPC (ex: NASA simulations)",
                                    "Fluxograma template",
                                    "Notas dos steps anteriores"
                                  ],
                                  "tips": "Considere supercomputadores atuais; problemas reais raramente são 'fixos'.",
                                  "learningObjective": "Identificar cenários práticos onde limitações da Amdahl são evidentes.",
                                  "commonMistakes": [
                                    "Aplicar Amdahl universalmente",
                                    "Não considerar custo de dados escalados",
                                    "Omitir exemplos concretos"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação climática global, com 100 processadores, Amdahl prevê speedup limitado por 5% serial (max ~20x), mas Gustafson permite ~95x ao escalar resolução espacial/temporal, processando grids maiores e mais precisos.",
                              "finalVerifications": [
                                "Explicar verbalmente as premissas de problema fixo vs. escalável.",
                                "Calcular e comparar speedups para N=64 em ambas leis com P/S=0.9.",
                                "Listar 3 limitações da Amdahl em contextos HPC.",
                                "Identificar 2 cenários científicos onde Gustafson aplica melhor.",
                                "Criar gráfico comparativo de speedup vs. N.",
                                "Debater validade de cada lei em workloads modernos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição das fórmulas e premissas (80% correto).",
                                "Qualidade da comparação quantitativa com cálculos/exemplos.",
                                "Identificação correta de limitações e cenários aplicáveis.",
                                "Profundidade nos substeps e verificações práticas.",
                                "Criatividade em conexões reais e fluxogramas.",
                                "Clareza na comunicação (tabelas, gráficos)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise assintótica e limites de funções.",
                                "Física Computacional: Modelagem de simulações escaláveis.",
                                "Engenharia de Software: Design de sistemas paralelos escaláveis.",
                                "Gestão de Projetos: Avaliação de custo-benefício em HPC.",
                                "Ciência de Dados: Escalabilidade em processamento massivo."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier (Oak Ridge), arquitetos usam Gustafson para justificar escalas em simulações de fusão nuclear ou previsão climática, evitando pessimismo da Amdahl para otimizar alocação de recursos e investimentos em hardware paralelo."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.3.1.3",
                            "name": "Relacionar com taxonomia de Flynn e modelos de memória",
                            "description": "Associar a Lei de Gustafson a arquiteturas paralelas (SIMD, MIMD) e modelos de memória compartilhada ou distribuída, explicando seu impacto na avaliação de desempenho.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude as quatro classes principais: SISD, SIMD, MISD e MIMD.",
                                    "Identifique exemplos de hardware para cada classe (ex: CPU tradicional para SISD, GPUs para SIMD).",
                                    "Analise as vantagens de paralelismo em SIMD e MIMD.",
                                    "Compare MIMD com arquiteturas sequenciais em termos de escalabilidade.",
                                    "Crie um diagrama simples ilustrando as classes."
                                  ],
                                  "verification": "Produzir um resumo escrito ou diagrama corretamente identificando e exemplificando as 4 classes da Taxonomia de Flynn.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação da Taxonomia de Flynn (Wikipedia ou livro de arquitetura de computadores)",
                                    "Papel e caneta ou ferramenta de diagramação como Draw.io"
                                  ],
                                  "tips": "Use mnemônicos para lembrar as classes: Single/Same/Multiple Instruction, Single/Multiple Data.",
                                  "learningObjective": "Compreender as classificações fundamentais de arquiteturas paralelas.",
                                  "commonMistakes": [
                                    "Confundir SIMD com MIMD",
                                    "Ignorar MISD como classe válida",
                                    "Não relacionar com hardware real"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender a Lei de Gustafson",
                                  "subSteps": [
                                    "Leia a definição original: escalabilidade é limitada pelo tamanho do problema, não apenas pelos processadores.",
                                    "Estude a fórmula: Tempo Sequencial fixo + Tempo Paralelizável * P (P=processadores).",
                                    "Compare com a Lei de Amdahl, destacando a diferença (problema fixo vs problema escalável).",
                                    "Calcule exemplos numéricos com diferentes valores de P e fração paralelizável.",
                                    "Discuta implicações para avaliação de desempenho em sistemas paralelos."
                                  ],
                                  "verification": "Resolver um exercício numérico demonstrando escalabilidade usando a fórmula de Gustafson.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Artigo original de John Gustafson",
                                    "Calculadora ou planilha Excel",
                                    "Slides ou vídeo explicativo sobre Leis de Escalabilidade"
                                  ],
                                  "tips": "Sempre considere o problema crescendo com P para captar a essência da lei.",
                                  "learningObjective": "Dominar os princípios matemáticos e conceituais da Lei de Gustafson.",
                                  "commonMistakes": [
                                    "Confundir com Lei de Amdahl",
                                    "Usar problema fixo em cálculos",
                                    "Ignorar o tempo sequencial"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Modelos de Memória Compartilhada e Distribuída",
                                  "subSteps": [
                                    "Defina memória compartilhada (UMA/NUMA) e suas características (acesso uniforme ou não).",
                                    "Defina memória distribuída (clusters, message passing).",
                                    "Compare overheads: latência em compartilhada vs comunicação em distribuída.",
                                    "Relacione com Taxonomia de Flynn: SIMD tipicamente compartilhada, MIMD pode ser ambas.",
                                    "Examine exemplos: OpenMP para compartilhada, MPI para distribuída."
                                  ],
                                  "verification": "Criar uma tabela comparativa entre os dois modelos, com prós, contras e exemplos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de OpenMP e MPI",
                                    "Livro de programação paralela (ex: Tanenbaum)"
                                  ],
                                  "tips": "Pense em escalabilidade: distribuída permite mais nós, mas com custo de comunicação.",
                                  "learningObjective": "Diferenciar modelos de memória e suas implicações em arquiteturas paralelas.",
                                  "commonMistakes": [
                                    "Assumir que MIMD é sempre distribuída",
                                    "Ignorar NUMA em compartilhada",
                                    "Não considerar overhead de sincronização"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Associar Lei de Gustafson a Arquiteturas e Modelos de Memória",
                                  "subSteps": [
                                    "Analise como Gustafson se aplica a SIMD (alta paralelização, problema escalável como imagens).",
                                    "Discuta MIMD com memória compartilhada: limites por contenção de memória.",
                                    "Explore MIMD distribuída: escalabilidade Gustafson mitigada por latência de rede.",
                                    "Explique impacto na avaliação: métrica scaled speedup vs speedup tradicional.",
                                    "Sintetize em um mapa conceitual unindo todos os elementos."
                                  ],
                                  "verification": "Produzir um relatório curto explicando associações e impacto no desempenho.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramenta de mindmap (ex: XMind)",
                                    "Exemplos de benchmarks paralelos"
                                  ],
                                  "tips": "Use scaled speedup de Gustafson para validar arquiteturas reais.",
                                  "learningObjective": "Integrar conceitos para avaliar desempenho em contextos paralelos.",
                                  "commonMistakes": [
                                    "Não considerar modelo de memória no impacto",
                                    "Aplicar Gustafson sem escalabilidade do problema",
                                    "Generalizar SIMD/MIMD sem nuances"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster MIMD com memória distribuída (ex: Hadoop para big data), aplique a Lei de Gustafson para prever que dobrar processadores em um problema escalável (processamento de 2x dados) resulta em ~1.8x speedup, considerando 10% sequencial e overhead de MPI, validando contra benchmarks reais.",
                              "finalVerifications": [
                                "Explicar corretamente as 4 classes da Taxonomia de Flynn com exemplos.",
                                "Calcular scaled speedup usando fórmula de Gustafson para um cenário dado.",
                                "Diferenciar memória compartilhada vs distribuída e associar a MIMD.",
                                "Descrever impacto de Gustafson na escolha de arquitetura para workloads escaláveis.",
                                "Criar diagrama relacionando todos os conceitos.",
                                "Comparar Gustafson vs Amdahl em paralelo/distribuído."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (90% correto na Taxonomia e Lei).",
                                "Profundidade na associação (explicação clara de impactos).",
                                "Uso correto de fórmulas e cálculos numéricos.",
                                "Criatividade em exemplos e diagramas.",
                                "Integração interdisciplinar (menções a aplicações reais).",
                                "Clareza e estrutura na comunicação."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelos assintóticos de complexidade e análise de speedup.",
                                "Engenharia de Software: Design de APIs paralelas (OpenMP/MPI).",
                                "Física Computacional: Simulações paralelas em GPUs (SIMD).",
                                "Administração: Avaliação custo-benefício em cloud computing escalável.",
                                "Redes de Computadores: Latência e topologias em memória distribuída."
                              ],
                              "realWorldApplication": "Na classificação TOP500 de supercomputadores, a Lei de Gustafson é usada para avaliar MIMD distribuídos (ex: Frontier), prevendo desempenho em simulações climáticas escaláveis, guiando investimentos em hardware paralelo."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.3.2",
                        "name": "Fórmula e Cálculo do Scaled Speedup",
                        "description": "Dominar a fórmula matemática da Lei de Gustafson e realizar cálculos para avaliar o speedup em cenários de crescimento do problema.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.3.2.1",
                            "name": "Derivar a fórmula da Lei de Gustafson",
                            "description": "Apresentar a equação S(p) = p + (1 - p) * (Ts / Tp), onde p é a fração paralelizável, Ts tempo serial e Tp tempo paralelo unitário, e derivá-la passo a passo.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais da Lei de Gustafson",
                                  "subSteps": [
                                    "Leia a definição da Lei de Gustafson e sua motivação: aborda limitações da Lei de Amdahl ao considerar problemas que escalam com o número de processadores.",
                                    "Identifique a diferença chave: Gustafson foca em speedup scaled, onde o tamanho do problema aumenta proporcionalmente aos processadores.",
                                    "Anote os componentes principais: fração paralelizável p, tempo serial Ts (fixo), tempo paralelo unitário Tp (por processador para porção paralela).",
                                    "Desenhe um diagrama simples mostrando tempo total com 1 processador vs. múltiplos.",
                                    "Compare verbalmente com Lei de Amdahl em uma frase."
                                  ],
                                  "verification": "Escreva um parágrafo resumindo a motivação da Lei de Gustafson e liste as 3 variáveis principais com suas definições.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Acesso a referência online sobre Leis de Speedup (Amdahl vs Gustafson)",
                                    "Calculadora"
                                  ],
                                  "tips": "Lembre-se: Gustafson assume que mais processadores permitem problemas maiores, mantendo tempo paralelo efetivo constante.",
                                  "learningObjective": "Entender o contexto teórico e as premissas únicas da Lei de Gustafson.",
                                  "commonMistakes": [
                                    "Confundir fração paralelizável p com fração serial",
                                    "Ignorar que Ts é fixo enquanto parte paralela escala",
                                    "Misturar definições de Amdahl"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir as variáveis e expressões iniciais",
                                  "subSteps": [
                                    "Defina p como a fração paralelizável da computação total (0 ≤ p ≤ 1).",
                                    "Defina Ts como o tempo de execução da porção serial, independente do número de processadores.",
                                    "Defina Tp como o tempo de execução da porção paralela unitária (com 1 processador para sua fatia).",
                                    "Escreva a equação do tempo total com 1 processador: T1 = Ts + Tp.",
                                    "Expresse a fração serial como (1 - p) e relacione com Ts e Tp."
                                  ],
                                  "verification": "Liste as definições exatas das 3 variáveis e escreva T1 em termos de Ts e Tp.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Folha de anotações para equações"
                                  ],
                                  "tips": "Use símbolos consistentes: sempre escreva p para paralelizável, Ts serial, Tp paralelo unitário.",
                                  "learningObjective": "Estabelecer notação precisa para derivação algébrica subsequente.",
                                  "commonMistakes": [
                                    "Definir p incorretamente como fração serial",
                                    "Confundir Tp com tempo paralelo total",
                                    "Esquecer que p = Tp / (Ts + Tp) implicitamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Modelar o tempo de execução para problema escalonado",
                                  "subSteps": [
                                    "Considere N processadores: tempo serial permanece Ts.",
                                    "Para problema escalonado, tempo paralelo total torna-se proporcional a N, mas por processador é Tp, então TN = Ts + Tp.",
                                    "Tempo serial hipotético para problema grande com 1 processador: Ts + (1-p)/p * Tp ou relacione via frações.",
                                    "Expresse o tempo do problema grande serializado: T_serial_large = Ts / (1-p) ou derive relação Ts / Tp.",
                                    "Escreva expressões para speedup scaled S como razão entre tempos."
                                  ],
                                  "verification": "Escreva as expressões para TN e T_serial_large, justificando cada termo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Calculadora para testes numéricos iniciais"
                                  ],
                                  "tips": "Pense em termos de frações: (1-p) relaciona-se à proporção serial que dita Ts/Tp.",
                                  "learningObjective": "Modelar tempos de execução sob premissas de escalonamento de Gustafson.",
                                  "commonMistakes": [
                                    "Assumir tempo paralelo divide por N como em Amdahl",
                                    "Não escalonar o problema adequadamente",
                                    "Ignorar fixidez de Tp por processador"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Derivar algebricamente a fórmula do speedup",
                                  "subSteps": [
                                    "Defina speedup S(p) = (tempo problema grande serial) / TN.",
                                    "Substitua expressões: assuma relação onde fator de escala leva a Ts / Tp como multiplicador serial efetivo.",
                                    "Manipule: S(p) = p * (algo) + (1-p) * (Ts / Tp), simplificando passo a passo.",
                                    "Some termos: isole p e (1-p), mostrando S(p) = p + (1 - p) * (Ts / Tp).",
                                    "Verifique com substituição: plugue valores simples (ex: p=1, S=1; p=0, S=Ts/Tp)."
                                  ],
                                  "verification": "Derive a fórmula completa em papel, chegando exatamente a S(p) = p + (1 - p) * (Ts / Tp).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Calculadora simbólica ou app como Wolfram Alpha para checagem"
                                  ],
                                  "tips": "Faça algebra passo a passo, numerando cada linha de manipulação.",
                                  "learningObjective": "Executar derivação algébrica precisa da fórmula final.",
                                  "commonMistakes": [
                                    "Erros aritméticos em fatoração",
                                    "Perder o termo (1-p)",
                                    "Não simplificar corretamente Ts/Tp"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e interpretar a fórmula derivada",
                                  "subSteps": [
                                    "Teste limites: se p=1 (totalmente paralelizável), S=1 + 0*(Ts/Tp)=1? Ajuste interpretação.",
                                    "Calcule exemplo numérico: p=0.9, Ts=10, Tp=1, compute S.",
                                    "Compare com Amdahl para mesmo cenário.",
                                    "Discuta implicações: como Ts/Tp afeta speedup quando p alto.",
                                    "Escreva a fórmula final destacada."
                                  ],
                                  "verification": "Resolva um exemplo numérico e explique verbalmente o resultado.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora",
                                    "Papel para exemplos"
                                  ],
                                  "tips": "Sempre teste extremos: p=0, p=1 para validar lógica.",
                                  "learningObjective": "Confirmar corretude e ganhar intuição sobre a fórmula.",
                                  "commonMistakes": [
                                    "Interpretação errada de limites",
                                    "Confusão em unidades de tempo",
                                    "Não relacionar de volta ao contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere um programa onde p=0.95 (95% paralelizável), Ts=50 segundos (serial), Tp=2 segundos (paralelo unitário). Derivando: S(0.95) = 0.95 + (1-0.95)*(50/2) = 0.95 + 0.05*25 = 0.95 + 1.25 = 2.2. Isso significa speedup scaled de 2.2x ao escalar o problema para usar mais processadores eficientemente.",
                              "finalVerifications": [
                                "Recitar a fórmula S(p) = p + (1 - p) * (Ts / Tp) sem olhar.",
                                "Explicar o papel de cada variável em uma frase.",
                                "Derivar os passos principais de memória.",
                                "Calcular S para p=0.8, Ts=20, Tp=5 corretamente (resposta: 0.8 + 0.2*4 = 1.6).",
                                "Distinguir Gustafson de Amdahl em 2 pontos chave.",
                                "Identificar quando usar essa fórmula (problemas escalonáveis)."
                              ],
                              "assessmentCriteria": [
                                "Precisão algébrica na derivação (sem erros de manipulação).",
                                "Compreensão conceitual das premissas de Gustafson.",
                                "Capacidade de aplicar fórmula em exemplo numérico.",
                                "Clareza nas definições de variáveis.",
                                "Identificação correta de diferenças com Amdahl.",
                                "Validação via testes de limite e exemplos."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Manipulação algébrica e funções lineares.",
                                "Física: Modelagem de sistemas escaláveis e eficiência energética em computação.",
                                "Economia: Análise custo-benefício de recursos computacionais.",
                                "Engenharia de Software: Otimização de desempenho em sistemas distribuídos.",
                                "Estatística: Interpretação de métricas de performance."
                              ],
                              "realWorldApplication": "Em data centers e supercomputadores (ex: clima, genômica), arquitetos usam a Lei de Gustafson para prever speedup ao escalar problemas com mais núcleos/ nós, otimizando alocação de hardware para workloads paralelizáveis altos, como simulações científicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.2.2",
                            "name": "Calcular speedup escalado",
                            "description": "Resolver exercícios numéricos para calcular o scaled speedup com diferentes números de processadores (p), frações paralelas e tempos sequenciais, usando exemplos de Grama et al.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender a fórmula do Scaled Speedup de Gustafson",
                                  "subSteps": [
                                    "Revise a Lei de Gustafson: problemas escalam com o número de processadores p.",
                                    "Memorize a fórmula: S(p) = p × T(1) / T(p), onde T(1) é o tempo sequencial total e T(p) = Ts + Tp / p.",
                                    "Identifique componentes: Ts (tempo sequencial), Tp (tempo paralelo), f = Tp / T(1) (fração paralela), s = 1 - f (fração sequencial).",
                                    "Simplifique: S(p) = p / (s + (1 - s)/p).",
                                    "Estude exemplos de Grama et al., como Ts = 100s, Tp = 900s, T(1) = 1000s."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula e seus componentes para um colega ou em um diário de aprendizado.",
                                  "estimatedTime": "20 minutes",
                                  "materials": [
                                    "Livro 'Introduction to Parallel Computing' de Grama et al. (capítulo relevante)",
                                    "Folha de anotações",
                                    "Calculadora"
                                  ],
                                  "tips": "Desenhe um diagrama mostrando como o problema escala com p para visualizar melhor.",
                                  "learningObjective": "Compreender conceitualmente o scaled speedup e derivar a fórmula básica.",
                                  "commonMistakes": [
                                    "Confundir com Amdahl (não escalado)",
                                    "Usar speedup clássico em problemas escalados",
                                    "Ignorar que T(1) inclui Ts + Tp"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e extrair parâmetros de problemas",
                                  "subSteps": [
                                    "Leia um problema: identifique p, Ts, Tp ou f e T(1).",
                                    "Calcule frações se não dadas: f = Tp / (Ts + Tp), s = Ts / (Ts + Tp).",
                                    "Normalize tempos se necessário: assuma T(1) = 1 para frações puras.",
                                    "Pratique com 2-3 exemplos simples de Grama et al.",
                                    "Anote unidades consistentes (segundos, etc.)."
                                  ],
                                  "verification": "Extraia corretamente parâmetros de 3 problemas exemplo e liste-os em uma tabela.",
                                  "estimatedTime": "15 minutes",
                                  "materials": [
                                    "Exemplos de Grama et al.",
                                    "Planilha Excel ou papel para tabelas",
                                    "Calculadora"
                                  ],
                                  "tips": "Sempre verifique se Ts + Tp = T(1) para validação inicial.",
                                  "learningObjective": "Extrair com precisão os valores de entrada para cálculos de speedup.",
                                  "commonMistakes": [
                                    "Confundir Ts com T(1)",
                                    "Usar fração errada (paralela vs sequencial)",
                                    "Ignorar normalização de tempos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar cálculos passo a passo para um exemplo",
                                  "subSteps": [
                                    "Escolha exemplo: p=4, Ts=100s, Tp=900s, T(1)=1000s.",
                                    "Calcule T(p) = 100 + 900/4 = 100 + 225 = 325s.",
                                    "Aplique S(p) = 4 * 1000 / 325 ≈ 12.31.",
                                    "Verifique com fórmula alternativa: s=0.1, S(p)=4 / (0.1 + 0.9/4) = 4 / 0.325 ≈ 12.31.",
                                    "Registre arredondamentos e precisão."
                                  ],
                                  "verification": "Calcule S(p) para o exemplo e confira com solução conhecida (erro <1%).",
                                  "estimatedTime": "25 minutes",
                                  "materials": [
                                    "Calculadora ou Python/Excel para verificação",
                                    "Exemplos de Grama et al.",
                                    "Papel para cálculos manuais"
                                  ],
                                  "tips": "Use ambos formatos de fórmula para cross-check e pratique aritmética de frações.",
                                  "learningObjective": "Executar cálculo numérico preciso do scaled speedup.",
                                  "commonMistakes": [
                                    "Erro em divisão Tp/p",
                                    "Multiplicar errado por p",
                                    "Arredondar prematuramente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Resolver exercícios variados e interpretar resultados",
                                  "subSteps": [
                                    "Resolva 5 exercícios com p variando (2,8,16), diferentes f (0.5,0.9).",
                                    "Compare S(p) com p: note que S(p) > p possível em Gustafson.",
                                    "Plote gráfico simples de S(p) vs p.",
                                    "Interprete: discuta limites à medida que p aumenta.",
                                    "Crie seu próprio exercício e resolva."
                                  ],
                                  "verification": "Resolva todos exercícios com acertos >90% e interprete um resultado em parágrafo.",
                                  "estimatedTime": "30 minutes",
                                  "materials": [
                                    "Lista de 5 exercícios (criar ou de Grama)",
                                    "Gráfico paper ou ferramenta online como Desmos",
                                    "Calculadora"
                                  ],
                                  "tips": "Varie p e f para ver tendências; foque em interpretação além do número.",
                                  "learningObjective": "Aplicar cálculo em cenários variados e analisar eficiência escalada.",
                                  "commonMistakes": [
                                    "Esperar S(p) <= p como em Amdahl",
                                    "Não interpretar superlinearidade",
                                    "Erros de propagação em cálculos múltiplos"
                                  ]
                                }
                              ],
                              "practicalExample": "Exemplo de Grama et al.: Para um problema de simulação com T(1)=1000s, Ts=100s (10% sequencial), p=64 processadores. T(64)=100 + 900/64 ≈ 100 + 14.06 = 114.06s. Scaled Speedup S(64)=64*1000/114.06 ≈ 561, mostrando superlinearidade devido ao escalonamento do problema.",
                              "finalVerifications": [
                                "Calcule corretamente S(p) para 3 novos exercícios sem erros aritméticos.",
                                "Explique diferença entre scaled speedup e Amdahl em 2 frases.",
                                "Interprete um resultado: 'Por que S(p) > p aqui?'",
                                "Crie e resolva um exercício próprio com p=16, f=0.8.",
                                "Plote S(p) para p=1 a 128 e identifique tendência."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos (erro <0.1%).",
                                "Correta identificação de parâmetros (Ts, Tp, f).",
                                "Interpretação qualitativa dos resultados.",
                                "Uso consistente da fórmula de Gustafson.",
                                "Capacidade de generalizar para novos valores de p e f.",
                                "Clareza na documentação de passos."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e funções racionais (S(p) = p / (s + (1-s)/p)).",
                                "Física: Simulações numéricas em dinâmica de fluidos ou clima, onde problemas escalam.",
                                "Engenharia de Software: Análise de performance em frameworks paralelos como MPI/OpenMP.",
                                "Estatística: Modelagem de eficiência e análise de sensibilidade a parâmetros."
                              ],
                              "realWorldApplication": "Em supercomputação, como no TOP500, arquitetos usam scaled speedup para projetar clusters que escalam problemas reais (ex: modelagem climática no Argonne Lab), prevendo performance para p=10^5 processadores e otimizando alocação de recursos em data centers."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.2.3",
                            "name": "Implementar cálculo em pseudocódigo",
                            "description": "Escrever pseudocódigo ou snippet em linguagens como OpenMP para simular e plotar curvas de speedup Gustafson versus Amdahl.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender e Definir Parâmetros das Leis de Amdahl e Gustafson",
                                  "subSteps": [
                                    "Revise a fórmula de Amdahl: Speedup = 1 / (S + (1-S)/P), onde S é fração serial, P é número de processadores.",
                                    "Revise a fórmula de Gustafson: Scaled Speedup = S + (1-S)*P, considerando problema escalável.",
                                    "Defina parâmetros iniciais: S = 0.1 (10% serial), P variando de 1 a 128.",
                                    "Liste variáveis: serialFraction, numProcessors, amdahlspeedup[], gustafsonSpeedup[].",
                                    "Crie um pseudocódigo skeleton com arrays para armazenar resultados."
                                  ],
                                  "verification": "Confirme que fórmulas estão corretamente anotadas em um documento ou comentário no código.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Editor de texto, papel e caneta para rascunhos, documentação das leis de Amdahl/Gustafson online.",
                                  "tips": "Use exemplos numéricos simples (P=1, P=2) para validar fórmulas manualmente antes de codificar.",
                                  "learningObjective": "Compreender as diferenças matemáticas entre as leis de speedup fixo e escalável.",
                                  "commonMistakes": "Confundir fração serial com paralela; assumir P inicia em 0 em vez de 1."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Cálculo de Speedup Amdahl em Pseudocódigo",
                                  "subSteps": [
                                    "Inicie loop para P de 1 a 128.",
                                    "Calcule speedupAmdahl = 1 / (serialFraction + (1 - serialFraction) / P).",
                                    "Armazene em array amdahlspeedup[P].",
                                    "Adicione tratamento para divisão por zero (P>=1).",
                                    "Teste com S=0.1, P=10: speedup esperado ~5.26."
                                  ],
                                  "verification": "Execute cálculo manual para 3 valores de P e compare com pseudocódigo.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Editor de texto para pseudocódigo, calculadora.",
                                  "tips": "Escreva funções modulares como 'calculateAmdahl(serialFrac, P)' para reutilização.",
                                  "learningObjective": "Implementar precisamente a fórmula de Amdahl em estrutura de loop iterativo.",
                                  "commonMistakes": "Esquecer parênteses na fórmula, levando a ordem errada de operações; usar P=0."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Cálculo de Speedup Gustafson em Pseudocódigo",
                                  "subSteps": [
                                    "No mesmo loop de P, calcule speedupGustafson = serialFraction + (1 - serialFraction) * P.",
                                    "Armazene em array gustafsonSpeedup[P].",
                                    "Teste com S=0.1, P=10: speedup esperado ~9.0.",
                                    "Compare valores lado a lado com Amdahl para o mesmo P.",
                                    "Adicione comentários explicando escalabilidade."
                                  ],
                                  "verification": "Verifique se para P=1, ambos speedups =1; para P grande, Gustafson cresce linearmente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Editor de texto, planilha para validação numérica.",
                                  "tips": "Use pseudocódigo similar ao Amdahl para consistência, facilitando integração.",
                                  "learningObjective": "Capturar a essência da escalabilidade na lei de Gustafson.",
                                  "commonMistakes": "Inverter termos serial e paralelo; não multiplicar pela P corretamente."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Simular Múltiplos Cenários e Integrar OpenMP Snippet Opcional",
                                  "subSteps": [
                                    "Varie serialFraction em [0.05, 0.1, 0.2] e gere dados para cada.",
                                    "Inclua pseudocódigo para OpenMP: #pragma omp parallel for para loop de simulação.",
                                    "Colete dados em estruturas como listas ou arquivos CSV simulados.",
                                    "Adicione varredura de parâmetros P logarítmico (1,2,4,8,...,128).",
                                    "Valide simulação paralela com redução de tempo estimado."
                                  ],
                                  "verification": "Gere tabela de resultados para 3 frações e confira tendências (Amdahl satura, Gustafson cresce).",
                                  "estimatedTime": "1 hora 30 minutos",
                                  "materials": "Compilador OpenMP (g++ com -fopenmp), editor.",
                                  "tips": "Use OpenMP apenas para acelerar simulação se P for grande; foque em serial primeiro.",
                                  "learningObjective": "Aplicar paralelismo na simulação de performance ironicamente.",
                                  "commonMistakes": "Ignorar overheads em OpenMP; loops não balanceados."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Implementar Plotagem das Curvas de Speedup",
                                  "subSteps": [
                                    "Use pseudocódigo para plot: import matplotlib.pyplot as plt; plt.plot(P, amdahlspeedup).",
                                    "Plote curvas Amdahl vs Gustafson no mesmo gráfico, log scale para P.",
                                    "Adicione labels, título 'Speedup Amdahl vs Gustafson (S=0.1)', legenda.",
                                    "Salve como imagem ou exiba.",
                                    "Teste plot para múltiplas S com subplots."
                                  ],
                                  "verification": "Visualize gráfico: Amdahl achata, Gustafson linear; eixos corretos.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python com matplotlib/numpy, ou ferramenta online como Desmos.",
                                  "tips": "Use escala log para P para melhor visualização em HPC.",
                                  "learningObjective": "Visualizar diferenças qualitativas das leis via gráficos.",
                                  "commonMistakes": "Eixos invertidos; não normalizar P=1; legenda ausente."
                                }
                              ],
                              "practicalExample": "Pseudocódigo completo:\nserialFraction = 0.1\nFOR P = 1 to 128 STEP log2\n  amdahl = 1 / (serialFraction + (1-serialFraction)/P)\n  gustafson = serialFraction + (1-serialFraction)*P\n  PLOT(P, amdahl, 'Amdahl')\n  PLOT(P, gustafson, 'Gustafson')\nENDFOR\n#pragma omp parallel for reduction(+:sum) // Opcional para simulação massiva",
                              "finalVerifications": [
                                "Fórmulas implementadas corretamente para P=1 (speedup=1) e P=100.",
                                "Gráfico mostra saturação Amdahl e crescimento linear Gustafson.",
                                "Simulação roda sem erros para 3 valores de serialFraction.",
                                "OpenMP snippet acelera loop se aplicável (>10% ganho).",
                                "Dados salvos/exportados para análise.",
                                "Comentários explicam cada seção do pseudocódigo."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática das fórmulas (erro <0.01).",
                                "Qualidade visual do plot (legendas, escalas adequadas).",
                                "Eficiência da simulação (tempo <5min para 128 P).",
                                "Modularidade do pseudocódigo (funções separadas).",
                                "Validação com casos extremos (S=0, S=1).",
                                "Integração correta de OpenMP sem race conditions."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise de funções limite e assíntotas.",
                                "Estatística: Visualização de dados e gráficos logarítmicos.",
                                "Física/Engenharia: Modelagem de performance em sistemas paralelos.",
                                "Economia: Análise custo-benefício de escalabilidade."
                              ],
                              "realWorldApplication": "Em High-Performance Computing (HPC), otimizar alocação de processadores em supercomputadores como Frontier, prevendo limites de speedup para workloads escaláveis como simulações climáticas ou IA distribuída."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.2.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.3.3",
                        "name": "Aplicações e Análise de Escalabilidade",
                        "description": "Aplicar a Lei de Gustafson em estudos de caso reais, analisando escalabilidade em plataformas multicores, heterogêneas e na nuvem.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.3.3.1",
                            "name": "Analisar estudo de caso em memória distribuída",
                            "description": "Examinar aplicações como decomposição de domínio em troca de mensagens (MPI), aplicando Gustafson para prever desempenho com crescimento do problema.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e compreender o estudo de caso em memória distribuída",
                                  "subSteps": [
                                    "Identificar um estudo de caso relevante, como simulação de dinâmica de fluidos computacional (CFD) usando MPI.",
                                    "Ler e resumir o problema: tamanho do domínio, requisitos de memória e padrões de comunicação.",
                                    "Mapear componentes sequenciais vs. paralelizáveis no contexto de memória distribuída.",
                                    "Documentar restrições de hardware, como número de nós e largura de banda de rede.",
                                    "Definir métricas de desempenho chave: tempo sequencial (Ts), tempo paralelo (Tp) e speedup."
                                  ],
                                  "verification": "Resumo escrito do estudo de caso com métricas identificadas e diagrama de domínio.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Artigo ou documento do estudo de caso (ex: PDF sobre CFD com MPI), papel e caneta ou ferramenta de diagramação como Draw.io.",
                                  "tips": "Escolha um caso real de repositórios como MPI benchmarks para maior relevância.",
                                  "learningObjective": "Compreender o contexto e escopo de um problema de memória distribuída.",
                                  "commonMistakes": "Ignorar overhead de comunicação ou assumir memória compartilhada em vez de distribuída."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Modelar decomposição de domínio e troca de mensagens com MPI",
                                  "subSteps": [
                                    "Dividir o domínio em subdomínios atribuídos a processos MPI.",
                                    "Identificar fronteiras entre subdomínios e padrões de troca de mensagens (ex: ghost cells).",
                                    "Estimar volume de comunicação: número de mensagens e tamanho por iteração.",
                                    "Implementar ou simular um protótipo simples em MPI para validar decomposição.",
                                    "Calcular fração sequencial (s) e paralela (p) baseada na decomposição."
                                  ],
                                  "verification": "Diagrama de decomposição com fluxos de MPI e código MPI mínimo executável.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Compilador MPI (OpenMPI ou MPICH), editor de código (VS Code), máquina com múltiplos cores.",
                                  "tips": "Use MPI_Sendrecv para trocas não-bloqueantes em fronteiras regulares.",
                                  "learningObjective": "Modelar paralelização em memória distribuída com foco em comunicação.",
                                  "commonMistakes": "Subestimar custo de latência em mensagens pequenas ou ignorar balanceamento de carga."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Lei de Gustafson para previsão de escalabilidade",
                                  "subSteps": [
                                    "Relembrar fórmula de Gustafson: Sp = s + p * P, onde P é número de processadores.",
                                    "Calcular tempo sequencial escalado (Ts') = Ts * P e frações ajustadas.",
                                    "Prever speedup para tamanhos de problema crescentes (ex: P=64, 128).",
                                    "Plotar gráfico de speedup vs. tamanho do problema usando ferramentas como Python/Matplotlib.",
                                    "Comparar com lei de Amdahl para destacar diferenças em escalabilidade forte vs. fraca."
                                  ],
                                  "verification": "Gráficos de previsão com cálculos tabulados e speedup > linear para problemas grandes.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Python com NumPy/Matplotlib, planilha (Excel/Google Sheets) para cálculos.",
                                  "tips": "Ajuste frações p e s empiricamente de benchmarks iniciais.",
                                  "learningObjective": "Usar Gustafson para modelar desempenho em problemas escaláveis.",
                                  "commonMistakes": "Confundir com Amdahl (fixo problema) ou usar speedup forte em cenários fracos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar desempenho e interpretar resultados",
                                  "subSteps": [
                                    "Executar simulações ou benchmarks reais com diferentes P e tamanhos de problema.",
                                    "Comparar previsões Gustafson com dados empíricos (tempo real, throughput).",
                                    "Identificar gargalos: comunicação, I/O ou imbalance.",
                                    "Recomendar otimizações, como decomposição 2D ou MPI non-blocking.",
                                    "Documentar limitações e cenários de aplicação."
                                  ],
                                  "verification": "Relatório com tabelas comparativas, gráficos e recomendações acionáveis.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Cluster ou máquina multi-core com MPI, ferramentas de profiling (TAU ou Vampir).",
                                  "tips": "Monitore com mpirun -np P e perfis de comunicação para validação.",
                                  "learningObjective": "Interpretar discrepâncias e otimizar análise de escalabilidade.",
                                  "commonMistakes": "Não considerar overhead de inicialização MPI ou variações de rede."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar análise e preparar conclusões",
                                  "subSteps": [
                                    "Resumir achados chave: escalabilidade demonstrada e limites.",
                                    "Discutir implicações para aplicações reais.",
                                    "Preparar apresentação ou relatório final.",
                                    "Realizar auto-avaliação contra critérios de Gustafson.",
                                    "Planejar extensões futuras, como hybrid MPI+OpenMP."
                                  ],
                                  "verification": "Relatório final completo com conclusões e referências.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Ferramenta de apresentação (PowerPoint/Google Slides), documento do estudo.",
                                  "tips": "Use bullet points para clareza e inclua visualizações.",
                                  "learningObjective": "Sintetizar análise em insights acionáveis.",
                                  "commonMistakes": "Generalizar resultados sem contexto específico do caso."
                                }
                              ],
                              "practicalExample": "Em uma simulação CFD para previsão de tempo em grade 1024x1024, decompor em 64 subdomínios MPI, trocando ghost cells (1KB/msg), aplicar Gustafson para prever speedup de 50x com P=64 e problema 4x maior, validando com execução real mostrando 48x devido a 5% overhead de rede.",
                              "finalVerifications": [
                                "Diagrama de decomposição de domínio preciso com fluxos MPI.",
                                "Cálculos Gustafson corretos com speedup escalável > P para problemas grandes.",
                                "Gráficos comparando previsão vs. empírico com <10% erro.",
                                "Identificação de pelo menos 2 gargalos e otimizações propostas.",
                                "Relatório explicando limitações de memória distribuída vs. compartilhada.",
                                "Benchmark executável reproduzindo resultados chave."
                              ],
                              "assessmentCriteria": [
                                "Precisão na modelagem de comunicação MPI (80%+ match empírico).",
                                "Correta aplicação de Gustafson com frações s/p justificadas.",
                                "Profundidade de análise de gargalos e otimizações (mínimo 3).",
                                "Qualidade de visualizações e documentação clara.",
                                "Capacidade de prever escalabilidade para cenários variados.",
                                "Integração de conceitos paralelos (Amdahl vs. Gustafson).",
                                "Originalidade no exemplo prático adaptado."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelagem numérica e análise assintótica O(n).",
                                "Física/Engenharia: Simulações CFD ou Monte Carlo em HPC.",
                                "Gestão de Projetos: Estimativa de desempenho para escalonamento de clusters.",
                                "Redes de Computadores: Impacto de latência/bandwidth em MPI.",
                                "Big Data: Paralelismo em Spark/Hadoop similar a memória distribuída."
                              ],
                              "realWorldApplication": "Otimizar simulações climáticas em supercomputadores como Frontier (ORNL), prevendo se adicionar nós escala para domínios maiores, reduzindo tempo de simulação de semanas para horas em previsão de furacões ou modelagem molecular em drug discovery."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.3.2",
                            "name": "Avaliar escalabilidade em OpenMP",
                            "description": "Usar exemplos de Van der Pas et al. para medir eficiência em tasking e SIMD, comparando com previsões da Lei de Gustafson em multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos fundamentais de OpenMP, tasking, SIMD e Lei de Gustafson",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP sobre tasking (cláusulas task, taskwait) e SIMD (cláusulas simd, omp_simd).",
                                    "Revise exemplos de Van der Pas et al., focando em eficiência de tasking e SIMD em reduções paralelas.",
                                    "Compreenda a Lei de Gustafson: speedup = s + (1-s)p, onde s é fração serial, p é processadores.",
                                    "Analise diferenças entre Lei de Amdahl e Gustafson para workloads escaláveis.",
                                    "Identifique métricas chave: speedup, eficiência (speedup/p), tempo de execução."
                                  ],
                                  "verification": "Resuma em um documento os conceitos chave e formule 3 perguntas de autoavaliação respondidas corretamente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação OpenMP 5.0+",
                                    "Artigos de Van der Pas (e.g., 'New and Precise Timer Routines'), PDF da Lei de Gustafson"
                                  ],
                                  "tips": "Use diagramas para visualizar tasking vs. loops paralelos; foque em overheads de tasking.",
                                  "learningObjective": "Compreender os fundamentos teóricos para avaliação de escalabilidade em OpenMP.",
                                  "commonMistakes": [
                                    "Confundir tasking com worksharing loops",
                                    "Ignorar overhead de criação de tasks",
                                    "Aplicar Amdahl em workloads Gustafson"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente de teste e implementar exemplos de Van der Pas",
                                  "subSteps": [
                                    "Instale compilador com suporte OpenMP (GCC 9+ ou Intel oneAPI) em máquina multicore (mín. 8 cores).",
                                    "Baixe e compile códigos de exemplo de Van der Pas para tasking e SIMD (e.g., parallel reduction).",
                                    "Adicione timers precisos (omp_get_wtime) para medir tempo de execução em diferentes números de threads.",
                                    "Execute testes iniciais com 1, 4, 8, 16 threads, variando tamanho do problema.",
                                    "Registre dados em planilha: threads, tempo serial, tempo paralelo, speedup."
                                  ],
                                  "verification": "Compile e execute com sucesso, obtendo dados de pelo menos 5 configurações de threads.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "GCC/Intel Compiler",
                                    "Código fonte de Van der Pas (GitHub ou papers)",
                                    "Máquina com 8+ cores",
                                    "Planilha Excel/Google Sheets"
                                  ],
                                  "tips": "Use OMP_NUM_THREADS env var; pin threads com OMP_PROC_BIND=spread para melhor escalabilidade.",
                                  "learningObjective": "Preparar ambiente prático para medições reais de desempenho.",
                                  "commonMistakes": [
                                    "Não sincronizar timers corretamente",
                                    "Usar problema pequeno (ruído domina)",
                                    "Ignorar aquecimento de cache"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Medir eficiência em tasking e SIMD e calcular métricas",
                                  "subSteps": [
                                    "Execute experimentos variando tasking vs. loops tradicionais e ativando/desativando SIMD.",
                                    "Calcule speedup e eficiência para cada configuração (tasking+SIMD, tasking only, etc.).",
                                    "Gere gráficos de speedup vs. núcleos e eficiência vs. tamanho problema.",
                                    "Identifique gargalos: overhead tasking em workloads pequenos, benefícios SIMD em vetoriais.",
                                    "Compare resultados empíricos com benchmarks publicados de Van der Pas."
                                  ],
                                  "verification": "Produza gráficos com speedup >1.5x em 8 cores e relatório de eficiência média >70%.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "GNUPlot/Matplotlib para gráficos",
                                    "Dados de execução em CSV",
                                    "Referências de benchmarks Van der Pas"
                                  ],
                                  "tips": "Aumente tamanho problema para saturar computação; rode múltiplas iterações (média de 10).",
                                  "learningObjective": "Coletar e visualizar dados empíricos de desempenho em OpenMP.",
                                  "commonMistakes": [
                                    "Métricas erradas (speedup = T1/Tp correto)",
                                    "Gráficos sem escalas log",
                                    "Não variar tamanho problema"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com previsões da Lei de Gustafson e avaliar escalabilidade",
                                  "subSteps": [
                                    "Estime fração serial 's' dos seus dados (fit linear no gráfico speedup vs. p).",
                                    "Preveja speedup Gustafson e compare com medido (erro <10%).",
                                    "Analise escalabilidade: strong vs. weak scaling em multicores.",
                                    "Discuta limitações: overhead OpenMP, memória bandwidth, NUMA effects.",
                                    "Conclua recomendações para otimização em tasking/SIMD."
                                  ],
                                  "verification": "Relatório final com tabela de comparação (medido vs. previsto) e conclusão sobre escalabilidade.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Planilha para fit de Gustafson",
                                    "Ferramentas de profiling como Intel VTune"
                                  ],
                                  "tips": "Use regressão linear para estimar 's'; valide com múltiplos tamanhos problema.",
                                  "learningObjective": "Aplicar Lei de Gustafson para validar escalabilidade prática.",
                                  "commonMistakes": [
                                    "Assumir s=0 (ideal)",
                                    "Não considerar weak scaling",
                                    "Ignorar efeitos de contenda"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente uma redução paralela de vetor de 1M elementos usando tasking e SIMD em OpenMP 5.0. Meça speedup em 1-16 cores de um Intel Xeon, compare eficiência tasking+SIMD (85%) vs. loops (75%) com previsão Gustafson (s=0.05, speedup previsto 14.2 vs. medido 13.8).",
                              "finalVerifications": [
                                "Speedup medido próximo (±10%) da previsão Gustafson em 3+ configurações.",
                                "Gráficos mostram eficiência >70% em tasking/SIMD para workloads grandes.",
                                "Relatório identifica pelo menos 2 gargalos específicos (e.g., task overhead).",
                                "Código executável com timers reproduz resultados.",
                                "Comparação com benchmarks Van der Pas valida abordagem.",
                                "Recomendações práticas para cenários reais."
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições (baixa variância, timers corretos): 25%",
                                "Análise Gustafson (fit correto de 's', comparação quantitativa): 25%",
                                "Profundidade em tasking/SIMD (overheads, benefícios): 20%",
                                "Qualidade de gráficos e visualizações: 15%",
                                "Conclusões e recomendações acionáveis: 15%"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Entender impacto de cache, NUMA em multicores.",
                                "Matemática Computacional: Regressão linear para modelagem de performance.",
                                "Análise de Dados: Visualização e estatísticas em experimentos HPC.",
                                "Engenharia de Software: Profiling e otimização de código paralelo."
                              ],
                              "realWorldApplication": "Em simulações científicas (CFD, ML training) em clusters HPC, avaliar escalabilidade OpenMP otimiza uso de nós multicore, reduzindo tempo de computação de dias para horas em data centers como os do LNCC ou AWS ParallelCluster."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.3.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.3.3",
                            "name": "Discutir limitações e extensões",
                            "description": "Analisar casos onde Gustafson falha (ex.: overhead de comunicação) e propor métricas híbridas com Pacheco e Malensek para nuvem e heterogêneos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar premissas e formulação da Lei de Gustafson",
                                  "subSteps": [
                                    "Leia a formulação original de Gustafson: S(p) = p - σ(p - 1), onde σ é a fração sequencial.",
                                    "Identifique premissas chave: escalabilidade com problema de tamanho crescente, paralelismo forte em serial fraction.",
                                    "Compare com Lei de Amdahl para destacar foco em scaled speedup.",
                                    "Anote exemplos ideais onde Gustafson se aplica perfeitamente (ex.: simulações climáticas).",
                                    "Registre limitações iniciais mencionadas por Gustafson."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando a lei e suas premissas, sem erros factuais.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Artigo original de Gustafson (1988), notas de aula sobre leis de escalabilidade.",
                                  "tips": "Use diagramas de speedup vs. processadores para visualizar.",
                                  "learningObjective": "Compreender as bases teóricas da Lei de Gustafson para contextualizar limitações.",
                                  "commonMistakes": "Confundir com Amdahl (fixed-size vs. scaled-size problems)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e analisar limitações da Lei de Gustafson",
                                  "subSteps": [
                                    "Liste limitações: overhead de comunicação, I/O bottlenecks, memória não escalável.",
                                    "Estude casos reais: aplicações HPC com alto overhead de rede (ex.: MPI em clusters).",
                                    "Quantifique impacto: calcule speedup degradado com overhead modelado como O(p) tempo.",
                                    "Colete evidências de literatura: papers citando falhas em cenários não-ideais.",
                                    "Crie tabela comparando cenários ideais vs. falhos."
                                  ],
                                  "verification": "Produza uma tabela com 3 casos onde Gustafson subestima overhead, incluindo cálculos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Papers sobre MPI overhead, ferramentas como ns-3 para simulação de rede.",
                                  "tips": "Modele overhead como fração adicional em equações de speedup.",
                                  "learningObjective": "Dominar casos onde Gustafson falha, focando em overhead de comunicação.",
                                  "commonMistakes": "Ignorar variações em topologias de rede (ex.: fat-tree vs. mesh)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar contribuições de Pacheco e Malensek",
                                  "subSteps": [
                                    "Resuma livro de Pacheco: métricas para paralelismo híbrido (MPI+OpenMP).",
                                    "Analise paper de Malensek: extensões para cloud/heterogêneos com métricas adaptativas.",
                                    "Identifique propostas: isoefficiency em heterogêneos, métricas que incorporam latência de nuvem.",
                                    "Compare com Gustafson: como elas lidam com overhead variável.",
                                    "Extraia fórmulas chave para métricas híbridas."
                                  ],
                                  "verification": "Escreva resumo comparativo de 1 página entre Gustafson, Pacheco e Malensek.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Livro 'An Introduction to Parallel Programming' de Pacheco, papers de Malensek em IEEE.",
                                  "tips": "Foque em seções sobre análise de performance em clouds.",
                                  "learningObjective": "Entender bases para métricas híbridas de autores complementares.",
                                  "commonMistakes": "Confundir isoefficiency (Pacheco) com scaled speedup (Gustafson)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Propor e validar métricas híbridas para nuvem e sistemas heterogêneos",
                                  "subSteps": [
                                    "Desenvolva métrica híbrida: S_hybrid = Gustafson ajustado por fator de overhead (de Pacheco) + heterogeneidade (Malensek).",
                                    "Aplique a cenários: nuvem AWS com GPUs heterogêneas.",
                                    "Simule ou calcule: use ferramentas para validar speedup previsto vs. real.",
                                    "Discuta extensões: integração com métricas de custo em nuvem.",
                                    "Escreva proposta formal com equação e justificativa."
                                  ],
                                  "verification": "Crie relatório de 300 palavras com equação híbrida e simulação de caso.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Ferramentas como AWS EC2 simulator, Python para modelagem matemática.",
                                  "tips": "Use sympy para derivar equações simbólicas.",
                                  "learningObjective": "Capacitar-se a propor extensões práticas integrando múltiplas abordagens.",
                                  "commonMistakes": "Não contabilizar variabilidade em latência de nuvem."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar discussão em análise crítica",
                                  "subSteps": [
                                    "Compile limitações e propostas em narrativa coesa.",
                                    "Avalie forças: quando híbridas superam Gustafson puro.",
                                    "Sugira direções futuras: IA para previsão dinâmica de overhead.",
                                    "Prepare argumentos para debate: prós/contras de cada métrica.",
                                    "Revise para clareza e precisão."
                                  ],
                                  "verification": "Grave vídeo de 5 minutos discutindo o tópico ou escreva ensaio final.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Gravação de tela ou editor de texto.",
                                  "tips": "Use bullet points para estrutura, depois expanda.",
                                  "learningObjective": "Desenvolver habilidade de discutir limitações e extensões de forma articulada.",
                                  "commonMistakes": "Ser muito genérico sem evidências quantitativas."
                                }
                              ],
                              "practicalExample": "Em um pipeline de ML distribuído na AWS (EC2 + SageMaker), overhead de comunicação entre nós GPU causa speedup abaixo do previsto por Gustafson. Proponha métrica híbrida: S(p) = [p - σ(p-1)] / (1 + α * latency_network), onde α de Pacheco e latency de Malensek, validada com logs reais mostrando 20% melhoria na previsão.",
                              "finalVerifications": [
                                "Lista pelo menos 4 limitações específicas de Gustafson com exemplos quantitativos.",
                                "Explica corretamente contribuições de Pacheco e Malensek em contexto híbrido.",
                                "Propõe uma métrica híbrida com equação derivada e aplicação a nuvem/heterogêneos.",
                                "Identifica cenários onde a extensão híbrida supera Gustafson (ex.: >30% erro reduzido).",
                                "Discute implicações para design de apps paralelos em produção.",
                                "Fornece referências bibliográficas precisas."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: 0-20% erros em leis e autores (peso 25%).",
                                "Profundidade analítica: análise quantitativa com cálculos (peso 25%).",
                                "Criatividade na proposta: originalidade da métrica híbrida (peso 20%).",
                                "Clareza e estrutura: lógica no ensaio/discussão (peso 15%).",
                                "Evidências práticas: uso de exemplos reais/simulações (peso 10%).",
                                "Conexões interdisciplinares: menção a cloud/rede (peso 5%)."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: modelagem de overhead de comunicação (TCP/IP, MPI).",
                                "Cloud Computing: métricas de custo/escalabilidade em AWS/GCP.",
                                "Análise de Algoritmos: complexidade em arquiteturas heterogêneas.",
                                "Engenharia de Software: design de sistemas paralelos resilientes."
                              ],
                              "realWorldApplication": "Otimizar workloads de big data em data centers híbridos (ex.: Netflix recomendação system), reduzindo custos de computação em 15-25% ao prever corretamente limites de escalabilidade e evitar overprovisioning baseado em Gustafson puro."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.4",
                    "name": "Análise de Overhead",
                    "description": "Identificação de custos adicionais como comunicação, sincronização e balanceamento de carga.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.4.1",
                        "name": "Overhead de Comunicação",
                        "description": "Custos adicionais associados à troca de mensagens e transferência de dados em sistemas de memória distribuída, impactando o desempenho geral do programa paralelo.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.4.1.1",
                            "name": "Identificar custos de latência e largura de banda na comunicação",
                            "description": "Analisar como a latência de rede e a largura de banda afetam o tempo de transferência de dados entre processos em modelos como MPI, calculando o overhead total com base em volume de dados e frequência de mensagens.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Básicos de Latência e Largura de Banda",
                                  "subSteps": [
                                    "Defina latência como o tempo fixo para iniciar uma comunicação (overhead por mensagem).",
                                    "Defina largura de banda como a taxa máxima de transferência de dados (em bytes/segundo).",
                                    "Diferencie latência (tempo morto) de largura de banda (tempo de transmissão proporcional ao tamanho).",
                                    "Estude o impacto em comunicações frequentes vs. grandes volumes de dados.",
                                    "Revise unidades comuns: microssegundos para latência, GB/s para largura de banda."
                                  ],
                                  "verification": "Explique em suas palavras a diferença entre latência e largura de banda com um diagrama simples.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Documentação MPI (Capítulo sobre comunicação ponto-a-ponto)",
                                    "Artigo sobre modelo Hockney"
                                  ],
                                  "tips": "Use analogias: latência é como o tempo para ligar o carro; largura de banda é a velocidade na estrada.",
                                  "learningObjective": "Distinguir latência e largura de banda e seu papel no overhead de comunicação.",
                                  "commonMistakes": [
                                    "Confundir latência com largura de banda",
                                    "Ignorar que latência é por mensagem, não por byte"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar o Modelo Matemático de Tempo de Comunicação",
                                  "subSteps": [
                                    "Aprenda o modelo Hockney: tempo = α + (β * tamanho_dados), onde α=latência, β=1/bandwidth.",
                                    "Para múltiplas mensagens: tempo_total = n * α + (total_dados * β), com n=frequência de mensagens.",
                                    "Calcule overhead: overhead = tempo_comunicacao - tempo_computacao_ideal.",
                                    "Implemente fórmulas em uma planilha ou script Python simples para experimentação.",
                                    "Analise como aumentar n ou tamanho afeta o overhead dominante (latência vs. bandwidth)."
                                  ],
                                  "verification": "Calcule o tempo para 100 mensagens de 1KB com α=10μs, β=1μs/byte.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Fórmulas do modelo LogP/Hockney (PDF ou wiki)",
                                    "Planilha Google Sheets ou Jupyter Notebook"
                                  ],
                                  "tips": "Sempre isole variáveis: teste com n=1 primeiro para medir α puro.",
                                  "learningObjective": "Aplicar fórmulas matemáticas para prever tempo de comunicação em cenários MPI.",
                                  "commonMistakes": [
                                    "Esquecer multiplicar latência por número de mensagens",
                                    "Usar unidades inconsistentes (μs vs. ms)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e Medir Comunicação em MPI",
                                  "subSteps": [
                                    "Instale OpenMPI e compile um programa simples de MPI_Send/MPI_Recv.",
                                    "Escreva código para variar tamanho de mensagens e número de trocas entre dois processos.",
                                    "Meça tempos reais com MPI_Wtime() e plote latência vs. bandwidth.",
                                    "Compare medições empíricas com predições do modelo matemático.",
                                    "Repita com diferentes configurações de rede (localhost vs. cluster)."
                                  ],
                                  "verification": "Gere um gráfico mostrando tempo vs. tamanho de mensagem alinhado com o modelo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "OpenMPI instalado",
                                    "Código exemplo MPI ping-pong",
                                    "GNUPlot ou Matplotlib para plots"
                                  ],
                                  "tips": "Use --mca btl self para localhost; aqueça a rede com mensagens dummy antes de medir.",
                                  "learningObjective": "Medir empiricamente latência e bandwidth em um ambiente MPI real.",
                                  "commonMistakes": [
                                    "Não sincronizar processos corretamente",
                                    "Medir sem aquecimento, capturando cache effects"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e Calcular Overhead Total de Comunicação",
                                  "subSteps": [
                                    "Integre comunicação em um programa paralelo simples (e.g., redução de vetores).",
                                    "Calcule overhead total: some tempos de todas as mensagens e subtraia computação serial.",
                                    "Identifique gargalos: se latência domina (muitas mensagens pequenas), sugira agregação.",
                                    "Otimize: teste non-blocking sends para reduzir impacto de latência.",
                                    "Documente relatório com cálculos, medições e recomendações."
                                  ],
                                  "verification": "Produza um relatório com overhead calculado <20% do tempo total em um benchmark.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código MPI expandido",
                                    "Ferramentas de profiling como mpiP ou TAU"
                                  ],
                                  "tips": "Registre logs de tempos para auditoria; mire em eficiência >80%.",
                                  "learningObjective": "Quantificar overhead de comunicação e propor mitigações baseadas em latência/bandwidth.",
                                  "commonMistakes": [
                                    "Incluir tempo de computação no overhead de comunicação",
                                    "Ignorar overhead de MPI_Init/Finalize"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster com 2 nós, transfira 1GB de dados divididos em 1000 mensagens de 1MB cada. Com latência α=20μs e bandwidth 10GB/s (β=0.1μs/byte), tempo teórico = 1000*20μs + (1e9 bytes * 0.1μs/byte) = 20ms + 100ms = 120ms. Meça com MPI para validar e calcule overhead se computação leva 50ms.",
                              "finalVerifications": [
                                "Calcula corretamente tempo de comunicação usando modelo Hockney para dados variados.",
                                "Identifica se latência ou bandwidth é o gargalo em um cenário dado.",
                                "Medições MPI empíricas batem com predições dentro de 10%.",
                                "Propõe otimizações adequadas (e.g., mensagens maiores se latência domina).",
                                "Explica impacto no overhead total de um programa paralelo.",
                                "Gera gráficos de tempo vs. tamanho/número de mensagens."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas fórmulas: 100% correto em cálculos manuais.",
                                "Análise qualitativa: Correta identificação de gargalos em 3 cenários.",
                                "Implementação prática: Código MPI roda sem erros e mede valores realistas.",
                                "Relatório: Inclui predições, medições, discrepâncias explicadas e otimizações.",
                                "Criatividade: Sugere pelo menos 2 aplicações reais ou melhorias.",
                                "Eficiência: Overhead reduzido em >20% após otimizações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelagem linear e análise assintótica (Big O para overhead).",
                                "Redes de Computadores: Protocolos TCP/IP e métricas de performance.",
                                "Otimização: Técnicas de tuning de parâmetros em sistemas distribuídos.",
                                "Estatística: Análise de variância em medições empíricas.",
                                "Engenharia de Software: Profiling e benchmarking de aplicações paralelas."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, otimizar MPI em simulações climáticas reduz tempo de execução de dias para horas, minimizando custos de energia e permitindo mais iterações; em data centers cloud (AWS/Google Cloud), baixa latência em microsserviços acelera ML training distribuído."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.4.1.2",
                            "name": "Medir overhead em trocas de mensagens ponto-a-ponto e coletivas",
                            "description": "Utilizar ferramentas como MPI timers para quantificar o overhead em operações send/receive e collectives (broadcast, reduce), comparando com tempo sequencial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e criar baseline sequencial",
                                  "subSteps": [
                                    "Instalar e verificar OpenMPI ou MPICH (ex: mpirun --version)",
                                    "Criar programa C sequencial simples (ex: soma de array de 1M elementos usando clock() ou gettimeofday())",
                                    "Compilar com gcc (sem MPI) e executar múltiplas vezes para média de tempo sequencial (t_seq)",
                                    "Variar tamanhos de input (10K, 100K, 1M elementos) e registrar baselines",
                                    "Documentar t_seq em tabela para cada tamanho"
                                  ],
                                  "verification": "Programa sequencial roda consistentemente com tempos reproduzíveis (variação <5%) e baselines registradas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Compilador GCC",
                                    "OpenMPI/MPICH instalado",
                                    "Editor de código (VSCode)",
                                    "Terminal/Linux cluster"
                                  ],
                                  "tips": "Execute 10+ runs e use média para reduzir ruído; evite caches afetando medições.",
                                  "learningObjective": "Estabelecer referência temporal sequencial precisa para comparações futuras.",
                                  "commonMistakes": [
                                    "Incluir I/O no tempo medido",
                                    "Usar tamanhos pequenos onde overhead é insignificante",
                                    "Não limpar cache entre runs"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e medir overhead em comunicações ponto-a-ponto (send/receive)",
                                  "subSteps": [
                                    "Adaptar código sequencial para MPI: inicializar MPI_Init(), obter rank e size com MPI_Comm_rank/size",
                                    "Implementar MPI_Send/MPI_Recv para trocar mensagens entre processos (ex: rank 0 envia array para rank 1)",
                                    "Usar MPI_Wtime() antes/depois de send/recv para medir tempo de comunicação (t_p2p)",
                                    "Executar com mpirun -np 2/4/8 e coletar tempos para diferentes tamanhos de mensagem",
                                    "Calcular overhead_p2p = (t_p2p - t_seq) / t_seq * 100%"
                                  ],
                                  "verification": "Tempos t_p2p coletados para múltiplos np e tamanhos; overhead >0 e crescente com tamanho.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código base sequencial",
                                    "mpicc compilador",
                                    "Cluster ou multi-core com mpirun"
                                  ],
                                  "tips": "Sincronize com MPI_Barrier() antes de medir para isolar comunicação; teste mensagens não-bloqueantes se avançado.",
                                  "learningObjective": "Quantificar overhead introduzido por trocas ponto-a-ponto usando timers MPI.",
                                  "commonMistakes": [
                                    "Não usar MPI_Wtime() (alta resolução)",
                                    "Medir tempo total incluindo computação",
                                    "Ignorar deadlocks em send/recv"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e medir overhead em operações coletivas (broadcast/reduce)",
                                  "subSteps": [
                                    "Modificar código para usar MPI_Bcast() (rank 0 broadcast array para todos)",
                                    "Adicionar MPI_Reduce() para soma coletiva de arrays parciais",
                                    "Medir MPI_Wtime() ao redor de cada collective (t_coll) separadamente e combinado",
                                    "Executar com np=4/8/16, variando tamanhos, e calcular overhead_coll = (t_coll - t_seq)/t_seq *100%",
                                    "Comparar overhead de Bcast vs Reduce em tabela"
                                  ],
                                  "verification": "t_coll medidos isoladamente; overhead collectives maior que P2P para np altos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código P2P anterior",
                                    "Documentação MPI (man pages)",
                                    "mpirun com np variável"
                                  ],
                                  "tips": "Use MPI_IN_PLACE em reduce para eficiência; meça com topologias line vs tree se suportado.",
                                  "learningObjective": "Avaliar impacto de collectives em overhead de comunicação coletiva.",
                                  "commonMistakes": [
                                    "Não especificar root correto em Bcast",
                                    "Confundir MPI_Allreduce com Reduce",
                                    "Executar em np=1 onde collective=sequencial"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e comparar overheads P2P vs Collectives",
                                  "subSteps": [
                                    "Coletar todos dados em planilha (t_seq, t_p2p, t_coll vs tamanho_msg e np)",
                                    "Plotar gráficos: overhead% vs tamanho mensagem para P2P e collectives",
                                    "Identificar padrões (ex: latência fixa + bandwidth linear; collectives escalam com np log np)",
                                    "Comparar com teoria (overhead ~ alpha + beta * size; alpha latência MPI)",
                                    "Relatar insights: quando collectives são melhores que P2P"
                                  ],
                                  "verification": "Gráficos gerados mostrando overhead crescente; conclusão escrita sobre trade-offs.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha (Excel/Google Sheets)",
                                    "Ferramenta de plot (Python Matplotlib ou Gnuplot)"
                                  ],
                                  "tips": "Faça múltiplas runs (20+) para erro padrão; normalize por processo.",
                                  "learningObjective": "Interpretar medições para otimizar escolha de primitivas MPI.",
                                  "commonMistakes": [
                                    "Escala errada nos gráficos",
                                    "Ignorar ruído de rede/OS",
                                    "Não comparar com sequencial por tamanho"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um programa de soma paralela de vetor 1M elems: sequencial t_seq=10ms; P2P send/recv entre 2 processos t_p2p=15ms (overhead 50%); Bcast+Reduce t_coll=12ms (overhead 20%), mostrando collectives mais eficientes.",
                              "finalVerifications": [
                                "Overheads calculados corretamente para P2P e collectives em múltiplos cenários",
                                "Gráficos de overhead vs tamanho mensagem e np gerados e interpretados",
                                "Tempos reproduzíveis com <10% variação entre runs",
                                "Comparação explícita P2P vs collectives com conclusões",
                                "Relatório documenta baselines sequenciais e padrões observados",
                                "Códigos funcionam com mpirun -np 2-16 sem erros"
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições (uso correto de MPI_Wtime e médias)",
                                "Qualidade dos gráficos e análise quantitativa (regressão linear para alpha/beta)",
                                "Correção na implementação MPI (sem deadlocks, sync correto)",
                                "Profundidade da comparação (P2P vs collectives vs teoria)",
                                "Clareza do relatório com insights acionáveis",
                                "Escalabilidade testada (np variado, tamanhos mensagem)"
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Latência/bandwidth de redes (InfiniBand/Ethernet)",
                                "Estatística: Análise de variância, regressão linear para modelar overhead",
                                "Algoritmos: Trade-offs em algoritmos paralelos (log np em collectives)",
                                "Sistemas Operacionais: Impacto de context switching em overhead MPI"
                              ],
                              "realWorldApplication": "Em simulações HPC como modelagem climática (ex: CESM) ou ML distribuído (Horovod), medir overhead guia otimização de collectives vs P2P, reduzindo tempo de simulação de dias para horas em supercomputadores."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.4.1.3",
                            "name": "Otimizar comunicação minimizando overhead",
                            "description": "Aplicar técnicas como agregação de mensagens e comunicação não-bloqueante para reduzir custos, avaliando o impacto no speedup via experimentos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar e medir overhead de comunicação baseline",
                                  "subSteps": [
                                    "Analise o código paralelo atual para identificar padrões de comunicação (ex: chamadas MPI_Send/Recv frequentes).",
                                    "Implemente instrumentação para medir tempo gasto em comunicação usando ferramentas como MPI_Wtime ou perf.",
                                    "Execute o programa em escala variada (2, 4, 8 processos) e registre métricas de tempo total, tempo de comunicação e speedup.",
                                    "Calcule o overhead como porcentagem do tempo total gasto em comunicação.",
                                    "Visualize resultados em gráficos (tempo vs. número de processos)."
                                  ],
                                  "verification": "Gráficos mostram overhead >20% do tempo total em pelo menos uma configuração.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Código paralelo em MPI/OpenMP, compilador (gcc/mpicc), ferramentas de profiling (perf, TAU), ambiente cluster/local com múltiplos cores.",
                                  "tips": "Use runs repetidos para médias confiáveis e isole comunicação de computação.",
                                  "learningObjective": "Compreender e quantificar o impacto do overhead de comunicação no desempenho geral.",
                                  "commonMistakes": "Ignorar variabilidade de rede; não normalizar por workload."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar agregação de mensagens",
                                  "subSteps": [
                                    "Identifique mensagens pequenas e frequentes para agrupar (ex: múltiplos sends em um buffer único).",
                                    "Crie buffers de agregação e use MPI_Pack/MPI_Unpack ou MPI_Gather para combinar dados.",
                                    "Modifique o código para enviar mensagens agregadas em intervalos fixos ou por threshold de tamanho.",
                                    "Teste funcionalidade com dados sintéticos para garantir integridade.",
                                    "Recompile e execute testes unitários para validar agregação."
                                  ],
                                  "verification": "Número de chamadas de comunicação reduzido em pelo menos 50%, confirmado por contadores MPI.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "Código baseline modificado, documentação MPI (man pages), debugger (gdb).",
                                  "tips": "Escolha tamanho de buffer baseado em MTU de rede (~64KB para Ethernet).",
                                  "learningObjective": "Aplicar agregação para reduzir latência de mensagens pequenas.",
                                  "commonMistakes": "Sobrecarga de buffer causando overflow; perda de ordem de mensagens."
                                },
                                {
                                  "stepNumber": "3",
                                  "title": "Implementar comunicação não-bloqueante",
                                  "subSteps": [
                                    "Substitua chamadas bloqueantes (MPI_Send/Recv) por não-bloqueantes (MPI_Isend/Irecv).",
                                    "Adicione MPI_Waitall ou MPI_Test para sincronização pós-post.",
                                    "Sobreponha comunicação e computação ajustando loops para progressão assíncrona.",
                                    "Otimize alocação de requests MPI para reutilização.",
                                    "Valide com testes de corretude (comparar saídas com versão bloqueante)."
                                  ],
                                  "verification": "Tempo de comunicação reportado <50% do baseline, sem deadlocks em runs longos.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "Código com agregação, MPI profiling tools (Vampir/Score-P).",
                                  "tips": "Use MPI_Request arrays para múltiplas operações pendentes.",
                                  "learningObjective": "Explorar sobreposição para mascarar latência de comunicação.",
                                  "commonMistakes": "Esquecer waits causando perda de mensagens; overhead excessivo de polling."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar experimentos e medir speedup",
                                  "subSteps": [
                                    "Defina workloads escaláveis (ex: matrix multiplication com N variando).",
                                    "Rode experimentos baseline vs. otimizado em múltiplas escalas, medindo tempo wall-clock e speedup (S = T1/Tp).",
                                    "Colete métricas: tempo comm, % sobreposição, throughput de mensagens.",
                                    "Use scripts para automação (bash/Python com MPI launchers).",
                                    "Gere plots de speedup vs. scale e overhead reduction."
                                  ],
                                  "verification": "Speedup otimizado >1.5x baseline em pelo menos 2 configurações.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Cluster/local multi-node, plotting tools (matplotlib/GNUPlot), scripts de benchmark.",
                                  "tips": "Fixe seed RNG para reprodutibilidade; rode weak/strong scaling.",
                                  "learningObjective": "Avaliar quantitativamente o impacto das otimizações no desempenho.",
                                  "commonMistakes": "Não controlar variáveis externas como load do cluster."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar resultados e iterar otimizações",
                                  "subSteps": [
                                    "Compare métricas pré/pós-otimização, identificando gargalos restantes.",
                                    "Ajuste parâmetros (ex: tamanho agregação baseado em análise).",
                                    "Teste combinações (agregação + non-blocking vs. isoladas).",
                                    "Documente trade-offs (ex: latência vs. throughput).",
                                    "Proponha melhorias adicionais como topology-aware comm."
                                  ],
                                  "verification": "Relatório com análise escrita e gráficos mostrando redução de overhead >40%.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Dados experimentais, Jupyter notebook para análise.",
                                  "tips": "Use Amdahl's law para prever limites teóricos.",
                                  "learningObjective": "Interpretar dados empíricos para decisões de otimização iterativa.",
                                  "commonMistakes": "Atribuir ganhos a ruído; ignorar escalabilidade."
                                }
                              ],
                              "practicalExample": "Em um programa MPI para multiplicação de matrizes distribuída, onde cada processo envia atualizações parciais frequentes para vizinhos: agregue 100 vetores pequenos em um buffer de 1MB enviado a cada iteração, use Isend/Irecv para sobrepor com computação local, resultando em speedup de 2.3x em 16 nodes.",
                              "finalVerifications": [
                                "Overhead de comunicação reduzido para <10% do tempo total.",
                                "Speedup linear ou superlinear em escalas testadas.",
                                "Nenhuma perda de dados ou deadlock em runs de 1h.",
                                "Sobreposição comm/comp >30% via profiling.",
                                "Reprodutibilidade: desvios <5% em 5 runs.",
                                "Documentação de código com comentários nas otimizações."
                              ],
                              "assessmentCriteria": [
                                "Correta implementação de agregação sem perda de dados (100% acurácia).",
                                "Uso efetivo de non-blocking com waits apropriados (sem busy-wait).",
                                "Experimentos bem desenhados com pelo menos 3 escalas e métricas claras.",
                                "Análise quantitativa com gráficos e cálculos de speedup precisos.",
                                "Identificação de pelo menos 2 trade-offs ou limitações.",
                                "Código limpo, modular e comentado."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Entender latência/bandwidth em topologias.",
                                "Análise de Algoritmos: Aplicar modelos como LogP para previsão.",
                                "Engenharia de Software: Refatoração para performance em sistemas distribuídos.",
                                "Estatística: Análise de variância em benchmarks.",
                                "Otimização Numérica: Balanceamento comm/comp em solvers paralelos."
                              ],
                              "realWorldApplication": "Em aplicações HPC como simulações climáticas (ex: CESM model) ou ML distribuído (ex: Horovod em TensorFlow), onde overhead de comm limita escalabilidade em milhares de GPUs, reduzindo custos de energia e tempo de treinamento de dias para horas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.4.2",
                        "name": "Overhead de Sincronização",
                        "description": "Custos decorrentes de mecanismos de coordenação entre threads ou processos, como locks e barreiras, em memória compartilhada ou distribuída.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.4.2.1",
                            "name": "Reconhecer overhead em exclusão mútua e barreiras",
                            "description": "Explicar e medir o custo de primitivas como mutex, semáforos e barrier em OpenMP ou Pthreads, identificando contenção e tempo de espera.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Teóricos de Overhead em Sincronização",
                                  "subSteps": [
                                    "Defina exclusão mútua (mutex) e explique seu papel em evitar condições de corrida.",
                                    "Descreva barreiras (barriers) e seu uso para sincronizar threads em pontos específicos.",
                                    "Explique overhead como o custo adicional de primitivas de sincronização (tempo de bloqueio, contenção).",
                                    "Diferencie contenção (espera por recurso compartilhado) de tempo de espera em barreiras.",
                                    "Revise primitivas em Pthreads (pthread_mutex_lock/unlock) e OpenMP (#pragma omp barrier)."
                                  ],
                                  "verification": "Resuma em um parágrafo os conceitos e forneça exemplos verbais sem código.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação oficial de Pthreads e OpenMP (man pages ou sites oficiais), caderno de anotações.",
                                  "tips": "Use diagramas de timeline para visualizar bloqueios e esperas.",
                                  "learningObjective": "Identificar e explicar os mecanismos de sincronização e seus custos inerentes.",
                                  "commonMistakes": "Confundir overhead com tempo de computação útil; ignorar diferenças entre mutex e barreiras."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente e Implementar Exemplo Básico com Mutex",
                                  "subSteps": [
                                    "Instale bibliotecas Pthreads ou configure OpenMP no GCC/Clang.",
                                    "Escreva um programa simples com múltiplas threads acessando uma seção crítica via mutex.",
                                    "Compile e execute sem medição para verificar funcionalidade básica.",
                                    "Adicione contadores para simular contenção alta (muitas threads disputando o mutex).",
                                    "Registre tempos iniciais usando clock_gettime() ou omp_get_wtime()."
                                  ],
                                  "verification": "Execute o código e confirme que não há condições de corrida (saídas consistentes).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Compilador GCC com suporte a Pthreads/OpenMP, editor de código (VS Code ou similar), terminal.",
                                  "tips": "Use -O0 para desabilitar otimizações que possam mascarar overhead.",
                                  "learningObjective": "Criar um benchmark controlado para medir overhead de mutex.",
                                  "commonMistakes": "Não inicializar mutex corretamente; usar variáveis globais sem proteção."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Medir e Analisar Overhead de Mutex e Contenção",
                                  "subSteps": [
                                    "Meça tempo total com e sem mutex (versão sequencial vs paralela).",
                                    "Calcule overhead como (tempo_com_sync - tempo_sem_sync) / iterações.",
                                    "Aumente número de threads e registre contenção (tempo gasto em lock/unlock).",
                                    "Compare com semáforos (sem_t) para notar diferenças em overhead.",
                                    "Plote gráficos de overhead vs número de threads usando ferramentas como Gnuplot."
                                  ],
                                  "verification": "Gere um relatório com tabelas de tempos e overhead > 10% em cenários de contenção.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Código do Step 2, ferramentas de plotagem (Gnuplot ou Python Matplotlib), planilha (Excel/Google Sheets).",
                                  "tips": "Execute múltiplas rodadas (média de 10) para reduzir variância de cache/CPU.",
                                  "learningObjective": "Quantificar custo de mutex/semáforos e identificar padrões de contenção.",
                                  "commonMistakes": "Ignorar overhead de cache; medir apenas tempo total sem isolar sync."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar, Medir e Comparar Overhead de Barreiras",
                                  "subSteps": [
                                    "Modifique o código para incluir barreiras em OpenMP ou pthread_barrier_wait.",
                                    "Crie workload desbalanceado para destacar tempo de espera em barreiras.",
                                    "Meça tempo de barreira isolado (rode em loop apertado).",
                                    "Compare overhead de barreiras vs mutex em workloads semelhantes.",
                                    "Analise impacto de contenção em barreiras (threads rápidas esperam lentas)."
                                  ],
                                  "verification": "Demonstre que overhead de barreira escala com desbalanceamento de workload.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Código expandido, perf/isntat para profiling avançado (opcional).",
                                  "tips": "Use #pragma omp barrier em loops paralelos para simplicidade.",
                                  "learningObjective": "Diferenciar e medir overhead específico de barreiras vs exclusão mútua.",
                                  "commonMistakes": "Não sincronizar corretamente antes da barreira; confundir com busy-waiting."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar Análise e Identificar Otimizações",
                                  "subSteps": [
                                    "Compile resultados: tabelas/gráficos de overhead mutex vs barreiras.",
                                    "Identifique cenários de alta contenção (ex: muitas threads curtas).",
                                    "Discuta métricas: speedup, eficiência, tempo ocioso.",
                                    "Sugira otimizações (read-write locks, atomic ops, reduzir sincronizações).",
                                    "Teste uma otimização e meça redução de overhead."
                                  ],
                                  "verification": "Escreva um relatório de 1 página com conclusões e evidências.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Resultados anteriores, template de relatório.",
                                  "tips": "Foco em scalability: overhead piora com mais cores.",
                                  "learningObjective": "Aplicar análise para reconhecer e mitigar overhead em cenários reais.",
                                  "commonMistakes": "Atribuir todo slowdown a sync sem baseline sequencial."
                                }
                              ],
                              "practicalExample": "Em um programa multi-threaded para soma de matriz usando Pthreads: 8 threads disputam um mutex para atualizar soma parcial. Sem mutex: condição de corrida. Com mutex: overhead de 25% em contenção alta (medido como tempo lock/unlock > compute). Barreira no final garante sincronização, mas adiciona 15% overhead em workloads desbalanceados.",
                              "finalVerifications": [
                                "Explicar verbalmente overhead de mutex vs barreira com exemplo numérico.",
                                "Executar código e relatar overhead >20% em contenção.",
                                "Identificar contenção em log de tempos (tempo ocioso >50%).",
                                "Comparar métricas com baseline sequencial.",
                                "Propor otimização que reduza overhead em 10-20%.",
                                "Plotar gráfico escalável de overhead vs threads."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas: 20%)",
                                "Correção de medições (overhead quantificado: 25%)",
                                "Análise de contenção/espera (identificada corretamente: 20%)",
                                "Qualidade de gráficos/relatórios (claro e legível: 15%)",
                                "Sugestões de otimização viáveis (10%)",
                                "Compreensão comparativa mutex/barreira (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Deadlocks e escalonamento de threads.",
                                "Arquitetura de Computadores: Impacto de cache coherence em sync.",
                                "Algoritmos: Work-stealing para reduzir contenção.",
                                "Engenharia de Software: Design de APIs thread-safe."
                              ],
                              "realWorldApplication": "Em servidores web como Apache/Nginx com worker threads, mutex em pools de conexão causa contenção sob load alto, levando a latência; barreiras em ML training (TensorFlow) sincronizam epochs, mas overhead limita escalabilidade em GPUs multi."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.4.2.2",
                            "name": "Analisar impacto de sincronização em escalabilidade",
                            "description": "Calcular o overhead de sincronização usando modelo de Amdahl, simulando cenários com diferentes números de threads e frações críticas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Modelo de Amdahl e sua Aplicação em Paralelismo",
                                  "subSteps": [
                                    "Revise a fórmula básica do speedup de Amdahl: Speedup = 1 / ((1 - P) + P/N), onde P é a fração paralelizável e N o número de processadores.",
                                    "Identifique limitações do modelo: assume fração serial fixa e não considera overheads como sincronização.",
                                    "Estude exemplos simples de cálculo manual para N=1,4,8 threads com P=0.9.",
                                    "Discuta como overhead de sincronização (ex: locks, barriers) aumenta a fração efetivamente serial.",
                                    "Anote definições chave: fração crítica (seção sincronizada) vs. fração paralelizável."
                                  ],
                                  "verification": "Resuma em um parágrafo as limitações do Amdahl e forneça um cálculo exemplo correto para P=0.95, N=16.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação do modelo de Amdahl (Wikipedia ou paper original), calculadora ou planilha Excel.",
                                  "tips": "Comece com exemplos pequenos para intuitivamente ver o 'teto de Amdahl'.",
                                  "learningObjective": "Compreender os fundamentos matemáticos do modelo de Amdahl e identificar onde overheads de sincronização se encaixam.",
                                  "commonMistakes": "Confundir fração serial com overhead; ignorar que overhead escala com N."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Modelar Overhead de Sincronização no Amdahl Estendido",
                                  "subSteps": [
                                    "Defina overhead de sincronização como tempo gasto em locks/barriers: Overhead = S * (1 - 1/N), onde S é custo por thread na seção crítica.",
                                    "Estenda a fórmula: Speedup efetivo = 1 / ((1 - P) + P/N + Overhead).",
                                    "Calcule overhead para cenários: fração crítica f=0.01, custo S=0.001s por thread, N variando de 1 a 64.",
                                    "Crie uma tabela comparando speedup básico vs. estendido para diferentes f.",
                                    "Implemente a fórmula em uma planilha para testes rápidos."
                                  ],
                                  "verification": "Gere uma tabela com speedups para N=1,8,32 com f=0.005 e S=0.002, mostrando degradação >20%.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Planilha Google Sheets ou Excel, pseudocódigo de fórmulas.",
                                  "tips": "Use cores relativas (normalizadas por tempo total serial) para facilitar comparações.",
                                  "learningObjective": "Adaptar o modelo de Amdahl para incluir overhead de sincronização de forma quantitativa.",
                                  "commonMistakes": "Não normalizar overhead pelo tempo total; assumir overhead constante independente de N."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar e Executar Simulações de Cenários",
                                  "subSteps": [
                                    "Defina parâmetros: frações críticas f=[0.001, 0.005, 0.01, 0.05]; threads N=[1,2,4,8,16,32,64]; P=0.95 fixo.",
                                    "Escreva um script Python simples usando NumPy para calcular speedups em loop.",
                                    "Execute simulações: plote curvas de speedup vs. N para cada f.",
                                    "Varie workloads: simule 'leitura compartilhada' (baixo overhead) vs. 'escrita concorrente' (alto).",
                                    "Salve resultados em CSV e gere gráficos com Matplotlib."
                                  ],
                                  "verification": "Produza 3 gráficos de speedup vs. N mostrando impacto crescente com f maior.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Python com NumPy/Matplotlib instalado, Jupyter Notebook.",
                                  "tips": "Log-scale no eixo Y para speedups >1; teste com N alto para ver saturação.",
                                  "learningObjective": "Simular múltiplos cenários para visualizar quantitativamente o impacto na escalabilidade.",
                                  "commonMistakes": "Escala errada nos plots; não variar f realisticamente (tipicamente <1%)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Resultados e Identificar Limites de Escalabilidade",
                                  "subSteps": [
                                    "Compare speedups: quantifique perda % devido a sincronização (ex: 30% em N=32 para f=0.01).",
                                    "Identifique thresholds: N onde speedup < linear (ex: knee point).",
                                    "Discuta trade-offs: reduzir f via redesign vs. hardware mais rápido.",
                                    "Calcule eficiência: Efficiency = Speedup / N, plote vs. N.",
                                    "Redija relatório resumindo achados chave e recomendações."
                                  ],
                                  "verification": "Escreva um relatório de 1 página com 2 insights acionáveis baseados nos gráficos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Gráficos gerados, editor de texto.",
                                  "tips": "Foco em 'por quês': overhead cresce porque contenção aumenta com N.",
                                  "learningObjective": "Interpretar simulações para prever e mitigar gargalos de escalabilidade.",
                                  "commonMistakes": "Atribuir toda perda a sincronização sem isolar variáveis."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar com Benchmark Real e Iterar",
                                  "subSteps": [
                                    "Escolha benchmark: adapte OpenMP matrix multiply com locks variáveis.",
                                    "Meça tempos reais em máquina multi-core para N=1-16, compare com modelo.",
                                    "Ajuste parâmetros do modelo para fit (calibre S e f).",
                                    "Analise discrepâncias: overheades não-modelados como cache coherence.",
                                    "Documente lições: quando modelo é preciso (f<0.01)."
                                  ],
                                  "verification": "Compare speedup medido vs. predito, com erro <15% em 80% dos casos.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Compilador GCC com OpenMP, máquina com >=8 cores.",
                                  "tips": "Use 'time' ou perf para medir; rode múltiplas iterações para médias.",
                                  "learningObjective": "Conectar teoria a prática, validando previsões em código real.",
                                  "commonMistakes": "Ignorar variância em benchmarks; não calibrar modelo."
                                }
                              ],
                              "practicalExample": "Em um servidor web multi-threaded processando requisições, simule 5% das requisições acessando um contador global compartilhado via mutex. Calcule que com 32 threads, overhead de lock contention reduz speedup de 20x para 12x, identificando necessidade de atomic operations ou sharding.",
                              "finalVerifications": [
                                "Calcula corretamente speedup estendido para 5 cenários variados com erro <5%.",
                                "Gera e interpreta gráficos mostrando saturação devido a sincronização.",
                                "Identifica fração crítica ótima (<0.5%) para escalar a 64 threads.",
                                "Valida modelo com benchmark real, ajustando parâmetros.",
                                "Redige relatório com recomendações práticas de otimização.",
                                "Explica verbalmente limitações do modelo em 2 minutos."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: fórmulas e cálculos corretos (30%).",
                                "Qualidade das simulações: variedade de parâmetros e visualizações claras (25%).",
                                "Análise interpretativa: insights profundos sobre impactos (20%).",
                                "Validação prática: comparação com benchmarks reais (15%).",
                                "Clareza e completude do relatório (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelagem não-linear e otimização.",
                                "Estatística: Análise de variância em simulações e benchmarks.",
                                "Engenharia de Software: Design de algoritmos lock-free.",
                                "Administração: Alocação eficiente de recursos computacionais."
                              ],
                              "realWorldApplication": "Em data centers como AWS ou Google Cloud, analisa overhead de sincronização em workloads como bancos NoSQL (Cassandra) para decidir entre mais threads vs. redesign assíncrono, economizando custos de hardware em 20-50% ao escalar para milhares de conexões."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.4.2.3",
                            "name": "Implementar sincronização de baixo overhead",
                            "description": "Comparar read-write locks vs. spinlocks e tasking em OpenMP, medindo redução de overhead em aplicações reais como decomposição de domínio.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos teóricos de sincronização em OpenMP",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP para spinlocks (#omp_set_lock, #omp_unset_lock).",
                                    "Analise read-write locks (#omp_init_lock, #omp_set_lock para escrita, #omp_set_nlock para leitura).",
                                    "Revise tasking em OpenMP (#omp task, #omp taskwait) e seu impacto em overhead.",
                                    "Compare overheads teóricos: spinlocks para esperas curtas, RW-locks para acessos concorrentes leitura/escrita, tasking para dependências dinâmicas.",
                                    "Identifique cenários ideais para cada: domínio decomposição com acessos majoritariamente leitura."
                                  ],
                                  "verification": "Resuma em um documento as diferenças chave e cenários de uso, com referências à spec OpenMP.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": "Documentação OpenMP (openmp.org), editor de texto.",
                                  "tips": "Use diagramas de Venn para visualizar sobreposições de uso.",
                                  "learningObjective": "Compreender fundamentos teóricos para seleção adequada de primitivas de sincronização.",
                                  "commonMistakes": "Confundir spinlocks com mutexes pesados; ignorar busy-waiting em spinlocks."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar exemplos básicos de spinlocks e read-write locks",
                                  "subSteps": [
                                    "Compile ambiente OpenMP: g++ -fopenmp exemplo.cpp.",
                                    "Implemente contador compartilhado com spinlock: omp_set_lock(&lock); count++; omp_unset_lock(&lock).",
                                    "Adapte para read-write lock: omp_set_nlock para múltiplas leituras, omp_set_lock para escrita.",
                                    "Teste com 4-8 threads em loop de 1M iterações.",
                                    "Meça tempo inicial com omp_get_wtime()."
                                  ],
                                  "verification": "Execute e confirme ausência de race conditions com valgrind --tool=helgrind.",
                                  "estimatedTime": "2 hours",
                                  "materials": "GCC com suporte OpenMP, Valgrind, código-fonte básico de contador.",
                                  "tips": "Use variáveis voláteis para spinloops personalizados se necessário.",
                                  "learningObjective": "Implementar corretamente primitivas de baixo overhead em código OpenMP.",
                                  "commonMistakes": "Esquecer omp_init_lock antes do uso; deadlocks por aninhamento incorreto."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar tasking e preparar aplicação de decomposição de domínio",
                                  "subSteps": [
                                    "Crie código de decomposição de domínio: grade 2D dividida em tasks por thread.",
                                    "Use #pragma omp parallel num_threads(8) { #pragma omp single { #pragma omp taskloop } }.",
                                    "Adicione dependências: #pragma omp task depend(out:cell[i]) para atualizações.",
                                    "Integre spinlock/RW-lock apenas em pontos críticos mínimos (ex: atualização de fronteiras).",
                                    "Execute baseline sem sincronização otimizada para comparação."
                                  ],
                                  "verification": "Verifique corretude com soma total da grade igual em execuções seriais/paralelas.",
                                  "estimatedTime": "2.5 hours",
                                  "materials": "Código-fonte de grade 2D (ex: Jacobi stencil), perf tool para profiling.",
                                  "tips": "Limite tasks a granulares > 10k operações para reduzir overhead de tasking.",
                                  "learningObjective": "Aplicar tasking em workloads reais com sincronização mínima.",
                                  "commonMistakes": "Excesso de tasks pequenas causando overhead; dependências incompletas levando a races."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Medir, comparar e analisar redução de overhead",
                                  "subSteps": [
                                    "Meça tempo total e overhead: use omp_get_wtime() em seções críticas e PAPI para locks adquiridos.",
                                    "Rode benchmarks: spinlock vs RW-lock vs tasking-only, 10 runs, média/desvio.",
                                    "Gere gráficos com Python/Matplotlib: speedup e overhead % vs threads.",
                                    "Identifique ganhador: ex: RW-locks reduzem 30-50% em acessos leitura-pesados.",
                                    "Otimize: ajuste spinlock com pausas (sched_yield) para longas esperas."
                                  ],
                                  "verification": "Relatório com tabelas/gráficos mostrando redução >20% em pelo menos um método.",
                                  "estimatedTime": "2 hours",
                                  "materials": "PAPI library para contadores hardware, Python/Matplotlib, likwid para perf.",
                                  "tips": "Fixe affinity de threads com OMP_PROC_BIND=spread para reprodutibilidade.",
                                  "learningObjective": "Quantificar empiricamente benefícios de sincronizações de baixo overhead.",
                                  "commonMistakes": "Medir apenas tempo total sem isolar overhead; ignorar cache effects."
                                }
                              ],
                              "practicalExample": "Em uma simulação de decomposição de domínio para grade 1024x1024 (Jacobi iteration), use RW-locks para acessos de fronteira leitura/escrita por tasks, reduzindo overhead de 15% (spinlock) para 5% do tempo total com 16 threads.",
                              "finalVerifications": [
                                "Código compila e executa sem erros ou races (valgrind clean).",
                                "Resultados corretos: grade final idêntica à serial.",
                                "Medições mostram redução de overhead >20% em pelo menos uma primitiva vs baseline.",
                                "Gráficos de speedup escalam sublinearmente mas melhor que mutex padrão.",
                                "Relatório resume trade-offs quantitativamente.",
                                "Testado em 4+ configurações de threads."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: distinção clara entre primitivas (80%).",
                                "Implementação correta: ausência de bugs sincronização (100%).",
                                "Análise quantitativa: métricas overhead precisas com erro <5% (90%).",
                                "Otimização demonstrada: escolha justificada pelo melhor método (85%).",
                                "Relatório claro: gráficos e conclusões acionáveis (90%).",
                                "Reprodutibilidade: scripts/inputs fornecidos."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: compreensão de primitivas de kernel como futexes.",
                                "Algoritmos e Estruturas: decomposição de domínio em grafos implícitos.",
                                "Engenharia de Software: profiling e otimização de performance.",
                                "Matemática Computacional: iterações em grades PDEs."
                              ],
                              "realWorldApplication": "Em simulações HPC como CFD (Computational Fluid Dynamics) no Lawrence Livermore Labs, RW-locks e tasking OpenMP reduzem overhead de sincronização em decomposições de malha, permitindo escalabilidade em 1000+ cores para previsões climáticas ou design automotivo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.4.3",
                        "name": "Overhead de Balanceamento de Carga",
                        "description": "Custos resultantes de distribuição desigual de trabalho entre processadores, levando a ociosidade e redução na eficiência paralela.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.4.3.1",
                            "name": "Detectar desbalanceamento em decomposições de domínio",
                            "description": "Identificar overhead por ociosidade em tarefas heterogêneas, usando profiling tools como gprof ou TAU para visualizar load imbalance em grades 2D/3D.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Decomposição de Domínio e Load Imbalance",
                                  "subSteps": [
                                    "Estude decomposição de domínio em grades 2D/3D, focando em divisão estática entre processos/threads.",
                                    "Identifique causas de desbalanceamento: tamanhos desiguais de subdomínios ou heterogeneidade computacional.",
                                    "Aprenda métricas chave: idle time (ociosidade), CPU utilization e overhead total.",
                                    "Revise exemplos visuais de grades uniformes vs. heterogêneas com regiões de alta/baixa carga.",
                                    "Diferencie load imbalance de outros overheads como comunicação ou sincronização."
                                  ],
                                  "verification": "Escreva um diagrama explicando load imbalance em uma grade 2D com 4 threads.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação OpenMP/MPI",
                                    "Tutoriais sobre profiling (gprof)",
                                    "Vídeos sobre domain decomposition"
                                  ],
                                  "tips": "Use desenhos à mão para visualizar como linhas de grade criam subdomínios desiguais.",
                                  "learningObjective": "Dominar fundamentos teóricos para reconhecer sintomas de desbalanceamento.",
                                  "commonMistakes": "Confundir desbalanceamento com gargalos de memória ou I/O."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Ambiente e Código de Exemplo com Heterogeneidade",
                                  "subSteps": [
                                    "Instale GCC com suporte a OpenMP e gprof (ex: sudo apt install gcc).",
                                    "Escreva código C/OpenMP para iterações em grade 2D (Jacobi stencil) com região central 2x mais computacional.",
                                    "Implemente decomposição estática por linhas, criando imbalance inerente.",
                                    "Adicione timers para medir wall-clock vs. CPU time por thread.",
                                    "Compile com flags -fopenmp -pg para habilitar profiling."
                                  ],
                                  "verification": "Compile e execute o código serial para validar resultados da grade.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Editor de código (VSCode)",
                                    "GCC com OpenMP",
                                    "Exemplo de código Jacobi 2D"
                                  ],
                                  "tips": "Comece com grade pequena (100x100) para testes rápidos; aumente para profiling.",
                                  "learningObjective": "Criar um benchmark reprodutível que exibe load imbalance mensurável.",
                                  "commonMistakes": "Esquecer #pragma omp parallel for ou usar schedule(static) sem ajuste."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar Profiling e Coletar Dados",
                                  "subSteps": [
                                    "Execute o código paralelo: ./programa 4 (para 4 threads).",
                                    "Gere arquivos gmon.out com múltiplas runs para estatísticas.",
                                    "Use gprof programa gmon.out > analysis.txt para relatório.",
                                    "Extraia tempos médios por função (compute_loop, barriers).",
                                    "Registre wall-time total vs. CPU-time agregado para calcular idle overhead."
                                  ],
                                  "verification": "Confirme presença de gmon.out e relatório gprof sem erros de parsing.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Terminal Linux/Mac",
                                    "gprof tool",
                                    "Código compilado"
                                  ],
                                  "tips": "Rode com OMP_NUM_THREADS=4; use time para capturar wall-clock.",
                                  "learningObjective": "Coletar dados brutos de profiling de forma consistente.",
                                  "commonMistakes": "Executar sem -pg ou em ambiente sem suporte a profiling."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e Visualizar Load Imbalance",
                                  "subSteps": [
                                    "Analise relatório gprof: identifique funções com alto tempo self vs. total (idle indicators).",
                                    "Calcule % idle: (wall_time * N_threads - sum CPU_time) / (wall_time * N_threads) * 100.",
                                    "Plote histogramas de tempo por thread usando dados de timers.",
                                    "Compare com run balanceado (schedule(dynamic)) para validação.",
                                    "Documente overhead por ociosidade em relatório com gráficos."
                                  ],
                                  "verification": "Produza gráfico mostrando >20% idle em pelo menos um thread.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python/Matplotlib para plots",
                                    "Relatório gprof",
                                    "Calculadora ou script"
                                  ],
                                  "tips": "Use call graphs do gprof para ver esperas em barriers.",
                                  "learningObjective": "Interpretar dados de profiling para quantificar e localizar imbalance.",
                                  "commonMistakes": "Ignorar variância entre runs; sempre média 5+ execuções."
                                }
                              ],
                              "practicalExample": "Em um solver de calor 2D (grade 512x512) com OpenMP e 8 threads, uma região central simula material denso (loops 2x mais iterações). gprof revela 25% idle time nos threads de borda, visualizado como picos desiguais em histogramas de tempo por thread.",
                              "finalVerifications": [
                                "Calculou corretamente % de overhead por ociosidade (>15% detectado).",
                                "Identificou threads/processos ociosos via relatório gprof.",
                                "Validou imbalance comparando com versão balanceada.",
                                "Produziu visualização clara (gráfico/histograma) do desbalanceamento.",
                                "Explicou causalidade ligando heterogeneidade da grade aos dados.",
                                "Quantificou impacto no speedup total."
                              ],
                              "assessmentCriteria": [
                                "Precisão na detecção: imbalance >10% identificado corretamente (90% acurácia).",
                                "Qualidade da análise: uso correto de métricas idle/CPU/wall.",
                                "Visualizações: gráficos legíveis e informativos.",
                                "Relatório completo: inclui causas, quantificação e sugestões de fix.",
                                "Reprodutibilidade: código e passos executáveis por terceiros.",
                                "Profundidade: diferencia de outros overheads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Discretização numérica de PDEs em grades estruturadas.",
                                "Estatística: Análise de variância e distribuições de tempos de execução.",
                                "Engenharia de Software: Práticas de benchmarking e otimização de performance.",
                                "Física/Computacional: Modelagem de simulações heterogêneas (ex: fluidodinâmica)."
                              ],
                              "realWorldApplication": "Em simulações CFD (Computational Fluid Dynamics) para previsão climática, onde regiões oceânicas têm workloads leves vs. continentes densos, detectando imbalance otimiza tempo de simulação em supercomputadores, reduzindo custos energéticos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.4.3.2",
                            "name": "Quantificar overhead de balanceamento dinâmico",
                            "description": "Medir custos de migração de tarefas em schedulers dinâmicos (ex: OpenMP runtime), comparando static vs. dynamic scheduling em loops paralelos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente e código base para benchmark",
                                  "subSteps": [
                                    "Instalar compilador com suporte OpenMP (ex: GCC >= 4.9)",
                                    "Criar código C/C++ com loop paralelo desbalanceado (ex: soma de array com workloads irregulares)",
                                    "Compilar com flags -fopenmp -O2 -g para debug e otimização",
                                    "Executar baseline sequencial para referência",
                                    "Verificar execução em múltiplos threads (ex: OMP_NUM_THREADS=4)"
                                  ],
                                  "verification": "Código compila sem erros e executa corretamente em modo sequencial e paralelo básico",
                                  "estimatedTime": "25 minutos",
                                  "materials": "GCC/Clang com OpenMP, editor de código (VSCode), terminal",
                                  "tips": "Use workloads desbalanceados como fib(n) ou pi computation para simular realismo",
                                  "learningObjective": "Estabelecer um benchmark reproducível para medir overheads",
                                  "commonMistakes": "Ignorar flags de otimização, causando medições inconsistentes; não balancear workload inicialmente"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e medir scheduling estático",
                                  "subSteps": [
                                    "Adicionar pragma #pragma omp parallel for schedule(static) ao loop",
                                    "Instrumentar código com omp_get_wtime() para medir tempo total de execução",
                                    "Executar múltiplas runs (ex: 100 iterações) e registrar tempos médios",
                                    "Calcular speedup estático vs. sequencial",
                                    "Exportar dados para CSV (tempo, threads, iterações)"
                                  ],
                                  "verification": "Tempos estáticos coletados com variância baixa (<5%) em runs repetidas",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código base do step 1, planilha (Excel/Google Sheets) para dados",
                                  "tips": "Fixe seed para workloads randômicos para reproducibilidade",
                                  "learningObjective": "Capturar baseline de overhead mínimo sem migrações",
                                  "commonMistakes": "Poucas runs, levando a ruído alto; confundir tempo wall-clock com CPU-time"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e medir scheduling dinâmico",
                                  "subSteps": [
                                    "Modificar pragma para #pragma omp parallel for schedule(dynamic, chunk_size)",
                                    "Testar diferentes chunk_sizes (ex: 1, 10, 100) para overhead variável",
                                    "Medir tempos com mesma instrumentação do step 2",
                                    "Executar runs idênticas ao estático para comparação direta",
                                    "Registrar overhead de migração via contadores OpenMP (omp_get_num_threads_migrated se disponível)"
                                  ],
                                  "verification": "Dados dinâmicos coletados, mostrando overhead > estático em workloads desbalanceados",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Código do step 2, documentação OpenMP para schedule(dynamic)",
                                  "tips": "Chunk pequeno aumenta migrações; monitore com omp_set_dynamic(1)",
                                  "learningObjective": "Quantificar custo de redistribuição de tarefas em runtime",
                                  "commonMistakes": "Chunk_size inadequado mascarando overhead; não isolar variáveis de ambiente"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e comparar overheads",
                                  "subSteps": [
                                    "Calcular overhead = (tempo_dinamico - tempo_estatico) / tempo_estatico * 100%",
                                    "Gerar gráficos (tempo vs. threads/chunk) usando Python/Matplotlib ou Gnuplot",
                                    "Analisar impacto de #threads e chunk_size no overhead",
                                    "Computar estatísticas (média, desvio padrão, intervalo de confiança)",
                                    "Documentar tabela comparativa static vs. dynamic"
                                  ],
                                  "verification": "Overhead quantificado numericamente (ex: 15-30% em cenários desbalanceados)",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Python com numpy/matplotlib, ou Excel avançado",
                                  "tips": "Use boxplots para visualizar variância entre runs",
                                  "learningObjective": "Extrair métricas acionáveis de dados brutos",
                                  "commonMistakes": "Erro em fórmula de overhead; ignorar cache effects em comparações"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar resultados e otimizar",
                                  "subSteps": [
                                    "Interpretar quando dynamic é benéfico (desbalance > overhead)",
                                    "Testar guided/auto schedules para comparação",
                                    "Identificar bottlenecks (ex: lock contention no runtime)",
                                    "Propor otimizações (chunk tuning, affinity)",
                                    "Redigir relatório com conclusões"
                                  ],
                                  "verification": "Relatório explica trade-offs com evidências gráficas",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Dados dos steps anteriores, ferramenta de plotting",
                                  "tips": "Considere hardware NUMA para migrações reais",
                                  "learningObjective": "Aplicar análise para decisões de scheduling",
                                  "commonMistakes": "Generalizar resultados sem contexto de workload/hardware"
                                }
                              ],
                              "practicalExample": "Em um loop de Monte Carlo para estimar Pi com 1M iterações desbalanceadas por thread, schedule(static) leva 2.1s (4 threads), dynamic(chunk=1) leva 2.8s; overhead = (2.8-2.1)/2.1 *100% = 33%, devido a 150 migrações registradas.",
                              "finalVerifications": [
                                "Overhead calculado corretamente para pelo menos 3 configurações (threads/chunk)",
                                "Gráficos comparativos gerados e interpretados",
                                "Relatório documenta condições de teste (hardware, workload)",
                                "Resultados reproduzíveis em runs independentes",
                                "Trade-offs static vs. dynamic explicados",
                                "Estatísticas de confiança (média ± DP) incluídas"
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos de overhead (erro <5%)",
                                "Qualidade e clareza dos gráficos/visualizações",
                                "Profundidade da análise de fatores influenciadores",
                                "Reprodutibilidade do experimento (código + dados)",
                                "Correta interpretação de quando usar cada schedule",
                                "Documentação completa e profissional"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Estatística descritiva e análise de variância",
                                "Arquitetura de Computadores: Efeitos de cache e NUMA em migrações",
                                "Engenharia de Software: Design de benchmarks e profiling",
                                "Algoritmos: Análise de complexidade em paralelismo",
                                "Sistemas Operacionais: Gerenciamento de threads e affinity"
                              ],
                              "realWorldApplication": "Em aplicações HPC como simulações climáticas ou ML training (ex: TensorFlow/OpenMP), quantificar overhead guia escolha de scheduler, reduzindo tempo de execução em 20-50% em clusters heterogêneos, otimizando custo em clouds como AWS ParallelCluster."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.3.1"
                            ]
                          },
                          {
                            "id": "10.1.5.4.3.3",
                            "name": "Aplicar técnicas de balanceamento para minimizar overhead",
                            "description": "Implementar partição recursiva bipartida ou work-stealing, avaliando melhoria no efficiency via métricas como speedup e eficiência em estudos de caso.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender fundamentos de balanceamento de carga e overhead",
                                  "subSteps": [
                                    "Estude o conceito de overhead em programação paralela, incluindo tempo gasto em sincronização e comunicação.",
                                    "Analise causas de desbalanceamento de carga, como tarefas de tamanhos variáveis.",
                                    "Revise métricas chave: speedup (S = T_seq / T_par), eficiência (E = S / P, onde P é número de processadores).",
                                    "Compare partição recursiva bipartida (divisão recursiva em metades) vs. work-stealing (roubo dinâmico de tarefas).",
                                    "Identifique cenários onde cada técnica minimiza overhead."
                                  ],
                                  "verification": "Resuma em um diagrama os trade-offs entre as técnicas e calcule speedup manualmente para um exemplo simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação OpenMP/MPI",
                                    "Artigos sobre balanceamento de carga (ex: Cilk papers)",
                                    "Calculadora ou planilha para métricas"
                                  ],
                                  "tips": "Use diagramas de Gantt para visualizar desbalanceamento antes/depois.",
                                  "learningObjective": "Entender como overhead de balanceamento impacta performance paralela.",
                                  "commonMistakes": [
                                    "Confundir overhead de balanceamento com overhead de comunicação",
                                    "Ignorar variabilidade de tarefas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar partição recursiva bipartida",
                                  "subSteps": [
                                    "Escolha um problema exemplo: multiplicação de matrizes ou ray tracing.",
                                    "Implemente partição inicial dividindo o domínio de dados em duas metades iguais.",
                                    "Aplique recursão até atingir granularidade desejada (ex: blocos de 100x100).",
                                    "Integre com framework paralelo (OpenMP sections ou MPI).",
                                    "Teste com cargas desbalanceadas inicialmente para observar melhoria."
                                  ],
                                  "verification": "Execute e verifique se workloads por thread são aproximadamente iguais via profiling (ex: gprof ou VTune).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador C++/Fortran com OpenMP/MPI",
                                    "Código base de multiplicação de matrizes sequencial",
                                    "Ferramenta de profiling como perf ou Intel VTune"
                                  ],
                                  "tips": "Comece com matrizes quadradas para simplicidade na bipartição.",
                                  "learningObjective": "Aplicar partição estática recursiva para distribuir workload uniformemente.",
                                  "commonMistakes": [
                                    "Partições desiguais devido a arredondamento",
                                    "Excesso de recursão levando a overhead de chamadas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar work-stealing para balanceamento dinâmico",
                                  "subSteps": [
                                    "Crie filas de tarefas (deques) por thread/worker.",
                                    "Implemente roubo: thread ociosa rouba da ponta oposta da fila de vítima.",
                                    "Integre com scheduler paralelo (ex: usando Cilk ou pthread custom).",
                                    "Adicione sincronização mínima com locks ou lock-free.",
                                    "Teste em workloads irregulares como merge sort paralelo."
                                  ],
                                  "verification": "Monitore taxa de roubo e reduções de idle time via logs ou traces.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Biblioteca pthread ou Intel TBB",
                                    "Código exemplo de work-stealing (GitHub repos)",
                                    "Debugger como gdb"
                                  ],
                                  "tips": "Use double-ended queues (deque) para eficiência em pop_front/pop_back.",
                                  "learningObjective": "Dominar balanceamento dinâmico adaptativo a variações de runtime.",
                                  "commonMistakes": [
                                    "Contenção excessiva em locks compartilhados",
                                    "Roubo de tarefas muito pequenas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar e medir melhorias em performance",
                                  "subSteps": [
                                    "Colete tempos sequencial e paralelo para baseline.",
                                    "Meça speedup e eficiência variando número de threads (2-16).",
                                    "Profile overhead: % tempo em balanceamento vs. compute.",
                                    "Compare as duas técnicas em estudos de caso (ex: matriz vs. tree traversal).",
                                    "Gere gráficos de speedup usando Python/Matplotlib."
                                  ],
                                  "verification": "Produza relatório com tabelas/gráficos mostrando speedup > 80% eficiência.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de timing: gettimeofday ou MPI_Wtime",
                                    "Python para plots",
                                    "Datasets de teste variados"
                                  ],
                                  "tips": "Repita medições 10x e use média para precisão.",
                                  "learningObjective": "Quantificar impacto das técnicas via métricas padrão.",
                                  "commonMistakes": [
                                    "Medir apenas tempo wall-clock sem isolar overhead",
                                    "Ignorar warm-up runs"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar estudos de caso e otimizar",
                                  "subSteps": [
                                    "Estude casos reais: ray tracing em Pixar ou simulações CFD.",
                                    "Identifique quando usar cada técnica (estático vs. dinâmico).",
                                    "Otimize híbrido: partição inicial + work-stealing.",
                                    "Documente lições aprendidas e thresholds de granularidade.",
                                    "Teste escalabilidade em cluster se disponível."
                                  ],
                                  "verification": "Escreva um estudo de caso de 1 página comparando técnicas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Papers ACM/IEEE sobre parallel workloads",
                                    "Cluster acessível ou simulador"
                                  ],
                                  "tips": "Foque em workloads reais para relevância.",
                                  "learningObjective": "Aplicar técnicas em contextos variados e iterar otimizações.",
                                  "commonMistakes": [
                                    "Generalizar uma técnica para todos cenários",
                                    "Subestimar custos de roubo"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um aplicativo de processamento de imagens paralelas (ex: filtro Gaussiano em OpenCV com múltiplas threads), aplique partição recursiva bipartida para dividir a imagem em regiões iguais ou work-stealing para tarefas de pixels irregulares, medindo redução de overhead de 30% em speedup via profiling.",
                              "finalVerifications": [
                                "Implementações de ambas técnicas compilam e executam sem erros.",
                                "Speedup linear até 8 threads com eficiência > 70%.",
                                "Overhead de balanceamento < 10% do tempo total.",
                                "Análise comparativa mostra escolha adequada por workload.",
                                "Relatório com métricas e gráficos gerados.",
                                "Testes em pelo menos dois cenários diferentes passam."
                              ],
                              "assessmentCriteria": [
                                "Precisão e correção das implementações (código funcional).",
                                "Qualidade das medições (reprodutibilidade e estatísticas).",
                                "Análise profunda de trade-offs e overhead.",
                                "Uso apropriado de ferramentas de profiling.",
                                "Clareza no relatório e visualizações.",
                                "Criatividade em otimizações híbridas."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados (árvores de partição recursiva).",
                                "Sistemas Operacionais (schedulers e threads).",
                                "Otimização e Análise de Algoritmos (métricas de performance).",
                                "Computação em Nuvem e HPC (escalabilidade distribuída).",
                                "Engenharia de Software (testes e profiling)."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas (ex: NASA models), servidores web como Nginx multi-threaded para balancear requests, ou frameworks big data como Apache Spark para tarefas MapReduce dinâmicas, minimizando idle time e maximizando throughput em clusters."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.3.1",
                              "10.1.5.4.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.5",
                    "name": "Ferramentas de Avaliação de Desempenho",
                    "description": "Uso de profilers e benchmarks para medir e analisar o desempenho paralelo.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.5.1.1",
                        "name": "Profilers para Programação Paralela",
                        "description": "Ferramentas especializadas em coletar e visualizar dados de execução de programas paralelos, identificando gargalos em computação, comunicação e sincronização em arquiteturas multicores, heterogêneas ou distribuídas.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.5.1.1.1",
                            "name": "Configurar e instrumentar um profiler como TAU ou Vampir",
                            "description": "Instalar ferramentas de profiling como TAU (Tuning and Analysis Utilities) ou Vampir, instrumentar códigos em linguagens paralelas (MPI, OpenMP) e coletar traces de execução para análise de desempenho.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Instalar e configurar TAU e Vampir",
                                  "subSteps": [
                                    "Verifique pré-requisitos: sistema Linux com compilador C/C++ (gcc), MPI (OpenMPI ou MPICH) e OpenMP suporte.",
                                    "Baixe TAU do site oficial (https://www.cs.uoregon.edu/research/tau/home.php) e extraia o tarball.",
                                    "Configure TAU com suporte a MPI e OpenMP: ./configure --prefix=/usr/local/tau -mpi.",
                                    "Compile e instale TAU: make && make install.",
                                    "Baixe Vampir do site oficial (https://www.vampir.eu/) e instale seguindo as instruções para sua distribuição."
                                  ],
                                  "verification": "Execute 'tau_exec -h' e 'vampir' para confirmar instalação sem erros.",
                                  "estimatedTime": "1-2 hours",
                                  "materials": [
                                    "Máquina Linux com privilégios sudo",
                                    "Compilador gcc/g++",
                                    "OpenMPI ou MPICH instalado",
                                    "Conexão internet"
                                  ],
                                  "tips": "Use um ambiente virtual como Conda para isolar dependências e evitar conflitos.",
                                  "learningObjective": "Configurar corretamente o ambiente de profiling com TAU e Vampir.",
                                  "commonMistakes": [
                                    "Esquecer de instalar dependências como PAPI ou hwloc",
                                    "Não especificar --mpi no configure do TAU",
                                    "Ignorar verificação de PATH após instalação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Instrumentar um programa MPI com TAU",
                                  "subSteps": [
                                    "Crie um programa MPI simples (ex: Hello World ou cálculo de Pi).",
                                    "Compile com TAU: tau_cc.sh -tau_makefile=/usr/local/tau/lib/Makefile.tau-mpi-pdt your_program.c -o your_program_tau.",
                                    "Execute o programa instrumentado: mpirun -np 4 ./your_program_tau -tau_trace.",
                                    "Confirme geração de arquivos de trace (.tau, .events).",
                                    "Copie os traces para análise posterior."
                                  ],
                                  "verification": "Verifique se arquivos .tau e .events foram gerados e não estão vazios.",
                                  "estimatedTime": "45 minutes",
                                  "materials": [
                                    "Código fonte MPI simples",
                                    "TAU instalado",
                                    "MPI runtime"
                                  ],
                                  "tips": "Sempre use tau_cc.sh como wrapper do compilador para instrumentação automática.",
                                  "learningObjective": "Instrumentar e executar códigos MPI coletando traces de desempenho.",
                                  "commonMistakes": [
                                    "Compilar sem tau_cc.sh, perdendo instrumentação",
                                    "Executar sem -tau_trace, sem coletar dados",
                                    "Usar np muito alto sem recursos suficientes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Instrumentar um programa OpenMP com TAU",
                                  "subSteps": [
                                    "Crie um programa OpenMP simples (ex: soma de vetores paralela).",
                                    "Compile com suporte OpenMP: tau_cc.sh -tau_makefile=/usr/local/tau/lib/Makefile.tau-pdt -openmp your_program.c -o your_program_tau.",
                                    "Execute: export OMP_NUM_THREADS=4; ./your_program_tau -tau_trace.",
                                    "Verifique geração de traces específicos para threads OpenMP.",
                                    "Compare tamanhos de traces com versão MPI."
                                  ],
                                  "verification": "Abra um trace em Vampir e confirme visualização de threads OpenMP.",
                                  "estimatedTime": "45 minutes",
                                  "materials": [
                                    "Código fonte OpenMP",
                                    "TAU com suporte OpenMP"
                                  ],
                                  "tips": "Defina OMP_NUM_THREADS via export para controle preciso de paralelismo.",
                                  "learningObjective": "Aplicar instrumentação TAU em códigos OpenMP para análise de threads.",
                                  "commonMistakes": [
                                    "Omitir flag -openmp no compile",
                                    "Não definir OMP_NUM_THREADS",
                                    "Confundir traces MPI com OpenMP"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Coletar traces e analisar com Vampir",
                                  "subSteps": [
                                    "Colete traces de execuções MPI e OpenMP em cenários variados (diferentes np/threads).",
                                    "Inicie Vampir: vampir.",
                                    "Carregue trace: File > Open Trace > selecione .tau ou merged traces.",
                                    "Explore visualizações: timeline, estadísticas de tempo, hotspots.",
                                    "Gere relatório básico de desempenho (tempo total, imbalance)."
                                  ],
                                  "verification": "Identifique pelo menos um hotspot ou imbalance no trace visualizado.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Traces gerados nos steps anteriores",
                                    "Vampir instalado"
                                  ],
                                  "tips": "Use 'tau_merge' para combinar múltiplos traces antes de abrir no Vampir.",
                                  "learningObjective": "Visualizar e interpretar traces de execução para análise inicial de desempenho.",
                                  "commonMistakes": [
                                    "Abrir traces sem merge para execuções múltiplas",
                                    "Ignorar filtros no Vampir para navegação",
                                    "Não calibrar traces para precisão temporal"
                                  ]
                                }
                              ],
                              "practicalExample": "Instrumente um programa MPI para cálculo paralelo de Pi usando 4 processos: compile com tau_cc.sh, execute com mpirun -np 4, gere trace, abra no Vampir e identifique tempo gasto em comunicação vs. computação.",
                              "finalVerifications": [
                                "TAU e Vampir instalados e executáveis sem erros.",
                                "Traces válidos gerados para MPI e OpenMP.",
                                "Visualização correta de timelines e estatísticas no Vampir.",
                                "Identificação de pelo menos um bottleneck em um trace.",
                                "Compilação e execução de códigos instrumentados sem falhas.",
                                "Relatório simples gerado com métricas de desempenho."
                              ],
                              "assessmentCriteria": [
                                "Precisão na instalação (sem warnings/erros).",
                                "Corretude dos traces (visualizáveis e com dados relevantes).",
                                "Capacidade de interpretar hotspots e imbalances.",
                                "Eficiência na instrumentação para ambos paradigmas (MPI/OpenMP).",
                                "Documentação clara de passos executados.",
                                "Aplicação em exemplo prático com análise."
                              ],
                              "crossCurricularConnections": [
                                "Programação Paralela: Integra com MPI/OpenMP basics.",
                                "Análise de Desempenho: Conecta com métricas como speedup/scalability.",
                                "Engenharia de Software: Práticas de debugging e otimização.",
                                "Ciência de Dados: Visualização de traces como gráficos temporais."
                              ],
                              "realWorldApplication": "Em supercomputadores para otimizar simulações científicas (ex: clima, física de partículas), reduzindo tempo de execução de dias para horas ao identificar gargalos de comunicação em códigos HPC."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.1.1.2",
                            "name": "Analisar traces de comunicação e sincronização",
                            "description": "Interpretar gráficos de timeline e estatísticas de profilers para identificar overheads em trocas de mensagens (MPI) ou exclusão mútua (OpenMP), relacionando com modelos de memória compartilhada e distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e coletar traces com profiler",
                                  "subSteps": [
                                    "Instale e configure um profiler compatível (ex: Vampir para MPI/OpenMP ou Intel Trace Analyzer).",
                                    "Compile o programa paralelo com flags de instrumentação (ex: -fopenmp para OpenMP ou mpirun com tracing para MPI).",
                                    "Execute o programa em um ambiente controlado (ex: cluster local ou máquina multi-core) e gere os arquivos de trace.",
                                    "Valide a coleta verificando se os arquivos de trace foram gerados sem erros.",
                                    "Carregue os traces no visualizador do profiler."
                                  ],
                                  "verification": "Confirme que os traces são carregados e exibem timelines iniciais sem erros de parsing.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código fonte paralelo (MPI/OpenMP), profiler instalado (Vampir/Intel Trace Analyzer), compilador com suporte (GCC/MPICH/OpenMPI).",
                                  "tips": "Use configurações de batch para evitar overhead desnecessário na coleta.",
                                  "learningObjective": "Configurar corretamente ferramentas de profiling para capturar dados de comunicação e sincronização.",
                                  "commonMistakes": "Esquecer flags de instrumentação, levando a traces vazios; executar em modo sequencial."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar gráficos de timeline para comunicação MPI",
                                  "subSteps": [
                                    "Identifique eventos de send/receive ou collectives (Allreduce, Broadcast) na timeline.",
                                    "Meça durações e gaps entre processos para detectar latência em trocas de mensagens.",
                                    "Analise o volume de dados transferidos e compare com o esperado.",
                                    "Marque regiões de overhead (ex: imbalance em collectives).",
                                    "Gere estatísticas agregadas de tempo gasto em comunicação."
                                  ],
                                  "verification": "Anote pelo menos 2 exemplos de overheads em comunicação com timestamps e durações.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Arquivos de trace gerados, visualizador de profiler.",
                                  "tips": "Zoom em regiões críticas e use filtros para isolar eventos MPI.",
                                  "learningObjective": "Reconhecer padrões de overhead em mensagens MPI via timelines visuais.",
                                  "commonMistakes": "Confundir latência de rede com overhead de CPU; ignorar imbalance entre ranks."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar traces de sincronização OpenMP e exclusão mútua",
                                  "subSteps": [
                                    "Localize barreiras (#pragma omp barrier) e locks/critical sections na timeline.",
                                    "Meça tempo de espera em threads e identifique contenção em locks.",
                                    "Compare overheads com workloads de threads para detectar serialização.",
                                    "Extraia estatísticas de profilers (ex: % tempo em sync).",
                                    "Relacione picos de sync com seções críticas do código."
                                  ],
                                  "verification": "Liste 3 instâncias de contenção com evidências de timeline e métricas.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Traces OpenMP do profiler, documentação da API OpenMP.",
                                  "tips": "Use counters de hardware para validar overheads de sync.",
                                  "learningObjective": "Identificar e quantificar overheads de sincronização em modelos de memória compartilhada.",
                                  "commonMistakes": "Atribuir overhead de sync a computação; não diferenciar busy-wait de lock contention."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar overheads com modelos de memória e propor otimizações",
                                  "subSteps": [
                                    "Classifique overheads como distribuídos (MPI: mensagens) vs. compartilhados (OpenMP: locks).",
                                    "Compare com teoria: NUMA effects em compartilhada, bandwidth em distribuída.",
                                    "Sugira otimizações (ex: non-blocking MPI, reduce locks em OpenMP).",
                                    "Simule/refatore uma seção otimizada e re-profile.",
                                    "Documente relatório com gráficos anotados."
                                  ],
                                  "verification": "Produza um relatório relacionando 2+ overheads a modelos de memória com propostas acionáveis.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Traces analisados, editores de código, teoria de memória paralela (referências).",
                                  "tips": "Priorize otimizações de baixo custo como reordenação de collectives.",
                                  "learningObjective": "Conectar análises empíricas de traces a conceitos teóricos de memória paralela.",
                                  "commonMistakes": "Ignorar locality em NUMA; propor MPI para problemas compartilhados."
                                }
                              ],
                              "practicalExample": "Em um programa de multiplicação de matrizes distribuída via MPI, analise traces Vampir para identificar que 40% do tempo é gasto em Allreduce desbalanceado entre ranks, propondo MPI_Iallreduce não-bloqueante para reduzir overhead em 25%. Para OpenMP, detecte contenção em critical para soma parcial, substituindo por atomic ou reduction.",
                              "finalVerifications": [
                                "Pode carregar e navegar traces sem erros.",
                                "Identifica corretamente overheads >10% em comunicação/sincronização.",
                                "Relaciona achados a MPI (distribuída) vs. OpenMP (compartilhada).",
                                "Propõe pelo menos 2 otimizações viáveis com re-profile.",
                                "Gera relatório com timelines anotadas.",
                                "Explica impacto em escalabilidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de eventos (90%+ taxa de acerto).",
                                "Profundidade da análise quantitativa (métricas com durações/volumes).",
                                "Correta distinção entre modelos de memória.",
                                "Qualidade das otimizações propostas (medidas por redução simulada).",
                                "Clareza do relatório (gráficos + explicações).",
                                "Integração de teoria e prática."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Latência/bandwidth em MPI.",
                                "Sistemas Operacionais: Gerenciamento de threads e locks NUMA.",
                                "Algoritmos e Estruturas: Balanceamento de workload em paralelos.",
                                "Engenharia de Software: Debugging e profiling tools."
                              ],
                              "realWorldApplication": "Em supercomputadores HPC (ex: simulações climáticas no TOP500), otimizar comunicação MPI reduz tempo de run de dias para horas; em data centers multi-core, minimizar locks OpenMP melhora throughput de apps web escaláveis."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.1.1.3",
                            "name": "Otimizar código baseado em resultados de profiler",
                            "description": "Usar relatórios de profilers para refatorar decomposição de domínio ou balanceamento de carga, medindo melhorias em speedup e eficiência em plataformas multicores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Instrumentar e Executar o Profiler no Código Original",
                                  "subSteps": [
                                    "Compile o código com flags de suporte a paralelismo (ex: -fopenmp para OpenMP).",
                                    "Instale e configure o profiler (ex: perf no Linux ou Intel VTune).",
                                    "Execute o profiler com o código baseline: perf record ./programa",
                                    "Colete métricas iniciais como tempo total, CPU utilization e chamadas de função.",
                                    "Gere o relatório inicial: perf report"
                                  ],
                                  "verification": "Verifique se o relatório do profiler foi gerado sem erros e contém dados de amostragem válidos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código fonte paralelo (ex: multiplicação de matrizes com OpenMP)",
                                    "Compilador GCC/Clang com suporte OpenMP",
                                    "Ferramenta perf instalada",
                                    "Máquina multicore"
                                  ],
                                  "tips": "Use cargas de trabalho representativas para simular cenários reais; evite otimizações do compilador inicialmente (-O0).",
                                  "learningObjective": "Aprender a coletar dados de perfilamento precisos do código paralelo baseline.",
                                  "commonMistakes": [
                                    "Executar sem flags corretas de profiling",
                                    "Usar datasets muito pequenos que mascaram gargalos",
                                    "Ignorar overhead do profiler"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o Relatório do Profiler para Identificar Gargalos",
                                  "subSteps": [
                                    "Examine hotspots: funções ou loops com alto % de tempo de CPU.",
                                    "Identifique desbalanceamento de carga: threads com tempos desiguais via timeline view.",
                                    "Analise decomposição de domínio: verifique granularidade de trabalho por thread.",
                                    "Registre métricas chave: speedup atual, eficiência (tempo útil / tempo total).",
                                    "Priorize gargalos: foco em hotspots >20% do tempo total."
                                  ],
                                  "verification": "Crie um sumário escrito dos top 3 gargalos identificados com evidências do relatório.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Relatório gerado pelo perf report ou VTune GUI",
                                    "Notebook para anotações",
                                    "Documentação do profiler"
                                  ],
                                  "tips": "Use views flame graph ou call graph para visualização intuitiva; filtre por threads específicas.",
                                  "learningObjective": "Desenvolver habilidade em interpretar relatórios de profiler para diagnósticos precisos.",
                                  "commonMistakes": [
                                    "Focar apenas em tempo absoluto, ignorando overheads paralelos",
                                    "Confundir cache misses com desbalanceamento",
                                    "Não considerar variância entre runs"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Planejar Refatorações Específicas Baseadas na Análise",
                                  "subSteps": [
                                    "Para desbalanceamento: planeje dynamic scheduling ou chunk size adjustment.",
                                    "Para decomposição ruim: refine partição de domínio (ex: block vs cyclic).",
                                    "Estime impacto: calcule speedup teórico via Lei de Amdahl.",
                                    "Defina hipóteses testáveis para cada mudança.",
                                    "Documente plano com pseudocódigo das alterações."
                                  ],
                                  "verification": "Revise o plano com um colega ou auto-revisão para cobertura de gargalos principais.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Sumário de análise do Step 2",
                                    "Lei de Amdahl reference sheet",
                                    "Editor de texto"
                                  ],
                                  "tips": "Priorize uma refatoração por vez para isolar impactos; mire em melhorias >10%.",
                                  "learningObjective": "Mapear insights de profiling para estratégias de otimização paralela acionáveis.",
                                  "commonMistakes": [
                                    "Planejar mudanças radicais sem baseline",
                                    "Ignorar custos de comunicação em refatorações",
                                    "Superestimar speedup sem Amdahl"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar Refatorações e Reperfilizar",
                                  "subSteps": [
                                    "Aplique mudanças no código (ex: schedule(dynamic) no OpenMP).",
                                    "Compile e execute múltiplas runs para média estatística.",
                                    "Reexecute profiler: perf record ./programa_otimizado",
                                    "Gere relatório comparativo: diff entre before/after.",
                                    "Meça speedup: tempo_original / tempo_novo."
                                  ],
                                  "verification": "Confirme que o novo relatório mostra redução nos hotspots targeted (>15% melhoria).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código refatorado",
                                    "Profiler",
                                    "Scripts para automação de runs"
                                  ],
                                  "tips": "Use version control (Git) para branches before/after; rode 10+ iterações para variância baixa.",
                                  "learningObjective": "Executar otimizações iterativas guiadas por dados de profiler.",
                                  "commonMistakes": [
                                    "Introduzir novos bugs durante refatoração",
                                    "Comparar runs sem controlar variáveis (ex: pinning de threads)",
                                    "Parar após primeira melhoria"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar Melhorias e Documentar Resultados",
                                  "subSteps": [
                                    "Calcule métricas finais: speedup, eficiência paralela, escalabilidade.",
                                    "Compare gráficos before/after de CPU time e balanceamento.",
                                    "Teste robustez: varie número de cores e tamanhos de input.",
                                    "Documente lições aprendidas e código final.",
                                    "Prepare relatório com evidências quantitativas."
                                  ],
                                  "verification": "Speedup >1.2x e eficiência >80% em pelo menos um gargalo principal.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Relatórios comparativos",
                                    "Ferramentas de plotagem (ex: matplotlib)",
                                    "Template de relatório"
                                  ],
                                  "tips": "Use numactl para pinning de threads em NUMA systems; benchmark em diferentes core counts.",
                                  "learningObjective": "Quantificar e validar ganhos de performance em programação paralela.",
                                  "commonMistakes": [
                                    "Aceitar melhorias aparentes sem testes de escalabilidade",
                                    "Não documentar para reutilização futura",
                                    "Ignorar overheads em small inputs"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um código de multiplicação de matrizes 1000x1000 com OpenMP, o profiler perf revela desbalanceamento (thread 0: 60% tempo). Refatore para schedule(dynamic,50), resultando em speedup de 1.8x de 4 para 8 cores, eficiência de 65% para 88%.",
                              "finalVerifications": [
                                "Relatórios before/after mostram redução quantificável em hotspots targeted.",
                                "Speedup mensurável (>1.2x) em múltiplos core counts.",
                                "Eficiência paralela >80% sem introduzir novos gargalos.",
                                "Código otimizado passa em testes de corretude.",
                                "Documentação inclui plano, métricas e lições.",
                                "Reproduzibilidade confirmada em 5+ runs."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de gargalos via profiler (cobertura >90% dos hotspots reais).",
                                "Relevância das refatorações ao diagnóstico (melhoria alinhada à análise).",
                                "Quantificação rigorosa de speedup e eficiência com estatísticas.",
                                "Qualidade do código refatorado (legível, comentado, sem bugs).",
                                "Análise de escalabilidade multicore demonstrada.",
                                "Documentação completa e acionável."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Aplicação da Lei de Amdahl e análise assintótica de algoritmos paralelos.",
                                "Engenharia de Software: Práticas de refatoração, versionamento e testes automatizados.",
                                "Arquitetura de Computadores: Compreensão de caches, NUMA e topologias multicore.",
                                "Gestão de Projetos: Iteração data-driven e priorização de tarefas.",
                                "Big Data: Paralelismo em frameworks como Spark ou Hadoop."
                              ],
                              "realWorldApplication": "Em simulações científicas (ex: modelagem climática no IPCC), HPC para IA (treinamento distribuído em TensorFlow), ou apps de streaming (balanceamento em Kafka clusters), onde otimizações de profiler reduzem tempo de computação de dias para horas, cortando custos em data centers."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.5.1.1.1",
                              "10.1.5.5.1.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.5.1.2",
                        "name": "Benchmarks para Avaliação de Desempenho Paralelo",
                        "description": "Conjuntos de testes padronizados para medir desempenho em diferentes arquiteturas, permitindo comparações de speedup, eficiência e escalabilidade em programação paralela.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.5.1.2.1",
                            "name": "Executar benchmarks como NAS ou HPL",
                            "description": "Compilar e rodar benchmarks NAS Parallel Benchmarks ou High-Performance Linpack (HPL) em clusters ou multicores, configurando parâmetros para memória distribuída e compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente de execução",
                                  "subSteps": [
                                    "Verificar hardware disponível: multicore local ou cluster com pelo menos 4 nós e rede de alta velocidade (ex: InfiniBand).",
                                    "Instalar dependências: compilador (GCC ou Intel oneAPI), biblioteca MPI (OpenMPI ou MPICH), BLAS/LAPACK (OpenBLAS ou MKL).",
                                    "Baixar código fonte oficial do HPL (netlib.org) ou NAS Parallel Benchmarks (nas.nasa.gov).",
                                    "Configurar variáveis de ambiente (ex: export MPICC=mpicc, LD_LIBRARY_PATH).",
                                    "Testar instalação com 'mpirun --version' e compilação de hello world MPI."
                                  ],
                                  "verification": "Todas as dependências instaladas e testadas sem erros de compilação básica.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Máquina Linux com SSH",
                                    "Compilador GCC/Intel",
                                    "OpenMPI",
                                    "Código fonte HPL/NAS",
                                    "Acesso a cluster (opcional)"
                                  ],
                                  "tips": "Use gerenciadores de pacotes como apt/yum ou módulos Spack/Slurm em clusters para evitar conflitos de versões.",
                                  "learningObjective": "Configurar corretamente o ambiente para execução de benchmarks paralelos.",
                                  "commonMistakes": [
                                    "Ignorar dependências de BLAS/MPI",
                                    "Usar versões incompatíveis de bibliotecas",
                                    "Não configurar PATH corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compilar o benchmark",
                                  "subSteps": [
                                    "Extrair o código fonte e navegar para o diretório (ex: cd HPL-2.3).",
                                    "Editar Make.<arquitetura> para apontar MPI e BLAS (ex: MPICC=mpicc, BLASLIB=-lopenblas).",
                                    "Executar make para compilar o executável (ex: make arch=mk-MPI).",
                                    "Verificar integridade do binário gerado (ex: ls -la xhpl).",
                                    "Testar compilação cruzada se necessário para cluster remoto."
                                  ],
                                  "verification": "Executável gerado sem warnings/erros e tamanho plausível (>1MB).",
                                  "estimatedTime": "30-60 minutos",
                                  "materials": [
                                    "Código fonte compilado",
                                    "Makefile editável",
                                    "Editor de texto (vim/nano)"
                                  ],
                                  "tips": "Backup do Makefile original antes de editar; use flags de otimização -O3 para performance.",
                                  "learningObjective": "Compilar benchmarks HPC adaptados a arquiteturas paralelas.",
                                  "commonMistakes": [
                                    "Configuração errada de paths para MPI/BLAS",
                                    "Ignorar flags de precisão (single/double)",
                                    "Compilação sem paralelismo habilitado"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar parâmetros do benchmark",
                                  "subSteps": [
                                    "Criar/Editar arquivo de input HPL.dat ou NAS class S (ex: N=10000, NB=192 para HPL).",
                                    "Definir topologia de processo: PxQ para grade lógica (ex: P=4 Q=16 para 64 processos).",
                                    "Configurar para memória compartilhada (OpenMP) ou distribuída (MPI): threshold, BCAST/REDUCE algoritmos.",
                                    "Ajustar para hardware: memória por processo <50% disponível, iterações para precisão.",
                                    "Validar sintaxe do arquivo de input com script de checagem se disponível."
                                  ],
                                  "verification": "Arquivo de input parseado sem erros ao rodar benchmark em modo dry-run.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Template HPL.dat ou NAS config",
                                    "Documentação oficial HPL/NAS"
                                  ],
                                  "tips": "Comece com configurações pequenas (N=5000) para testar; otimize NB baseado em cache L1/L2.",
                                  "learningObjective": "Personalizar parâmetros para otimizar desempenho em diferentes modelos de memória.",
                                  "commonMistakes": [
                                    "PxQ não divisível pelo número de processos",
                                    "N muito grande causando OOM",
                                    "Algoritmos de comunicação subótimos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar o benchmark",
                                  "subSteps": [
                                    "Submeter job via scheduler (ex: sbatch script.slurm) ou mpirun local (mpirun -np 64 ./xhpl).",
                                    "Monitorar execução: usar top/htop, squeue para progresso e uso de CPU/GPU/rede.",
                                    "Capturar output: redirecionar stdout/stderr para logs (ex: > hpl.out 2> hpl.err).",
                                    "Executar múltiplas runs com variações de parâmetros para reprodutibilidade.",
                                    "Parar execução se detectar anomalias (ex: Ctrl+C ou scancel)."
                                  ],
                                  "verification": "Benchmark completa 100% das iterações sem crashes, gera relatório final.",
                                  "estimatedTime": "1-4 horas (depende de hardware)",
                                  "materials": [
                                    "Script Slurm/PBS",
                                    "Acesso de escrita no filesystem compartilhado"
                                  ],
                                  "tips": "Defina ulimit -s unlimited para stack; rode em nodes exclusivos para precisão.",
                                  "learningObjective": "Executar benchmarks em ambientes paralelos reais com gerenciamento de jobs.",
                                  "commonMistakes": [
                                    "Sobrecarga de nós causando thrashing",
                                    "Falta de filesystem rápido para I/O",
                                    "Não bindar processos a cores"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar resultados e verificar",
                                  "subSteps": [
                                    "Extrair métricas chave: GFLOPS residuais e teóricos do output (ex: grep 'Gflops' hpl.out).",
                                    "Plotar escalabilidade: speedup vs. #processos usando gnuplot ou Python/Matplotlib.",
                                    "Comparar com baselines: TOP500 ou resultados prévios no mesmo hardware.",
                                    "Diagnosticar bottlenecks: analisar timings de comunicação/computação.",
                                    "Documentar achados em relatório com screenshots de outputs."
                                  ],
                                  "verification": "Relatório com GFLOPS >80% eficiência e gráficos gerados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python/Matplotlib",
                                    "Gnuplot",
                                    "Editor para relatório"
                                  ],
                                  "tips": "Use Rpeak/Rmax para normalizar; valide eficiência >70% para configs boas.",
                                  "learningObjective": "Interpretar e validar resultados de benchmarks para avaliação de desempenho.",
                                  "commonMistakes": [
                                    "Confundir GFLOPS reais com teóricos",
                                    "Ignorar variância entre runs",
                                    "Não considerar overhead de rede"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster com 4 nós (Intel Xeon, 32 cores/no), compile HPL com OpenMPI+OpenBLAS, configure HPL.dat com N=20000, P=8 Q=32 (256 processos), rode via Slurm: sbatch -N4 -n256 hpl.job, obtenha ~500 GFLOPS residuais, analise escalabilidade perfeita até 128 processos.",
                              "finalVerifications": [
                                "Benchmark compilou e executou sem erros ou crashes.",
                                "GFLOPS residuais reportados e consistentes (>70% eficiência).",
                                "Arquivos de output/logs gerados e parseáveis.",
                                "Escalabilidade testada em pelo menos 3 configurações de processos.",
                                "Resultados reproduzíveis em segunda execução.",
                                "Nenhum OOM ou timeout durante a run."
                              ],
                              "assessmentCriteria": [
                                "Configuração precisa de parâmetros para modelo de memória (distribuída/compartilhada).",
                                "Eficiência de performance >75% do teórico.",
                                "Análise correta de bottlenecks e escalabilidade.",
                                "Uso eficiente de recursos de cluster (sem desperdício de nós).",
                                "Documentação completa com métricas e gráficos.",
                                "Troubleshooting de erros comuns demonstrado."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra Linear e resolução de sistemas (base do HPL).",
                                "Redes de Computadores: Protocolos de comunicação MPI em clusters.",
                                "Administração de Sistemas: Gerenciamento de filas Slurm/PBS e alocação de recursos.",
                                "Otimização Numérica: Tuning de algoritmos BLAS e topologias de processo.",
                                "Engenharia de Software: Compilação cruzada e automação de builds."
                              ],
                              "realWorldApplication": "Esses benchmarks são usados no ranking TOP500 de supercomputadores para certificar performance de hardware em laboratórios nacionais (ex: LNCC/SENAI), otimizar data centers de IA/clima, e validar compras de clusters em indústrias de óleo/gás e pesquisa científica."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.1.2.2",
                            "name": "Calcular métricas de desempenho a partir de benchmarks",
                            "description": "Computar speedup, eficiência, isoeficiência e tempo de comunicação usando resultados de benchmarks, relacionando com taxonomia de Flynn e modelos de programação paralela.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Métricas de Desempenho Paralelo",
                                  "subSteps": [
                                    "Estude as definições de speedup (S_p = T_1 / T_p), eficiência (E_p = S_p / p) e isoeficiência.",
                                    "Revise taxonomia de Flynn (SISD, SIMD, MISD, MIMD) e como benchmarks se aplicam a cada classe.",
                                    "Aprenda modelos de programação paralela (ex: PRAM, BSP) e seu impacto em métricas.",
                                    "Identifique componentes de tempo de comunicação em benchmarks (ex: modelo logP: L, o, g, G).",
                                    "Relacione métricas com overheads paralelos (comunicação, sincronização)."
                                  ],
                                  "verification": "Liste e explique corretamente as 4 classes de Flynn e fórmulas de speedup/eficiência com exemplos numéricos simples.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Introduction to Parallel Computing' de Grama et al. (cap. 4-5)",
                                    "Documentação NAS Parallel Benchmarks",
                                    "Notebook Jupyter com fórmulas"
                                  ],
                                  "tips": "Use diagramas para visualizar Flynn; memorize fórmulas com exemplos pequenos (p=4, T1=100, Tp=30).",
                                  "learningObjective": "Dominar definições teóricas e fórmulas chave para métricas de desempenho paralelo.",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Ignorar overhead de comunicação em Flynn MIMD"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Coletar e Preparar Dados de Benchmarks",
                                  "subSteps": [
                                    "Selecione um benchmark padrão (ex: HPL, STREAM para MIMD).",
                                    "Execute benchmark sequencial (T_1) em máquina single-core.",
                                    "Execute em configurações paralelas (ex: 4, 8, 16 cores) medindo T_p total e tempos de comunicação.",
                                    "Registre dados em tabela: p, T_1, T_p, tempo comm, flops.",
                                    "Valide dados removendo outliers e normalizando."
                                  ],
                                  "verification": "Crie uma tabela com pelo menos 3 configurações paralelas e T_1, confirmando T_p < T_1 para speedup >1.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas: MPI/OpenMP, cluster ou AWS EC2",
                                    "Benchmarks: HPLinpack, NAS PB",
                                    "Planilha Excel/Google Sheets"
                                  ],
                                  "tips": "Use slurm ou mpirun para execuções; rode múltiplas vezes para média.",
                                  "learningObjective": "Preparar dataset realista de benchmarks para cálculos precisos.",
                                  "commonMistakes": [
                                    "Não medir tempo de comunicação separadamente",
                                    "Executar em hardware inconsistente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Métricas Básicas: Speedup e Eficiência",
                                  "subSteps": [
                                    "Calcule speedup para cada p: S_p = T_1 / T_p.",
                                    "Calcule eficiência: E_p = S_p / p, expressando em %.",
                                    "Plote curvas S_p vs p e E_p vs p.",
                                    "Analise escalabilidade: superlinear (>p) ou sublinear.",
                                    "Compare com baseline teórico (Gustafson ou Amdahl)."
                                  ],
                                  "verification": "Produza plot com speedup=8 para p=16 (80% eficiente) e eficiência decrescente.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python/Matplotlib/Pandas para plots",
                                    "Dados do Step 2"
                                  ],
                                  "tips": "Use log-scale para plots; verifique S_p <= p sempre.",
                                  "learningObjective": "Aplicar fórmulas para quantificar desempenho paralelo básico.",
                                  "commonMistakes": [
                                    "Dividir errado (Tp/T1 em vez de T1/Tp)",
                                    "Ignorar p na eficiência"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular Métricas Avançadas e Relacionar com Modelos",
                                  "subSteps": [
                                    "Calcule isoeficiência: W = K * p^α (para modelo dado).",
                                    "Estime tempo de comunicação: T_comm = volume * g + latency.",
                                    "Relacione com Flynn: ex. SIMD tem low comm, MIMD high.",
                                    "Compare com modelos paralelos: BSP vs logP para seu benchmark.",
                                    "Gere relatório integrando todas métricas."
                                  ],
                                  "verification": "Calcule isoeficiência para α=1.2, K=10^6 e explique relação com MIMD.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Paper 'Isoefficiency' de Grama",
                                    "Ferramentas: Python SciPy para fits"
                                  ],
                                  "tips": "Ajuste α empiricamente do plot E_p vs W.",
                                  "learningObjective": "Integrar métricas avançadas com taxonomia e modelos para análise completa.",
                                  "commonMistakes": [
                                    "Confundir isoeficiência com eficiência",
                                    "Não relacionar comm com modelo específico"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar e Validar Resultados Completos",
                                  "subSteps": [
                                    "Sintetize todos cálculos em dashboard.",
                                    "Identifique gargalos (ex: comm >50% T_p indica MIMD poor scaling).",
                                    "Compare com literatura (ex: TOP500 HPL efficiencies).",
                                    "Teste sensibilidade variando p ou problema size.",
                                    "Documente insights relacionando a Flynn/modelos."
                                  ],
                                  "verification": "Relatório com plots, tabelas e conclusão: 'Speedup 12x em MIMD com 70% eff devido low comm'.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Tableau/PowerBI ou Matplotlib dashboards",
                                    "Referências TOP500.org"
                                  ],
                                  "tips": "Foque em storytelling: problema -> métricas -> insights.",
                                  "learningObjective": "Validar e interpretar métricas em contexto teórico-prático.",
                                  "commonMistakes": [
                                    "Overclaim superlinear sem prova",
                                    "Ignorar size-up em benchmarks"
                                  ]
                                }
                              ],
                              "practicalExample": "Em benchmark HPL (High-Performance Linpack, MIMD Flynn), T_1=1000s para n=10k em 1 core; T_p=80s para p=16 cores com T_comm=15s. Calcule: S_16=12.5, E_16=78%, isoeficiência W~p^{1.1}, validando escalabilidade BSP.",
                              "finalVerifications": [
                                "Calcule speedup corretamente para dados dados (erro <1%).",
                                "Explique queda de eficiência >20% devido comm.",
                                "Identifique classe Flynn correta do benchmark (ex: MIMD).",
                                "Estime T_comm corretamente de traces.",
                                "Relacione métricas a modelo paralelo (ex: logP params).",
                                "Gere plot escalabilidade com interpretação.",
                                "",
                                "Valide isoeficiência com fit linear log-log."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica em todos cálculos (100% fórmulas corretas).",
                                "Profundidade conceitual: explicações claras de Flynn/modelos (80%+ cobertura).",
                                "Qualidade de plots/tabelas: legíveis, anotados (rubrica visual).",
                                "Análise de gargalos: identifica 2+ causas corretas.",
                                "Relatório estruturado: intro-métodos-resultados-conclusão.",
                                "Aplicação prática: exemplo executável e reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear (HPL resolve Ax=b), análise assintótica O(p^α).",
                                "Estatística: Análise de variância em benchmarks repetidos, regressão para isoeficiência.",
                                "Engenharia de Software: Otimização de código paralelo (OpenMP/MPI).",
                                "Arquitetura de Computadores: Memória hierárquica impactando comm.",
                                "Ciência de Dados: Visualização e dashboards de performance."
                              ],
                              "realWorldApplication": "Otimizar aplicações HPC em supercomputadores (ex: tuning HPL para TOP500), dimensionar clusters cloud (AWS/Azure) minimizando custo via eficiência, ou avaliar aceleração GPU/TPU em ML training relacionando MIMD com isoeficiência."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.5.1.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.5.1.2.3",
                            "name": "Comparar desempenhos em plataformas heterogêneas",
                            "description": "Executar benchmarks em plataformas multicores, GPUs ou nuvem (ex: AWS ParallelCluster), analisando impactos de linguagens como OpenMP em aceleradores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambientes de Plataformas Heterogêneas",
                                  "subSteps": [
                                    "Instalar software base: compiladores (GCC com suporte OpenMP), CUDA para GPUs, e SDKs de nuvem como AWS CLI.",
                                    "Configurar máquina local multi-core (ex: Intel i7 com 8 cores), GPU (ex: NVIDIA RTX), e instância AWS ParallelCluster.",
                                    "Testar conectividade e alocação de recursos em cada plataforma (CPU, GPU, nuvem).",
                                    "Criar scripts de setup automatizados para reproducibilidade.",
                                    "Verificar detecção de hardware via comandos como nproc, nvidia-smi e AWS status."
                                  ],
                                  "verification": "Executar comandos de diagnóstico em cada plataforma e confirmar saída sem erros.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Máquina local com Linux, NVIDIA GPU, AWS account gratuito, AWS ParallelCluster docs"
                                  ],
                                  "tips": "Use Docker containers para isolar ambientes e facilitar migração entre plataformas.",
                                  "learningObjective": "Entender e preparar infraestruturas heterogêneas para benchmarks paralelos.",
                                  "commonMistakes": [
                                    "Ignorar dependências de drivers GPU",
                                    "Não configurar chaves SSH para nuvem",
                                    "Subestimar custos AWS"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Desenvolver Código de Benchmark com OpenMP",
                                  "subSteps": [
                                    "Implementar benchmark simples: multiplicação de matrizes usando OpenMP para paralelização.",
                                    "Adicionar pragmas OpenMP para loops paralelos e redução de dados.",
                                    "Incluir medição de tempo com omp_get_wtime() e contadores de flops.",
                                    "Compilar com flags -fopenmp e -O3 para otimização.",
                                    "Testar serial vs paralelo localmente para validação inicial."
                                  ],
                                  "verification": "Compilar e rodar código localmente, obtendo speedup >1 em multi-core.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Editor de código (VSCode), GCC 9+, exemplos OpenMP da Intel docs"
                                  ],
                                  "tips": "Comece com matrizes pequenas (N=1024) para debug rápido antes de escalar.",
                                  "learningObjective": "Criar benchmarks portáteis que explorem paralelismo OpenMP em hardware variado.",
                                  "commonMistakes": [
                                    "Race conditions em atualizações compartilhadas",
                                    "Não normalizar tamanhos de input",
                                    "Omitir aquecimento de cache"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar Benchmarks nas Plataformas",
                                  "subSteps": [
                                    "Rodar benchmark 10x em CPU multi-core, registrando tempos médios e desvios.",
                                    "Executar em GPU com offload OpenMP (se suportado) ou equivalente CUDA, coletando métricas.",
                                    "Deploy no AWS ParallelCluster: submit job via Slurm, monitorar com sacct.",
                                    "Variar configurações: threads=cores, batch sizes, para múltiplos runs.",
                                    "Registrar uso de recursos (CPU%, GPU util, network I/O)."
                                  ],
                                  "verification": "Gerar log com resultados de pelo menos 3 plataformas, sem falhas de execução.",
                                  "estimatedTime": "5 horas",
                                  "materials": [
                                    "AWS ParallelCluster AMI, Slurm scheduler, scripts de submissão"
                                  ],
                                  "tips": "Use --export=OMP_NUM_THREADS=8 para controlar paralelismo explicitamente.",
                                  "learningObjective": "Executar experimentos controlados em hardware heterogêneo.",
                                  "commonMistakes": [
                                    "Não repetir runs para estatística",
                                    "Ignorar overhead de transferência de dados para GPU/nuvem",
                                    "Exceder limites gratuitos AWS"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Coletar, Visualizar e Comparar Dados de Performance",
                                  "subSteps": [
                                    "Exportar dados para CSV: GFLOPS, tempo, speedup por plataforma.",
                                    "Usar Python/Pandas para análise estatística (média, std dev).",
                                    "Plotar gráficos com Matplotlib: bar charts de GFLOPS, roofline model.",
                                    "Calcular métricas: speedup relativo (CPU baseline), eficiência paralela.",
                                    "Documentar impactos: ex. OpenMP em GPU vs CPU, latência nuvem."
                                  ],
                                  "verification": "Produzir relatório PDF com gráficos e tabela comparativa.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Python 3+, Pandas, Matplotlib, Jupyter Notebook"
                                  ],
                                  "tips": "Normalise por flops teóricos para comparação justa entre arquiteturas.",
                                  "learningObjective": "Analisar quantitativamente diferenças de performance em plataformas heterogêneas.",
                                  "commonMistakes": [
                                    "Escalas erradas em plots",
                                    "Confundir throughput com latência",
                                    "Não considerar variância"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar Resultados e Otimizar",
                                  "subSteps": [
                                    "Identificar gargalos: bottleneck de memória em GPU, escalabilidade em nuvem.",
                                    "Comparar impactos OpenMP: overhead em small data vs gains em large.",
                                    "Propor otimizações: tiling para cache, hybrid MPI+OpenMP para cluster.",
                                    "Testar uma otimização e re-benchmark.",
                                    "Escrever conclusão com recomendações por workload."
                                  ],
                                  "verification": "Relatório final com insights acionáveis e pelo menos uma otimização validada.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Relatório template LaTeX/Markdown, perf tools como VTune/NSight"
                                  ],
                                  "tips": "Use roofline model para prever limites teóricos.",
                                  "learningObjective": "Derivar insights práticos de comparações de performance.",
                                  "commonMistakes": [
                                    "Atribuir causalidade sem controles",
                                    "Ignorar power/ custo em análises"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um benchmark de multiplicação de matrizes 4096x4096 com OpenMP. Rode em: (1) CPU 8-core local (GFLOPS ~50), (2) GPU RTX 3060 (GFLOPS ~200 com offload), (3) AWS c5.4xlarge cluster (GFLOPS ~150). Compare: GPU excels em compute-intensive, mas nuvem vence em escalabilidade >16 cores.",
                              "finalVerifications": [
                                "Relatório gerado com dados de 3+ plataformas e gráficos comparativos.",
                                "Speedup calculado corretamente (ex: GPU 4x vs CPU).",
                                "Gargalos identificados com evidências métricas.",
                                "Recomendações platform-specific justificadas.",
                                "Código e scripts reproduzíveis em repo GitHub.",
                                "Análise de custo-benefício para nuvem incluída."
                              ],
                              "assessmentCriteria": [
                                "Precisão na coleta de métricas (erro <5%).",
                                "Qualidade de visualizações (claras, legíveis, informativas).",
                                "Profundidade da análise (quantitativa + qualitativa).",
                                "Reprodutibilidade do experimento (scripts funcionais).",
                                "Insights originais sobre impactos OpenMP.",
                                "Documentação completa e profissional."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e análise numérica para flops.",
                                "Engenharia de Software: Portabilidade e DevOps com containers.",
                                "Cloud Computing: Gerenciamento de clusters e orquestração.",
                                "Física/Engenharia: Modelos de performance (roofline, Amdahl).",
                                "Gestão de Projetos: Controle de custos e escalabilidade."
                              ],
                              "realWorldApplication": "Otimizar aplicações HPC como simulações climáticas ou ML training, escolhendo plataformas custo-efetivas (ex: migrar de GPU local para AWS para workloads >TB), reduzindo tempo de computação em 50-80% em data centers."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.5.1.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.5.1.3",
                        "name": "Integração de Profilers e Benchmarks em Estudos de Caso",
                        "description": "Aplicação combinada de ferramentas para avaliar aplicações reais, como simulações científicas, integrando análise com bibliografia de referência (Grama, Pacheco).",
                        "specificSkills": [
                          {
                            "id": "10.1.5.5.1.3.1",
                            "name": "Aplicar ferramentas em um estudo de caso paralelo",
                            "description": "Usar profiler e benchmark em uma aplicação de decomposição de domínio (ex: matrizes ou N-body), medindo desempenho em memória compartilhada vs. distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o Estudo de Caso Sequencial",
                                  "subSteps": [
                                    "Selecione o problema de decomposição de domínio: multiplicação de matrizes NxN (ex: N=2048).",
                                    "Implemente o código sequencial em C++ para multiplicar duas matrizes e verificar corretude.",
                                    "Teste com tamanhos variados e meça tempo baseline usando std::chrono.",
                                    "Gere saída com tempo de execução e valide resultado contra implementação conhecida.",
                                    "Documente o código com comentários sobre complexidade O(N^3)."
                                  ],
                                  "verification": "Código compila sem erros, executa corretamente e produz tempo baseline preciso (erro <1%).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Compilador g++ com suporte C++11+, editor VSCode ou CLion, terminal para testes.",
                                  "tips": "Use alocação dinâmica com std::vector para matrizes grandes e evite cache misses alinhando dados.",
                                  "learningObjective": "Estabelecer baseline sequencial para comparação futura em cenários paralelos.",
                                  "commonMistakes": [
                                    "Índices de matriz off-by-one levando a resultados incorretos.",
                                    "Não liberar memória causando vazamentos.",
                                    "Uso de matrizes pequenas que mascaram overheads paralelos."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Versão Paralela com Memória Compartilhada (OpenMP)",
                                  "subSteps": [
                                    "Configure flags de compilação: g++ -fopenmp.",
                                    "Aplique decomposição de domínio em blocos com #pragma omp parallel for para loops de linha/coluna.",
                                    "Adicione cláusulas schedule(dynamic) para balanceamento de carga.",
                                    "Compile e teste corretude comparando com sequencial.",
                                    "Meça speedup inicial com std::chrono em múltiplos threads (2-16)."
                                  ],
                                  "verification": "Resultado idêntico ao sequencial e speedup >1x em múltiplos threads.",
                                  "estimatedTime": "2 horas",
                                  "materials": "g++ com OpenMP, máquina multi-core (4+ núcleos), std::chrono.",
                                  "tips": "Monitore num_threads com omp_get_num_threads() para depuração.",
                                  "learningObjective": "Dominar paralelização shared-memory via decomposição de domínio.",
                                  "commonMistakes": [
                                    "Race conditions em acessos compartilhados sem critical.",
                                    "Sobrecarga de threads excessivos degradando performance.",
                                    "Ignorar alinhamento de dados afetando cache locality."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Instrumentar Profiler e Benchmark na Versão OpenMP",
                                  "subSteps": [
                                    "Instale e configure perf: sudo apt install linux-tools-common linux-tools-generic.",
                                    "Execute benchmark: perf stat -e cycles,instructions,cache-misses ./openmp_app.",
                                    "Colete métricas: tempo total, IPC, cache misses, % de CPU por thread.",
                                    "Gere relatórios com perf report e analise hotspots nos loops.",
                                    "Repita para diferentes N e threads, salvando dados em CSV."
                                  ],
                                  "verification": "Relatório perf gerado com métricas quantificáveis (ex: cycles >1e10 para N=2048).",
                                  "estimatedTime": "2 horas",
                                  "materials": "Ferramenta perf (Linux), OpenMP app compilada com -g para símbolos.",
                                  "tips": "Use perf record -g para call-graph e perf script para análise profunda.",
                                  "learningObjective": "Aplicar profiling para identificar gargalos em memória compartilhada.",
                                  "commonMistakes": [
                                    "Executar sem privilégios root para perf events.",
                                    "Não incluir -g flag perdendo símbolos.",
                                    "Interpretar métricas sem normalizar por workload size."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e Instrumentar Versão Paralela com Memória Distribuída (MPI)",
                                  "subSteps": [
                                    "Instale MPICH: sudo apt install mpich libmpich-dev.",
                                    "Compile com mpicxx e implemente decomposição 2D de domínio com MPI_Scatter/MPI_Gather.",
                                    "Configure ranks para receber blocos de matrizes e computar localmente.",
                                    "Teste corretude com mpirun -np 4 e meça tempo com MPI_Wtime().",
                                    "Aplique perf ou mpiP para profiling distribuído."
                                  ],
                                  "verification": "Resultado correto com speedup em múltiplos nodes/processos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": "MPICH, cluster local ou multi-máquina, mpirun.",
                                  "tips": "Use MPI_Bcast para matrizes de entrada e reduza comunicações com blocos otimizados.",
                                  "learningObjective": "Paralelizar via message-passing com foco em decomposição distribuída.",
                                  "commonMistakes": [
                                    "Deadlocks em MPI_Send/Recv sem tags.",
                                    "Perda de dados em scatters mal dimensionados.",
                                    "Não contabilizar tempo de comunicação separadamente."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Comparar Desempenho e Analisar Resultados",
                                  "subSteps": [
                                    "Colete dados de ambas versões: tempo, cycles, bandwidth, speedup/scalability.",
                                    "Gere gráficos com Python/Matplotlib (tempo vs threads/processos).",
                                    "Analise trade-offs: overhead OpenMP vs latência MPI.",
                                    "Documente insights em relatório: bottlenecks, scaling limits.",
                                    "Proponha otimizações baseadas em profiling (ex: melhor decomposição)."
                                  ],
                                  "verification": "Relatório PDF com tabelas, gráficos e conclusões quantitativas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python + Matplotlib/Pandas, dados CSV de perf/chrono.",
                                  "tips": "Normalize métricas por core/processo para fair comparison.",
                                  "learningObjective": "Interpretar dados de profiler/benchmark para otimização paralela.",
                                  "commonMistakes": [
                                    "Comparar apples-to-oranges (diferentes N ou hardware).",
                                    "Ignorar variância em runs repetidos.",
                                    "Atribuir overheads errados sem evidência de profiling."
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente multiplicação de matrizes 2048x2048 com decomposição em blocos de 64x64. Use OpenMP para 8 threads (shared): meça com perf stat tempo=12s, cache-misses=1e9. Para MPI com 4 ranks (distributed): mpirun -np 4, tempo=18s mas melhor scalability, analise comunicação 20% do tempo total.",
                              "finalVerifications": [
                                "Relatório completo com métricas de profiler/benchmark para ambas arquiteturas.",
                                "Gráficos de speedup e eficiência vs número de threads/processos.",
                                "Resultados validados contra sequencial (erro <1e-6).",
                                "Análise escrita de gargalos identificados (ex: comunicação MPI > cache OpenMP).",
                                "Códigos fonte versionados e reproduzíveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão e completude das medições (métricas cobrem tempo, CPU, memória: 20%).",
                                "Qualidade da implementação paralela (corretude e eficiência: 25%).",
                                "Profundidade da análise de profiling (identifica hotspots corretos: 20%).",
                                "Clareza do relatório e visualizações (gráficos legíveis: 20%).",
                                "Insights acionáveis e comparações quantitativas (15%)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática Computacional: Álgebra linear e decomposição de matrizes.",
                                "Física Computacional: Simulações N-body com domínio distribuído.",
                                "Engenharia de Software: Boas práticas em HPC e versionamento.",
                                "Análise de Dados: Visualização e estatísticas de performance com Python."
                              ],
                              "realWorldApplication": "Otimização de simulações científicas em supercomputadores (ex: modelagem climática com matrizes massivas ou dinâmica molecular N-body), onde profiling guia escalabilidade de shared para distributed memory em clusters como TOP500."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.5.1.1.3",
                              "10.1.5.5.1.2.2"
                            ]
                          },
                          {
                            "id": "10.1.5.5.1.3.2",
                            "name": "Gerar relatórios de avaliação de desempenho",
                            "description": "Compilar resultados de profilers e benchmarks em relatórios com gráficos de speedup e eficiência, propondo otimizações baseadas em livros como 'Introduction to Parallel Computing'.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coletar e Organizar Dados de Profilers e Benchmarks",
                                  "subSteps": [
                                    "Execute profilers (ex: gprof, perf) e benchmarks (ex: HPL, STREAM) no código paralelo.",
                                    "Exporte dados brutos para CSV ou JSON, incluindo tempo de execução, uso de CPU e memória por configuração (número de threads/cores).",
                                    "Limpe dados inconsistentes, removendo outliers e normalizando unidades (ex: segundos para milissegundos).",
                                    "Crie uma tabela estruturada com colunas: Configuração, Tempo Serial, Tempo Paralelo, Recursos Usados.",
                                    "Valide integridade dos dados comparando somas e médias."
                                  ],
                                  "verification": "Tabela de dados organizada e salva em arquivo acessível, sem erros de formatação ou valores nulos.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Ferramentas de profiling (perf, VTune)",
                                    "Benchmarks executáveis",
                                    "Planilha (Excel/Google Sheets) ou Python Pandas",
                                    "Código fonte paralelo testado"
                                  ],
                                  "tips": "Sempre anote metadados como hardware (CPU modelo, RAM) e software (compilador versão) para reproducibilidade.",
                                  "learningObjective": "Dominar coleta e pré-processamento de dados de desempenho para análise precisa.",
                                  "commonMistakes": [
                                    "Ignorar outliers que distorcem médias.",
                                    "Misturar unidades de tempo.",
                                    "Esquecer de registrar configurações de hardware."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Métricas de Desempenho: Speedup e Eficiência",
                                  "subSteps": [
                                    "Calcule speedup: Speedup = Tempo_Serial / Tempo_Paralelo para cada configuração.",
                                    "Calcule eficiência: Eficiência = (Speedup / Número_de_Threads) * 100%.",
                                    "Aplique fórmulas do livro 'Introduction to Parallel Computing' (ex: Amdahl's Law para limites teóricos).",
                                    "Gere tabela de métricas com colunas: Threads, Speedup, Eficiência, Limite Teórico.",
                                    "Compare resultados reais vs. teóricos e anote discrepâncias."
                                  ],
                                  "verification": "Tabela de métricas calculadas corretamente, com fórmulas documentadas e valores coerentes (speedup >1).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Planilha ou script Python (NumPy/Pandas)",
                                    "Livro 'Introduction to Parallel Computing' (capítulos sobre métricas)",
                                    "Dados do Step 1"
                                  ],
                                  "tips": "Use scripts automatizados para cálculos repetitivos; valide com casos conhecidos (ex: speedup ideal linear).",
                                  "learningObjective": "Aplicar fórmulas padrão de paralelismo para quantificar ganhos de desempenho.",
                                  "commonMistakes": [
                                    "Confundir speedup forte vs. fraco.",
                                    "Não considerar overhead de comunicação.",
                                    "Erros aritméticos em divisões por zero."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Criar Gráficos de Speedup e Eficiência",
                                  "subSteps": [
                                    "Selecione ferramentas de visualização (Matplotlib, GNUPlot ou Excel).",
                                    "Gere gráfico de speedup vs. número de threads (linha com limite de Amdahl).",
                                    "Crie gráfico de eficiência vs. threads (barras ou linha decrescente).",
                                    "Adicione rótulos, legendas, títulos e grid para clareza.",
                                    "Exporte gráficos em alta resolução (PNG/SVG) com captions explicativas."
                                  ],
                                  "verification": "Gráficos gerados, legíveis e salvos, mostrando tendências claras (ex: speedup sub-linear).",
                                  "estimatedTime": "1-1.5 horas",
                                  "materials": [
                                    "Python (Matplotlib/Seaborn)",
                                    "Excel ou Tableau",
                                    "Dados métricas do Step 2"
                                  ],
                                  "tips": "Use escalas logarítmicas para speedup em grandes faixas; inclua erro bars se houver múltiplas runs.",
                                  "learningObjective": "Visualizar dados de desempenho para comunicação efetiva de insights.",
                                  "commonMistakes": [
                                    "Eixos invertidos (threads no y-axis).",
                                    "Falta de legendas.",
                                    "Gráficos sobrecarregados sem foco."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Resultados e Propor Otimizações",
                                  "subSteps": [
                                    "Identifique gargalos nos dados (ex: eficiência baixa indica load imbalance).",
                                    "Relacione com conceitos do livro (ex: granulosidade, scheduling).",
                                    "Proponha 3-5 otimizações específicas (ex: ajustar chunk sizes, usar affinity).",
                                    "Estime impacto potencial com cálculos simples (ex: speedup projetado).",
                                    "Priorize otimizações por custo-benefício."
                                  ],
                                  "verification": "Seção de análise com pelo menos 3 propostas justificadas por dados e referências teóricas.",
                                  "estimatedTime": "1.5-2 horas",
                                  "materials": [
                                    "Livro 'Introduction to Parallel Computing'",
                                    "Dados e gráficos anteriores",
                                    "Notas de profiling detalhadas"
                                  ],
                                  "tips": "Use perguntas guiadas: O que explica o platô no speedup? Como mitigar?",
                                  "learningObjective": "Interpretar dados para recomendações acionáveis baseadas em teoria.",
                                  "commonMistakes": [
                                    "Propostas genéricas sem ligação a dados.",
                                    "Ignorar trade-offs (ex: mais threads aumenta cache misses).",
                                    "Falta de referências teóricas."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Compilar e Finalizar o Relatório",
                                  "subSteps": [
                                    "Estruture relatório: Introdução, Metodologia, Resultados (tabelas/gráficos), Análise, Conclusões, Referências.",
                                    "Integre todos elementos com formatação profissional (LaTeX, Markdown ou Word).",
                                    "Adicione sumário executivo e apêndices com dados brutos.",
                                    "Revise por clareza, gramática e consistência.",
                                    "Gere versão PDF e valide hyperlinks/figuras."
                                  ],
                                  "verification": "Relatório completo (5-10 páginas), compilado e sem erros, pronto para apresentação.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Editor LaTeX (Overleaf) ou Google Docs",
                                    "Gráficos e dados de steps anteriores",
                                    "Template de relatório técnico"
                                  ],
                                  "tips": "Siga estrutura IMRaD (Introduction, Methods, Results, and Discussion) para relatórios científicos.",
                                  "learningObjective": "Produzir documentação técnica profissional e persuasiva.",
                                  "commonMistakes": [
                                    "Seções desbalanceadas (resultados longos, análise curta).",
                                    "Figuras sem referência no texto.",
                                    "Falta de sumário."
                                  ]
                                }
                              ],
                              "practicalExample": "Benchmark de multiplicação de matrizes 1000x1000 usando OpenMP: colete tempos para 1-16 threads, calcule speedup (máx 8x), eficiência (cai para 50% em 16 threads), gere gráficos, proponha otimizações como block tiling baseado no livro.",
                              "finalVerifications": [
                                "Relatório inclui tabelas de dados limpos e métricas calculadas corretamente.",
                                "Gráficos de speedup e eficiência são claros e interpretáveis.",
                                "Análise cita pelo menos 2 conceitos do 'Introduction to Parallel Computing'.",
                                "Propostas de otimização são específicas e quantificadas.",
                                "Relatório está formatado profissionalmente com referências.",
                                "Reprodutibilidade: outro pode recriar resultados com metadados fornecidos."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática das métricas (speedup/eficiência sem erros >1%).",
                                "Qualidade visual e legibilidade dos gráficos (rótulos completos).",
                                "Profundidade da análise (ligação dados-teoria-otimizações).",
                                "Clareza e estrutura do relatório (fácil navegação).",
                                "Criatividade e viabilidade das propostas de otimização.",
                                "Uso adequado de referências e terminologia técnica."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Cálculo de médias, desvios e análise de variância em benchmarks.",
                                "Comunicação Técnica: Redação de relatórios e visualizações persuasivas.",
                                "Matemática: Aplicação de leis como Amdahl e Gustafson em modelagem.",
                                "Gestão de Projetos: Documentação de experimentos para equipes de desenvolvimento.",
                                "Design de Software: Identificação de gargalos para refatoração."
                              ],
                              "realWorldApplication": "Em centros de supercomputação como o Argonne National Lab, engenheiros geram relatórios semelhantes para otimizar simulações climáticas ou de IA, reduzindo tempo de execução de dias para horas e economizando custos em hardware caro."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.5.1.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.6",
                "name": "Aplicações e Estudos de Caso",
                "description": "Analisa aplicações práticas da programação paralela por meio de estudos de caso.",
                "totalSkills": 47,
                "atomicTopics": [
                  {
                    "id": "10.1.6.1",
                    "name": "Estudo de Caso: Multiplicação de Matrizes Paralela",
                    "description": "Análise de algoritmos paralelos para multiplicação de matrizes usando decomposição de domínio em memória compartilhada e distribuída.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.1.1",
                        "name": "Decomposição de Domínio em Memória Compartilhada",
                        "description": "Análise do algoritmo paralelo para multiplicação de matrizes utilizando decomposição de domínio em arquiteturas de memória compartilhada, como multicores com OpenMP, focando na divisão das matrizes em blocos e sincronização via exclusão mútua.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.1.1.1",
                            "name": "Identificar a decomposição de domínio para matrizes",
                            "description": "Explicar como dividir as matrizes A, B e C em blocos para distribuição entre threads em memória compartilhada, considerando a taxonomia de Flynn (SIMD/SIMT) e modelos de memória uniforme.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Multiplicação de Matrizes e Paralelismo em Memória Compartilhada",
                                  "subSteps": [
                                    "Estude a multiplicação sequencial de matrizes C = A * B, onde C[i][j] = soma(A[i][k] * B[k][j] para k em 0..n-1).",
                                    "Identifique o loop triplo na implementação sequencial e explique por que ele é paralelizado (independência de i e j).",
                                    "Aprenda sobre threads em memória compartilhada (ex: CUDA/OpenMP), onde threads acessam a mesma memória global.",
                                    "Desenhe um diagrama simples de matrizes A (m x k), B (k x n) e C (m x n) compartilhadas entre múltiplas threads.",
                                    "Discuta limitações de acesso à memória compartilhada, como coalescência e divergência."
                                  ],
                                  "verification": "Crie um diagrama anotado das matrizes e explique verbalmente ou por escrito a independência dos elementos de C.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação CUDA/OpenMP básica",
                                    "Editor de imagens para diagramas (ex: Draw.io)",
                                    "Notebook para anotações"
                                  ],
                                  "tips": [
                                    "Comece com matrizes pequenas (2x2) para visualizar.",
                                    "Use cores para diferenciar threads no diagrama.",
                                    "Revise álgebra linear básica se necessário."
                                  ],
                                  "learningObjective": "Compreender a estrutura da multiplicação de matrizes e o papel da memória compartilhada no paralelismo.",
                                  "commonMistakes": [
                                    "Confundir multiplicação de matrizes com produto elemento a elemento.",
                                    "Ignorar que threads compartilham memória, assumindo cópias locais.",
                                    "Não reconhecer dependências no loop k."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar Taxonomia de Flynn e Conceitos SIMD/SIMT",
                                  "subSteps": [
                                    "Revise a taxonomia de Flynn: SISD, SIMD, MISD, MIMD; foque em SIMD (Single Instruction Multiple Data).",
                                    "Explique SIMD clássico (ex: vetores SSE/AVX) vs. SIMT (Single Instruction Multiple Threads, ex: GPUs).",
                                    "Identifique como SIMT permite execução lockstep em warps/threads, mas com divergência possível.",
                                    "Relacione com decomposição: em SIMD/SIMT, dados devem ser alinhados em blocos para vetores/warps.",
                                    "Pesquise exemplos de como matrizes são processadas em GPUs sob SIMT."
                                  ],
                                  "verification": "Escreva um resumo de 1 parágrafo diferenciando SIMD e SIMT, com exemplos de aplicação em matrizes.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Artigo ou vídeo sobre Taxonomia de Flynn",
                                    "Documentação NVIDIA sobre SIMT",
                                    "Slides ou PDF de arquitetura paralela"
                                  ],
                                  "tips": [
                                    "Use analogias: SIMD como orquestra tocando a mesma nota.",
                                    "Memorize acrônimos com exemplos reais (CPU vs GPU).",
                                    "Assista a um vídeo curto de 5 min sobre warps."
                                  ],
                                  "learningObjective": "Dominar como SIMD/SIMT influencia a divisão de dados em blocos uniformes.",
                                  "commonMistakes": [
                                    "Confundir MIMD com SIMD.",
                                    "Ignorar divergência em SIMT como overhead.",
                                    "Não ligar taxonomia diretamente à decomposição de matrizes."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Compreender Modelos de Memória Uniforme e Decomposição de Domínio",
                                  "subSteps": [
                                    "Defina memória uniforme: todos os processadores/threads veem a mesma visão de memória (UM vs NUMA).",
                                    "Explique decomposição de domínio: dividir o espaço de problema (matrizes) em subdomínios independentes.",
                                    "Para multiplicação de matrizes, identifique decomposições 1D (linha/coluna) vs 2D (blocos).",
                                    "Discuta blocos quadrados/cuboides para balanceamento de carga em memória compartilhada.",
                                    "Calcule tamanhos de blocos considerando número de threads e alinhamento SIMD/SIMT (ex: múltiplos de 32 para warps)."
                                  ],
                                  "verification": "Calcule e desenhe decomposição 2D para matrizes 8x8 com 16 threads.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Calculadora ou Python para simulações",
                                    "Papel e lápis para esboços",
                                    "Referência de livros como 'Programming Massively Parallel Processors'"
                                  ],
                                  "tips": [
                                    "Prefira blocos quadrados para simplicidade.",
                                    "Verifique soma de blocos = matriz original.",
                                    "Considere overhead de sincronização."
                                  ],
                                  "learningObjective": "Aplicar modelos de memória e decomposição para divisão otimizada de matrizes.",
                                  "commonMistakes": [
                                    "Usar decomposição 1D em contextos 2D eficientes.",
                                    "Ignorar alinhamento de memória para SIMD.",
                                    "Desbalancear cargas entre threads."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Decomposição às Matrizes A, B e C para Threads",
                                  "subSteps": [
                                    "Para A (m x k): divida em blocos de linhas (cada thread/bloco processa sub-linhas).",
                                    "Para B (k x n): divida em blocos de colunas (cada thread acessa sub-colunas).",
                                    "Para C (m x n): cada thread computa sub-bloco C[i_block][j_block].",
                                    "Simule distribuição: thread_id = blockIdx * blockDim + threadIdx; mapeie para índices de bloco.",
                                    "Verifique acessos: A row-major, B column-major para coalescência em SIMT."
                                  ],
                                  "verification": "Implemente pseudocódigo ou código CUDA simples para mapear threads a blocos e execute com exemplo pequeno.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Compilador CUDA ou simulador online",
                                    "Exemplo de código de multiplicação de matrizes paralela",
                                    "Debugger visual"
                                  ],
                                  "tips": [
                                    "Use tile sizes como 16x16 para GPUs.",
                                    "Teste com printf para mapear threads.",
                                    "Otimize acessos: A sequencial por thread, B transposta."
                                  ],
                                  "learningObjective": "Identificar e especificar decomposição completa para A, B, C em cenários reais.",
                                  "commonMistakes": [
                                    "Acessar B de forma não-coalescente.",
                                    "Esquecer broadcast de elementos comuns.",
                                    "Não lidar com bordas de blocos."
                                  ]
                                }
                              ],
                              "practicalExample": "Considere matrizes A(4x4), B(4x4), C(4x4) com 4 threads. Divida em blocos 2x2: Thread 0 computa C[0:2][0:2] usando A[0:2][0:4] e B[0:4][0:2]; Thread 1: C[0:2][2:4], etc. Em SIMT (GPU), cada warp processa linhas alinhadas.",
                              "finalVerifications": [
                                "Desenhar corretamente a decomposição de A, B, C em blocos para 16 threads.",
                                "Explicar impacto de SIMT na escolha de tamanhos de blocos.",
                                "Simular execução sem erros de race condition ou acesso inválido.",
                                "Calcular carga balanceada entre threads.",
                                "Identificar otimizações para memória uniforme."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de blocos para A, B, C (100% cobertura).",
                                "Integração correta de SIMD/SIMT na justificativa.",
                                "Demonstração de acessos coalescentes e balanceamento.",
                                "Clareza em diagramas e explicações.",
                                "Capacidade de generalizar para tamanhos arbitrários."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e decomposição de matrizes.",
                                "Arquitetura de Computadores: Modelos de memória e taxonomia de Flynn.",
                                "Engenharia de Software: Otimização de código paralelo.",
                                "Física Computacional: Simulações numéricas em GPUs."
                              ],
                              "realWorldApplication": "Em machine learning (ex: TensorFlow/PyTorch em GPUs), decomposição de domínio otimiza treinamento de redes neurais com multiplicações massivas de matrizes; em simulações científicas (CFD, clima), acelera computações em supercomputadores."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.1.1.2",
                            "name": "Implementar multiplicação paralela com OpenMP",
                            "description": "Desenvolver código em C/C++ usando diretivas OpenMP para paralelizar loops de multiplicação de matrizes com cláusulas #pragma omp parallel for e exclusão mútua para atualizações seguras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente de desenvolvimento OpenMP",
                                  "subSteps": [
                                    "Instale um compilador compatível com OpenMP, como GCC ou Clang.",
                                    "Compile um programa de teste simples com a flag -fopenmp para verificar suporte.",
                                    "Defina variáveis de ambiente como OMP_NUM_THREADS=4 para controlar threads.",
                                    "Crie um template de código C/C++ com inclusão de <omp.h>.",
                                    "Teste a detecção de número de processadores com omp_get_num_procs()."
                                  ],
                                  "verification": "Compilação bem-sucedida de um hello world OpenMP e saída mostrando número de threads.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "GCC/Clang com suporte OpenMP",
                                    "Editor de código (VS Code ou similar)",
                                    "Terminal"
                                  ],
                                  "tips": "Use 'export OMP_NUM_THREADS=4' no Linux/Mac para testes consistentes.",
                                  "learningObjective": "Entender pré-requisitos e configuração básica para programação OpenMP.",
                                  "commonMistakes": [
                                    "Esquecer flag -fopenmp na compilação",
                                    "Não definir OMP_NUM_THREADS levando a uso de 1 thread"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar multiplicação de matrizes sequencial",
                                  "subSteps": [
                                    "Declare matrizes A (m x k), B (k x n) e C (m x n) com alocação dinâmica usando malloc.",
                                    "Implemente o loop triplo padrão: for i, for j, for k com C[i][j] += A[i][k] * B[k][j].",
                                    "Inicialize C com zeros antes da multiplicação.",
                                    "Adicione função para imprimir matrizes e verificar resultados.",
                                    "Teste com matrizes pequenas (ex: 100x100) e valide contra resultados manuais."
                                  ],
                                  "verification": "Programa sequencial produz C correta sem erros de segmentação.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código template do Step 1",
                                    "Calculadora ou MATLAB para validação manual"
                                  ],
                                  "tips": "Use srand(time(NULL)) para inicializar A e B com valores randômicos reproduzíveis.",
                                  "learningObjective": "Dominar implementação sequencial de multiplicação de matrizes como baseline.",
                                  "commonMistakes": [
                                    "Índices invertidos em B[k][j]",
                                    "Não zerar C levando a lixo acumulado"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Paralelizar o loop externo com #pragma omp parallel for",
                                  "subSteps": [
                                    "Adicione #pragma omp parallel for antes do loop for(i=0; i<m; i++) .",
                                    "Mantenha os loops internos j e k sequenciais dentro do i.",
                                    "Compile com -fopenmp e execute com diferentes OMP_NUM_THREADS.",
                                    "Meça tempo sequencial vs paralelo usando clock() ou omp_get_wtime().",
                                    "Verifique se resultados são idênticos ao sequencial."
                                  ],
                                  "verification": "Execução paralela produz mesma C que sequencial e speedup >1 em multicore.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código sequencial do Step 2",
                                    "Máquina com >=4 cores"
                                  ],
                                  "tips": "Use schedule(static) inicialmente para balanceamento simples.",
                                  "learningObjective": "Aplicar paralelismo de domínio em loops independentes sem race conditions.",
                                  "commonMistakes": [
                                    "Paralelizar loop errado (k interno causa dependências)",
                                    "Ignorar overhead em matrizes pequenas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar exclusão mútua para atualizações seguras",
                                  "subSteps": [
                                    "Modifique para um cenário com redução compartilhada (ex: soma global de elementos de C).",
                                    "Use #pragma omp parallel for reduction(+:sum) ou critical para updates em variável compartilhada.",
                                    "Implemente seção critical: #pragma omp critical { sum += C[i][j]; } após inner loops.",
                                    "Teste com múltiplas execuções para detectar inconsistências sem mutex.",
                                    "Compare performance com e sem sincronização."
                                  ],
                                  "verification": "Valor de sum é consistente em todas runs paralelas, igual ao sequencial.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Código paralelo do Step 3",
                                    "Profiler como gprof para overhead"
                                  ],
                                  "tips": "Prefira reduction sobre critical para melhor performance.",
                                  "learningObjective": "Gerenciar race conditions com exclusão mútua em cenários compartilhados.",
                                  "commonMistakes": [
                                    "Usar critical no loop inteiro degradando speedup",
                                    "Esquecer flush() em variáveis voláteis"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimizar, testar e avaliar performance",
                                  "subSteps": [
                                    "Adicione cláusulas como collapse(2) para loops i-j se m e n similares.",
                                    "Teste com matrizes maiores (500x500+) e varie OMP_NUM_THREADS até num_procs.",
                                    "Meça speedup, efficiency e plota gráfico simples com tempo vs threads.",
                                    "Corrija falsos compartilhamentos alinhando matrizes com omp_align.",
                                    "Documente código com comentários sobre diretivas usadas."
                                  ],
                                  "verification": "Speedup linear até limite hardware, sem perda de precisão numérica.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código completo",
                                    "GNUPlot ou Excel para gráficos",
                                    "htop para monitorar CPU"
                                  ],
                                  "tips": "Use private(i,j,k) explicitamente se dúvidas sobre escopo.",
                                  "learningObjective": "Avaliar e otimizar código OpenMP para aplicações reais.",
                                  "commonMistakes": [
                                    "Testar só com matrizes pequenas mascarando overhead",
                                    "Ignorar cache effects em tamanhos não múltiplos de linha cache"
                                  ]
                                }
                              ],
                              "practicalExample": "Em processamento de imagens, paralelize convolução 2D (análoga a matmul) para filtros como blur em fotos 4K, reduzindo tempo de 10s sequencial para 2s em 4 cores.",
                              "finalVerifications": [
                                "Código compila e executa sem warnings OpenMP.",
                                "Resultados idênticos sequencial vs paralelo para múltiplas seeds.",
                                "Speedup >= 2x em 4 threads para matrizes 512x512.",
                                "Nenhuma race condition detectada em 100 runs com soma compartilhada.",
                                "Eficiência >70% (speedup/threads).",
                                "Memória alocada/desalocada corretamente sem leaks."
                              ],
                              "assessmentCriteria": [
                                "Correção: Matriz C exata (erro <1e-10).",
                                "Performance: Speedup mensurável e otimizado.",
                                "Robustez: Funciona em diferentes tamanhos e threads.",
                                "Código limpo: Comentários, indentação e cláusulas apropriadas.",
                                "Uso de sincronização: Mutex/reduction apenas onde necessário.",
                                "Escalabilidade: Bom comportamento até max threads."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e decomposição de loops.",
                                "Arquitetura de Computadores: Memória compartilhada e multicore.",
                                "Análise de Algoritmos: Complexidade O(n^3) e paralelismo.",
                                "Engenharia de Software: Testes unitários e profiling."
                              ],
                              "realWorldApplication": "Aceleração de multiplicações de matrizes em machine learning (treinamento de redes neurais no TensorFlow/PyTorch backend), simulações físicas (CFD em engenharia) e processamento de big data (Spark MLlib)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.1.1.3",
                            "name": "Analisar overheads em memória compartilhada",
                            "description": "Identificar e quantificar overheads como contenção de cache, falsos compartilhamentos e sincronização em implementações paralelas de multiplicação de matrizes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Teóricos de Overheads em Memória Compartilhada",
                                  "subSteps": [
                                    "Estude a definição de contenção de cache: competição por linhas de cache entre threads.",
                                    "Analise falsos compartilhamentos: quando dados não compartilhados são mapeados na mesma linha de cache.",
                                    "Revise mecanismos de sincronização em OpenMP, como #pragma omp critical e locks, e seus custos.",
                                    "Compare overheads com baseline sequencial para contextualizar impactos na performance.",
                                    "Identifique padrões comuns em loops paralelos de multiplicação de matrizes que geram esses overheads."
                                  ],
                                  "verification": "Resuma em um diagrama os três overheads principais e seus mecanismos em um código de exemplo simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação OpenMP, slides ou artigos sobre cache coherence (ex: Intel VTune guide), editor de texto para anotações.",
                                  "tips": "Use analogias como 'trânsito em rodovia' para contenção de cache para fixar conceitos.",
                                  "learningObjective": "Dominar definições e causas raiz dos overheads para reconhecimento intuitivo.",
                                  "commonMistakes": "Confundir falsos compartilhamentos com compartilhamentos verdadeiros; ignorar granularidade de locks."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente e Código Base para Multiplicação de Matrizes Paralela",
                                  "subSteps": [
                                    "Compile e execute um código OpenMP padrão para multiplicação de matrizes NxN (N=1024+).",
                                    "Adicione pragmas paralelos inadequados para induzir overheads: omp for sem schedule(dynamic).",
                                    "Implemente sincronização básica com omp critical em atualizações de C[i][j].",
                                    "Gere matrizes aleatórias e meça tempo sequencial vs. paralelo com múltiplos threads.",
                                    "Prepare scripts para variar número de threads (2,4,8,16)."
                                  ],
                                  "verification": "Execute o código e confirme speedup <1 em alguns cenários, indicando overheads.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Compilador GCC com suporte OpenMP (g++ -fopenmp), matrizes de teste em C (ex: código GitHub para matrix_multiply_openmp.c), terminal Linux.",
                                  "tips": "Use export OMP_NUM_THREADS=4 para controlar threads sem recompilar.",
                                  "learningObjective": "Configurar um benchmark reprodutível que manifeste overheads reais.",
                                  "commonMistakes": "Usar matrizes muito pequenas (N<512), mascarando overheads por tempo de computação baixo."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Instrumentar e Medir Overheads Específicos",
                                  "subSteps": [
                                    "Use omp_get_wtime() para medir tempo total e seções críticas.",
                                    "Aplique ferramentas como likwid ou perf para perfis de cache misses e contenda.",
                                    "Meça falsos compartilhamentos alinhando dados inadequados (ex: arrays coluna-major em row-major loops).",
                                    "Registre estatísticas de sincronização: número de aquisições de locks e esperas.",
                                    "Execute múltiplas runs (10+) e compute médias/desvios para dados estatísticos robustos."
                                  ],
                                  "verification": "Gere tabela com métricas: cache misses, lock waits, antes/depois de uma otimização simples.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Ferramentas likwid-perfctr ou perf (sudo apt install likwid), código instrumentado, planilhas Excel/Google Sheets para dados.",
                                  "tips": " likwid-pin -c para fixar threads em cores, reduzindo ruído de migração.",
                                  "learningObjective": "Coletar dados empíricos quantificáveis de cada overhead.",
                                  "commonMistakes": "Não normalizar por tamanho de matriz; ignorar variabilidade entre runs."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e Quantificar Impactos dos Overheads",
                                  "subSteps": [
                                    "Calcule overhead como (tempo_paralelo / (threads * tempo_sequencial)) - 1.",
                                    "Compare métricas: % de tempo em sincronização vs. computação útil.",
                                    "Identifique gargalos dominantes plotando gráficos (tempo vs. threads).",
                                    "Teste mitigações: padding para falsos compartilhamentos, schedule(dynamic) para contenção.",
                                    "Documente conclusões em relatório com gráficos e recomendações."
                                  ],
                                  "verification": "Produza relatório de 1 página com quantificações (ex: 'contenção causa 30% overhead').",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python/Matplotlib ou Gnuplot para plots, relatório template em Markdown.",
                                  "tips": "Amdahl's Law para estimar limites teóricos de speedup.",
                                  "learningObjective": "Interpretar dados para quantificar e priorizar overheads.",
                                  "commonMistakes": "Atribuir todos slowdowns a um overhead sem evidência; esquecer baseline otimizada."
                                }
                              ],
                              "practicalExample": "Em um código OpenMP para C = A * B (N=2048), use #pragma omp for sem schedule em loop externo row-wise: threads disputam cache L2 ao acessar A[i][k], causando contenção (misses >50%). Adicione omp critical em C[i][j] += : lock waits somam 20% tempo. Padding de 64 bytes em A resolve falsos compartilhamentos, reduzindo misses em 40%.",
                              "finalVerifications": [
                                "Identifica contenção de cache em perfil likwid (eventos LLC_M_REPL).",
                                "Quantifica falsos compartilhamentos comparando cache misses com/sem padding.",
                                "Medições mostram >10% tempo em sincronização com locks desnecessários.",
                                "Speedup vs. threads revela platô devido a overheads dominantes.",
                                "Relatório inclui gráficos de tempo total e breakdown de overheads.",
                                "Sugere 2+ otimizações baseadas em análise (ex: private clauses)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de causas de cada overhead (80%+ acerto).",
                                "Dados quantitativos robustos (médias de 10 runs, desvios <5%).",
                                "Análise inclui comparação pré/pós-mitigação com % melhorias.",
                                "Uso correto de ferramentas de profiling sem erros de configuração.",
                                "Relatório claro com visualizações e conclusões acionáveis.",
                                "Demonstra compreensão de trade-offs (ex: locks vs. atomic)."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Coerência de cache (MESI protocol).",
                                "Algoritmos e Estruturas de Dados: Otimização de acesso a matrizes (tiling).",
                                "Sistemas Operacionais: Gerenciamento de threads e escalonamento.",
                                "Matemática Computacional: Análise de complexidade em paralelo (Amdahl/Gustafson)."
                              ],
                              "realWorldApplication": "Em simulações científicas HPC (ex: modelagem climática no Lawrence Livermore Lab), análise de overheads em OpenMP otimiza multiplicações de matrizes em GPUs/CPU clusters, reduzindo tempo de simulação de horas para minutos e economizando energia em supercomputadores."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.1.2",
                        "name": "Decomposição de Domínio em Memória Distribuída",
                        "description": "Estudo do algoritmo de multiplicação de matrizes em sistemas de memória distribuída, utilizando troca de mensagens (MPI) para comunicação entre processos em plataformas como clusters ou nuvem.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.1.2.1",
                            "name": "Mapear decomposição para topologias distribuídas",
                            "description": "Descrever como alocar blocos de matrizes a processos em grade 2D, considerando comunicação ponto-a-ponto (MPI_Send/MPI_Recv) para somas parciais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir a Topologia de Grade 2D em MPI",
                                  "subSteps": [
                                    "Instale e configure um ambiente MPI (ex: OpenMPI ou MPICH).",
                                    "Crie um comunicador Cartesiano 2D usando MPI_Cart_create com dimensões PxP (ex: 4x4 processos).",
                                    "Obtenha coordenadas (i,j) de cada processo com MPI_Cart_coords.",
                                    "Identifique vizinhos (norte, sul, leste, oeste) usando MPI_Cart_shift.",
                                    "Teste a topologia imprimindo coordenadas e ranks em um programa simples."
                                  ],
                                  "verification": "Execute mpirun -np 16 e verifique se cada processo imprime coordenadas corretas e vizinhos válidos sem erros de MPI.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Compilador MPI (mpicc), terminal com mpirun, documentação MPI (mpi4py ou man pages).",
                                  "tips": "Escolha dimensões quadradas (sqrt(N) inteiro) para simplificar; use MPI_COMM_WORLD como base.",
                                  "learningObjective": "Compreender e implementar topologias Cartesianas 2D para mapear processos em grades.",
                                  "commonMistakes": "Esquecer de definir MPI_COMM_NULL para processos extras; dimensões não divisíveis por número de processos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular e Mapear Blocos de Matrizes à Grade 2D",
                                  "subSteps": [
                                    "Defina dimensões globais das matrizes N x N (ex: N múltiplo de P).",
                                    "Calcule tamanho de bloco local: block_size = N / P para linhas e colunas.",
                                    "Mapeie posição global (i,j) de um elemento para processo (proc_row = i / block_size, proc_col = j / block_size).",
                                    "Atribua blocos de A (linhas fixas, colunas distribuídas) e B (linhas distribuídas, colunas fixas) aos processos.",
                                    "Crie arrays locais para armazenar blocos usando MPI_Dims_create para otimizar."
                                  ],
                                  "verification": "Imprima tamanhos de blocos e posições mapeadas; confirme que todos os elementos são cobertos sem sobreposição.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Editor de código (VSCode com MPI extension), debugger MPI (ex: TotalView ou printf).",
                                  "tips": "Use assert para verificar N % P == 0; visualize grade em papel para matriz 8x8 com P=4.",
                                  "learningObjective": "Mapear decomposição de domínio de matrizes em blocos para processos em grade 2D.",
                                  "commonMistakes": "Off-by-one em cálculos de índices globais; confundir alocação de A vs B."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Alocar e Distribuir Dados Iniciais nas Matrizes",
                                  "subSteps": [
                                    "Inicialize matrizes globais A e B no processo raiz (rank 0).",
                                    "Distribua blocos usando MPI_Scatterv ou loops com MPI_Send para cada processo.",
                                    "Alocar memória local para submatrizes A_local[PxP], B_local[PxP], C_local[PxP].",
                                    "Preencha dados de teste (ex: A[i][j]=i+j) e verifique recebimento local.",
                                    "Sincronize com MPI_Barrier para garantir distribuição completa."
                                  ],
                                  "verification": "Cada processo imprime seu bloco local; raiz verifica soma global vs soma de locais.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Matrizes de teste geradas por script Python (numpy para validação serial).",
                                  "tips": "Use contadores para rastrear envios; prefira MPI_Sendrecv para distribuição balanceada.",
                                  "learningObjective": "Implementar alocação distribuída de dados em memória distribuída.",
                                  "commonMistakes": "Não sincronizar após distribuição; tamanhos incorretos em MPI_Type_vector."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar Comunicação Ponto-a-Ponto para Somas Parciais",
                                  "subSteps": [
                                    "Configure shifts iniciais para alinhar A e B (ex: Cannon's algorithm: shift A por colunas, B por linhas).",
                                    "Em loop de P iterações: compute C_local += A_local * B_local; shift A left/up, B up/left com MPI_Send/MPI_Recv.",
                                    "Use MPI_Cart_shift para vizinhos; acumule somas parciais em C_local.",
                                    "Após loops, reduza C_local para C global com MPI_Reduce ou allgather.",
                                    "Teste com matrizes pequenas, comparando com versão serial."
                                  ],
                                  "verification": "Resultado final MPI == multiplicação serial; tempo de execução escalável com np.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Benchmark tool (ex: MPI_Wtime), validador serial em C/Python.",
                                  "tips": "Non-blocking MPI_Isend/Irecv para overlap; visualize shifts em grade 2x2.",
                                  "learningObjective": "Usar MPI_Send/Recv em topologias para computação paralela de multiplicação.",
                                  "commonMistakes": "Deadlocks em Send/Recv sem tags corretas; shifts errados quebram alinhamento."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Otimizar o Mapeamento Completo",
                                  "subSteps": [
                                    "Colete todos C_local em raiz com MPI_Gather.",
                                    "Compare com numpy.dot(A,B) para precisão (erro < 1e-10).",
                                    "Meça speedup e eficiência variando N e P.",
                                    "Otimize: use MPI_Wtime para perfis, reduza comunicações com Sendrecv.",
                                    "Documente código com comentários sobre mapeamento."
                                  ],
                                  "verification": "Testes passam para N=64,128 com P=16; speedup > 8x.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Scripts de teste automatizados, perf (gprof ou TAU).",
                                  "tips": "Salve saídas em arquivos por rank; rode em cluster se possível.",
                                  "learningObjective": "Verificar corretude e performance do mapeamento distribuído.",
                                  "commonMistakes": "Floating-point acumulação sem inicialização zero; ignorar overhead de comunicação."
                                }
                              ],
                              "practicalExample": "Para matrizes A e B 8x8 em grade 4 processos (2x2): Processo (0,0) recebe A[0:4,0:4] e B[0:4,0:4]; após shifts e multiplicaçoes parciais, C[0:4,0:4] é computado localmente e coletado corretamente, resultando em C serial exata.",
                              "finalVerifications": [
                                "Topologia 2D criada sem erros, coordenadas corretas impressas.",
                                "Blocos mapeados cobrem matriz global sem lacunas/sobreposições.",
                                "Dados distribuídos e recebidos corretamente em todos processos.",
                                "Comunicação MPI_Send/Recv completa shifts sem deadlocks.",
                                "Resultado final idêntico à multiplicação serial para N até 256.",
                                "Speedup linear observado com aumento de processos."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de blocos e mapeamento (100% cobertura).",
                                "Corretude da topologia Cartesian 2D e shifts de vizinhos.",
                                "Eficiência de comunicação (sem busy-waiting ou deadlocks).",
                                "Escalabilidade: speedup > 70% do ideal para P=16.",
                                "Código limpo com comentários e tratamento de erros MPI.",
                                "Validação quantitativa vs serial (erro < 1e-12)."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Decomposição de matrizes e multiplicação.",
                                "Redes de Computadores: Topologias e comunicação ponto-a-ponto.",
                                "Estruturas de Dados: Arrays 2D distribuídos e hashing de ranks.",
                                "Análise de Algoritmos: Complexidade O(N^3/P) com overhead log P."
                              ],
                              "realWorldApplication": "Em simulações científicas como modelagem climática (matrizes grandes em supercomputadores), processamento de big data em HPC clusters, ou treinamento de redes neurais distribuídas onde multiplicações de matrizes densas são gargalos computacionais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.1.2.2",
                            "name": "Implementar com MPI para multiplicação paralela",
                            "description": "Criar programa MPI em C para multiplicação de matrizes NxN, usando MPI_Scatter, MPI_Gather e MPI_Allreduce para distribuição, computação e redução de resultados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e inicializar o programa",
                                  "subSteps": [
                                    "Instalar MPI se necessário (ex: OpenMPI ou MPICH via apt/yum).",
                                    "Criar um arquivo C com includes: #include <mpi.h>, <stdio.h>, <stdlib.h>.",
                                    "Implementar MPI_Init(&argc, &argv); e obter rank/world_size com MPI_Comm_rank e MPI_Comm_size.",
                                    "Definir tamanho N da matriz (ex: 4 para teste) e seed para rand().",
                                    "Verificar se o número de processos divide N para decomposição uniforme."
                                  ],
                                  "verification": "Compilar com 'mpicc -o prog file.c' e executar 'mpirun -np 4 ./prog' sem erros de inicialização.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Editor de texto (VSCode ou vim)",
                                    "Terminal com MPI instalado"
                                  ],
                                  "tips": "Use #pragma omp para evitar warnings se necessário; teste com np=1 primeiro.",
                                  "learningObjective": "Entender inicialização de ambiente distribuído e coleta de informações de processos.",
                                  "commonMistakes": "Esquecer MPI_Init antes de usar funções MPI; não verificar argc/argv."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar matrizes A e B no processo raiz",
                                  "subSteps": [
                                    "No rank 0, alocar matrizes A e B como double A[N][N], B[N][N].",
                                    "Preencher A e B com valores rand() % 10 para teste reproduzível (usar srand(42)).",
                                    "Alocar local_A[N_local][N] e local_C[N_local][N], onde N_local = N / world_size.",
                                    "Imprimir matrizes completas no rank 0 para verificação inicial.",
                                    "Garantir que N seja divisível por world_size para simplificar."
                                  ],
                                  "verification": "Executar e inspecionar output no rank 0 mostrando A e B corretas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código do step 1",
                                    "Calculadora para verificar alocações manuais"
                                  ],
                                  "tips": "Use loops aninhados para alocação dinâmica se N variável; fixe N=4 inicialmente.",
                                  "learningObjective": "Preparar dados globais para distribuição em memória distribuída.",
                                  "commonMistakes": "Alocação errada de local_A (linhas vs colunas); não inicializar srand."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Distribuir dados com MPI_Scatter e MPI_Bcast",
                                  "subSteps": [
                                    "Usar MPI_Scatter para enviar linhas de A do rank 0 para local_A em todos processos (count=N*N_local, MPI_DOUBLE).",
                                    "Broadcast B completa do rank 0 para todos processos com MPI_Bcast(&B[0][0], N*N, MPI_DOUBLE, 0, MPI_COMM_WORLD).",
                                    "Imprimir local_A e B recebidas em cada rank para debug (use rank no printf).",
                                    "Verificar tamanhos: local_A tem N_local linhas, B tem N x N.",
                                    "Adicionar MPI_Barrier para sincronização se necessário."
                                  ],
                                  "verification": "Output mostra local_A diferente por rank e B idêntica em todos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código anterior",
                                    "Documentação MPI_Scatter/Bcast"
                                  ],
                                  "tips": "Scatter envia blocos contíguos; use &A[0][0] como buffer raiz.",
                                  "learningObjective": "Dominar distribuição de dados em decomposição por linhas.",
                                  "commonMistakes": "Tipo de dado errado (int vs double); forget root=0 em Scatter."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Computar multiplicação local das porções",
                                  "subSteps": [
                                    "Para cada i em 0..N_local-1, para cada j em 0..N-1, local_C[i][j] = 0.",
                                    "Para cada k em 0..N-1, local_C[i][j] += local_A[i][k] * B[k][j].",
                                    "Otimizar com loops ikj ou ijk para cache (testar).",
                                    "Imprimir local_C por rank para verificação parcial.",
                                    "Medir tempo local com MPI_Wtime para análise futura."
                                  ],
                                  "verification": "local_C impressa por rank bate com multiplicação manual para submatriz.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Matrizes de teste impressas",
                                    "Papel para multiplicação manual"
                                  ],
                                  "tips": "Use double para precisão; acumule em local_C inicializada a zero.",
                                  "learningObjective": "Implementar kernel de multiplicação matricial em paralelo.",
                                  "commonMistakes": "Índices off-by-one em loops; não zerar local_C."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Coletar resultados com MPI_Gather e usar MPI_Allreduce para verificação",
                                  "subSteps": [
                                    "No rank 0, alocar C[N][N]; usar MPI_Gather para coletar local_C em C (count=N*N_local).",
                                    "Imprimir C completa no rank 0.",
                                    "Opcional: Allreduce soma de tempos locais para tempo médio total.",
                                    "Finalizar com MPI_Finalize();",
                                    "Testar com N=4, np=2/4 e comparar com versão serial."
                                  ],
                                  "verification": "C final igual à multiplicação serial de A x B.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Versão serial para benchmark",
                                    "mpirun com diferentes np"
                                  ],
                                  "tips": "Gather requer buffers simétricos; valide com pequena N.",
                                  "learningObjective": "Reunir resultados distribuídos e finalizar programa MPI.",
                                  "commonMistakes": "MPI_Gather sem alocação de recvbuf no raiz; esquecer Finalize."
                                }
                              ],
                              "practicalExample": "Multiplique matrizes 4x4: A=[[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]], B identidade. Com 4 processos, cada computa 1 linha de C. Resultado deve ser A. Execute mpirun -np 4 ./matmul_mpi e verifique output.",
                              "finalVerifications": [
                                "Programa compila e executa sem deadlocks ou erros MPI.",
                                "Matriz C resultante é idêntica à serial para N=4,8.",
                                "Tempo escala com np (speedup visível em N=64).",
                                "Nenhum vazamento de memória (valgrind mpirun).",
                                "local_A e B corretos em logs por rank.",
                                "MPI_Allreduce de checksum de C bate em todos ranks."
                              ],
                              "assessmentCriteria": [
                                "Correção: C exata com tolerância 1e-10.",
                                "Eficiência: Comunicação mínima (Scatter/Bcast/Gather).",
                                "Qualidade de código: Comentários, error handling MPI.",
                                "Escalabilidade: Funciona para np=1 a N.",
                                "Documentação: README com como compilar/executar.",
                                "Otimização: Loops cache-friendly."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e decomposição de matrizes.",
                                "Redes de Computadores: Protocolos de comunicação ponto-a-ponto e coletiva.",
                                "Algoritmos: Análise de complexidade O(N^3/p + comm).",
                                "Engenharia de Software: Modularidade em códigos paralelos.",
                                "Física Computacional: Simulações numéricas distribuídas."
                              ],
                              "realWorldApplication": "Usado em solvers de equações diferenciais em CFD (ex: OpenFOAM), treinamento de redes neurais (TensorFlow distribuído), simulações climáticas (CESM) e análise de big data em supercomputadores."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.1.2.3",
                            "name": "Otimizar comunicação em MPI",
                            "description": "Aplicar técnicas como Cannon's algorithm ou Fox's algorithm para minimizar volume de mensagens e latência em multiplicação de matrizes distribuída.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os desafios de comunicação em MPI para multiplicação de matrizes",
                                  "subSteps": [
                                    "Analise o algoritmo naive de multiplicação de matrizes em MPI e identifique gargalos de comunicação (all-to-all).",
                                    "Estude métricas chave: volume de mensagens (total de dados enviados) e latência (tempo de espera por mensagens).",
                                    "Revise primitivas MPI como MPI_Send, MPI_Recv, MPI_Allreduce e MPI_Bcast.",
                                    "Calcule teoricamente o volume de comunicação para uma matriz NxN em P processos.",
                                    "Compare com requisitos de algoritmos otimizados como Cannon's e Fox's."
                                  ],
                                  "verification": "Crie um diagrama de fluxo mostrando gargalos no algoritmo naive e anote métricas teóricas calculadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação MPI oficial",
                                    "Livro 'Parallel Programming with MPI' de Peter Pacheco",
                                    "Notebook Jupyter para cálculos teóricos"
                                  ],
                                  "tips": "Use ferramentas como Draw.io para diagramas visuais de comunicação entre processos.",
                                  "learningObjective": "Identificar e quantificar ineficiências de comunicação em implementações distribuídas básicas.",
                                  "commonMistakes": [
                                    "Ignorar overhead de latência vs. bandwidth",
                                    "Confundir volume total com volume por processo",
                                    "Não considerar topologia de rede"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar e modelar o algoritmo de Cannon",
                                  "subSteps": [
                                    "Descreva os princípios do Cannon's algorithm: alinhamento inicial, computação local e shift ciclico.",
                                    "Modele o algoritmo para uma grade 2D de processos (ex: 4x4 processos para matriz 16x16).",
                                    "Calcule volume de comunicação: 2*N^2 elementos por processo ao longo de N passos.",
                                    "Simule manualmente 2-3 iterações em papel para matriz pequena (4x4).",
                                    "Compare latência: O(N) shifts vs. O(log P) em algoritmos SUMMA."
                                  ],
                                  "verification": "Produza um pseudocódigo completo do Cannon's algorithm com anotações de comunicação MPI.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Artigo original de Lynn Cannon (1969)",
                                    "Slides ou tutoriais sobre MPI matrix multiplication",
                                    "Papel e caneta para simulação manual"
                                  ],
                                  "tips": "Visualize shifts com animações online ou ferramentas como MPI tracer (Tau ou Vampir).",
                                  "learningObjective": "Modelar algoritmos de comunicação otimizada para decomposição 2D.",
                                  "commonMistakes": [
                                    "Esquecer alinhamento inicial das matrizes A e B",
                                    "Não sincronizar shifts com MPI_Barrier",
                                    "Assumir grade quadrada sem generalizar"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e testar Cannon's algorithm em MPI",
                                  "subSteps": [
                                    "Escreva código MPI para Cannon's: inicialize matrizes, realize alinhamento, loop de shift e multiply.",
                                    "Use MPI_Cart_create para topologia 2D e MPI_Sendrecv para shifts eficientes.",
                                    "Compile e execute em cluster com 4-16 processos para matrizes 256x256.",
                                    "Meça performance com MPI_Wtime: tempo total, volume (MPI_Reduce com contadores) e latência.",
                                    "Valide resultado com multiplicação serial em um processo raiz."
                                  ],
                                  "verification": "Código roda corretamente, resultado matricial é preciso (erro < 1e-10) e métricas de comunicação são registradas.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Compilador MPI (OpenMPI ou MPICH)",
                                    "Cluster ou multi-core com mpirun",
                                    "Código base de multiplicação naive para baseline"
                                  ],
                                  "tips": "Use MPI_Sendrecv_replace para shifts bidirecionais e evite deadlocks com padrões não-bloqueantes.",
                                  "learningObjective": "Implementar algoritmo otimizado com primitivas MPI avançadas.",
                                  "commonMistakes": [
                                    "Deadlocks em MPI_Send/Recv sem tags adequados",
                                    "Não particionar matrizes corretamente em blocos",
                                    "Overflow em contadores de volume para matrizes grandes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com Fox's algorithm e otimizar",
                                  "subSteps": [
                                    "Implemente Fox's algorithm: broadcasting em direções de grade e reduções locais.",
                                    "Execute ambos algoritmos com mesmas entradas e compare volume/latência.",
                                    "Otimize: ajuste tamanhos de bloco, use MPI_Isend/Irecv para overlap de comunicação/computação.",
                                    "Gere gráficos de speedup e eficiência vs. número de processos.",
                                    "Documente trade-offs: Cannon's bom para latência alta, Fox's para bandwidth alto."
                                  ],
                                  "verification": "Relatório com tabelas/gráficos mostrando redução de 30-50% no volume vs. naive.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "GNUPlot ou Matplotlib para gráficos",
                                    "Artigo de Fox sobre algoritmos paralelos",
                                    "Perfilador MPI como Scalasca"
                                  ],
                                  "tips": "Teste em topologias reais (ex: torus) com MPI_Cart_shift para simular shifts eficientes.",
                                  "learningObjective": "Avaliar e refinar algoritmos para cenários específicos de hardware.",
                                  "commonMistakes": [
                                    "Não normalizar speedup por baseline correto",
                                    "Ignorar custos de broadcasting em Fox's",
                                    "Executar testes sem aquecimento de cache"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente multiplicação de duas matrizes 1024x1024 em um cluster de 16 nós (4x4 grade). Use Cannon's para reduzir volume de mensagens de ~8GB (naive) para ~2GB, medindo latência média por shift em 50ms.",
                              "finalVerifications": [
                                "Código MPI compila e executa sem erros em múltiplos processos.",
                                "Resultado da multiplicação é numericamente correto (norma do erro < 1e-12).",
                                "Volume de mensagens reduzido em pelo menos 40% vs. implementação naive.",
                                "Latência por iteração medida e plotada vs. tamanho da matriz.",
                                "Speedup superlinear observado para matrizes quadradas grandes.",
                                "Relatório inclui diagramas de comunicação e métricas profiladas."
                              ],
                              "assessmentCriteria": [
                                "Precisão algorítmica: shifts e multiplications corretos (100%).",
                                "Eficiência de comunicação: uso ótimo de Sendrecv e topologias (80%+ eficiência).",
                                "Medição rigorosa: contadores precisos de volume/latência com profiling.",
                                "Comparação quantitativa: tabelas/gráficos vs. baselines.",
                                "Otimização demonstrada: overlap comm/comp ou ajustes de bloco.",
                                "Documentação clara: pseudocódigo, comentários e análise de trade-offs."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e decomposição de matrizes em blocos.",
                                "Redes de Computadores: Modelos de comunicação (latency-bound vs. bandwidth-bound).",
                                "Otimização: Algoritmos heurísticos e análise assintótica O(N^3/P + comunicação).",
                                "Engenharia de Software: Modularidade em código paralelo e testes distribuídos.",
                                "Ciência de Dados: Aplicações em ML distribuído (ex: gradient descent paralelo)."
                              ],
                              "realWorldApplication": "Em supercomputadores como Frontier ou Fugaku, otimiza simulações climáticas, treinamento de redes neurais em TensorFlow/PyTorch distribuído e processamento de imagens em HPC, reduzindo tempo de execução de dias para horas em problemas de petabyte-scale."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.1.3",
                        "name": "Avaliação de Desempenho e Comparação",
                        "description": "Comparação quantitativa dos algoritmos em memória compartilhada e distribuída, utilizando métricas de speedup, eficiência, escalabilidade e referência à bibliografia como Grama et al. e Pacheco.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.1.3.1",
                            "name": "Calcular speedup e eficiência",
                            "description": "Aplicar fórmulas de Amdahl e Gustafson para medir speedup (Ts/Tp) e eficiência (speedup/p) em execuções de multiplicação de matrizes paralelas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender conceitos fundamentais de speedup e eficiência",
                                  "subSteps": [
                                    "Defina speedup como a razão entre o tempo de execução sequencial (Ts) e paralelo (Tp): speedup = Ts / Tp.",
                                    "Defina eficiência como speedup dividido pelo número de processadores (p): eficiência = speedup / p.",
                                    "Identifique componentes seriais e paralelizáveis em uma aplicação como multiplicação de matrizes.",
                                    "Explique por que speedup ideal é p, mas real é menor devido a overheads.",
                                    "Calcule speedup e eficiência para um exemplo simples hipotético com Ts=100s, Tp=30s, p=4."
                                  ],
                                  "verification": "Responda corretamente a um quiz com 5 perguntas sobre definições e cálculo básico (acurácia 100%).",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notebook, calculadora, documento com fórmulas de speedup e eficiência.",
                                  "tips": "Use unidades consistentes de tempo (segundos) para evitar erros de escala.",
                                  "learningObjective": "Compreender as métricas básicas de desempenho paralelo.",
                                  "commonMistakes": "Confundir Ts com Tp ou esquecer de dividir por p na eficiência."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar a Lei de Amdahl para speedup",
                                  "subSteps": [
                                    "Identifique a fração serial (f) e paralela (1-f) na multiplicação de matrizes (ex: inicialização serial).",
                                    "Aplique fórmula de Amdahl: speedup = 1 / (f + (1-f)/p).",
                                    "Meça ou estime Ts e frações para uma implementação sequencial de multiplicação NxN.",
                                    "Calcule speedup para p=4,8,16 com f=0.1.",
                                    "Compare com speedup linear e plote gráfico de escalabilidade."
                                  ],
                                  "verification": "Gere tabela com speedups para diferentes p e f, validada contra calculadora online (erro <1%).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Planilha Excel/Google Sheets, código fonte sequencial de multiplicação de matrizes.",
                                  "tips": "Comece com f pequena (comum em apps paralelas) para ver limites reais.",
                                  "learningObjective": "Calcular limites de speedup sob Lei de Amdahl.",
                                  "commonMistakes": "Usar fração errada (ex: superestimar serial) ou inverter f e (1-f)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar a Lei de Gustafson para eficiência escalável",
                                  "subSteps": [
                                    "Entenda Gustafson: speedup = p * (1 - s) + s, onde s é fração serial escalada.",
                                    "Adapte para problema maior: tempo paralelo Tp = s * Ts + (p - s * (p-1)) * Tp_unit.",
                                    "Para multiplicação de matrizes, escale N com p e recalcule Ts e Tp.",
                                    "Calcule eficiência para p=4 com s=0.05, comparando com Amdahl.",
                                    "Discuta quando Gustafson é mais realista (problemas escaláveis)."
                                  ],
                                  "verification": "Produza relatório com cálculos Gustafson vs Amdahl, com gráfico mostrando diferenças (análise coerente).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python/MATLAB para simulações, gráficos (Matplotlib).",
                                  "tips": "Use s pequena para apps HPC como multiplicação de matrizes em IA.",
                                  "learningObjective": "Avaliar escalabilidade com crescimento de problema.",
                                  "commonMistakes": "Ignorar escalonamento do problema ou confundir s com f de Amdahl."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e comparar em multiplicação de matrizes paralela",
                                  "subSteps": [
                                    "Execute código sequencial e paralelo (ex: OpenMP/MPI) para matrizes 1000x1000.",
                                    "Meça Ts e Tp para p=1,4,8; calcule speedup e eficiência real.",
                                    "Aplique Amdahl e Gustafson aos dados medidos e compare com reais.",
                                    "Analise discrepâncias (overheads, balanceamento).",
                                    "Otimize código e recalcule métricas."
                                  ],
                                  "verification": "Submeta código, tempos medidos e cálculos; speedup calculado bate com medido (±5%).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Ambiente com compilador paralelo (GCC+OpenMP), máquina multi-core.",
                                  "tips": "Use matrizes grandes para minimizar overheads de memória.",
                                  "learningObjective": "Integrar teoria com prática em estudo de caso real.",
                                  "commonMistakes": "Medir tempos inconsistentes (sem aquecimento de cache) ou ignorar overheads de comunicação."
                                }
                              ],
                              "practicalExample": "Para multiplicação de matrizes 1024x1024: Ts=10s (sequencial), Tp=3s com 4 cores. Speedup Amdahl (f=0.1): 1/(0.1 + 0.9/4)=3.08; Eficiência=3.08/4=0.77. Gustafson (s=0.1): speedup=4*(1-0.1)+0.1=3.7; Eficiência=3.7/4=0.925. Real medido: speedup=3.2, eficiência=0.8.",
                              "finalVerifications": [
                                "Cálculo correto de speedup Amdahl para dado f e p.",
                                "Cálculo correto de speedup Gustafson para dado s e p.",
                                "Eficiência computada como speedup/p em todos casos.",
                                "Comparação gráfica entre teorias e medidas reais.",
                                "Análise de discrepâncias com overheads identificados.",
                                "Otimização aplicada resultando em speedup >10% melhor."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos (erro <1%).",
                                "Correta identificação de frações serial/paralela.",
                                "Uso apropriado de Amdahl vs Gustafson por cenário.",
                                "Qualidade de medições experimentais (repetições, estatísticas).",
                                "Análise crítica das limitações e otimizações.",
                                "Clareza em relatórios e gráficos.",
                                "Integração com contexto de multiplicação de matrizes."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear (multiplicação de matrizes) e análise limite.",
                                "Física: Simulações numéricas paralelas (ex: dinâmica molecular).",
                                "Engenharia de Software: Otimização de performance e profiling.",
                                "Ciência de Dados: Aceleração de ML com GPUs (similar a matrizes)."
                              ],
                              "realWorldApplication": "Em supercomputadores para treinamento de redes neurais (ex: TensorFlow distribuído), onde speedup Amdahl guia paralelização inicial e Gustafson valida escalas massivas, otimizando tempo de treinamento de dias para horas em data centers."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.1.3.2",
                            "name": "Executar benchmarks comparativos",
                            "description": "Rodar experimentos em plataformas multicores e clusters, plotando curvas de escalabilidade e analisando gargalos como comunicação vs computação.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e código baseline para benchmarks",
                                  "subSteps": [
                                    "Compilar o código de multiplicação de matrizes paralela usando OpenMP para multicore e MPI para cluster.",
                                    "Definir tamanhos de matriz variados (ex: 512x512, 1024x1024 até 4096x4096) e números de threads/processos (1, 2, 4, 8, 16).",
                                    "Configurar scripts de automação para rodar múltiplas execuções e calcular médias/tempos.",
                                    "Testar execução single-thread para baseline sequencial.",
                                    "Verificar integridade dos resultados com checksums ou comparações."
                                  ],
                                  "verification": "Código compila sem erros, baseline sequencial roda e produz resultados corretos verificados por checksum.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Código fonte de multiplicação de matrizes (OpenMP/MPI)",
                                    "Compilador (GCC com suporte OpenMP/MPI)",
                                    "Scripts Bash/Python para automação",
                                    "Ambiente Linux com multicore/cluster acessível"
                                  ],
                                  "tips": "Use flags de otimização como -O3 e -march=native para resultados realistas; rode em máquina dedicada para evitar interferências.",
                                  "learningObjective": "Configurar corretamente ambientes paralelos e preparar benchmarks reprodutíveis.",
                                  "commonMistakes": [
                                    "Esquecer de desabilitar otimizações do compilador que mascaram gargalos",
                                    "Não usar sementes fixas para geradores de matrizes aleatórias",
                                    "Ignorar overhead de I/O em scripts de medição"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar benchmarks em plataforma multicore (OpenMP)",
                                  "subSteps": [
                                    "Rodar experimentos variando número de threads para cada tamanho de matriz, com 10 repetições por configuração.",
                                    "Medir tempo de wall-clock, CPU-time e flops usando ferramentas como likwid ou perf.",
                                    "Registrar métricas: tempo total, speedup, eficiência e uso de memória.",
                                    "Exportar dados para CSV com colunas: tamanho_matriz, num_threads, tempo_medio, speedup.",
                                    "Validar ausência de falsos compartilhamentos ou contenção de cache."
                                  ],
                                  "verification": "Dados coletados em CSV com pelo menos 5 tamanhos x 5 threads, speedup >1 para casos paralelizáveis.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Cluster local ou máquina multicore (8+ cores)",
                                    "Ferramentas: likwid, perf ou omp_get_wtime()",
                                    "Planilha ou Pandas para pré-processamento"
                                  ],
                                  "tips": "Fixe afinidade de threads com OMP_PROC_BIND=spread para melhor escalabilidade; monitore temperatura da CPU.",
                                  "learningObjective": "Executar medições precisas em ambientes compartilhados de memória.",
                                  "commonMistakes": [
                                    "Não fazer warm-up runs antes de medir",
                                    "Confundir wall-time com CPU-time",
                                    "Executar em background com outros processos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar benchmarks em cluster distribuído (MPI)",
                                  "subSteps": [
                                    "Configurar jobs no gerenciador de filas (SLURM/PBS) com alocação de nós variados (1-8 nós).",
                                    "Rodar experimentos similares ao multicore, medindo tempo de comunicação com MPI_Wtime.",
                                    "Coletar métricas adicionais: volume de mensagens, latência via MPI profilers como Vampir.",
                                    "Exportar dados CSV incluindo num_nos, tempo_comunicacao, tempo_computacao.",
                                    "Comparar com resultados multicore."
                                  ],
                                  "verification": "Jobs submetidos e completados, dados CSV com speedup linear até certo ponto.",
                                  "estimatedTime": "3-4 horas (inclui tempo de fila)",
                                  "materials": [
                                    "Cluster com MPI instalado (OpenMPI/MPICH)",
                                    "Gerenciador de filas (SLURM)",
                                    "Profiler MPI (Scalasca/TAU)"
                                  ],
                                  "tips": "Use --ntasks-per-node=1 para minimizar contenção; teste conectividade de rede antes.",
                                  "learningObjective": "Gerenciar experimentos distribuídos e isolar custos de comunicação.",
                                  "commonMistakes": [
                                    "Sobrecarregar rede sem throttling",
                                    "Não sincronizar clocks entre nós",
                                    "Ignorar overhead de inicialização MPI"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Plotar curvas de escalabilidade e coletar dados",
                                  "subSteps": [
                                    "Carregar dados CSV em Python (Pandas/Matplotlib/Seaborn).",
                                    "Gerar plots: speedup vs num_cores/procs (strong scaling), tempo vs tamanho_matriz (weak scaling).",
                                    "Adicionar curvas teóricas (Gustafson/Amdahl) para comparação.",
                                    "Criar gráficos de gargalos: % tempo em compute vs comm.",
                                    "Salvar plots em alta resolução com legendas e anotações."
                                  ],
                                  "verification": "Plots gerados mostrando escalabilidade sub-linear em grandes escalas, salvos como PNG/PDF.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python com Pandas, Matplotlib, NumPy",
                                    "Jupyter Notebook para experimentação"
                                  ],
                                  "tips": "Use log-scale para eixos de performance; inclua barras de erro das repetições.",
                                  "learningObjective": "Visualizar e comunicar resultados de benchmarks de forma clara.",
                                  "commonMistakes": [
                                    "Escalas lineares inadequadas para speedup",
                                    "Não normalizar por baseline correto",
                                    "Plots sem labels ou títulos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar gargalos e gerar relatório",
                                  "subSteps": [
                                    "Identificar knee da curva de escalabilidade (ponto de saturação).",
                                    "Quantificar gargalos: ratio comm/compute, impacto de latência vs bandwidth.",
                                    "Comparar multicore vs cluster: quando um é melhor.",
                                    "Propor otimizações baseadas em análise (ex: hybrid MPI+OpenMP).",
                                    "Escrever relatório resumindo achados com plots embedados."
                                  ],
                                  "verification": "Relatório identifica pelo menos 2 gargalos principais com evidências quantitativas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Editor de texto/Markdown para relatório",
                                    "Plots gerados anteriormente"
                                  ],
                                  "tips": "Use roofline model para validar análise; cite literatura como 'Scalability Fun with Speedup'.",
                                  "learningObjective": "Interpretar dados de performance para insights acionáveis.",
                                  "commonMistakes": [
                                    "Atribuir gargalos a hardware sem dados",
                                    "Ignorar variância nas repetições",
                                    "Não considerar problema específico (matriz denso)"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um cluster de 4 nós (16 cores/no), benchmark multiplicação de matriz 2048x2048: OpenMP atinge speedup 10x em 16 threads, mas MPI em 4 nós só 25x devido a all-reduce custoso; plot mostra comm >50% tempo após 8 procs.",
                              "finalVerifications": [
                                "Curvas de strong/weak scaling plotadas corretamente com speedup mensurável.",
                                "Gargalos identificados quantitativamente (ex: comm/compute >20%).",
                                "Dados CSV completos e reprodutíveis.",
                                "Relatório resume comparações multicore vs cluster.",
                                "Validações de corretude (checksums) em todos runs.",
                                "Plots incluem baselines teóricas e barras de erro."
                              ],
                              "assessmentCriteria": [
                                "Precisão das medições: repetições >=5, coef var <10%.",
                                "Qualidade dos plots: legíveis, escalas adequadas, anotações claras.",
                                "Profundidade da análise: quantifica gargalos com ratios e compara plataformas.",
                                "Reprodutibilidade: scripts e dados versionados (Git).",
                                "Insights acionáveis: sugere pelo menos uma otimização válida.",
                                "Relatório estruturado: intro, métodos, resultados, discussão."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: análise de variância e intervalos de confiança nos tempos.",
                                "Hardware/Arquitetura: compreensão de caches, redes InfiniBand e NUMA.",
                                "Programação: profiling avançado com TAU ou Intel VTune.",
                                "Matemática: modelos de Amdahl/Gustafson para predição teórica.",
                                "Gestão de Projetos: automação de experimentos com CI/CD."
                              ],
                              "realWorldApplication": "Em centros de supercomputação como o LNCC (Santos Dumont), benchmarks guiam alocação de jobs para minimizar tempo de espera e energia em simulações climáticas ou drug discovery, otimizando apps como GROMACS para milhares de cores."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.1.3.3",
                            "name": "Interpretar resultados com modelos teóricos",
                            "description": "Relacionar desempenhos observados com modelos de PRAM, LogP e análise assintótica (O(N^3/p) para p processadores).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os Modelos Teóricos de Desempenho Paralelo",
                                  "subSteps": [
                                    "Estudar o modelo PRAM: entender variantes (EREW, CREW, CRCW) e complexidade para multiplicação de matrizes (T = O(log N) com p = N^3 processadores)",
                                    "Analisar o modelo LogP: identificar parâmetros (L: latência, o: overhead, g: gap de comunicação, P: processadores) e sua aplicação em comunicações reais",
                                    "Explorar análise assintótica: calcular tempo sequencial O(N^3), paralelo ideal O(N^3/p), speedup S(p) = T(1)/T(p) e eficiência E(p) = S(p)/p",
                                    "Comparar suposições: PRAM (compartilhamento instantâneo de memória) vs. LogP (comunicação realista com latência)",
                                    "Mapear para multiplicação de matrizes: overheads como broadcast e reduce em algoritmos como Cannon ou Fox"
                                  ],
                                  "verification": "Criar um resumo escrito de 1 página comparando os três modelos, com fórmulas chave.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação oficial de PRAM (Wikipedia ou papers de Fortune & Wyllie)",
                                    "Paper original de LogP (Karp et al.)",
                                    "Notas de aula sobre análise assintótica paralela",
                                    "Exemplos de código MPI para MM"
                                  ],
                                  "tips": "Use diagramas para visualizar as diferenças entre modelos ideais e realistas.",
                                  "learningObjective": "Compreender as premissas, fórmulas e limitações de PRAM, LogP e análise assintótica aplicados a programação paralela.",
                                  "commonMistakes": [
                                    "Confundir variantes de PRAM",
                                    "Ignorar o parâmetro 'o' (overhead CPU) no LogP",
                                    "Esquecer termos de overhead na análise assintótica"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Coletar e Organizar Dados Experimentais Observados",
                                  "subSteps": [
                                    "Executar benchmarks de multiplicação de matrizes paralelas (ex: N=512,1024) com 1, 2, 4, 8, 16 processadores usando MPI/OpenMP",
                                    "Registrar tempos de execução (T(p)), uso de CPU, bandwidth de rede e latência medida com ferramentas como mpiBlib ou TAU",
                                    "Calcular métricas observadas: speedup S_obs(p) = T(1)/T(p), eficiência E_obs(p) = S_obs(p)/p, isoeficiência",
                                    "Visualizar dados: plotar gráficos de speedup vs. p (lei de Gustafson/Amdahl) e tempo total vs. tamanho N",
                                    "Identificar anomalias: gargalos como contenção de memória ou overhead de comunicação"
                                  ],
                                  "verification": "Gerar gráficos e tabela de dados com pelo menos 5 configurações de p e N, salvos em arquivo.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Cluster ou máquina multi-core com MPI instalado",
                                    "Código fonte de MM paralela (ex: GitHub repos)",
                                    "Ferramentas: Gnuplot/Matplotlib para plots, mpistat para métricas"
                                  ],
                                  "tips": "Varie tamanhos de matriz para capturar regimes computacional vs. comunicação-dominado.",
                                  "learningObjective": "Preparar dados empíricos robustos para comparação com modelos teóricos.",
                                  "commonMistakes": [
                                    "Medir apenas tempo wall-clock sem considerar overheads",
                                    "Usar N pequeno onde overhead domina",
                                    "Ignorar variabilidade em runs repetidos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Modelos Teóricos aos Dados Observados",
                                  "subSteps": [
                                    "Calcular predições PRAM: T_PRAM(p) ≈ N^3 / p + log N (adaptado para MM), comparar com S_obs",
                                    "Estimar parâmetros LogP: medir L, g, o experimentalmente e simular T_LogP(p) = computação + L + o*(msgs-1) + g*msgs/p",
                                    "Realizar análise assintótica: plotar O(N^3/p) ajustado por constantes, prever scaling para p maior",
                                    "Fitar modelos: usar regressão linear em log-scale para speedup e identificar melhor fit (R^2)",
                                    "Quantificar desvios: calcular erro percentual |T_obs - T_model| / T_obs * 100%"
                                  ],
                                  "verification": "Produzir tabela comparativa com predições vs. observados para cada modelo, incluindo erros.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Planilhas Excel/Python (NumPy/SciPy para fitting)",
                                    "Scripts para simulação LogP",
                                    "Referências: livros como 'Parallel Computer Architecture' de Culler"
                                  ],
                                  "tips": "Comece com análise assintótica simples antes de modelos complexos como LogP.",
                                  "learningObjective": "Gerar predições quantitativas dos modelos e compará-las numericamente com dados reais.",
                                  "commonMistakes": [
                                    "Não calibrar parâmetros LogP com dados reais",
                                    "Aplicar PRAM diretamente sem considerar memória distribuída",
                                    "Esquecer normalização por tamanho N"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Discrepâncias e Extrair Insights",
                                  "subSteps": [
                                    "Analisar por que PRAM superestima speedup (falta realismo em comunicação/memória)",
                                    "Explicar fit do LogP: impacto de g e L em regimes de alta latência",
                                    "Discutir limites assintóticos: quando O(N^3/p) falha (overheads fixos dominam para p baixo)",
                                    "Recomendar otimizações: reduzir comunicações baseadas em desvios observados",
                                    "Documentar conclusões: relatório com gráficos overlay de modelos vs. dados"
                                  ],
                                  "verification": "Escrever relatório de 1-2 páginas com interpretações e recomendações.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Templates de relatório LaTeX/Markdown",
                                    "Ferramentas de plotagem avançada (ggplot2 ou similar)"
                                  ],
                                  "tips": "Use perguntas guiadas: 'Por que o speedup não é linear? Qual modelo explica melhor?'",
                                  "learningObjective": "Relacionar discrepâncias teórico-empíricas a limitações hardware/algoritmo.",
                                  "commonMistakes": [
                                    "Atribuir todos desvios a 'ruído' sem análise",
                                    "Ignorar contexto do hardware (ex: InfiniBand vs. Ethernet)",
                                    "Generalizar de poucos dados"
                                  ]
                                }
                              ],
                              "practicalExample": "Em experimentos de multiplicação de matrizes 1024x1024 com MPI em 8 nodes: T(1)=120s, T(8)=20s (S_obs=6, E_obs=0.75). PRAM prevê S=8 (ideal), LogP ajustado com L=50μs, g=1μs explica perda por 200k mensagens/all-reduce, análise O(N^3/p) confirma regime computacional mas destaca overhead de 15%. Interpretação: otimizar reduzindo broadcasts.",
                              "finalVerifications": [
                                "Explicar verbalmente por que LogP fits melhor que PRAM em cluster real",
                                "Prever corretamente speedup para p=16 baseado em modelo escolhido",
                                "Identificar gargalo principal (computação/comunicação) de gráfico de scaling",
                                "Calcular eficiência isoeficiência para N=2048",
                                "Propor 2 otimizações baseadas em discrepâncias",
                                "Comparar com lei de Amdahl para fração paralela"
                              ],
                              "assessmentCriteria": [
                                "Precisão das predições teóricas (erro <20%)",
                                "Qualidade da visualização e comparação gráfica",
                                "Profundidade da interpretação de discrepâncias",
                                "Correção matemática em cálculos de speedup/eficiência",
                                "Relevância das recomendações práticas",
                                "Clareza e estrutura do relatório final"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise assintótica e regressão linear",
                                "Estatística: Ajuste de modelos e análise de variância",
                                "Engenharia de Software: Benchmarking e profiling",
                                "Física Computacional: Modelos de sistemas distribuídos",
                                "Gestão de Projetos: Análise custo-benefício de scaling"
                              ],
                              "realWorldApplication": "Otimizar performance em supercomputadores para treinamento de redes neurais (ex: TensorFlow distribuído), análise sísmica em óleo/gás ou simulações climáticas, onde predizer scaling com LogP evita desperdício de recursos em clusters caros."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.2",
                    "name": "Estudo de Caso: Simulação N-Corpos",
                    "description": "Aplicação de programação paralela em simulações físicas de partículas interagentes, com foco em troca de mensagens e avaliação de desempenho.",
                    "individualConcepts": [
                      {
                        "id": "64.3.1.1",
                        "name": "Modelo Sequencial da Simulação N-Corpos",
                        "description": "Entender o problema clássico da simulação N-corpos, onde partículas interagem via lei da gravitação universal, calculando forças e atualizando posições e velocidades em um loop temporal sequencial.",
                        "specificSkills": [
                          {
                            "id": "64.3.1.1.1",
                            "name": "Implementar simulação sequencial básica",
                            "description": "Desenvolver um programa sequencial em C ou Python que simule N partículas, calculando forças gravitacionais O(N²) e atualizando posições para um número fixo de iterações.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir estruturas de dados e inicializar partículas",
                                  "subSteps": [
                                    "Crie uma classe Particle em Python com atributos: position (lista [x, y]), velocity (lista [vx, vy]), mass (float)",
                                    "Defina constantes globais: G (constante gravitacional), dt (passo de tempo), num_iterations (ex: 100), N (número de partículas, ex: 10)",
                                    "Inicialize uma lista de N partículas com posições aleatórias em um quadrado (ex: -100 a 100), velocidades zero ou aleatórias pequenas, massas aleatórias (ex: 1 a 10)",
                                    "Implemente uma função para imprimir posições iniciais para verificação",
                                    "Teste a inicialização rodando um script simples que cria e printa as partículas"
                                  ],
                                  "verification": "Execute o código de inicialização e confirme que as partículas têm atributos corretos e posições variadas sem erros",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Editor de código (VS Code ou Jupyter), Python 3 instalado",
                                  "tips": "Use numpy para vetores se quiser precisão, mas listas puras bastam para básico",
                                  "learningObjective": "Entender representação de entidades físicas em código e inicialização de simulações",
                                  "commonMistakes": "Esquecer de importar random ou math; posições idênticas causando colapso imediato"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar cálculo de forças gravitacionais O(N²)",
                                  "subSteps": [
                                    "Crie uma função compute_forces(particles) que retorna uma lista de forças totais [fx, fy] para cada partícula",
                                    "Para cada par i,j (i < j): calcule distância r = sqrt((dx)^2 + (dy)^2), força magnitude = G * m_i * m_j / r^2",
                                    "Direção: unit_vector = [dx/r, dy/r], adicione força ao i e subtraia do j (ação-reação)",
                                    "Some forças de todos pares para força total de cada partícula",
                                    "Adicione verificação: se r < epsilon (ex: 1e-6), ignore para evitar divisão por zero"
                                  ],
                                  "verification": "Teste com 2 partículas fixas: forças devem ser iguais e opostas; print forças antes de loop",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python com math module; papel para desenhar vetores de teste",
                                  "tips": "Use loop duplo for i in range(N): for j in range(i+1, N) para evitar double-counting",
                                  "learningObjective": "Dominar algoritmo O(N²) para interações pairwise e lei da gravitação universal",
                                  "commonMistakes": "Esquecer fator 1/r^2 ou direção errada; não tratar r=0 causando NaN"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar atualização de velocidades e posições",
                                  "subSteps": [
                                    "Crie função update_velocities_and_positions(particles, forces, dt): para cada partícula, acc = force / mass, v += acc * dt, pos += v * dt",
                                    "Garanta que forças sejam calculadas antes da atualização para timestep Euler simples",
                                    "Adicione limites de borda opcionais: se pos fora de [-500,500], reverta velocity",
                                    "Teste atualização isolada: mova uma partícula livre e verifique movimento linear",
                                    "Integre com compute_forces em uma função step_simulation(particles, dt)"
                                  ],
                                  "verification": "Simule 1 timestep com 2 partículas atraentes: velocidades devem apontar uma para outra",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Mesmos do step 1; debugger para inspecionar variáveis",
                                  "tips": "Use cópias de listas para forces para evitar mutação durante cálculo",
                                  "learningObjective": "Aplicar integração numérica básica (Euler) para dinâmica clássica",
                                  "commonMistakes": "Atualizar posições antes de forças; escalas erradas causando explosão/implosão"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar loop de simulação e adicionar output/visualização",
                                  "subSteps": [
                                    "Crie loop principal: for t in range(num_iterations): forces = compute_forces(), update(...), se t % 10 == 0: print posições",
                                    "Opcional: salve posições em lista para animação posterior com matplotlib",
                                    "Implemente plot simples: após simulação, plote trajetórias de todas partículas",
                                    "Execute com N=5, 100 iterações e verifique se partículas orbitam ou colidem realisticamente",
                                    "Otimize print para não floodar terminal (apenas cada 10 steps)"
                                  ],
                                  "verification": "Programa roda 100 iterações sem crash; posições mudam coerentemente (atração gravitacional visível em prints/plots)",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Matplotlib instalado (pip install matplotlib)",
                                  "tips": "Comece sem plot, adicione depois; ajuste dt=0.01 para estabilidade",
                                  "learningObjective": "Estruturar simulação temporal completa e visualizar resultados",
                                  "commonMistakes": "dt muito grande causando instabilidade; loop infinito sem range()"
                                }
                              ],
                              "practicalExample": "Simule 5 partículas com massas variadas em uma caixa 2D. Após 200 iterações (dt=0.01), plote trajetórias: partículas devem formar órbitas caóticas ou colidir, demonstrando atração gravitacional realista.",
                              "finalVerifications": [
                                "Programa executa todas iterações sem erros ou NaN",
                                "Forças calculadas corretamente para pares isolados (teste unitário)",
                                "Trajetórias mostram atração mútua (não movimento linear puro)",
                                "Tempo de execução razoável para N=10 (~segundos)",
                                "Visualização (print ou plot) confirma dinâmica gravitacional",
                                "Código modular com funções separadas"
                              ],
                              "assessmentCriteria": [
                                "Correção algorítmica: O(N²) exato com forças pairwise (80%)",
                                "Estabilidade numérica: sem explosões/implosões prematuras (15%)",
                                "Clareza e modularidade do código: funções bem nomeadas, comentários (5%)",
                                "Eficiência básica: sem loops desnecessários (bonus)",
                                "Visualização funcional e informativa",
                                "Tratamento de edge cases (r=0)"
                              ],
                              "crossCurricularConnections": [
                                "Física: Lei da Gravitação Universal de Newton e dinâmica de partículas",
                                "Matemática: Álgebra vetorial, cálculo de magnitudes e unit vectors",
                                "Computação: Complexidade O(N²) e profiling de performance",
                                "Visualização de Dados: Uso de matplotlib para trajetórias",
                                "Engenharia de Software: Modularidade e testes unitários"
                              ],
                              "realWorldApplication": "Simulações N-corpos são usadas em astrofísica para modelar galáxias e aglomerados estelares (ex: software como REBOUND ou GADGET), previsão de colisões planetárias, e em jogos/efeitos visuais para simular multidões gravitacionais."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.3.1.1.2",
                            "name": "Analisar complexidade computacional",
                            "description": "Calcular e justificar a complexidade temporal O(N²) por iteração e identificar gargalos para paralelização em simulações físicas realistas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o modelo sequencial da simulação N-Corpos",
                                  "subSteps": [
                                    "Examine o pseudocódigo ou código fonte da simulação sequencial, identificando as estruturas principais: inicialização de partículas, loop principal de iterações de tempo e loops internos para cálculo de forças.",
                                    "Identifique os loops aninhados: para cada iteração t, para cada partícula i (1 a N), para cada partícula j (1 a N, j ≠ i), calcular a força gravitacional.",
                                    "Registre o número de operações básicas (adições, multiplicações, divisões) dentro do loop mais interno.",
                                    "Anote as atualizações de posição e velocidade após o cálculo de forças para cada partícula.",
                                    "Desenhe um diagrama de fluxo destacando os loops aninhados."
                                  ],
                                  "verification": "Confirme que pode listar todos os loops aninhados e operações principais em um diagrama ou resumo escrito.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código fonte da simulação N-Corpos sequencial, papel e caneta ou ferramenta de diagramação como Draw.io",
                                  "tips": "Comece pelo loop externo de tempo para contextualizar; ignore otimizações por enquanto.",
                                  "learningObjective": "Compreender a estrutura algorítmica sequencial da simulação N-Corpos.",
                                  "commonMistakes": "Confundir loops de força com loops de atualização; assumir j inclui i (auto-interação)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Contar operações e calcular contagem exata por iteração",
                                  "subSteps": [
                                    "Para uma iteração fixa de tempo, conte o número de interações de pares: aproximadamente N*(N-1)/2 pares únicos, mas no código sequencial é ~N².",
                                    "Liste operações por par (i,j): cálculo de vetor distância (3 subtrações), magnitude (3 multiplicações + raiz), normalização, força (G*m1*m2 / r², ~5 operações).",
                                    "Some operações para aceleração total por partícula i (acumulação de forças de todos j).",
                                    "Inclua atualizações pós-força: nova velocidade (vel + acc*dt), nova posição (pos + vel*dt), ~6 operações por partícula.",
                                    "Calcule total de flops (floating point operations) por iteração: ~20 * N² flops."
                                  ],
                                  "verification": "Escreva uma fórmula exata para flops por iteração e compute para N=1000 (deve ser ~2e6 flops).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Calculadora ou planilha (Excel/Google Sheets), código fonte",
                                  "tips": "Use notação somatória: ∑_{i=1}^N ∑_{j≠i}^N para contar pares.",
                                  "learningObjective": "Quantificar precisamente o custo computacional por iteração.",
                                  "commonMistakes": "Esquecer operações de acumulação ou usar N(N-1)/2 sem considerar código double-loop; ignorar constantes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar e justificar a notação Big-O O(N²)",
                                  "subSteps": [
                                    "Analise dominância: o loop duplo aninhado domina, com custo Θ(N²) por iteração.",
                                    "Ignore termos inferiores: inicialização O(N), atualizações O(N).",
                                    "Justifique assintoticamente: para N grande, flops ~ c*N², onde c é constante de operações por par.",
                                    "Compare com benchmarks: rode simulação para N=100, 1000 e plote tempo vs N² (deve ser linear).",
                                    "Escreva prova formal: T(N) = O(N²) se ∃ k, N0 tal que T(N) ≤ k N² para N > N0."
                                  ],
                                  "verification": "Produza um gráfico ou tabela mostrando tempo/iteração escalando com N² e uma justificativa escrita.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Ambiente de programação (Python/C++ com timer), planilha para plotagem",
                                  "tips": "Use perfis simples como timeit em Python para medir tempo real.",
                                  "learningObjective": "Dominar análise assintótica e justificativa de complexidade O(N²).",
                                  "commonMistakes": "Confundir O com Θ; alegar O(N³) por múltiplas operações; não testar empiricamente."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar gargalos e oportunidades de paralelização",
                                  "subSteps": [
                                    "Localize gargalos: loop interno de pares (i,j) é independente para diferentes i; dependência só na acumulação por i.",
                                    "Classifique dependências: cálculos de força para i são independentes entre si, mas sequenciais dentro de i.",
                                    "Proponha paralelização: paralelizar outer loop sobre i (cada thread processa forças para um i).",
                                    "Discuta gargalos restantes: redução de forças (atomic adds), memória (acesso a posições compartilhadas).",
                                    "Estime speedup: ideal ~N (mas limitado por Amdahl a ~p processos)."
                                  ],
                                  "verification": "Liste 3 gargalos principais e 2 estratégias de paralelização com justificativa de viabilidade.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Papel para diagrama de dependências, documentação OpenMP/MPI básica",
                                  "tips": "Pense em 'embarrassingly parallel' para forças por partícula.",
                                  "learningObjective": "Reconhecer padrões paralelizáveis em algoritmos O(N²).",
                                  "commonMistakes": "Ignorar race conditions na acumulação; superestimar speedup sem considerar overhead."
                                }
                              ],
                              "practicalExample": "Em uma simulação de 1000 estrelas em uma galáxia, o modelo sequencial leva 2e6 flops por iteração. Analisando, o double-loop consome 95% do tempo; paralelizando sobre partículas i com 4 threads, reduz para 0.5s/iteração vs 2s sequencial.",
                              "finalVerifications": [
                                "Calcula corretamente flops por iteração como ~20 N².",
                                "Justifica O(N²) com análise assintótica e evidência empírica.",
                                "Identifica loop de pares como gargalo principal.",
                                "Propõe paralelização válida sem race conditions.",
                                "Compara speedup teórico vs prático.",
                                "Desenha diagrama de dependências de dados."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de complexidade (exata e assintótica).",
                                "Qualidade da justificativa (formal + empírica).",
                                "Identificação correta de gargalos (≥3 com explicação).",
                                "Propostas de paralelização realistas e corretas.",
                                "Clareza e completude do diagrama/análise.",
                                "Uso apropriado de notação Big-O."
                              ],
                              "crossCurricularConnections": [
                                "Física: Leis de Newton e gravitação em simulações numéricas.",
                                "Matemática: Análise assintótica e somatórios duplos.",
                                "Engenharia de Software: Profiling e otimização de performance.",
                                "Computação Científica: Métodos numéricos para EDOs.",
                                "Arquitetura de Computadores: Paralelismo e gargalos de memória."
                              ],
                              "realWorldApplication": "Em astrofísica (simulações de formação de galáxias como no projeto Illustris), jogos (física de partículas em engines como Unity), e computação de alto desempenho (HPC clusters para N>10^6 em supercomputadores como Frontier)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "64.3.1.1.3",
                            "name": "Visualizar resultados sequenciais",
                            "description": "Gerar trajetórias de partículas e plotar usando bibliotecas como Matplotlib para validar o modelo físico antes da paralelização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coletar e preparar dados das trajetórias das partículas",
                                  "subSteps": [
                                    "Execute a simulação sequencial N-Corpos para gerar posições das partículas ao longo de múltiplos timesteps.",
                                    "Armazene as posições em arrays NumPy multidimensionais (ex: shape [n_particulas, n_timesteps, 2] para 2D).",
                                    "Calcule velocidades ou acelerações derivadas se necessário para plots adicionais.",
                                    "Normalize ou filtre dados para evitar overflows em plots.",
                                    "Salve dados em formato acessível como .npy para reutilização."
                                  ],
                                  "verification": "Verifique se arrays de posições têm dimensões corretas via print(shape) e sem NaNs via np.isnan().any().",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python com NumPy, código da simulação sequencial N-Corpos.",
                                  "tips": "Use loops eficientes para coleta durante a simulação para evitar memória excessiva.",
                                  "learningObjective": "Entender como estruturar dados temporais para visualização científica.",
                                  "commonMistakes": "Esquecer de inicializar arrays vazios ou misturar coordenadas 2D/3D."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente de plotting com Matplotlib",
                                  "subSteps": [
                                    "Instale e importe matplotlib.pyplot e numpy.",
                                    "Configure o estilo de plot (ex: plt.style.use('seaborn-v0_8')) para melhor legibilidade.",
                                    "Crie figure e axes com tamanho adequado (ex: plt.subplots(1,1,figsize=(10,8))).",
                                    "Defina labels, títulos e legendas preliminares.",
                                    "Ative grid e ajuste limites dos eixos baseados nos dados."
                                  ],
                                  "verification": "Execute plt.show() em um plot de teste simples e confirme renderização sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Python, Matplotlib instalado (pip install matplotlib).",
                                  "tips": "Use %matplotlib inline em Jupyter para visualização interativa.",
                                  "learningObjective": "Dominar configuração básica de plots científicos em Matplotlib.",
                                  "commonMistakes": "Importar módulos errados ou esquecer plt.ion() para interatividade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerar plots estáticos das trajetórias das partículas",
                                  "subSteps": [
                                    "Plote trajetórias de cada partícula usando plt.plot(positions[i,:,0], positions[i,:,1]).",
                                    "Adicione marcadores iniciais e finais (ex: scatter para posições start/end).",
                                    "Inclua setas para indicar direção de movimento em pontos chave.",
                                    "Salve o plot como PNG/PDF com plt.savefig('trajetorias.png', dpi=300).",
                                    "Adicione anotações para forças gravitacionais em interações críticas."
                                  ],
                                  "verification": "Abra o arquivo salvo e confirme que todas trajetórias são visíveis e rotuladas corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Código dos steps anteriores, Matplotlib.",
                                  "tips": "Use cores diferentes por partícula e linewidth variável para destaque.",
                                  "learningObjective": "Criar visualizações estáticas claras de dados dinâmicos.",
                                  "commonMistakes": "Plots sobrepostos ilegíveis; escalar eixos automaticamente com plt.axis('equal')."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Criar animação dinâmica e validar modelo físico",
                                  "subSteps": [
                                    "Use FuncAnimation de matplotlib.animation para animar posições ao longo do tempo.",
                                    "Defina função de update que plota posições atuais e limpa trails anteriores.",
                                    "Salve animação como MP4 (precisa de ffmpeg).",
                                    "Observe comportamentos: órbitas estáveis, colisões, conservação de energia visual.",
                                    "Compare com expectativas físicas (ex: elipses para gravidade 2-corpos)."
                                  ],
                                  "verification": "Reproduza animação e confirme movimento suave sem saltos ou crashes.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Matplotlib animation, ffmpeg instalado.",
                                  "tips": "Limite frames para performance; use blit=True para animações rápidas.",
                                  "learningObjective": "Visualizar e validar dinâmicas físicas através de animações.",
                                  "commonMistakes": "Animação muito rápida/lenta; ajustar interval em ms."
                                }
                              ],
                              "practicalExample": "Em uma simulação de 5 partículas com massas variadas em 2D, colete 1000 timesteps, plote trajetórias coloridas mostrando órbitas elípticas ao redor do centro de massa, e anime para validar conservação de momento angular sem dispersão indevida.",
                              "finalVerifications": [
                                "Todos plots e animação gerados sem erros de runtime.",
                                "Trajetórias mostram física coerente (ex: atração gravitacional mútua).",
                                "Dados preservados corretamente (checksum ou shape match).",
                                "Arquivos salvos legíveis e de alta resolução.",
                                "Validação visual: ausência de artefatos como linhas quebradas.",
                                "Tempo de execução da visualização < 10s para replay."
                              ],
                              "assessmentCriteria": [
                                "Clareza e legibilidade dos plots (cores, labels, escalas).",
                                "Precisão na representação das trajetórias (match com dados numéricos).",
                                "Eficiência do código (sem loops desnecessários em plotting).",
                                "Validação física demonstrada (comentários ou anotações).",
                                "Criatividade na visualização (animações, múltiplos views).",
                                "Documentação inline no código."
                              ],
                              "crossCurricularConnections": [
                                "Física: Leis de Newton e gravitação universal.",
                                "Matemática: Vetores, integração numérica (Euler/Verlet).",
                                "Computação Gráfica: Renderização de trajetórias dinâmicas.",
                                "Análise de Dados: Visualização exploratória com Matplotlib."
                              ],
                              "realWorldApplication": "Desenvolvimento de simuladores astrofísicos como galáxias em formação (NASA), validação de modelos em jogos físicos (Unity/Unreal), ou previsão de trajetórias em sistemas de partículas como aerossóis em engenharia ambiental."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "64.3.1.2",
                        "name": "Paralelização via Decomposição de Domínio e Troca de Mensagens",
                        "description": "Aplicar decomposição espacial de domínio para distribuir partículas entre processos, utilizando troca de mensagens (MPI) para propagar forças de partículas vizinhas em memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "64.3.1.2.1",
                            "name": "Dividir domínio espacial em subdomínios",
                            "description": "Implementar decomposição de domínio 2D ou 3D, atribuindo partículas a processos baseados em posição e identificando regiões de halo para troca.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir o domínio espacial e método de decomposição",
                                  "subSteps": [
                                    "Identifique as dimensões do domínio (2D ou 3D) e limites (ex: caixa cúbica de lado L).",
                                    "Escolha o método de decomposição: uniforme em grid (ex: Nx x Ny x Nz células).",
                                    "Calcule o número de subdomínios baseado no número de processos (ex: raiz cúbica de P processos).",
                                    "Defina coordenadas globais para cada subdomínio (bounding box: xmin, xmax, ymin, ymax, etc.).",
                                    "Implemente funções para mapear posição global para subdomínio local."
                                  ],
                                  "verification": "Execute um teste imprimindo bounding boxes de todos os subdomínios; verifique se cobrem o domínio sem sobreposições ou lacunas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código base da simulação N-Corpos em C++ com MPI, editor de código, terminal com MPI instalado.",
                                  "tips": "Use MPI_Comm_size para obter número de processos e garanta divisibilidade para evitar subdomínios irregulares.",
                                  "learningObjective": "Compreender e implementar decomposição espacial uniforme para paralelização.",
                                  "commonMistakes": "Ignorar divisibilidade do número de processos, levando a subdomínios desbalanceados; confundir coordenadas locais com globais."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Atribuir partículas aos processos baseados em posição",
                                  "subSteps": [
                                    "Para cada partícula, compute seu subdomínio de destino usando posição (x,y,z) e bounding boxes.",
                                    "Crie listas locais de partículas para cada processo (vetor de partículas por rank).",
                                    "Implemente balanceamento de carga inicial contando partículas por subdomínio.",
                                    "Use MPI scatter ou loops para distribuir partículas do processo raiz para os locais.",
                                    "Verifique contagens de partículas por processo para balanceamento (ideal: ~N/P por processo)."
                                  ],
                                  "verification": "Imprima número de partículas por processo; deve ser aproximadamente igual e total somar N.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Código do Step 1, gerador de partículas aleatórias, MPI_Bcast para dados iniciais.",
                                  "tips": "Pré-calcule mapas de posição para subdomínio com funções hash ou divisão inteira para eficiência.",
                                  "learningObjective": "Mapear dados (partículas) para subdomínios de forma escalável e balanceada.",
                                  "commonMistakes": "Atribuição errada de partículas próximas à borda; não balanceamento levando a cargas desiguais."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar e definir regiões de halo para troca de mensagens",
                                  "subSteps": [
                                    "Defina largura do halo baseada no raio de interação (ex: halo = 2 * r_cut para forças N-Corpos).",
                                    "Para cada subdomínio, compute regiões de halo adjacentes (vizinhos 26 em 3D grid).",
                                    "Identifique partículas nos halos de cada processo (partículas locais dentro da região halo).",
                                    "Crie listas de envio/recebimento para cada par de processos vizinhos.",
                                    "Implemente MPI_Isend/MPI_Irecv para troca assíncrona de partículas halo."
                                  ],
                                  "verification": "Após troca, verifique se todas as partículas dentro do raio de interação estão disponíveis localmente em todos os processos.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Código dos Steps anteriores, MPI tags para diferentes vizinhos, debugger como gdb.",
                                  "tips": "Use stencil de vizinhança (Moore neighborhood) para 3D; armazene halos em buffers temporários para evitar cópias desnecessárias.",
                                  "learningObjective": "Gerenciar dependências espaciais via comunicação halo em domínios distribuídos.",
                                  "commonMistakes": "Halo muito estreito causando perda de interações; envios duplicados para vizinhos não adjacentes."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar decomposição e testar a simulação paralela completa",
                                  "subSteps": [
                                    "Integre passos de decomposição, atribuição e halo no loop principal de tempo da simulação.",
                                    "Execute com 4-8 processos e compare energia total conservada vs. serial.",
                                    "Meça speedup e eficiência (tempo por iteração vs. serial).",
                                    "Otimize comunicações minimizando volume de halo.",
                                    "Adicione checkpoint para salvar estado distribuído."
                                  ],
                                  "verification": "Simulação roda sem deadlocks, conservação de energia <1% erro, speedup >80% eficiência.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Código completo, cluster ou multi-core com mpirun, script para gerar gráficos de speedup.",
                                  "tips": "Use MPI_Wtime para profiling; teste com N pequeno primeiro (ex: 10k partículas).",
                                  "learningObjective": "Validar implementação de domínio decomposto em contexto de simulação N-Corpos.",
                                  "commonMistakes": "Deadlocks em trocas MPI; perda de partículas na redistribuição durante evolução."
                                }
                              ],
                              "practicalExample": "Em uma simulação 3D de 100.000 partículas em uma caixa [0,1]^3 com 8 processos, divida em grid 2x2x2. Cada subdomínio tem bounding box de lado 0.5. Halo de largura 0.1 captura partículas vizinhas para computar forças gravitacionais precisas.",
                              "finalVerifications": [
                                "Subdomínios cobrem domínio global sem gaps ou overlaps.",
                                "Número de partículas por processo balanceado (±10%).",
                                "Troca de halo inclui todas partículas dentro raio de corte.",
                                "Simulação paralela conserva momentum e energia como versão serial.",
                                "Tempo de comunicação <20% do tempo total de iteração.",
                                "Nenhuma perda ou duplicação de partículas após múltiplas iterações."
                              ],
                              "assessmentCriteria": [
                                "Precisão na decomposição espacial (bounding boxes corretas).",
                                "Balanceamento de carga efetivo (variação <15% em partículas/processo).",
                                "Eficiência de halo exchange (volume mínimo, assíncrono).",
                                "Escalabilidade demonstrada (speedup linear até 8 processos).",
                                "Robustez: sem erros MPI, deadlocks ou crashes.",
                                "Clareza e modularidade do código (funções separadas para cada step)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Geometria computacional e particionamento de malhas.",
                                "Física: Dinâmica de partículas e simulações gravitacionais.",
                                "Computação Gráfica: Renderização distribuída e LOD (Level of Detail).",
                                "Engenharia de Software: Design de sistemas distribuídos e profiling.",
                                "Ciência de Dados: Processamento paralelo de grandes datasets espaciais."
                              ],
                              "realWorldApplication": "Usado em simulações astrofísicas como GADGET para galáxias, CFD em aerodinâmica (NASA), e jogos multiplayer com mundos abertos (ex: particionamento de mapas em MMOs)."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.1.1"
                            ]
                          },
                          {
                            "id": "64.3.1.2.2",
                            "name": "Implementar troca de mensagens com MPI",
                            "description": "Usar MPI_Send, MPI_Recv ou MPI_Alltoall para trocar informações de partículas de halo entre processos vizinhos, evitando cálculos remotos desnecessários.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Inicializar MPI e decompor o domínio em subdomínios",
                                  "subSteps": [
                                    "Inclua as bibliotecas MPI necessárias (mpi.h) e inicialize MPI com MPI_Init.",
                                    "Obtenha o número de processos (MPI_Comm_size) e o rank do processo atual (MPI_Comm_rank).",
                                    "Defina a decomposição do domínio global em subdomínios locais baseados no rank, usando divisão uniforme em grades 1D ou 2D.",
                                    "Alocar arrays locais para partículas e halos usando MPI coordenadas para determinar tamanhos."
                                  ],
                                  "verification": "Verifique se todos os processos reportam ranks corretos e tamanhos de subdomínio via MPI_Barrier e printf com MPI rank.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Compilador MPI (mpicc)",
                                    "Código base de simulação N-corpos sequencial"
                                  ],
                                  "tips": "Use MPI_Wtime para medir tempos de inicialização e garantir sincronização inicial.",
                                  "learningObjective": "Entender inicialização de MPI e mapeamento de domínio global para local.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init antes de chamadas MPI",
                                    "Divisão incorreta de domínio levando a tamanhos desiguais"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar regiões de halo e processos vizinhos",
                                  "subSteps": [
                                    "Defina as larguras dos halos (ex: 1 célula em cada direção para vizinhos imediatos).",
                                    "Calcule índices de halo local: halo_esquerdo = 0 a halo_width, halo_direito = local_size - halo_width a local_size.",
                                    "Mapeie vizinhos: processo esquerdo = (rank - 1 + num_procs) % num_procs, direito similar.",
                                    "Crie estruturas de dados para armazenar partículas de halo (arrays ou structs).",
                                    "Copie partículas de halo dos subdomínios locais para buffers de envio."
                                  ],
                                  "verification": "Imprima tamanhos de halos e ranks de vizinhos em cada processo; confirme com visualização manual para 4 processos.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Documentação MPI para tags e comunadores",
                                    "Ferramenta de debug como gdb com mpirun"
                                  ],
                                  "tips": "Use tags únicas em mensagens para distinguir halos esquerdo/direito.",
                                  "learningObjective": "Mapear dependências espaciais para comunicação entre processos vizinhos.",
                                  "commonMistakes": [
                                    "Off-by-one em índices de halo",
                                    "Não considerar topologia toroidal para domínios periódicos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar envio e recebimento de mensagens com MPI_Send e MPI_Recv",
                                  "subSteps": [
                                    "Prepare buffers de envio com dados de partículas de halo (posição, velocidade, massa).",
                                    "Inicie MPI_Isend para vizinho esquerdo e direito (não-bloqueante para sobreposição).",
                                    "Inicie MPI_Irecv para receber de vizinhos correspondentes.",
                                    "Use MPI_Waitall para sincronizar envios/recebimentos pendentes.",
                                    "Copie dados recebidos para regiões de halo locais."
                                  ],
                                  "verification": "Compare dados de halo recebidos com valores esperados conhecidos; verifique ausência de deadlocks rodando com 2-8 processos.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Exemplos de código MPI point-to-point da documentação oficial"
                                  ],
                                  "tips": "Sempre use MPI_Request para rastrear requests não-bloqueantes e evitar perda de mensagens.",
                                  "learningObjective": "Executar comunicação assíncrona ponto-a-ponto para troca de halos.",
                                  "commonMistakes": [
                                    "Mismatch de tamanhos de buffer entre send/recv",
                                    "Esquecer MPI_Wait, causando corrupção de memória"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar troca na simulação e verificar corretude",
                                  "subSteps": [
                                    "Insira troca de halos antes do loop de cálculo de forças entre partículas.",
                                    "Atualize cálculos de força usando partículas locais + halos recebidos.",
                                    "Implemente MPI_Finalize no final.",
                                    "Compile e rode com mpirun -np 4; compare resultados com versão sequencial.",
                                    "Meça speedup e verifique conservação de energia/momento."
                                  ],
                                  "verification": "Resultados da simulação coincidem com sequencial (erro < 1e-6); sem crashes ou deadlocks.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Scripts de teste com partículas conhecidas",
                                    "Profiler como mpiP ou TAU"
                                  ],
                                  "tips": "Teste com grids pequenos primeiro (ex: 10x10) para debug visual.",
                                  "learningObjective": "Integrar comunicação em pipeline de simulação paralela.",
                                  "commonMistakes": [
                                    "Troca de halos após cálculos, causando dados obsoletos",
                                    "Não limpar halos após uso"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimizar com MPI_Alltoall para cenários avançados",
                                  "subSteps": [
                                    "Avalie se MPI_Alltoall é aplicável para trocas não-apenas-vizinhos.",
                                    "Prepare buffers de contagem e deslocamento com MPI_Alltoallv.",
                                    "Substitua pares Send/Recv por Alltoall para todos-vizinhos.",
                                    "Teste performance em mais processos (8-16).",
                                    "Compare tempos de comunicação."
                                  ],
                                  "verification": "Redução no tempo de comunicação >20% vs Send/Recv; corretude preservada.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Documentação MPI para coletivas"
                                  ],
                                  "tips": "Alltoall é eficiente para padrões regulares; fallback para point-to-point se irregular.",
                                  "learningObjective": "Escolher primitivas MPI otimizadas baseadas no padrão de comunicação.",
                                  "commonMistakes": [
                                    "Usar Alltoall sem necessidade, aumentando overhead"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação 2D de 1000 partículas em grade 10x10 dividida em 4 processos (2x2), cada processo envia 5 partículas de halo esquerdo/direito/superior/inferior usando MPI_Isend/Irecv com tag=1 para horizontal, tag=2 para vertical, garantindo forças calculadas corretamente sem duplicatas.",
                              "finalVerifications": [
                                "Código compila e roda sem erros com mpirun -np 2 a 8.",
                                "Dados de halo trocados corretamente (verificados por soma global via MPI_Reduce).",
                                "Ausência de deadlocks ou perdas de mensagens em runs longos (>1000 steps).",
                                "Conservação de propriedades físicas (energia, momento) dentro de 1e-5.",
                                "Speedup linear ou superlinear vs sequencial.",
                                "Memória não vaza (verificado com valgrind mpirun)."
                              ],
                              "assessmentCriteria": [
                                "Corretude: Halos atualizados antes de cálculos, sem ghost cells vazios.",
                                "Eficiência: Uso de comunicação não-bloqueante e mínima.",
                                "Escalabilidade: Funciona para num_procs variável.",
                                "Robustez: Trata bordas de domínio e topologias periódicas.",
                                "Clareza: Código comentado com explicação de tags e buffers.",
                                "Otimização: Escolha apropriada de Send/Recv vs Alltoall."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Conceitos de latência e bandwidth em interconexões.",
                                "Algoritmos e Estruturas de Dados: Decomposição de domínio como particionamento gráfico.",
                                "Física Computacional: Aplicações em dinâmica molecular e astrofísica.",
                                "Engenharia de Software: Gerenciamento de dependências em código paralelo.",
                                "Matemática Numérica: Acurácia em métodos de partículas."
                              ],
                              "realWorldApplication": "Simulações de N-corpos em supercomputadores para modelar galáxias (ex: GADGET code), dinâmica de fluidos computacional (CFD) com decomposição de malha, e machine learning distribuído para trocas de gradientes em clusters."
                            },
                            "estimatedTime": "4 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.1.1"
                            ]
                          },
                          {
                            "id": "64.3.1.2.3",
                            "name": "Otimizar cálculo de forças locais",
                            "description": "Calcular forças apenas entre partículas locais e de halo recebidas, reduzindo comunicação e mantendo precisão física.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir Domínios Locais e Regiões de Halo",
                                  "subSteps": [
                                    "Divida o espaço de simulação em domínios locais para cada processo usando decomposição de domínio espacial (ex: grid 2D ou 3D).",
                                    "Identifique as regiões de halo como camadas adjacentes aos domínios locais, considerando o raio de corte da força (cutoff radius).",
                                    "Calcule o tamanho do halo baseado no raio máximo de interação entre partículas.",
                                    "Implemente funções para mapear partículas para domínios e identificar quais pertencem ao halo.",
                                    "Visualize a decomposição usando ferramentas como matplotlib ou paraview para validar a divisão."
                                  ],
                                  "verification": "Verifique se cada domínio local contém apenas partículas atribuídas corretamente e halos são identificados sem sobreposições desnecessárias, usando logs ou plots.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código base de simulação N-corpos serial",
                                    "Bibliotecas MPI, NumPy, Matplotlib",
                                    "Documentação MPI para topologias"
                                  ],
                                  "tips": "Use um raio de corte fixo inicialmente para simplificar; ajuste dinamicamente depois.",
                                  "learningObjective": "Compreender e implementar decomposição de domínio com halos para minimizar comunicações.",
                                  "commonMistakes": [
                                    "Ignorar bordas periódicas levando a halos assimétricos",
                                    "Definir halo muito pequeno causando perda de precisão",
                                    "Não considerar migração de partículas entre domínios"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Cálculo de Forças Locais Incluindo Halo",
                                  "subSteps": [
                                    "Modifique a função de cálculo de forças para iterar apenas sobre partículas no domínio local e nas regiões de halo.",
                                    "Para cada partícula local, some forças de todas as partículas locais e halo (excluindo auto-interação).",
                                    "Otimize loops com NumPy vectorizado ou OpenMP para aceleração intra-nó.",
                                    "Armazene forças em buffers separados para locais e recebidas de halos.",
                                    "Teste serialmente comparando com cálculo global para validar precisão."
                                  ],
                                  "verification": "Compare forças calculadas localmente com versão serial/global; erro deve ser < 1e-6.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código do Step 1",
                                    "Função de força gravitacional ou Lennard-Jones",
                                    "Profiler como gprof ou Intel VTune"
                                  ],
                                  "tips": "Use cell-lists para acelerar buscas de vizinhos dentro do domínio + halo.",
                                  "learningObjective": "Calcular forças precisas usando apenas dados locais e halo, reduzindo computação desnecessária.",
                                  "commonMistakes": [
                                    "Incluir forças de partículas remotas não-halo",
                                    "Esquecer soma de forças de múltiplos halos",
                                    "Não normalizar forças por massa ou distância"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Integrar Troca de Mensagens para Dados de Halo",
                                  "subSteps": [
                                    "Use MPI_Sendrecv para trocar posições e velocidades de partículas halo entre processos vizinhos.",
                                    "Defina tags MPI específicas para cada direção de halo (ex: norte, sul, leste, oeste em 2D).",
                                    "Atualize buffers de halo após cada timestep antes do cálculo de forças.",
                                    "Implemente topologia cartesiana MPI para comunicação eficiente em grids.",
                                    "Meça latência de comunicação com MPI_Wtime."
                                  ],
                                  "verification": "Execute com 4-8 processos; verifique logs de tamanhos de mensagens e ausência de deadlocks.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Biblioteca MPI instalada",
                                    "Código dos Steps 1-2",
                                    "Cluster ou multi-core com MPI",
                                    "Scripts de compilação mpicc"
                                  ],
                                  "tips": "Combine envios em uma única fase 'halo exchange' para minimizar overhead de MPI.",
                                  "learningObjective": "Gerenciar comunicações assíncronas ou síncronas para dados de halo mantendo escalabilidade.",
                                  "commonMistakes": [
                                    "Enviar dados desatualizados",
                                    "Mismatch de tamanhos de buffers entre processos",
                                    "Não tratar condições de fronteira"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar Performance e Verificar Precisão Física",
                                  "subSteps": [
                                    "Profile o código com ferramentas como TAU ou Score-P para identificar gargalos em cálculo/forças vs comunicação.",
                                    "Reduza comunicações trocando apenas partículas dentro do raio de corte.",
                                    "Valide conservação de energia/momento comparando com serial.",
                                    "Escala weak/strong com np=1,4,16 processos medindo speedup.",
                                    "Ajuste tamanhos de domínio para balanceamento de carga."
                                  ],
                                  "verification": "Speedup > 80% do ideal; energia conservada dentro de 0.1%; plots de trajetórias coincidem com serial.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Profilers MPI (TAU, Vampir)",
                                    "Dados de benchmark N-corpos (ex: 10k-100k partículas)",
                                    "Hardware multi-nó"
                                  ],
                                  "tips": "Use non-blocking MPI_Isend/Irecv para sobrepor comunicação e computação.",
                                  "learningObjective": "Otimizar trade-off entre precisão, comunicação e computação em simulações paralelas.",
                                  "commonMistakes": [
                                    "Overhead de comunicação domina em domínios pequenos",
                                    "Perda de precisão por halo insuficiente",
                                    "Desbalanceamento de carga por partículas não-uniformes"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma simulação gravitacional N-corpos com 50.000 partículas em um cluster de 8 nós, divida em domínios 2D grid. Cada processo calcula forças de suas ~6.000 partículas locais + ~2.000 de halos vizinhos, trocando dados via MPI. Reduz comunicação de O(N^2) para O(N_local * halo_size), alcançando speedup de 6.5x com precisão mantida.",
                              "finalVerifications": [
                                "Cálculo de forças ignora partículas remotas não-halo.",
                                "Troca de halo ocorre corretamente sem perda de dados.",
                                "Energia total e momento conservados dentro de 0.1% vs serial.",
                                "Tempo de comunicação < 20% do total em runs escalados.",
                                "Trajetórias de partículas coincidem visualmente em plots.",
                                "Sem erros MPI ou crashes em 100 timesteps."
                              ],
                              "assessmentCriteria": [
                                "Implementação correta de domínios e halos (raio de corte respeitado).",
                                "Eficiência: redução >90% em pares de interações vs naive.",
                                "Escalabilidade: speedup linear até 16 processos.",
                                "Precisão física: erro relativo <1e-5 em forças.",
                                "Código limpo com comentários e funções modulares.",
                                "Relatório com profiles e benchmarks."
                              ],
                              "crossCurricularConnections": [
                                "Física: Leis de Newton e forças de longo alcance em simulações.",
                                "Matemática: Álgebra linear para vetores de força e decomposição espacial.",
                                "Computação: Algoritmos paralelos, análise de complexidade O(N log N) aproximado.",
                                "Engenharia de Software: Design de padrões como Domain Decomposition.",
                                "Ciência de Dados: Visualização e profiling de performance."
                              ],
                              "realWorldApplication": "Usado em simulações astrofísicas (ex: galáxias em GADGET code), dinâmica molecular (GROMACS para proteínas), e CFD (fluidos computacionais), onde escalabilidade em milhares de nós é crítica para modelar fenômenos reais como formação de estrelas ou folding de proteínas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "64.3.1.3",
                        "name": "Avaliação de Desempenho da Simulação Paralela",
                        "description": "Medir speedup, eficiência e escalabilidade da implementação paralela, analisando overhead de comunicação e balanceamento de carga em diferentes números de processos.",
                        "specificSkills": [
                          {
                            "id": "64.3.1.3.1",
                            "name": "Instrumentar código com MPI_Wtime",
                            "description": "Adicionar medições de tempo total, computacional e de comunicação usando funções MPI para coletar dados em múltiplas execuções.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e o código base para instrumentação MPI",
                                  "subSteps": [
                                    "Inclua o header <mpi.h> no código fonte da simulação N-corpos paralela.",
                                    "Inicialize o MPI com MPI_Init e obtenha o rank e size com MPI_Comm_rank e MPI_Comm_size.",
                                    "Identifique os pontos chave no código: início/fim da execução, loops computacionais e chamadas MPI (Send/Recv).",
                                    "Compile o código com mpicc para verificar se está pronto para instrumentação.",
                                    "Execute uma versão baseline sem instrumentação para obter tempos de referência."
                                  ],
                                  "verification": "Código compila sem erros com mpicc e executa corretamente produzindo saída esperada.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Código fonte da simulação N-corpos paralela",
                                    "Compilador MPI (mpicc)",
                                    "Manual MPI oficial"
                                  ],
                                  "tips": "Sempre use MPI_Wtick() para verificar a resolução do relógio antes de medir.",
                                  "learningObjective": "Configurar corretamente o ambiente MPI para medições precisas de tempo.",
                                  "commonMistakes": [
                                    "Esquecer de chamar MPI_Init antes de qualquer função MPI.",
                                    "Não finalizar com MPI_Finalize.",
                                    "Compilar sem flags MPI (-std=c99)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar medição de tempo total de execução",
                                  "subSteps": [
                                    "Declare variáveis double start_time, end_time no escopo principal.",
                                    "Registre start_time = MPI_Wtime() logo após MPI_Init.",
                                    "Registre end_time = MPI_Wtime() logo antes de MPI_Finalize.",
                                    "Calcule tempo_total = end_time - start_time no processo rank 0.",
                                    "Use MPI_Barrier(MPI_COMM_WORLD) antes de end_time para sincronizar todos os processos."
                                  ],
                                  "verification": "Execute com mpirun -np 4 e verifique se tempo_total é impresso apenas pelo rank 0 e é consistente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código do Step 1 instrumentado",
                                    "mpirun para execução paralela"
                                  ],
                                  "tips": "MPI_Wtime retorna tempo em segundos desde algum ponto arbitrário; use diferenças para intervalos.",
                                  "learningObjective": "Medir o tempo wall-clock total de uma aplicação paralela usando MPI_Wtime.",
                                  "commonMistakes": [
                                    "Não sincronizar processos com MPI_Barrier, causando tempos inconsistentes.",
                                    "Imprimir tempo em todos os ranks sem redução.",
                                    "Confundir MPI_Wtime com MPI_Wtick (este é só para resolução)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Instrumentar tempo computacional (excluindo comunicação)",
                                  "subSteps": [
                                    "Declare variáveis double comp_start, comp_end para tempo computacional.",
                                    "Identifique os loops principais de cálculo (ex: força gravitacional em N-corpos).",
                                    "Registre comp_start = MPI_Wtime() antes do loop computacional.",
                                    "Registre comp_end = MPI_Wtime() após o loop, excluindo seções MPI.",
                                    "Calcule tempo_comp = comp_end - comp_start e some sobre iterações de simulação."
                                  ],
                                  "verification": "Compare tempo_comp com tempo_total; deve ser menor e positivo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código instrumentado dos steps anteriores",
                                    "Debugger como gdb com MPI support"
                                  ],
                                  "tips": "Meça apenas código sequencial local; isole bem seções de comunicação.",
                                  "learningObjective": "Isolar e medir o tempo gasto em computação pura por processo.",
                                  "commonMistakes": [
                                    "Incluir acidentalmente chamadas MPI no intervalo comp.",
                                    "Não resetar contadores por timestep da simulação.",
                                    "Ignorar overhead de MPI_Wtime em loops apertados."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Instrumentar tempo de comunicação",
                                  "subSteps": [
                                    "Declare double comm_start, comm_end.",
                                    "Envolva todas as chamadas MPI_Isend, MPI_Irecv, MPI_Wait em um bloco.",
                                    "Registre comm_start antes das postagens de MPI_Isend/Irecv.",
                                    "Registre comm_end após MPI_Waitall para completar.",
                                    "Calcule tempo_comm = comm_end - comm_start e acumule por timestep."
                                  ],
                                  "verification": "tempo_comp + tempo_comm deve aproximar tempo_total (permitir overhead pequeno).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código com tempos total e comp",
                                    "Documentação MPI para non-blocking collectives"
                                  ],
                                  "tips": "Use non-blocking MPI para sobrepor comm e comp quando possível, mas meça separadamente.",
                                  "learningObjective": "Quantificar overhead de comunicação em aplicações paralelas.",
                                  "commonMistakes": [
                                    "Medir apenas MPI_Send/Recv síncronos, ignorando asíncronos.",
                                    "Não esperar completude com MPI_Wait.",
                                    "Atribuir tempo de espera à comunicação incorretamente."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Coletar dados de múltiplas execuções e reportar estatísticas",
                                  "subSteps": [
                                    "Crie um loop externo para executar a simulação N vezes (ex: 10 runs).",
                                    "Use MPI_Reduce para coletar tempos de todos ranks no rank 0 (MPI_MAX, MPI_MIN, MPI_SUM).",
                                    "Calcule médias e desvios padrão dos tempos total, comp e comm.",
                                    "Imprima relatório final com tabela de médias por número de processos.",
                                    "Salve dados em arquivo CSV para análise posterior."
                                  ],
                                  "verification": "Execute 5 runs; verifique se médias são estáveis e desvios baixos (<5%).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código fully instrumentado",
                                    "Script bash para múltiplas mpirun",
                                    "Ferramentas como awk/python para análise"
                                  ],
                                  "tips": "Aqueça o sistema com 2 runs iniciais para estabilizar cache.",
                                  "learningObjective": "Realizar profiling estatístico robusto em cenários paralelos variáveis.",
                                  "commonMistakes": [
                                    "Não usar MPI_Reduce para agregação, perdendo dados de ranks.",
                                    "Executar runs sem variar np ou input size.",
                                    "Ignorar variância em relatórios."
                                  ]
                                }
                              ],
                              "practicalExample": "Na simulação N-corpos paralela, adicione MPI_Wtime() após MPI_Init para start_total, antes/depois do loop de forças para comp_time, e em volta de MPI_Alltoallv para exchange de posições para comm_time. Execute com mpirun -np 8 ./nbody 10000 1000, coletando 10 runs e reportando: Avg total=2.45s, comp=1.89s, comm=0.45s.",
                              "finalVerifications": [
                                "Código compila e executa sem crashes em múltiplos np (2-16).",
                                "Tempos total >= comp + comm com overhead <10%.",
                                "Relatório de 10 runs mostra média estável e std dev <5%.",
                                "Dados salvos em CSV com colunas: np, run, total, comp, comm.",
                                "Rank 0 imprime resumo; outros silenciosos.",
                                "MPI_Finalize chamado corretamente após todas medições."
                              ],
                              "assessmentCriteria": [
                                "Uso correto e consistente de MPI_Wtime para todos intervalos.",
                                "Separação precisa entre tempos total, computacional e comunicação.",
                                "Coleta estatística de múltiplas execuções com agregação MPI.",
                                "Sincronização adequada com MPI_Barrier onde necessário.",
                                "Relatório claro e reproduzível com desvios padrão.",
                                "Código limpo, comentado e modular."
                              ],
                              "crossCurricularConnections": [
                                "Análise de Dados: Cálculo de médias, desvios e visualização de perfis.",
                                "Matemática Computacional: Modelagem de speedup e eficiência paralela.",
                                "Engenharia de Software: Práticas de profiling e debugging em escala.",
                                "Sistemas Operacionais: Entendimento de scheduling e overheads de processo.",
                                "Física Computacional: Otimização de simulações numéricas."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, instrumentar códigos como GROMACS ou LAMMPS com MPI_Wtime para identificar gargalos de comunicação vs. computação, guiando refatorações para escalabilidade em milhares de cores, essencial em pesquisa climática, drug discovery e astrofísica."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.2.2"
                            ]
                          },
                          {
                            "id": "64.3.1.3.2",
                            "name": "Calcular métricas de desempenho",
                            "description": "Computar speedup (T_seq / T_par), eficiência (speedup / P) e analisar Lei de Gustafson ou Amdahl para prever escalabilidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coletar e medir tempos de execução sequencial e paralelo",
                                  "subSteps": [
                                    "Execute a versão sequencial da simulação N-Corpos com um conjunto de dados fixo (ex: 1000 partículas).",
                                    "Registre o tempo total de execução T_seq usando ferramentas de profiling como time ou gprof.",
                                    "Execute a versão paralela com diferentes números de processadores/threads (P=1,2,4,8).",
                                    "Registre os tempos T_par para cada configuração de P.",
                                    "Repita as medições 5 vezes por configuração e calcule a média para reduzir variância."
                                  ],
                                  "verification": "Tabela com T_seq e T_par médios para cada P, com desvios padrão abaixo de 5%.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código fonte sequencial e paralelo",
                                    "Ambiente de execução (Linux/Mac com compilador MPI/OpenMP)",
                                    "Ferramentas: time, gprof ou perf"
                                  ],
                                  "tips": "Desative interferências como antivirus ou outros processos para medições precisas.",
                                  "learningObjective": "Compreender como medir tempos de execução de forma confiável em contextos paralelos.",
                                  "commonMistakes": [
                                    "Não repetir medições (leva a resultados inconsistentes)",
                                    "Incluir tempo de inicialização no T_par",
                                    "Usar tamanhos de input variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular speedup e eficiência",
                                  "subSteps": [
                                    "Calcule speedup para cada P: S(P) = T_seq / T_par(P).",
                                    "Verifique se S(1) ≈ 1 para validar a medição.",
                                    "Calcule eficiência: E(P) = S(P) / P, expressa em porcentagem.",
                                    "Plote gráficos de S(P) vs P e E(P) vs P usando Python/Matplotlib.",
                                    "Identifique o speedup máximo e o ponto de saturação."
                                  ],
                                  "verification": "Gráficos plotados com speedup >1 para P>1 e eficiência <100%.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dados de tempo coletados",
                                    "Python com NumPy/Matplotlib ou Excel"
                                  ],
                                  "tips": "Use log escala no eixo Y para visualizar saturação em altos P.",
                                  "learningObjective": "Dominar fórmulas de speedup e eficiência e sua interpretação gráfica.",
                                  "commonMistakes": [
                                    "Inverter fórmula de speedup (T_par / T_seq)",
                                    "Esquecer de dividir por P na eficiência",
                                    "Ignorar overhead de comunicação"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Lei de Amdahl e Gustafson para análise",
                                  "subSteps": [
                                    "Estime a fração serial f da Lei de Amdahl ajustando S(P) = 1 / (f + (1-f)/P) para dados reais.",
                                    "Calcule limite de speedup pela Amdahl: 1/f.",
                                    "Aplique Lei de Gustafson: S(P) = P - f*(P-1), assumindo escalabilidade forte/fraca.",
                                    "Compare predições das leis com seus dados experimentais.",
                                    "Discuta quando usar Amdahl (problemas fixos) vs Gustafson (problemas escaláveis)."
                                  ],
                                  "verification": "Relatório com f estimado, limites preditos e comparação tabular/gráfica com dados.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dados de speedup",
                                    "Ferramentas de ajuste: Python SciPy curve_fit ou solver manual"
                                  ],
                                  "tips": "Comece com P pequenos para estimar f com precisão.",
                                  "learningObjective": "Analisar limites teóricos de escalabilidade usando leis clássicas.",
                                  "commonMistakes": [
                                    "Confundir Amdahl (escala forte) com Gustafson (escala fraca)",
                                    "Usar f=0 sem validação",
                                    "Não plotar curvas teóricas vs experimentais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Prever escalabilidade e interpretar resultados",
                                  "subSteps": [
                                    "Preveja desempenho para P maiores (ex: 16,32) baseado nas leis.",
                                    "Identifique gargalos (serial, comunicação) dos gráficos.",
                                    "Sugira otimizações baseadas na análise (reduzir f, balancear carga).",
                                    "Documente conclusões em um relatório com tabelas e gráficos.",
                                    "Valide predições executando para P alto se possível."
                                  ],
                                  "verification": "Relatório final com predições, gargalos identificados e sugestões acionáveis.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resultados anteriores",
                                    "Editor de texto para relatório"
                                  ],
                                  "tips": "Foque em insights qualitativos além dos números.",
                                  "learningObjective": "Integrar métricas e leis para previsões práticas de escalabilidade.",
                                  "commonMistakes": [
                                    "Ignorar overhead real não capturado pelas leis",
                                    "Predições otimistas sem dados de validação",
                                    "Relatório sem visualizações"
                                  ]
                                }
                              ],
                              "practicalExample": "Na simulação N-Corpos com 4096 partículas: T_seq=120s, T_par(P=4)=35s → speedup=3.43, eficiência=85.75%. Usando Amdahl com f=0.1, limite=10x; Gustafson prevê melhor escalabilidade para inputs maiores.",
                              "finalVerifications": [
                                "Speedup e eficiência calculados corretamente para todos P testados.",
                                "Gráficos de S(P) e E(P) mostram tendências realistas (sublineares).",
                                "f estimado da Amdahl ajusta dados com erro <10%.",
                                "Comparação Amdahl vs Gustafson discute aplicabilidade.",
                                "Relatório prevê escalabilidade para P=16 com justificativa.",
                                "Gargalos identificados com evidências dos dados."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos (erro <1% nas fórmulas básicas).",
                                "Qualidade dos gráficos e visualizações (legendas, escalas adequadas).",
                                "Correta estimação e interpretação de f (Amdahl).",
                                "Análise comparativa das leis com dados experimentais.",
                                "Sugestões de otimização baseadas em evidências.",
                                "Clareza e completude do relatório final."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Modelagem não-linear e ajuste de curvas.",
                                "Física: Simulações computacionais de dinâmica de partículas.",
                                "Engenharia de Software: Profiling e otimização de performance.",
                                "Estatística: Análise de variância em medições repetidas."
                              ],
                              "realWorldApplication": "Em supercomputadores para simulações climáticas ou astrofísica (ex: Millennium Simulation), otimizar código paralelo prevendo escalabilidade antes de alocar milhares de nós caros."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.3.1"
                            ]
                          },
                          {
                            "id": "64.3.1.3.3",
                            "name": "Plotar gráficos de escalabilidade",
                            "description": "Gerar curvas de speedup vs. número de processos e identificar gargalos como comunicação excessiva ou desbalanceamento.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coletar dados de desempenho da simulação paralela",
                                  "subSteps": [
                                    "Execute a simulação N-corpos serial para obter o tempo de referência T1.",
                                    "Execute a versão paralela com 1, 2, 4, 8 e 16 processos, registrando o tempo de execução Tp para cada configuração.",
                                    "Registre métricas adicionais como tempo de comunicação e carga por processo usando ferramentas como MPI profiling.",
                                    "Salve os dados em um arquivo CSV com colunas: num_processos, tempo_execucao, tempo_comunicacao.",
                                    "Repita as execuções 3-5 vezes por configuração para calcular médias e desvios padrão."
                                  ],
                                  "verification": "Verifique se o CSV contém dados consistentes para pelo menos 5 configurações de processos, com médias calculadas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código da simulação N-corpos (MPI/OpenMP), cluster ou máquina multi-core, ferramenta de profiling (ex: MPI_Wtime), planilha ou script Python para CSV.",
                                  "tips": "Use seeds fixas para reprodutibilidade e execute em condições idênticas (mesmo hardware, sem interferências).",
                                  "learningObjective": "Entender como coletar dados empíricos confiáveis para análise de escalabilidade.",
                                  "commonMistakes": "Ignorar variabilidade (não repetir execuções), usar hardware inconsistente, esquecer tempo serial como baseline."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular métricas de speedup e eficiência",
                                  "subSteps": [
                                    "Calcule speedup S(p) = T1 / Tp para cada número de processos p.",
                                    "Calcule eficiência E(p) = S(p) / p para avaliar perda de performance.",
                                    "Identifique métricas de gargalo: razão comunicação/computação = tempo_comunicacao / (Tp - tempo_comunicacao).",
                                    "Adicione colunas ao CSV: speedup, eficiencia, ratio_comunicacao.",
                                    "Visualize dados preliminarmente com scatter plot para detectar outliers."
                                  ],
                                  "verification": "Confirme cálculos com fórmula manual para p=2 e verifique se S(1)=1 e E(1)=1.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Arquivo CSV de dados, Python com Pandas/NumPy ou Excel.",
                                  "tips": "Automatize cálculos em script para evitar erros manuais; use log-scale se ranges amplos.",
                                  "learningObjective": "Dominar fórmulas padrão de análise de desempenho paralelo (Amdahl's law implícita).",
                                  "commonMistakes": "Usar Tp como baseline em vez de T1, ignorar overheads de inicialização, arredondamentos errados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerar curvas de escalabilidade",
                                  "subSteps": [
                                    "Carregue dados no Matplotlib/Seaborn ou GNUPlot.",
                                    "Plote speedup vs. número de processos (linha ideal y=p para comparação).",
                                    "Adicione plot de eficiência e ratio comunicação em subplot ou eixo secundário.",
                                    "Configure eixos: log para processos, labels claros, grid, legenda.",
                                    "Salve gráfico em alta resolução como PNG/PDF com título descritivo."
                                  ],
                                  "verification": "Gráfico mostra speedup sub-linear se gargalos presentes; valide contra dados manuais.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (Matplotlib, Pandas), Jupyter Notebook ou script .py.",
                                  "tips": "Use plt.semilogx() para eixo x logarítmico; inclua barras de erro para variabilidade.",
                                  "learningObjective": "Criar visualizações profissionais de dados de desempenho.",
                                  "commonMistakes": "Escalas lineares inadequadas, falta de linha ideal, legenda ausente."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar gráfico e identificar gargalos",
                                  "subSteps": [
                                    "Observe desvio da linha ideal: platô indica desbalanceamento de carga.",
                                    "Picos no ratio comunicação sugerem gargalos de rede (comunicação excessiva).",
                                    "Compare com lei de Amdahl: estime fração paralelizável f = 1 / S_max.",
                                    "Documente achados em relatório: 'Speedup estagna em p=8 devido a 40% tempo em MPI_Allreduce'.",
                                    "Proponha otimizações: particionamento melhor, reduzir all-to-all."
                                  ],
                                  "verification": "Relatório lista pelo menos 2 gargalos com evidências do gráfico e sugestões.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Gráfico gerado, editor de texto ou Markdown para relatório.",
                                  "tips": "Anote coordenadas exatas de platôs; valide com profiling detalhado.",
                                  "learningObjective": "Interpretar visualizações para diagnósticos de performance.",
                                  "commonMistakes": "Atribuir gargalos sem evidência quantitativa, ignorar eficiência."
                                }
                              ],
                              "practicalExample": "Na simulação N-corpos com 10.000 partículas usando MPI, colete tempos: T1=120s (serial), Tp=65s(p=2), 40s(p=4), 35s(p=8), 38s(p=16). Calcule S=[1,1.85,3.0,3.43,3.16]. Plote speedup: sobe até p=8, platô em p=16 devido a desbalanceamento (partículas irregulares) e comunicação em MPI_Allgather (30% do tempo).",
                              "finalVerifications": [
                                "CSV com dados completos e cálculos corretos de speedup/eficiência.",
                                "Gráfico de speedup vs. processos com linha ideal e elementos visuais claros.",
                                "Identificação explícita de pelo menos um gargalo (ex: comunicação ou balanceamento).",
                                "Relatório com interpretação quantitativa e sugestões de melhoria.",
                                "Reprodutibilidade: script roda e gera gráfico idêntico.",
                                "Gráfico salvo em formato profissional (PNG/PDF alta resolução)."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos de speedup (erro <1%).",
                                "Qualidade visual do gráfico (legibilidade, escalas adequadas, legenda).",
                                "Profundidade da análise de gargalos (evidências + quantificação).",
                                "Conexão com teoria (referência a Amdahl/Gustafson).",
                                "Clareza e estrutura do relatório final.",
                                "Uso correto de ferramentas e reprodutibilidade."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Funções logarítmicas e modelagem de curvas de crescimento.",
                                "Estatística: Cálculo de médias, desvios padrão e análise de variância em dados empíricos.",
                                "Engenharia de Software: Profiling e otimização de código.",
                                "Física/Computação Científica: Simulações numéricas e análise de performance em HPC.",
                                "Visualização de Dados: Técnicas de plotting e storytelling com gráficos."
                              ],
                              "realWorldApplication": "Em centros de supercomputação como o Argonne National Lab, engenheiros usam esses gráficos para otimizar simulações climáticas ou astrofísicas em milhares de nós, identificando gargalos para reduzir tempo de simulação de dias para horas, economizando energia e custos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.3.2"
                            ]
                          },
                          {
                            "id": "64.3.1.3.4",
                            "name": "Comparar com aproximações como Barnes-Hut",
                            "description": "Discutir limitações do O(N²) e introduzir brevemente algoritmos hierárquicos para simulações maiores, avaliando trade-offs.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender as limitações do algoritmo O(N²) em simulações N-corpos",
                                  "subSteps": [
                                    "Calcule a complexidade temporal do algoritmo força bruta O(N²) para diferentes valores de N (ex: N=100, 1000, 10000).",
                                    "Discuta o gargalo computacional: cada partícula interage com todas as outras, levando a escalabilidade pobre.",
                                    "Analise o impacto em simulações paralelas: overhead de comunicação em arquiteturas distribuídas.",
                                    "Compare tempo de execução teórico vs prático em hardware real.",
                                    "Identifique cenários onde O(N²) é viável (N pequeno) vs inviável (N grande)."
                                  ],
                                  "verification": "Crie um gráfico ou tabela mostrando tempo de execução vs N, confirmando escalabilidade quadrática.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha ou Python para simulações simples",
                                    "Gráficos de complexidade assintótica (Big O)"
                                  ],
                                  "tips": "Use log-log plots para visualizar claramente a escalabilidade quadrática.",
                                  "learningObjective": "Compreender por que O(N²) falha para simulações grandes e seu impacto em paralelismo.",
                                  "commonMistakes": "Ignorar custos de memória ou assumir paralelismo perfeito elimina o problema."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir conceitos de algoritmos hierárquicos e o Barnes-Hut",
                                  "subSteps": [
                                    "Explique a ideia de aproximação: agrupar partículas distantes em 'superpartículas' para reduzir interações.",
                                    "Descreva a estrutura de árvore quad (quadtree) usada no Barnes-Hut para particionar o espaço.",
                                    "Apresente a heurística de aceitação: θ = d/s < threshold, onde d é distância ao centro e s é tamanho da célula.",
                                    "Discuta a complexidade média O(N log N) vs pior caso O(N²).",
                                    "Compare com Fast Multipole Method (FMM) brevemente para contexto."
                                  ],
                                  "verification": "Desenhe um quadtree simples para 10 partículas e aplique a heurística θ em um exemplo.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Artigos introdutórios sobre Barnes-Hut (ex: original de Barnes & Hut 1986)",
                                    "Visualizadores online de quadtrees"
                                  ],
                                  "tips": "Comece com 2D para simplicidade antes de estender para 3D.",
                                  "learningObjective": "Dominar os fundamentos hierárquicos que reduzem complexidade de O(N²) para O(N log N).",
                                  "commonMistakes": "Confundir complexidade média com garantida, ignorando casos patológicos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e testar uma versão simplificada do Barnes-Hut",
                                  "subSteps": [
                                    "Escreva código para construir um quadtree a partir de posições de partículas.",
                                    "Implemente o traversal da árvore para calcular forças aproximadas por partícula.",
                                    "Execute simulação com N=1000 e compare tempo/força com O(N²).",
                                    "Ajuste parâmetro θ e meça trade-off precisão vs velocidade.",
                                    "Paralelize o traversal usando OpenMP ou MPI para contexto de programação paralela."
                                  ],
                                  "verification": "Gere relatório com tempos de execução, erro relativo de forças e speedup.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Biblioteca NumPy/SciPy em Python",
                                    "Código template de N-corpos disponível online"
                                  ],
                                  "tips": "Use θ=0.5 inicialmente; valide contra O(N²) exato para pequenas N.",
                                  "learningObjective": "Aplicar Barnes-Hut na prática e observar ganhos reais.",
                                  "commonMistakes": "Erro na construção do quadtree levando a células vazias ou sobreposições."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar trade-offs e comparações entre O(N²) e Barnes-Hut",
                                  "subSteps": [
                                    "Compare métricas: tempo, precisão, memória, escalabilidade paralela.",
                                    "Discuta trade-offs: perda de precisão em colisões próximas vs ganhos em N grande.",
                                    "Analise em contextos paralelos: balanceamento de carga no Barnes-Hut vs all-to-all em O(N²).",
                                    "Avalie cenários ideais: O(N²) para precisão alta/N baixo; Barnes-Hut para N>10k.",
                                    "Conclua com recomendações para simulações reais."
                                  ],
                                  "verification": "Escreva um relatório de 1 página resumindo prós/contras com dados numéricos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Resultados das simulações anteriores",
                                    "Tabelas de comparação pré-formatadas"
                                  ],
                                  "tips": "Use métricas normalizadas (ex: tempo por iteração por partícula) para comparações justas.",
                                  "learningObjective": "Criticar objetivamente as abordagens e escolher baseado em requisitos.",
                                  "commonMistakes": "Superestimar precisão do Barnes-Hut sem validação empírica."
                                }
                              ],
                              "practicalExample": "Em uma simulação de aglomerado estelar com 50.000 estrelas (N=50k), o O(N²) leva 10 horas em um cluster de 64 núcleos, enquanto Barnes-Hut com θ=0.6 reduz para 20 minutos com erro <1% nas órbitas, permitindo estudos de evolução galáctica em tempo real.",
                              "finalVerifications": [
                                "Explicar verbalmente limitações O(N²) e como Barnes-Hut as resolve.",
                                "Demonstrar construção manual de quadtree para 8 partículas.",
                                "Apresentar resultados de simulação comparativa com gráficos.",
                                "Discutir trade-offs numéricos (ex: speedup 100x com perda 0.5%).",
                                "Identificar quando usar cada método em projetos paralelos.",
                                "Comparar Barnes-Hut com FMM em uma frase precisa."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição da complexidade O(N log N) e heurística θ.",
                                "Qualidade dos experimentos: dados empíricos vs teoria.",
                                "Análise equilibrada de trade-offs (precisão vs velocidade).",
                                "Integração com paralelismo: discussão de overheads.",
                                "Clareza na comunicação: gráficos e exemplos concretos.",
                                "Profundidade: menção a extensões 3D ou adaptações paralelas."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Estruturas de dados espaciais (quadtrees, KD-trees).",
                                "Física: Dinâmica N-corpos em astrofísica e mecânica de fluidos.",
                                "Engenharia de Software: Otimização de algoritmos e profiling.",
                                "Computação Gráfica: Simulações de partículas em jogos e VFX."
                              ],
                              "realWorldApplication": "Usado em softwares como GADGET para simulações cosmológicas, permitindo modelar a formação de galáxias com bilhões de partículas em supercomputadores, essencial para pesquisa em astrofísica e previsão climática via partículas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "64.3.1.1.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.3",
                    "name": "Estudo de Caso: Transformada Rápida de Fourier (FFT)",
                    "description": "Implementação paralela da FFT para processamento de sinais, explorando modelos de memória compartilhada com OpenMP.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.3.1",
                        "name": "Fundamentos da Transformada Rápida de Fourier (FFT)",
                        "description": "Compreensão do algoritmo sequencial da FFT baseado no método Cooley-Tukey, sua complexidade computacional O(n log n) e aplicação no processamento de sinais, preparando o terreno para paralelização.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.1.1",
                            "name": "Implementar FFT sequencial",
                            "description": "Codificar a versão sequencial da FFT recursiva ou iterativa para vetores de tamanho potência de 2, manipulando índices bit-reversos e fatores de twiddle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Implementar a função de reversão de bits (bit-reversal)",
                                  "subSteps": [
                                    "Estude o conceito de reversão de bits para índices em representação binária.",
                                    "Escreva uma função que recebe um inteiro k e o log2(N), retornando o índice bit-reverso.",
                                    "Teste a função para N=8 com k=0 a 7, verificando saídas como rev(0)=0, rev(1)=4, etc.",
                                    "Integre a função para permutar um array de teste.",
                                    "Otimize para evitar loops desnecessários usando shifts binários."
                                  ],
                                  "verification": "Execute testes unitários: para N=8, a permutação deve transformar [0,1,2,3,4,5,6,7] em [0,4,2,6,1,5,3,7].",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Editor de código (VS Code ou similar)",
                                    "Python 3 com complex built-in",
                                    "Biblioteca unittest para testes"
                                  ],
                                  "tips": "Use operações bitwise (>> e <<) para eficiência ao invés de strings binárias.",
                                  "learningObjective": "Dominar manipulação de índices bit-reversos essenciais para a estrutura da FFT.",
                                  "commonMistakes": [
                                    "Confundir o número de bits (use log2(N))",
                                    "Não tratar N=1 ou N=2 corretamente",
                                    "Ignorar overflow em linguagens de 32 bits"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar fatores de twiddle (twiddle factors)",
                                  "subSteps": [
                                    "Revise a fórmula do twiddle factor: exp(-2πi * k / (2^m)) para estágio m e k.",
                                    "Implemente uma função que gera uma tabela de twiddles pré-computados para todos os estágios.",
                                    "Use números complexos nativos da linguagem (ex: complex em Python ou std::complex em C++).",
                                    "Teste para N=4: twiddles devem incluir 1, -i, -1, i.",
                                    "Armazene em array 1D ou 2D para acesso rápido."
                                  ],
                                  "verification": "Para N=4, imprima twiddles e confirme valores unitários (|w| ≈ 1) e ângulos corretos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de números complexos da linguagem",
                                    "Calculadora para validar fórmulas manuais"
                                  ],
                                  "tips": "Pré-compute todos os twiddles para evitar recálculos caros na execução.",
                                  "learningObjective": "Compreender e codificar os coeficientes rotacionais da DFT decimada.",
                                  "commonMistakes": [
                                    "Sinal errado no expoente (- vs +)",
                                    "Dividir por 2^l em vez de 2^m",
                                    "Não normalizar magnitudes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a permutação bit-reversal e as operações butterfly",
                                  "subSteps": [
                                    "Copie o vetor de entrada e aplique bit-reversal usando a função do step 1.",
                                    "Implemente o loop principal: para cada estágio s=1 a log2(N), para cada grupo e borboleta.",
                                    "Na borboleta: X[k] = a + w*b, X[k+m] = a - w*b, onde m= N/(2^s).",
                                    "Atualize in-place para eficiência de memória.",
                                    "Adicione logs para depurar valores intermediários."
                                  ],
                                  "verification": "Para input [1,1,1,1] N=4, saída deve ser [4, 0, 0, 0] (up to scaling).",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "Papel e lápis para simular FFT manual N=8",
                                    "Debugger do IDE"
                                  ],
                                  "tips": "Desenhe o fluxo de dados (butterfly diagram) para N=8 antes de codificar.",
                                  "learningObjective": "Construir o algoritmo Cooley-Tukey iterativo in-place.",
                                  "commonMistakes": [
                                    "Índices errados nas borboletas (k e k+m)",
                                    "Atualização fora de ordem causando sobrescrita",
                                    "Fator de escala esquecido (divida por N se necessário)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar a FFT completa, testar e otimizar",
                                  "subSteps": [
                                    "Crie a função fft_sequential(input_vector) que chama todas as partes anteriores.",
                                    "Teste com vetores conhecidos: DC [1,0,0,0], sinusóide simples.",
                                    "Compare com DFT ingênua ou biblioteca (numpy.fft para validação).",
                                    "Meça tempo de execução para N=1024 e confirme O(N log N).",
                                    "Adicione tratamento de erros (tamanho não potência de 2)."
                                  ],
                                  "verification": "Erro relativo < 1e-10 comparado a implementação conhecida para N=16.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Numpy para validação (apenas testes)",
                                    "Timer (timeit em Python)"
                                  ],
                                  "tips": "Comece com N pequeno e dobre gradualmente para depurar.",
                                  "learningObjective": "Validar implementação sequencial como base para paralela.",
                                  "commonMistakes": [
                                    "Não bit-reversar antes das borboletas",
                                    "Twiddles com fase errada",
                                    "Falta de scaling na saída"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente fft_sequential([1+0j, 0j, 0j, 0j, 0j, 0j, 0j, 0j]) para N=8; a saída deve concentrar energia no bin 0 (valor ~8+0j), demonstrando detecção de componente DC em sinal constante.",
                              "finalVerifications": [
                                "Função processa corretamente vetores de tamanho 2^k (k=1 a 10).",
                                "Bit-reversal permutation é identidade para N=1 e correta para N=4/8.",
                                "Magnitudes dos twiddles são unitárias (erro <1e-12).",
                                "Saída matches DFT para sinais sinusoidais simples.",
                                "Execução sem crashes ou NaNs para inputs reais/imaginários.",
                                "Tempo escala como N log N (teste N=256 vs 1024)."
                              ],
                              "assessmentCriteria": [
                                "Correção numérica: erro L2 < 1e-10 vs referência.",
                                "Eficiência: complexidade O(N log N) confirmada empiricamente.",
                                "Código modular: funções separadas para bit-rev e twiddles.",
                                "Robustez: valida tamanho potência de 2 e trata edge cases.",
                                "Documentação: comentários explicando fórmulas e loops.",
                                "Legibilidade: nomes variáveis intuitivos (ex: twiddle, butterfly)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Séries de Fourier e números complexos.",
                                "Física: Análise espectral de ondas e sinais.",
                                "Engenharia Elétrica: Processamento digital de sinais (DSP).",
                                "Ciência da Computação: Algoritmos divide-and-conquer.",
                                "Áudio/Imagens: Bibliotecas como FFTW baseadas nisso."
                              ],
                              "realWorldApplication": "Essencial em processamento de áudio (MP3, equalizadores), análise de imagens (JPEG, MRI), telecomunicações (modulação OFDM em 5G) e simulações científicas (espectroscopia)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.1.2",
                            "name": "Analisar complexidade da FFT",
                            "description": "Calcular e comparar a complexidade temporal e espacial da FFT versus DFT direta, identificando gargalos computacionais para paralelização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Complexidade da DFT Direta",
                                  "subSteps": [
                                    "Estude a definição matemática da DFT: X[k] = sum_{n=0}^{N-1} x[n] * exp(-2πi k n / N).",
                                    "Conte o número de operações: N multiplicações complexas e N-1 adições por cada um dos N coeficientes de saída.",
                                    "Calcule complexidade temporal: O(N^2) operações aritméticas.",
                                    "Analise complexidade espacial: O(N) para entrada e saída, mais O(1) auxiliares.",
                                    "Implemente uma DFT simples em pseudocódigo para visualizar loops aninhados."
                                  ],
                                  "verification": "Escreva a fórmula de complexidade temporal e espacial da DFT e justifique com contagem de operações.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Notas de aula sobre DFT",
                                    "Pseudocódigo editor (ex: Jupyter Notebook)",
                                    "Calculadora ou papel para contagens"
                                  ],
                                  "tips": [
                                    "Comece contando operações para N=4 manualmente para intuitar O(N^2).",
                                    "Use twiddle factors para identificar multiplicações complexas."
                                  ],
                                  "learningObjective": "Compreender e quantificar a ineficiência computacional da DFT direta.",
                                  "commonMistakes": [
                                    "Confundir adições com multiplicações no count.",
                                    "Ignorar que exp() é pré-computável mas ainda custa O(N^2)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender a Decomposição Recursiva da FFT",
                                  "subSteps": [
                                    "Aprenda o algoritmo Cooley-Tukey: divida DFT de tamanho N em duas DFTs de N/2 (par e ímpar).",
                                    "Desenhe o butterfly diagram para N=8, mostrando recursão.",
                                    "Identifique twiddle factors e como eles reduzem redundâncias.",
                                    "Trace a recursão: T(N) = 2 T(N/2) + O(N).",
                                    "Explique por que isso leva a divide-and-conquer."
                                  ],
                                  "verification": "Desenhe o fluxo de dados (butterfly) para N=4 e rotule twiddle factors.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Diagrama de FFT impresso ou online",
                                    "Ferramenta de desenho (ex: Draw.io)",
                                    "Vídeo tutorial Cooley-Tukey (Khan Academy ou similar)"
                                  ],
                                  "tips": [
                                    "Visualize recursão com potências de 2 primeiro.",
                                    "Lembre: bit-reversal é para ordenação, não afeta complexidade assintótica."
                                  ],
                                  "learningObjective": "Dominar a estrutura recursiva que permite eficiência na FFT.",
                                  "commonMistakes": [
                                    "Confundir DFT com FFT na base.",
                                    "Esquecer o custo O(N) na combinação das sub-DFTs."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Complexidade Temporal e Espacial da FFT",
                                  "subSteps": [
                                    "Resolva a recorrência: T(N) = 2 T(N/2) + N → O(N log N) usando Master Theorem.",
                                    "Conte operações: ~5 N log N flops (2 real mult + 2 real add por butterfly).",
                                    "Analise espacial: O(N) para arrays in-place, ou O(N log N) out-of-place.",
                                    "Compare graficamente O(N^2) vs O(N log N) para N=1024.",
                                    "Implemente contadores de flops em código FFT simples."
                                  ],
                                  "verification": "Forneça prova da recorrência e plote curvas de complexidade.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Livro 'Numerical Recipes' capítulo FFT",
                                    "Python/MATLAB para plotar",
                                    "Solver de recorrências online"
                                  ],
                                  "tips": [
                                    "Use log2(N) para stages, N/2 butterflies por stage.",
                                    "In-place reduz espaço mas complica código."
                                  ],
                                  "learningObjective": "Quantificar precisamente as melhorias da FFT.",
                                  "commonMistakes": [
                                    "Contar log N errado (é lg N stages).",
                                    "Ignorar constantes como 5N log N."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar e Identificar Gargalos para Paralelização",
                                  "subSteps": [
                                    "Tabela comparativa: DFT O(N^2) time/espaço vs FFT O(N log N)/O(N).",
                                    "Identifique dependências: butterflies independentes em stages.",
                                    "Gargalos DFT: loops serializados; FFT: stages paralelizáveis.",
                                    "Discuta speedup teórico: N/ log N em hardware paralelo.",
                                    "Simule em pseudocódigo paralelo (ex: stages em threads)."
                                  ],
                                  "verification": "Crie tabela de comparação e liste 3 gargalos paralelizáveis na FFT.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Planilha Excel/Google Sheets para tabelas",
                                    "Pseudocódigo paralelo",
                                    "Artigo sobre parallel FFT"
                                  ],
                                  "tips": [
                                    "Foco em data dependencies entre stages.",
                                    "Considere GPU para butterflies massivos."
                                  ],
                                  "learningObjective": "Analisar trade-offs e oportunidades de paralelismo.",
                                  "commonMistakes": [
                                    "Superestimar paralelismo ignorando comunicações.",
                                    "Confundir complexidade com speedup prático."
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente DFT e FFT para N=1024 em Python (usando numpy.fft para validar), meça tempos de execução, compare complexidades plotando tempo vs N, e identifique como paralelizar stages da FFT com multiprocessing.",
                              "finalVerifications": [
                                "Calcula corretamente O(N^2) para DFT e O(N log N) para FFT.",
                                "Desenha butterfly diagram preciso para N=8.",
                                "Lista pelo menos 3 gargalos computacionais na DFT ausentes na FFT.",
                                "Explica recursão Cooley-Tukey verbalmente.",
                                "Compara speedup potencial em cenários paralelos.",
                                "Identifica quando FFT in-place é preferível."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas contagens de operações (temporal/espaço).",
                                "Correta aplicação do Master Theorem.",
                                "Qualidade do diagrama butterfly e análise de dependências.",
                                "Profundidade na identificação de gargalos para paralelização.",
                                "Clareza na tabela comparativa e exemplos práticos.",
                                "Capacidade de relacionar teoria a implementações reais."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Resolução de recorrências e análise assintótica (Big O).",
                                "Física: Processamento de sinais em ondas sonoras ou eletromagnéticas.",
                                "Engenharia de Computação: Arquiteturas paralelas (GPU, MPI).",
                                "Algoritmos e Estruturas de Dados: Divide-and-conquer paradigms.",
                                "Processamento de Imagens: Aplicações em MRI e filtros convolucionais."
                              ],
                              "realWorldApplication": "Em telecomunicações, FFT acelera OFDM em 5G (reduz latência de N^2 para N log N); em áudio, habilita equalizadores em tempo real; em IA, acelera convoluções em redes neurais via FFT para processamento de imagens."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.1.3",
                            "name": "Aplicar FFT em sinais reais",
                            "description": "Processar sinais de áudio ou imagem simples com FFT sequencial, visualizando espectros de frequência com bibliotecas como FFTW ou implementação manual.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar ambiente e carregar sinal real",
                                  "subSteps": [
                                    "Instalar bibliotecas necessárias como NumPy, SciPy e Matplotlib.",
                                    "Selecionar e baixar um sinal real simples, como um arquivo WAV de áudio ou imagem PNG.",
                                    "Carregar o sinal em um array NumPy, normalizando os valores.",
                                    "Visualizar o sinal no domínio do tempo ou espaço para confirmação inicial.",
                                    "Verificar dimensões e amostragem do sinal."
                                  ],
                                  "verification": "Sinal carregado e plotado corretamente sem erros ou distorções visíveis.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python 3.x",
                                    "NumPy",
                                    "SciPy",
                                    "Matplotlib",
                                    "Arquivo WAV ou PNG de teste (ex: tom puro de 440Hz)"
                                  ],
                                  "tips": "Use scipy.io.wavfile para áudio e matplotlib.pyplot para plots iniciais.",
                                  "learningObjective": "Configurar ambiente e manipular dados reais de sinal.",
                                  "commonMistakes": "Ignorar normalização de dados, levando a overflows; não verificar taxa de amostragem."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar FFT sequencial",
                                  "subSteps": [
                                    "Estudar algoritmo Cooley-Tukey para FFT sequencial.",
                                    "Implementar FFT manual recursiva ou iterativa para vetores de tamanho potência de 2.",
                                    "Alternativamente, usar biblioteca como numpy.fft.fft para comparação.",
                                    "Testar implementação com sinal sintético conhecido (ex: senoide).",
                                    "Comparar resultados com FFT analítica para validação."
                                  ],
                                  "verification": "FFT de sinal teste produz espectro idêntico ao esperado (pico na frequência correta).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código Python",
                                    "NumPy para testes",
                                    "Documentação FFTW ou numpy.fft"
                                  ],
                                  "tips": "Garanta que N seja potência de 2 com zero-padding se necessário.",
                                  "learningObjective": "Compreender e codificar o algoritmo FFT sequencial.",
                                  "commonMistakes": "Erro no bit-reversal ou na combinação de butterflies; confundir forward/inverse."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar FFT ao sinal real",
                                  "subSteps": [
                                    "Preparar sinal real com padding para tamanho potência de 2.",
                                    "Executar FFT sequencial no sinal carregado.",
                                    "Calcular magnitude do espectro (|X[k]| = sqrt(Re^2 + Im^2)).",
                                    "Aplicar janela (ex: Hamming) para reduzir leakage se aplicável.",
                                    "Computar frequências correspondentes (f = k * fs / N)."
                                  ],
                                  "verification": "Magnitude do espectro varia monotonicamente e sem valores NaN.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código da Step 2",
                                    "Sinal da Step 1",
                                    "NumPy para cálculos"
                                  ],
                                  "tips": "Divida sinal longo em segmentos para análise espectral.",
                                  "learningObjective": "Processar sinal real com FFT sequencial.",
                                  "commonMistakes": "Esquecer de dividir por N na magnitude; aliasing por falta de padding."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Visualizar e interpretar espectro",
                                  "subSteps": [
                                    "Plotar espectro de magnitude vs frequência em escala logarítmica.",
                                    "Identificar picos principais e harmônicos no espectro.",
                                    "Comparar com sinal original para validar.",
                                    "Adicionar anotações para frequências chave.",
                                    "Exportar plot e espectro para relatório."
                                  ],
                                  "verification": "Gráfico mostra picos coerentes com o sinal real (ex: fundamental em áudio).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Matplotlib",
                                    "Código das steps anteriores"
                                  ],
                                  "tips": "Use plt.xscale('log') para melhor visualização de espectros.",
                                  "learningObjective": "Analisar e visualizar resultados de FFT.",
                                  "commonMistakes": "Escala linear em vez de log; rotular eixo de frequência errado."
                                }
                              ],
                              "practicalExample": "Carregue um arquivo WAV de uma nota 'A' (440Hz), aplique FFT sequencial, visualize espectro mostrando pico em 440Hz e harmônicos, confirmando pureza tonal.",
                              "finalVerifications": [
                                "Sinal processado sem erros numéricos.",
                                "Espectro exibe picos nas frequências esperadas.",
                                "Visualização clara com eixos corretos.",
                                "Tempo de execução razoável para sinal de 10s.",
                                "Resultados reproduzíveis em múltiplas execuções.",
                                "Comparação com numpy.fft.fft idêntica dentro de 1e-10."
                              ],
                              "assessmentCriteria": [
                                "Precisão do espectro (erro < 1%).",
                                "Eficiência da implementação sequencial.",
                                "Clareza e legibilidade dos plots.",
                                "Correta manipulação de dados reais.",
                                "Validação com testes unitários.",
                                "Documentação de código inline."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Séries de Fourier e transformadas.",
                                "Física: Análise de ondas e vibrações sonoras.",
                                "Engenharia Elétrica: Processamento digital de sinais.",
                                "Ciência da Computação: Algoritmos recursivos e otimização."
                              ],
                              "realWorldApplication": "Análise de áudio em equalizadores e compressores MP3; detecção de falhas em vibrações mecânicas; processamento de imagens em filtros de ruído e MRI médica."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.3.2",
                        "name": "Estratégias de Paralelização da FFT",
                        "description": "Exploração de decomposição de domínio e estágios independentes na FFT, considerando modelos de memória compartilhada e taxonomia de Flynn (SIMD/MIMD).",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.2.1",
                            "name": "Identificar paralelismo na FFT",
                            "description": "Mapear dependências de dados nos estágios da FFT butterfly, identificando loops independentes para decomposição de domínio em memória compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Estrutura do Diagrama Butterfly da FFT",
                                  "subSteps": [
                                    "Estudar o algoritmo Cooley-Tukey para FFT radix-2.",
                                    "Desenhar o diagrama butterfly para uma FFT de tamanho N=8 (3 estágios).",
                                    "Identificar os fatores de rotação (twiddle factors) em cada estágio.",
                                    "Marcar as entradas e saídas de cada nó butterfly.",
                                    "Explicar o fluxo de dados de entrada para saída."
                                  ],
                                  "verification": "Diagrama butterfly desenhado corretamente com todos os twiddle factors e fluxos de dados anotados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta ou software de diagramação (ex: Draw.io)",
                                    "Referência ao pseudocódigo da FFT Cooley-Tukey"
                                  ],
                                  "tips": "Comece com N=4 para simplicidade antes de N=8; use cores para diferenciar estágios.",
                                  "learningObjective": "Dominar a topologia de dados da FFT para análise posterior de dependências.",
                                  "commonMistakes": [
                                    "Confundir a ordem dos estágios (inverter bit-reversal)",
                                    "Ignorar a dependência nos twiddle factors entre estágios"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Mapear Dependências de Dados nos Estágios da FFT",
                                  "subSteps": [
                                    "Analisar o primeiro estágio: identificar dependências entre pares de entradas.",
                                    "Mapear dependências inter-estágios: saídas de um estágio alimentam o próximo.",
                                    "Usar setas direcionadas no diagrama para representar read-after-write (RAW) dependências.",
                                    "Listar todas as dependências de dados para cada nó butterfly.",
                                    "Verificar se há dependências intra-estágio (dentro do mesmo estágio)."
                                  ],
                                  "verification": "Mapa de dependências completo com setas e legendas no diagrama butterfly.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Diagrama butterfly do Step 1",
                                    "Folha de anotação para dependências"
                                  ],
                                  "tips": "Use notação de análise de dependências (ex: RAW, WAR, WAW) para clareza.",
                                  "learningObjective": "Identificar precisamente as dependências de dados que limitam o paralelismo.",
                                  "commonMistakes": [
                                    "Assumir independência entre butterflies de estágios adjacentes",
                                    "Esquecer dependências condicionais via twiddles"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar Operações e Loops Independentes para Paralelismo",
                                  "subSteps": [
                                    "Observar que dentro de cada estágio, os butterflies são independentes (sem dependências intra-estágio).",
                                    "Identificar loops sobre grupos de butterflies em um estágio (ex: loop de N/2 operações).",
                                    "Marcar loops independentes: um por estágio, executáveis em paralelo.",
                                    "Calcular o grau de paralelismo: até N/2 threads por estágio.",
                                    "Simular execução sequencial vs. paralela para um estágio."
                                  ],
                                  "verification": "Lista de loops independentes identificados, com grau de paralelismo calculado para cada estágio.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Mapa de dependências do Step 2",
                                    "Pseudocódigo de FFT com loops destacados"
                                  ],
                                  "tips": "Pense em termos de wavefront: estágios sequenciais, mas paralelos internamente.",
                                  "learningObjective": "Reconhecer padrões de paralelismo coarse-grained na estrutura da FFT.",
                                  "commonMistakes": [
                                    "Confundir independência intra-estágio com inter-estágio",
                                    "Superestimar paralelismo ignorando bit-reversal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Identificação de Paralelismo para Decomposição de Domínio em Memória Compartilhada",
                                  "subSteps": [
                                    "Escolher decomposição de domínio: dividir o loop de saída ou o array de entrada.",
                                    "Atribuir subdomínios independentes a threads (ex: cada thread um butterfly por estágio).",
                                    "Discutir sincronização necessária entre estágios (barreiras).",
                                    "Implementar pseudocódigo paralelo para um estágio usando OpenMP ou similar.",
                                    "Avaliar overheads: carga de trabalho balanceada e acesso à memória compartilhada."
                                  ],
                                  "verification": "Pseudocódigo paralelo escrito com decomposição de domínio e pontos de sincronização.",
                                  "estimatedTime": "55 minutos",
                                  "materials": [
                                    "Pseudocódigo sequencial da FFT",
                                    "Documentação de OpenMP para #pragma omp parallel for"
                                  ],
                                  "tips": "Use schedule(dynamic) para balanceamento em domínios irregulares.",
                                  "learningObjective": "Mapear paralelismo identificado para estratégias práticas em arquiteturas compartilhadas.",
                                  "commonMistakes": [
                                    "Esquecer barreiras entre estágios",
                                    "Criar falsos compartilhamentos desnecessários"
                                  ]
                                }
                              ],
                              "practicalExample": "Para uma FFT de 16 pontos (4 estágios), desenhe o butterfly, mapeie dependências mostrando que no estágio 1 há 8 butterflies independentes. Identifique o loop 'for k=0 to 7 { butterfly(input[2*k], input[2*k+1]) }' como paralelizável com 8 threads em memória compartilhada, sincronizando via barreira antes do estágio 2.",
                              "finalVerifications": [
                                "Diagrama butterfly com dependências mapeadas corretamente para N>=8.",
                                "Identificação precisa de loops independentes em pelo menos 3 estágios.",
                                "Pseudocódigo paralelo com decomposição de domínio funcional.",
                                "Cálculo correto do grau de paralelismo (ex: N/2 por estágio).",
                                "Explicação de sincronizações necessárias entre estágios.",
                                "Análise de balanceamento de carga sem sobrecarga significativa."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de dependências RAW inter-estágio (100% corretas).",
                                "Correta detecção de independência intra-estágio em todos os loops.",
                                "Qualidade do pseudocódigo paralelo: compilável e sem race conditions.",
                                "Profundidade da análise de decomposição de domínio (cobertura de overheads).",
                                "Clareza das visualizações (diagramas legíveis e anotados).",
                                "Capacidade de generalizar para tamanhos N arbitrários (potências de 2)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e transformadas discretas (DFT).",
                                "Engenharia de Computação: Arquiteturas paralelas e programação GPU (CUDA/OpenCL).",
                                "Processamento de Sinais: Análise espectral em áudio e imagens.",
                                "Algoritmos: Análise assintótica de paralelismo (work-depth model)."
                              ],
                              "realWorldApplication": "Em processamento de sinais em tempo real, como análise de espectro em radares ou compressão de áudio em smartphones, identificar paralelismo na FFT permite acelerações de 10-100x em GPUs, otimizando memória compartilhada para grandes datasets (ex: MRI médica ou streaming de vídeo)."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.6.3.2.2",
                            "name": "Aplicar decomposição de domínio",
                            "description": "Dividir o vetor de entrada em subproblemas independentes para estágios da FFT, gerenciando sincronização e exclusão mútua em acessos compartilhados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar a estrutura algorítmica da FFT para identificar pontos de decomposição",
                                  "subSteps": [
                                    "Estude o algoritmo Cooley-Tukey da FFT, focando nos estágios de butterflies e padrões de acesso aos dados.",
                                    "Identifique as dependências entre elementos do vetor de entrada nos diferentes estágios.",
                                    "Desenhe um diagrama representando o fluxo de dados e os pontos onde subproblemas podem ser independentes.",
                                    "Determine o tamanho do vetor (potência de 2) e o número de processos/threads disponíveis.",
                                    "Liste os acessos compartilhados potenciais, como tabelas de twiddle factors."
                                  ],
                                  "verification": "Diagrama completo desenhado e anotado com pontos de independência e dependências.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Documentação do algoritmo FFT (Wikipedia ou livros como Cormen), papel/caneta ou ferramenta de diagramação como Draw.io.",
                                  "tips": "Comece com um exemplo pequeno (N=8) para visualizar os butterflies manualmente.",
                                  "learningObjective": "Compreender as dependências de dados na FFT para delimitar subproblemas independentes.",
                                  "commonMistakes": "Assumir independência total entre estágios sem analisar os butterflies cruzados."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Dividir o vetor de entrada em subproblemas independentes por domínio",
                                  "subSteps": [
                                    "Calcule o tamanho de cada sub-vetor baseado no número de processos (ex: N/p para p processos).",
                                    "Atribua sub-vetores contíguos a cada processo/thread, preservando alinhamento para FFT local.",
                                    "Prepare dados locais para cada subproblema, copiando porções relevantes do vetor global.",
                                    "Defina comunicação inicial para distribuir o vetor de entrada (scatter em MPI).",
                                    "Verifique se a divisão mantém a estrutura radix-2 da FFT."
                                  ],
                                  "verification": "Código ou pseudocódigo escrito distribuindo o vetor corretamente, testado com print de sub-vetores.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Ambiente de programação paralela (MPI/OpenMP), editor de código (VSCode), vetor de teste pequeno.",
                                  "tips": "Use índices modulares para mapear domínios e evite sobreposições desnecessárias.",
                                  "learningObjective": "Mapear o domínio de dados em subproblemas paralelizáveis sem perda de informação.",
                                  "commonMistakes": "Dividir em tamanhos não-potências de 2, quebrando a recursão da FFT."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar processamento paralelo nos subproblemas com FFT local",
                                  "subSteps": [
                                    "Implemente FFT sequencial em cada sub-vetor local usando uma biblioteca ou código radix-2.",
                                    "Execute butterflies locais em paralelo nos subproblemas independentes.",
                                    "Combine resultados locais considerando transposições ou rearranjos entre estágios.",
                                    "Otimize acessos locais para cache-friendly (bit-reversal ou stockham formulation).",
                                    "Teste a FFT local em cada domínio com sinal conhecido (ex: senoide)."
                                  ],
                                  "verification": "Cada processo/thread produz FFT correta de seu sub-vetor, comparada à sequencial.",
                                  "estimatedTime": "4 horas",
                                  "materials": "Biblioteca FFT (FFTW ou implementação própria), compilador com suporte MPI/OpenMP.",
                                  "tips": "Use formulações out-of-place para evitar conflitos de memória durante butterflies.",
                                  "learningObjective": "Executar computação autônoma em domínios paralelos com precisão numérica.",
                                  "commonMistakes": "Ignorar normalização ou fatores de twiddle incorretos nos subproblemas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Gerenciar sincronização e exclusão mútua em acessos compartilhados",
                                  "subSteps": [
                                    "Identifique pontos de sincronização entre estágios (barreiras após cada fase de butterflies).",
                                    "Implemente comunicação all-to-all ou transpose para dados entre domínios.",
                                    "Use locks ou atomic operations para acessos compartilhados (ex: buffer global de resultados).",
                                    "Colete resultados finais com gather/reduce para reconstruir FFT global.",
                                    "Meça overhead de sincronização e otimize com pipelining se possível."
                                  ],
                                  "verification": "Execução paralela completa sem deadlocks ou race conditions, resultados corretos.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Profiler de paralelismo (Intel VTune ou gprof), hardware multi-core/cluster.",
                                  "tips": "Minimize comunicações usando decomposição 1D e barreiras coletivas eficientes.",
                                  "learningObjective": "Garantir corretude e performance com mecanismos de sincronização adequados.",
                                  "commonMistakes": "Excesso de locks causando gargalos ou esquecimento de barreiras entre estágios."
                                }
                              ],
                              "practicalExample": "Em um vetor de 1024 pontos representando um sinal de áudio, divida em 4 sub-vetores de 256 pontos cada para 4 threads OpenMP. Cada thread computa FFT local nos estágios iniciais, sincroniza com barrier(), e troca dados via array compartilhado com atomic updates para combinar frequências globais, resultando em speedup de 3.5x.",
                              "finalVerifications": [
                                "FFT paralela produz espectro idêntico à versão sequencial (erro L2 < 1e-12).",
                                "Execução sem erros de sincronização ou deadlocks em múltiplas runs.",
                                "Speedup linear observado com aumento de threads/processos.",
                                "Memória utilizada dentro de limites esperados por domínio.",
                                "Perfil mostra balanceamento de carga entre domínios (>90%).",
                                "Teste com sinal real (ex: áudio) preserva fidelidade espectral."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica da FFT global (erro relativo < 1e-10).",
                                "Eficiência de decomposição (speedup > número de domínios - overhead).",
                                "Uso correto de sincronização sem race conditions.",
                                "Escalabilidade com tamanhos de vetor crescentes (N até 2^20).",
                                "Código limpo com comentários sobre domínios e locks.",
                                "Otimização de comunicações minimizada."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise de Fourier e álgebra linear paralela.",
                                "Física: Processamento de sinais e ondas em telecomunicações.",
                                "Engenharia de Software: Design de algoritmos distribuídos.",
                                "Ciência da Computação: Otimização de alto desempenho (HPC)."
                              ],
                              "realWorldApplication": "Em processamento de imagens médicas, como tomografia computadorizada, onde FFT paralela por decomposição de domínio acelera reconstruções 3D em GPUs, reduzindo tempo de diagnóstico de horas para minutos em scanners hospitalares."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.6.3.2.3",
                            "name": "Avaliar modelos de memória compartilhada",
                            "description": "Comparar uniform e não-uniform memory access (UMA/NUMA) no contexto da FFT, prevendo impactos em desempenho paralelo.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Básicos de UMA e NUMA",
                                  "subSteps": [
                                    "Defina memória compartilhada e seus modelos de acesso: UMA (Uniform Memory Access) e NUMA (Non-Uniform Memory Access).",
                                    "Estude a arquitetura UMA: todos os processadores acessam a memória com o mesmo tempo de latência.",
                                    "Analise a arquitetura NUMA: tempos de acesso variam dependendo da proximidade do nó de memória local.",
                                    "Identifique componentes chave como nós locais/remotos, interconexões e caches em sistemas NUMA.",
                                    "Revise exemplos de hardware: UMA em sistemas single-socket, NUMA em multi-socket como servidores AMD EPYC."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as diferenças entre UMA e NUMA com diagramas simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação Intel/AMD sobre arquiteturas NUMA",
                                    "Ferramenta numactl para Linux",
                                    "Diagramas de arquitetura de memória"
                                  ],
                                  "tips": "Use ferramentas como 'numactl --hardware' para visualizar topologia NUMA no seu sistema.",
                                  "learningObjective": "Diferenciar precisamente UMA e NUMA e suas implicações em latência de acesso.",
                                  "commonMistakes": "Confundir NUMA com DMA (Direct Memory Access) ou ignorar o impacto de caches hierárquicos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Revisar Paralelização da FFT e Dependências de Memória",
                                  "subSteps": [
                                    "Recapitule o algoritmo FFT sequencial e suas versões paralelas (ex: Cooley-Tukey).",
                                    "Identifique padrões de acesso à memória na FFT: acessos locais vs. globais em estágios de butterfly.",
                                    "Analise como threads/processos compartilham arrays de entrada/saída em programação paralela (OpenMP/MPI).",
                                    "Discuta contenda de memória (false sharing) e locality em implementações paralelas.",
                                    "Examine métricas de performance: tempo de execução, bandwidth de memória e escalabilidade."
                                  ],
                                  "verification": "Desenhe um grafo de dependências de memória para uma FFT de tamanho 1024 com 4 threads.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código fonte FFT em C/OpenMP",
                                    "Livro 'Parallel Programming in C with MPI and OpenMP'",
                                    "Profiler como VTune ou gprof"
                                  ],
                                  "tips": "Compile e rode uma FFT simples com 'omp_get_wtime()' para medir tempos iniciais.",
                                  "learningObjective": "Mapear padrões de acesso à memória na FFT paralela e suas vulnerabilidades a modelos de memória.",
                                  "commonMistakes": "Subestimar acessos não-locais nos estágios iniciais/finais da FFT."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Impactos de UMA vs NUMA na Performance da FFT",
                                  "subSteps": [
                                    "Simule UMA: assuma latência uniforme e meça performance em máquina single-socket.",
                                    "Simule NUMA: use affinity de threads para núcleos remotos e observe degradação.",
                                    "Meça métricas: throughput de FFT, overhead de migração de páginas e taxa de hits de cache.",
                                    "Compare curvas de escalabilidade: speedup vs. número de threads em UMA vs NUMA.",
                                    "Analise bottlenecks: contenda em barramentos compartilhados vs. hops de interconexão NUMA."
                                  ],
                                  "verification": "Gere gráficos comparativos de tempo de execução para 2-16 threads em cenários UMA/NUMA.",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Ambiente Linux com numactl",
                                    "Código FFT paralelizado",
                                    "Ferramentas de profiling: likwid ou perf"
                                  ],
                                  "tips": "Fixe threads com 'numactl --cpunodebind=0 --membind=0' para simular locality.",
                                  "learningObjective": "Quantificar empiricamente os impactos de UMA/NUMA na FFT paralela.",
                                  "commonMistakes": "Não pinnear threads adequadamente, levando a resultados inconsistentes."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Prever e Otimizar Desempenho Baseado em Modelos de Memória",
                                  "subSteps": [
                                    "Preveja cenários: FFT em cluster NUMA vs. máquina UMA para tamanhos N=2^20.",
                                    "Proponha otimizações NUMA-aware: alocação de memória local, padding para evitar false sharing.",
                                    "Avalie trade-offs: custo de migração vs. ganho de locality.",
                                    "Documente previsões vs. resultados reais em um relatório.",
                                    "Teste otimizações e valide melhorias de performance."
                                  ],
                                  "verification": "Escreva um relatório de 1 página com previsões validadas e otimizações sugeridas.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Código otimizado NUMA",
                                    "Benchmark scripts",
                                    "Templates de relatório"
                                  ],
                                  "tips": "Use 'numa_alloc_local()' ou OpenMP 'OMP_PROC_BIND=close' para otimizações.",
                                  "learningObjective": "Prever impactos futuros e propor soluções para desempenho paralelo em diferentes arquiteturas.",
                                  "commonMistakes": "Ignorar overhead de inicialização NUMA em benchmarks curtos."
                                }
                              ],
                              "practicalExample": "Implemente uma FFT 1D de tamanho 2^18 usando OpenMP em um servidor dual-socket NUMA. Rode sem pinning (baseline UMA-like), com pinning remoto (pior NUMA) e pinning local (otimizado). Meça tempos: baseline 1.2s, remoto 3.5s (+192%), otimizado 0.8s (-33%).",
                              "finalVerifications": [
                                "Explicar corretamente diferenças UMA/NUMA com exemplos de hardware.",
                                "Identificar padrões de memória problemáticos na FFT paralela.",
                                "Apresentar dados empíricos comparando performance em UMA vs NUMA.",
                                "Propor pelo menos 2 otimizações NUMA-aware com justificativa.",
                                "Prever corretamente impacto em escalabilidade para N>2^20.",
                                "Demonstrar uso de ferramentas como numactl em demo ao vivo."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (20%): Definições e diferenças UMA/NUMA corretas.",
                                "Análise empírica (30%): Dados de benchmarks válidos e gráficos claros.",
                                "Profundidade de impacto (20%): Correlação precisa com FFT paralela.",
                                "Previsões e otimizações (20%): Realistas e baseadas em evidências.",
                                "Clareza e estrutura (10%): Relatório organizado com verificações."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Estudo de hierarquias de cache e interconexões.",
                                "Otimização de Algoritmos: Técnicas de locality e data-oriented design.",
                                "Sistemas Operacionais: Gerenciamento de memória NUMA e scheduling de threads.",
                                "Processamento de Sinais: Aplicações reais de FFT em HPC."
                              ],
                              "realWorldApplication": "Em supercomputadores como os do TOP500, otimizar FFT NUMA-aware acelera simulações sísmicas, processamento de imagens médicas (MRI) e modelagem climática, reduzindo tempo de jobs de horas para minutos em clusters multi-nó."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.3.3",
                        "name": "Implementação Paralela com OpenMP",
                        "description": "Uso de diretivas OpenMP para paralelizar a FFT em plataformas multicores, focando em memória compartilhada, tasking e affinity.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.3.1",
                            "name": "Paralelizar loops com #pragma omp parallel for",
                            "description": "Aplicar diretivas OpenMP em loops de estágios da FFT, gerenciando redução de resultados complexos e schedule dinâmico para balanceamento de carga.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e analisar o código sequencial de FFT",
                                  "subSteps": [
                                    "Instale o compilador com suporte a OpenMP (ex: gcc com -fopenmp).",
                                    "Obtenha ou crie um código sequencial de FFT radix-2 para array de complexos.",
                                    "Identifique os loops principais (estágios da FFT) candidatos a paralelização.",
                                    "Meça o tempo de execução sequencial com múltiplos tamanhos de input (potências de 2).",
                                    "Registre o número de threads disponíveis no sistema com omp_get_num_procs()."
                                  ],
                                  "verification": "Código sequencial compila e executa corretamente, produzindo resultados idênticos a uma biblioteca de referência como FFTW.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Compilador GCC/Clang com OpenMP, código fonte sequencial de FFT (C/C++), timer de alta resolução (gettimeofday ou std::chrono).",
                                  "tips": "Use tamanhos de N=2^10 a 2^20 para testar escalabilidade.",
                                  "learningObjective": "Compreender a estrutura sequencial da FFT para identificar oportunidades de paralelismo.",
                                  "commonMistakes": "Ignorar alinhamento de memória para complexos ou usar tamanhos não-potência de 2."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar #pragma omp parallel for ao loop de estágios da FFT",
                                  "subSteps": [
                                    "Inclua <omp.h> e inicialize OpenMP com omp_set_num_threads(4) ou variável de ambiente OMP_NUM_THREADS.",
                                    "Adicione #pragma omp parallel for ao loop externo dos estágios (butterflies).",
                                    "Garanta independência de iterações: cada thread processa um estágio independentemente.",
                                    "Compile com -fopenmp e execute com 1, 2, 4 threads, medindo tempo.",
                                    "Verifique correção comparando saída com versão sequencial."
                                  ],
                                  "verification": "Execução paralela produz resultados bit-identicos à sequencial e speedup >1x.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código do Step 1, terminal para setar OMP_NUM_THREADS, valgrind ou debugger para checar races.",
                                  "tips": "Coloque o pragma apenas em loops com muitas iterações para overhead baixo.",
                                  "learningObjective": "Implementar paralelismo loop-level básico com OpenMP.",
                                  "commonMistakes": "Esquecer de declarar variáveis shared/private, causando data races."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerenciar reduções de resultados complexos em loops paralelos",
                                  "subSteps": [
                                    "Identifique operações de redução (ex: soma de magnitudes ou acumulação de espectro).",
                                    "Use #pragma omp parallel for reduction(+:real_part, imag_part) para complexos customizados.",
                                    "Defina estruturas complexas com operadores +/* ou use std::complex com redução manual.",
                                    "Teste com partial sums por thread e combine no final.",
                                    "Valide precisão numérica com epsilon (1e-10) contra sequencial."
                                  ],
                                  "verification": "Resultados de redução paralela coincidem com sequencial dentro de tolerância numérica.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Código dos steps anteriores, biblioteca <complex> ou custom struct, script para diff de saídas.",
                                  "tips": "Para complexos, reduza real e imag separadamente ou use atomic para critical sections.",
                                  "learningObjective": "Lidar com operações de redução em dados complexos em ambientes paralelos.",
                                  "commonMistakes": "Não inicializar acumuladores locais por thread, levando a resultados incorretos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar schedule dinâmico para balanceamento de carga",
                                  "subSteps": [
                                    "Adicione schedule(dynamic) ou schedule(dynamic, chunk_size) ao pragma omp parallel for.",
                                    "Teste chunk sizes (ex: 1, 16, 64) para loops com workloads desbalanceados nos estágios FFT.",
                                    "Meça speedup e load balance com omp_get_wtime() por thread.",
                                    "Compare com schedule(static) e ajuste baseado em profiling.",
                                    "Execute em máquina multi-core e plote speedup vs. threads."
                                  ],
                                  "verification": "Speedup melhora >20% com dynamic vs. static, sem perda de correção.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código completo, gnuplot ou matplotlib para gráficos de speedup, perf ou gprof para profiling.",
                                  "tips": "Use chunk pequeno para desbalanceamento alto nos estágios iniciais da FFT.",
                                  "learningObjective": "Otimizar distribuição de trabalho com schedulers OpenMP.",
                                  "commonMistakes": "Overhead alto com dynamic em workloads balanceados; testar sempre."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar, otimizar e documentar a implementação paralela",
                                  "subSteps": [
                                    "Rode benchmarks com N variando, threads 1-16, coletando tempos e speedups.",
                                    "Use collapse(2) se inner loops forem pequenos para mais granularidade.",
                                    "Adicione collapse e num_threads para refinar.",
                                    "Documente flags de compilação, env vars e lições aprendidas.",
                                    "Compartilhe código em repo Git com README de resultados."
                                  ],
                                  "verification": "Speedup linear até limite de cores, eficiência >80%, código reproduzível.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Todos códigos anteriores, GitHub, planilha para tabela de benchmarks.",
                                  "tips": "Monitore cache misses com perf para otimizações adicionais.",
                                  "learningObjective": "Avaliar e refinar performance paralela completa.",
                                  "commonMistakes": "Não normalizar speedup pela versão sequencial otimizada."
                                }
                              ],
                              "practicalExample": "Em uma implementação radix-2 FFT para N=2^16 pontos de áudio, paralelize o loop de log2(N) estágios: for(int stage=0; stage<logN; stage++) #pragma omp parallel for schedule(dynamic,16) for(int group=0; group<groups; group++) { /* butterfly computations */ } com redução na soma de energia: double energy=0; #pragma omp parallel for reduction(+:energy) for(int i=0;i<N;i++) energy += real_part[i]*real_part[i] + imag_part[i]*imag_part[i]; Resultado: speedup de 3.8x em quad-core.",
                              "finalVerifications": [
                                "Código compila e executa sem warnings ou erros de runtime em múltiplos threads.",
                                "Saídas paralelas são numericamente idênticas à sequencial (erro <1e-10).",
                                "Speedup superlinear em alguns casos devido a cache effects.",
                                "Load balance >90% medido por tempo por thread.",
                                "Nenhum data race detectado por ThreadSanitizer.",
                                "Escalabilidade até número de cores físicos do sistema."
                              ],
                              "assessmentCriteria": [
                                "Correção: Resultados exatos em todos testes.",
                                "Performance: Speedup >= (num_threads - 0.2) para workloads balanceados.",
                                "Otimização: Uso correto de schedule dinâmico melhora >15% vs. static.",
                                "Robustez: Funciona com N=1024 a 1M, threads=1-16.",
                                "Código limpo: Comentários, private/shared explícitos, sem leaks.",
                                "Documentação: Relatório com gráficos de speedup e análise."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Algoritmos de divide-and-conquer na FFT (Coefield de Fourier).",
                                "Hardware: Arquitetura multi-core e hierarquia de cache.",
                                "Engenharia de Software: Profiling e otimização de performance.",
                                "Processamento de Sinais: Aplicações em DSP (áudio, imagem).",
                                "Computação Científica: Bibliotecas como MKL ou FFTW com OpenMP."
                              ],
                              "realWorldApplication": "Acelerar processamento de sinais em tempo real, como análise espectral em telecomunicações (5G), compressão de áudio/vídeo (MP3/HEVC), simulações físicas (MRI em medicina), e machine learning (FFT em convoluções para CNNs), reduzindo tempo de computação de horas para segundos em servidores multi-core."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.2.1",
                              "10.1.6.3.2.2"
                            ]
                          },
                          {
                            "id": "10.1.6.3.3.2",
                            "name": "Gerenciar sincronização e exclusão mútua",
                            "description": "Implementar critical sections, atomic e barriers em regiões de atualização compartilhada na FFT paralela com OpenMP.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de Sincronização no OpenMP",
                                  "subSteps": [
                                    "Estude a documentação oficial do OpenMP para diretivas critical, atomic e barrier.",
                                    "Identifique diferenças: critical para seções grandes, atomic para operações simples (++, --, etc.), barrier para sincronização global.",
                                    "Analise exemplos básicos de código sem paralelismo para entender race conditions em atualizações compartilhadas.",
                                    "Compile e execute códigos de exemplo com omp_get_thread_num() para visualizar threads.",
                                    "Pratique com um array compartilhado simples atualizado por múltiplas threads sem sincronização para observar inconsistências."
                                  ],
                                  "verification": "Explique em um relatório curto as diferenças entre critical, atomic e barrier, com exemplos de código que compilam e rodam corretamente.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Documentação OpenMP (openmp.org)",
                                    "Compilador GCC com suporte OpenMP (gcc -fopenmp)",
                                    "Editor de código (VS Code ou similar)"
                                  ],
                                  "tips": "Use omp_set_num_threads(4) para testes consistentes e visualize saídas com printf.",
                                  "learningObjective": "Compreender as diretivas de sincronização OpenMP e identificar quando usar cada uma.",
                                  "commonMistakes": [
                                    "Confundir atomic com critical (atomic só para operações simples)",
                                    "Ignorar overhead de critical em seções longas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Código FFT Paralelo e Identificar Regiões Críticas",
                                  "subSteps": [
                                    "Obtenha ou implemente uma versão básica paralela da FFT usando OpenMP (loops paralelos com #pragma omp parallel for).",
                                    "Execute o código com múltiplas threads e meça tempo/performance com omp_get_wtime().",
                                    "Use ferramentas como gdb ou valgrind para detectar race conditions em arrays compartilhados (ex: twiddle factors ou buffers de saída).",
                                    "Marque manualmente linhas com atualizações compartilhadas (ex: soma ou multiplicação em posições globais).",
                                    "Crie um diagrama de fluxo mostrando threads acessando regiões compartilhadas."
                                  ],
                                  "verification": "Produza um mapa anotado do código destacando pelo menos 3 regiões críticas com evidência de race conditions (logs de execução inconsistentes).",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Código fonte FFT paralela básica",
                                    "GDB ou Valgrind para debugging",
                                    "Cronômetro OpenMP (omp_get_wtime())"
                                  ],
                                  "tips": "Rode com OMP_NUM_THREADS=8 e repita 10x para confirmar inconsistências nos resultados.",
                                  "learningObjective": "Identificar precisamente regiões de atualização compartilhada em algoritmos paralelos como FFT.",
                                  "commonMistakes": [
                                    "Subestimar races em loops de redução",
                                    "Ignorar acessos indiretos a arrays via índices computados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Critical Sections e Atomic Operations",
                                  "subSteps": [
                                    "Adicione #pragma omp critical em torno das primeiras regiões críticas identificadas (ex: atualização de soma global).",
                                    "Substitua critical por #pragma omp atomic onde aplicável (operações como a += b* c).",
                                    "Teste compilação e execução: verifique se resultados são consistentes em múltiplas runs.",
                                    "Meça overhead comparando tempos com/ sem sincronização usando omp_get_wtime().",
                                    "Otimize movendo computações independentes para fora das seções críticas."
                                  ],
                                  "verification": "Código modificado roda 20x com resultados idênticos (erro < 1e-10 vs sequencial) e tempo reportado.",
                                  "estimatedTime": "2.5 hours",
                                  "materials": [
                                    "Código FFT do step 2",
                                    "Compilador GCC -fopenmp -O2",
                                    "Scripts de teste automatizados"
                                  ],
                                  "tips": "Use nomes em critical (ex: #pragma omp critical(update_sum)) para evitar deadlocks.",
                                  "learningObjective": "Aplicar corretamente critical e atomic para eliminar race conditions em FFT.",
                                  "commonMistakes": [
                                    "Usar atomic em expressões complexas (só aritmética simples)",
                                    "Deixar variáveis locais dentro de critical"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Adicionar Barriers e Verificar Sincronização Completa",
                                  "subSteps": [
                                    "Insira #pragma omp barrier após loops paralelos para sincronizar antes de atualizações dependentes.",
                                    "Combine com critical/atomic: ex: barrier antes de critical global na FFT.",
                                    "Execute com diferentes números de threads (2-16) e valide precisão vs versão sequencial.",
                                    "Profile com ferramentas como Intel VTune ou gprof para medir escalabilidade.",
                                    "Refatore para minimizar uso de sincronização, movendo reduções para #pragma omp parallel for reduction."
                                  ],
                                  "verification": "Código final atinge speedup > 2x com 4 threads, resultados precisos e sem warnings de tools de análise.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Código do step 3",
                                    "Ferramentas de profiling (perf ou VTune)",
                                    "Dados de teste: sinais senoidais para FFT"
                                  ],
                                  "tips": "Evite barriers desnecessários; use single/master para inicializações.",
                                  "learningObjective": "Integrar barriers com critical/atomic para sincronização robusta em FFT paralela.",
                                  "commonMistakes": [
                                    "Barrier em loops paralelos desnecessários (causa overhead)",
                                    "Deadlocks por ordem errada de locks"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma FFT paralela de 1024 pontos, use #pragma omp critical(twiddle_update) para atualizar fatores twiddle compartilhados: dentro do critical, twiddle[i] += sin(2*PI*k/n) * cos(...); Para contadores de iterações, use atomic: iter_count++; Barrier após estágio de borfly para sincronizar butterflies entre threads.",
                              "finalVerifications": [
                                "Resultados da FFT paralela coincidem com versão sequencial (erro L2 < 1e-8).",
                                "Execuções repetidas (50x) com múltiplas threads produzem saídas idênticas.",
                                "Sem race conditions detectadas por ThreadSanitizer (gcc -fsanitize=thread).",
                                "Speedup linear até 8 threads medido com omp_get_wtime().",
                                "Código compila com -fopenmp -Wall sem warnings.",
                                "Profiling mostra <20% tempo em seções críticas."
                              ],
                              "assessmentCriteria": [
                                "Correto uso de #pragma omp critical com nomes únicos onde necessário (20%).",
                                "Aplicação precisa de atomic para operações suportadas (20%).",
                                "Barriers posicionados corretamente para dependências inter-thread (20%).",
                                "Eliminação completa de race conditions comprovada (20%).",
                                "Otimização de performance com overhead mínimo (10%).",
                                "Documentação clara de mudanças e testes (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Algoritmos e Estruturas de Dados: Complexidade da FFT (O(n log n)) e paralelização.",
                                "Sistemas Operacionais: Conceitos de mutexes e semáforos subjacentes ao OpenMP.",
                                "Matemática Computacional: Aplicação da FFT em processamento de sinais.",
                                "Engenharia de Software: Debugging paralelo e profiling.",
                                "Arquitetura de Computadores: Impacto de cache coherence em sincronizações."
                              ],
                              "realWorldApplication": "Em processamento de áudio/vídeo (ex: FFmpeg usa FFT paralela), simulações científicas (ex: modelagem climática com spectral methods) e machine learning (ex: convoluções rápidas via FFT em redes neurais), garantindo precisão em clusters multi-core sem perda de dados por races."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.2.2"
                            ]
                          },
                          {
                            "id": "10.1.6.3.3.3",
                            "name": "Otimizar com affinity e tasking",
                            "description": "Usar OMP_PROC_BIND, task directives e SIMD para melhorar locality e vetorização na implementação OpenMP da FFT.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Affinity com OMP_PROC_BIND",
                                  "subSteps": [
                                    "Estude a documentação do OpenMP sobre OMP_PROC_BIND e seus valores possíveis (close, spread, master, etc.).",
                                    "Modifique o ambiente de execução definindo OMP_PROC_BIND=close para melhorar a locality de cache entre threads.",
                                    "Compile o código FFT OpenMP com suporte a affinity usando export OMP_PROC_BIND=close antes da execução.",
                                    "Execute o código baseline sem affinity e meça o tempo de execução com ferramentas como time ou OMP timers.",
                                    "Execute novamente com affinity ativado e compare os resultados iniciais de performance."
                                  ],
                                  "verification": "Verifique logs de execução ou use omp_get_proc_bind() para confirmar que o binding está aplicado corretamente.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Código fonte da FFT OpenMP",
                                    "Compilador GCC com -fopenmp",
                                    "Ambiente Linux com múltiplos cores"
                                  ],
                                  "tips": "Use OMP_PROC_BIND=close para workloads com alta locality de dados como FFT.",
                                  "learningObjective": "Compreender e aplicar controle de affinity para otimizar locality de cache em aplicações paralelas.",
                                  "commonMistakes": [
                                    "Ignorar NUMA effects em sistemas multi-socket",
                                    "Não exportar a variável antes da execução"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar Task Directives para Melhorar Load Balance e Locality",
                                  "subSteps": [
                                    "Identifique loops desbalanceados na FFT OpenMP, como divisões de butterflies irregulares.",
                                    "Refatore o loop principal usando #pragma omp task para criar tasks dinâmicos com taskloop ou taskwait.",
                                    "Adicione cláusulas como untied e mergeable para reduzir overhead de tasks.",
                                    "Garanta dependências corretas com depend(in/out) para preservar ordem de computação na FFT.",
                                    "Teste a implementação serializando tasks inicialmente para depuração."
                                  ],
                                  "verification": "Use OMP_DISPLAY_ENV=TRUE para inspecionar task creation e verifique ausência de deadlocks com gdb.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Código FFT modificado do Step 1",
                                    "Documentação OpenMP 5.0 para tasks",
                                    "Debugger GDB"
                                  ],
                                  "tips": "Combine taskloop com grainsize para controlar granularidade e evitar overhead excessivo.",
                                  "learningObjective": "Dominar directives de task para dynamic scheduling e melhor locality em algoritmos recursivos como FFT.",
                                  "commonMistakes": [
                                    "Omitir taskwait levando a race conditions",
                                    "Tasks muito finos causando overhead"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Adicionar SIMD Pragmas para Vetorização Automática",
                                  "subSteps": [
                                    "Analise loops internos da FFT (ex: butterfly operations) para identificar oportunidades de vetorização.",
                                    "Insira #pragma omp simd em loops independentes com redução de stride-1.",
                                    "Adicione cláusulas como simdlen(8) ou aligned() para alinhamento de dados.",
                                    "Combine com #pragma omp declare simd no protótipo de funções para vetorização de kernels.",
                                    "Recompile com -fopenmp -march=native -O3 para ativar vetorização AVX/SVE."
                                  ],
                                  "verification": "Use -fopt-info-vec para logs de vetorização do GCC e confirme vetores de 256/512 bits.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Código com tasks do Step 2",
                                    "Compilador GCC 11+ com suporte SIMD avançado"
                                  ],
                                  "tips": "Alinhe arrays com __attribute__((aligned(32))) para evitar penalidades de misaligned access.",
                                  "learningObjective": "Aplicar pragmas SIMD para explorar vetorização em computações numéricas intensivas.",
                                  "commonMistakes": [
                                    "Aplicar SIMD em loops com dependências de controle",
                                    "Ignorar alinhamento de dados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar Otimizações, Medir e Ajustar Performance",
                                  "subSteps": [
                                    "Integre todas as mudanças: affinity + tasks + SIMD no código FFT completo.",
                                    "Meça performance com múltiplos tamanhos de input (N=2^10 a 2^20) usando timers OpenMP.",
                                    "Use ferramentas como likwid ou perf para medir cache misses, IPC e vetorização efetiva.",
                                    "Compare speedup vs baseline e identifique gargalos restantes.",
                                    "Ajuste parâmetros (ex: num_threads, grainsize) baseado em profiling."
                                  ],
                                  "verification": "Gere relatório com speedup > 1.5x, redução de L2 misses > 20%, e confirmação de uso de SIMD via perf.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Ferramentas likwid-perfctr ou perf",
                                    "Múltiplos datasets FFT (sinais sinusoidais)"
                                  ],
                                  "tips": "Varra num_threads de 1 a núcleos disponíveis para encontrar ótimo.",
                                  "learningObjective": "Avaliar holísticamente otimizações OpenMP através de profiling e tuning iterativo.",
                                  "commonMistakes": [
                                    "Medir apenas tempo wall-clock sem profiling de hardware counters",
                                    "Testar apenas um tamanho de input"
                                  ]
                                }
                              ],
                              "practicalExample": "Otimize uma implementação OpenMP da FFT Cooley-Tukey para processar um sinal de áudio de 1M samples: aplique OMP_PROC_BIND=close para locality em stages de butterflies, tasks para balancear sub-FFTs recursivas, e SIMD nos loops de twiddle factors, alcançando speedup de 3x em 16 cores.",
                              "finalVerifications": [
                                "Execução sem erros ou deadlocks com affinity ativado.",
                                "Uso confirmado de tasks via OMP trace ou display.",
                                "Logs de compilação mostram loops vetorizados com AVX2/SVE.",
                                "Speedup médio > 2x vs baseline em múltiplos runs.",
                                "Redução de cache misses > 15% via likwid-topology.",
                                "Escalabilidade linear até 80% dos cores disponíveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão da FFT mantida (erro < 1e-10 vs serial).",
                                "Correta aplicação de OMP_PROC_BIND com verificação runtime.",
                                "Tasks implementados com dependências corretas e sem overhead excessivo.",
                                "SIMD pragmas efetivos, confirmados por vetorização reports.",
                                "Análise de performance inclui métricas de hardware (IPC, cache hits).",
                                "Código limpo, comentado e reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Algoritmos de Transformada Discreta de Fourier e complexidade O(n log n).",
                                "Arquitetura de Computadores: Hierarquia de cache, NUMA e unidades vetoriais SIMD.",
                                "Engenharia de Software: Profiling e otimização de performance em HPC.",
                                "Processamento de Sinais: Aplicações reais de FFT em áudio/imagens."
                              ],
                              "realWorldApplication": "Em supercomputação para simulações científicas (ex: clima, CFD), processamento de imagens médicas (MRI) e telecomunicações (5G OFDM), onde otimizações OpenMP com affinity, tasks e SIMD reduzem tempo de FFT de horas para minutos em clusters multi-node."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.3.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.3.4",
                        "name": "Avaliação de Desempenho e Estudos de Caso",
                        "description": "Medição de speedup, eficiência e escalabilidade da FFT paralela, comparando com benchmarks e analisando overheads em multicores.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.4.1",
                            "name": "Medir speedup e eficiência",
                            "description": "Executar testes com diferentes tamanhos de N e threads, calculando speedup (S = T_seq / T_par) e eficiência (E = S / P), plotando gráficos de escalabilidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e medir o tempo de execução da versão sequencial da FFT",
                                  "subSteps": [
                                    "Implemente ou compile a implementação sequencial da FFT para potências de 2 (N = 2^10 até 2^20).",
                                    "Adicione medição de tempo usando funções como clock() ou gettimeofday() ao redor da chamada da FFT.",
                                    "Execute a FFT sequencial 10 vezes para cada N, descartando a primeira execução (warm-up), e calcule a média dos tempos restantes.",
                                    "Registre os tempos médios T_seq para cada N em um arquivo CSV ou planilha.",
                                    "Valide a corretidão da FFT comparando saídas com uma biblioteca padrão como FFTW sequencial."
                                  ],
                                  "verification": "Tempos T_seq salvos em CSV com valores consistentes (aumentando com N) e saídas da FFT validadas contra referência.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Código fonte sequencial da FFT",
                                    "Compilador C/C++ com suporte a timing (ex: gcc)",
                                    "Biblioteca FFTW sequencial (opcional para validação)",
                                    "Planilha ou script Python para CSV"
                                  ],
                                  "tips": [
                                    "Use o mesmo hardware e desative turbo boost para consistência.",
                                    "Execute em ambiente controlado sem outras cargas."
                                  ],
                                  "learningObjective": "Dominar medição precisa de tempos sequenciais e validação de implementações.",
                                  "commonMistakes": [
                                    "Não descartar warm-up, levando a tempos inflados.",
                                    "Medir tempo incluindo I/O em vez de só computação.",
                                    "Usar N não-potências de 2, invalidando FFT radix-2."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar e configurar a versão paralela da FFT com múltiplos threads",
                                  "subSteps": [
                                    "Adicione diretivas OpenMP ao código sequencial: #pragma omp parallel for nas loops principais da FFT.",
                                    "Configure o número de threads usando omp_set_num_threads(P) para P = 1,2,4,8,16.",
                                    "Compile com -fopenmp e teste corretude com P=1 (deve igualar sequencial).",
                                    "Adicione medição de tempo similar à sequencial, dentro da região paralela.",
                                    "Execute warm-up e múltiplas rodadas para cada combinação de N e P."
                                  ],
                                  "verification": "Código compila sem erros OpenMP, tempos com P=1 igualam T_seq, e saídas corretas para P>1.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Código sequencial modificado",
                                    "Compilador gcc com -fopenmp",
                                    "Ambiente com múltiplos cores (ex: 16+ threads)"
                                  ],
                                  "tips": [
                                    "Use OMP_NUM_THREADS env var para controle fino.",
                                    "Verifique balanceamento de carga com omp_get_thread_num() logs iniciais."
                                  ],
                                  "learningObjective": "Aplicar paralelização OpenMP em algoritmos recursivos como FFT e medir overhead inicial.",
                                  "commonMistakes": [
                                    "Race conditions em loops não-private.",
                                    "Sobrecarga de threads > núcleos físicos.",
                                    "Não sincronizar corretamente com #pragma omp barrier."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar experimentos completos e coletar dados de tempos paralelos",
                                  "subSteps": [
                                    "Crie um script bash ou Python para automatizar: loop sobre N=[1024,2048,...,1048576] e P=[1,2,4,8,16].",
                                    "Para cada par (N,P), rode 10 execuções, compute média T_par e desvio padrão.",
                                    "Salve em CSV: colunas N, P, T_seq, T_par, std_dev.",
                                    "Monitore uso de CPU com top/htop para confirmar escalonamento.",
                                    "Repita experimentos 2-3 vezes para reprodutibilidade."
                                  ],
                                  "verification": "CSV completo com ~5 N x 5 P = 25 linhas, T_par diminuindo com P para N fixo, desvios <5%.",
                                  "estimatedTime": "2.5 hours",
                                  "materials": [
                                    "Script de automação (bash/Python)",
                                    "CSV viewer (Excel ou pandas)",
                                    "Ferramentas de monitoramento (htop)"
                                  ],
                                  "tips": [
                                    "Fixe seed para geradores randômicos de input.",
                                    "Use inputs idênticos para todas runs."
                                  ],
                                  "learningObjective": "Coletar dados experimentais robustos para análise de desempenho paralelo.",
                                  "commonMistakes": [
                                    "Poucas repetições, dados ruidosos.",
                                    "Variação de N sem log-scale, mascarando tendências.",
                                    "Ignorar overhead de memória para N grandes."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular speedup, eficiência e gerar gráficos de escalabilidade",
                                  "subSteps": [
                                    "No Python/MATLAB: leia CSV, compute S(N,P) = T_seq(N) / T_par(N,P), E(N,P) = S / P.",
                                    "Plote: Speedup vs P (para cada N, ideal linear), Eficiência vs P (deve <1 e decrescente).",
                                    "Adicione linhas ideais (S=P, E=1) e barras de erro do std_dev.",
                                    "Analise: identifique knee-of-curve onde mais threads não ajudam.",
                                    "Exporte gráficos como PNG/PDF com legendas claras."
                                  ],
                                  "verification": "Gráficos mostram S sub-linear, E<1 para P>1, cálculos batem manualmente para 2-3 pontos.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Python com numpy, matplotlib ou pandas",
                                    "MATLAB/Octave (alternativa)",
                                    "CSV de tempos"
                                  ],
                                  "tips": [
                                    "Use log-log scale para N vs tempo.",
                                    "Normalize por flops para eficiência absoluta."
                                  ],
                                  "learningObjective": "Interpretar métricas de escalabilidade e visualizar resultados experimentais.",
                                  "commonMistakes": [
                                    "Erro em fórmula: usar T_par / T_seq ao invés.",
                                    "Plots sem erros ou legendas.",
                                    "Ignorar Amdahl's law na interpretação."
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente FFT sequencial e paralela OpenMP para N=2^14 (16384) pontos complexos. Rode com P=1,4,8,16 threads em máquina 16-core. Meça T_seq=2.5s, T_par(P=4)=0.8s → S=3.125, E=0.78; plote S vs P mostrando saturação em P=8.",
                              "finalVerifications": [
                                "CSV com tempos consistentes e múltiplas repetições para todos N/P.",
                                "Cálculos de S e E corretos, validados manualmente em pelo menos 3 pontos.",
                                "Gráficos de speedup e eficiência com linhas ideais, escalas adequadas e legendas.",
                                "Análise escrita identificando limitações (ex: overhead comunicação em FFT).",
                                "Reprodutibilidade: re-run dá resultados dentro de 5% de variação.",
                                "Validação de corretude: FFT paralela produz mesma saída que sequencial."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos cálculos de S e E (erro <1%).",
                                "Qualidade dos gráficos: clareza, escalas corretas, erros mostrados.",
                                "Robustez experimental: repetições suficientes, controle de variáveis.",
                                "Interpretação: discussão de superlinearidade ou gargalos.",
                                "Automação: uso de scripts para eficiência.",
                                "Documentação: relatório com código, dados e plots."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Análise assintótica O(N log N) da FFT e leis de escalabilidade (Amdahl/Gustafson).",
                                "Estatística: Cálculo de médias, desvios padrão e análise de variância em benchmarks.",
                                "Engenharia de Software: Práticas de benchmarking, profiling e reproducible research.",
                                "Física/Engenharia: Aplicações em processamento de sinal (MRI, áudio) e HPC.",
                                "Ciência de Dados: Visualização de dados com matplotlib e análise exploratória."
                              ],
                              "realWorldApplication": "Em supercomputação para simulações climáticas ou astrofísica (ex: FFT em dados de telescópios como SKA), onde medir speedup guia alocação de milhares de nós; em IA para convoluções rápidas em redes neurais ou processamento de imagem em apps como Photoshop."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.3.1"
                            ]
                          },
                          {
                            "id": "10.1.6.3.4.2",
                            "name": "Analisar overheads e gargalos",
                            "description": "Identificar overheads de sincronização, contenção de cache e load imbalance na FFT OpenMP usando ferramentas como omp_get_wtime e perf.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o Ambiente e Código Baseline para FFT OpenMP",
                                  "subSteps": [
                                    "Compilar o código FFT OpenMP com suporte a profiling: use `gcc -fopenmp -O2 -g fft_omp.c -o fft_omp`",
                                    "Executar baseline sequencial e paralelo com diferentes threads: `./fft_omp 1024 1` e `./fft_omp 1024 4`",
                                    "Registrar tempos iniciais usando `omp_get_wtime()` em pontos chave: início, fim de loops paralelos e sincronizações",
                                    "Plotar speedup inicial vs. número de threads para baseline visual",
                                    "Salvar logs de tempo em arquivo CSV para análise posterior"
                                  ],
                                  "verification": "Verifique se os tempos baseline foram salvos em CSV e speedup plotado mostra anomalias iniciais (ex: speedup < linear)",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código fonte FFT OpenMP",
                                    "GCC com OpenMP",
                                    "GNUPlot ou Python Matplotlib para plots",
                                    "Sistema Linux com múltiplos cores"
                                  ],
                                  "tips": "Use tamanhos de input power-of-2 (ex: 1024, 4096) para FFT eficiente",
                                  "learningObjective": "Configurar medições precisas de tempo para estabelecer baseline de performance",
                                  "commonMistakes": "Ignorar flags de otimização (-O2) que mascaram overheads reais; não usar tamanhos de input adequados"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Instrumentar e Medir Overheads de Sincronização com omp_get_wtime",
                                  "subSteps": [
                                    "Adicionar timers `omp_get_wtime()` ao redor de `#pragma omp barrier` e critical sections",
                                    "Executar com variação de threads (2,4,8,16) e registrar tempo de sync: `double sync_time = omp_get_wtime() - start_sync;`",
                                    "Calcular overhead de sync como % do tempo total: `(sync_time / total_time) * 100`",
                                    "Comparar overheads entre configurações de threads",
                                    "Identificar se overhead >5-10% indica gargalo significativo"
                                  ],
                                  "verification": "Overhead de sync calculado e tabulado; gráfico mostra aumento com mais threads",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Código instrumentado",
                                    "Script Python para processar CSV de tempos"
                                  ],
                                  "tips": "Meça múltiplas runs (média de 10) para reduzir ruído",
                                  "learningObjective": "Quantificar overheads de sincronização em loops paralelos da FFT",
                                  "commonMistakes": "Não isolar sync de compute time; medir em single run volátil"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Contenção de Cache e Load Imbalance com Perf",
                                  "subSteps": [
                                    "Instalar e rodar perf: `perf record -e cache-misses,cache-references ./fft_omp 4096 8`",
                                    "Gerar relatório: `perf report` e filtrar por funções FFT (ex: fft_radix2)",
                                    "Calcular miss rate: `cache-misses / cache-references * 100`; threshold >5% é gargalo",
                                    "Usar `perf stat -e cycles,instructions` para IPC e detectar imbalance via cycles/thread",
                                    "Visualizar flamegraph com `perf script | stackcollapse-perf.pl | flamegraph.pl`"
                                  ],
                                  "verification": "Relatório perf mostra miss rate >5% e IPC <1 indicando contenção/imbalance",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Ferramenta perf (sudo apt install linux-tools)",
                                    "Flamegraph scripts",
                                    "Sistema com perf_events_open support"
                                  ],
                                  "tips": "Rode como root se necessário para perf full access",
                                  "learningObjective": "Usar profiling tools para detectar não-uniformidades de cache e workload",
                                  "commonMistakes": "Interpretar misses absolutos sem rate relativo; ignorar eventos errados"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Identificar Gargalos Principais",
                                  "subSteps": [
                                    "Compilar tabela: sync overhead, cache miss rate, speedup por thread count",
                                    "Identificar gargalo dominante: sync se >10%, cache se miss>5%, imbalance se speedup platô",
                                    "Propor otimizações iniciais: reduzir barriers, pad data para cache alignment, dynamic scheduling",
                                    "Documentar em relatório com gráficos e conclusões",
                                    "Testar uma otimização rápida e re-medir"
                                  ],
                                  "verification": "Relatório final lista top-3 gargalos com evidências quantitativas",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "CSV/logs de steps anteriores",
                                    "LaTeX ou Markdown para relatório"
                                  ],
                                  "tips": "Priorize gargalos >10% impacto",
                                  "learningObjective": "Sintetizar dados de profiling em diagnósticos acionáveis",
                                  "commonMistakes": "Atribuir gargalos sem dados quantitativos; ignorar interações entre gargalos"
                                }
                              ],
                              "practicalExample": "Em uma FFT de 4096 pontos com 8 threads, perf revela 12% cache miss rate devido a acessos stride-1 em arrays transpostos; omp_get_wtime mostra 8% sync overhead em barriers pós-butterfly; solução: padding arrays para alinhamento de cache-line.",
                              "finalVerifications": [
                                "Overhead de sync quantificado corretamente >5% em pelo menos uma config",
                                "Cache miss rate calculada e > threshold em relatório perf",
                                "Load imbalance detectado via speedup não-linear ou perf cycles/thread",
                                "Gráficos de speedup/tempo vs threads gerados",
                                "Relatório lista 2+ gargalos com evidências"
                              ],
                              "assessmentCriteria": [
                                "Precisão nas medições: erros <5% em tempos repetidos (80%)",
                                "Correta identificação de gargalos via thresholds (90%)",
                                "Uso correto de tools: timers isolados, perf events relevantes (100%)",
                                "Análise qualitativa/quantitativa balanceada no relatório (85%)",
                                "Propostas de otimização baseadas em evidências (75%)",
                                "Clareza em visualizações e documentação (90%)"
                              ],
                              "crossCurricularConnections": [
                                "Otimização de Performance em Machine Learning: análise similar para convoluções paralelas em CNNs",
                                "Arquitetura de Computadores: compreensão de hierarquia de cache L1/L2/L3",
                                "Engenharia de Software: profiling e debugging em pipelines CI/CD",
                                "Processamento de Sinais: FFT em aplicações de áudio/imagem real-time",
                                "High-Performance Computing (HPC): escalabilidade em clusters MPI+OpenMP"
                              ],
                              "realWorldApplication": "Em data centers de processamento de imagens médicas (MRI), analisar gargalos em FFT OpenMP otimiza throughput de reconstruções 3D, reduzindo tempo de diagnóstico de horas para minutos em GPUs/CPs multi-core."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.3.4.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.4",
                    "name": "Estudo de Caso: Processamento de Imagens em Plataformas Heterogêneas",
                    "description": "Aplicações paralelas em filtros de imagem usando linguagens para multicores e aceleradores como GPUs.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.4.1",
                        "name": "Plataformas Heterogêneas para Processamento de Imagens",
                        "description": "Conceitos fundamentais sobre plataformas heterogêneas, incluindo multicores e aceleradores como GPUs, com ênfase na taxonomia de Flynn e modelos de memória distribuída e compartilhada aplicados ao processamento paralelo de imagens.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.4.1.1",
                            "name": "Identificar taxonomia de Flynn em plataformas heterogêneas",
                            "description": "Classificar arquiteturas de computadores paralelos (SISD, SIMD, MISD, MIMD) e relacionar com plataformas multicores e GPUs usadas em processamento de imagens, como convoluções em filtros.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude a definição de taxonomia de Flynn: classificação baseada em instruções (sequencial ou múltiplas) e dados (sequencial ou múltiplos).",
                                    "Memorize as quatro classes: SISD (Single Instruction Single Data), SIMD (Single Instruction Multiple Data), MISD (Multiple Instruction Single Data) e MIMD (Multiple Instruction Multiple Data).",
                                    "Analise diagramas visuais representando fluxos de instruções e dados para cada classe.",
                                    "Compare SISD com arquiteturas seriais tradicionais como processadores von Neumann.",
                                    "Identifique exemplos históricos iniciais para cada classe, como Cray para SIMD."
                                  ],
                                  "verification": "Crie um diagrama manual ou digital resumindo as quatro classes com setas para instruções e dados; verifique se distingue corretamente os fluxos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Diagrama da taxonomia de Flynn (impresso ou online)",
                                    "Vídeo introdutório no YouTube sobre Flynn's Taxonomy",
                                    "Papel e caneta para esboços"
                                  ],
                                  "tips": "Use mnemônicos como 'S-S, S-M, M-S, M-M' para lembrar as combinações.",
                                  "learningObjective": "Dominar as definições e classificações básicas da taxonomia de Flynn.",
                                  "commonMistakes": [
                                    "Confundir SIMD com MIMD (foco em dados vs. instruções)",
                                    "Ignorar MISD como rara mas válida",
                                    "Não visualizar fluxos paralelos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Classificar Arquiteturas Paralelas Clássicas",
                                  "subSteps": [
                                    "Classifique exemplos clássicos: SISD (Intel 8086), SIMD (vector processors como Cray-1), MISD (fault-tolerant systems), MIMD (clusters de workstations).",
                                    "Crie uma tabela comparativa com colunas para cada classe, listando características chave como paralelismo de dados/instruções.",
                                    "Simule fluxos de execução com pseudocódigo simples para cada classe.",
                                    "Pesquise e anote limitações de cada classe em termos de eficiência.",
                                    "Teste classificação com quiz online ou flashcards."
                                  ],
                                  "verification": "Preencha uma tabela de classificação com 5 exemplos de arquiteturas e justifique cada uma; revise com fonte confiável.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Tabela em branco no Google Sheets ou Excel",
                                    "Artigo da Wikipedia sobre Flynn Taxonomy",
                                    "Flashcards app como Anki"
                                  ],
                                  "tips": "Associe SIMD a vetores (como arrays em imagens), MIMD a threads independentes.",
                                  "learningObjective": "Aplicar a taxonomia para classificar arquiteturas paralelas conhecidas.",
                                  "commonMistakes": [
                                    "Classificar GPUs prematuramente como puras SIMD sem contexto",
                                    "Subestimar raridade de MISD",
                                    "Misturar níveis de paralelismo (bit vs. word)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Mapear Taxonomia para Plataformas Modernas Multicores e GPUs",
                                  "subSteps": [
                                    "Analise CPUs multicores: classifique como MIMD devido a núcleos independentes executando instruções diferentes em dados diferentes.",
                                    "Estude GPUs: identifique como SIMD em larga escala (warp execution em NVIDIA CUDA) para operações vetoriais.",
                                    "Compare plataformas heterogêneas: CPU (MIMD) + GPU (SIMD) em sistemas como laptops modernos.",
                                    "Examine híbridos: como Intel Xeon Phi (muitos cores SIMD dentro de MIMD).",
                                    "Crie um mapa conceitual ligando Flynn a hardware atual."
                                  ],
                                  "verification": "Desenhe um mapa ligando 3 plataformas modernas (ex: Intel Core i7, NVIDIA RTX, AMD APU) às classes de Flynn com evidências.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Documentação NVIDIA CUDA Programming Guide",
                                    "Especificações de CPU/GPU online",
                                    "Ferramenta de mindmap como Draw.io"
                                  ],
                                  "tips": "Pense em GPUs como 'SIMD massivo' para paralelismo de dados em pixels de imagens.",
                                  "learningObjective": "Relacionar taxonomia clássica com arquiteturas heterogêneas contemporâneas.",
                                  "commonMistakes": [
                                    "Chamar todas as GPUs de SIMD puras ignorando MIMD em controladores",
                                    "Confundir multicores com SIMD",
                                    "Não considerar heterogeneidade CPU-GPU"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Processamento de Imagens e Convoluções",
                                  "subSteps": [
                                    "Identifique convoluções em filtros de imagem: operações SIMD ideais (mesmo kernel em múltiplos pixels).",
                                    "Simule convolução 2D em pseudocódigo e classifique como SIMD em GPU.",
                                    "Analise pipeline heterogêneo: pré-processamento MIMD na CPU, convolução SIMD na GPU.",
                                    "Pesquise casos reais como OpenCV com CUDA ou TensorFlow em GPUs.",
                                    "Crie um fluxograma de uma aplicação de processamento de imagens destacando classes de Flynn."
                                  ],
                                  "verification": "Classifique componentes de um pipeline de convolução de imagem (CPU prep, GPU compute) e valide com código simples.",
                                  "estimatedTime": "55 minutos",
                                  "materials": [
                                    "Exemplo de código OpenCV/CUDA",
                                    "Imagem de teste para convolução (JPEG)",
                                    "Ambiente Python com NumPy/Matplotlib"
                                  ],
                                  "tips": "Visualize convolução como SIMD: uma instrução (apply kernel) em múltiplos dados (pixels vizinhos).",
                                  "learningObjective": "Identificar taxonomia de Flynn em cenários práticos de plataformas heterogêneas para imagens.",
                                  "commonMistakes": [
                                    "Ignorar overhead de transferência CPU-GPU como MIMD",
                                    "Não mapear controle sequencial como SISD",
                                    "Generalizar demais sem exemplos concretos"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um pipeline de detecção de bordas em imagens usando OpenCV com CUDA: a CPU multicores (MIMD) carrega e pré-processa a imagem (redimensiona, normaliza), enquanto a GPU NVIDIA (SIMD) executa convolução com filtro Sobel em todos os pixels simultaneamente, acelerando o processamento em 10x para imagens HD.",
                              "finalVerifications": [
                                "Classifique corretamente SISD, SIMD, MISD e MIMD com exemplos modernos.",
                                "Mapeie uma GPU para SIMD e CPU multicores para MIMD em heterogeneidade.",
                                "Explique por que convoluções em imagens são SIMD em GPUs.",
                                "Crie diagrama de pipeline heterogêneo com labels de Flynn.",
                                "Responda quiz de 10 perguntas sobre taxonomia com 90% acerto.",
                                "Simule classificação de uma plataforma real como NVIDIA Jetson."
                              ],
                              "assessmentCriteria": [
                                "Precisão na classificação das quatro classes de Flynn (100% correto).",
                                "Correta relação com hardware moderno (multicores MIMD, GPUs SIMD).",
                                "Profundidade na análise de convoluções como exemplo SIMD.",
                                "Criatividade e clareza em diagramas/mapas conceituais.",
                                "Evidências de compreensão via exemplos práticos e verificações.",
                                "Identificação de limitações em plataformas heterogêneas."
                              ],
                              "crossCurricularConnections": [
                                "Programação Paralela: Implementação em CUDA/OpenMP.",
                                "Processamento de Imagens: Filtros convolucionais em visão computacional.",
                                "Arquitetura de Computadores: Evolução de hardware paralela.",
                                "Inteligência Artificial: Aceleração de redes neurais em GPUs.",
                                "Engenharia de Software: Design de pipelines heterogêneos."
                              ],
                              "realWorldApplication": "Em visão computacional para veículos autônomos, GPUs classificadas como SIMD aceleram convoluções em câmeras para detecção de objetos em tempo real, combinadas com CPUs MIMD para lógica de decisão, otimizando eficiência em plataformas heterogêneas como NVIDIA DRIVE."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.1.2",
                            "name": "Diferenciar modelos de memória em aplicações de imagens",
                            "description": "Comparar modelos de memória compartilhada e distribuída, explicando impactos no processamento paralelo de imagens, como latência em acessos distribuídos versus cache em compartilhada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Modelo de Memória Compartilhada",
                                  "subSteps": [
                                    "Defina memória compartilhada como um espaço único acessível por todos os processadores.",
                                    "Explique o hardware típico: multiprocessadores simétricos (SMP) com cache hierárquico.",
                                    "Descreva mecanismos de coerência de cache (ex: MESI protocol).",
                                    "Discuta acessos rápidos via cache local versus invalidações em acessos remotos.",
                                    "Relacione com programação: threads acessam dados globais sem cópias explícitas."
                                  ],
                                  "verification": "Crie um diagrama simples mostrando cache L1/L2 compartilhado e confirme com autoexplicação.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Diagramas de arquitetura SMP, documentação OpenMP.",
                                  "tips": "Visualize como uma 'mesa compartilhada' onde todos pegam itens sem aviso prévio.",
                                  "learningObjective": "Identificar características e vantagens da memória compartilhada em sistemas paralelos.",
                                  "commonMistakes": "Confundir com memória distribuída; ignorar overhead de coerência de cache."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender o Modelo de Memória Distribuída",
                                  "subSteps": [
                                    "Defina memória distribuída como cada processador tendo sua memória local privada.",
                                    "Explique comunicação via mensagens (MPI) ou redes (ex: InfiniBand).",
                                    "Descreva latência alta em acessos remotos devido a rede.",
                                    "Discuta ausência de cache compartilhado; uso de DMA para transferências.",
                                    "Relacione com programação: dados devem ser explicitamente enviados/recebidos."
                                  ],
                                  "verification": "Esboce um cluster de nós com setas de mensagens e valide acessos locais vs remotos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Diagramas de clusters MPI, tutoriais MPI básicos.",
                                  "tips": "Pense como 'casas separadas' comunicando por correio, com atrasos inevitáveis.",
                                  "learningObjective": "Reconhecer limitações e mecanismos de comunicação na memória distribuída.",
                                  "commonMistakes": "Subestimar latência de rede; assumir cache global como em compartilhada."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Modelos no Contexto de Processamento de Imagens",
                                  "subSteps": [
                                    "Compare acesso a pixels: compartilhada permite leitura/escrita direta; distribuída requer scatter/gather.",
                                    "Analise filtros de imagem (ex: convolução): cache hits em compartilhada vs mensagens em distribuída.",
                                    "Discuta escalabilidade: compartilhada limitada por bus; distribuída por topologia de rede.",
                                    "Exemplo: OpenCV em multi-core (compartilhada) vs clusters para imagens grandes.",
                                    "Tabela comparativa: latência (baixa/alta), bandwidth (alto/baixo), programação (fácil/complexa)."
                                  ],
                                  "verification": "Preencha uma tabela de comparação com 5 métricas e revise com exemplos de imagens.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Ferramentas como draw.io para tabelas, exemplos OpenCV/MPI.",
                                  "tips": "Use imagens reais (ex: 4K photo) para simular tamanhos e calcular acessos.",
                                  "learningObjective": "Diferenciar impactos práticos nos dois modelos para tarefas de imagem.",
                                  "commonMistakes": "Ignorar tamanho de dados de imagem afetando bandwidth."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Impactos Específicos e Simular",
                                  "subSteps": [
                                    "Quantifique latência: compartilhada ~ns (cache), distribuída ~μs-ms (rede).",
                                    "Simule processamento: divida imagem em blocos e compare tempos.",
                                    "Discuta trade-offs: compartilhada para baixa latência, distribuída para escalabilidade.",
                                    "Exemplo prático: edge detection em GPU (compartilhada) vs cluster.",
                                    "Conclua com quando escolher cada modelo baseado em workload."
                                  ],
                                  "verification": "Execute pseudocódigo ou simulação simples e registre métricas comparativas.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Pseudocódigo em Python (NumPy para compartilhada, mpi4py para distribuída), imagens de teste.",
                                  "tips": "Meça com timer em código para validar diferenças reais.",
                                  "learningObjective": "Explicar e quantificar impactos como latência e cache em aplicações de imagens.",
                                  "commonMistakes": "Generalizar sem considerar workload específico de imagens."
                                }
                              ],
                              "practicalExample": "Em um pipeline de processamento de imagens médicas (ex: MRI scans), use OpenMP em um servidor multi-core com memória compartilhada para filtros locais rápidos (cache eficiente), enquanto MPI em um cluster distribuído para reconstrução 3D distribuída, enviando blocos de voxels via mensagens, destacando latência extra mas escalabilidade para datasets >1TB.",
                              "finalVerifications": [
                                "Explique verbalmente diferenças em 3 frases concisas.",
                                "Desenhe diagramas precisos de ambos modelos.",
                                "Preencha tabela comparativa com ≥5 itens corretos.",
                                "Simule impacto em uma imagem de 1024x1024 pixels.",
                                "Identifique 2 cenários onde um modelo supera o outro.",
                                "Responda quiz de 5 perguntas sobre latência/cache."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (20%): Definições corretas sem confusões.",
                                "Profundidade comparativa (25%): Impactos quantificados em imagens.",
                                "Exemplos práticos (20%): Relevância a processamento paralelo.",
                                "Clareza de diagramas/tabelas (15%): Visualizações precisas.",
                                "Análise de trade-offs (10%): Latência vs escalabilidade.",
                                "Simulação/verificação (10%): Evidência de aplicação."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Cache coherence protocols.",
                                "Redes de Computadores: Latência e topologias em clusters.",
                                "Processamento de Imagens: Algoritmos paralelizáveis como FFT.",
                                "Sistemas Operacionais: Gerenciamento de memória em threads/processos.",
                                "Inteligência Artificial: Aceleração de CNNs em GPUs (compartilhada)."
                              ],
                              "realWorldApplication": "Em visão computacional para veículos autônomos, GPUs com memória compartilhada (CUDA) processam frames em tempo real com baixa latência via cache unificado, enquanto clusters distribuídos (Kubernetes + MPI) lidam com análise de vídeo em escala para data centers, balanceando custo e performance."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.1.3",
                            "name": "Aplicar conceitos de decomposição de domínio em imagens",
                            "description": "Demonstrar decomposição de domínio para dividir imagens em blocos processáveis em paralelo por núcleos multicores ou GPUs, minimizando comunicações.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Decomposição de Domínio",
                                  "subSteps": [
                                    "Estude a definição de decomposição de domínio como divisão do espaço de problema (imagem) em subdomínios independentes.",
                                    "Analise exemplos de domínios 1D, 2D e 3D, focando em imagens 2D.",
                                    "Identifique o trade-off entre granularidade (tamanho dos blocos) e overhead de comunicação.",
                                    "Revise conceitos de paralelismo em multicores e GPUs, como threads e kernels.",
                                    "Anote os benefícios para processamento de imagens, como filtros e transformações."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras explicando decomposição de domínio e sua relevância para imagens, incluindo um diagrama simples.",
                                  "estimatedTime": "45-60 minutes",
                                  "materials": [
                                    "Documentação OpenMP ou CUDA sobre decomposição",
                                    "Artigos ou tutoriais sobre processamento paralelo de imagens",
                                    "Editor de texto para anotações e desenhos"
                                  ],
                                  "tips": "Use diagramas visuais para representar a divisão de uma imagem em blocos; comece com imagens pequenas para intuição.",
                                  "learningObjective": "Dominar a teoria da decomposição de domínio aplicada a imagens para paralelismo.",
                                  "commonMistakes": [
                                    "Confundir decomposição de domínio com decomposição de tarefas; ignorar dependências de borda nas imagens."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar e Planejar Divisão da Imagem em Blocos",
                                  "subSteps": [
                                    "Carregue uma imagem de teste (ex: 1024x1024 pixels) usando bibliotecas como OpenCV ou Pillow.",
                                    "Determine dimensões ideais de blocos baseadas no número de núcleos/GPUs (ex: blocos NxN para equilíbrio de carga).",
                                    "Planeje tratamento de bordas com halo regions para minimizar comunicações em operações como filtros.",
                                    "Calcule o número de blocos e overhead estimado de comunicação.",
                                    "Desenhe um mapa da divisão, marcando overlaps necessários."
                                  ],
                                  "verification": "Crie um diagrama da imagem dividida em blocos com anotações de tamanhos e overlaps; valide dimensões matematicamente.",
                                  "estimatedTime": "60-90 minutes",
                                  "materials": [
                                    "Biblioteca OpenCV ou Pillow para Python",
                                    "Imagem de teste (ex: Lena.png)",
                                    "Ferramenta de desenho como Draw.io ou papel"
                                  ],
                                  "tips": "Escolha blocos quadrados para simplicidade em GPUs; mire em 80-90% de cobertura independente para reduzir comunicações.",
                                  "learningObjective": "Planejar uma decomposição otimizada que equilibre carga e minimize comunicações.",
                                  "commonMistakes": [
                                    "Blocos desiguais causando imbalance de carga; subestimar overlaps em filtros convolucionais."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Decomposição em Código Paralelo",
                                  "subSteps": [
                                    "Escreva código sequencial base para processar a imagem (ex: filtro Gaussiano).",
                                    "Implemente divisão em blocos usando loops paralelos (OpenMP para CPU) ou grids de blocos (CUDA para GPU).",
                                    "Adicione exchanges de halo para bordas compartilhadas.",
                                    "Garanta sincronização e junção dos resultados em imagem final.",
                                    "Compile e execute em ambiente com múltiplos núcleos/GPU."
                                  ],
                                  "verification": "Execute o código e compare imagem resultante com versão sequencial (PSNR > 40dB).",
                                  "estimatedTime": "90-120 minutes",
                                  "materials": [
                                    "Ambiente de desenvolvimento com OpenMP/CUDA (GCC + nvcc)",
                                    "Código base sequencial",
                                    "GPU ou multicore CPU disponível"
                                  ],
                                  "tips": "Use #pragma omp parallel for para simplicidade inicial; teste com imagens pequenas antes de escalar.",
                                  "learningObjective": "Codificar decomposição de domínio funcional em plataformas heterogêneas.",
                                  "commonMistakes": [
                                    "Race conditions em bordas sem halo; forgetar de mapear blocos de volta à imagem global."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, Otimizar e Avaliar Performance",
                                  "subSteps": [
                                    "Meça tempo sequencial vs paralelo com ferramentas como time ou nvprof.",
                                    "Profile comunicações e compute speedup/efficiency.",
                                    "Ajuste tamanho de blocos e overlaps para otimizar.",
                                    "Teste escalabilidade variando número de núcleos/GPUs.",
                                    "Documente métricas e gráficos de performance."
                                  ],
                                  "verification": "Gere relatório com speedup > 2x em 4 núcleos e comunicações < 10% do tempo total.",
                                  "estimatedTime": "60-90 minutes",
                                  "materials": [
                                    "Ferramentas de profiling: gprof, nvprof ou Intel VTune",
                                    "Planilhas para gráficos (Excel/Google Sheets)"
                                  ],
                                  "tips": "Use imagens maiores para evidenciar ganhos; compare múltiplas estratégias de decomposição.",
                                  "learningObjective": "Avaliar e refinar decomposição para performance real.",
                                  "commonMistakes": [
                                    "Medir apenas tempo total ignorando overhead; não testar em hardware alvo."
                                  ]
                                }
                              ],
                              "practicalExample": "Divida uma imagem RGB 2048x2048 em 16 blocos de 512x512 pixels com halo de 5 pixels nas bordas para aplicar um filtro blur em paralelo usando CUDA em uma GPU NVIDIA. Cada bloco é processado por um thread block, com exchanges de halo via shared memory, resultando em speedup de 8x vs CPU sequencial e comunicações minimizadas a 5% do tempo.",
                              "finalVerifications": [
                                "Imagem final idêntica à sequencial (erro < 1%).",
                                "Todos blocos processados em paralelo sem deadlocks.",
                                "Speedup mensurável (> 4x em 8 núcleos/GPUs).",
                                "Overhead de comunicação < 15% do tempo total.",
                                "Escalabilidade demonstrada com variação de recursos.",
                                "Código comentado e reproduzível."
                              ],
                              "assessmentCriteria": [
                                "Compreensão teórica (20%): Explicação precisa de conceitos.",
                                "Planejamento da divisão (25%): Diagrama otimizado com cálculos.",
                                "Implementação funcional (30%): Código correto e paralelo.",
                                "Análise de performance (15%): Métricas e otimizações.",
                                "Documentação e verificações (10%): Relatório claro."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear para representações matriciais de imagens e divisões.",
                                "Física: Processamento de sinais e convoluções em imagens.",
                                "Engenharia de Software: Design de algoritmos distribuídos e profiling.",
                                "Computação Gráfica: Renderização paralela e texturas em GPUs.",
                                "Inteligência Artificial: Pré-processamento de imagens para visão computacional."
                              ],
                              "realWorldApplication": "Em visão computacional para veículos autônomos (processamento de câmeras em tempo real), análise médica de imagens (MRI/CT em clusters GPU) e edição de vídeo (filtros paralelos em Adobe Premiere ou DaVinci Resolve), onde decomposição de domínio permite escalar para imagens HD/4K em hardware heterogêneo, reduzindo latência crítica."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.4.2",
                        "name": "Modelos de Programação Paralela para Filtros de Imagem",
                        "description": "Principais modelos de programação paralela, como troca de mensagens e exclusão mútua, adaptados para implementação de filtros de imagem em ambientes multicores e heterogêneos.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.4.2.1",
                            "name": "Implementar troca de mensagens em filtros de imagem",
                            "description": "Usar paradigmas como MPI para troca de mensagens entre processos em plataformas distribuídas, aplicando em filtros como Gaussiano onde bordas de domínios precisam de dados vizinhos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente MPI e particionar a imagem",
                                  "subSteps": [
                                    "Instalar e configurar o ambiente MPI (ex: OpenMPI ou MPICH)",
                                    "Criar um programa base em C/C++ com MPI_Init e MPI_Comm_rank/size",
                                    "Carregar uma imagem de teste (formato PPM ou PNG usando biblioteca como stb_image)",
                                    "Implementar particionamento da imagem em domínios locais para cada processo (divisão em blocos horizontais ou 2D)",
                                    "Definir dimensões dos domínios e alocar buffers para ghost cells (bordas vizinhas)"
                                  ],
                                  "verification": "Executar mpirun -np 4 ./programa e verificar se cada processo imprime corretamente seu domínio local sem erros",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Compilador mpicc",
                                    "Biblioteca stb_image ou similar",
                                    "Imagem de teste 512x512 pixels"
                                  ],
                                  "tips": "Use MPI_Bcast para distribuir parâmetros globais da imagem; prefira particionamento uniforme para simplicidade inicial",
                                  "learningObjective": "Entender inicialização MPI e divisão de dados em plataformas distribuídas",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init antes de usar funções MPI",
                                    "Particionamento incorreto levando a sobreposições ou lacunas",
                                    "Não considerar tamanhos de buffer para ghost cells"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar troca de mensagens para ghost cells",
                                  "subSteps": [
                                    "Definir regiões de borda superior/inferior/esquerda/direita para cada domínio",
                                    "Usar MPI_Send e MPI_Recv para trocar dados de borda entre processos adjacentes (topologia 1D ou 2D)",
                                    "Implementar troca não-bloqueante com MPI_Isend e MPI_Irecv para melhor performance",
                                    "Verificar tamanhos das mensagens com MPI_Type_vector para regiões retangulares",
                                    "Sincronizar com MPI_Barrier após trocas para garantir consistência"
                                  ],
                                  "verification": "Adicionar prints dos ghost cells recebidos e confirmar que correspondem às bordas dos vizinhos",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação MPI (man pages ou mpi4py se em Python)",
                                    "Editor de código com suporte MPI (VSCode + extensão)"
                                  ],
                                  "tips": "Crie funções auxiliares como exchange_halo_top() e exchange_halo_bottom() para clareza; teste com np=2 primeiro",
                                  "learningObjective": "Dominar paradigmas de comunicação ponto-a-ponto em MPI para dados vizinhos",
                                  "commonMistakes": [
                                    "Deadlocks por ordem errada de Send/Recv",
                                    "Tamanhos de mensagem inconsistentes",
                                    "Esquecer de esperar MPI_Wait em comunicações não-bloqueantes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar filtro Gaussiano utilizando dados trocados",
                                  "subSteps": [
                                    "Definir kernel Gaussiano (matriz 5x5 com pesos sigma=1)",
                                    "Para cada pixel no domínio local (incluindo ghost cells), calcular convolução com vizinhos",
                                    "Implementar a soma ponderada evitando acessar fora dos ghost cells",
                                    "Armazenar resultados apenas no domínio proprietário (excluindo ghosts)",
                                    "Otimizar com loops aninhados e evitar recálculo de pesos"
                                  ],
                                  "verification": "Comparar visualmente partes internas da imagem filtrada com versão sequencial",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código sequencial de filtro Gaussiano para referência",
                                    "Ferramenta de visualização de imagens (GIMP ou imagemagick)"
                                  ],
                                  "tips": "Use #pragma omp simd para vetorização interna se suportado; normalize o kernel para soma=1",
                                  "learningObjective": "Integrar comunicação paralela com computação local em filtros de imagem",
                                  "commonMistakes": [
                                    "Aplicar filtro em ghost cells permanentemente",
                                    "Erros de índice em bordas",
                                    "Kernel não normalizado causando escurecimento"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Reconstruir imagem global e verificar resultados",
                                  "subSteps": [
                                    "Coletar domínios processados usando MPI_Gather ou MPI_Send para processo raiz",
                                    "No processo raiz, montar imagem global e salvar em arquivo",
                                    "Implementar verificação de speedup comparando tempos com versão sequencial (MPI_Wtime)",
                                    "Testar com diferentes números de processos (np=2,4,8)",
                                    "Analisar artefatos em bordas e ajustar trocas se necessário"
                                  ],
                                  "verification": "Imagem final idêntica à sequencial (PSNR > 40dB) e speedup > 2x para np=4",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Biblioteca para salvar PPM/PNG",
                                    "Script para calcular PSNR ou diff de imagens"
                                  ],
                                  "tips": "Use MPI_Reduce para tempo global; salve imagens intermediárias para debug",
                                  "learningObjective": "Avaliar performance e corretude em aplicações paralelas distribuídas",
                                  "commonMistakes": [
                                    "Perda de dados em Gather",
                                    "Sincronização incompleta",
                                    "Não tratar casos de np incompatível com dimensões da imagem"
                                  ]
                                }
                              ],
                              "practicalExample": "Aplique filtro Gaussiano em uma imagem 1024x1024 dividida em 4 processos (2x2 grid). Cada processo troca ghost cells de 2 pixels de largura com vizinhos, aplicando kernel 5x5 para suavização sem artefatos nas bordas dos domínios.",
                              "finalVerifications": [
                                "Programa executa sem deadlocks ou crashes para np até 8",
                                "Ghost cells são corretamente preenchidos com dados vizinhos",
                                "Filtro Gaussiano produz imagem idêntica à versão sequencial nas bordas",
                                "Tempo de execução reduz com aumento de processos (speedup linear inicial)",
                                "Nenhum overflow/underflow em buffers de mensagem",
                                "Imagem salva corretamente sem corrupção"
                              ],
                              "assessmentCriteria": [
                                "Correção da troca de mensagens (verificação de dados em ghosts)",
                                "Eficiência computacional (tempo de convolução < 50% do total)",
                                "Escalabilidade com np variável",
                                "Robustez a diferentes tamanhos de imagem e kernels",
                                "Clareza e modularidade do código (funções separadas)",
                                "Documentação de tempos e speedups"
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de comunicação assíncrona",
                                "Processamento Digital de Sinais: Convolução e filtros espaciais",
                                "Sistemas Operacionais: Gerenciamento de memória distribuída",
                                "Matemática Computacional: Decomposição de domínios",
                                "Engenharia de Software: Modularidade em código paralelo"
                              ],
                              "realWorldApplication": "Processamento de imagens em clusters HPC para visão computacional, como detecção de objetos em satélites (ex: NASA Earthdata) ou reconstrução tomográfica em medicina, onde filtros exigem troca de pixels vizinhos em grades distribuídas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.2.2",
                            "name": "Gerenciar exclusão mútua em acessos compartilhados",
                            "description": "Aplicar mecanismos de exclusão mútua (semáforos, locks) em memória compartilhada para filtros de imagem em multicores, evitando race conditions em pixels compartilhados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar e Simular Race Conditions em Memória Compartilhada para Filtros de Imagem",
                                  "subSteps": [
                                    "Analise um código de filtro de imagem (ex: filtro de média) que divide a imagem em blocos processados por threads múltiplas.",
                                    "Execute o código sem sincronização em múltiplas runs e observe inconsistências em pixels de borda compartilhados.",
                                    "Use ferramentas de profiling (ex: gdb ou Valgrind) para capturar acessos concorrentes a pixels.",
                                    "Registre timestamps ou contadores para demonstrar sobreposição de leituras/escritas em pixels.",
                                    "Documente o impacto: artefatos visuais como linhas distorcidas ou valores incorretos."
                                  ],
                                  "verification": "Race conditions reproduzíveis em pelo menos 80% das execuções múltiplas, com imagens de saída inconsistentes.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Compilador C/C++ com pthread, imagem de teste (PNG 1024x1024), Valgrind ou ThreadSanitizer.",
                                  "tips": "Use imagens com bordas nítidas para visualizar artefatos facilmente.",
                                  "learningObjective": "Compreender como acessos concorrentes a memória compartilhada causam race conditions em processamento paralelo de imagens.",
                                  "commonMistakes": "Ignorar pixels de borda; assumir que threads não se sobrepõem sem teste."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar Mecanismos de Exclusão Mútua: Locks e Semáforos",
                                  "subSteps": [
                                    "Revise conceitos: locks (mutex) para exclusão mútua binária e semáforos para contagem.",
                                    "Compare cenários: locks para seções críticas simples vs semáforos para recursos limitados.",
                                    "Estude APIs: pthread_mutex_lock/unlock e pthread_sem_init/post/wait.",
                                    "Analise trade-offs: overhead de locks granulares vs risco de deadlocks.",
                                    "Crie diagramas de fluxo mostrando threads aguardando/acessando memória compartilhada."
                                  ],
                                  "verification": "Resumo escrito comparando locks e semáforos, com pseudocódigo para filtro de imagem.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Documentação pthread (man pages), tutoriais online sobre sincronização POSIX.",
                                  "tips": "Priorize mutex para exclusão mútua simples em pixels; use semáforos se houver limite de threads simultâneas.",
                                  "learningObjective": "Selecionar o mecanismo apropriado de sincronização para acessos compartilhados em multithreading.",
                                  "commonMistakes": "Confundir semáforos binários com mutex; ignorar inicialização de estruturas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Exclusão Mútua em Código de Filtro de Imagem Multithread",
                                  "subSteps": [
                                    "Modifique o código para proteger seções críticas (ex: array de pixels) com pthread_mutex_t.",
                                    "Defina locks granulares por linha/borda de bloco para minimizar contenção.",
                                    "Integre ao loop de threads: lock antes de ler/escrever pixels compartilhados, unlock após.",
                                    "Adicione logging para rastrear aquisições/liberações de locks.",
                                    "Compile e execute com 4-8 threads em imagem grande."
                                  ],
                                  "verification": "Código compila sem warnings de thread-safety; saída da imagem é consistente em 100% das runs.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Código base de filtro multithread, pthread library, editor IDE (VSCode/Clion).",
                                  "tips": "Use mutex trylock para evitar deadlocks em casos de alta contenção.",
                                  "learningObjective": "Aplicar locks ou semáforos corretamente em memória compartilhada para processamento paralelo de imagens.",
                                  "commonMistakes": "Esquecer unlock (causa deadlock); locks muito amplos (reduz paralelismo)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar, Debugar e Otimizar a Sincronização",
                                  "subSteps": [
                                    "Execute stress tests com cargas variáveis de threads e imagens.",
                                    "Use ThreadSanitizer para detectar data races residuais.",
                                    "Meça performance: tempo de execução com vs sem locks.",
                                    "Otimize: teste locks readers-writer se leituras dominarem.",
                                    "Gere relatório com métricas e imagens antes/depois."
                                  ],
                                  "verification": "Nenhum data race detectado; speedup paralelo mantido (>2x vs sequencial).",
                                  "estimatedTime": "2 horas",
                                  "materials": "ThreadSanitizer (compilar com -fsanitize=thread), perf ou gprof para profiling.",
                                  "tips": "Monitore tempo de espera em locks para identificar gargalos.",
                                  "learningObjective": "Validar e refinar implementações de exclusão mútua para robustez e eficiência.",
                                  "commonMistakes": "Não testar com número alto de threads; ignorar overhead de sincronização."
                                }
                              ],
                              "practicalExample": "Em um filtro de borrão gaussiano aplicado a uma imagem 4K dividida em 8 threads, use um mutex para proteger o acesso ao buffer de pixels de borda entre blocos adjacentes. Cada thread adquire o lock, atualiza pixels compartilhados somando contribuições vizinhas e libera, produzindo imagem borrada consistente sem artefatos.",
                              "finalVerifications": [
                                "Execução múltipla (50+) produz imagens idênticas sem crashes ou deadlocks.",
                                "ThreadSanitizer ou Valgrind reporta zero data races ou leaks.",
                                "Performance: tempo < 2x sequencial com 4+ threads.",
                                "Logging mostra locks adquiridos/liberados corretamente sem starvation.",
                                "Imagem final visualmente correta (compare com versão sequencial).",
                                "Código limpo: todos locks pareados e inicializados."
                              ],
                              "assessmentCriteria": [
                                "Identificação precisa de race conditions com evidências (logs/imagens).",
                                "Escolha justificada de mutex/semáforo com trade-offs explicados.",
                                "Implementação correta: locks granulares, sem vazamentos ou deadlocks.",
                                "Testes abrangentes cobrindo cenários edge (alta contenção).",
                                "Otimização demonstrada com métricas de performance.",
                                "Documentação clara de código e relatório."
                              ],
                              "crossCurricularConnections": [
                                "Sistemas Operacionais: Conceitos de primitivas de sincronização POSIX.",
                                "Algoritmos e Estruturas de Dados: Buffers circulares para memória compartilhada.",
                                "Hardware: Cache coherence e NUMA em multicore.",
                                "Engenharia de Software: Design thread-safe e atomicidade."
                              ],
                              "realWorldApplication": "Em editores de imagem como Photoshop ou GIMP com processamento multithread, locks protegem buffers compartilhados durante filtros em tempo real, evitando corrupção em GPUs/CPs heterogêneas; similar em visão computacional para drones ou apps de AR."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.2.3",
                            "name": "Utilizar linguagens para multicores e GPUs",
                            "description": "Explorar OpenMP para multicores e CUDA/OpenCL para GPUs na implementação de filtros como Sobel ou Média, destacando diretivas de paralelização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente e aprender conceitos básicos de OpenMP para multicores",
                                  "subSteps": [
                                    "Instalar compilador com suporte a OpenMP (g++ com flag -fopenmp)",
                                    "Estudar diretivas principais: #pragma omp parallel, for, sections",
                                    "Entender cláusulas: num_threads, schedule, reduction",
                                    "Executar exemplo simples de paralelização de loop soma",
                                    "Analisar overhead de threads e escalabilidade em multicores"
                                  ],
                                  "verification": "Compilar e executar um programa OpenMP que paraleliza soma de array, verificando speedup com omp_get_wtime()",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Compilador GCC/Clang com OpenMP",
                                    "Editor de código (VS Code)",
                                    "Documentação OpenMP oficial",
                                    "Máquina com múltiplos cores (4+)"
                                  ],
                                  "tips": "Use OMP_NUM_THREADS para controlar threads manualmente e monitore com htop",
                                  "learningObjective": "Compreender e aplicar diretivas OpenMP para paralelizar loops em CPUs multicores",
                                  "commonMistakes": [
                                    "Esquecer flag -fopenmp no compile",
                                    "Race conditions sem reduction",
                                    "Sobrecarregar threads além do número de cores"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar filtro de Média usando OpenMP",
                                  "subSteps": [
                                    "Carregar imagem em formato PPM/PGM usando biblioteca simples (ex: stb_image)",
                                    "Implementar filtro de média sequencial (kernel 3x3)",
                                    "Paralelizar loop externo da imagem com #pragma omp parallel for",
                                    "Adicionar cláusula schedule(dynamic) para balanceamento",
                                    "Medir tempo sequencial vs paralelo e calcular speedup"
                                  ],
                                  "verification": "Executar filtro em imagem 1024x1024, speedup > 2x em 4 cores, sem artefatos visuais",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Biblioteca stb_image para I/O",
                                    "Imagens de teste (PGM 512x512 e 2048x2048)",
                                    "Profiler simples (time ou omp_get_wtime)"
                                  ],
                                  "tips": "Aplique padding na borda da imagem para evitar acessos inválidos",
                                  "learningObjective": "Desenvolver filtro de imagem convolucional paralelo em multicores com OpenMP",
                                  "commonMistakes": [
                                    "Acessos fora dos limites da imagem",
                                    "Não sincronizar writes em pixels compartilhados",
                                    "Ignorar cache locality em loops"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar ambiente CUDA/OpenCL e conceitos básicos de GPUs",
                                  "subSteps": [
                                    "Instalar CUDA Toolkit (NVIDIA) ou POCL para OpenCL",
                                    "Estudar modelo de execução: grids, blocks, threads, warps",
                                    "Escrever kernel simples de soma vetorizada",
                                    "Gerenciar memória: cudaMalloc, cudaMemcpy, cudaFree",
                                    "Executar e verificar com nvprof ou nsys para occupancy"
                                  ],
                                  "verification": "Kernel CUDA soma array de 1M elementos com speedup > 10x vs CPU serial",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "CUDA Toolkit 12+ ou OpenCL 2.0",
                                    "GPU NVIDIA compatível",
                                    "Documentação NVIDIA CUDA Programming Guide"
                                  ],
                                  "tips": "Use cudaDeviceSynchronize() para medir tempos kernel precisos",
                                  "learningObjective": "Dominar alocação de memória e lançamento de kernels em GPUs",
                                  "commonMistakes": [
                                    "Esquecer cudaMemcpy para transferir dados",
                                    "Blocos de threads > 1024",
                                    "Baixo occupancy por grid mal dimensionado"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar filtros Sobel e Média em GPU com CUDA/OpenCL",
                                  "subSteps": [
                                    "Adaptar filtro de Média para kernel CUDA (shared memory para kernel 3x3)",
                                    "Implementar Sobel (Gx e Gy) com kernels separados ou coalesced",
                                    "Otimizar com tiled convolution usando shared memory",
                                    "Comparar performance GPU vs OpenMP em mesma imagem",
                                    "Visualizar resultados com ferramenta como ImageMagick"
                                  ],
                                  "verification": "Filtros produzem saída idêntica à serial, speedup GPU > 20x vs CPU",
                                  "estimatedTime": "3-4 horas",
                                  "materials": [
                                    "stb_image para CPU/GPU I/O",
                                    "Imagens de teste com bordas (ex: lenna.pgm)",
                                    "nsys ou nvprof para profiling"
                                  ],
                                  "tips": "Coalesce acessos globais e use __syncthreads() em shared memory",
                                  "learningObjective": "Implementar convoluções eficientes em GPUs destacando paralelismo massivo",
                                  "commonMistakes": [
                                    "Thread divergence em branches condicionais",
                                    "Bank conflicts em shared memory",
                                    "Transferências H2D/D2H desnecessárias"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Analisar performance, otimizar e integrar plataformas heterogêneas",
                                  "subSteps": [
                                    "Medir speedup, eficiência e scaling (variações de tamanho imagem/threads)",
                                    "Otimizar hotspots identificados (ex: reduzir global memory access)",
                                    "Explorar runtime heterogêneo (OpenMP + CUDA via pragmas ou chamadas)",
                                    "Documentar trade-offs: CPU para controle, GPU para compute intensivo",
                                    "Testar em plataforma real heterogênea"
                                  ],
                                  "verification": "Relatório com gráficos speedup vs size, otimização >20% melhoria",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de plot (matplotlib ou gnuplot)",
                                    "Sistema com CPU multi-core + GPU"
                                  ],
                                  "tips": "Use roofline model para prever limites teóricos de performance",
                                  "learningObjective": "Avaliar e otimizar aplicações paralelas em hardware heterogêneo",
                                  "commonMistakes": [
                                    "Comparar apples-to-oranges (diferentes otimizações)",
                                    "Ignorar tempo de transferência PCIe",
                                    "Overfitting a uma imagem específica"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente o filtro Sobel em uma imagem médica de 2048x2048 (ex: raio-X). Use OpenMP para versão CPU (4 threads, speedup 3.5x) e CUDA para GPU (block 16x16, speedup 50x total), comparando tempos e qualidade visual com diff de pixels.",
                              "finalVerifications": [
                                "Códigos compilam sem warnings em OpenMP e CUDA",
                                "Filtros produzem saídas bitwise idênticas à implementação serial",
                                "Speedup mensurável: OpenMP >2x, GPU >20x em imagens grandes",
                                "Ausência de artefatos (bordas pretas, ruído) em visualização",
                                "Relatório com profiling mostra bottlenecks corretamente identificados",
                                "Integração heterogênea executa sem crashes"
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica dos filtros (erro <1e-6 vs serial)",
                                "Eficiência de paralelização (speedup linear até limite hardware)",
                                "Qualidade de código (modular, comentado, sem leaks de memória)",
                                "Otimização GPU (occupancy >50%, coalesced access)",
                                "Análise comparativa completa com métricas quantitativas",
                                "Tratamento robusto de bordas e tamanhos variados",
                                "Documentação de diretivas e kernels usadas"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Convolução matricial e gradientes (cálculo vetorial)",
                                "Física: Processamento de sinal e filtros espaciais",
                                "Engenharia de Computação: Arquitetura de hardware (SIMD, cache, PCIe)",
                                "Inteligência Artificial: Pré-processamento para visão computacional",
                                "Gestão de Projetos: Benchmarking e trade-off performance/custo"
                              ],
                              "realWorldApplication": "Em visão computacional para veículos autônomos (detecção de bordas em tempo real via GPU) ou processamento médico (filtros em tomografias com OpenMP para CPUs em clusters heterogêneos), acelerando pipelines de IA em data centers."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.4.3",
                        "name": "Avaliação de Desempenho e Estudos de Caso",
                        "description": "Métodos de avaliação de desempenho em aplicações paralelas de processamento de imagens e análise de estudos de caso reais em plataformas heterogêneas.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.4.3.1",
                            "name": "Medir speedup e eficiência em filtros paralelos",
                            "description": "Calcular métricas como speedup, eficiência e escalabilidade em implementações de filtros de imagem, usando leis de Amdahl e Gustafson em multicores e GPUs.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos teóricos de speedup, eficiência e leis de Amdahl e Gustafson",
                                  "subSteps": [
                                    "Estudar a definição de speedup como T_sequencial / T_paralelo",
                                    "Analisar eficiência como speedup / número de processadores",
                                    "Revisar a lei de Amdahl: limite de speedup considerando fração serial",
                                    "Explorar a lei de Gustafson: escalabilidade com aumento de problema",
                                    "Comparar aplicações em multicores e GPUs"
                                  ],
                                  "verification": "Escrever resumo de 200 palavras explicando cada métrica e fórmula",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentos sobre leis de Amdahl e Gustafson (Wikipedia/PDFs acadêmicos)",
                                    "Slides de programação paralela"
                                  ],
                                  "tips": "Anote as fórmulas matemáticas e exemplos numéricos simples",
                                  "learningObjective": "Dominar as bases teóricas para cálculo preciso de desempenho",
                                  "commonMistakes": [
                                    "Confundir speedup com eficiência",
                                    "Ignorar fração serial na lei de Amdahl",
                                    "Aplicar Gustafson sem escalar o problema"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar ambiente de medição para filtros de imagem",
                                  "subSteps": [
                                    "Implementar filtro sequencial (ex: Gaussian blur) em C++/OpenCV",
                                    "Preparar versão paralela com OpenMP para multicores",
                                    "Configurar versão GPU com CUDA ou OpenCL",
                                    "Definir tamanhos de imagem variados para testes de escalabilidade",
                                    "Instalar ferramentas de profiling (gprof, nvprof)"
                                  ],
                                  "verification": "Executar código sequencial e confirmar tempo baseline",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "OpenCV, OpenMP, CUDA Toolkit",
                                    "Imagens de teste (512x512 a 4096x4096)"
                                  ],
                                  "tips": "Use imagens grandes para evidenciar diferenças de performance",
                                  "learningObjective": "Preparar benchmarks reprodutíveis",
                                  "commonMistakes": [
                                    "Não sincronizar threads corretamente",
                                    "Usar imagens pequenas que mascaram overheads",
                                    "Esquecer de compilar com flags de otimização (-O3)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Medir tempos de execução sequencial e paralelo",
                                  "subSteps": [
                                    "Executar 10 runs sequenciais e calcular média/desvio padrão",
                                    "Medir tempos paralelos variando núcleos (1-16) e GPUs",
                                    "Registrar overheads de inicialização (MPI/CUDA)",
                                    "Automatizar medições com script bash/python",
                                    "Exportar dados para CSV"
                                  ],
                                  "verification": "Gerar tabela com tempos médios para cada configuração",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Cronômetro de alta precisão (std::chrono, CUDA events)",
                                    "Planilhas Excel ou Pandas"
                                  ],
                                  "tips": "Aqueça o sistema com runs iniciais para cache",
                                  "learningObjective": "Coletar dados confiáveis para análise",
                                  "commonMistakes": [
                                    "Média de poucos runs",
                                    "Não considerar variabilidade do SO",
                                    "Medir tempo wall-clock sem CPU time"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e analisar speedup, eficiência e escalabilidade",
                                  "subSteps": [
                                    "Calcular speedup para cada configuração usando fórmulas",
                                    "Aplicar lei de Amdahl para prever limites teóricos",
                                    "Usar Gustafson para cenários de problema escalável",
                                    "Plotar gráficos (speedup vs núcleos, eficiência vs núcleos)",
                                    "Interpretar desvios (bottlenecks, overheads)"
                                  ],
                                  "verification": "Produzir relatório com gráficos e tabelas de métricas",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python/Matplotlib ou GNUPlot",
                                    "Fórmulas em spreadsheet"
                                  ],
                                  "tips": "Valide cálculos com exemplos teóricos conhecidos",
                                  "learningObjective": "Interpretar métricas para otimização",
                                  "commonMistakes": [
                                    "Usar tempo total incluindo I/O",
                                    "Não normalizar por tamanho de imagem",
                                    "Ignorar superlinear speedup em GPUs"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e comparar desempenhos em plataformas heterogêneas",
                                  "subSteps": [
                                    "Comparar multicores vs GPUs em speedup e eficiência",
                                    "Simular frações seriais variadas e prever com Amdahl",
                                    "Testar escalabilidade Gustafson com imagens maiores",
                                    "Documentar conclusões e recomendações",
                                    "Preparar apresentação de resultados"
                                  ],
                                  "verification": "Gráfico comparativo multicores/GPU com análise escrita",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Ferramentas de plotagem",
                                    "Relatório template LaTeX/Markdown"
                                  ],
                                  "tips": "Foco em trade-offs: custo vs performance",
                                  "learningObjective": "Aplicar conhecimentos em contextos reais heterogêneos",
                                  "commonMistakes": [
                                    "Generalizar resultados sem múltiplos testes",
                                    "Esquecer limitações de memória em GPUs",
                                    "Não discutir portabilidade de código"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um filtro de mediana em uma imagem 2048x2048: versão sequencial em OpenCV (baseline 10s), OpenMP com 8 núcleos (speedup 5.2, eficiência 65%), CUDA em GPU (speedup 45, eficiência 90%). Calcule usando Amdahl (fração serial 10%) prevendo limite 5.6x em infinitos núcleos.",
                              "finalVerifications": [
                                "Cálculo correto de speedup e eficiência com erro <1%",
                                "Gráficos de speedup/escalabilidade gerados e interpretados",
                                "Aplicação precisa das leis de Amdahl e Gustafson",
                                "Dados de medição com médias e desvios padrões",
                                "Análise de bottlenecks identificados",
                                "Relatório com conclusões acionáveis"
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas fórmulas (30%)",
                                "Qualidade e reprodutibilidade das medições (25%)",
                                "Interpretação teórica e prática (20%)",
                                "Visualizações claras e informativas (15%)",
                                "Documentação completa e organizada (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Cálculo numérico e análise de funções",
                                "Engenharia de Software: Benchmarking e profiling",
                                "Processamento de Sinais: Filtros em imagens",
                                "Arquitetura de Computadores: Paralelismo em hardware",
                                "Estatística: Análise de variância em medições"
                              ],
                              "realWorldApplication": "Em visão computacional para carros autônomos (detecção de objetos em vídeo real-time), processamento médico de imagens (MRI/CT em hospitais) e edição de vídeo em streaming (Netflix/YouTube), onde otimizar speedup reduz latência e custos de computação em nuvem."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.3.2",
                            "name": "Analisar estudo de caso em processamento heterogêneo",
                            "description": "Estudar casos reais de filtros de imagem em plataformas heterogêneas, comparando desempenho entre CPU multicores, GPUs e nuvem, com base em referências como Grama et al. e Pacheco.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e Compreender o Estudo de Caso",
                                  "subSteps": [
                                    "Identifique estudos de caso relevantes em processamento de imagens heterogêneo, focando em filtros como Gaussian blur ou edge detection.",
                                    "Leia a introdução e o contexto do paper de Grama et al. ou Pacheco para entender o problema.",
                                    "Resuma os objetivos do estudo, incluindo o tipo de filtro de imagem e as plataformas testadas (CPU multicores, GPU, nuvem).",
                                    "Anote os desafios iniciais mencionados, como latência e escalabilidade.",
                                    "Crie um mapa mental das seções principais do estudo."
                                  ],
                                  "verification": "Resumo escrito de 1 página com mapa mental anexado, cobrindo objetivos e plataformas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Acesso a papers: Grama et al. 'Introduction to Parallel Computing', Pacheco 'Parallel Programming', PDF reader",
                                    "Ferramentas de mind mapping como XMind ou papel e caneta"
                                  ],
                                  "tips": "Comece pelo abstract e conclusões para visão geral rápida.",
                                  "learningObjective": "Compreender o escopo e motivação do estudo de caso em processamento heterogêneo.",
                                  "commonMistakes": [
                                    "Ignorar referências bibliográficas iniciais",
                                    "Não diferenciar filtros de imagem específicos",
                                    "Ler superficialmente sem anotações"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Plataformas e Implementações",
                                  "subSteps": [
                                    "Liste as plataformas usadas: CPU multicores (ex: OpenMP), GPU (ex: CUDA/OpenCL), nuvem (ex: AWS EC2 com GPUs).",
                                    "Descreva as implementações paralelas para o filtro de imagem em cada plataforma.",
                                    "Registre métricas de desempenho coletadas, como tempo de execução, throughput e uso de memória.",
                                    "Compare arquiteturas: núcleos vs. streams CUDA vs. instâncias em nuvem.",
                                    "Anote ferramentas de profiling usadas no estudo (ex: gprof, NVIDIA Nsight)."
                                  ],
                                  "verification": "Tabela comparativa das plataformas com colunas para implementação, métricas e ferramentas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Papers selecionados",
                                    "Planilha Excel ou Google Sheets para tabelas",
                                    "Documentação de OpenMP/CUDA/AWS"
                                  ],
                                  "tips": "Use cores para destacar diferenças arquiteturais na tabela.",
                                  "learningObjective": "Mapear implementações paralelas em plataformas heterogêneas para filtros de imagem.",
                                  "commonMistakes": [
                                    "Confundir CPU multicores com GPUs",
                                    "Omitir detalhes de bibliotecas usadas",
                                    "Não registrar unidades de métricas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar e Comparar Dados de Desempenho",
                                  "subSteps": [
                                    "Colete dados numéricos de tempo de execução para tamanhos de imagem variados (ex: 512x512, 4K).",
                                    "Calcule speedup e eficiência: speedup = tempo_seq / tempo_paralelo.",
                                    "Gere gráficos de barras ou linhas comparando CPU, GPU e nuvem.",
                                    "Identifique gargalos: ex: transferência de dados em GPU, custo em nuvem.",
                                    "Aplique testes estatísticos simples se disponíveis no estudo (ex: variância)."
                                  ],
                                  "verification": "Gráficos gerados e tabela de speedup com cálculos mostrados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de plotagem: Python Matplotlib, Excel",
                                    "Dados extraídos dos papers",
                                    "Calculadora ou Python para speedup"
                                  ],
                                  "tips": "Normalize dados por tamanho de imagem para comparações justas.",
                                  "learningObjective": "Realizar análise quantitativa de desempenho em cenários heterogêneos.",
                                  "commonMistakes": [
                                    "Usar escalas diferentes nos gráficos",
                                    "Esquecer overhead de comunicação",
                                    "Ignorar tamanhos de entrada variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Tirar Conclusões e Discutir Implicações",
                                  "subSteps": [
                                    "Resuma achados principais: qual plataforma vence em quais cenários?",
                                    "Discuta trade-offs: custo vs. performance, portabilidade.",
                                    "Relacione com referências de Grama e Pacheco sobre escalabilidade.",
                                    "Proponha melhorias hipotéticas, como hybrid CPU-GPU.",
                                    "Escreva recomendações para aplicações reais de processamento de imagens."
                                  ],
                                  "verification": "Relatório de 1-2 páginas com conclusões, trade-offs e recomendações.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Editor de texto ou LaTeX",
                                    "Papers para citação"
                                  ],
                                  "tips": "Use bullet points para trade-offs claros.",
                                  "learningObjective": "Sintetizar análises em insights acionáveis para programação paralela.",
                                  "commonMistakes": [
                                    "Conclusões sem suporte de dados",
                                    "Ignorar limitações do estudo",
                                    "Não citar fontes"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar Análise com Simulação Simples",
                                  "subSteps": [
                                    "Implemente um filtro simples (ex: grayscale) sequencial em CPU.",
                                    "Paralelize com OpenMP e teste em multicores local.",
                                    "Simule GPU com código CUDA básico ou use Google Colab para nuvem.",
                                    "Meça tempos e compare com dados do estudo.",
                                    "Ajuste análise inicial com resultados práticos."
                                  ],
                                  "verification": "Código fonte com outputs de tempo e comparação tabular.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Ambiente de programação: GCC com OpenMP, CUDA toolkit ou Colab",
                                    "Imagens de teste (ex: Lena 512x512)"
                                  ],
                                  "tips": "Use imagens pequenas primeiro para depuração rápida.",
                                  "learningObjective": "Validar conceitos teóricos com experimentação prática.",
                                  "commonMistakes": [
                                    "Não sincronizar threads corretamente",
                                    "Omitir warm-up runs",
                                    "Comparar hardware diferente"
                                  ]
                                }
                              ],
                              "practicalExample": "Analise o estudo de caso do paper de Pacheco sobre filtro Sobel em CPU (OpenMP, 8 cores), GPU (CUDA GTX 1080) e AWS EC2 g4dn.xlarge: CPU leva 2.5s para 4K image, GPU 0.3s, nuvem 0.5s com custo $0.01; conclua que GPU local é ideal para batch processing offline.",
                              "finalVerifications": [
                                "Relatório completo com resumo, tabelas, gráficos e conclusões.",
                                "Cálculos de speedup validados com pelo menos 3 tamanhos de imagem.",
                                "Simulação prática executada com código funcional.",
                                "Trade-offs discutidos com exemplos quantitativos.",
                                "Referências citadas corretamente (Grama et al., Pacheco).",
                                "Recomendações personalizadas para um cenário real."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e análise de dados de desempenho (30%).",
                                "Qualidade dos gráficos e tabelas comparativos (20%).",
                                "Profundidade das conclusões e trade-offs (20%).",
                                "Validação prática via simulação (15%).",
                                "Clareza e estrutura do relatório (10%).",
                                "Integração de referências bibliográficas (5%)."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear para representações de filtros convolucionais.",
                                "Engenharia de Software: Design de APIs portáteis para heterogeneidade (ex: OpenCL).",
                                "Ciência da Computação: Algoritmos de otimização e profiling.",
                                "Economia/Gestão: Análise custo-benefício em computação em nuvem.",
                                "Física/Engenharia: Processamento de sinais em imagens médicas."
                              ],
                              "realWorldApplication": "Em empresas como Google ou Adobe, analistas usam isso para otimizar pipelines de visão computacional em apps de edição de fotos (Photoshop) ou diagnósticos médicos, escolhendo GPU para real-time filtering em smartphones ou nuvem para grandes datasets de satélite."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.3.3",
                            "name": "Otimizar código paralelo para imagens grandes",
                            "description": "Identificar gargalos (overhead de comunicação, balanceamento de carga) e otimizar implementações de filtros em linguagens como OpenMP e CUDA para imagens de alta resolução.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Perfilamento e Identificação de Gargalos",
                                  "subSteps": [
                                    "Carregue uma imagem de alta resolução (ex: 4096x4096 pixels) em formato PPM ou similar.",
                                    "Implemente uma versão baseline sequencial de um filtro de imagem (ex: Gaussiano ou mediana).",
                                    "Compile e execute com profilers: gprof ou Intel VTune para OpenMP, nvprof/nsys para CUDA.",
                                    "Analise métricas: tempo de overhead de comunicação, desbalanceamento de carga (via histograms de tempo por thread/block).",
                                    "Identifique gargalos principais: comunicação excessiva, load imbalance ou acessos de memória ineficientes."
                                  ],
                                  "verification": "Relatório de perfilamento gerado mostrando top 3 gargalos com métricas quantitativas (ex: % tempo em comunicação).",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Imagem grande (>1GB)",
                                    "Compiladores GCC/Clang com OpenMP",
                                    "CUDA Toolkit 11+",
                                    "Profilers: gprof, VTune, Nsight Systems"
                                  ],
                                  "tips": "Use imagens sintéticas geradas para testes repetíveis; foque em runs quentes (warm-up iterations).",
                                  "learningObjective": "Compreender e quantificar gargalos como overhead de comunicação e balanceamento de carga em código paralelo.",
                                  "commonMistakes": [
                                    "Ignorar overhead de inicialização",
                                    "Usar imagens pequenas que mascaram problemas",
                                    "Não normalizar métricas por core/GPU"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Otimização em OpenMP para Balanceamento de Carga",
                                  "subSteps": [
                                    "Paralelize o filtro com #pragma omp parallel for, usando schedule(dynamic) ou guided para load balance.",
                                    "Reduza overhead: agrupe loops internos, use collapse(2) para granularidade maior.",
                                    "Implemente redução de comunicação: privatize variáveis locais, use omp critical apenas quando necessário.",
                                    "Teste com diferentes números de threads e meça speedup com omp_get_wtime().",
                                    "Ajuste chunk sizes baseados no perfilamento anterior para minimizar imbalance."
                                  ],
                                  "verification": "Speedup >4x vs sequencial em 16 threads, com variance de tempo por thread <10%.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": [
                                    "Código baseline do Step 1",
                                    "Máquina multi-core (8+ cores)",
                                    "OpenMP 4.5+"
                                  ],
                                  "tips": "Monitore com omp_set_num_threads() e export OMP_DISPLAY_ENV=VERBOSE.",
                                  "learningObjective": "Aplicar técnicas de OpenMP para mitigar overhead de comunicação e balancear carga em imagens grandes.",
                                  "commonMistakes": [
                                    "schedule(static) em workloads irregulares",
                                    "False sharing em arrays compartilhados",
                                    "Excesso de sincronizações"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Otimização em CUDA para Imagens Grandes",
                                  "subSteps": [
                                    "Porte o filtro para CUDA: aloque memória com cudaMallocPitch para alinhamento 2D.",
                                    "Garanta coalescência de memória: use acessos shared memory para tiles de imagem.",
                                    "Balanceie blocos: calcule grid/block sizes baseado em tamanho da imagem (ex: 16x16 threads/block).",
                                    "Minimize overhead: streams para overlap compute/communication, unroll loops internos.",
                                    "Perfil com Nsight Compute: otimize occupancy e registre spills."
                                  ],
                                  "verification": "Kernel executa sem erros de memória (cuda-memcheck), speedup >10x vs CPU em GPU moderna.",
                                  "estimatedTime": "4-5 horas",
                                  "materials": [
                                    "NVIDIA GPU (RTX série)",
                                    "CUDA Samples para filtros",
                                    "Nsight Systems/Compute"
                                  ],
                                  "tips": "Use cudaDeviceSynchronize() apenas para medições; prefira eventos para timing preciso.",
                                  "learningObjective": "Otimizar kernels CUDA para throughput em imagens de alta resolução, focando memória e balanceamento.",
                                  "commonMistakes": [
                                    "Acessos não-coalescentes",
                                    "Blocos muito grandes (>1024 threads)",
                                    "Ignorar limite de shared memory (48KB)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparação, Tuning Híbrido e Validação",
                                  "subSteps": [
                                    "Compare desempenhos: rode benchmarks em OpenMP vs CUDA para múltiplas imagens.",
                                    "Implemente híbrido: OpenMP para pré-processamento + CUDA para filtro principal via cudaMemcpyAsync.",
                                    "Tune parâmetros: auto-tune chunk/block sizes com grid search simples.",
                                    "Valide qualidade: compare output com baseline sequencial (PSNR >40dB).",
                                    "Documente trade-offs: energia, escalabilidade com imagens maiores."
                                  ],
                                  "verification": "Tabela de benchmarks mostrando speedup relativo e qualidade preservada.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Scripts de benchmark (Python/Matlab para PSNR)",
                                    "Ferramentas de power profiling (nvidia-smi)"
                                  ],
                                  "tips": "Use imagens reais (ex: do dataset DIV2K) para realismo; automatize com Makefiles.",
                                  "learningObjective": "Integrar otimizações OpenMP/CUDA, comparando em cenários heterogêneos.",
                                  "commonMistakes": [
                                    "Overfitting a uma imagem",
                                    "Esquecer validação de precisão numérica",
                                    "Não considerar overhead de transferência PCI-e"
                                  ]
                                }
                              ],
                              "practicalExample": "Otimizar um filtro de mediana 5x5 em imagem 8192x8192 pixels: baseline sequencial leva 120s em CPU; após otimizações, OpenMP atinge 20s (6x speedup), CUDA 8s (15x), com PSNR=inf (exato).",
                              "finalVerifications": [
                                "Código paralelo roda sem crashes ou erros de memória em imagens >4K.",
                                "Identificados e mitigados pelo menos 2 gargalos principais (com métricas antes/depois).",
                                "Speedup OpenMP >4x e CUDA >10x vs sequencial.",
                                "Balanceamento de carga: std dev tempo/thread <15%.",
                                "Qualidade da imagem preservada (PSNR >50dB).",
                                "Benchmark comparativo documentado em tabela.",
                                "Código comentado e reproduzível."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de gargalos (80% das métricas corretas).",
                                "Efetividade das otimizações (speedup mínimo alcançado).",
                                "Qualidade do código: legibilidade, comentários e modularidade.",
                                "Análise quantitativa: gráficos de speedup e profiling.",
                                "Correção numérica e robustez para tamanhos variados.",
                                "Documentação de trade-offs e limitações."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear para operações convolucionais e análise de FFT.",
                                "Hardware/Arquitetura: Entendimento de caches, pipelines GPU e topologias NUMA.",
                                "Análise de Dados: Técnicas de profiling e visualização de métricas de performance.",
                                "Engenharia de Software: Refatoração, testes unitários e versionamento com Git.",
                                "Inteligência Artificial: Pré-processamento para visão computacional em ML."
                              ],
                              "realWorldApplication": "Otimização de processamento de imagens em satélites (ex: análise de terras via Google Earth Engine), imaging médico (CT/MRI em tempo real) ou visão computacional em carros autônomos (detecção de objetos em 4K+ video feeds)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.5",
                    "name": "Estudo de Caso: Aplicações em Computação em Nuvem",
                    "description": "Análise de programas paralelos escaláveis na nuvem, com ênfase em modelos distribuídos e avaliação de performance.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.5.1",
                        "name": "Modelos de Programação Distribuída na Nuvem",
                        "description": "Exploração dos principais modelos de programação paralela para memória distribuída aplicados em ambientes de computação em nuvem, incluindo troca de mensagens e decomposição de domínio.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.5.1.1",
                            "name": "Identificar modelos de troca de mensagens em plataformas de nuvem",
                            "description": "Analisar o uso de bibliotecas como MPI em clusters de nuvem para comunicação entre processos distribuídos, destacando paradigmas como send-receive e collective operations.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Comunicação Distribuída",
                                  "subSteps": [
                                    "Estude definições de processos distribuídos e necessidade de troca de mensagens em clusters de nuvem.",
                                    "Revise paradigmas básicos: ponto-a-ponto vs. coletivo.",
                                    "Analise diferenças entre comunicação síncrona e assíncrona.",
                                    "Explore exemplos iniciais de bibliotecas como MPI, PVM e sockets.",
                                    "Identifique contextos de uso em plataformas de nuvem como AWS ou GCP."
                                  ],
                                  "verification": "Resuma em um diagrama os paradigmas básicos e liste 3 exemplos de bibliotecas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação oficial do MPI (mpi-forum.org)",
                                    "Slides introdutórios sobre computação distribuída",
                                    "Acesso a um cluster de nuvem gratuito (ex: Google Colab com MPI)"
                                  ],
                                  "tips": "Use diagramas de fluxo para visualizar trocas de mensagens; comece com analogias cotidianas como envio de cartas.",
                                  "learningObjective": "Diferenciar modelos fundamentais de comunicação em sistemas distribuídos.",
                                  "commonMistakes": [
                                    "Confundir comunicação ponto-a-ponto com coletiva",
                                    "Ignorar latência em ambientes de nuvem",
                                    "Não considerar falhas de rede"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Paradigma Send-Receive no MPI",
                                  "subSteps": [
                                    "Instale e configure MPI em um ambiente local ou nuvem (ex: MPICH ou OpenMPI).",
                                    "Implemente exemplos básicos de MPI_Send e MPI_Recv em código C ou Python (mpi4py).",
                                    "Teste comunicação síncrona e assíncrona com MPI_Isend/MPI_Irecv.",
                                    "Meça performance em um cluster simulado (ex: múltiplos terminais ou Docker).",
                                    "Analise deadlocks comuns em send-receive e como evitá-los com MPI_Bsend."
                                  ],
                                  "verification": "Execute um programa que envie e receba mensagens entre 2 processos e capture o output correto.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Compilador C/GCC com MPI",
                                    "mpi4py para Python",
                                    "Ambiente Docker para simular cluster",
                                    "Tutoriais LLNL MPI (hpc-tutorials.llnl.gov)"
                                  ],
                                  "tips": "Sempre inicialize com MPI_Init e finalize com MPI_Finalize; use ranks para identificar processos.",
                                  "learningObjective": "Implementar e debugar trocas ponto-a-ponto usando MPI.",
                                  "commonMistakes": [
                                    "Esquecer MPI_Init/Finalize",
                                    "Mismatch de tags em recv",
                                    "Deadlocks por ordem errada de send/recv"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Operações Coletivas em MPI",
                                  "subSteps": [
                                    "Estude funções como MPI_Bcast, MPI_Reduce, MPI_Allreduce e MPI_Gather.",
                                    "Implemente exemplos de broadcast e redução em um programa multi-processo.",
                                    "Compare performance de coletivas vs. ponto-a-ponto em cenários distribuídos.",
                                    "Teste em cluster de nuvem (ex: AWS ParallelCluster) com 4+ nós.",
                                    "Documente topologias comuns (cartesianas, estrelas) para coletivas."
                                  ],
                                  "verification": "Crie e rode um programa que use MPI_Allreduce para somar valores de todos processos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "AWS ParallelCluster ou Google Cloud HPC",
                                    "Exemplos de código do site OpenMPI",
                                    "Ferramentas de profiling como mpiP"
                                  ],
                                  "tips": "Escolha o root process corretamente; use non-blocking para otimizar.",
                                  "learningObjective": "Aplicar operações coletivas para comunicação eficiente em grupos de processos.",
                                  "commonMistakes": [
                                    "Usar coletivas em vez de ponto-a-ponto quando não necessário",
                                    "Ignorar datatype mismatches",
                                    "Não escalar corretamente com número de processos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar e Comparar Modelos em Plataformas de Nuvem",
                                  "subSteps": [
                                    "Revise arquiteturas de clusters de nuvem (ex: Slurm + MPI no Azure).",
                                    "Compare MPI com alternativas como Apache Spark RDDs ou Ray.",
                                    "Crie um relatório comparando send-receive vs. coletivas em workloads reais.",
                                    "Simule falhas de rede e recuperação em nuvem.",
                                    "Identifique quando usar cada modelo baseado em latência/bandwidth."
                                  ],
                                  "verification": "Produza um tabela comparativa de modelos com prós/contras e exemplos de código.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação AWS/GCP para HPC",
                                    "Papers sobre MPI na nuvem (ex: SC conferences)",
                                    "Ferramentas como Ganglia para monitoring"
                                  ],
                                  "tips": "Considere custos de nuvem; use instâncias spot para testes.",
                                  "learningObjective": "Reconhecer e selecionar modelos apropriados para cenários de nuvem.",
                                  "commonMistakes": [
                                    "Generalizar performance local para nuvem",
                                    "Ignorar overhead de virtualização",
                                    "Não testar escalabilidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente um programa MPI em AWS ParallelCluster onde 4 processos simulam nós de um grafo: use send-receive para trocas vizinhas e MPI_Allreduce para computar soma global de distâncias, medindo tempo em um workload de machine learning distribuído.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças entre send-receive e coletivas com diagrama.",
                                "Executar código MPI sem erros em cluster de 4+ processos.",
                                "Identificar deadlock em código dado e corrigi-lo.",
                                "Comparar performance de MPI vs. sockets em benchmark simples.",
                                "Listar 3 cenários reais de nuvem onde cada paradigma é preferível.",
                                "Produzir relatório de 1 página com análise de um caso de estudo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção de paradigmas (90%+ correto).",
                                "Códigos funcionais e eficientes sem deadlocks.",
                                "Análise de performance com métricas quantificáveis.",
                                "Uso correto de terminologia MPI e conceitos distribuídos.",
                                "Criatividade em exemplos práticos e conexões com nuvem.",
                                "Relatório claro com diagramas e evidências empíricas."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Protocolos de transporte (TCP/UDP análogos).",
                                "Sistemas Operacionais: Gerenciamento de processos e IPC.",
                                "Big Data: Integração com Spark/Hadoop para workflows híbridos.",
                                "Inteligência Artificial: Treinamento distribuído de modelos (Horovod + MPI).",
                                "Engenharia de Software: Design patterns para paralelismo."
                              ],
                              "realWorldApplication": "Em supercomputação na nuvem como o NASA HECC ou AWS para simulações climáticas, onde MPI send-receive gerencia dados locais entre nós e coletivas agregam resultados globais, otimizando workloads HPC escaláveis."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.1.2",
                            "name": "Aplicar decomposição de domínio em aplicações paralelas na nuvem",
                            "description": "Dividir problemas computacionais em subdomínios independentes para execução paralela em nós distribuídos na nuvem, considerando balanceamento de carga e sobreposições.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Análise do Problema Computacional",
                                  "subSteps": [
                                    "Identifique o problema computacional candidato à decomposição de domínio, como simulações numéricas ou processamento de grids.",
                                    "Analise as dependências espaciais e temporais no domínio do problema.",
                                    "Determine as regiões independentes ou com mínima sobreposição.",
                                    "Estime o tamanho do domínio e requisitos computacionais.",
                                    "Documente as características que favorecem paralelismo na nuvem."
                                  ],
                                  "verification": "Criar um diagrama do domínio original com regiões destacadas para decomposição.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Papel e caneta ou ferramenta de diagramação como Draw.io",
                                    "Descrição do problema de exemplo"
                                  ],
                                  "tips": "Comece com problemas regulares como grades 2D/3D para facilitar a visualização.",
                                  "learningObjective": "Compreender as propriedades do problema que permitem decomposição de domínio.",
                                  "commonMistakes": [
                                    "Ignorar dependências não-espaciais",
                                    "Subestimar overhead de comunicação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Decomposição em Subdomínios Independentes",
                                  "subSteps": [
                                    "Divida o domínio global em subdomínios geométricos independentes.",
                                    "Defina regiões de sobreposição (ghost cells) para problemas com interdependências.",
                                    "Aplique métodos como decomposição em blocos ou recursiva.",
                                    "Calcule o número ideal de subdomínios baseado no número de nós disponíveis.",
                                    "Valide a independência dos subdomínios via análise estática."
                                  ],
                                  "verification": "Gerar um esquema visual dos subdomínios com sobreposições marcadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software de programação (Python/MATLAB)",
                                    "Bibliotecas numéricas como NumPy"
                                  ],
                                  "tips": "Use decomposição uniforme para iniciantes; refine para domínios irregulares.",
                                  "learningObjective": "Dominar técnicas de partição de domínio para minimizar comunicações.",
                                  "commonMistakes": [
                                    "Partições desbalanceadas em tamanho",
                                    "Sobreposições excessivas que aumentam memória"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Design de Distribuição na Nuvem",
                                  "subSteps": [
                                    "Selecione um modelo de programação distribuída (ex: MPI, Spark, Dask).",
                                    "Mapeie subdomínios para nós virtuais na nuvem (ex: EC2 instances).",
                                    "Planeje o balanceamento inicial de carga baseado em complexidade computacional.",
                                    "Defina estratégias de comunicação entre nós (ex: all-to-all para sobreposições).",
                                    "Configure escalabilidade horizontal para mais nós."
                                  ],
                                  "verification": "Criar um grafo de mapeamento subdomínio-nó com estimativas de carga.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Conta em nuvem (AWS/GCP free tier)",
                                    "Documentação de frameworks distribuídos"
                                  ],
                                  "tips": "Priorize frameworks gerenciados como Spark para reduzir setup.",
                                  "learningObjective": "Projetar distribuições eficientes considerando topologia da nuvem.",
                                  "commonMistakes": [
                                    "Ignorar latência de rede entre regiões",
                                    "Mapeamento fixo sem considerar heterogeneidade de nós"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementação e Execução Paralela",
                                  "subSteps": [
                                    "Implemente o código para distribuição de subdomínios e trocas de fronteira.",
                                    "Configure o cluster na nuvem e lance a aplicação paralela.",
                                    "Monitore execução com ferramentas de profiling (ex: Ganglia, CloudWatch).",
                                    "Execute iterações do algoritmo em paralelo.",
                                    "Colete resultados parciais e agregue no domínio global."
                                  ],
                                  "verification": "Executar o código e obter saída correta comparada à versão sequencial.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Ambiente de nuvem configurado",
                                    "Código-fonte em Python com PySpark ou MPI4Py"
                                  ],
                                  "tips": "Teste em escala pequena (2-4 nós) antes de escalar.",
                                  "learningObjective": "Implementar decomposição funcional em ambientes distribuídos.",
                                  "commonMistakes": [
                                    "Deadlocks em trocas de dados",
                                    "Perda de dados em agregação"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimização de Balanceamento de Carga e Verificação",
                                  "subSteps": [
                                    "Meça cargas por nó e identifique desbalanceamentos.",
                                    "Ajuste partições dinamicamente ou use load balancers.",
                                    "Otimize sobreposições para reduzir comunicações.",
                                    "Compare speedup e eficiência com baseline sequencial.",
                                    "Teste resiliência a falhas de nós."
                                  ],
                                  "verification": "Relatório com métricas: speedup > 80% do ideal, variação de carga < 15%.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de monitoramento (Spark UI, AWS CloudWatch)",
                                    "Dados de performance"
                                  ],
                                  "tips": "Use partição adaptativa para workloads heterogêneos.",
                                  "learningObjective": "Otimizar aplicações paralelas para performance na nuvem.",
                                  "commonMistakes": [
                                    "Otimização prematura sem profiling",
                                    "Ignorar custos de transferência de dados"
                                  ]
                                }
                              ],
                              "practicalExample": "Implemente decomposição de domínio para resolver a equação de calor em uma grade 2D de 1000x1000 usando PySpark em um cluster EMR na AWS, dividindo em 16 subdomínios com 5% de sobreposição, alcançando speedup de 12x em 8 nós.",
                              "finalVerifications": [
                                "A aplicação executa corretamente em pelo menos 4 nós distribuídos.",
                                "Resultados coincidem com versão sequencial (erro < 1e-6).",
                                "Variação de tempo de computação entre nós < 20%.",
                                "Comunicação de sobreposições não excede 10% do tempo total.",
                                "Escalabilidade demonstrada com +50% speedup ao dobrar nós.",
                                "Código é resiliente a falha de um nó."
                              ],
                              "assessmentCriteria": [
                                "Precisão da decomposição (independência e cobertura total).",
                                "Eficiência de balanceamento de carga (variação < 15%).",
                                "Speedup linear ou superlinear em relação a nós.",
                                "Uso eficiente de recursos na nuvem (custo/tempo otimizado).",
                                "Qualidade do código: modularidade e documentação.",
                                "Análise de performance com gráficos de profiling."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Métodos Numéricos e Análise de Erros.",
                                "Engenharia de Software: Design de Sistemas Distribuídos.",
                                "Administração: Gerenciamento de Recursos e Custos em Nuvem.",
                                "Física: Simulações Computacionais de Fenômenos Contínuos.",
                                "Gestão de Projetos: Escalabilidade e Resiliência em Ambientes Distribuídos."
                              ],
                              "realWorldApplication": "Aplicado em simulações climáticas (modelos GCM no Google Cloud), processamento de imagens satélite em larga escala (NASA Earthdata), treinamento distribuído de redes neurais (TensorFlow em Kubernetes) e análise sísmica em óleo e gás (Petrobras na AWS)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.1.3",
                            "name": "Gerenciar exclusão mútua em memória distribuída na nuvem",
                            "description": "Implementar mecanismos de sincronização como barreiras e locks distribuídos para evitar condições de corrida em programas paralelos executados em infraestrutura de nuvem.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Fundamentos de Exclusão Mútua em Sistemas Distribuídos",
                                  "subSteps": [
                                    "Estude conceitos de condições de corrida (race conditions) em memória compartilhada distribuída.",
                                    "Analise o problema da exclusão mútua em ambientes de nuvem sem coordenação centralizada.",
                                    "Revise algoritmos clássicos como Lamport Bakery e Peterson adaptados para distribuição.",
                                    "Explore barreiras de sincronização e seu papel em programas paralelos distribuídos.",
                                    "Identifique desafios específicos da nuvem, como latência de rede e particionamento."
                                  ],
                                  "verification": "Resuma em um diagrama os problemas de race conditions e soluções básicas, explicando verbalmente ou por escrito.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Documentação de sistemas distribuídos (ex: 'Distributed Systems' de Tanenbaum), vídeos Khan Academy sobre sincronização, diagramação tool como Draw.io"
                                  ],
                                  "tips": "Use analogias reais, como múltiplos caixas em um supermercado sem coordenação, para visualizar race conditions.",
                                  "learningObjective": "Dominar os princípios teóricos de mutual exclusion e identificar cenários de risco em nuvem.",
                                  "commonMistakes": [
                                    "Confundir locks locais com distribuídos",
                                    "Ignorar latência de rede em análises teóricas",
                                    "Subestimar impacto de falhas em nós"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar Ambiente de Nuvem para Testes Distribuídos",
                                  "subSteps": [
                                    "Crie uma conta gratuita em AWS, GCP ou Azure e configure instâncias virtuais (ex: EC2 ou VMs).",
                                    "Instale linguagens de programação paralela como Java, Go ou Python com bibliotecas distribuídas (ex: Apache ZooKeeper client).",
                                    "Configure um serviço de coordenação distribuída como ZooKeeper ou etcd em cluster.",
                                    "Desenvolva um programa simples de contador compartilhado para simular memória distribuída.",
                                    "Teste conectividade e deploy inicial entre instâncias."
                                  ],
                                  "verification": "Execute um script simples em múltiplas instâncias e confirme logs de comunicação sem erros.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Contas AWS/GCP free tier, ZooKeeper ou etcd Docker images, IDE como VS Code com extensões de nuvem"
                                  ],
                                  "tips": "Use Docker Compose para simular cluster localmente antes de deploy em nuvem para economizar custos.",
                                  "learningObjective": "Preparar infraestrutura prática para experimentação com sincronização distribuída.",
                                  "commonMistakes": [
                                    "Não configurar security groups/firewalls corretamente",
                                    "Usar IPs hardcoded em vez de DNS elástico",
                                    "Ignorar custos de instâncias persistentes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Locks Distribuídos para Exclusão Mútua",
                                  "subSteps": [
                                    "Integre cliente ZooKeeper para criar locks distribuídos usando znodes efêmeros.",
                                    "Implemente lógica de acquire/release lock com heartbeats para detecção de falhas.",
                                    "Modifique o contador compartilhado para usar lock antes de increment/decrement.",
                                    "Teste com múltiplas threads/instâncias concorrentes simulando carga alta.",
                                    "Adicione retry mechanisms para falhas de rede."
                                  ],
                                  "verification": "Execute 1000+ operações concorrentes e verifique que o contador final é correto (sem race conditions).",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "ZooKeeper library (Curator para Java ou kazoo para Python), código-fonte de exemplo no GitHub (distributed-lock-examples)"
                                  ],
                                  "tips": "Monitore znodes via ZooKeeper shell para visualizar locks ativos em tempo real.",
                                  "learningObjective": "Construir e validar um mecanismo de lock distribuído funcional em nuvem.",
                                  "commonMistakes": [
                                    "Não usar locks efêmeros levando a deadlocks em falhas",
                                    "Timeouts muito curtos causando starvation",
                                    "Falta de logging para depuração"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar Barreiras Distribuídas para Sincronização de Fases",
                                  "subSteps": [
                                    "Estenda ZooKeeper para criar barreiras cíclicas usando contadores em znodes.",
                                    "Implemente arrive/await/release para sincronizar N processos distribuídos.",
                                    "Integre barreira ao programa de contador para fases de leitura/escrita coordenadas.",
                                    "Teste com cenários de chegada desbalanceada e falhas parciais.",
                                    "Otimize para escalabilidade adicionando suporte a grupos dinâmicos."
                                  ],
                                  "verification": "Logs mostram que todos os processos chegam à barreira antes de prosseguir, sem deadlocks.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Documentação ZooKeeper Recipes, exemplos de barreiras em repositórios open-source"
                                  ],
                                  "tips": "Simule falhas matando instâncias para testar robustez da barreira.",
                                  "learningObjective": "Desenvolver barreiras para coordenar fases paralelas em aplicações distribuídas.",
                                  "commonMistakes": [
                                    "Contadores não atômicos levando a contagens erradas",
                                    "Não resetar barreira entre ciclos",
                                    "Ignorar ordenação de chegada"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Testar, Depurar e Otimizar a Solução Completa",
                                  "subSteps": [
                                    "Crie testes de stress com ferramentas como JMeter ou Locust para simular tráfego real.",
                                    "Analise logs e métricas (throughput, latência) usando CloudWatch ou Prometheus.",
                                    "Depure race conditions residuais com ferramentas como gdb distribuído ou traces.",
                                    "Otimize performance reduzindo overhead de locks (ex: read-write locks).",
                                    "Documente o sistema e crie um relatório de lições aprendidas."
                                  ],
                                  "verification": "Sistema passa em todos os testes com 0 race conditions detectadas em 10k+ execuções.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de teste: Locust, Prometheus/Grafana, logs centralizados como ELK stack"
                                  ],
                                  "tips": "Use chaos engineering (ex: Chaos Monkey) para testar resiliência.",
                                  "learningObjective": "Validar e refinar implementações para produção em nuvem.",
                                  "commonMistakes": [
                                    "Testes insuficientes em baixa carga mascarando problemas",
                                    "Não medir latência end-to-end",
                                    "Otimizar prematuramente sem baseline"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de e-commerce na AWS, múltiplas instâncias Lambda/EC2 atualizam estoque compartilhado em DynamoDB. Use locks distribuídos via DynamoDB conditional writes ou ZooKeeper para evitar overselling durante picos de Black Friday.",
                              "finalVerifications": [
                                "Programa roda sem race conditions em pelo menos 3 instâncias simultâneas por 30 minutos.",
                                "Locks e barreiras liberam corretamente após falhas de nós.",
                                "Métricas mostram latência < 100ms e throughput escalável.",
                                "Código inclui tratamento de exceções para rede/particionamento.",
                                "Documentação cobre setup, uso e troubleshooting.",
                                "Testes unitários/integração cobrem 80%+ do código."
                              ],
                              "assessmentCriteria": [
                                "Precisão na prevenção de race conditions (verificado por testes automatizados).",
                                "Robustez a falhas (kill 1/3 nós e recuperação automática).",
                                "Eficiência: overhead de sincronização < 20% do tempo total.",
                                "Clareza e modularidade do código (legível e comentado).",
                                "Escalabilidade comprovada com 5+ instâncias.",
                                "Uso correto de serviços de nuvem nativos."
                              ],
                              "crossCurricularConnections": [
                                "Redes de Computadores: Entender CAP theorem e eventual consistency.",
                                "Banco de Dados Distribuídos: Locks em NoSQL como DynamoDB/Cassandra.",
                                "Segurança da Informação: Autenticação em serviços de coordenação.",
                                "Engenharia de Software: Padrões de design para alta disponibilidade.",
                                "Análise de Algoritmos: Complexidade temporal de algoritmos distribuídos."
                              ],
                              "realWorldApplication": "Em plataformas como Netflix ou Uber, locks distribuídos gerenciam reservas de recursos compartilhados (ex: assentos de voo ou rides) em clusters Kubernetes na nuvem, evitando overbooking e garantindo consistência em escala global."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.5.2",
                        "name": "Escalabilidade de Programas Paralelos na Nuvem",
                        "description": "Análise da escalabilidade linear e superlinear de algoritmos paralelos em plataformas de nuvem, relacionando com taxonomia de Flynn e modelos de memória distribuída.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.5.2.1",
                            "name": "Classificar aplicações paralelas pela taxonomia de Flynn em contextos de nuvem",
                            "description": "Categorizar programas como SIMD, MIMD e suas variantes em arquiteturas de nuvem heterogêneas, identificando adequação para escalabilidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos da Taxonomia de Flynn",
                                  "subSteps": [
                                    "Estude as quatro categorias principais: SISD, SIMD, MISD e MIMD.",
                                    "Identifique características chave de cada uma: instruções e dados sequenciais/paralelos.",
                                    "Analise exemplos clássicos como vetores para SIMD e multiprocessadores para MIMD.",
                                    "Compare variantes modernas como SPMD e MPMD.",
                                    "Anote definições em um glossário pessoal."
                                  ],
                                  "verification": "Crie um diagrama ou tabela resumindo as 4 categorias + variantes com exemplos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Computer Architecture: A Quantitative Approach' (Hennessy & Patterson)",
                                    "Artigo original de Michael J. Flynn (1966)",
                                    "Vídeos Khan Academy ou YouTube sobre Taxonomia de Flynn"
                                  ],
                                  "tips": "Use mnemônicos: Single Instruction Single Data (SISD) vs. Many Instruction Many Data (MIMD).",
                                  "learningObjective": "Compreender precisamente as categorias da taxonomia de Flynn e suas distinções.",
                                  "commonMistakes": [
                                    "Confundir SIMD com vetores simples",
                                    "Ignorar MIMD como dominante em nuvens modernas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Contextos de Nuvem Heterogêneos",
                                  "subSteps": [
                                    "Descreva arquiteturas de nuvem heterogêneas: CPUs, GPUs, TPUs em clusters como AWS ou GCP.",
                                    "Explique como Flynn se aplica: SIMD em GPUs para IA, MIMD em contêineres independentes.",
                                    "Estude desafios de escalabilidade: latência de rede, balanceamento de carga.",
                                    "Identifique como heterogeneidade afeta classificação (ex: hibridizações).",
                                    "Mapeie taxonomia a serviços de nuvem (EC2, Lambda, Kubernetes)."
                                  ],
                                  "verification": "Liste 3 exemplos de hardware heterogêneo em nuvem e sua classificação Flynn.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação AWS EC2 Instance Types",
                                    "Google Cloud TPUs docs",
                                    "Artigo 'Flynn's Taxonomy in Cloud Computing'"
                                  ],
                                  "tips": "Pense em workloads: IA usa SIMD/GPU, bancos de dados MIMD.",
                                  "learningObjective": "Relacionar taxonomia de Flynn a arquiteturas de nuvem reais e heterogêneas.",
                                  "commonMistakes": [
                                    "Assumir homogeneidade em nuvens",
                                    "Subestimar impacto de rede em MIMD"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Praticar Classificação de Aplicações Paralelas",
                                  "subSteps": [
                                    "Selecione 5 aplicações paralelas comuns (ex: MapReduce, MPI jobs, TensorFlow).",
                                    "Classifique cada uma: analise instruções/dados, identifique SIMD/MIMD/etc.",
                                    "Justifique com fluxogramas ou pseudocódigo.",
                                    "Adapte para nuvem: considere escalabilidade horizontal/vertical.",
                                    "Crie uma tabela de classificação com colunas: App, Categoria Flynn, Razão, Nuvem Adequada."
                                  ],
                                  "verification": "Classifique corretamente pelo menos 4/5 aplicações com justificativas escritas.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Exemplos de código Hadoop/Spark",
                                    "Ferramentas como Draw.io para diagramas",
                                    "Papers sobre workloads paralelos em nuvem"
                                  ],
                                  "tips": "Pergunte: 'Instruções são as mesmas para todos dados?' para SIMD vs MIMD.",
                                  "learningObjective": "Aplicar taxonomia para categorizar programas paralelos em nuvem.",
                                  "commonMistakes": [
                                    "Classificar tudo como MIMD",
                                    "Ignorar variantes SPMD em Spark"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar Adequação para Escalabilidade em Nuvem",
                                  "subSteps": [
                                    "Para cada classificação, avalie escalabilidade: forte vs fraca, Amdahl/Gustafson.",
                                    "Identifique bottlenecks por categoria (ex: SIMD bom para data-parallel, MIMD para task-parallel).",
                                    "Simule cenários: auto-scaling em Kubernetes para MIMD.",
                                    "Compare performance em nuvens heterogêneas.",
                                    "Proponha otimizações baseadas em Flynn."
                                  ],
                                  "verification": "Gere relatório com adequação escalável para 3 aplicações classificadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Ferramentas de simulação como CloudSim",
                                    "Benchmarks SPEC ou PARSEC",
                                    "Docs Kubernetes autoscaling"
                                  ],
                                  "tips": "Use lei de Amdahl para quantificar limites de escalabilidade.",
                                  "learningObjective": "Determinar como classificações Flynn impactam escalabilidade em nuvem.",
                                  "commonMistakes": [
                                    "Confundir escalabilidade forte/fraca",
                                    "Não considerar overhead de comunicação"
                                  ]
                                }
                              ],
                              "practicalExample": "Classifique o Apache Spark em um cluster AWS EC2 heterogêneo (EC2 + GPU instances): identifique como MIMD/SPMD, justifique paralelismo em tarefas de ML (SIMD em GPUs), e avalie escalabilidade via auto-scaling groups para big data processing.",
                              "finalVerifications": [
                                "Tabela de classificação completa com 5+ aplicações e categorias Flynn corretas.",
                                "Diagrama mostrando mapeamento para hardware de nuvem heterogêneo.",
                                "Análise de escalabilidade com limites identificados por Amdahl.",
                                "Exemplo prático classificado com justificativa detalhada.",
                                "Relatório de adequação para pelo menos 3 cenários de nuvem."
                              ],
                              "assessmentCriteria": [
                                "Precisão na classificação Flynn (90%+ correto).",
                                "Justificativas técnicas profundas com exemplos de código/arquitetura.",
                                "Integração correta de contextos de nuvem heterogêneos.",
                                "Análise quantitativa de escalabilidade (leis de Amdahl/Gustafson).",
                                "Criatividade em conexões reais e otimizações propostas.",
                                "Clareza e estrutura nos diagramas/tabelas."
                              ],
                              "crossCurricularConnections": [
                                "Arquitetura de Computadores: Evolução de hardware para Flynn.",
                                "Redes de Computadores: Impacto de latência em MIMD distribuído.",
                                "Big Data e Analytics: Classificação de frameworks como Spark/Hadoop.",
                                "Inteligência Artificial: SIMD em GPUs para DL em nuvem.",
                                "Gerenciamento de Sistemas: Orquestração em Kubernetes/Docker."
                              ],
                              "realWorldApplication": "Em empresas como Netflix ou Uber, classifica workloads paralelos (ex: recomendação via Spark MIMD) para otimizar custos em AWS, escalando GPUs para SIMD em ML e CPUs MIMD para processing, reduzindo latência e despesas em 30-50%."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.2.2",
                            "name": "Implementar linguagens paralelas em plataformas de nuvem",
                            "description": "Utilizar linguagens e frameworks como OpenMP, MPI ou Spark em serviços de nuvem (ex: AWS EC2, Google Cloud) para desenvolver aplicações escaláveis multicores e heterogêneas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente de nuvem para computação paralela",
                                  "subSteps": [
                                    "Criar conta gratuita em AWS ou Google Cloud se não existir.",
                                    "Lançar uma instância EC2 (AWS) ou VM (GCP) com suporte a múltiplos núcleos (ex: t3.medium com 2 vCPUs).",
                                    "Configurar chave SSH para acesso seguro.",
                                    "Instalar sistema operacional Linux (Ubuntu) e atualizar pacotes via apt update && apt upgrade.",
                                    "Configurar firewall para permitir tráfego SSH (porta 22) e portas necessárias para MPI (ex: 1024-65535)."
                                  ],
                                  "verification": "Acessar a instância via SSH sem erros e executar 'nproc' para confirmar múltiplos núcleos disponíveis.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Conta AWS/GCP",
                                    "Chave SSH gerada",
                                    "Cliente SSH (PuTTY ou terminal)"
                                  ],
                                  "tips": "Use instâncias spot para economia em testes; monitore custos no dashboard da nuvem.",
                                  "learningObjective": "Entender configuração básica de ambientes de nuvem para workloads paralelos.",
                                  "commonMistakes": [
                                    "Esquecer de abrir portas no security group, causando falhas de comunicação.",
                                    "Selecionar instância sem suporte a multicores.",
                                    "Não configurar chave SSH corretamente, levando a autenticação falha."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Instalar linguagens e frameworks paralelos",
                                  "subSteps": [
                                    "Instalar compilador GCC ou Java para Spark via apt install gcc g++ openjdk-11-jdk.",
                                    "Para OpenMP: Habilitar flags com export OMP_NUM_THREADS=4.",
                                    "Para MPI: Instalar OpenMPI com apt install openmpi-bin libopenmpi-dev e testar com mpirun --version.",
                                    "Para Spark: Baixar Spark de apache.org, extrair e configurar SPARK_HOME/export PATH.",
                                    "Testar instalação básica: Compilar e rodar 'hello world' para cada framework."
                                  ],
                                  "verification": "Executar programas de teste (ex: mpirun -np 4 hostname) e confirmar saída paralela sem erros.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Documentação oficial OpenMP/MPI/Spark",
                                    "Terminal SSH conectado à instância"
                                  ],
                                  "tips": "Use repositórios universe/multiverse no Ubuntu para pacotes MPI; evite sudo desnecessário.",
                                  "learningObjective": "Dominar instalação de ferramentas paralelas em ambientes Linux de nuvem.",
                                  "commonMistakes": [
                                    "Instalar versão errada de Java para Spark.",
                                    "Não definir variáveis de ambiente, causando falhas em runtime.",
                                    "Conflitos de bibliotecas entre MPI e OpenMPI."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Desenvolver aplicação paralela escalável",
                                  "subSteps": [
                                    "Escolher problema: Ex: multiplicação de matrizes paralela.",
                                    "Implementar em OpenMP (pragmas #pragma omp parallel for), MPI (mpi_send/recv) ou Spark (RDD transformations).",
                                    "Estruturar código para heterogeneidade: Detectar núcleos com omp_get_num_threads() ou spark.executor.cores.",
                                    "Adicionar logging para medir tempo de execução por nó.",
                                    "Compilar: g++ -fopenmp code.cpp ou mpic++ code.cpp -o app."
                                  ],
                                  "verification": "Compilar código sem warnings/erros e executar localmente com 1-4 processos/threads.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Editor de texto (nano/vim)",
                                    "Exemplos de código de repositórios GitHub para OpenMP/MPI/Spark"
                                  ],
                                  "tips": "Comece com OpenMP para simplicidade; migre para MPI para multi-nós.",
                                  "learningObjective": "Criar código paralelo que escale com recursos de nuvem.",
                                  "commonMistakes": [
                                    "Race conditions em OpenMP sem atomic.",
                                    "Deadlocks em MPI por ordem errada de send/recv.",
                                    "Não particionar dados corretamente em Spark."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar, testar e medir escalabilidade",
                                  "subSteps": [
                                    "Executar com diferentes configurações: mpirun -np 2/4/8 ou spark-submit com --num-executors.",
                                    "Medir performance: Usar time, perf ou Spark UI para speedup e eficiência.",
                                    "Testar em múltiplas instâncias: Configurar cluster com AWS Auto Scaling ou GCP MIG.",
                                    "Monitorar uso de CPU/RAM via cloudwatch ou gcloud monitoring.",
                                    "Analisar bottlenecks: Balanceamento de carga e overhead de comunicação."
                                  ],
                                  "verification": "Gerar relatório com tempos de execução mostrando speedup linear (ex: 4x mais rápido com 4 núcleos).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Ferramentas de profiling (perf, time)",
                                    "Dashboards de monitoramento da nuvem"
                                  ],
                                  "tips": "Use --hostfile em MPI para clusters multi-nós; capture métricas em CSV.",
                                  "learningObjective": "Avaliar performance paralela em cenários de nuvem reais.",
                                  "commonMistakes": [
                                    "Sobrecarregar instância além de limites de vCPU.",
                                    "Ignorar latência de rede em multi-nós.",
                                    "Métricas enviesadas por caches quentes."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimizar e implantar aplicação heterogênea",
                                  "subSteps": [
                                    "Otimizar: Ajustar chunk sizes em OpenMP, allreduce em MPI, partitions em Spark.",
                                    "Adicionar suporte heterogêneo: Detectar GPUs se disponível (ex: AWS EC2 com NVIDIA).",
                                    "Containerizar com Docker: Dockerfile com frameworks instalados.",
                                    "Deploy via Kubernetes (EKS/GKE) ou Elastic Beanstalk para escalabilidade auto.",
                                    "Documentar pipeline CI/CD com GitHub Actions para rebuild/deploy."
                                  ],
                                  "verification": "Aplicação roda em cluster escalado com >80% eficiência e resiste a falhas de nó.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Docker instalado",
                                    "Helm/Kubectl para K8s",
                                    "Exemplos de Dockerfiles paralelos"
                                  ],
                                  "tips": "Use imagens base como ubuntu:20.04 para reproducibilidade.",
                                  "learningObjective": "Preparar apps paralelas para produção em nuvem heterogênea.",
                                  "commonMistakes": [
                                    "Não otimizar comunicações, limitando speedup.",
                                    "Containers sem multi-stage build, inchando imagens.",
                                    "Ignorar tolerância a falhas em clusters."
                                  ]
                                }
                              ],
                              "practicalExample": "Implementar multiplicação de matrizes 1000x1000 usando MPI em um cluster de 4 instâncias AWS EC2 t3.medium: Dividir matriz em blocos, enviar via MPI_Scatter, computar localmente e coletar com MPI_Gather, alcançando speedup de 3.5x.",
                              "finalVerifications": [
                                "Código compila e executa sem erros em configurações single/multi-nó.",
                                "Speedup demonstrado com pelo menos 2x melhoria ao dobrar núcleos.",
                                "Monitoramento mostra uso eficiente de CPU (>70%) e baixa latência de rede.",
                                "Aplicação tolera falha de um nó via retry ou checkpointing.",
                                "Relatório com gráficos de performance gerado.",
                                "Deploy containerizado acessível via endpoint público."
                              ],
                              "assessmentCriteria": [
                                "Correção da configuração de nuvem e instalação (30%).",
                                "Qualidade e escalabilidade do código paralelo (25%).",
                                "Precisão das métricas de performance e análise (20%).",
                                "Otimização e suporte a heterogeneidade (15%).",
                                "Documentação e deploy production-ready (10%)."
                              ],
                              "crossCurricularConnections": [
                                "DevOps: Integração com CI/CD e orquestração Kubernetes.",
                                "Big Data: Aplicação de Spark para processamento distribuído.",
                                "Segurança: Configuração de IAM roles e VPC para acesso seguro.",
                                "Análise de Dados: Uso de métricas para otimização via ML.",
                                "Redes: Entendimento de latência e bandwidth em comunicações paralelas."
                              ],
                              "realWorldApplication": "Desenvolvimento de pipelines de ML escaláveis em AWS para processamento de imagens médicas, simulações climáticas heterogêneas no Google Cloud, ou análise de big data em tempo real com Spark para e-commerce."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.5.3",
                        "name": "Avaliação de Performance em Aplicações Paralelas na Nuvem",
                        "description": "Métodos para medir speedup, eficiência e custo-benefício de programas paralelos em ambientes de nuvem, com foco em estudos de caso reais.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.5.3.1",
                            "name": "Calcular métricas de desempenho em programas distribuídos",
                            "description": "Aplicar fórmulas de Amdahl e Gustafson para avaliar speedup e eficiência em execuções paralelas na nuvem, considerando overhead de comunicação.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as Leis de Amdahl e Gustafson",
                                  "subSteps": [
                                    "Estude a Lei de Amdahl: speedup = 1 / ((1 - P) + P/N), onde P é a fração paralelizável e N é o número de processadores.",
                                    "Analise limitações da Amdahl: foco em problema fixo, não escala com mais processadores para frações seriais altas.",
                                    "Estude a Lei de Gustafson: speedup = S + (1-S)*N, onde S é a fração serial escalável com problema maior.",
                                    "Compare Amdahl vs Gustafson: Amdahl para eficiência em problema fixo, Gustafson para escalabilidade em problemas maiores.",
                                    "Identifique quando usar cada lei em contextos de nuvem distribuída."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as diferenças entre Amdahl e Gustafson com exemplos numéricos simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação oficial das leis (Wikipedia ou papers originais)",
                                    "Calculadora ou planilha Excel/Google Sheets"
                                  ],
                                  "tips": "Use diagramas para visualizar frações paralelas e seriais.",
                                  "learningObjective": "Dominar as fórmulas e premissas fundamentais das leis de performance paralela.",
                                  "commonMistakes": [
                                    "Confundir P como fração serial em vez de paralela",
                                    "Ignorar que Gustafson assume problema escalável"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Speedup e Eficiência com Lei de Amdahl",
                                  "subSteps": [
                                    "Defina um problema de exemplo: programa com 80% paralelizável (P=0.8), teste com N=4, 8, 16 processadores.",
                                    "Calcule speedup para cada N usando fórmula Amdahl.",
                                    "Calcule eficiência: eficiência = speedup / N * 100%.",
                                    "Plote gráfico de speedup vs N para visualizar saturação.",
                                    "Interprete resultados: identifique ponto de diminuição de retornos."
                                  ],
                                  "verification": "Submeta cálculos e gráfico mostrando speedup < N devido a overhead serial.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Planilha com fórmulas prontas",
                                    "Ferramenta de plotagem como Python Matplotlib ou Excel"
                                  ],
                                  "tips": "Sempre normalize tempos para 1 unidade no serial para simplificar.",
                                  "learningObjective": "Aplicar Amdahl para quantificar ganhos de paralelismo em problemas fixos.",
                                  "commonMistakes": [
                                    "Esquecer de converter para fração decimal (ex: 80% = 0.8)",
                                    "Calcular eficiência como speedup sem dividir por N"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Lei de Gustafson para Escala em Nuvem",
                                  "subSteps": [
                                    "Escolha exemplo escalável: processamento de big data com fração serial S=0.1, N=100.",
                                    "Calcule speedup Gustafson: S + (1-S)*N.",
                                    "Compare com Amdahl no mesmo cenário para mostrar superioridade em problemas grandes.",
                                    "Calcule eficiência Gustafson: speedup / N.",
                                    "Discuta implicações para aplicações na nuvem onde dados crescem com processadores."
                                  ],
                                  "verification": "Forneça tabela comparativa Amdahl vs Gustafson para N=10,50,100.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Mesma planilha do Step 2",
                                    "Exemplos de papers sobre cloud scaling"
                                  ],
                                  "tips": "Lembre que Gustafson é ideal para workloads dinâmicos como MapReduce.",
                                  "learningObjective": "Usar Gustafson para avaliar performance em cenários de problema escalável.",
                                  "commonMistakes": [
                                    "Aplicar Gustafson a problemas fixos pequenos",
                                    "Confundir S com P de Amdahl"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Incorporar Overhead de Comunicação em Programas Distribuídos",
                                  "subSteps": [
                                    "Modele overhead: tempo_total = tempo_serial + (tempo_paralelo / N) + overhead_com * (N-1)/N.",
                                    "Ajuste Amdahl/Gustafson: speedup ajustado = tempo_seq / tempo_total.",
                                    "Simule cenário nuvem: overhead_com = 0.05s por task, aplique a exemplo com N=16.",
                                    "Calcule métricas finais: speedup efetivo, eficiência, breakeven point para overhead.",
                                    "Avalie sensibilidade: varie overhead e N, plote impacto."
                                  ],
                                  "verification": "Submeta relatório com cálculos ajustados e gráficos de sensibilidade.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Simulador simples em Python ou planilha avançada",
                                    "Referências sobre MPI/OpenMP overhead"
                                  ],
                                  "tips": "Use unidades consistentes (ex: segundos) para todos tempos.",
                                  "learningObjective": "Integrar realidades de nuvem como latência de rede nas métricas.",
                                  "commonMistakes": [
                                    "Ignorar fator (N-1)/N no overhead",
                                    "Subestimar impacto em N alto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma aplicação de processamento de imagens na AWS EC2 com 16 instâncias: 70% paralelizável, overhead comunicação 2% do tempo paralelo. Calcule speedup Amdahl=3.8, Gustafson ajustado=12.5, eficiência efetiva=78% após overhead.",
                              "finalVerifications": [
                                "Calcula corretamente speedup Amdahl para P=0.9, N=32 (esperado ~5.5).",
                                "Aplica Gustafson corretamente para S=0.05, N=100 (speedup ~95).",
                                "Inclui overhead e obtém speedup efetivo < teórico.",
                                "Interpreta resultados: explica por que eficiência cai com N alto.",
                                "Compara Amdahl vs Gustafson em relatório escrito.",
                                "Plota gráficos precisos de speedup vs N."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: erros <1% nos cálculos.",
                                "Compreensão conceitual: explica limitações de cada lei.",
                                "Integração de overhead: modelo realista para nuvem.",
                                "Análise qualitativa: discute implicações práticas.",
                                "Visualizações: gráficos claros e rotulados.",
                                "Relatório completo: estrutura lógica e referências."
                              ],
                              "crossCurricularConnections": [
                                "Matemática: Álgebra linear e funções de escalabilidade.",
                                "Redes de Computadores: Latência e bandwidth em comunicações distribuídas.",
                                "Engenharia de Software: Otimização de algoritmos paralelos.",
                                "Estatística: Análise de sensibilidade e modelagem de variância."
                              ],
                              "realWorldApplication": "Otimizar clusters Spark no Google Cloud para ETL de dados petabyte, prevendo se adicionar 2x nós justifica custo considerando overhead de rede, evitando overprovisioning e reduzindo bills em 20-30%."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.3.2",
                            "name": "Analisar estudos de caso de aplicações em nuvem",
                            "description": "Estudar casos reais como processamento de big data com MapReduce ou machine learning distribuído, avaliando performance em plataformas como AWS ou Azure.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e Compreender o Estudo de Caso",
                                  "subSteps": [
                                    "Pesquise e selecione um estudo de caso relevante, como o uso de MapReduce no processamento de big data pela Netflix na AWS.",
                                    "Leia o estudo de caso completo, identificando contexto, objetivos e desafios iniciais.",
                                    "Resuma os principais componentes: problema resolvido, tecnologias adotadas e resultados alcançados.",
                                    "Anote perguntas iniciais sobre performance, como latência, escalabilidade e custos.",
                                    "Crie um mapa mental ou diagrama inicial da aplicação."
                                  ],
                                  "verification": "Resumo escrito de 1 página e mapa mental completos, sem lacunas no entendimento básico.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Acesso à internet para estudos de caso (AWS Case Studies, Azure Blogs)",
                                    "Ferramentas de diagramação como Draw.io ou Lucidchart",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Escolha casos recentes (últimos 2-3 anos) para relevância com tecnologias atuais.",
                                  "learningObjective": "Compreender o contexto e escopo de aplicações paralelas em nuvem através de casos reais.",
                                  "commonMistakes": [
                                    "Selecionar casos irrelevantes ou desatualizados",
                                    "Pular a leitura detalhada e focar só em resumos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Arquitetura e Tecnologias Utilizadas",
                                  "subSteps": [
                                    "Identifique serviços de nuvem usados (ex: AWS EMR para MapReduce, Azure HDInsight).",
                                    "Desenhe a arquitetura: componentes paralelos, fluxos de dados e integrações.",
                                    "Avalie como o paralelismo é implementado (ex: distribuição de tarefas em clusters).",
                                    "Compare com alternativas teóricas, notando escolhas específicas.",
                                    "Documente dependências e integrações com outros serviços (ex: S3 para storage)."
                                  ],
                                  "verification": "Diagrama de arquitetura detalhado com legendas e tabela de tecnologias.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Documentação oficial AWS/Azure",
                                    "Ferramentas de modelagem UML ou AWS Architecture Icons",
                                    "Estudos de caso impressos ou PDFs"
                                  ],
                                  "tips": "Use ícones oficiais de arquitetura para visualização precisa.",
                                  "learningObjective": "Mapear arquiteturas paralelas em nuvem e suas tecnologias chave.",
                                  "commonMistakes": [
                                    "Ignorar integrações laterais como storage ou networking",
                                    "Confundir serviços semelhantes (ex: EMR vs Lambda)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Avaliar Performance e Métricas",
                                  "subSteps": [
                                    "Colete métricas reportadas: throughput, latência, custo por workload, escalabilidade.",
                                    "Calcule ou estime KPIs como tempo de processamento vs sequencial.",
                                    "Identifique gargalos resolvidos (ex: sharding de dados em ML distribuído).",
                                    "Compare performance pré e pós-implementação na nuvem.",
                                    "Analise trade-offs: custo vs performance, usando ferramentas como AWS Cost Explorer simulações."
                                  ],
                                  "verification": "Tabela de métricas com gráficos comparativos e análise escrita.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Calculadoras de custo AWS/Azure",
                                    "Ferramentas de gráficos como Excel ou Google Sheets",
                                    "Relatórios de performance dos casos"
                                  ],
                                  "tips": "Normalize métricas (ex: por TB processado) para comparações justas.",
                                  "learningObjective": "Quantificar e qualificar performance em cenários paralelos na nuvem.",
                                  "commonMistakes": [
                                    "Focar só em números absolutos sem contexto",
                                    "Ignorar custos operacionais recorrentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Extrair Conclusões e Lições Aprendidas",
                                  "subSteps": [
                                    "Sintetize sucessos, falhas e otimizações aplicadas.",
                                    "Identifique lições transferíveis para outros projetos.",
                                    "Proponha melhorias hipotéticas baseadas em tendências atuais.",
                                    "Discuta impactos em escalabilidade e sustentabilidade.",
                                    "Prepare um relatório final com recomendações."
                                  ],
                                  "verification": "Relatório de 2-3 páginas com conclusões claras e referências.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Template de relatório (Word/Google Docs)",
                                    "Referências bibliográficas"
                                  ],
                                  "tips": "Use framework STAR (Situation, Task, Action, Result) para estruturar lições.",
                                  "learningObjective": "Derivar insights acionáveis de análises de performance em nuvem.",
                                  "commonMistakes": [
                                    "Conclusões genéricas sem evidências",
                                    "Não ligar lições ao contexto paralelo"
                                  ]
                                }
                              ],
                              "practicalExample": "Analise o caso da Netflix usando AWS EMR com MapReduce para processar logs de streaming: avalie como clusters escaláveis reduziram tempo de batch de horas para minutos, medindo custo por TB e latência em picos de uso.",
                              "finalVerifications": [
                                "Pode diagramar a arquitetura completa do caso.",
                                "Identifica pelo menos 3 métricas chave de performance com valores reais.",
                                "Lista 2-3 lições aprendidas aplicáveis a projetos semelhantes.",
                                "Compara performance na nuvem vs on-premise.",
                                "Propõe uma otimização viável baseada na análise.",
                                "Relatório final cobre todos os aspectos sem lacunas."
                              ],
                              "assessmentCriteria": [
                                "Profundidade da análise arquitetural (30%)",
                                "Precisão e relevância das métricas de performance (25%)",
                                "Qualidade das conclusões e lições (20%)",
                                "Uso de evidências e referências (15%)",
                                "Clareza e estrutura do relatório (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Big Data e Hadoop: Integração com MapReduce.",
                                "Machine Learning Distribuído: Frameworks como TensorFlow on Cloud.",
                                "DevOps e CI/CD: Pipelines para deploy em nuvem.",
                                "Gestão de Custos e Sustentabilidade: Otimização de recursos.",
                                "Segurança em Nuvem: Compliance em workloads paralelos."
                              ],
                              "realWorldApplication": "Empresas como e-commerces usam análises semelhantes para otimizar processamento de recomendações em tempo real na AWS, reduzindo custos em 40% e melhorando experiência do usuário durante Black Friday."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.3.3",
                            "name": "Otimizar performance com base em benchmarks na nuvem",
                            "description": "Realizar profiling e tuning de aplicações paralelas usando ferramentas como TAU ou cloud-native monitoring para melhorar escalabilidade e reduzir latência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar Ambiente de Benchmarking na Nuvem",
                                  "subSteps": [
                                    "Selecionar provedor de nuvem (ex: AWS, GCP, Azure) e instâncias adequadas para workloads paralelas.",
                                    "Instalar ferramentas de monitoramento cloud-native (ex: AWS CloudWatch, GCP Stackdriver) e TAU para profiling.",
                                    "Configurar aplicação paralela de teste (ex: MPI ou Spark job) com workloads representativos.",
                                    "Definir métricas baseline: latência, throughput, CPU/GPU utilization.",
                                    "Executar benchmarks iniciais para coletar dados de referência."
                                  ],
                                  "verification": "Ambiente pronto quando benchmarks iniciais rodam sem erros e métricas baseline são registradas em dashboards.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Conta em provedor de nuvem",
                                    "Ferramentas: TAU, CloudWatch/GCP Monitoring",
                                    "Código de app paralela de exemplo"
                                  ],
                                  "tips": "Use instâncias spot para reduzir custos durante testes iniciais.",
                                  "learningObjective": "Entender configuração de ambientes escaláveis para medição precisa de performance.",
                                  "commonMistakes": [
                                    "Escolher instâncias subdimensionadas",
                                    "Ignorar configuração de rede para latência",
                                    "Não calibrar workloads"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar Profiling Detalhado da Aplicação Paralela",
                                  "subSteps": [
                                    "Instrumentar código com TAU ou equivalentes para capturar traces de funções paralelas.",
                                    "Executar profiling em cenários variados: low/high load, diferentes tamanhos de dados.",
                                    "Coletar dados de hotspots: tempo em kernels, comunicação inter-nós, I/O bottlenecks.",
                                    "Integrar com monitoring cloud para métricas agregadas (ex: traces distribuídos).",
                                    "Gerar relatórios iniciais de profiling com visualizações (flame graphs, timelines)."
                                  ],
                                  "verification": "Relatórios de profiling gerados mostrando hotspots identificados em pelo menos 80% das funções críticas.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": [
                                    "TAU ou Perfetto",
                                    "Dashboards cloud",
                                    "Scripts de automação para runs repetidas"
                                  ],
                                  "tips": "Ative sampling mode no TAU para overhead mínimo em apps long-running.",
                                  "learningObjective": "Dominar técnicas de profiling para identificar ineficiências em apps paralelas.",
                                  "commonMistakes": [
                                    "Profiling sem carga realista",
                                    "Ignorar overhead de instrumentação",
                                    "Não correlacionar com métricas cloud"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Benchmarks e Identificar Gargalos",
                                  "subSteps": [
                                    "Comparar métricas baseline vs profiling: focar em latência > threshold e escalabilidade subótima.",
                                    "Mapear gargalos: comunicação (MPI all-reduce), memória, ou escalonamento cloud.",
                                    "Usar ferramentas analíticas (ex: TAU ParaProf) para quantificar impactos.",
                                    "Priorizar gargalos por ROI: alto impacto com baixa complexidade de fix.",
                                    "Documentar hipóteses de tuning baseadas em análise."
                                  ],
                                  "verification": "Relatório de análise com lista priorizada de 3-5 gargalos principais e hipóteses testáveis.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de análise TAU",
                                    "Planilhas ou Jupyter para visualização",
                                    "Dashboards cloud"
                                  ],
                                  "tips": "Use Pareto analysis (80/20 rule) para focar nos top contributors de latência.",
                                  "learningObjective": "Desenvolver skills analíticas para traduzir dados de benchmark em ações acionáveis.",
                                  "commonMistakes": [
                                    "Sobrecarga de dados sem priorização",
                                    "Atribuir gargalos errados (ex: confundir rede com CPU)",
                                    "Ignorar variabilidade estocástica"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Tuning e Otimizações Específicas",
                                  "subSteps": [
                                    "Implementar otimizações baseadas em análise: ex: batching em MPI, auto-scaling rules.",
                                    "Ajustar configs cloud: resize instâncias, affinity groups para locality.",
                                    "Testar tuning incremental: uma mudança por vez para isolar impactos.",
                                    "Re-instrumentar e profile otimizações para validar.",
                                    "Automatizar tuning com scripts ou tools como Kubernetes HPA."
                                  ],
                                  "verification": "Código/configs atualizados versionados, com pelo menos 20% melhoria em métricas chave observada.",
                                  "estimatedTime": "4-5 horas",
                                  "materials": [
                                    "Código fonte da app",
                                    "Ferramentas de CI/CD cloud",
                                    "Documentação de APIs de tuning"
                                  ],
                                  "tips": "Versione configs com Git para rollback rápido em regressões.",
                                  "learningObjective": "Aprender técnicas práticas de tuning para escalabilidade e baixa latência.",
                                  "commonMistakes": [
                                    "Mudanças múltiplas simultâneas",
                                    "Otimizar sem re-testar",
                                    "Ignorar custos de tuning"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar Melhorias e Iterar",
                                  "subSteps": [
                                    "Executar benchmarks finais comparativos (before/after).",
                                    "Verificar estabilidade: runs múltiplas para variância <5%.",
                                    "Documentar ganhos: % redução latência, melhoria throughput.",
                                    "Planejar iterações futuras base em residual bottlenecks.",
                                    "Compartilhar resultados em relatório final com gráficos."
                                  ],
                                  "verification": "Benchmarks finais mostram melhorias sustentadas e relatório completo gerado.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Scripts de benchmark automatizados",
                                    "Ferramentas de plotting (Matplotlib)"
                                  ],
                                  "tips": "Use statistical tests (t-test) para validar significância das melhorias.",
                                  "learningObjective": "Estabelecer processo iterativo de otimização contínua.",
                                  "commonMistakes": [
                                    "Testes únicos sem repetição",
                                    "Não documentar para reprodutibilidade",
                                    "Parar em ganhos marginais"
                                  ]
                                }
                              ],
                              "practicalExample": "Otimizar um job Spark ML para treinamento distribuído no AWS EMR: profiling revela gargalo em shuffle; tuning com partition tuning e auto-scaling reduz latência de 10min para 3min em dataset de 1TB.",
                              "finalVerifications": [
                                "Latência reduzida em pelo menos 30% em workloads de pico.",
                                "Throughput escalável linearmente com +50% nós.",
                                "Utilização de recursos >75% sem overhead excessivo.",
                                "Relatórios de profiling before/after comparáveis.",
                                "Custos operacionais otimizados sem sacrificar performance.",
                                "Processo documentado e reproduzível."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de gargalos (alinhamento com ferramentas padrão).",
                                "Efetividade das otimizações (ganhos quantificáveis).",
                                "Qualidade da documentação e relatórios.",
                                "Eficiência no uso de recursos cloud.",
                                "Capacidade de iterar baseado em dados.",
                                "Integração correta de ferramentas (TAU + cloud monitoring)."
                              ],
                              "crossCurricularConnections": [
                                "DevOps: Auto-scaling e CI/CD para tuning contínuo.",
                                "Big Data: Otimização em frameworks como Spark/Hadoop.",
                                "Engenharia de Software: Profiling em desenvolvimento ágil.",
                                "Redes: Tuning de comunicação paralela (MPI).",
                                "Gestão de Custos: Análise custo-performance na nuvem."
                              ],
                              "realWorldApplication": "Em serviços de streaming como Netflix, otimizar pipelines paralelos de recomendação reduz latência de sugestões em escala global, economizando milhões em infra e melhorando UX."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            ],
            "totalSkills": 283
          }
        ],
        "totalSkills": 283
      }
    ]
  }
}