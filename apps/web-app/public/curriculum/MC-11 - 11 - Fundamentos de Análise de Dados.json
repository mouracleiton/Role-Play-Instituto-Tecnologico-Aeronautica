{
  "formatVersion": "1.0",
  "exportDate": "2025-12-04T22:47:32.568Z",
  "appVersion": "1.0",
  "curriculumData": {
    "metadata": {
      "baseOn": "Catálogo dos Cursos de Graduação 2025 - MC-11",
      "lastUpdated": "2025-12-04",
      "totalAtomicSkills": 331
    },
    "areas": [
      {
        "id": "10",
        "name": "Matemática Computacional",
        "description": "Área dedicada aos fundamentos matemáticos e computacionais aplicados à engenharia, incluindo análise de dados e econometria.",
        "disciplines": [
          {
            "id": "10.1",
            "name": "Fundamentos de Análise de Dados",
            "description": "No contexto de econometria aplicada à engenharia: métodos de mínimos quadrados ordinários, regressão linear, pressupostos, inferência, testes de hipótese, seleção de modelos, máxima verossimilhança, métodos generalizados dos momentos, regressão em grandes amostras, séries temporais (ARIMA, cointegração, VAR), análise de componentes principais e fatorial.",
            "mainTopics": [
              {
                "id": "10.1.1",
                "name": "Regressão Linear e Mínimos Quadrados Ordinários",
                "description": "Apresenta os métodos de mínimos quadrados ordinários e regressão linear no contexto de econometria aplicada à engenharia, incluindo pressupostos básicos.",
                "totalSkills": 55,
                "atomicTopics": [
                  {
                    "id": "10.1.1.1",
                    "name": "Método dos Mínimos Quadrados Ordinários (MQO)",
                    "description": "Técnica de estimação que minimiza a soma dos quadrados dos resíduos em um modelo de regressão linear.",
                    "individualConcepts": [
                      {
                        "id": "11.1.1.1.1",
                        "name": "Modelo de Regressão Linear",
                        "description": "Definição do modelo populacional Y = β₀ + β₁X + u e do modelo amostral y_i = β₀ + β₁x_i + u_i, no contexto de econometria aplicada à engenharia, destacando variáveis dependentes e independentes.",
                        "specificSkills": [
                          {
                            "id": "11.1.1.1.1.1",
                            "name": "Identificar componentes do modelo linear simples",
                            "description": "Reconhecer e nomear os elementos β₀ (intercepto), β₁ (coeficiente angular), X (variável explicativa), Y (variável resposta) e u (termo de erro) em uma equação de regressão linear simples.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a estrutura geral do modelo de regressão linear simples",
                                  "subSteps": [
                                    "Examine a equação padrão: Y = β₀ + β₁X + u",
                                    "Identifique que esta é a forma matemática do modelo linear simples",
                                    "Discuta o propósito: modelar a relação linear entre uma variável resposta (Y) e uma variável explicativa (X)",
                                    "Anote a equação em um papel ou editor de texto para visualização",
                                    "Compare com exemplos não lineares para destacar a linearidade"
                                  ],
                                  "verification": "Reescreva a equação corretamente de memória e explique seu propósito em uma frase",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Papel e caneta ou editor de texto simples; quadro branco opcional",
                                  "tips": "Sempre escreva a equação com espaços claros entre termos para melhor visualização",
                                  "learningObjective": "Reconhecer a forma canônica da equação de regressão linear simples",
                                  "commonMistakes": "Confundir com equações lineares puras sem termo de erro; ignorar a presença de u"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender o significado e notação de cada componente individual",
                                  "subSteps": [
                                    "Estude β₀ (intercepto): valor de Y quando X=0; ponto de corte no eixo Y",
                                    "Analise β₁ (coeficiente angular): mudança em Y para cada unidade de aumento em X",
                                    "Defina X (variável explicativa): variável independente ou preditora",
                                    "Descreva Y (variável resposta): variável dependente ou outcome",
                                    "Explique u (termo de erro): parte não explicada pelo modelo, captura ruído ou variáveis omitidas",
                                    "Crie flashcards com cada símbolo, definição e exemplo numérico"
                                  ],
                                  "verification": "Liste todos os cinco componentes com suas definições corretas sem consultar notas",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Flashcards (físicos ou app como Anki); tabela de referência impressa",
                                  "tips": "Use mnemônicos: 'β-zero é o início (intercepto), β-um é a inclinação (slope)'",
                                  "learningObjective": "Associar corretamente cada símbolo à sua função no modelo",
                                  "commonMistakes": "Trocar β₀ com β₁; confundir X e Y; esquecer que u representa erro aleatório"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Praticar identificação em equações variadas",
                                  "subSteps": [
                                    "Pegue equações como: Salário = 25.000 + 1.500 * AnosExp + ε; identifique cada parte",
                                    "Resolva 5 equações diferentes, rotulando β₀, β₁, X, Y, u",
                                    "Varie notações: use ε em vez de u, ou subscritos diferentes",
                                    "Desenhe gráficos lineares e marque os componentes visualmente",
                                    "Troque papéis com um parceiro para correção mútua"
                                  ],
                                  "verification": "Identifique corretamente componentes em 5 equações de teste sem erros",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Lista de 10 equações de prática (preparada ou online); software de gráficos como Desmos ou GeoGebra",
                                  "tips": "Destaque cada componente com cores diferentes na equação para reforço visual",
                                  "learningObjective": "Aplicar o conhecimento para rotular componentes em contextos reais",
                                  "commonMistakes": "Interpretar coeficientes numéricos como símbolos; confundir variável resposta com explicativa"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Reforçar com análise contextual e autoavaliação",
                                  "subSteps": [
                                    "Analise um dataset simples (ex: altura vs peso) e escreva o modelo identificando componentes",
                                    "Explique verbalmente o papel de cada componente em um cenário real",
                                    "Crie sua própria equação fictícia e rotule os componentes",
                                    "Resolva um quiz com 10 perguntas de identificação",
                                    "Registre erros e revise conceitos fracos"
                                  ],
                                  "verification": "Complete um quiz de 10 itens com 90% de acerto e explique um erro se houver",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Dataset simples (Excel ou CSV); quiz online (Quizlet ou Google Forms)",
                                  "tips": "Pense em termos de 'previsão': Y é o que prevemos, X é o que usamos para prever",
                                  "learningObjective": "Integrar identificação com interpretação contextual do modelo",
                                  "commonMistakes": "Ignorar o termo de erro como 'desnecessário'; superestimar precisão do modelo sem u"
                                }
                              ],
                              "practicalExample": "Em um estudo de salários: Salário (Y) = 30.000 (β₀) + 2.500 * Experiência (β₁ X) + u. Aqui, β₀ é o salário base sem experiência, β₁ indica R$2.500 a mais por ano de experiência, X é anos de experiência, Y é salário, e u captura fatores como habilidades não medidas.",
                              "finalVerifications": [
                                "Nomeie corretamente β₀, β₁, X, Y e u em uma equação dada",
                                "Explique o papel do intercepto em uma frase",
                                "Identifique a variável explicativa e resposta em um contexto real",
                                "Destaque o termo de erro e seu propósito",
                                "Rotule componentes em um gráfico de regressão linear",
                                "Crie uma equação simples com todos os componentes identificados"
                              ],
                              "assessmentCriteria": [
                                "Precisão na nomeação de todos os cinco componentes (100% correto)",
                                "Explicação clara do significado funcional de cada elemento",
                                "Capacidade de identificar em equações com notações variadas (ε vs u)",
                                "Interpretação contextual correta (ex: preditor vs outcome)",
                                "Ausência de confusão entre coeficientes (β₀ vs β₁)",
                                "Integração visual (gráficos) com identificação precisa"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Fundamentos de inferência e estimação de parâmetros",
                                "Programação: Implementação em Python (statsmodels) ou R para visualização de modelos",
                                "Econometria: Aplicação em modelos de demanda e oferta",
                                "Ciência de Dados: Pré-processamento de features em machine learning",
                                "Matemática: Equações lineares e funções afins"
                              ],
                              "realWorldApplication": "Em análise de dados de vendas, identificar Y=vendas, X=preço de publicidade, β₀=vendas base, β₁=impacto da publicidade, u=fatores sazonais permite otimizar orçamentos de marketing em empresas como e-commerces."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.1.1.2",
                            "name": "Especificar modelo linear múltipla",
                            "description": "Construir a notação matricial Y = Xβ + u para regressão múltipla, identificando a matriz de design X e o vetor de parâmetros β.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Regressão Linear Simples e Introduzir Múltipla",
                                  "subSteps": [
                                    "Relembre a equação da regressão linear simples: Y = β₀ + β₁X + u.",
                                    "Entenda que na regressão múltipla, múltiplas variáveis explicativas são incluídas: Y = β₀ + β₁X₁ + β₂X₂ + ... + βₖXₖ + u.",
                                    "Identifique a necessidade de notação matricial para generalizar e facilitar cálculos computacionais.",
                                    "Discuta os componentes: vetor resposta Y (n x 1), matriz X (n x (k+1)), vetor β ((k+1) x 1), vetor erro u (n x 1).",
                                    "Esboce um exemplo simples com duas variáveis explicativas."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre simples e múltipla, listando componentes matriciais.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Acesso a notas de aula sobre regressão linear simples"
                                  ],
                                  "tips": "Use diagramas para visualizar vetores e matrizes; comece com k=1 para transição suave.",
                                  "learningObjective": "Compreender a extensão da regressão simples para múltipla e motivação para notação matricial.",
                                  "commonMistakes": "Confundir regressão simples com múltipla sem generalizar; ignorar o intercepto β₀."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir o Vetor de Resposta Y",
                                  "subSteps": [
                                    "Colete ou liste os dados observados da variável dependente (Y_i para i=1 a n).",
                                    "Forme o vetor coluna Y = [Y₁, Y₂, ..., Yₙ]ᵀ.",
                                    "Verifique dimensões: Y deve ser n x 1, onde n é o número de observações.",
                                    "Padronize ou centralize Y se necessário para análise (opcional neste passo).",
                                    "Exemplo: Para salários, Y = [salário₁, salário₂, ..., salárioₙ]ᵀ."
                                  ],
                                  "verification": "Construa Y para um conjunto de dados pequeno (5 observações) e confirme dimensões.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Planilha Excel ou Jupyter Notebook",
                                    "Conjunto de dados exemplo (CSV com Y)"
                                  ],
                                  "tips": "Sempre transpose para coluna: use ᵀ para indicar.",
                                  "learningObjective": "Identificar e formatar corretamente o vetor resposta Y em notação matricial.",
                                  "commonMistakes": "Esquecer de transpor para vetor coluna; incluir variáveis independentes em Y."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir a Matriz de Design X",
                                  "subSteps": [
                                    "Inclua uma coluna de 1's para o intercepto β₀ (primeira coluna).",
                                    "Adicione colunas para cada variável explicativa X₁, X₂, ..., Xₖ, centradas se aplicável.",
                                    "Forme X como matriz n x (k+1): linha i contém [1, X_{i1}, X_{i2}, ..., X_{ik}].",
                                    "Verifique rank e ausência de multicolinearidade perfeita básica.",
                                    "Exemplo: Para experiência (X1) e educação (X2), X tem colunas [1, exp_i, edu_i]."
                                  ],
                                  "verification": "Monte X para 5 observações com 2 variáveis e imprima a matriz.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python com NumPy ou R",
                                    "Dados exemplo em CSV"
                                  ],
                                  "tips": "Use funções como np.column_stack() em Python para montar X rapidamente.",
                                  "learningObjective": "Construir a matriz de design X corretamente, incluindo intercepto.",
                                  "commonMistakes": "Esquecer coluna de 1's; ordenar colunas incorretamente."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Definir Vetor de Parâmetros β e Erro u",
                                  "subSteps": [
                                    "Defina β = [β₀, β₁, ..., βₖ]ᵀ como vetor (k+1) x 1 de coeficientes.",
                                    "Explique u = [u₁, u₂, ..., uₙ]ᵀ como erros/resíduos (n x 1), assumindo E(u)=0.",
                                    "Verifique compatibilidade dimensional: Xβ deve ser n x 1.",
                                    "Escreva a equação completa: Y = Xβ + u.",
                                    "Teste dimensionalmente: (n x p) * (p x 1) + (n x 1) = (n x 1)."
                                  ],
                                  "verification": "Escreva β e u para o exemplo, confirmando Y = Xβ + u.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Cálculo matricial básico",
                                    "Software para multiplicação matriz-vetor"
                                  ],
                                  "tips": "Sempre cheque dimensões com regra de multiplicação de matrizes.",
                                  "learningObjective": "Completar a notação matricial identificando β e u corretamente.",
                                  "commonMistakes": "Dimensões incompatíveis; confundir β com linha em vez de coluna."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Aplicar o Modelo Especificado",
                                  "subSteps": [
                                    "Implemente em software: crie Y, X, gere β fictício e u = Y - Xβ.",
                                    "Verifique se Xβ + u = Y numericamente.",
                                    "Discuta premissas: linearidade, exogeneidade, etc.",
                                    "Ajuste para dados reais e plote resíduos.",
                                    "Documente o modelo em relatório curto."
                                  ],
                                  "verification": "Execute código e confirme igualdade Y ≈ Xβ + u (com erros aleatórios).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Jupyter Notebook com NumPy/SciPy",
                                    "Dados reais (ex: Boston Housing dataset)"
                                  ],
                                  "tips": "Use print(shape) para dimensões; seed para reprodutibilidade.",
                                  "learningObjective": "Validar o modelo matricial em prática computacional.",
                                  "commonMistakes": "Não verificar numericamente; ignorar premissas do modelo."
                                }
                              ],
                              "practicalExample": "Considere dados de salários: Y = salários de 100 funcionários. X inclui colunas [1, anos_experiencia, anos_educacao]. Então Y (100x1) = X (100x3) * β (3x1) + u (100x1), onde β = [salário_base, coef_exp, coef_edu]ᵀ. Em Python: import numpy as np; X = np.column_stack((np.ones(100), exp, edu)); Y = X @ beta + u.",
                              "finalVerifications": [
                                "Pode construir Y, X, β e u para um dataset com 3 variáveis?",
                                "Confirma dimensões corretas em todos componentes?",
                                "Implementa Y = Xβ + u em software sem erros?",
                                "Explica verbalmente cada componente do modelo?",
                                "Identifica e corrige erros dimensionais comuns?",
                                "Aplica a premissas básicas do modelo MQO?"
                              ],
                              "assessmentCriteria": [
                                "Precisão na construção da matriz X (incluindo intercepto): 25%",
                                "Correta identificação dimensional de todos vetores: 20%",
                                "Implementação computacional funcional: 25%",
                                "Explicação clara dos componentes: 15%",
                                "Validação numérica e detecção de erros: 15%"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Premissas dos Mínimos Quadrados Ordinários.",
                                "Programação: Manipulação de arrays em Python/R (NumPy, matrices).",
                                "Economia: Modelos econométricos para previsão de variáveis.",
                                "Machine Learning: Base para regressão linear em scikit-learn."
                              ],
                              "realWorldApplication": "Em análise de dados empresariais, especificar Y = Xβ + u permite prever vendas baseado em publicidade, preço e sazonalidade usando MQO em ferramentas como R ou Python, otimizando estratégias de marketing com estimativas de β."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.1.1.3",
                            "name": "Diferenciar modelo populacional e amostral",
                            "description": "Explicar a relação entre o modelo teórico populacional e sua representação empírica com dados amostrais em aplicações de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Modelo Populacional",
                                  "subSteps": [
                                    "Definir população como o conjunto completo de observações possíveis.",
                                    "Explicar parâmetros populacionais (β₀, β₁, σ²) como valores verdadeiros e fixos.",
                                    "Escrever a equação do modelo: Y = β₀ + β₁X + ε, onde ε ~ N(0, σ²).",
                                    "Listar pressupostos do modelo (linearidade, independência, homocedasticidade, normalidade).",
                                    "Discutir que o modelo populacional é teórico e inacessível diretamente."
                                  ],
                                  "verification": "Escrever corretamente a equação do modelo populacional e listar pelo menos 3 pressupostos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Livro de regressão linear, software como R ou Python (para visualização opcional), quadro branco.",
                                  "tips": "Visualize a reta verdadeira como uma linha perfeita no plano ideal.",
                                  "learningObjective": "Dominar a estrutura teórica do modelo populacional em regressão linear.",
                                  "commonMistakes": "Confundir parâmetros populacionais (β) com estimativas amostrais (b); ignorar a distribuição de ε."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender o Conceito de Modelo Amostral",
                                  "subSteps": [
                                    "Definir amostra como subconjunto finito da população.",
                                    "Explicar estimadores amostrais (b₀, b₁) como aproximações de β₀ e β₁.",
                                    "Escrever a equação do modelo: yᵢ = b₀ + b₁xᵢ + eᵢ, onde eᵢ são resíduos.",
                                    "Calcular manualmente b₀ e b₁ usando fórmulas dos Mínimos Quadrados Ordinários (MQO).",
                                    "Discutir propriedades dos estimadores (não viesados, consistentes, eficientes)."
                                  ],
                                  "verification": "Calcular b₀ e b₁ para um conjunto de dados pequeno e explicar resíduos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Planilha Excel ou Python (biblioteca statsmodels), conjunto de dados amostral simples.",
                                  "tips": "Use fórmulas explícitas: b₁ = Σ(xᵢ - x̄)(yᵢ - ȳ) / Σ(xᵢ - x̄)².",
                                  "learningObjective": "Entender como dados empíricos representam o modelo teórico.",
                                  "commonMistakes": "Achar que b₀ e b₁ são exatos; confundir resíduos (e) com erros populacionais (ε)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diferenciar e Relacionar os Dois Modelos",
                                  "subSteps": [
                                    "Comparar equações: destacar β vs. b, ε vs. e, maiúsculas (população) vs. minúsculas (amostra).",
                                    "Explicar que o modelo amostral é uma estimação empírica do populacional.",
                                    "Discutir variância: amostral tem variância amostrada s² ≈ σ².",
                                    "Analisar convergência: com n → ∞, b → β (lei dos grandes números).",
                                    "Identificar limitações: amostras finitas introduzem incerteza (intervalos de confiança)."
                                  ],
                                  "verification": "Criar uma tabela comparativa entre modelo populacional e amostral com pelo menos 5 diferenças.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Tabela comparativa em papel ou Google Docs, gráficos de simulação em Python.",
                                  "tips": "Use notação consistente: Y,X maiúsculos para população; y,x minúsculos para amostra.",
                                  "learningObjective": "Diferenciar claramente e explicar a relação probabilística entre modelos.",
                                  "commonMistakes": "Ignorar que b é aleatório (distribuição amostragem); tratar amostra como população."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a Diferenciação em um Contexto de Engenharia",
                                  "subSteps": [
                                    "Escolher um problema real: prever deformação (Y) vs. carga (X) em vigas.",
                                    "Definir modelo populacional teórico e estimar com dados amostrais.",
                                    "Simular variabilidade amostral gerando múltiplas amostras.",
                                    "Interpretar: como b aproxima β e impactos em decisões de engenharia.",
                                    "Avaliar incertezas usando erros padrão de b."
                                  ],
                                  "verification": "Gerar relatório curto comparando modelo populacional e amostral em um exemplo.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Software Python/R com dados sintéticos, calculadora.",
                                  "tips": "Simule 100 amostras para visualizar distribuição de b em torno de β.",
                                  "learningObjective": "Aplicar conceitos em cenários práticos de engenharia.",
                                  "commonMistakes": "Superestimar precisão de b com amostras pequenas; negligenciar pressupostos."
                                }
                              ],
                              "practicalExample": "Em engenharia mecânica, para prever a deformação (Y) de vigas sob carga (X): modelo populacional Y = 0.5 + 2X + ε (β verdadeiros); com 20 medidas amostrais, estima-se y = 0.48 + 2.1x + e, onde b aproxima β, mas com variância devido à amostra finita.",
                              "finalVerifications": [
                                "Definir corretamente modelo populacional com equação e pressupostos.",
                                "Explicar estimadores amostrais e sua relação com parâmetros populacionais.",
                                "Comparar diferenças chave (teórico vs. empírico, fixo vs. aleatório).",
                                "Calcular MQO para dados simples e interpretar.",
                                "Discutir convergência e incertezas em amostras finitas.",
                                "Aplicar em exemplo de engenharia com interpretação correta."
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação e equações (30%)",
                                "Compreensão da relação probabilística (25%)",
                                "Capacidade de diferenciação clara (20%)",
                                "Aplicação prática em contexto de engenharia (15%)",
                                "Identificação de erros comuns e limitações (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuição amostragem e inferência.",
                                "Programação: Simulações em Python/R para MQO.",
                                "Engenharia: Modelagem preditiva em estruturas e controle de qualidade.",
                                "Probabilidade: Propriedades de estimadores não viesados."
                              ],
                              "realWorldApplication": "Em projetos de engenharia civil, diferenciação permite estimar parâmetros verdadeiros de resistência de materiais a partir de testes amostrais, calculando margens de segurança e evitando super ou subestimação de falhas estruturais."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.1.1.1.2",
                        "name": "Resíduos e Critério de Minimização",
                        "description": "Conceito de resíduos e_i = y_i - ŷ_i, e o critério MQO que minimiza a soma dos quadrados SSR = Σ e_i².",
                        "specificSkills": [
                          {
                            "id": "11.1.1.1.2.1",
                            "name": "Calcular resíduos em regressão simples",
                            "description": "Dado um conjunto de dados, computar os valores preditos ŷ_i e resíduos e_i para um modelo linear simples.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o conjunto de dados e identificar o modelo linear",
                                  "subSteps": [
                                    "Liste todos os pares de observações (x_i, y_i) do conjunto de dados.",
                                    "Identifique os parâmetros do modelo linear simples: intercepto β₀ e inclinação β₁.",
                                    "Confirme que o modelo é ŷ_i = β₀ + β₁ x_i.",
                                    "Registre o número de observações n.",
                                    "Verifique se os dados estão limpos (sem valores ausentes)."
                                  ],
                                  "verification": "Lista de dados e parâmetros do modelo documentados corretamente.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Conjunto de dados fornecido",
                                    "Papel e caneta ou planilha (Excel/Google Sheets)"
                                  ],
                                  "tips": "Sempre use os parâmetros exatos do modelo ajustado para evitar erros de entrada.",
                                  "learningObjective": "Compreender a estrutura do modelo linear simples e preparar dados para cálculos.",
                                  "commonMistakes": [
                                    "Confundir x_i com y_i",
                                    "Usar parâmetros incorretos do modelo",
                                    "Ignorar valores ausentes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os valores preditos ŷ_i para cada observação",
                                  "subSteps": [
                                    "Para cada x_i, compute ŷ_i = β₀ + β₁ × x_i.",
                                    "Registre ŷ_i ao lado de cada x_i e y_i em uma tabela.",
                                    "Arredonde os valores conforme a precisão necessária (ex: 2 casas decimais).",
                                    "Some todos os ŷ_i para verificação inicial.",
                                    "Compare com a média de y para coerência."
                                  ],
                                  "verification": "Tabela com ŷ_i calculados e soma verificada.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Calculadora ou planilha",
                                    "Tabela de dados do Step 1"
                                  ],
                                  "tips": "Use fórmulas em planilhas para automatizar: =B0 + B1 * A2.",
                                  "learningObjective": "Dominar o cálculo de predições lineares a partir de parâmetros conhecidos.",
                                  "commonMistakes": [
                                    "Erro aritmético em multiplicação",
                                    "Arredondamento prematuro",
                                    "Confundir β₀ com β₁"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular os resíduos e_i para cada observação",
                                  "subSteps": [
                                    "Para cada i, compute e_i = y_i - ŷ_i.",
                                    "Adicione a coluna de resíduos à tabela.",
                                    "Calcule a soma dos resíduos (deve ser aproximadamente zero em MQO).",
                                    "Identifique resíduos positivos e negativos.",
                                    "Registre o resíduo absoluto |e_i| se necessário."
                                  ],
                                  "verification": "Tabela completa com e_i e soma dos resíduos ≈ 0.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Calculadora ou planilha",
                                    "Tabela com ŷ_i do Step 2"
                                  ],
                                  "tips": "Resíduos positivos indicam subpredição; negativos, superpredição.",
                                  "learningObjective": "Aplicar a definição de resíduo e interpretá-los basicamente.",
                                  "commonMistakes": [
                                    "Subtrair na ordem errada (ŷ_i - y_i)",
                                    "Ignorar sinal dos resíduos",
                                    "Não somar para verificação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e resumir os resíduos calculados",
                                  "subSteps": [
                                    "Calcule estatísticas resumidas: média, variância e soma quadrados dos resíduos.",
                                    "Plote resíduos vs. ŷ_i ou x_i manualmente ou em software para inspeção visual.",
                                    "Confirme que não há padrões sistemáticos nos resíduos.",
                                    "Documente qualquer discrepância encontrada.",
                                    "Salve a tabela final para relatório."
                                  ],
                                  "verification": "Relatório com resumo estatístico e gráfico de resíduos sem padrões evidentes.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Planilha ou software de plotagem (Excel/Python/Matlab)",
                                    "Tabela completa"
                                  ],
                                  "tips": "Use scatter plot para resíduos; linha horizontal em zero é ideal.",
                                  "learningObjective": "Validar cálculos de resíduos e introduzir análise diagnóstica básica.",
                                  "commonMistakes": [
                                    "Não verificar soma zero",
                                    "Ignorar outliers em resíduos",
                                    "Plot errada (resíduos vs. y_i em vez de ŷ_i)"
                                  ]
                                }
                              ],
                              "practicalExample": "Conjunto de dados: x = [1, 2, 3, 4], y = [2.1, 4.0, 5.9, 8.0]. Modelo ajustado: β₀ = 0.3, β₁ = 1.9. Cálculos: ŷ = [2.2, 4.1, 6.0, 7.9]; e = [-0.1, -0.1, -0.1, 0.1]. Soma e_i ≈ 0.",
                              "finalVerifications": [
                                "Todos ŷ_i calculados corretamente com fórmula linear.",
                                "Resíduos e_i = y_i - ŷ_i exatos para cada i.",
                                "Soma dos resíduos aproximadamente zero.",
                                "Tabela completa com x_i, y_i, ŷ_i, e_i.",
                                "Estatísticas resumidas dos resíduos computadas.",
                                "Gráfico de resíduos sem padrões lineares evidentes."
                              ],
                              "assessmentCriteria": [
                                "Precisão aritmética nos cálculos (erro < 0.01).",
                                "Correta aplicação da fórmula de predição e resíduo.",
                                "Verificação adequada da soma dos resíduos.",
                                "Interpretação básica dos resíduos (positivos/negativos).",
                                "Apresentação clara da tabela e resumo.",
                                "Identificação de pelo menos um erro comum evitado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Análise de variância e suposições do MQO.",
                                "Programação: Implementar em Python (numpy/scipy) ou R.",
                                "Econometria: Diagnóstico de modelos em séries temporais.",
                                "Ciência de Dados: Pré-processamento em machine learning."
                              ],
                              "realWorldApplication": "Em análise de vendas, calcular resíduos para avaliar precisão de um modelo preditivo de demanda baseado em publicidade, identificando subestimações para ajustes estratégicos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.1.1"
                            ]
                          },
                          {
                            "id": "11.1.1.1.2.2",
                            "name": "Formular a função objetivo MQO",
                            "description": "Escrever matematicamente a soma dos quadrados dos resíduos SSR(β) = (y - Xβ)'(y - Xβ) e explicar sua minimização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de Regressão Linear",
                                  "subSteps": [
                                    "Defina os vetores y (vetor resposta observada), X (matriz de design ou covariáveis) e β (vetor de parâmetros).",
                                    "Explique o modelo linear: y = Xβ + ε, onde ε são os erros.",
                                    "Discuta a predição ŷ = Xβ e os resíduos e = y - ŷ.",
                                    "Identifique o papel dos resíduos como medida de erro do modelo.",
                                    "Pratique com um exemplo simples de 2 variáveis."
                                  ],
                                  "verification": "Escreva definições corretas de y, X, β e e em um caderno ou documento.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Caderno ou editor de texto",
                                    "Exemplo de dados simples (planilha ou papel)"
                                  ],
                                  "tips": "Use notação consistente: y em negrito ou minúsculo para vetores, maiúsculo para matrizes.",
                                  "learningObjective": "Compreender os componentes básicos do modelo de regressão linear.",
                                  "commonMistakes": "Confundir y (observado) com ŷ (predito); ignorar dimensões das matrizes."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir a Soma dos Quadrados dos Resíduos (SSR)",
                                  "subSteps": [
                                    "Defina resíduo individual e_i = y_i - x_i^T β.",
                                    "Escreva SSR em forma escalar: SSR(β) = Σ (y_i - x_i^T β)^2 para i=1 a n.",
                                    "Explique por que usamos quadrados: penaliza erros grandes e trata positivos/negativos igualmente.",
                                    "Calcule SSR manualmente para um dataset pequeno (n=3).",
                                    "Compare SSR para diferentes valores de β."
                                  ],
                                  "verification": "Calcule SSR para β=0 e β estimado em um exemplo numérico e compare os valores.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora ou Python/Jupyter para cálculos",
                                    "Dataset exemplo com 3-5 observações"
                                  ],
                                  "tips": "Sempre expanda (y_i - predito)^2 para verificar o cálculo.",
                                  "learningObjective": "Formular SSR na forma soma escalar e entender sua intuição.",
                                  "commonMistakes": "Esquecer o quadrado nos resíduos; somar resíduos absolutos em vez de quadrados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Escrever SSR na Forma Matricial",
                                  "subSteps": [
                                    "Expresse resíduos como vetor e = y - Xβ.",
                                    "Derive SSR(β) = e^T e = (y - Xβ)^T (y - Xβ).",
                                    "Expanda a expressão: y^T y - 2 β^T X^T y + β^T X^T X β.",
                                    "Verifique dimensões: todos termos devem ser escalares.",
                                    "Implemente em software para validar (ex: NumPy)."
                                  ],
                                  "verification": "Escreva e expanda a fórmula matricial corretamente, confirmando que resulta em escalar.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Folha de papel para álgebra matricial",
                                    "Python com NumPy para verificação"
                                  ],
                                  "tips": "Lembre-se: (A - B)^T (A - B) = A^T A - 2 A^T B + B^T B, com A=y, B=Xβ.",
                                  "learningObjective": "Dominar a notação matricial compacta da função objetivo MQO.",
                                  "commonMistakes": "Erro na transposição: esquecer ' em (y - Xβ)'; confundir X^T X com X X^T."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explicar a Minimização da Função Objetivo",
                                  "subSteps": [
                                    "Descreva MQO como argmin_β SSR(β).",
                                    "Discuta propriedades: SSR é quadrática convexa, mínimo único em β = (X^T X)^{-1} X^T y.",
                                    "Explique geometricamente: projeção ortogonal de y sobre coluna de X.",
                                    "Compare com outros critérios (ex: máxima verossimilhança sob erros normais).",
                                    "Aplique a um exemplo: minimize SSR analiticamente para regressão simples."
                                  ],
                                  "verification": "Derive a solução normal das equações e verifique com dados.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Livro de regressão ou notas de aula",
                                    "Software para resolver X^T X β = X^T y"
                                  ],
                                  "tips": "Visualize: minimizar SSR é encaixar a melhor reta/plano nos dados.",
                                  "learningObjective": "Entender o critério de minimização e sua solução.",
                                  "commonMistakes": "Achar que minimizamos soma de resíduos (não é zero); ignorar invertibilidade de X^T X."
                                }
                              ],
                              "practicalExample": "Considere dados: y = [3, 5, 7], X = [[1,1], [1,2], [1,3]] (intercepto + x). Calcule e = y - Xβ para β=[1,2]^T: e=[0, -1, 0]^T. SSR = 0 +1 +0 =1. Em matricial: (y - Xβ)^T (y - Xβ)=1. Minimize variando β.",
                              "finalVerifications": [
                                "Escreve corretamente SSR(β) = (y - Xβ)'(y - Xβ).",
                                "Expande a forma matricial para y'y - 2β'X'y + β'X'Xβ.",
                                "Calcula SSR numericamente para um dataset dado.",
                                "Explica por que minimizamos SSR (menor erro quadrático médio).",
                                "Deriva as equações normais X'X β = X'y.",
                                "Identifica quando X'X é invertível (colunas linearmente independentes)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação matricial (100% correto).",
                                "Correção nos cálculos numéricos (erro <1%).",
                                "Explicação clara da intuição da minimização (3+ razões).",
                                "Uso correto de transposições e dimensões.",
                                "Aplicação em exemplo prático com interpretação.",
                                "Identificação de pré-condições (ex: full rank de X)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuição dos resíduos sob normalidade.",
                                "Programação: Implementação em Python (NumPy/SciPy) ou R.",
                                "Álgebra Linear: Operações matriciais e projeções.",
                                "Machine Learning: Função de perda em regressão.",
                                "Econometria: Modelos de regressão em dados econômicos."
                              ],
                              "realWorldApplication": "Em análise de dados, MQO ajusta modelos preditivos como previsão de vendas (X=preços, y=vendas), minimizando erros em machine learning, econometria e ciências sociais para estimar relações causais confiáveis."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.1.2"
                            ]
                          },
                          {
                            "id": "11.1.1.1.2.3",
                            "name": "Interpretar propriedades geométricas dos resíduos",
                            "description": "Descrever ortogonalidade entre resíduos e variáveis explicativas no espaço vetorial projetado pelo MQO.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de Vetores, Projeções e Ortogonalidade",
                                  "subSteps": [
                                    "Defina vetor, espaço vetorial e produto interno em R^n.",
                                    "Explique projeção ortogonal de um vetor y sobre um subespaço spanned por vetores x1, ..., xk.",
                                    "Descreva o conceito de ortogonalidade: dois vetores u e v são ortogonais se u · v = 0.",
                                    "Calcule a projeção de um vetor simples y sobre um vetor x unitário.",
                                    "Verifique ortogonalidade entre o resíduo (y - proj_x y) e x."
                                  ],
                                  "verification": "Resolva um exercício simples: projete [3,4] sobre [1,0] e confirme que resíduo · [1,0] = 0.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de Álgebra Linear (ex: Strang), calculadora ou Python/NumPy para vetores.",
                                  "tips": "Visualize com desenhos de vetores no plano 2D para intuição geométrica.",
                                  "learningObjective": "Compreender projeção ortogonal e ortogonalidade como base para MQO.",
                                  "commonMistakes": "Confundir projeção com soma ponderada não-ortogonal; esquecer normalização."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender o Modelo de Regressão Linear em Notação Matricial",
                                  "subSteps": [
                                    "Escreva o modelo y = Xβ + ε, onde X é matriz n x (p+1), β vetor parâmetros, ε resíduos.",
                                    "Defina o estimador MQO: β_hat = (X^T X)^{-1} X^T y.",
                                    "Compute fitted values ŷ = X β_hat = P y, onde P = X (X^T X)^{-1} X^T é matriz de projeção.",
                                    "Identifique resíduos e = y - ŷ.",
                                    "Verifique dimensionalidade: e é vetor n x 1."
                                  ],
                                  "verification": "Derive manualmente β_hat para X com intercepto em dados simulados 3x2.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Software R/Python (numpy.linalg.lstsq), planilha para matrizes pequenas.",
                                  "tips": "Use transposição ^T consistentemente; pratique com n=2, p=1.",
                                  "learningObjective": "Representar regressão linear como problema de projeção matricial.",
                                  "commonMistakes": "Esquecer intercepto em X; inverter ordem em X^T X."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Visualizar a Geometria do MQO no Espaço Vetorial",
                                  "subSteps": [
                                    "Desenhe o espaço coluna col(X) como subespaço de R^n.",
                                    "Ilustre y arbitrário, sua projeção ŷ em col(X), e resíduo e perpendicular a col(X).",
                                    "Mostre que MQO minimiza ||e||^2 pois e ⊥ col(X) pelo teorema de projeção ortogonal.",
                                    "Gere gráfico 2D/3D: para n=3, p=1, plote y, col(X), ŷ, e.",
                                    "Confirme geometricamente: qualquer outro ŷ' em col(X) tem ||y - ŷ'|| > ||e||."
                                  ],
                                  "verification": "Crie plot em Python (matplotlib) mostrando ortogonalidade via setas perpendiculares.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Python (matplotlib, numpy), ou GeoGebra para visualização 3D.",
                                  "tips": "Comece com caso simples univariado sem intercepto para clareza visual.",
                                  "learningObjective": "Interpretar MQO como projeção ortogonal de y sobre col(X).",
                                  "commonMistakes": "Confundir col(X) com espaço de linhas; ignorar multicolinearidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Ortogonalidade entre Resíduos e Variáveis Explicativas",
                                  "subSteps": [
                                    "Prove que X^T e = 0, implicando cada coluna de X ⊥ e.",
                                    "Explique implicações: covariância zero entre preditores e resíduos.",
                                    "Discuta propriedades: E[e] = 0, Var(e) = σ^2 I sob pressupostos.",
                                    "Aplique em exemplo: compute X^T e e verifique nulidade.",
                                    "Relacione com diagnósticos: resíduos não correlacionados com fitted values."
                                  ],
                                  "verification": "Em dataset real (ex: Boston Housing), compute X^T e e confirme próximo de zero.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Dataset exemplo (sklearn.datasets), Jupyter Notebook.",
                                  "tips": "Use np.dot(X.T, e) para verificação numérica; tolerância para floating point.",
                                  "learningObjective": "Descrever e validar ortogonalidade como propriedade chave dos resíduos MQO.",
                                  "commonMistakes": "Achar que e ⊥ ŷ sempre (só se intercepto); confundir com homocedasticidade."
                                }
                              ],
                              "practicalExample": "Considere regressão simples y = [1,2,3]^T, X = [[1,1],[1,2],[1,3]] (com intercepto). β_hat ≈ [0.5, 0.833], ŷ ≈ [1.333, 2, 2.667], e ≈ [-0.333, 0, 0.333]. Verifique X^T e = [0, 0]^T, e ⊥ col(X) visualmente no plano.",
                              "finalVerifications": [
                                "Explicar verbalmente por que resíduos são ortogonais a col(X).",
                                "Derivar X^T e = 0 a partir de β_hat.",
                                "Gerar plot geométrico confirmando perpendicularidade.",
                                "Aplicar em dataset com múltiplas variáveis e verificar numericamente.",
                                "Discutir o que viola essa propriedade (ex: omitir variável relevante).",
                                "Relacionar com soma de quadrados: SST = SSR + SSE."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de projeção ortogonal (90%+ correto).",
                                "Correta derivação de X^T e = 0 com passos lógicos.",
                                "Qualidade do gráfico: e claramente perpendicular a col(X).",
                                "Interpretação correta de implicações estatísticas (cov=0).",
                                "Exemplo prático resolvido sem erros numéricos.",
                                "Conexão clara com minimização de ||e||^2."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Propriedades dos estimadores MQO (insesgo, BLUE).",
                                "Machine Learning: Geometria em Gradient Descent e embeddings.",
                                "Física: Projeções em mecânica vetorial (forças perpendiculares).",
                                "Computação: Álgebra linear numérica em NumPy/SciPy.",
                                "Econometria: Diagnósticos de resíduos em modelos econômicos."
                              ],
                              "realWorldApplication": "Em análise de dados, essa propriedade valida modelos de regressão (ex: previsão de vendas), detecta violações (omissões) e fundamenta inferência estatística em finanças, biologia e engenharia."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.1.3"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "11.1.1.1.3",
                        "name": "Estimadores e Solução MQO",
                        "description": "Derivação analítica dos estimadores β̂ = (X'X)⁻¹X'y e suas propriedades básicas sob pressupostos clássicos.",
                        "specificSkills": [
                          {
                            "id": "11.1.1.1.3.1",
                            "name": "Derivar estimador MQO para regressão simples",
                            "description": "Resolver ∂SSR/∂β = 0 para obter β̂₁ = Σ(x_i - x̄)(y_i - ȳ)/Σ(x_i - x̄)² e β̂₀ = ȳ - β̂₁x̄.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir o modelo de regressão linear simples e a função SSR",
                                  "subSteps": [
                                    "Escreva o modelo: y_i = β₀ + β₁ x_i + ε_i para i=1 a n.",
                                    "Defina a Soma dos Quadrados dos Resíduos (SSR): SSR(β₀, β₁) = Σ_{i=1}^n (y_i - β₀ - β₁ x_i)^2.",
                                    "Calcule as médias amostrais: x̄ = (1/n) Σ x_i e ȳ = (1/n) Σ y_i.",
                                    "Explique que o objetivo é minimizar SSR encontrando β̂₀ e β̂₁.",
                                    "Expanda SSR para facilitar derivações: SSR = Σ(y_i - ȳ)^2 + Σ(ȳ - β₀ - β₁ x_i)^2 - 2 Σ(y_i - ȳ)(ȳ - β₀ - β₁ x_i), mas foque na forma direta."
                                  ],
                                  "verification": "Confirme que SSR está corretamente escrita e expandida, sem erros de indexação.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Papel e caneta, calculadora para somas, tabela de dados de exemplo (x, y).",
                                  "tips": "Use notação clara com subscritos para evitar confusão entre somas.",
                                  "learningObjective": "Compreender a formulação matemática do problema de minimização em MQO.",
                                  "commonMistakes": "Esquecer o expoente 2 nos resíduos ou confundir y_i com ȳ na definição."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a condição normal para β₀: ∂SSR/∂β₀ = 0",
                                  "subSteps": [
                                    "Compute a derivada parcial: ∂SSR/∂β₀ = -2 Σ_{i=1}^n (y_i - β₀ - β₁ x_i).",
                                    "Iguale a zero: Σ (y_i - β₀ - β₁ x_i) = 0.",
                                    "Reorganize: n β₀ + β₁ Σ x_i = Σ y_i.",
                                    "Divida por n: β₀ + β₁ x̄ = ȳ.",
                                    "Conclua: β̂₀ = ȳ - β̂₁ x̄ (expressa em termos de β₁)."
                                  ],
                                  "verification": "Verifique se a equação resulta em β̂₀ = ȳ - β̂₁ x̄ substituindo as médias.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Papel para derivação, régua para alinhar equações.",
                                  "tips": "Lembre-se da regra da cadeia: derivada de (resíduo)^2 em relação a β₀ traz -2 * resíduo.",
                                  "learningObjective": "Aplicar cálculo diferencial para obter a primeira equação normal.",
                                  "commonMistakes": "Esquecer o fator -2 na derivada ou não dividir corretamente por n."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar a condição normal para β₁: ∂SSR/∂β₁ = 0",
                                  "subSteps": [
                                    "Compute ∂SSR/∂β₁ = -2 Σ_{i=1}^n x_i (y_i - β₀ - β₁ x_i).",
                                    "Iguale a zero: Σ x_i (y_i - β₀ - β₁ x_i) = 0.",
                                    "Substitua β₀ da equação anterior: Σ x_i (y_i - (ȳ - β₁ x̄) - β₁ x_i) = 0.",
                                    "Simplifique: Σ x_i ( (y_i - ȳ) - β₁ (x_i - x̄) ) = 0.",
                                    "Resolva: Σ x_i (y_i - ȳ) = β₁ Σ x_i (x_i - x̄), levando a β̂₁ = Σ (x_i - x̄)(y_i - ȳ) / Σ (x_i - x̄)^2."
                                  ],
                                  "verification": "Confirme a fórmula de β̂₁ batendo com a expressão covariância/variância.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Papel, lápis para expansões algébricas longas.",
                                  "tips": "Centre as variáveis subtraindo médias para simplificar somas cruzadas.",
                                  "learningObjective": "Derivar o estimador de inclinação usando álgebra matricial implícita.",
                                  "commonMistakes": "Não centralizar variáveis, resultando em somas não zero como Σ(x_i - x̄)=0."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e interpretar os estimadores MQO finais",
                                  "subSteps": [
                                    "Substitua β̂₁ na fórmula de β̂₀ para obter ambos explicitamente.",
                                    "Verifique propriedades: β̂₁ é covariância(x,y)/variância(x), β̂₀ ajusta intercepto.",
                                    "Teste com dados numéricos pequenos para validar.",
                                    "Discuta desvio padrão dos resíduos e R² como extensões.",
                                    "Conclua que isso minimiza SSR por construção das condições normais."
                                  ],
                                  "verification": "Aplique fórmulas em um dataset de 3-5 pontos e compute SSR mínimo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Calculadora ou planilha Excel para verificação numérica.",
                                  "tips": "Sempre normalize dados centrando para evitar erros de arredondamento.",
                                  "learningObjective": "Interpretar e validar os estimadores derivados no contexto MQO.",
                                  "commonMistakes": "Confundir Σ(x_i y_i) com Σ(x_i - x̄)(y_i - ȳ), ignorando centralização."
                                }
                              ],
                              "practicalExample": "Considere dados: x = [1,2,3,4], y=[2,4,5,7]. Compute x̄=2.5, ȳ=4.5. Então β̂₁ = [(1-2.5)(2-4.5)+...+(4-2.5)(7-4.5)] / Σ(x_i-x̄)^2 = (10)/[(-1.5)^2 + ... +1.5^2=5] = 2. β̂₀=4.5-2*2.5=-0.5. Linha: y=-0.5+2x, SSR mínimo calculado.",
                              "finalVerifications": [
                                "Fórmula de β̂₁ matches Σ(x_i - x̄)(y_i - ȳ)/Σ(x_i - x̄)² exatamente.",
                                "Fórmula de β̂₀ = ȳ - β̂₁ x̄ derivada corretamente.",
                                "Condições normais ∂SSR/∂βⱼ=0 levam ao sistema resolvido.",
                                "Verificação numérica com dados pequenos reproduz fórmulas.",
                                "SSR é minimizado comparado a outros β arbitrários.",
                                "Sem erros algébricos em expansões de somas."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação de ∂SSR/∂β₀ e ∂SSR/∂β₁ (100%).",
                                "Correta simplificação usando médias amostrais (90%).",
                                "Interpretação correta das fórmulas finais como cov/var (80%).",
                                "Verificação numérica sem erros de cálculo (70%).",
                                "Clareza na apresentação de passos e subpassos (60%).",
                                "Identificação de pelo menos 2 erros comuns evitados (50%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Propriedades de não-viés e eficiência dos estimadores MQO.",
                                "Programação: Implementar em Python com NumPy para `np.polyfit(x,y,1)`.",
                                "Econometria: Modelagem de relações causais em dados observacionais.",
                                "Cálculo: Aplicação de otimização multivariada sem restrições."
                              ],
                              "realWorldApplication": "Em análise de dados, derivação MQO é base para prever vendas (y) vs. publicidade (x) em marketing, ajustando preços em e-commerce ou modelando crescimento populacional vs. tempo em biologia."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.2.1"
                            ]
                          },
                          {
                            "id": "11.1.1.1.3.2",
                            "name": "Aplicar fórmula matricial MQO",
                            "description": "Calcular β̂ usando (X'X)⁻¹X'y em software ou manualmente para modelo múltiplo com dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o conjunto de dados e ambiente computacional",
                                  "subSteps": [
                                    "Selecione um dataset de engenharia com pelo menos 3 variáveis independentes (ex: peso, temperatura, pressão) e uma dependente (ex: resistência material).",
                                    "Carregue os dados em software como Python (NumPy/SciPy) ou MATLAB; para manual, use planilha ou papel.",
                                    "Verifique ausência de valores ausentes e normalize se necessário (centrar/subtrair média).",
                                    "Adicione coluna de 1s à X para intercepto.",
                                    "Defina y como vetor coluna da variável dependente."
                                  ],
                                  "verification": "Matrizes X (n x k) e y (n x 1) prontas e exibidas corretamente sem erros de shape.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com NumPy/SciPy/Pandas",
                                    "MATLAB ou Excel",
                                    "Dataset CSV de engenharia (ex: propriedades materiais)"
                                  ],
                                  "tips": "Use pd.read_csv() no Python para importação rápida; sempre cheque dimensões com .shape.",
                                  "learningObjective": "Configurar dados matriciais corretamente para MQO múltiplo.",
                                  "commonMistakes": [
                                    "Esquecer coluna de 1s para intercepto",
                                    "Confundir X (matriz) com y (vetor)",
                                    "Ignorar valores ausentes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir e calcular X'X",
                                  "subSteps": [
                                    "Calcule a transposta X' usando np.transpose(X) ou X.T no Python.",
                                    "Multiplique X' por X para obter matriz k x k simétrica.",
                                    "Verifique se X'X é definida positiva (autovalores >0).",
                                    "Para manual: compute elemento a_ij = soma_k X_ki * X_kj.",
                                    "Armazene como XXt."
                                  ],
                                  "verification": "Matriz XXt quadrada, simétrica e com diagonal positiva; teste multiplicação manual em submatriz 2x2.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código Python/MATLAB",
                                    "Papel para cálculos manuais pequenos",
                                    "Calculadora matricial online se necessário"
                                  ],
                                  "tips": "No Python: XXt = X.T @ X; evite loops para eficiência.",
                                  "learningObjective": "Dominar transposição e multiplicação matricial para MQO.",
                                  "commonMistakes": [
                                    "Erro na transposição (linhas viram colunas)",
                                    "Multiplicar X*X ao invés de X'*X",
                                    "Arredondamento excessivo em manual"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a inversa de (X'X)⁻¹",
                                  "subSteps": [
                                    "Use np.linalg.inv(XXt) no Python ou inv(XXt) no MATLAB.",
                                    "Para manual (pequenas matrizes): aplique fórmula de Cramer ou Gauss-Jordan.",
                                    "Verifique inversa multiplicando XXt * inv(XXt) ≈ I (identidade).",
                                    "Confira condicionalidade com np.linalg.cond(XXt) < 1e10.",
                                    "Armazene como invXXt."
                                  ],
                                  "verification": "XXt @ invXXt resulta em matriz identidade (tol=1e-6); det(XXt) ≠ 0.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Bibliotecas NumPy/SciPy",
                                    "Tabela de inversas 2x2/3x3 para manual"
                                  ],
                                  "tips": "Para multicolinearidade, use pseudoinversa np.linalg.pinv(); sempre verifique identidade.",
                                  "learningObjective": "Aplicar inversão matricial robusta em contextos de regressão.",
                                  "commonMistakes": [
                                    "Inverter matriz singular (multicolinearidade)",
                                    "Esquecer verificação I",
                                    "Erro de sinal em Gauss-Jordan"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular X'y e estimador β̂ = (X'X)⁻¹X'y",
                                  "subSteps": [
                                    "Calcule X'y como X.T @ y.",
                                    "Multiplique invXXt por Xy: beta = invXXt @ Xy.",
                                    "Interprete coeficientes: β0 intercepto, βi efeitos parciais.",
                                    "Compare com regressão linear simples para validação.",
                                    "Salve β̂ e plote y vs ŷ para visualização."
                                  ],
                                  "verification": "β̂ vetor k x 1; R² > 0.7 em dataset bom; resíduos médios ~0.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código existente",
                                    "Gráficos Matplotlib/Plot"
                                  ],
                                  "tips": "No Python: beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ y) em uma linha para automação.",
                                  "learningObjective": "Executar fórmula completa MQO e interpretar resultados.",
                                  "commonMistakes": [
                                    "Ordem errada: (X'X)⁻¹ * y ao invés de X'y",
                                    "Ignorar escala de variáveis",
                                    "Confundir β̂ com resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e interpretar o modelo MQO",
                                  "subSteps": [
                                    "Calcule ŷ = X @ β̂ e resíduos e = y - ŷ.",
                                    "Compute R² = 1 - SSE/SST.",
                                    "Teste pressupostos: linearidade, homocedasticidade via plots.",
                                    "Compare manual vs software para consistência.",
                                    "Documente limitações (ex: multicolinearidade)."
                                  ],
                                  "verification": "R² coerente; plots de resíduos sem padrões; β̂ idênticos em métodos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Matplotlib/Seaborn para plots",
                                    "Statsmodels para summary opcional"
                                  ],
                                  "tips": "Use QQ-plot para normalidade; se R² baixo, cheque multicolinearidade com VIF.",
                                  "learningObjective": "Avaliar validade do estimador MQO em dados reais.",
                                  "commonMistakes": [
                                    "Não checar pressupostos MQO",
                                    "Interpretar causalidade como correlação",
                                    "Overfitting em poucos dados"
                                  ]
                                }
                              ],
                              "practicalExample": "Dataset de engenharia mecânica: 50 amostras de vigas de aço com variáveis X: espessura (mm), comprimento (m), carga (kN); y: deformação máxima (mm). Calcule β̂: β0=-0.05, β1=0.12, β2=-0.08, β3=0.45. Usando Python: X = np.column_stack([ones, thickness, length, load]); beta = np.linalg.inv(X.T@X) @ (X.T@y). Resultado valida com R²=0.92.",
                              "finalVerifications": [
                                "β̂ calculado corretamente em software e manual (diferença <1e-4).",
                                "Matriz identidade na verificação de inversa.",
                                "R² >0.8 e resíduos com média zero.",
                                "Dimensões matriciais consistentes (X n x k, β k x 1).",
                                "Plots de y vs ŷ mostram ajuste linear.",
                                "Ausência de erros numéricos (NaN/inf)."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica: erro relativo <1e-6 em β̂.",
                                "Correta implementação da fórmula completa MQO.",
                                "Validação robusta com verificações e plots.",
                                "Interpretação física coerente dos coeficientes.",
                                "Eficiência: código otimizado sem loops desnecessários.",
                                "Tratamento de edge cases (ex: singularidade)."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: transposição, inversa, multiplicação.",
                                "Estatística: pressupostos regressão, R², resíduos.",
                                "Programação: NumPy/MATLAB para computação numérica.",
                                "Engenharia: modelagem preditiva em materiais/processos.",
                                "Análise de Dados: feature engineering e multicolinearidade."
                              ],
                              "realWorldApplication": "Em engenharia civil, otimizar design de pontes prevendo deformação via MQO com dados de sensores (peso, vento, material), reduzindo custos e riscos de falha estrutural."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.2.2"
                            ]
                          },
                          {
                            "id": "11.1.1.1.3.3",
                            "name": "Verificar propriedades dos estimadores",
                            "description": "Listar e justificar LINE (Linearidade, Independência, Normalidade, Esperança zero, Homocedasticidade) para validade do MQO.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Listar e compreender as propriedades LINE",
                                  "subSteps": [
                                    "Definir Linearidade: E(y|X) = Xβ, o modelo é linear nos parâmetros.",
                                    "Explicar Independência: Os erros u_i são independentes entre si.",
                                    "Descrever Normalidade: Os erros seguem distribuição normal N(0, σ²).",
                                    "Detalhar Esperança zero: E(u|X) = 0, média condicional dos erros é zero.",
                                    "Definir Homocedasticidade: Var(u|X) = σ² constante para todos os níveis de X."
                                  ],
                                  "verification": "Recitar verbalmente ou por escrito as 5 propriedades com definições corretas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notebook para anotações",
                                    "Material teórico sobre MQO (PDF ou slides)"
                                  ],
                                  "tips": "Use o acrônimo LINE para memorizar a ordem: Linearidade, Independência, Normalidade, Esperança zero, Homocedasticidade.",
                                  "learningObjective": "Compreender conceitualmente cada propriedade e sua importância para a validade dos estimadores MQO.",
                                  "commonMistakes": "Confundir independência com normalidade ou homocedasticidade com variância zero."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar dados e ajustar modelo MQO",
                                  "subSteps": [
                                    "Carregar um dataset exemplo (ex: Boston Housing via sklearn).",
                                    "Selecionar variáveis explicativas e resposta, dividir em treino/teste.",
                                    "Ajustar o modelo de regressão linear usando statsmodels.OLS.",
                                    "Extrair resíduos e valores preditos para análises subsequentes."
                                  ],
                                  "verification": "Modelo ajustado com summary() mostrando coeficientes e R²; resíduos calculados e plotados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com bibliotecas: pandas, statsmodels, matplotlib, seaborn",
                                    "Dataset exemplo (sklearn.datasets.load_boston)"
                                  ],
                                  "tips": "Sempre centralize variáveis se necessário para evitar multicolinearidade.",
                                  "learningObjective": "Dominar a implementação prática do MQO e extração de resíduos para verificações.",
                                  "commonMistakes": "Esquecer de tratar missing values ou outliers antes do ajuste."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificar Linearidade e Esperança zero",
                                  "subSteps": [
                                    "Gerar scatter plot de y vs predito e residual vs fitted plot.",
                                    "Calcular média dos resíduos e testar se ≈0 (t-test ou visual).",
                                    "Analisar padrões nos gráficos: ausência de curvas ou funis indica conformidade.",
                                    "Documentar evidências de linearidade condicional."
                                  ],
                                  "verification": "Gráficos mostram resíduos aleatórios sem padrões; média de resíduos < 0.01 em valor absoluto.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Bibliotecas: seaborn para plots",
                                    "statsmodels para resíduos"
                                  ],
                                  "tips": "Use scale_location plot para melhor visualização de linearidade.",
                                  "learningObjective": "Aplicar testes visuais e estatísticos para Linearidade e E(u)=0.",
                                  "commonMistakes": "Interpretar ruído aleatório como violação de linearidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar Independência e Homocedasticidade",
                                  "subSteps": [
                                    "Aplicar teste Durbin-Watson para autocorrelação (independência).",
                                    "Realizar teste Breusch-Pagan para homocedasticidade.",
                                    "Plotar residual vs ordem/lag e residual vs fitted com lowess.",
                                    "Interpretar p-valores: >0.05 indica não rejeição das hipóteses nulas."
                                  ],
                                  "verification": "Durbin-Watson ≈2; p-valor Breusch-Pagan >0.05; gráficos sem padrões seriais ou heteroscedasticidade.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "statsmodels.stats.diagnostic (dwtest, breuschpagan)",
                                    "seaborn.residplot"
                                  ],
                                  "tips": "Para amostras pequenas, priorize gráficos sobre testes.",
                                  "learningObjective": "Executar e interpretar testes diagnósticos para erros independentes e variância constante.",
                                  "commonMistakes": "Ignorar autocorrelação em dados temporais."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar Normalidade e sintetizar justificativa",
                                  "subSteps": [
                                    "Gerar QQ-plot dos resíduos e histograma.",
                                    "Aplicar teste Shapiro-Wilk ou Jarque-Bera para normalidade.",
                                    "Compilar relatório: listar conformidades/violações e justificar validade MQO.",
                                    "Propor correções se violações (ex: transformações, robust SE)."
                                  ],
                                  "verification": "QQ-plot linear; p-valor Shapiro >0.05; relatório escrito com conclusões claras.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "scipy.stats.shapiro",
                                    "statsmodels.stats.stattools.jarque_bera",
                                    "seaborn.distplot"
                                  ],
                                  "tips": "Normalidade é mais crítica para inferência; para predição, menos impactante.",
                                  "learningObjective": "Concluir sobre BLUE (Best Linear Unbiased Estimator) baseado em todas as verificações.",
                                  "commonMistakes": "Rejeitar modelo por violação leve de normalidade em grandes amostras."
                                }
                              ],
                              "practicalExample": "Usando dataset Boston Housing: ajuste MQO com RM (número de quartos) prevendo MEDV (preço). Verifique resíduos: plots mostram leve heteroscedasticidade (Breusch-Pagan p<0.05), mas linearidade ok; justifique uso de erros robustos.",
                              "finalVerifications": [
                                "Lista completa e correta das 5 propriedades LINE com definições.",
                                "Todos os gráficos e testes gerados com interpretações.",
                                "Relatório escrito justificando validade ou propondo ajustes.",
                                "Média de resíduos ≈0 e ausência de padrões nos residual plots.",
                                "p-valores dos testes documentados e thresholds aplicados corretamente.",
                                "Conclusão explícita sobre se estimadores MQO são válidos (BLUE)."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual nas definições das propriedades (100% corretas).",
                                "Correta implementação de testes e plots em Python (sem erros de código).",
                                "Interpretação lógica de resultados (evidências vs suposições).",
                                "Justificativa robusta ligando violações à invalidade dos estimadores.",
                                "Relatório claro e estruturado com recomendações práticas.",
                                "Uso adequado de múltiplos métodos de verificação por propriedade."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses e distribuições.",
                                "Programação Computacional: Manipulação de dados em Python/R.",
                                "Econometria: Diagnósticos em modelos de regressão.",
                                "Machine Learning: Validação de premissas em modelos lineares."
                              ],
                              "realWorldApplication": "Em previsão de vendas de imóveis, verificar LINE garante que coeficientes MQO sejam não viesados e eficientes, permitindo decisões confiáveis como precificação baseada em tamanho da casa, evitando prejuízos por modelos inválidos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.1.1"
                            ]
                          },
                          {
                            "id": "11.1.1.1.3.4",
                            "name": "Implementar MQO em R para dados reais",
                            "description": "Usar lm() no R para ajustar modelo MQO e interpretar summary() em contexto de análise de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e carregar dados reais no R",
                                  "subSteps": [
                                    "Instale e carregue pacotes necessários: install.packages(c('readr', 'dplyr')) e library(readr); library(dplyr)",
                                    "Carregue um dataset real de engenharia, como dados de testes de materiais (ex: tensão vs. deformação de aço)",
                                    "Inspecione a estrutura dos dados com str(), head() e summary()",
                                    "Trate valores ausentes com na.omit() ou imputação simples",
                                    "Defina variáveis dependente (y, ex: deformação) e independentes (x, ex: tensão)"
                                  ],
                                  "verification": "Execute head(df) e summary(df) sem erros e confirme que y e x estão numéricos e sem NAs",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Dataset CSV de engenharia (ex: steel_stress_strain.csv)"
                                  ],
                                  "tips": "Sempre use set.seed() para reprodutibilidade em simulações; nomeie variáveis claramente como 'stress' e 'strain'",
                                  "learningObjective": "Dominar carregamento e limpeza de dados reais para modelagem",
                                  "commonMistakes": [
                                    "Ignorar NAs levando a erros no lm()",
                                    "Confundir tipos de dados (factor vs numeric)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar dados e verificar premissas iniciais",
                                  "subSteps": [
                                    "Crie gráficos exploratórios: plot(x, y) e cor() para correlação",
                                    "Calcule correlação com cor(x, y) e verifique linearidade",
                                    "Teste normalidade residual preliminar com qqnorm() em uma amostra",
                                    "Verifique homocedasticidade com plot(x, y | residuais simulados)",
                                    "Documente insights em um relatório R Markdown"
                                  ],
                                  "verification": "Gráficos mostram relação aproximadamente linear e correlação > 0.7",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Pacotes base R + ggplot2 opcional"
                                  ],
                                  "tips": "Use pairs() para múltiplas variáveis; foque em outliers visuais",
                                  "learningObjective": "Identificar se dados atendem premissas OLS antes do modelo",
                                  "commonMistakes": [
                                    "Pular exploração e ajustar modelo em dados sujos",
                                    "Interpretar correlação alta como causalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar o modelo MQO usando lm()",
                                  "subSteps": [
                                    "Especifique a fórmula: model <- lm(y ~ x, data = df)",
                                    "Execute o modelo e armazene em 'model'",
                                    "Verifique a classe com class(model) == 'lm'",
                                    "Salve o summary inicial: sum_model <- summary(model)",
                                    "Extraia coeficientes com coef(model)"
                                  ],
                                  "verification": "summary(model) executa sem warnings e retorna p-value < 0.05 para intercepto e slope",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Ambiente R limpo com dados preparados"
                                  ],
                                  "tips": "Use lm(y ~ x + I(x^2)) para não-linearidades se necessário; sempre cheque residuals(model)",
                                  "learningObjective": "Executar ajuste OLS preciso com lm() em dados reais",
                                  "commonMistakes": [
                                    "Fórmula errada como lm(x ~ y)",
                                    "Não especificar data= para evitar busca global"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar o summary() do modelo",
                                  "subSteps": [
                                    "Analise coeficientes: Estimate, Std. Error, t value, Pr(>|t|)",
                                    "Interprete R-squared: proporção de variância explicada",
                                    "Examine p-values: significância de cada preditor",
                                    "Verifique F-statistic e Adjusted R-squared para ajuste global",
                                    "Discuta em contexto de engenharia: ex: slope como módulo de elasticidade"
                                  ],
                                  "verification": "Escreva um parágrafo resumindo: 'O modelo explica XX% da variância com slope significativo (p=YY)'",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Output de summary(model)"
                                  ],
                                  "tips": "Foquem em CI (confint(model)); R-squared > 0.8 é bom para engenharia preditiva",
                                  "learningObjective": "Extrair e contextualizar métricas OLS para análise de engenharia",
                                  "commonMistakes": [
                                    "Confundir p-value com probabilidade de nulidade",
                                    "Ignorar Adjusted R-squared em múltiplos preditores"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e visualizar o modelo ajustado",
                                  "subSteps": [
                                    "Plote diagnósticos: plot(model) para residuals vs fitted, Q-Q, Scale-Location",
                                    "Teste premissas: shapiro.test(residuals(model)) para normalidade",
                                    "Crie predições: predict(model, newdata) e compare com reais",
                                    "Visualize linha de regressão: abline(coef(model)) no scatterplot",
                                    "Gere relatório com knitr::kable(summary(model)$coefficients)"
                                  ],
                                  "verification": "Gráficos de diagnóstico sem padrões claros em residuals e predições RMSE < 10% do range(y)",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "ggplot2 para plots avançados"
                                  ],
                                  "tips": "Use dwtest(model) para autocorrelação se dados temporais; itere ajustando modelo se premissas falharem",
                                  "learningObjective": "Validar robustez do MQO e comunicar resultados visualmente",
                                  "commonMistakes": [
                                    "Aceitar modelo sem checar residuals heteroscedásticos",
                                    "Não escalar variáveis para comparações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em testes de materiais de engenharia, use dataset 'steel_data.csv' com colunas 'stress' (MPa) e 'strain' (%). Ajuste lm(strain ~ stress) para estimar módulo de elasticidade (slope ≈ 200 GPa para aço). Interprete summary() para confirmar significância e use predições para prever deformação em tensões de design (ex: 300 MPa).",
                              "finalVerifications": [
                                "Modelo lm() ajusta sem erros e summary() mostra todos p-values < 0.05",
                                "R-squared > 0.75 e residuals plot sem padrões não-lineares",
                                "Predições em novos dados reais coincidem com observados (erro < 5%)",
                                "Relatório escrito explica coeficientes em termos de engenharia",
                                "Diagnósticos confirmam premissas OLS (normalidade, homocedasticidade)",
                                "Código R é reprodutível com set.seed() e comentários"
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação lm() e interpretação correta de summary() (40%)",
                                "Qualidade da exploração e tratamento de dados reais (20%)",
                                "Validação completa com plots e testes estatísticos (20%)",
                                "Conexão contextual com análise de engenharia (10%)",
                                "Clareza e reprodutibilidade do código R (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência sobre parâmetros β (t-tests, CI)",
                                "Programação: Manipulação de dados com dplyr/tidyverse",
                                "Engenharia Mecânica: Modelagem constitutiva de materiais",
                                "Matemática: Álgebra matricial subjacente ao lm()",
                                "Visualização de Dados: ggplot2 para diagnósticos"
                              ],
                              "realWorldApplication": "Em engenharia civil, MQO com lm() modela relação tensão-deformação para dimensionar vigas de aço, prevendo falhas sob cargas reais e otimizando designs sustentáveis; em automotiva, prevê eficiência de motores via regressão de MPG vs. peso."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.1.1.1.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.2",
                    "name": "Modelo de Regressão Linear",
                    "description": "Representação matemática da relação linear entre uma variável dependente e uma ou mais variáveis independentes.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.2.1",
                        "name": "Modelo de Regressão Linear Simples",
                        "description": "Representação matemática da relação linear entre uma variável dependente Y e uma única variável independente X, expressa como Y = β₀ + β₁X + ε, no contexto de econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.2.1.1",
                            "name": "Identificar componentes do modelo simples",
                            "description": "Reconhecer e nomear as variáveis dependente (Y), independente (X), intercepto (β₀), coeficiente angular (β₁) e termo de erro (ε) na equação Y = β₀ + β₁X + ε.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Familiarizar-se com a equação do modelo de regressão linear simples",
                                  "subSteps": [
                                    "Escreva a equação Y = β₀ + β₁X + ε em um papel ou quadro.",
                                    "Leia a equação em voz alta, destacando cada símbolo.",
                                    "Desenhe um gráfico simples de uma reta para visualizar Y em função de X.",
                                    "Compare com a equação de uma reta simples (y = mx + b) e note as diferenças.",
                                    "Anote a definição geral: modelo que relaciona uma variável dependente a uma independente."
                                  ],
                                  "verification": "Recite a equação completa sem olhar e explique brevemente seu propósito.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Quadro ou ferramenta digital como GeoGebra"
                                  ],
                                  "tips": "Use cores diferentes para cada símbolo ao escrever a equação.",
                                  "learningObjective": "Memorizar e compreender a estrutura padrão da equação de regressão linear simples.",
                                  "commonMistakes": "Ignorar o termo de erro (ε), tratando como equação determinística exata."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar a variável dependente (Y) e independente (X)",
                                  "subSteps": [
                                    "Defina Y como a variável que queremos prever ou explicar (dependente).",
                                    "Defina X como a variável que usamos para explicar ou prever Y (independente).",
                                    "Em um contexto real, como 'altura (Y) vs peso (X)', rotule cada uma.",
                                    "Escreva exemplos de pares (X, Y) de diferentes áreas (ex: economia, biologia).",
                                    "Crie uma tabela com colunas X e Y para dados fictícios."
                                  ],
                                  "verification": "Dado um problema descritivo, aponte corretamente qual é X e qual é Y.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel para tabelas",
                                    "Exemplos impressos ou digitais de datasets simples"
                                  ],
                                  "tips": "Lembre-se: X é o 'input' ou causa, Y é o 'output' ou efeito.",
                                  "learningObjective": "Distinguir e nomear corretamente as variáveis dependente e independente.",
                                  "commonMistakes": "Confundir Y com X em cenários onde a causalidade não é óbvia."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Reconhecer o intercepto (β₀) e o coeficiente angular (β₁)",
                                  "subSteps": [
                                    "Explique β₀ como o valor de Y quando X=0 (ponto de intercepto no eixo Y).",
                                    "Explique β₁ como a inclinação da reta, ou mudança em Y por unidade de X.",
                                    "Calcule β₀ e β₁ manualmente em um exemplo simples com dois pontos.",
                                    "Desenhe a reta no gráfico e marque β₀ e β₁ visualmente.",
                                    "Discuta unidades: β₁ tem unidades de Y/X."
                                  ],
                                  "verification": "Em uma equação dada, isole e descreva o papel de β₀ e β₁ com um exemplo numérico.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora simples",
                                    "Gráficos impressos ou software como Desmos"
                                  ],
                                  "tips": "Pense em β₀ como 'salário base sem experiência' em um modelo de salário vs anos.",
                                  "learningObjective": "Identificar e interpretar os parâmetros de intercepto e inclinação.",
                                  "commonMistakes": "Confundir β₀ com β₁ ou ignorar que eles são estimados, não conhecidos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Entender o termo de erro (ε) e sintetizar todos os componentes",
                                  "subSteps": [
                                    "Defina ε como a diferença entre o valor observado de Y e o previsto pelo modelo.",
                                    "Explique que ε captura variações aleatórias ou não explicadas por X.",
                                    "Em um gráfico de dispersão, marque pontos de dados e desenhe linhas de erro verticais.",
                                    "Reescreva a equação destacando todos os cinco componentes juntos.",
                                    "Crie um fluxograma mostrando como cada parte se encaixa no modelo."
                                  ],
                                  "verification": "Explique a equação completa, nomeando e descrevendo todos os componentes em sequência.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel para fluxogramas",
                                    "Gráficos de dispersão exemplo"
                                  ],
                                  "tips": "ε é como 'ruído' no sistema; sem ele, o modelo seria perfeito, o que é raro.",
                                  "learningObjective": "Compreender o papel do erro e integrar todos os componentes do modelo.",
                                  "commonMistakes": "Subestimar ε, achando que o modelo explica 100% da variação."
                                }
                              ],
                              "practicalExample": "Em um dataset de vendas de sorvete (Y, em unidades) vs temperatura (X, em °C): Y = 20 + 5X + ε. Aqui, Y é vendas (dependente), X é temperatura (independente), β₀=20 (vendas base sem calor), β₁=5 (5 unidades extras por °C), ε=variação devido a outros fatores como feriados.",
                              "finalVerifications": [
                                "Nomeie corretamente os cinco componentes da equação Y = β₀ + β₁X + ε.",
                                "Explique o papel de cada componente em uma frase.",
                                "Identifique X e Y em um problema contextualizado.",
                                "Diferencie β₀ de β₁ com um exemplo gráfico.",
                                "Descreva ε como termo estocástico.",
                                "Reconstrua a equação a partir de descrições verbais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na nomeação de todos os componentes (100% correto).",
                                "Capacidade de explicar funções sem erros conceituais.",
                                "Aplicação correta em exemplos práticos.",
                                "Uso adequado de terminologia estatística (ex: dependente vs independente).",
                                "Demonstração visual ou gráfica coerente.",
                                "Identificação de limitações do modelo simples."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Conceitos de variância e resíduos.",
                                "Programação: Implementação em Python com bibliotecas como NumPy e scikit-learn.",
                                "Economia: Modelos de previsão de demanda e oferta.",
                                "Ciências Biológicas: Regressão em experimentos de crescimento vegetal.",
                                "Física: Relações lineares em movimento uniforme."
                              ],
                              "realWorldApplication": "Esse conhecimento é fundamental em análise de dados para construir modelos preditivos simples, como estimar o consumo de energia (Y) baseado na temperatura externa (X) em sistemas de climatização inteligente, ou prever notas de alunos (Y) com base em horas de estudo (X) em ferramentas educacionais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.1.2",
                            "name": "Escrever a equação do modelo simples",
                            "description": "Formular matematicamente o modelo de regressão linear simples para dados de engenharia, como relação entre tensão aplicada e deformação em materiais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os componentes fundamentais do modelo de regressão linear simples",
                                  "subSteps": [
                                    "Defina a variável dependente y como a resposta observada (ex: deformação ε em materiais).",
                                    "Defina a variável independente x como o preditor (ex: tensão σ aplicada).",
                                    "Identifique o intercepto β₀ como o valor esperado de y quando x=0.",
                                    "Identifique o coeficiente β₁ como a inclinação da reta, representando a mudança em y por unidade de x.",
                                    "Explique o termo de erro ε como a variação aleatória não explicada pelo modelo."
                                  ],
                                  "verification": "Liste e descreva corretamente os quatro componentes (y, x, β₀, β₁, ε) com exemplos do contexto de engenharia.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão linear",
                                    "Gráfico de tensão vs. deformação",
                                    "Calculadora ou software como Excel"
                                  ],
                                  "tips": [
                                    "Visualize graficamente: plote pontos de dados para ver a relação linear intuitivamente.",
                                    "Relacione com Lei de Hooke: ε = σ / E, onde E ≈ β₁."
                                  ],
                                  "learningObjective": "Dominar a notação e o significado físico de cada parâmetro no modelo.",
                                  "commonMistakes": [
                                    "Confundir variável dependente (y) com independente (x).",
                                    "Esquecer que β₀ pode não ter significado físico em alguns contextos.",
                                    "Ignorar o termo ε, tratando o modelo como perfeitamente determinístico."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o contexto de engenharia e selecionar variáveis apropriadas",
                                  "subSteps": [
                                    "Revise o problema: identifique tensão aplicada como x e deformação como y em testes de materiais.",
                                    "Colete ou simule um conjunto de dados pequeno (ex: 5 pares (σ, ε) de um teste de tração).",
                                    "Plote os dados em um gráfico de dispersão para confirmar linearidade aproximada.",
                                    "Discuta premissas: independência, homocedasticidade e normalidade de resíduos.",
                                    "Defina o domínio físico: tensão até o limite elástico."
                                  ],
                                  "verification": "Crie um gráfico de dispersão com dados rotulados corretamente e anote premissas assumidas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dados de exemplo de testes de tração (planilha Excel)",
                                    "Software de plotagem como Python Matplotlib ou Excel"
                                  ],
                                  "tips": [
                                    "Use escalas reais de engenharia (MPa para tensão, % para deformação).",
                                    "Verifique outliers que possam indicar não-linearidade (plástico)."
                                  ],
                                  "learningObjective": "Aplicar conceitos teóricos a dados reais de engenharia para contextualizar o modelo.",
                                  "commonMistakes": [
                                    "Escolher variáveis erradas (ex: inverter x e y).",
                                    "Ignorar faixa de validade linear.",
                                    "Não plotar dados antes de modelar."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Formular a equação determinística inicial do modelo",
                                  "subSteps": [
                                    "Escreva a relação esperada: E(y|x) = β₀ + β₁ x.",
                                    "Substitua variáveis do contexto: deformação esperada = β₀ + β₁ * tensão.",
                                    "Interprete β₀: deformação residual sem tensão (idealmente 0).",
                                    "Interprete β₁: módulo de elasticidade aproximado (1/E se invertido).",
                                    "Teste com um ponto de dados: calcule y previsto."
                                  ],
                                  "verification": "Escreva a equação com notação correta e interprete os coeficientes fisicamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e lápis para derivação",
                                    "Exemplo de dados da etapa 2"
                                  ],
                                  "tips": [
                                    "Comece com β₀ = 0 se fisicamente faz sentido.",
                                    "Use subscritos para clareza: y_i = β₀ + β₁ x_i."
                                  ],
                                  "learningObjective": "Construir a forma esperada do modelo linear simples.",
                                  "commonMistakes": [
                                    "Escrever y = β x sem intercepto quando necessário.",
                                    "Usar notação inconsistente (gregas vs. latinas).",
                                    "Confundir E(y) com y observada."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Incorporar estocasticidade e finalizar a equação do modelo",
                                  "subSteps": [
                                    "Adicione o termo de erro: y = β₀ + β₁ x + ε.",
                                    "Especifique propriedades de ε: E(ε)=0, Var(ε)=σ² constante.",
                                    "Escreva para observações múltiplas: y_i = β₀ + β₁ x_i + ε_i, i=1,...,n.",
                                    "Relacione com o exemplo: ε captura ruído experimental em testes de materiais.",
                                    "Resuma o modelo completo em uma frase contextualizada."
                                  ],
                                  "verification": "Escreva a equação estocástica completa e liste 3 propriedades de ε.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resumo de premissas da regressão linear",
                                    "Livro-texto de estatística aplicada à engenharia"
                                  ],
                                  "tips": [
                                    "Lembre: sem ε, o modelo é irrealista para dados reais.",
                                    "Anote IID para resíduos independentes e identicamente distribuídos."
                                  ],
                                  "learningObjective": "Completar o modelo reconhecendo incerteza inerente a dados empíricos.",
                                  "commonMistakes": [
                                    "Omitir ε na equação final.",
                                    "Assumir ε determinístico.",
                                    "Não indexar observações (i)."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um teste de tração de aço carbono, com dados: tensão (MPa): [100, 200, 300, 400]; deformação (%): [0.05, 0.10, 0.15, 0.20 + ruído]. O modelo é: ε = β₀ + β₁ σ + ε_i, onde β₁ ≈ 1/E (E≈200 GPa), prevendo deformação para design seguro.",
                              "finalVerifications": [
                                "Equação escrita corretamente como y = β₀ + β₁ x + ε com notação padrão.",
                                "Variáveis x (tensão) e y (deformação) identificadas e justificadas.",
                                "Coeficientes β₀ e β₁ interpretados fisicamente no contexto de materiais.",
                                "Termo ε incluído com pelo menos uma propriedade (média zero).",
                                "Modelo relacionado explicitamente ao exemplo de engenharia.",
                                "Premissas lineares mencionadas brevemente."
                              ],
                              "assessmentCriteria": [
                                "Precisão da notação matemática (20%)",
                                "Correta identificação e rotulagem de variáveis (20%)",
                                "Interpretação física relevante dos parâmetros (25%)",
                                "Inclusão e explicação do termo de erro (20%)",
                                "Clareza e completude da equação final (15%)"
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Materiais: Lei de Hooke e propriedades elásticas.",
                                "Estatística: Premissas dos Mínimos Quadrados Ordinários.",
                                "Física: Relações lineares em mecânica dos sólidos.",
                                "Programação: Implementação em Python (numpy.polyfit) para ajuste.",
                                "Análise de Dados: Visualização e diagnóstico de resíduos."
                              ],
                              "realWorldApplication": "Em engenharia civil/aeroespacial, o modelo prevê deformação sob tensão em vigas ou asas, auxiliando no dimensionamento seguro de estruturas para evitar falhas elásticas, otimizando materiais e custos em projetos como pontes ou aviões."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.1.3",
                            "name": "Interpretar parâmetros β₀ e β₁",
                            "description": "Explicar o significado prático do intercepto β₀ (valor de Y quando X=0) e do coeficiente β₁ (mudança em Y por unidade de X), com exemplos em análise de custos de produção em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a equação do modelo de regressão linear simples",
                                  "subSteps": [
                                    "Estude a forma geral da equação: Y = β₀ + β₁X + ε, onde Y é a variável dependente, X é a independente, β₀ é o intercepto, β₁ é o coeficiente angular e ε é o erro.",
                                    "Identifique cada componente: explique o papel de β₀ como ponto de partida e β₁ como taxa de mudança.",
                                    "Visualize a equação em um gráfico de dispersão com a reta de regressão.",
                                    "Pratique reescrevendo a equação para diferentes contextos.",
                                    "Compare com uma linha reta simples y = mx + b."
                                  ],
                                  "verification": "Recite a equação completa e identifique corretamente cada parâmetro em um papel ou verbalmente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Gráfico de exemplo de regressão linear",
                                    "Calculadora"
                                  ],
                                  "tips": "Sempre inclua o termo de erro ε para lembrar que o modelo é uma aproximação.",
                                  "learningObjective": "Dominar a estrutura matemática do modelo de regressão linear simples.",
                                  "commonMistakes": [
                                    "Ignorar o termo de erro ε",
                                    "Confundir Y com X",
                                    "Pensar que β₀ e β₁ são fixos sem dados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar o parâmetro β₀ (intercepto)",
                                  "subSteps": [
                                    "Defina β₀ como o valor esperado de Y quando X = 0.",
                                    "Discuta se X=0 é realista no contexto (ex: custo fixo mesmo sem produção).",
                                    "Calcule Y para X=0 usando um exemplo numérico simples.",
                                    "Explique o significado prático: representa o baseline ou custo fixo.",
                                    "Desenhe o gráfico destacando o ponto (0, β₀)."
                                  ],
                                  "verification": "Explique verbalmente o que β₀ representa e calcule Y para X=0 em um exemplo dado.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráfico de regressão",
                                    "Exemplo de dados tabulares",
                                    "Software como Excel ou Python (opcional)"
                                  ],
                                  "tips": "Se X=0 não fizer sentido prático, destaque que β₀ é uma extrapolação útil para interpretação.",
                                  "learningObjective": "Explicar o significado prático do intercepto β₀ em contextos reais.",
                                  "commonMistakes": [
                                    "Interpretar β₀ como a média de Y",
                                    "Assumir que β₀ é sempre positivo",
                                    "Ignorar o contexto da variável X"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar o parâmetro β₁ (coeficiente angular)",
                                  "subSteps": [
                                    "Defina β₁ como a mudança esperada em Y para cada aumento unitário em X.",
                                    "Calcule a variação: ΔY = β₁ * ΔX.",
                                    "Interprete o sinal: positivo (aumento), negativo (diminuição), zero (sem relação).",
                                    "Aplique em unidades reais: ex: R$ por unidade produzida.",
                                    "Visualize no gráfico: inclinação da reta."
                                  ],
                                  "verification": "Dado β₁ = 10 e ΔX = 5, calcule e explique a mudança em Y.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tabela de dados exemplo",
                                    "Gráfico com reta de regressão",
                                    "Calculadora"
                                  ],
                                  "tips": "Sempre especifique as unidades de X e Y para uma interpretação clara.",
                                  "learningObjective": "Compreender β₁ como taxa de mudança e sua interpretação prática.",
                                  "commonMistakes": [
                                    "Confundir com variação percentual",
                                    "Ignorar o sinal de β₁",
                                    "Pensar que β₁ é absoluto"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a interpretação em análise de custos de produção",
                                  "subSteps": [
                                    "Escolha um dataset de custos: X = unidades produzidas, Y = custo total.",
                                    "Estime ou use β₀ = custo fixo (ex: aluguel), β₁ = custo variável por unidade.",
                                    "Preveja custos para diferentes X e interprete os parâmetros.",
                                    "Analise cenários: o que acontece se X dobra?",
                                    "Discuta limitações do modelo no contexto de engenharia."
                                  ],
                                  "verification": "Interprete β₀ e β₁ em um exemplo completo de custos e preveja Y para X=100.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dataset exemplo de custos (planilha Excel)",
                                    "Gráfico gerado",
                                    "Caneta e papel"
                                  ],
                                  "tips": "Use exemplos próximos à engenharia para fixar o aprendizado.",
                                  "learningObjective": "Integrar interpretações de β₀ e β₁ em um problema real de engenharia.",
                                  "commonMistakes": [
                                    "Extrapolação além do range de dados",
                                    "Confundir custo fixo com marginal",
                                    "Ignorar não-linearidades"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de engenharia, o modelo estimado é Custo Total (Y em R$) = 5000 + 20 * Unidades Produzidas (X). β₀ = 5000 representa os custos fixos (máquinas, aluguel) quando nenhuma unidade é produzida. β₁ = 20 indica que cada unidade adicional custa R$20 em materiais e mão de obra variável.",
                              "finalVerifications": [
                                "Explique β₀ e β₁ em suas próprias palavras com o exemplo de custos.",
                                "Calcule e interprete Y para X=0 e X=50.",
                                "Identifique o sinal e magnitude de β₁ em um novo modelo.",
                                "Descreva limitações se X=0 não for viável.",
                                "Compare interpretações em dois contextos diferentes.",
                                "Desenhe o gráfico rotulando β₀ e β₁ corretamente."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de β₀ como valor de Y em X=0.",
                                "Correta interpretação de β₁ como mudança por unidade de X.",
                                "Uso apropriado de unidades e contexto prático.",
                                "Inclusão de limitações ou caveats na interpretação.",
                                "Clareza na explicação verbal ou escrita.",
                                "Aplicação correta em exemplo numérico."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Produção: Otimização de custos e previsão de despesas.",
                                "Economia: Análise de custos fixos e variáveis em modelos econômicos.",
                                "Estatística: Inferência sobre parâmetros em testes de hipóteses.",
                                "Programação: Implementação em Python/R para estimação de β via mínimos quadrados.",
                                "Gestão: Tomada de decisões baseadas em regressão para forecasting."
                              ],
                              "realWorldApplication": "Na engenharia industrial, interpretar β₀ e β₁ permite prever custos de produção, definir preços de venda, otimizar escalas de produção e identificar ineficiências, como em fábricas de automóveis ou linhas de montagem onde custos fixos (infraestrutura) e variáveis (matéria-prima) são modelados para simulações de cenários econômicos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.1.4",
                            "name": "Explicar o termo de erro ε",
                            "description": "Descrever o termo de erro ε como a diferença entre o valor observado e predito de Y, representando variações não explicadas pelo modelo linear.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o modelo de regressão linear simples",
                                  "subSteps": [
                                    "Lembre-se da equação geral: Y = β₀ + β₁X + ε",
                                    "Identifique Y como a variável dependente observada",
                                    "Identifique X como a variável independente",
                                    "Explique β₀ e β₁ como parâmetros do modelo",
                                    "Discuta o papel do termo aditivo ε"
                                  ],
                                  "verification": "Escreva a equação completa do modelo e identifique cada componente verbalmente",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Quadro branco ou papel",
                                    "Livro de regressão linear ou slides introdutórios"
                                  ],
                                  "tips": "Use analogias como uma linha reta que melhor se ajusta a pontos espalhados",
                                  "learningObjective": "Compreender a estrutura fundamental do modelo de regressão linear simples",
                                  "commonMistakes": [
                                    "Confundir Y com X",
                                    "Esquecer o termo ε na equação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diferenciar valores observados e preditos",
                                  "subSteps": [
                                    "Defina Ŷ (Y chapéu) como o valor predito: Ŷ = β₀ + β₁X",
                                    "Compare Y (observado) com Ŷ (predito)",
                                    "Calcule a diferença Y - Ŷ para um dado ponto",
                                    "Repita para múltiplos pontos de dados",
                                    "Visualize graficamente com pontos reais e linha de regressão"
                                  ],
                                  "verification": "Para um conjunto de dados simples (3 pontos), calcule Ŷ e Y - Ŷ",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora ou Excel",
                                    "Gráfico de dispersão impresso ou software como Python/Matplotlib"
                                  ],
                                  "tips": "Sempre plote os dados para visualizar a discrepância",
                                  "learningObjective": "Distinguir com clareza entre valores reais e estimados pelo modelo",
                                  "commonMistakes": [
                                    "Usar a equação errada para Ŷ",
                                    "Ignorar que predições são determinísticas sem ε"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir e formular o termo de erro ε",
                                  "subSteps": [
                                    "Estabeleça ε = Y - Ŷ como a definição matemática",
                                    "Explique que ε captura a diferença entre observado e predito",
                                    "Descreva ε como uma variável aleatória com média zero",
                                    "Discuta suposições: ε ~ N(0, σ²) independentemente",
                                    "Escreva exemplos numéricos de ε positivo e negativo"
                                  ],
                                  "verification": "Formule ε para 5 pontos de dados e verifique se a média dos ε é próxima de zero",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Notas de aula sobre suposições do modelo"
                                  ],
                                  "tips": "Lembre-se: ε não é constante; varia por observação",
                                  "learningObjective": "Formular precisamente o termo de erro e suas propriedades básicas",
                                  "commonMistakes": [
                                    "Confundir ε com β",
                                    "Achar que ε é fixo em vez de aleatório"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar o significado e implicações de ε",
                                  "subSteps": [
                                    "Explique que ε representa variações não explicadas por X",
                                    "Discuta fontes de ε: ruído aleatório, variáveis omitidas, erros de medição",
                                    "Analise resíduos (ε) para diagnóstico do modelo",
                                    "Verifique normalidade e homocedasticidade de ε",
                                    "Conclua que um bom modelo minimiza a soma dos quadrados de ε"
                                  ],
                                  "verification": "Descreva verbalmente 3 fontes possíveis de ε em um contexto real e liste 2 testes para ε",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software R ou Python para plotar resíduos",
                                    "Exemplo de dados reais"
                                  ],
                                  "tips": "Sempre cheque resíduos graficamente para validar o modelo",
                                  "learningObjective": "Interpretar ε como medida de incerteza e inadequação do modelo",
                                  "commonMistakes": [
                                    "Achar que ε zero significa modelo perfeito",
                                    "Ignorar violações das suposições de ε"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (Y) vs. anos de experiência (X), para um funcionário com 5 anos de experiência, Y observado = R$50.000, Ŷ predito = R$45.000, então ε = +R$5.000 (salário acima do predito devido a fatores não capturados como habilidades extras).",
                              "finalVerifications": [
                                "Pode escrever e explicar a equação Y = β₀ + β₁X + ε",
                                "Calcula corretamente ε para dados fornecidos",
                                "Descreve ε como diferença observada-predita",
                                "Identifica variações não explicadas pelo modelo",
                                "Explica suposições básicas sobre ε (média zero, independência)",
                                "Interpreta um gráfico de resíduos envolvendo ε"
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição matemática de ε (Y - Ŷ)",
                                "Correta interpretação como erro aleatório não sistemático",
                                "Uso apropriado de exemplos numéricos e gráficos",
                                "Compreensão das suposições do modelo linear sobre ε",
                                "Capacidade de diagnosticar problemas via análise de ε",
                                "Clareza na explicação verbal e escrita"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuição de resíduos e testes de normalidade",
                                "Programação: Cálculo de resíduos em Python (statsmodels) ou R",
                                "Probabilidade: Variáveis aleatórias e variância de ε",
                                "Análise de Dados: Diagnóstico de modelos via resíduos",
                                "Física: Modelos com ruído experimental semelhantes a ε"
                              ],
                              "realWorldApplication": "No setor financeiro, ε modela incertezas em previsões de preços de ações não explicadas por variáveis como volume de negociação, auxiliando em gestão de riscos e portfólios de investimento."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.2.2",
                        "name": "Modelo de Regressão Linear Múltipla",
                        "description": "Representação matemática da relação linear entre uma variável dependente Y e múltiplas variáveis independentes X₁, X₂, ..., Xₖ, dada por Y = β₀ + β₁X₁ + ... + βₖXₖ + ε, aplicada em cenários multivariados de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.2.2.1",
                            "name": "Formular a equação do modelo múltiplo",
                            "description": "Escrever a forma matricial ou escalar do modelo Y = β₀ + Σ βⱼXⱼ + ε para k variáveis independentes, usando notação vetorial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar componentes do modelo de regressão linear simples e estender para múltiplo",
                                  "subSteps": [
                                    "Relembre a equação do modelo simples: Y = β₀ + β₁X₁ + ε",
                                    "Identifique os elementos: variável dependente Y, intercepto β₀, coeficientes βⱼ, variáveis independentes Xⱼ e erro ε",
                                    "Entenda a extensão para k variáveis: adicione termos Σ βⱼXⱼ para j=1 a k",
                                    "Defina suposições básicas: independência dos erros, homocedasticidade e normalidade",
                                    "Anote os símbolos: Y (n x 1), Xⱼ (vetores de observações)"
                                  ],
                                  "verification": "Liste corretamente os componentes e a extensão para múltiplas variáveis em um papel ou documento",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Folha de papel ou editor de texto",
                                    "Livro ou notas de regressão linear simples"
                                  ],
                                  "tips": [
                                    "Comece pelo modelo simples para construir confiança",
                                    "Use subscritos para diferenciar variáveis"
                                  ],
                                  "learningObjective": "Compreender a estrutura básica e a generalização do modelo múltiplo",
                                  "commonMistakes": [
                                    "Confundir Y com variável independente",
                                    "Esquecer o termo de erro ε"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a equação na forma escalar",
                                  "subSteps": [
                                    "Escreva a equação geral: Y_i = β₀ + Σ_{j=1}^k βⱼ X_{i j} + ε_i para i=1 a n",
                                    "Especifique para uma observação i: inclua o índice i em cada termo",
                                    "Expanda para k=2 como exemplo: Y_i = β₀ + β₁ X_{i1} + β₂ X_{i2} + ε_i",
                                    "Verifique a notação: use Σ para soma geral e subscritos consistentes",
                                    "Pratique reescrevendo para k=3 variáveis independentes"
                                  ],
                                  "verification": "Escreva a equação escalar correta para k variáveis e confira com referência padrão",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Caderno de exercícios",
                                    "Referência de livro de econometria ou estatística"
                                  ],
                                  "tips": [
                                    "Sempre inclua o índice i para observações",
                                    "Leia em voz alta para fixar a notação"
                                  ],
                                  "learningObjective": "Dominar a representação escalar do modelo múltiplo",
                                  "commonMistakes": [
                                    "Omitir o índice i nos termos",
                                    "Confundir soma Σ com produto"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Converter para forma matricial ou vetorial",
                                  "subSteps": [
                                    "Defina vetores: Y (n x 1), ε (n x 1), β ( (k+1) x 1 ) com β₀ no topo",
                                    "Construa a matriz X (n x (k+1)): primeira coluna de 1's, seguida de colunas Xⱼ",
                                    "Escreva Y = X β + ε",
                                    "Expanda para k=2: X tem colunas [1, X1, X2]",
                                    "Confirme dimensões: n linhas em X, (k+1) colunas"
                                  ],
                                  "verification": "Desenhe a matriz X para um exemplo com n=5, k=2 e verifique multiplicação Xβ resulta em vetor n x 1",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software como MATLAB, R ou Python (opcional para simulação)",
                                    "Papel quadriculado para matrizes"
                                  ],
                                  "tips": [
                                    "Lembre: coluna de 1's é crucial para β₀",
                                    "Verifique dimensões antes de prosseguir"
                                  ],
                                  "learningObjective": "Representar o modelo de forma compacta matricial",
                                  "commonMistakes": [
                                    "Esquecer coluna de 1's em X",
                                    "Erro nas dimensões da matriz β"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar e validar a formulação",
                                  "subSteps": [
                                    "Interprete: E(Y|X) = X β (valor esperado condicional)",
                                    "Discuta propriedades: βⱼ mede mudança em Y por unidade em Xⱼ, ceteris paribus",
                                    "Compare escalar vs. matricial: ambas equivalentes",
                                    "Teste com dados fictícios: crie Y, X e verifique se encaixa",
                                    "Anote diferenças entre modelo populacional e amostral (usar y, x minúsculo para amostra)"
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a equivalência entre formas e interprete um coeficiente",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Exemplo de dataset pequeno (planilha Excel)",
                                    "Calculadora para verificações numéricas"
                                  ],
                                  "tips": [
                                    "Pense em termos de expectativa condicional",
                                    "Use exemplos reais para motivação"
                                  ],
                                  "learningObjective": "Interpretar corretamente o modelo formulado",
                                  "commonMistakes": [
                                    "Confundir modelo populacional com amostral",
                                    "Ignorar 'ceteris paribus' na interpretação"
                                  ]
                                }
                              ],
                              "practicalExample": "Para prever salário (Y) baseado em anos de experiência (X1) e educação (X2): Y_i = β₀ + β₁ X_{i1} + β₂ X_{i2} + ε_i. Em matricial: Y = [1 | X1 | X2] β + ε, onde β = [β₀, β₁, β₂]^T.",
                              "finalVerifications": [
                                "Equação escalar inclui Σ βⱼ Xⱼ e ε corretamente?",
                                "Matriz X tem coluna de 1's e dimensões n x (k+1)?",
                                "Notação vetorial Y = X β + ε é precisa?",
                                "Interpretação de βⱼ está correta (ceteris paribus)?",
                                "Diferença entre forma escalar e matricial é clara?",
                                "Suposições básicas do modelo são mencionadas?"
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação escalar e matricial (100%)",
                                "Correção das dimensões de vetores e matrizes",
                                "Capacidade de expandir para qualquer k",
                                "Interpretação adequada dos coeficientes",
                                "Identificação de erros comuns evitados",
                                "Clareza na explicação escrita ou verbal"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuição dos erros ε ~ N(0, σ²)",
                                "Programação: Implementação em R (lm()) ou Python (statsmodels)",
                                "Economia: Modelos de demanda com múltiplos fatores",
                                "Matemática: Álgebra linear para multiplicação matricial",
                                "Ciência de Dados: Pré-processamento de features em ML"
                              ],
                              "realWorldApplication": "Em finanças, formular salário = β₀ + β₁*experiência + β₂*educação + β₃*localização + ε para prever remunerações em recrutamento; em matricial para estimação via mínimos quadrados em software."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.2.2",
                            "name": "Interpretar coeficientes parciais βⱼ",
                            "description": "Analisar βⱼ como o efeito marginal de Xⱼ sobre Y, mantendo outras variáveis constantes, em contextos como previsão de desempenho de sistemas de controle baseados em múltiplos fatores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o modelo de regressão linear múltipla",
                                  "subSteps": [
                                    "Revise a equação geral do modelo: Y = β₀ + β₁X₁ + β₂X₂ + ... + βⱼXⱼ + ... + ε",
                                    "Identifique as variáveis independentes Xⱼ e a dependente Y no contexto de sistemas de controle",
                                    "Explique o papel de 'outras variáveis constantes' (ceteris paribus)",
                                    "Discuta a suposição de linearidade e independência entre preditores",
                                    "Calcule manualmente βⱼ em um modelo bivariado simples para transição"
                                  ],
                                  "verification": "Resuma o modelo em uma frase e liste as variáveis de um exemplo dado",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Folha de papel ou editor de texto",
                                    "Exemplo de dataset simples em CSV (ex: temperatura, pressão, desempenho)"
                                  ],
                                  "tips": "Use diagramas para visualizar o plano de hiperplano da regressão múltipla",
                                  "learningObjective": "Entender a estrutura do modelo onde βⱼ surge",
                                  "commonMistakes": [
                                    "Confundir com regressão simples",
                                    "Ignorar o termo de erro ε",
                                    "Esquecer a constante β₀"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir o coeficiente parcial βⱼ matematicamente",
                                  "subSteps": [
                                    "Derive βⱼ como ∂Y/∂Xⱼ | Xₖ≠ⱼ constante",
                                    "Interprete como a inclinação parcial da superfície de regressão",
                                    "Compare com β em regressão simples: por que muda com múltiplas variáveis?",
                                    "Use a fórmula de estimação OLS: βⱼ = Cov(Xⱼ, Y | outras X) / Var(Xⱼ | outras X)",
                                    "Calcule βⱼ ajustado removendo efeitos de outras variáveis via resíduos"
                                  ],
                                  "verification": "Escreva a derivada parcial e explique com um gráfico 3D (Y vs X1 vs X2)",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Calculadora ou Python/R com bibliotecas statsmodels/sklearn",
                                    "Gráfico 3D gerado por software"
                                  ],
                                  "tips": "Pense em βⱼ como 'efeito isolado' após controlar confounders",
                                  "learningObjective": "Dominar a definição formal de βⱼ como efeito marginal",
                                  "commonMistakes": [
                                    "Interpretar como causalidade sem evidência",
                                    "Confundir com correlação total",
                                    "Ignorar multicolinearidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar βⱼ em termos práticos e unidades",
                                  "subSteps": [
                                    "Traduza βⱼ para: 'uma unidade extra em Xⱼ muda Y em βⱼ unidades, ceteris paribus'",
                                    "Considere escalas: padronize variáveis se necessário (β em desvios padrão)",
                                    "Avalie sinal (positivo/negativo), magnitude e significância (p-value)",
                                    "Discuta limitações: linearidade, homocedasticidade, não causalidade automática",
                                    "Pratique reescrevendo βⱼ em linguagem não técnica para stakeholders"
                                  ],
                                  "verification": "Interprete um βⱼ dado: ex. β_temp = 0.5 → 'a cada °C, eficiência +0.5%, voltagem fixa'",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tabela de coeficientes de um modelo OLS",
                                    "Dicionário de unidades das variáveis"
                                  ],
                                  "tips": "Sempre mencione 'mantendo outras constantes' para evitar confusão",
                                  "learningObjective": "Converter matemática em interpretação acionável",
                                  "commonMistakes": [
                                    "Ignorar unidades (ex: β=2 pode ser trivial ou enorme)",
                                    "Sobre-generalizar sem contexto",
                                    "Confundir com efeito total"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar interpretação em contexto de sistemas de controle",
                                  "subSteps": [
                                    "Selecione dataset: Y=desempenho motor, X1=temperatura, X2=pressão, X3=voltagem",
                                    "Estime modelo e extraia βⱼ para X1",
                                    "Interprete: impacto isolado da temperatura na previsão de desempenho",
                                    "Simule cenários: prediga Y com ΔXⱼ=1, outras fixas",
                                    "Valide com gráficos de efeitos parciais (partial dependence plots)"
                                  ],
                                  "verification": "Gere relatório de 1 parágrafo interpretando todos βⱼ do modelo",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Python com pandas, statsmodels ou scikit-learn",
                                    "Dataset sintético ou real de sistemas de controle"
                                  ],
                                  "tips": "Use predict() para ilustrar efeitos marginais numericamente",
                                  "learningObjective": "Integrar interpretação em problemas reais de previsão",
                                  "commonMistakes": [
                                    "Não checar diagnósticos do modelo (R², VIF)",
                                    "Interpretar β insignificante como zero",
                                    "Esquecer interações possíveis"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de um drone, Y é a precisão de voo (em %), X₁ é vento (m/s), X₂ é bateria (%), X₃ é peso carga (kg). β₁ = 0.8 significa: a cada m/s extra de vento, precisão cai 0.8%, mantendo bateria e peso constantes. Útil para calibrar controladores PID preditivos.",
                              "finalVerifications": [
                                "Explique βⱼ sem fórmulas matemáticas em 1 minuto",
                                "Dado um modelo, interprete corretamente 3 βⱼ em contexto",
                                "Identifique quando βⱼ NÃO é causal",
                                "Gere predição correta alterando apenas uma Xⱼ",
                                "Discuta limitações em um parágrafo",
                                "Compare βⱼ com regressão univariada no mesmo dataset"
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de efeito marginal (ceteris paribus)",
                                "Correta tradução de unidades e magnitude para contexto real",
                                "Reconhecimento de suposições OLS violadas",
                                "Uso de linguagem clara e não técnica",
                                "Aplicação correta em exemplo prático com predições",
                                "Identificação de multicolinearidade ou insignificância"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses para βⱼ",
                                "Engenharia de Controle: Otimização de sistemas multivariados",
                                "Economia: Modelos econométricos de demanda multifatorial",
                                "Ciência de Dados: Feature importance em ML regressão",
                                "Física: Modelagem de sistemas dinâmicos com variáveis ambientais"
                              ],
                              "realWorldApplication": "Na indústria 4.0, interpretar βⱼ em regressões de sensores IoT permite prever falhas em linhas de produção, ajustando apenas um fator (ex: vibração) enquanto monitora outros, otimizando manutenção preditiva e reduzindo downtime em 20-30%."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.2.3",
                            "name": "Aplicar o modelo em dados de engenharia",
                            "description": "Construir um modelo múltiplo para dados reais, como regressão de eficiência energética em função de temperatura, potência e carga em sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Aquisição e Preparação de Dados de Engenharia",
                                  "subSteps": [
                                    "Identifique e baixe um conjunto de dados reais de eficiência energética, como do repositório UCI ou Kaggle, contendo variáveis temperatura, potência e carga.",
                                    "Carregue os dados em Python usando pandas (pd.read_csv()).",
                                    "Limpe os dados: remova valores ausentes com dropna(), trate outliers usando IQR method.",
                                    "Divida as variáveis: defina eficiência energética como y (target) e temperatura, potência, carga como X (features).",
                                    "Padronize as features usando StandardScaler do sklearn para normalização."
                                  ],
                                  "verification": "Dataset limpo carregado sem erros, shape verificado com df.shape e df.info(), sem NaNs (df.isnull().sum() == 0).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (pandas, numpy), Jupyter Notebook, dataset de eficiência energética (ex: Energy efficiency dataset UCI).",
                                  "tips": "Sempre visualize os dados iniciais com df.head() e df.describe() para entender a estrutura.",
                                  "learningObjective": "Preparar dados reais de engenharia para modelagem, garantindo qualidade e adequação para regressão múltipla.",
                                  "commonMistakes": "Ignorar outliers ou não normalizar features, levando a modelos enviesados."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Análise Exploratória de Dados (EDA)",
                                  "subSteps": [
                                    "Crie gráficos de dispersão (scatter plots) entre y e cada feature usando seaborn.pairplot().",
                                    "Calcule correlações com df.corr() e visualize com heatmap seaborn.",
                                    "Verifique multicolinearidade com VIF (Variance Inflation Factor) usando statsmodels.",
                                    "Analise distribuições com histograms e boxplots para cada variável.",
                                    "Identifique padrões lineares e potenciais transformações (ex: log para não-linearidades)."
                                  ],
                                  "verification": "Relatório EDA gerado com gráficos salvos e insights anotados, VIF < 5 para todas features.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (seaborn, matplotlib, statsmodels), Jupyter Notebook.",
                                  "tips": "Use plt.figure(figsize=(10,8)) para gráficos legíveis e salve com plt.savefig().",
                                  "learningObjective": "Explorar dados para validar premissas de regressão linear múltipla (linearidade, independência).",
                                  "commonMistakes": "Não detectar multicolinearidade, causando coeficientes instáveis."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construção do Modelo de Regressão Linear Múltipla",
                                  "subSteps": [
                                    "Divida dados em treino/teste (80/20) com train_test_split do sklearn.",
                                    "Treine o modelo com LinearRegression() do sklearn: model.fit(X_train, y_train).",
                                    "Obtenha coeficientes e intercepto com model.coef_ e model.intercept_.",
                                    "Faça previsões em treino e teste: y_pred_train e y_pred_test.",
                                    "Calcule métricas iniciais: R² com r2_score."
                                  ],
                                  "verification": "Modelo treinado com R² > 0.6 no treino, coeficientes impressos sem erros numéricos (inf/nan).",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python (sklearn.linear_model, sklearn.model_selection, sklearn.metrics).",
                                  "tips": "Use random_state=42 para reprodutibilidade nas divisões de dados.",
                                  "learningObjective": "Implementar e ajustar um modelo de regressão múltipla em dados reais.",
                                  "commonMistakes": "Não dividir em treino/teste, levando a overfitting não detectado."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliação e Otimização do Modelo",
                                  "subSteps": [
                                    "Calcule métricas: MSE, RMSE, MAE com mean_squared_error, mean_absolute_error.",
                                    "Plote resíduos vs preditos e Q-Q plot para verificar homocedasticidade e normalidade.",
                                    "Ajuste hiperparâmetros se necessário (ex: Ridge para regularização).",
                                    "Compare com baseline (média de y) para validar melhoria.",
                                    "Salve o modelo com joblib.dump(model, 'modelo_engenharia.pkl')."
                                  ],
                                  "verification": "Gráficos de resíduos sem padrões, RMSE_test < RMSE_treino, modelo salvo e carregado com sucesso.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (sklearn.metrics, scipy.stats para Q-Q, joblib).",
                                  "tips": "Resíduos devem estar aleatórios; se não, considere transformações nos dados.",
                                  "learningObjective": "Avaliar robustez do modelo e otimizar para aplicação em engenharia.",
                                  "commonMistakes": "Interpretar alto R² sem checar resíduos, ignorando violações de premissas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretação e Aplicação do Modelo",
                                  "subSteps": [
                                    "Interprete coeficientes: impacto de cada feature na eficiência (ex: +1°C reduz eficiência em X%).",
                                    "Gere previsões para cenários novos (ex: temp=25, pot=100, carga=50).",
                                    "Crie relatório com summary do statsmodels para p-values e significância.",
                                    "Discuta limitações (ex: causalidade não provada).",
                                    "Planeje deployment (ex: em app de controle de sistemas)."
                                  ],
                                  "verification": "Relatório gerado com interpretações claras, previsões precisas validadas em hold-out set.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Python (statsmodels.api para OLS summary), Jupyter Notebook.",
                                  "tips": "Foquem em significância estatística (p-value < 0.05) para engenharia confiável.",
                                  "learningObjective": "Extrair insights acionáveis de um modelo múltiplo para decisões de engenharia.",
                                  "commonMistakes": "Confundir correlação com causalidade sem contexto de domínio."
                                }
                              ],
                              "practicalExample": "Usando dataset de eficiência energética de edifícios (UCI): modele eficiência (y) como função de temperatura superficial (x1), potência de aquecimento (x2) e carga térmica (x3). Treine o modelo, obtenha coeficientes (ex: beta1=-0.15 para temperatura), preveja eficiência para novos inputs e otimize sistemas de controle HVAC.",
                              "finalVerifications": [
                                "Modelo treinado com R² > 0.7 no conjunto de teste.",
                                "Resíduos normalmente distribuídos (Shapiro-Wilk p>0.05).",
                                "Nenhum VIF > 5, confirmando baixa multicolinearidade.",
                                "Previsões em novos dados dentro de ±10% do real.",
                                "Relatório de interpretação com coeficientes e p-values gerado.",
                                "Modelo salvo e recarregado com previsões idênticas."
                              ],
                              "assessmentCriteria": [
                                "Precisão do modelo (R² > 0.7, RMSE baixo).",
                                "Qualidade da EDA (gráficos claros, insights documentados).",
                                "Correta implementação de regressão múltipla (sklearn/statsmodels).",
                                "Verificação completa de premissas (resíduos, VIF).",
                                "Interpretação contextualizada para engenharia.",
                                "Código limpo, reprodutível e comentado."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Controle: Otimização de sistemas HVAC baseados em previsões.",
                                "Estatística: Testes de hipóteses e inferência em coeficientes.",
                                "Programação: Manipulação de dados com Python/pandas.",
                                "Física/Termodinâmica: Relações entre temperatura, potência e eficiência energética."
                              ],
                              "realWorldApplication": "Em sistemas de controle industrial, como edifícios inteligentes ou fábricas, o modelo prevê eficiência energética para otimizar consumo, reduzir custos e emissões de CO2, permitindo automação via PLCs ou IoT integrando previsões em tempo real."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.2.4",
                            "name": "Diferenciar modelos simples e múltiplos",
                            "description": "Comparar as representações matemáticas e implicações práticas entre regressão simples e múltipla, destacando controle de variáveis confusoras em análises econométricas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Regressão Linear Simples",
                                  "subSteps": [
                                    "Defina regressão linear simples como um modelo que relaciona uma variável dependente (Y) a uma única variável independente (X) via equação Y = β0 + β1X + ε.",
                                    "Explique os componentes: intercepto (β0), inclinação (β1) e termo de erro (ε).",
                                    "Discuta suposições básicas: linearidade, independência dos erros, homocedasticidade e normalidade.",
                                    "Implemente um exemplo simples em software para visualizar a reta de regressão.",
                                    "Interprete os coeficientes: β1 indica mudança em Y por unidade de X."
                                  ],
                                  "verification": "Crie e interprete um modelo simples com dados fictícios, confirmando que o gráfico mostra uma única linha de tendência.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (scikit-learn ou statsmodels), dataset simples (ex: anos de estudo vs. salário), Jupyter Notebook.",
                                  "tips": "Sempre plote os dados primeiro para verificar linearidade visual.",
                                  "learningObjective": "Dominar a estrutura e interpretação da regressão simples.",
                                  "commonMistakes": "Confundir correlação com causalidade; ignorar verificação de suposições."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a Regressão Linear Múltipla",
                                  "subSteps": [
                                    "Defina regressão múltipla como Y = β0 + β1X1 + β2X2 + ... + βkXk + ε, com múltiplas variáveis independentes.",
                                    "Descreva como os coeficientes β representam efeitos parciais, controlando outras variáveis.",
                                    "Liste suposições adicionais: ausência de multicolinearidade perfeita e variáveis relevantes.",
                                    "Ajuste um modelo múltiplo com software e examine a matriz de coeficientes.",
                                    "Calcule e interprete R² ajustado para avaliar ajuste global."
                                  ],
                                  "verification": "Ajuste um modelo múltiplo e explique como um coeficiente muda ao adicionar variáveis.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Mesmo que Step 1, mais dataset com múltiplas variáveis (ex: Boston Housing).",
                                  "tips": "Use VIF (Variance Inflation Factor) para checar multicolinearidade.",
                                  "learningObjective": "Entender como a múltipla controla variáveis e altera interpretações.",
                                  "commonMistakes": "Interpretar coeficientes como marginais sem considerar controles; omitir diagnósticos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Representações Matemáticas e Interpretações",
                                  "subSteps": [
                                    "Compare equações: simples (uma X) vs. múltipla (múltiplas Xs).",
                                    "Discuta como na simples, β1 é total; na múltipla, é parcial (ceteris paribus).",
                                    "Analise impacto em previsões: simples pode superestimar/subestimar sem controles.",
                                    "Crie tabelas lado a lado de coeficientes de modelos simples vs. múltiplos no mesmo dataset.",
                                    "Visualize com gráficos parciais ou superfícies 3D para múltipla."
                                  ],
                                  "verification": "Gere uma tabela comparativa de coeficientes e R² para um dataset comum.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Software de plotagem (matplotlib/seaborn), mesmo datasets.",
                                  "tips": "Mantenha datasets idênticos para comparações justas.",
                                  "learningObjective": "Identificar diferenças chave em representações e implicações.",
                                  "commonMistakes": "Ignorar mudança nos coeficientes ao adicionar variáveis; confundir significância estatística com econômica."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Implicações Práticas e Controle de Variáveis Confusoras",
                                  "subSteps": [
                                    "Explique variáveis confusoras: afetam Y e X, bias na simples.",
                                    "Demonstre com exemplo: regressão simples omite educação em modelo salário-experiência.",
                                    "Discuta quando usar cada: simples para exploração, múltipla para controle rigoroso.",
                                    "Avalie trade-offs: simples é interpretável, múltipla é precisa mas complexa.",
                                    "Aplique em contexto econométrico: políticas públicas controlando covariáveis."
                                  ],
                                  "verification": "Identifique uma confusora em um cenário real e mostre bias corrigido na múltipla.",
                                  "estimatedTime": "55 minutos",
                                  "materials": "Datasets econométricos (ex: wage data do Wooldridge), relatórios de output.",
                                  "tips": "Pense em causalidade: múltipla aproxima mas não garante.",
                                  "learningObjective": "Aplicar conceitos para análises econométricas robustas.",
                                  "commonMistakes": "Assumir que múltipla resolve endogeneidade; sobrecarregar modelo com variáveis irrelevantes."
                                }
                              ],
                              "practicalExample": "Em um dataset de salários: Regressão simples (salário ~ experiência) superestima efeito da experiência se educação for omitida (confusora). Na múltipla (salário ~ experiência + educação), o coeficiente de experiência cai para efeito parcial, controlando educação.",
                              "finalVerifications": [
                                "Explique verbalmente diferenças em equações e interpretações.",
                                "Ajuste ambos modelos em software e compare coeficientes/R².",
                                "Identifique uma variável confusora em um cenário dado.",
                                "Interprete saída de modelo múltiplo 'ceteris paribus'.",
                                "Crie gráfico comparativo de fits simples vs. múltiplo.",
                                "Discuta limitação da simples em análises causais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e equações de ambos modelos (80%+ acerto).",
                                "Correta identificação de efeitos parciais vs. totais.",
                                "Demonstração prática com software sem erros de código.",
                                "Análise qualitativa de confusoras e bias.",
                                "Clareza em comparações visuais/tabulares.",
                                "Compreensão de trade-offs práticos em econometria."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e diagnósticos de modelo.",
                                "Economia: Modelagem econométrica para políticas públicas.",
                                "Ciência de Dados: Machine Learning (regressão como baseline).",
                                "Matemática: Álgebra matricial subjacente aos Mínimos Quadrados.",
                                "Computação: Programação em Python/R para análise de dados."
                              ],
                              "realWorldApplication": "Em econometria, diferenciação é crucial para estudos de impacto de políticas (ex: efeito de treinamento no emprego, controlando idade e gênero), evitando conclusões enviesadas em relatórios governamentais ou pesquisas acadêmicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.2.3",
                        "name": "Notação Matricial do Modelo Linear",
                        "description": "Representação geral do modelo de regressão linear em forma matricial Y = Xβ + ε, unificando simples e múltipla para estimativa por mínimos quadrados ordinários.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.2.3.1",
                            "name": "Definir vetores e matrizes do modelo",
                            "description": "Identificar o vetor Y (n×1), matriz X (n×k+1), vetor β (k+1×1) e vetor ε (n×1) na notação Y = Xβ + ε.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a notação matricial geral do modelo Y = Xβ + ε",
                                  "subSteps": [
                                    "Revise o modelo de regressão linear simples: Y_i = β_0 + β_1 X_i + ε_i para i=1 a n.",
                                    "Estenda para forma matricial: Y (vetor coluna) = X (matriz) vezes β (vetor) + ε (vetor de erros).",
                                    "Identifique os símbolos principais: Y, X, β, ε e suas posições na equação.",
                                    "Anote as dimensões típicas: n observações, k preditores.",
                                    "Desenhe um diagrama esquemático da multiplicação matricial."
                                  ],
                                  "verification": "Escreva a equação Y = Xβ + ε e explique verbalmente o que cada termo representa.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Editor de texto ou quadro branco",
                                    "Referência: Livro de regressão linear (cap. matriz)"
                                  ],
                                  "tips": "Use cores diferentes para cada componente ao desenhar para facilitar a visualização.",
                                  "learningObjective": "Entender a estrutura fundamental da notação matricial no modelo de regressão linear.",
                                  "commonMistakes": [
                                    "Confundir Y com X",
                                    "Ignorar o termo de erro ε",
                                    "Esquecer o intercepto em X"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir e identificar o vetor de resposta Y (n×1)",
                                  "subSteps": [
                                    "Y é o vetor coluna das variáveis dependentes observadas (n linhas, 1 coluna).",
                                    "Exemplo: Em dados de altura vs peso, Y = pesos observados.",
                                    "Confirme dimensão: n×1, onde n é o número de observações.",
                                    "Escreva Y explicitamente como [y1, y2, ..., yn]^T.",
                                    "Diferencie Y dos preditores: Y é o que queremos prever."
                                  ],
                                  "verification": "Dado um dataset com 5 observações, extraia e rotule corretamente o vetor Y.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Dataset exemplo em CSV ou Excel (altura-peso)",
                                    "Calculadora ou Python/Jupyter para visualizar"
                                  ],
                                  "tips": "Sempre pense em Y como 'o que medir' ou 'o target'.",
                                  "learningObjective": "Identificar precisamente o vetor Y e sua dimensão no contexto do modelo.",
                                  "commonMistakes": [
                                    "Usar dimensão errada (ex: 1×n em vez de n×1)",
                                    "Incluir preditores em Y",
                                    "Confundir com vetor de erros"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir a matriz de design X (n×k+1) e vetor de parâmetros β (k+1×1)",
                                  "subSteps": [
                                    "X inclui coluna de 1's para intercepto (primeira coluna) e colunas de preditores (k colunas).",
                                    "Dimensão X: n linhas (observações) × (k+1) colunas (intercepto + k preditores).",
                                    "β é vetor coluna de coeficientes: [β0 (intercepto), β1, ..., βk]^T, dimensão (k+1)×1.",
                                    "Verifique multiplicação: Xβ resulta em vetor n×1 compatível com Y.",
                                    "Exemplo: Para 1 preditor, X tem 2 colunas: [1, x1; 1, x2; ...]."
                                  ],
                                  "verification": "Construa X e β para um modelo com 2 preditores e 10 observações, confirmando dimensões.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Dataset com múltiplos preditores",
                                    "Software como R, Python (numpy) ou papel para matriz manual"
                                  ],
                                  "tips": "Lembre: primeira coluna de X é sempre 1's para o intercepto β0.",
                                  "learningObjective": "Construir e dimensionar corretamente X e β para qualquer número de preditores.",
                                  "commonMistakes": [
                                    "Esquecer a coluna de 1's em X",
                                    "Invertir dimensões de β (1×k+1)",
                                    "Confundir X com Y"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Definir o vetor de erros ε (n×1) e verificar consistência dimensional",
                                  "subSteps": [
                                    "ε é vetor coluna de erros/resíduos independentes: [ε1, ε2, ..., εn]^T, dimensão n×1.",
                                    "Na equação, Xβ + ε = Y, então ε = Y - Xβ.",
                                    "Confirme: Todos os termos (Y, Xβ, ε) têm dimensão n×1.",
                                    "Discuta suposições: ε ~ N(0, σ²I), mas foque na definição agora.",
                                    "Teste consistência: Multiplique dimensões (n×(k+1)) × ((k+1)×1) = n×1."
                                  ],
                                  "verification": "Para um exemplo dado, compute dimensões e confirme que Y = Xβ + ε faz sentido dimensionalmente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Exemplo numérico impresso",
                                    "Calculadora matricial ou Python (numpy.dot)"
                                  ],
                                  "tips": "Use a regra de multiplicação de matrizes para validar sempre.",
                                  "learningObjective": "Compreender o papel de ε e garantir compatibilidade dimensional em todo o modelo.",
                                  "commonMistakes": [
                                    "Atribuir dimensão errada a ε",
                                    "Pensar ε como escalar",
                                    "Ignorar que ε explica variação não capturada"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar a notação completa em um dataset exemplo",
                                  "subSteps": [
                                    "Carregue um dataset simples (ex: 5 observações, 1 preditor).",
                                    "Extraia Y, construa X (com 1's), defina β (hipotético), ε.",
                                    "Escreva a equação matricial explícita.",
                                    "Visualize matrizes em formato tabular.",
                                    "Simule ajuste: Compute Xβ e compare com Y."
                                  ],
                                  "verification": "Produza um relatório curto com Y, X, β, ε identificados corretamente para o dataset.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dataset exemplo (CSV: casas - preço vs tamanho)",
                                    "Python/R ou Excel para manipulação"
                                  ],
                                  "tips": "Comece com poucos dados para evitar confusão; escale depois.",
                                  "learningObjective": "Integrar todos os componentes em uma aplicação prática do modelo.",
                                  "commonMistakes": [
                                    "Erro na transposição de vetores",
                                    "Colunas erradas em X",
                                    "Dimensões incompatíveis na soma"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dataset de 4 casas: Preço (Y): [100, 150, 200, 250]^T (n=4). Tamanho (preditor único, k=1): [1, 1.5, 2, 2.5]. Então X = [[1,1], [1,1.5], [1,2], [1,2.5]] (4×2), β = [β0, β1]^T (2×1), ε = [ε1,ε2,ε3,ε4]^T (4×1). Equação: Y = Xβ + ε.",
                              "finalVerifications": [
                                "Identifica corretamente Y como vetor n×1 de respostas.",
                                "Constrói X com coluna de 1's e preditores, dimensão n×(k+1).",
                                "Define β como (k+1)×1 com intercepto primeiro.",
                                "Explica ε como n×1 de erros aleatórios.",
                                "Verifica consistência: Xβ resulta em n×1 compatível com Y e ε.",
                                "Aplica em exemplo sem erros dimensionais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e dimensões de cada componente (90% correto).",
                                "Capacidade de construir X corretamente, incluindo intercepto.",
                                "Compreensão verbal da equação Y = Xβ + ε.",
                                "Identificação correta em datasets reais.",
                                "Verificação dimensional sem inconsistências.",
                                "Integração fluida em exemplo prático."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Suposições do modelo linear e resíduos.",
                                "Programação: Implementação em NumPy/Pandas (matrizes em Python/R).",
                                "Machine Learning: Base para regressão linear em scikit-learn.",
                                "Álgebra Linear: Multiplicação de matrizes e vetores.",
                                "Ciência de Dados: Preparação de features (X) em pipelines."
                              ],
                              "realWorldApplication": "Em análise de dados para previsão de vendas (Y= vendedores, X=publicidade+preço), modelagem econômica (Y=PIB, X=investimentos), ou epidemiologia (Y=casos COVID, X=idade+vacinação), onde a notação matricial permite computação eficiente de estimativas β via mínimos quadrados."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.3.2",
                            "name": "Converter equação escalar para matricial",
                            "description": "Transformar a equação escalar de regressão em sua equivalente matricial, preparando para métodos de estimação em software como R.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar e compreender a equação escalar de regressão linear",
                                  "subSteps": [
                                    "Identifique a forma geral da equação escalar: y_i = β_0 + β_1 x_{i1} + ... + β_p x_{ip} + ε_i para i = 1 a n.",
                                    "Anote os componentes: variável dependente y_i, preditoras x_{ij}, coeficientes β_j e erro ε_i.",
                                    "Determine o número de observações n e o número de preditoras p (incluindo intercepto).",
                                    "Escreva um exemplo simples com p=2 para visualização.",
                                    "Verifique se a equação está no formato padrão de regressão linear simples ou múltipla."
                                  ],
                                  "verification": "Confirme que todos os componentes da equação escalar estão corretamente identificados e anotados em um papel ou editor.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta ou editor de texto",
                                    "Exemplo de dados de regressão (planilha ou código R)"
                                  ],
                                  "tips": "Comece com um modelo simples (uma preditora) antes de múltiplas para evitar confusão.",
                                  "learningObjective": "Compreender os elementos individuais da equação escalar como base para a transição matricial.",
                                  "commonMistakes": [
                                    "Confundir índices i (observações) e j (preditoras)",
                                    "Esquecer o termo de erro ε_i"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir os vetores e matrizes equivalentes",
                                  "subSteps": [
                                    "Construa o vetor Y: coluna com todos os y_i (dimensão n x 1).",
                                    "Crie o vetor β: coluna com β_0, β_1, ..., β_p (dimensão (p+1) x 1).",
                                    "Forme a matriz X: n linhas (observações), (p+1) colunas (1 para intercepto, x_{i1}, ..., x_{ip}).",
                                    "Defina o vetor de erros ε: coluna com ε_i (dimensão n x 1).",
                                    "Esboce as dimensões de cada componente matricial."
                                  ],
                                  "verification": "Desenhe ou liste Y, X, β e ε com dimensões corretas e valores de exemplo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Editor de equações (LaTeX ou MathJax online)",
                                    "Planilha para simular dados (Excel/Google Sheets)"
                                  ],
                                  "tips": "Sempre inclua a coluna de 1's para o intercepto β_0 na matriz X.",
                                  "learningObjective": "Mapear cada termo escalar para sua representação vetorial ou matricial.",
                                  "commonMistakes": [
                                    "Esquecer a coluna de uns na matriz X",
                                    "Invertar dimensões (linhas vs colunas)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Escrever a equação matricial completa",
                                  "subSteps": [
                                    "Escreva Y = X β + ε, confirmando que é uma operação matricial válida.",
                                    "Verifique a multiplicação X β: resulta em vetor n x 1.",
                                    "Substitua valores de exemplo na equação matricial para validar.",
                                    "Compare com a equação escalar original para cada i.",
                                    "Anote a notação em formato LaTeX para clareza: \\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}."
                                  ],
                                  "verification": "A equação matricial reproduz a escalar para pelo menos 2 observações de exemplo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramenta LaTeX (Overleaf ou R Markdown)",
                                    "Código R simples para gerar X e Y"
                                  ],
                                  "tips": "Use negrito ou setas para vetores e maiúscula para matrizes na notação.",
                                  "learningObjective": "Construir e validar a forma matricial equivalente à escalar.",
                                  "commonMistakes": [
                                    "Escrever Y = β X em vez de Y = X β",
                                    "Ignorar dimensões na multiplicação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e preparar para estimação em software",
                                  "subSteps": [
                                    "Confirme dimensões: X (n x (p+1)), compatíveis com β ((p+1) x 1).",
                                    "Gere um conjunto de dados de exemplo e construa X manualmente.",
                                    "Teste em R: use matrix() ou model.matrix() para verificar.",
                                    "Discuta como isso leva a β_hat = (X'X)^(-1) X'Y.",
                                    "Documente o processo em um relatório curto."
                                  ],
                                  "verification": "Execute código R que constrói X e multiplica X β para recuperar y (sem erro).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Ambiente R ou RStudio",
                                    "Script R com dados simulados"
                                  ],
                                  "tips": "Use model.matrix() no R para automatizar X e comparar com manual.",
                                  "learningObjective": "Aplicar a conversão em contexto computacional para estimação OLS.",
                                  "commonMistakes": [
                                    "Não transpor corretamente em verificações",
                                    "Usar dados não centrados sem intercepto"
                                  ]
                                }
                              ],
                              "practicalExample": "Para y_i = 2 + 3 x_{i1} + ε_i com n=3, x1=[1,2,4]: Y=[y1,y2,y3]', X=[[1,1],[1,2],[1,4]], β=[2,3]', então Y = X β + ε reproduz a equação escalar.",
                              "finalVerifications": [
                                "Dimensões de X, Y, β e ε estão corretas (n x (p+1), n x 1, (p+1) x 1, n x 1).",
                                "Multiplicação X β resulta em vetor compatível com Y.",
                                "Equação matricial equivale à escalar para todas observações de exemplo.",
                                "Código R constrói X corretamente e valida Y ≈ X β.",
                                "Notação LaTeX está precisa e legível.",
                                "Intercepto β_0 é incluído como primeira coluna de 1's em X."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de componentes escalar para matricial (100%).",
                                "Correção das dimensões e operações matriciais.",
                                "Validação prática com exemplo numérico.",
                                "Clareza na notação e documentação.",
                                "Preparação correta para estimação em R (model.matrix).",
                                "Ausência de erros comuns como transposições erradas."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Construção de matrizes em R ou Python (NumPy).",
                                "Estatística: Base para Mínimos Quadrados Ordinários (OLS).",
                                "Álgebra Linear: Multiplicação matricial e propriedades de vetores.",
                                "Ciência de Dados: Preparação de dados para lm() no R."
                              ],
                              "realWorldApplication": "Em análise de dados reais, como prever preços de casas (Boston Housing dataset), converter para matricial permite usar funções como lm() no R para estimação eficiente de coeficientes em grandes datasets."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.2.3.3",
                            "name": "Interpretar propriedades da matriz X",
                            "description": "Explicar a inclusão da coluna de 1's para o intercepto e implicações para estimação em grandes amostras de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Notação Matricial do Modelo de Regressão Linear",
                                  "subSteps": [
                                    "Defina o modelo linear matricial: Y = Xβ + ε, onde Y é o vetor de respostas, X é a matriz de design, β são os coeficientes e ε é o erro.",
                                    "Identifique as dimensões: X é n x (p+1), com n observações e p preditores mais intercepto.",
                                    "Construa um exemplo simples de X com dados fictícios de engenharia (ex: tensão vs. temperatura e carga).",
                                    "Verifique a estrutura usando software como Python (NumPy) ou MATLAB.",
                                    "Explique o papel geral de X na estimação OLS: β_hat = (X^T X)^(-1) X^T Y."
                                  ],
                                  "verification": "Construa uma matriz X 5x3 manualmente e confirme dimensões e estrutura via print em código.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notebook Jupyter com NumPy, papel e caneta para esboços manuais.",
                                  "tips": "Sempre comece com dimensões para evitar confusões em cálculos matriciais.",
                                  "learningObjective": "Compreender a estrutura fundamental da matriz X no modelo linear.",
                                  "commonMistakes": "Confundir linhas (observações) com colunas (preditores); ignorar dimensões."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explicar a Inclusão da Coluna de 1's para o Intercepto",
                                  "subSteps": [
                                    "Adicione uma coluna inicial de 1's a X para representar o intercepto β0.",
                                    "Compare modelos com e sem intercepto: demonstre geometricamente como o intercepto permite interceptar o eixo Y.",
                                    "Calcule β_hat com e sem coluna de 1's em um dataset pequeno de engenharia (ex: regressão de resistência de materiais).",
                                    "Discuta quando omitir o intercepto (raro, só se teoricamente justificado).",
                                    "Verifique multicolinearidade perfeita se todas linhas forem idênticas sem 1's."
                                  ],
                                  "verification": "Gere X com e sem coluna de 1's; confirme que (X^T X) é invertível apenas com 1's via det() != 0.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (NumPy, SciPy para det()), dataset CSV simples de engenharia.",
                                  "tips": "Visualize X como uma tabela: primeira coluna sempre 1's para flexibilidade do modelo.",
                                  "learningObjective": "Justificar matematicamente a necessidade da coluna de 1's.",
                                  "commonMistakes": "Esquecer que sem 1's, β0 é forçado a 0, distorcendo predições."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Propriedades Chave da Matriz X",
                                  "subSteps": [
                                    "Verifique full column rank: rank(X) = p+1 para estimação única.",
                                    "Calcule número de condição cond(X) = σ_max / σ_min; valores >30 indicam problemas.",
                                    "Identifique multicolinearidade: correlações altas entre colunas.",
                                    "Em grandes amostras (n >> p), discuta assintótica: X^T X / n converge para matriz de covariância populacional.",
                                    "Simule X com n=1000 em dados de engenharia para observar estabilidade."
                                  ],
                                  "verification": "Compute rank(X), cond(X) e VIF para preditores; confirme rank == p+1.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (NumPy, SciPy.linalg, statsmodels para VIF), dataset grande (>1000 rows).",
                                  "tips": "Use SVD para decompor X e inspecionar singular values.",
                                  "learningObjective": "Interpretar propriedades como rank e condicionalidade de X.",
                                  "commonMistakes": "Ignorar que n grande mitiga multicolinearidade moderada, mas não severa."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Implicações para Estimação em Grandes Amostras de Dados de Engenharia",
                                  "subSteps": [
                                    "Discuta variância de β_hat: Var(β_hat) = σ² (X^T X)^(-1); n grande reduz variância.",
                                    "Simule estimação OLS em dataset engenharia real (ex: sensores IoT com 10k+ pontos).",
                                    "Analise impactos: precisão em predições, confiança em intervalos.",
                                    "Compare com small n: demonstre instabilidade via bootstrap.",
                                    "Conclua com melhores práticas: center/scale preditores para melhorar cond(X)."
                                  ],
                                  "verification": "Estime β_hat em n=100 vs n=10000; compare std errors e R².",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dataset real de engenharia (Kaggle: structural engineering data), Python (statsmodels).",
                                  "tips": "Sempre padronize X para interpretação em grandes datasets.",
                                  "learningObjective": "Ligar propriedades de X à performance de estimação em big data engenharia.",
                                  "commonMistakes": "Subestimar que n grande não resolve multicolinearidade perfeita."
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia estrutural, use dados de sensores (n=5000): Y=tensão medida, X1=temperatura, X2=carga aplicada. Inclua coluna de 1's em X para estimar intercepto (tensão basal). Compute cond(X)=15 (aceitável), rank=3; em OLS, variância baixa permite predições confiáveis para design de pontes.",
                              "finalVerifications": [
                                "Construir e analisar X completa com coluna de 1's em dataset engenharia.",
                                "Confirmar rank(X) = número de colunas e cond(X) < 100.",
                                "Explicar verbalmente por que 1's são essenciais e impactos em n grande.",
                                "Simular OLS e interpretar variância de β_hat.",
                                "Identificar e mitigar uma multicolinearidade simulada."
                              ],
                              "assessmentCriteria": [
                                "Precisão na justificativa da coluna de 1's (correta em 100%).",
                                "Correta interpretação de propriedades (rank, cond) com cálculos.",
                                "Análise qualitativa/quantitativa de implicações em big data.",
                                "Uso apropriado de software para verificações.",
                                "Clareza em exemplos práticos de engenharia.",
                                "Identificação de erros comuns e soluções."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teoria assintótica de OLS e inferência.",
                                "Programação: Manipulação matricial em Python/R/MATLAB.",
                                "Engenharia: Modelagem preditiva em dados sensoriais/IoT.",
                                "Álgebra Linear: Decomposições SVD/QR para análise de X."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, interpretar X em regressão para prever fadiga de materiais de grandes datasets de testes (n=10k+), garantindo designs seguros via estimação estável de coeficientes, incluindo intercepto para condições basais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.3",
                    "name": "Pressupostos Básicos da Regressão Linear",
                    "description": "Condições como linearidade nos parâmetros, exogeneidade, homocedasticidade, não autocorrelação e normalidade dos erros.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.3.1",
                        "name": "Linearidade nos Parâmetros",
                        "description": "O modelo de regressão é especificado de forma linear nos coeficientes β, permitindo que a relação entre a variável dependente Y e as variáveis independentes X seja expressa como Y = Xβ + ε, fundamental para a aplicação dos Mínimos Quadrados Ordinários (MQO) em análises econométricas aplicadas à engenharia, como modelagem de sistemas dinâmicos.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.1.1",
                            "name": "Definir e identificar linearidade nos parâmetros",
                            "description": "Explicar o pressuposto de linearidade nos parâmetros β em um modelo de regressão linear simples e múltipla, distinguindo-o de linearidade nas variáveis, com exemplos em dados de engenharia como previsão de desempenho de materiais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir o conceito de linearidade nos parâmetros β",
                                  "subSteps": [
                                    "Revise a equação geral do modelo de regressão linear: Y = β₀ + β₁X₁ + ... + βₖXₖ + ε",
                                    "Explique que linearidade nos parâmetros significa que β são coeficientes constantes multiplicados linearmente pelas variáveis X",
                                    "Discuta que o modelo é linear em β, independentemente da forma funcional das X",
                                    "Forneça a definição formal: E(Y|X) = Xβ, onde β é um vetor de parâmetros fixos",
                                    "Esclareça que isso permite estimar β via mínimos quadrados ordinários (MQO)"
                                  ],
                                  "verification": "Escreva uma definição precisa em suas palavras e identifique a equação linear em β em um modelo dado",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Livro de regressão linear (ex: Wooldridge), notebook Jupyter com Python/R",
                                  "tips": "Sempre comece pela equação do modelo para ancorar a definição",
                                  "learningObjective": "Compreender a definição matemática de linearidade nos parâmetros β",
                                  "commonMistakes": "Confundir linearidade em β com linearidade nas variáveis X (ex: pensar que X deve ser linear)"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Distinguir linearidade nos parâmetros de linearidade nas variáveis",
                                  "subSteps": [
                                    "Defina linearidade nas variáveis: relação direta entre X e Y sem transformações",
                                    "Mostre exemplos não-lineares em X mas lineares em β: Y = β₀ + β₁ log(X) + ε ou Y = β₀ + β₁ X² + ε",
                                    "Explique que o modelo pode ser não-linear em X (polinomial, logarítmico) mas ainda linear em β",
                                    "Crie uma tabela comparativa: Linear em β (sempre requerido) vs. Linear em X (não requerido)",
                                    "Teste com um plot: ajuste um modelo polinomial e verifique se MQO funciona"
                                  ],
                                  "verification": "Crie dois exemplos: um linear em X e um não-linear em X, ambos lineares em β, e explique a diferença",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Software estatístico (Python com statsmodels ou R), dados sintéticos gerados",
                                  "tips": "Use gráficos de scatterplot com curvas fitted para visualizar não-linearidade em X",
                                  "learningObjective": "Diferenciar claramente os dois tipos de linearidade e reconhecer modelos válidos",
                                  "commonMistakes": "Assumir que regressão linear requer X linear; muitos modelos úteis são não-lineares em X"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar linearidade nos parâmetros em regressão simples",
                                  "subSteps": [
                                    "Considere um modelo simples: Y = β₀ + β₁X + ε",
                                    "Verifique se é linear em β: sim, pois β₀ e β₁ são multiplicados linearmente por 1 e X",
                                    "Gere dados simulados e ajuste via MQO: observe que funciona sem restrições em X",
                                    "Teste um modelo não-linear em β: Y = β₀ + β₁^X + ε (inválido para MQO linear)",
                                    "Analise resíduos para confirmar adequação inicial do pressuposto"
                                  ],
                                  "verification": "Ajuste um modelo simples em software e confirme que a matriz de design X tem posto completo para estimar β",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Python (numpy, statsmodels), R, conjunto de dados simples (ex: mtcars)",
                                  "tips": "Sempre cheque a matriz Xβ para ver a estrutura linear",
                                  "learningObjective": "Aplicar o conceito em regressão simples e validar via estimação",
                                  "commonMistakes": "Ignorar que transformações em X (como log) preservam linearidade em β"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar e aplicar em regressão múltipla com exemplo de engenharia",
                                  "subSteps": [
                                    "Use dados de engenharia: prever resistência de materiais (Y) baseada em temperatura (X1) e composição % (X2)",
                                    "Especifique modelo: Resistência = β₀ + β₁ Temp + β₂ Comp² + ε (linear em β, não em X2)",
                                    "Ajuste o modelo via MQO e interprete coeficientes β",
                                    "Verifique linearidade em β plotando predicted vs actual e analisando resíduos",
                                    "Discuta violações: modelos como β₀ e^(β₁X) são não-lineares em β e requerem métodos não-lineares"
                                  ],
                                  "verification": "Ajuste o modelo em dados reais/simulados e produza um relatório confirmando linearidade em β",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Dataset de materiais (ex: Kaggle engineering datasets), Python/R, Excel para dados iniciais",
                                  "tips": "Inclua termos polinomiais para simular cenários reais de engenharia",
                                  "learningObjective": "Identificar linearidade em contextos múltiplos e práticos de engenharia",
                                  "commonMistakes": "Confundir multicolinearidade com violação de linearidade em β"
                                }
                              ],
                              "practicalExample": "Em engenharia de materiais, prever a resistência à tração (Y) de uma liga metálica usando temperatura de tratamento (X1) e fração de carbono ao quadrado (X2²): Y = β₀ + β₁ X1 + β₂ X2² + ε. O modelo é linear em β, permitindo MQO mesmo com X2 não-linear.",
                              "finalVerifications": [
                                "Defina corretamente linearidade em β com equação",
                                "Distinga de linearidade em X com 2 exemplos",
                                "Ajuste um modelo simples e múltiplo via MQO sem erros",
                                "Identifique um modelo não-linear em β",
                                "Analise resíduos em exemplo de engenharia para confirmar",
                                "Explique por que MQO funciona apenas para linear em β"
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição matemática (80%+ correto)",
                                "Correta distinção entre linearidade em β vs X (com exemplos)",
                                "Sucesso na estimação de modelos via software",
                                "Interpretação adequada de coeficientes β",
                                "Análise de resíduos e plots para validação",
                                "Aplicação contextual em dados de engenharia"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: estimação via MQO e inferência",
                                "Programação: implementação em Python/R/statsmodels",
                                "Engenharia: modelagem preditiva de materiais",
                                "Matemática: álgebra linear (matriz Xβ)"
                              ],
                              "realWorldApplication": "Em engenharia, otimizar desempenho de materiais prevendo resistência baseada em parâmetros processuais, reduzindo testes caros e acelerando design de produtos como aviões ou pontes."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.1.2",
                            "name": "Reconhecer violações de linearidade",
                            "description": "Identificar formas comuns de não-linearidade, como relações quadráticas ou logarítmicas, e propor transformações adequadas (ex.: log-log) para restaurar a linearidade em contextos de análise de dados industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de linearidade nos parâmetros da regressão",
                                  "subSteps": [
                                    "Defina linearidade como a relação onde o modelo é uma combinação linear dos parâmetros, independentemente da forma funcional dos preditores.",
                                    "Diferencie linearidade nos parâmetros de linearidade na verdade (curva).",
                                    "Examine equações lineares (y = β0 + β1x) versus não-lineares nos parâmetros (y = β0 * β1^x).",
                                    "Analise exemplos gráficos de relações lineares e não-lineares.",
                                    "Discuta o impacto de violações na interpretação e precisão da regressão linear."
                                  ],
                                  "verification": "Explique em suas palavras a diferença entre linearidade nos parâmetros e na verdade, com um exemplo de cada.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Gráficos de scatter plots de exemplos lineares e não-lineares",
                                    "Notebook Jupyter com código Python para plotar y = x vs y = x^2"
                                  ],
                                  "tips": "Sempre foque nos parâmetros β; teste substituindo valores para ver se a equação permanece linear.",
                                  "learningObjective": "Entender o que constitui linearidade nos parâmetros e reconhecer quando ela é violada.",
                                  "commonMistakes": [
                                    "Confundir linearidade nos parâmetros com linearidade visual nos dados",
                                    "Ignorar que transformações nos preditores mantêm linearidade nos parâmetros"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar formas comuns de violações de linearidade",
                                  "subSteps": [
                                    "Liste violações comuns: quadráticas (y ~ x^2), logarítmicas (y ~ log(x)), exponenciais (y ~ e^x).",
                                    "Estude padrões gráficos para cada tipo: parábolas para quadráticas, curvas em S para logarítmicas.",
                                    "Use dados simulados para visualizar cada violação em scatter plots.",
                                    "Compare com relações lineares para destacar diferenças.",
                                    "Registre exemplos industriais, como yield de produção vs temperatura (quadrática)."
                                  ],
                                  "verification": "Classifique 5 scatter plots fornecidos como linear ou violação específica (quadrática, log, etc.).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Datasets simulados em CSV (quadrático, logarítmico, exponencial)",
                                    "Python com matplotlib e seaborn para plots"
                                  ],
                                  "tips": "Procure por curvatura sistemática nos plots; linearidade gera pontos aleatórios ao redor da linha.",
                                  "learningObjective": "Reconhecer visual e conceitualmente violações comuns de linearidade.",
                                  "commonMistakes": [
                                    "Atribuir curvatura leve a ruído em vez de violação",
                                    "Confundir heterocedasticidade com não-linearidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diagnosticar violações de linearidade em dados reais",
                                  "subSteps": [
                                    "Ajuste uma regressão linear simples aos dados industriais.",
                                    "Gere plots diagnósticos: scatter de preditor vs resposta, residuals vs fitted values.",
                                    "Identifique padrões nos residuals: U-shape indica quadrática, crescente indica log/exponencial.",
                                    "Calcule métricas como R^2 e teste visual para confirmação.",
                                    "Documente evidências de violação com screenshots de plots."
                                  ],
                                  "verification": "Produza um relatório com plots diagnósticos identificando pelo menos uma violação em um dataset dado.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Dataset industrial CSV (ex: temperatura vs yield em produção)",
                                    "Python: statsmodels ou scikit-learn para regressão e plots de residuals"
                                  ],
                                  "tips": "Amplie os eixos dos plots de residuals para detectar padrões sutis; use escala log se necessário.",
                                  "learningObjective": "Aplicar métodos diagnósticos para detectar violações em dados empíricos.",
                                  "commonMistakes": [
                                    "Interpretar residuals aleatórios como não-lineares",
                                    "Não plotar residuals vs fitted (só vs preditor)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Propor e aplicar transformações para restaurar linearidade",
                                  "subSteps": [
                                    "Para quadrática: sugira sqrt(y) ou y vs x^2; para logarítmica: log(y) vs log(x).",
                                    "Escolha transformação baseada no diagnóstico (ex: log-log para relações multiplicativas).",
                                    "Aplique a transformação nos dados e re-ajuste a regressão linear.",
                                    "Compare plots antes/depois e métricas (R^2 melhorado, residuals aleatórios).",
                                    "Valide com teste de Ramsey RESET para não-linearidade residual."
                                  ],
                                  "verification": "Transforme um dataset violado, re-ajuste e demonstre melhoria nos diagnósticos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Mesmo dataset do Step 3",
                                    "Python: numpy para transformações (np.log, np.sqrt), statsmodels para RESET test"
                                  ],
                                  "tips": "Comece com transformações simples; verifique multicolinearidade após polinômios.",
                                  "learningObjective": "Selecionar e implementar transformações adequadas para linearizar relações.",
                                  "commonMistakes": [
                                    "Aplicar transformação errada (ex: log em quadrática)",
                                    "Não re-verificar diagnósticos pós-transformação"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar e interpretar resultados pós-transformação",
                                  "subSteps": [
                                    "Reavalie plots de residuals e fitted values pós-transformação.",
                                    "Interprete coeficientes na escala transformada (ex: log-log implica elasticidade).",
                                    "Discuta limitações: transformações podem induzir heterocedasticidade.",
                                    "Compare modelos original vs transformado com AIC/BIC.",
                                    "Documente recomendação final para análise industrial."
                                  ],
                                  "verification": "Escreva um parágrafo resumindo se a linearidade foi restaurada e por quê.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código Python do Step 4 estendido com AIC/BIC",
                                    "Tabela comparativa de modelos"
                                  ],
                                  "tips": "Sempre back-transforme predições para a escala original ao interpretar.",
                                  "learningObjective": "Confirmar restauração de linearidade e interpretar implicações práticas.",
                                  "commonMistakes": [
                                    "Aceitar R^2 alto sem checar residuals",
                                    "Ignorar interpretações alteradas pelos logs"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de semicondutores, o yield (rendimento) vs temperatura de processo mostra curvatura quadrática em scatter plot. Detecte via residuals em U-shape, aplique transformação sqrt(yield) vs temperatura, re-ajuste OLS e confirme linearidade restaurada com residuals aleatórios, melhorando predições de processo otimizado.",
                              "finalVerifications": [
                                "Classifica corretamente 80% dos scatter plots como linear ou tipo de violação.",
                                "Gera plots diagnósticos identificando padrões não-lineares em residuals.",
                                "Propõe transformação correta para 3 cenários comuns (quadrática, log, exponencial).",
                                "Demonstra melhoria em R^2 e randomização de residuals pós-transformação.",
                                "Explica interpretação de coeficientes em modelos transformados.",
                                "Aplica teste RESET e interpreta resultados."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de violações (visual e diagnóstica): 30%.",
                                "Adequação das transformações propostas e justificadas: 25%.",
                                "Qualidade dos plots e análises comparativas: 20%.",
                                "Interpretação correta de resultados transformados: 15%.",
                                "Documentação clara e completa do processo: 10%."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Análise de residuals e testes de diagnóstico.",
                                "Programação: Uso de Python/R para modelagem e visualização de dados.",
                                "Engenharia Industrial: Otimização de processos via modelagem preditiva.",
                                "Física/Química: Modelos empíricos de relações não-lineares em experimentos."
                              ],
                              "realWorldApplication": "Na análise de dados industriais, como otimização de yields em manufatura química ou previsão de falhas em manutenção preditiva, reconhecer e corrigir não-linearidades garante modelos precisos para decisões de custo-efetividade, reduzindo desperdícios em milhões de dólares anuais."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.1.3",
                            "name": "Verificar linearidade graficamente",
                            "description": "Utilizar gráficos de resíduos vs. valores ajustados ou componentes parciais para diagnosticar não-linearidade em conjuntos de dados de engenharia, interpretando padrões como curvas ou funis.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o dataset e ajustar o modelo de regressão linear",
                                  "subSteps": [
                                    "Carregue o conjunto de dados de engenharia usando pandas (ex: dados de tensão vs. deformação em testes de materiais).",
                                    "Selecione a variável dependente (Y) e independentes (X) relevantes para o modelo linear.",
                                    "Ajuste o modelo de regressão linear usando statsmodels ou sklearn, obtendo os valores ajustados (fitted values).",
                                    "Salve o modelo ajustado para uso posterior.",
                                    "Verifique estatísticas básicas como R² para contexto inicial."
                                  ],
                                  "verification": "Modelo ajustado com coeficientes e R² exibidos; sem erros de convergência.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com pandas, statsmodels ou sklearn",
                                    "Dataset de exemplo (CSV com dados de engenharia)"
                                  ],
                                  "tips": "Padronize variáveis se houver escalas muito diferentes para melhor interpretação visual.",
                                  "learningObjective": "Compreender como preparar dados e ajustar um modelo linear básico para análise de resíduos.",
                                  "commonMistakes": [
                                    "Esquecer de tratar valores ausentes ou outliers antes do ajuste.",
                                    "Usar variáveis categóricas sem codificação.",
                                    "Não verificar multicolinearidade entre preditores."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular resíduos e valores ajustados",
                                  "subSteps": [
                                    "Extraia os resíduos do modelo (resíduos = Y observados - Y ajustados).",
                                    "Obtenha os valores ajustados (predicted Y) diretamente do modelo.",
                                    "Crie um DataFrame com colunas para resíduos e valores ajustados.",
                                    "Visualize distribuições iniciais com histogramas para resíduos.",
                                    "Padronize resíduos se necessário para análise gráfica."
                                  ],
                                  "verification": "DataFrame com resíduos e ajustados criado; média dos resíduos próxima de zero.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Jupyter Notebook ou script Python",
                                    "Bibliotecas: numpy, matplotlib"
                                  ],
                                  "tips": "Use residuals = model.residuais() em statsmodels para simplicidade.",
                                  "learningObjective": "Dominar o cálculo preciso de resíduos como base para diagnósticos gráficos.",
                                  "commonMistakes": [
                                    "Confundir resíduos padronizados com não-padronizados.",
                                    "Não verificar se resíduos são studentizados para interpretações avançadas.",
                                    "Ignorar resíduos studentizados para detecção de outliers."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir o gráfico de resíduos vs. valores ajustados",
                                  "subSteps": [
                                    "Crie um scatter plot com valores ajustados no eixo X e resíduos no eixo Y usando matplotlib ou seaborn.",
                                    "Adicione uma linha horizontal em y=0 para referência.",
                                    "Inclua rótulos de eixos, título e grade para clareza.",
                                    "Opcionalmente, adicione uma linha suavizada (lowess) para destacar tendências.",
                                    "Salve ou exiba o gráfico para análise."
                                  ],
                                  "verification": "Gráfico gerado sem padrões óbvios iniciais; eixos corretamente rotulados.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com matplotlib ou seaborn"
                                  ],
                                  "tips": "Use seaborn.residplot() para gráfico pronto com ajustes automáticos.",
                                  "learningObjective": "Criar visualizações diagnósticas padronizadas para resíduos.",
                                  "commonMistakes": [
                                    "Escala inadequada nos eixos, escondendo padrões.",
                                    "Não adicionar linha y=0, dificultando identificação de dispersão.",
                                    "Usar gráfico de linha em vez de scatter para dados não sequenciais."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar o gráfico e diagnosticar não-linearidade",
                                  "subSteps": [
                                    "Examine padrões: procure curvas, funis ou clusters sistemáticos nos resíduos.",
                                    "Identifique não-linearidade se resíduos mostrarem tendência parabólica ou sinusoidal vs. ajustados.",
                                    "Compare com gráfico ideal (resíduos aleatórios ao redor de zero).",
                                    "Documente observações: descreva padrões como 'funil crescente' ou 'curva em U'.",
                                    "Sugira correções: transformação de variáveis ou modelo não-linear."
                                  ],
                                  "verification": "Relatório escrito identificando padrões ou confirmando linearidade; sem ambiguidades.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráfico gerado do step anterior",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Rotacione mentalmente o gráfico: padrões em X indicam não-linearidade em relação ao preditor.",
                                  "learningObjective": "Interpretar visualmente violações de linearidade e propor soluções.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade (funil) com não-linearidade (curvas).",
                                    "Ignorar amostras pequenas onde padrões são menos confiáveis.",
                                    "Concluir linearidade prematuramente sem zoom ou rotação."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia mecânica com tensão (X) vs. deformação (Y) em testes de fadiga de aço, ajuste regressão linear. Plote resíduos vs. ajustados: um padrão em 'U' indica não-linearidade devido à fase plástica, sugerindo modelo polinomial ou log-transformação.",
                              "finalVerifications": [
                                "Resíduos exibem dispersão aleatória sem padrões curvos ou funis evidentes.",
                                "Nenhum resíduo outlier domina o gráfico (verificar com boxplot complementar).",
                                "Interpretação documentada matches critérios teóricos de linearidade.",
                                "Gráfico inclui todos elementos visuais padrão (linhas, labels).",
                                "Sugestões de modelagem alternativa justificadas se não-linearidade detectada.",
                                "Código reproduzível gera o mesmo diagnóstico."
                              ],
                              "assessmentCriteria": [
                                "Precisão no ajuste do modelo e cálculo de resíduos (sem erros numéricos).",
                                "Qualidade visual do gráfico (clareza, labels corretos).",
                                "Identificação correta de padrões não-lineares (curvas, funis).",
                                "Interpretação alinhada com teoria estatística de regressão.",
                                "Propostas de correção lógicas e acionáveis.",
                                "Eficiência temporal e código limpo."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Diagnósticos de regressão e testes formais (Ramsey RESET).",
                                "Programação: Manipulação de dados em Python/R e visualização com ggplot/seaborn.",
                                "Engenharia: Modelagem preditiva em processos industriais (ex: fadiga de materiais).",
                                "Matemática: Análise de funções e transformações não-lineares.",
                                "Ciência de Dados: Pipelines de ML para validação de premissas."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, verificar linearidade em regressões de carga vs. deformação em asas de aviões para evitar falhas estruturais; detecção precoce de não-linearidade previne erros em simulações de voo e otimiza designs."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.3.2",
                        "name": "Exogeneidade dos Regressores",
                        "description": "Os regressores X são exógenos, ou seja, a esperança condicional dos erros é zero: E(ε|X) = 0, garantindo que os estimadores MQO sejam insesgados e consistentes em aplicações econométricas para engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.2.1",
                            "name": "Definir exogeneidade estrita",
                            "description": "Descrever o pressuposto E(ε_i | X_i) = 0 e suas implicações para a ausência de viés nos estimadores β, com exemplos em regressões de eficiência de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Definição Formal de Exogeneidade Estrita",
                                  "subSteps": [
                                    "Revise a equação do modelo de regressão linear: Y_i = X_i β + ε_i.",
                                    "Defina exogeneidade estrita como E(ε_i | X_i) = 0, significando que o erro condicional esperado dado X_i é zero.",
                                    "Interprete isso como independência condicional entre erros e regressores.",
                                    "Compare com exogeneidade fraca E(ε_i) = 0.",
                                    "Anote a notação matemática em um caderno ou ferramenta digital."
                                  ],
                                  "verification": "Escreva a definição em suas próprias palavras e confirme que menciona a expectativa condicional.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Livro de econometria (ex: Wooldridge), Jupyter Notebook, caneta e papel.",
                                  "tips": "Use diagramas de Venn para visualizar a independência condicional.",
                                  "learningObjective": "Dominar a definição precisa de exogeneidade estrita e diferenciá-la de conceitos relacionados.",
                                  "commonMistakes": "Confundir com homocedasticidade ou assumir que implica correlação zero incondicional."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Implicações para a Ausência de Viés nos Estimadores β",
                                  "subSteps": [
                                    "Derive a expectativa do estimador MQO: E(β_hat) = β sob exogeneidade.",
                                    "Mostre matematicamente que sem exogeneidade, E(β_hat | X) ≠ β (viés).",
                                    "Discuta como isso garante consistência e unbiasedness em amostras grandes.",
                                    "Simule um modelo simples em Python/R para ilustrar o viés sem exogeneidade.",
                                    "Calcule e plote E(β_hat) em cenários com e sem o pressuposto."
                                  ],
                                  "verification": "Execute uma simulação e verifique se o viés é zero quando E(ε|X)=0.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python com statsmodels ou R, dados simulados (numpy/pandas).",
                                  "tips": "Use seed para reproducibilidade nas simulações.",
                                  "learningObjective": "Entender e provar como exogeneidade leva a estimadores não viesados.",
                                  "commonMistakes": "Ignorar a condição condicional e focar apenas em E(ε)=0."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar o Conceito em Regressões de Eficiência de Processos Industriais",
                                  "subSteps": [
                                    "Defina um exemplo: Regredir eficiência (Y) em horas de máquina (X1) e mão de obra (X2) em uma fábrica.",
                                    "Assuma exogeneidade: Horas de máquina não correlacionadas com choques de eficiência (ε).",
                                    "Discuta violações potenciais, como endogeneidade por omitir variáveis (ex: qualidade de matéria-prima).",
                                    "Estime o modelo com dados fictícios industriais e teste resíduos vs. X.",
                                    "Interprete coeficientes β como efeitos causais sob exogeneidade."
                                  ],
                                  "verification": "Crie um gráfico de resíduos vs. preditores e confirme ausência de padrões.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Dataset industrial simulado (CSV com Y, X1, X2), Python/R.",
                                  "tips": "Gere dados com correlação intencional para testar violações.",
                                  "learningObjective": "Aplicar exogeneidade a contextos industriais reais.",
                                  "commonMistakes": "Assumir exogeneidade sem justificativa contextual."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar e Diagnosticar Exogeneidade em Prática",
                                  "subSteps": [
                                    "Aprenda testes auxiliares: Regressão de resíduos em X e teste significância.",
                                    "Implemente Hausman ou Durbin-Wu-Hausman para endogeneidade.",
                                    "Analise diagnósticos gráficos: Scatter plots de ε_hat vs. X.",
                                    "Discuta instrumentos para corrigir violações (IV).",
                                    "Documente achados em um relatório curto."
                                  ],
                                  "verification": "Realize um teste e interprete p-valor > 0.05 como evidência de exogeneidade.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Biblioteca ivreg em R ou linearmodels em Python, dataset do Step 3.",
                                  "tips": "Sempre cheque multicolinearidade antes dos testes.",
                                  "learningObjective": "Diagnosticar e validar exogeneidade empiricamente.",
                                  "commonMistakes": "Confundir falta de significância com prova de exogeneidade."
                                }
                              ],
                              "practicalExample": "Em uma fábrica de automóveis, regredir produção diária (Y) em horas de robôs (X1) e turnos humanos (X2). Exogeneidade estrita assume que choques ε (ex: falhas inesperadas) não dependem de X1/X2, permitindo estimar β como impacto causal de mais robôs na produção.",
                              "finalVerifications": [
                                "Defina corretamente E(ε_i | X_i) = 0 e prove unbiasedness de β.",
                                "Simule e mostre viés sem exogeneidade.",
                                "Aplique a um exemplo industrial com gráfico de resíduos.",
                                "Execute teste de exogeneidade e interprete resultados.",
                                "Explique implicações de violação em eficiência industrial.",
                                "Diferencie exogeneidade estrita de fraca."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição matemática (100% correta).",
                                "Correta derivação de unbiasedness com notação.",
                                "Simulação funcional mostrando viés zero sob pressuposto.",
                                "Exemplo industrial relevante e bem interpretado.",
                                "Testes diagnósticos implementados e analisados.",
                                "Ausência de confusões conceituais comuns."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Testes de endogeneidade e IV.",
                                "Engenharia Industrial: Modelagem de processos e eficiência.",
                                "Estatística: Expectativas condicionais e propriedades de estimadores.",
                                "Economia: Causalidade em modelos de produção."
                              ],
                              "realWorldApplication": "Em auditorias de eficiência fabril, verificar exogeneidade garante que coeficientes de regressão reflitam impactos reais de investimentos em máquinas, evitando decisões baseadas em estimativas viesadas que superestimem retornos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.2.2",
                            "name": "Explicar consequências de endogeneidade",
                            "description": "Analisar os efeitos de violações, como viés e inconsistência nos estimadores, e discutir instrumentos em cenários de engenharia como causalidade em testes de sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir Endogeneidade e Suas Causas",
                                  "subSteps": [
                                    "Revise o pressuposto de exogeneidade na regressão linear: E[ε|X] = 0.",
                                    "Identifique as três principais fontes de endogeneidade: variáveis omitidas, simultaneidade e erro de medição.",
                                    "Explique como cada fonte viola a exogeneidade com fórmulas simples, como Cov(X, ε) ≠ 0.",
                                    "Diferencie endogeneidade de multicolinearidade ou heterocedasticidade.",
                                    "Crie um diagrama causal ilustrando endogeneidade."
                                  ],
                                  "verification": "Desenhe um diagrama DAG mostrando uma violação de exogeneidade e explique verbalmente.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro de Econometria (Wooldridge), quadro branco, software de desenho (Draw.io)"
                                  ],
                                  "tips": "Use analogias cotidianas, como 'efeito rebote' em dietas para simultaneidade.",
                                  "learningObjective": "Compreender conceitualmente o que é endogeneidade e suas origens.",
                                  "commonMistakes": [
                                    "Confundir com correlação espúria",
                                    "Ignorar simultaneidade em modelos econômicos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o Viés nos Estimadores OLS",
                                  "subSteps": [
                                    "Derive a fórmula de viés: Bias(β_hat) = Cov(X,ε)/Var(X).",
                                    "Simule dados endógenos em Python/R com variáveis omitidas e estime OLS.",
                                    "Compare β_hat com o verdadeiro β em múltiplas simulações.",
                                    "Discuta sinal e magnitude do viés (positivo/negativo).",
                                    "Calcule viés analiticamente para um modelo bivariado simples."
                                  ],
                                  "verification": "Execute simulação e mostre que o viés médio é não-nulo.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python (statsmodels, numpy), Jupyter Notebook, dataset simulado"
                                  ],
                                  "tips": "Use seed para reprodutibilidade nas simulações.",
                                  "learningObjective": "Quantificar o viés finito-amostral causado pela endogeneidade.",
                                  "commonMistakes": [
                                    "Assumir viés sempre positivo",
                                    "Esquecer de centralizar variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explicar Inconsistência Assintótica",
                                  "subSteps": [
                                    "Derive a inconsistência: plim β_hat = β + Cov(X,ε)/Var(X).",
                                    "Aumente o tamanho da amostra em simulações e observe que β_hat não converge para β.",
                                    "Compare com OLS consistente sob exogeneidade.",
                                    "Discuta implicações para inferência: testes t inválidos.",
                                    "Analise cenários onde viés e inconsistência diferem."
                                  ],
                                  "verification": "Gere gráfico de convergência mostrando não-convergência com n→∞.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "R (ggplot2 para plots), código de simulação expandido"
                                  ],
                                  "tips": "Varie n de 100 a 10000 para visualizar assintótica.",
                                  "learningObjective": "Entender por que endogeneidade torna OLS não confiável mesmo com grandes amostras.",
                                  "commonMistakes": [
                                    "Confundir inconsistência com variância alta",
                                    "Ignorar termos de covariância"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Discutir Variáveis Instrumentais em Contextos de Engenharia",
                                  "subSteps": [
                                    "Defina IV: Z correlacionado com X (relevância), não com ε (exogeneidade).",
                                    "Estime 2SLS: primeira etapa regressão X em Z, segunda Y em X_hat.",
                                    "Aplique em exemplo de engenharia: causalidade em testes de sistemas de controle (ex: tuning PID endógeno por feedback).",
                                    "Teste relevância (F-stat >10) e sobredentificação (Sargan).",
                                    "Compare OLS vs IV em simulação de sistema de controle."
                                  ],
                                  "verification": "Implemente 2SLS e mostre redução de viés.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Python (linearmodels para IV), dados simulados de sistema de controle"
                                  ],
                                  "tips": "Use ruído aleatório como instrumento para tuning exógeno.",
                                  "learningObjective": "Aplicar soluções para endogeneidade em cenários práticos de engenharia.",
                                  "commonMistakes": [
                                    "Escolher Z fraco (baixa correlação)",
                                    "Violar exogeneidade do instrumento"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar e Verificar Compreensão",
                                  "subSteps": [
                                    "Resuma consequências: viés, inconsistência, inferência inválida.",
                                    "Crie tabela comparativa OLS vs IV.",
                                    "Discuta limitações de IV (viés de fracos, custo de precisão).",
                                    "Relacione a testes de causalidade em engenharia.",
                                    "Prepare um relatório de 1 página explicando tudo."
                                  ],
                                  "verification": "Escreva relatório e autoavalie com checklist.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Template de relatório, checklist de verificação"
                                  ],
                                  "tips": "Use bullet points para clareza no relatório.",
                                  "learningObjective": "Integrar conhecimentos em uma narrativa coesa.",
                                  "commonMistakes": [
                                    "Superestimar robustez de IV",
                                    "Omitir testes de validade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em testes de um sistema de controle PID para um drone, regredir performance (Y) no parâmetro de tuning (X) resulta em endogeneidade por feedback simultâneo. Use ruído experimental aleatório como instrumento Z para estimar efeito causal verdadeiro via 2SLS, revelando viés OLS de +20%.",
                              "finalVerifications": [
                                "Derivar corretamente a fórmula de viés OLS.",
                                "Simular e plotar viés/inconsistência.",
                                "Identificar IV válido em exemplo de engenharia.",
                                "Explicar condições de IV (relevância e exogeneidade).",
                                "Comparar resultados OLS vs IV numericamente.",
                                "Discutir limitações em contexto real."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições corretas: 20%)",
                                "Correção matemática (derivations e fórmulas: 25%)",
                                "Proficiência em simulações/código (resultados reproduzíveis: 20%)",
                                "Aplicação contextual (engenharia: 15%)",
                                "Clareza na explicação (relatório: 10%)",
                                "Identificação de erros comuns (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Identificação causal em dados observacionais.",
                                "Engenharia de Controle: Análise de causalidade em laços de feedback.",
                                "Machine Learning: Causal inference vs predição (Double ML).",
                                "Estatística: Propriedades assintóticas de estimadores.",
                                "Física: Modelagem de sistemas dinâmicos com endogeneidade."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, analisar endogeneidade em testes de estabilidade de aeronaves permite estimar efeitos causais de ajustes de controle, evitando decisões baseadas em viés OLS que poderiam levar a falhas de design custosas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.2.3",
                            "name": "Realizar testes básicos de exogeneidade",
                            "description": "Aplicar testes como o de Hausman para detectar endogeneidade em dados simulados ou reais de análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente computacional e os dados",
                                  "subSteps": [
                                    "Instale bibliotecas necessárias: pandas, numpy, statsmodels e matplotlib.",
                                    "Carregue ou simule um conjunto de dados com variáveis dependentes, independentes exógenas e potencialmente endógenas (ex: salário como Y, educação como X endógena, experiência como instrumento).",
                                    "Verifique estatísticas descritivas e plote correlações para identificar suspeitas de endogeneidade.",
                                    "Defina a especificação do modelo de regressão linear: Y = β0 + β1X + ε.",
                                    "Prepare instrumentos válidos (relevantes e exógenos) para o teste."
                                  ],
                                  "verification": "Ambiente configurado sem erros de importação; dados carregados e visualizados corretamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python 3.x, Jupyter Notebook, bibliotecas: pandas, numpy, statsmodels, matplotlib",
                                  "tips": "Use dados simulados inicialmente para controlar endogeneidade artificialmente.",
                                  "learningObjective": "Configurar ambiente e dados para testes de exogeneidade.",
                                  "commonMistakes": "Esquecer de instalar statsmodels ou usar dados sem instrumentos válidos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar modelos OLS e IV",
                                  "subSteps": [
                                    "Estime o modelo por Mínimos Quadrados Ordinários (OLS) usando sm.OLS().",
                                    "Identifique e implemente regressão instrumental (IV) com sm.IV2SLS(), usando instrumentos para a variável suspeita.",
                                    "Extraia coeficientes, erros-padrão e estatísticas de ambos os modelos.",
                                    "Compare coeficientes de OLS e IV visualmente (gráfico de diferenças).",
                                    "Calcule matriz de covariância entre estimadores OLS e IV se necessário."
                                  ],
                                  "verification": "Ambos modelos estimados com outputs válidos (sem singularidade ou warnings graves).",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código Python com statsmodels.formula.api as smf",
                                  "tips": "Garanta que instrumentos sejam relevantes testando F-stat na primeira etapa.",
                                  "learningObjective": "Implementar estimações comparativas para base do teste de Hausman.",
                                  "commonMistakes": "Confundir variável endógena com instrumento ou ignorar multicolinearidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar o teste de Hausman",
                                  "subSteps": [
                                    "Implemente a estatística de Hausman: H = (β_OLS - β_IV)' [Var(β_OLS) - Var(β_IV)]^{-1} (β_OLS - β_IV).",
                                    "Use função pronta do statsmodels: HausmanTest() ou calcule manualmente com numpy.",
                                    "Determine graus de liberdade (número de parâmetros testados).",
                                    "Calcule p-valor via distribuição qui-quadrado.",
                                    "Defina hipótese nula: H0 (exogeneidade: β_OLS = β_IV).",
                                    "Automatize em função reutilizável."
                                  ],
                                  "verification": "Estatística H, df e p-valor computados corretamente, comparados a valor crítico.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "statsmodels.stats.diagnostic.linear_hausman ou código customizado",
                                  "tips": "Verifique se matriz de variância é positiva definida para evitar erros numéricos.",
                                  "learningObjective": "Executar computacionalmente o teste de Hausman.",
                                  "commonMistakes": "Erro na inversão da matriz de covariância ou uso incorreto de df."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e validar",
                                  "subSteps": [
                                    "Analise: se p-valor < 0.05, rejeite H0 (endogeneidade detectada).",
                                    "Reporte coeficientes, H-stat, p-valor e conclusão em tabela formatada.",
                                    "Teste robustez com bootstrap ou diferentes instrumentos.",
                                    "Visualize resíduos e Q-Q plot para confirmar pressupostos.",
                                    "Documente limitações (ex: instrumentos fracos)."
                                  ],
                                  "verification": "Relatório gerado com interpretação clara e consistente com resultados.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Pandas para tabelas, matplotlib/seaborn para plots",
                                  "tips": "Sempre relacione p-valor ao contexto econômico da endogeneidade.",
                                  "learningObjective": "Interpretar e validar teste de exogeneidade.",
                                  "commonMistakes": "Ignorar p-valor e focar só em sinal dos coeficientes."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar em dados reais e sintetizar",
                                  "subSteps": [
                                    "Carregue dataset real de engenharia (ex: dados de produção industrial).",
                                    "Repita passos 2-4 adaptando ao contexto.",
                                    "Compare resultados simulados vs. reais.",
                                    "Gere relatório final com código, outputs e recomendações.",
                                    "Salve modelo corrigido se endogeneidade confirmada."
                                  ],
                                  "verification": "Aplicação em dados reais com conclusão acionável.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Dataset real (ex: de Kaggle ou UCI ML Repository)",
                                  "tips": "Escolha dados onde endogeneidade é plausível, como causalidade reversa.",
                                  "learningObjective": "Transferir teste para cenários reais.",
                                  "commonMistakes": "Usar dados sem viés potencial, invalidando o teste."
                                }
                              ],
                              "practicalExample": "Simule dados: Y (salário) = 10 + 2*educação + ε, mas corrompa educação com u (choque não observado). Use 'distância à escola' como instrumento. Estime OLS: β_edu=1.8; IV: β_edu=2.5; Hausman p-valor=0.03 → rejeita exogeneidade, indicando viés em OLS.",
                              "finalVerifications": [
                                "Teste de Hausman implementado e executado sem erros numéricos.",
                                "Interpretação correta: rejeição H0 se p<0.05.",
                                "Comparação de coeficientes OLS vs IV consistente.",
                                "Instrumentos validados (F-stat >10 na 1ª etapa).",
                                "Relatório inclui plots e tabelas legíveis.",
                                "Aplicação em dados reais reproduz resultados semelhantes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação do teste (matriz de covariância correta).",
                                "Correta interpretação estatística e econômica.",
                                "Uso apropriado de instrumentos relevantes e exógenos.",
                                "Código limpo, comentado e reproduzível.",
                                "Análise de robustez incluída.",
                                "Documentação clara de limitações."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Distribuições qui-quadrado e testes de hipótese.",
                                "Econometria: Modelos IV e correção de endogeneidade.",
                                "Engenharia de Dados: Manipulação e simulação de datasets.",
                                "Programação Computacional: Otimização numérica em Python.",
                                "Análise de Sistemas: Modelagem causal em processos industriais."
                              ],
                              "realWorldApplication": "Em engenharia, detectar endogeneidade em regressões para prever demanda de energia (ex: consumo endógeno a preço), permitindo modelos IV mais precisos para otimização de redes elétricas e políticas de eficiência energética."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.3.3",
                        "name": "Homocedasticidade dos Erros",
                        "description": "A variância dos erros é constante e independente das variáveis explicativas: Var(ε_i | X_i) = σ², essencial para a eficiência dos estimadores MQO e validade de inferências em econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.3.1",
                            "name": "Definir homocedasticidade",
                            "description": "Explicar o pressuposto de variância constante dos resíduos e seu papel nos teoremas de Gauss-Markov, ilustrando com dados de medições em sensores de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender variância e resíduos em regressão linear",
                                  "subSteps": [
                                    "Revise a definição de variância como medida de dispersão em uma distribuição de dados.",
                                    "Explique o que são resíduos em um modelo de regressão linear: diferença entre valor observado e predito.",
                                    "Calcule manualmente resíduos para um pequeno conjunto de dados de exemplo.",
                                    "Plote resíduos versus valores preditos para visualizar padrões.",
                                    "Discuta por que resíduos são cruciais para validar pressupostos do modelo."
                                  ],
                                  "verification": "Você pode calcular e plotar resíduos corretamente para um dataset simples e identificar se eles exibem variância constante.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Planilha Excel ou Jupyter Notebook com Python (bibliotecas: numpy, matplotlib)",
                                    "Dataset exemplo de regressão linear"
                                  ],
                                  "tips": "Sempre centre os resíduos em zero para análise; use gráficos de dispersão para visualização intuitiva.",
                                  "learningObjective": "Compreender os fundamentos de variância e resíduos como base para homocedasticidade.",
                                  "commonMistakes": [
                                    "Confundir resíduos com erros absolutos sem subtrair predições",
                                    "Ignorar a necessidade de resíduos padronizados",
                                    "Assumir variância constante sem verificação gráfica"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir homocedasticidade e contrastar com heteroscedasticidade",
                                  "subSteps": [
                                    "Defina homocedasticidade: variância constante dos resíduos independentemente dos valores preditos.",
                                    "Defina heteroscedasticidade: variância dos resíduos que varia sistematicamente.",
                                    "Gere exemplos sintéticos de dados homocedásticos e heteroscedásticos.",
                                    "Crie gráficos de resíduos vs. preditos para ambos os casos.",
                                    "Explique implicações de violar homocedasticidade nos estimadores de Mínimos Quadrados."
                                  ],
                                  "verification": "Explique a diferença entre homo e heteroscedasticidade em suas palavras e identifique em um gráfico fornecido.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Jupyter Notebook com Python (statsmodels, seaborn)",
                                    "Código para gerar dados sintéticos"
                                  ],
                                  "tips": "Use escala logarítmica nos gráficos para detectar padrões sutis de heteroscedasticidade.",
                                  "learningObjective": "Definir precisamente homocedasticidade e reconhecer sua violação visualmente.",
                                  "commonMistakes": [
                                    "Pensar que homocedasticidade significa média zero dos resíduos",
                                    "Confundir com normalidade dos erros",
                                    "Não diferenciar variância condicional de marginal"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar o papel da homocedasticidade nos teoremas de Gauss-Markov",
                                  "subSteps": [
                                    "Enuncie o Teorema de Gauss-Markov: OLS é BLUE (Best Linear Unbiased Estimator) sob certos pressupostos.",
                                    "Liste os pressupostos do teorema: linearidade, exogeneidade, homocedasticidade, etc.",
                                    "Explique como homocedasticidade garante eficiência dos estimadores OLS.",
                                    "Discuta o que acontece sem homocedasticidade: estimadores ainda não-viciados, mas ineficientes.",
                                    "Derive qualitativamente a variância do estimador OLS mostrando dependência na homocedasticidade."
                                  ],
                                  "verification": "Resuma os pressupostos de Gauss-Markov e o impacto específico da homocedasticidade na eficiência.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Texto de econometria ou estatística (ex: Wooldridge)",
                                    "Notas ou vídeo sobre Gauss-Markov"
                                  ],
                                  "tips": "Lembre-se: Gauss-Markov requer homocedasticidade para minimal variance, mas não normalidade.",
                                  "learningObjective": "Entender o teorema de Gauss-Markov e o papel pivotal da homocedasticidade.",
                                  "commonMistakes": [
                                    "Confundir BLUE com máxima verossimilhança",
                                    "Omitir que sem homocedasticidade OLS perde eficiência",
                                    "Achar que Gauss-Markov requer normalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Ilustrar homocedasticidade com dados de sensores de engenharia",
                                  "subSteps": [
                                    "Colete ou simule dados de medições de sensores (ex: temperatura vs. tensão em termistores).",
                                    "Ajuste um modelo de regressão linear e extraia resíduos.",
                                    "Plote resíduos vs. preditos e teste visualmente para homocedasticidade.",
                                    "Aplique teste estatístico (ex: Breusch-Pagan) para confirmar.",
                                    "Discuta correções se heteroscedasticidade for detectada (ex: pesos no WLS)."
                                  ],
                                  "verification": "Analise um dataset real de sensores, plote resíduos e conclua se homocedasticidade holds.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dataset de sensores (ex: Kaggle IoT sensor data)",
                                    "Python: statsmodels para testes BP"
                                  ],
                                  "tips": "Em sensores, variância pode aumentar com sinal fraco; normalize dados antes.",
                                  "learningObjective": "Aplicar o conceito a dados reais de engenharia para validação prática.",
                                  "commonMistakes": [
                                    "Não padronizar variáveis independentes",
                                    "Ignorar outliers que mascaram heteroscedasticidade",
                                    "Confundir ruído de sensor com violação sistemática"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sensor de pressão industrial, ajuste regressão linear de pressão vs. voltagem. Plote resíduos: se espalhados uniformemente (homocedásticos), modelo válido; se em forma de funil (heteroscedásticos), ajuste pesos para precisão em baixas pressões.",
                              "finalVerifications": [
                                "Defina homocedasticidade corretamente incluindo variância constante dos resíduos.",
                                "Explique seu papel essencial no Teorema de Gauss-Markov para eficiência OLS.",
                                "Identifique homocedasticidade vs. heteroscedasticidade em um gráfico de resíduos.",
                                "Aplique teste Breusch-Pagan a dados de sensores e interprete p-valor.",
                                "Descreva implicações em engenharia se violado.",
                                "Sugira correção via Weighted Least Squares (WLS)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição (100% match com variância constante condicional).",
                                "Correta enunciação de Gauss-Markov e destaque à homocedasticidade (eficiência).",
                                "Análise gráfica correta de resíduos em exemplo prático.",
                                "Interpretação estatística adequada (testes e thresholds).",
                                "Conexão contextual com dados de sensores de engenharia.",
                                "Clareza e estrutura na explicação escrita/oral."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de diagnóstico de regressão (Breusch-Pagan, White).",
                                "Engenharia: Calibração de sensores e modelagem de ruído.",
                                "Computação: Implementação em Python/R para análise de resíduos.",
                                "Econometria: Eficiência de estimadores em séries temporais.",
                                "Machine Learning: Pressupostos em regressão linear generalizada."
                              ],
                              "realWorldApplication": "Na engenharia de sensores IoT, homocedasticidade assegura que modelos de regressão predigam com variância previsível, evitando falhas em monitoramento de estruturas (ex: detecção precoce de fadiga em pontes via strain gauges), otimizando segurança e manutenção preditiva."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.3.2",
                            "name": "Detectar heteroscedasticidade graficamente",
                            "description": "Interpretar gráficos de resíduos vs. ajustados para identificar padrões de variância crescente, comuns em dados de engenharia como ruído em sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de heteroscedasticidade e homocedasticidade",
                                  "subSteps": [
                                    "Defina homocedasticidade: variância constante dos erros em todos os níveis dos preditores.",
                                    "Defina heteroscedasticidade: variância dos erros que varia sistematicamente, frequentemente aumentando com o valor ajustado.",
                                    "Explique por que a heteroscedasticidade viola os pressupostos da regressão linear OLS.",
                                    "Discuta impactos: estimativas enviesadas, intervalos de confiança inválidos e testes estatísticos incorretos.",
                                    "Relacione com dados de engenharia, como ruído em sistemas de controle que aumenta com a magnitude do sinal."
                                  ],
                                  "verification": "Resuma em suas palavras a diferença entre homo e heteroscedasticidade e liste 2 consequências em um modelo de regressão.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Livro de regressão linear (cap. pressupostos)",
                                    "Artigo online sobre diagnósticos de regressão"
                                  ],
                                  "tips": "Use analogias visuais, como funil para heteroscedasticidade crescente.",
                                  "learningObjective": "Diferenciar homocedasticidade de heteroscedasticidade e entender suas implicações nos pressupostos da regressão.",
                                  "commonMistakes": "Confundir variância dos erros com variância dos preditores; ignorar contexto de engenharia."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar o gráfico de resíduos vs. valores ajustados",
                                  "subSteps": [
                                    "Ajuste um modelo de regressão linear simples aos dados usando software (ex: Python com statsmodels ou R).",
                                    "Calcule os resíduos: e = y - y_hat, onde y_hat são valores ajustados.",
                                    "Crie o gráfico de dispersão: eixo x = valores ajustados (y_hat), eixo y = resíduos padronizados.",
                                    "Adicione linha horizontal em y=0 e faixa de confiança (±2 desvios padrão).",
                                    "Salve o gráfico com rótulos claros: título, eixos e legenda."
                                  ],
                                  "verification": "Gere e exiba o gráfico para um conjunto de dados de exemplo; confirme que resíduos e ajustados estão corretos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python/R instalado",
                                    "Biblioteca statsmodels (Python) ou lmtest (R)",
                                    "Dataset de exemplo com heteroscedasticidade"
                                  ],
                                  "tips": "Padronize resíduos para facilitar interpretação (divida por desvio padrão).",
                                  "learningObjective": "Produzir corretamente o gráfico diagnóstico de resíduos vs. ajustados.",
                                  "commonMistakes": "Usar resíduos brutos em vez de padronizados; inverter eixos x e y."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar padrões gráficos de heteroscedasticidade",
                                  "subSteps": [
                                    "Procure por variância crescente: pontos se espalhando em forma de funil à direita.",
                                    "Identifique variância decrescente: pontos se concentrando à direita.",
                                    "Detecte padrões não lineares: curvas ou clusters irregulares.",
                                    "Confirme homocedasticidade: nuvem aleatória uniforme ao redor de y=0.",
                                    "Quantifique visualmente: observe largura da faixa de resíduos em diferentes intervalos de y_hat."
                                  ],
                                  "verification": "Analise um gráfico fornecido e classifique como homo ou heteroscedástico, justificando com padrões observados.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráficos de exemplo (homo e hetero)",
                                    "Ferramenta de zoom em plots interativos"
                                  ],
                                  "tips": "Use grid e cores para destacar regiões de variância variável.",
                                  "learningObjective": "Reconhecer visualmente padrões indicativos de heteroscedasticidade no gráfico.",
                                  "commonMistakes": "Confundir heterocedasticidade com heterocedasticidade não linear; ignorar outliers isolados."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar detecção em dados reais de engenharia e interpretar",
                                  "subSteps": [
                                    "Carregue dados de ruído em sistema de controle (ex: tensão vs. ruído).",
                                    "Ajuste regressão e gere gráfico de resíduos vs. ajustados.",
                                    "Interprete: se variância crescente, sugira transformações (ex: log).",
                                    "Compare com teste formal (ex: Breusch-Pagan) para validação.",
                                    "Documente achados em relatório curto com gráfico e conclusão."
                                  ],
                                  "verification": "Produza relatório com gráfico analisado, identificando heteroscedasticidade e recomendação.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dataset real: ruído em sistemas de controle",
                                    "Jupyter Notebook ou R Markdown"
                                  ],
                                  "tips": "Sempre relacione achados ao contexto do problema de engenharia.",
                                  "learningObjective": "Aplicar detecção gráfica em dados reais e propor soluções.",
                                  "commonMistakes": "Sobrepor interpretação visual a testes formais sem validação; ignorar escala dos eixos."
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de motor, dados de tensão de entrada (x) vs. ruído medido (y). Após regressão linear, o gráfico de resíduos vs. ajustados mostra variância crescente (funil) para tensões altas, indicando heteroscedasticidade devido a ruído proporcional à magnitude do sinal. Solução: aplicar transformação log(y).",
                              "finalVerifications": [
                                "Gere corretamente gráfico de resíduos vs. ajustados para dados novos.",
                                "Identifique funil crescente em gráfico com heteroscedasticidade.",
                                "Explique impacto na inferência estatística.",
                                "Sugira correção apropriada (ex: transformações).",
                                "Compare detecção gráfica com teste Breusch-Pagan.",
                                "Aplique em dataset de engenharia com relatório."
                              ],
                              "assessmentCriteria": [
                                "Precisão na geração do gráfico (rótulos, escalas corretas).",
                                "Correta identificação de padrões (funil, nuvem uniforme).",
                                "Justificativa clara baseada em pressupostos da regressão.",
                                "Relevância ao contexto de engenharia (ex: ruído em controles).",
                                "Proposta de soluções práticas e acionáveis.",
                                "Documentação completa com interpretações.",
                                "Tempo de execução dentro do estimado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes formais como Breusch-Pagan para validação gráfica.",
                                "Programação: Uso de Python/R para automação de diagnósticos.",
                                "Engenharia de Controle: Análise de ruído em sistemas dinâmicos.",
                                "Matemática Aplicada: Transformações para estabilizar variância."
                              ],
                              "realWorldApplication": "Em engenharia, detectar heteroscedasticidade em dados de sensores de sistemas de controle evita modelos imprecisos, melhorando previsões de ruído e estabilidade, como em drones onde variância de vento aumenta com velocidade."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.3.3",
                            "name": "Aplicar testes de homocedasticidade",
                            "description": "Executar testes como Breusch-Pagan ou White em software como R, interpretando resultados e propondo correções como MQO robusto para aplicações em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar ambiente, dados e modelo de regressão linear em R",
                                  "subSteps": [
                                    "Instale e carregue pacotes necessários: lmtest, sandwich e lmtest.",
                                    "Carregue um conjunto de dados relevante, como dados simulados de custos de projetos de engenharia vs tamanho do projeto.",
                                    "Ajuste o modelo de regressão linear ordinária (MQO) usando lm() para prever custo ~ tamanho.",
                                    "Visualize resíduos plotando residuals() vs fitted() para inspeção inicial.",
                                    "Salve o modelo em uma variável para uso posterior."
                                  ],
                                  "verification": "Confirme que o modelo lm foi ajustado sem erros e que o summary(modelo) exibe coeficientes e R² válidos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Pacotes: lmtest, sandwich",
                                    "Dataset exemplo: simule com data.frame(custo = 100 + 2*tamanho + rnorm(100,0,sd=varia), tamanho=1:100)"
                                  ],
                                  "tips": "Use set.seed(123) para reprodutibilidade nos dados simulados.",
                                  "learningObjective": "Configurar corretamente um ambiente R para análise de regressão e preparar modelo OLS.",
                                  "commonMistakes": [
                                    "Esquecer de carregar pacotes com library()",
                                    "Usar dados não numéricos sem conversão",
                                    "Não verificar multicolinearidade inicial"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar o teste de Breusch-Pagan para homocedasticidade",
                                  "subSteps": [
                                    "Carregue o pacote lmtest com library(lmtest).",
                                    "Execute bptest(modelo) para testar homocedasticidade dos resíduos quadrados.",
                                    "Registre o p-valor e estatística do teste.",
                                    "Interprete preliminarmente: p-valor < 0.05 indica heteroscedasticidade.",
                                    "Salve o resultado em uma variável para relatório."
                                  ],
                                  "verification": "O output de bptest() mostra studentize: FALSE por padrão e p-valor calculado corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Pacote lmtest",
                                    "Modelo OLS ajustado do Step 1"
                                  ],
                                  "tips": "Use bptest(modelo, studentize=FALSE) para versão clássica se necessário.",
                                  "learningObjective": "Aplicar e executar o teste Breusch-Pagan corretamente em R.",
                                  "commonMistakes": [
                                    "Aplicar bptest diretamente em dados sem modelo lm",
                                    "Ignorar a opção studentize",
                                    "Confundir p-valor com estatística do teste"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste de White para heteroscedasticidade geral",
                                  "subSteps": [
                                    "Use lmtest::bptest(modelo, studentize=FALSE) para aproximação do teste White.",
                                    "Alternativamente, instale e use pacote 'whitest' se disponível, ou implemente manualmente com regressão auxiliar.",
                                    "Registre estatística LM e p-valor do teste White.",
                                    "Compare resultados com Breusch-Pagan para consistência.",
                                    "Documente diferenças nos outputs."
                                  ],
                                  "verification": "p-valor do teste White < 0.05 confirma rejeição de homocedasticidade, alinhado com Breusch-Pagan.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Pacotes lmtest ou whitest",
                                    "Modelo OLS do Step 1"
                                  ],
                                  "tips": "Teste White é mais geral; use para capturar formas não-lineares de heteroscedasticidade.",
                                  "learningObjective": "Executar teste White e compará-lo com Breusch-Pagan em R.",
                                  "commonMistakes": [
                                    "Confundir parâmetros studentize",
                                    "Não incluir termos quadrados no teste manual",
                                    "Ignorar amostras pequenas onde teste é impreciso"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e propor/implementar correções com MQO robusto",
                                  "subSteps": [
                                    "Analise p-valores: se ambos < 0.05, conclua heteroscedasticidade.",
                                    "Instale/carregue sandwich: library(sandwich).",
                                    "Calcule erros padrão robustos com sqrt(diag(vcovHC(modelo, type='HC1'))).",
                                    "Re-ajuste coeficientes robustos e compare com OLS padrão via coeftest(modelo, vcov=vcovHC(modelo)).",
                                    "Reporte conclusões e aplique modelo robusto para inferências confiáveis."
                                  ],
                                  "verification": "coeftest() mostra intervalos de confiança ajustados e significância alterada corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Pacote sandwich",
                                    "Resultados dos testes anteriores"
                                  ],
                                  "tips": "Use type='HC1' para viés finito-amostral em engenharia.",
                                  "learningObjective": "Interpretar testes e corrigir heteroscedasticidade com estimadores robustos.",
                                  "commonMistakes": [
                                    "Não usar vcovHC corretamente",
                                    "Ignorar type em HC",
                                    "Concluir sem comparar OLS vs robusto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia civil, modele o custo de construção (em milhões) vs comprimento da ponte (em km) com dados de 50 pontes. Execute Breusch-Pagan (p=0.01) e White (p=0.008), detectando heteroscedasticidade devido a projetos maiores. Aplique MQO robusto, revelando que o coeficiente de comprimento muda de significativo para marginal, ajustando estimativas de custo.",
                              "finalVerifications": [
                                "Executar bptest() e obter output com p-valor <0.05 em dados heteroscedásticos simulados.",
                                "Aplicar coeftest() com vcovHC() e interpretar mudança em p-valores de coeficientes.",
                                "Gerar plot de resíduos vs fitted() pré e pós-robusto mostrando correção.",
                                "Relatar corretamente: 'Rejeita H0 de homocedasticidade; use erros robustos'.",
                                "Reproduzir análise em dataset novo com set.seed().",
                                "Comparar estatísticas de Breusch-Pagan e White com consistência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na execução de bptest() e interpretação de p-valor (90% correto).",
                                "Correta implementação de vcovHC() e coeftest() sem erros de sintaxe.",
                                "Interpretação coerente: detecção de heteroscedasticidade leva a robusto.",
                                "Relatório inclui p-valores, conclusões e aplicação em contexto de engenharia.",
                                "Uso de visualizações (plots) para suporte à interpretação.",
                                "Tempo total dentro de 80 minutos com qualidade alta."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Pressupostos de regressão e testes de diagnóstico.",
                                "Programação: Manipulação de dados e funções em R para análise computacional.",
                                "Engenharia: Modelagem preditiva de custos e riscos em projetos reais.",
                                "Econometria: Correções robustas em dados empíricos não-ideais.",
                                "Visualização de Dados: Plots de resíduos para diagnóstico gráfico."
                              ],
                              "realWorldApplication": "Em engenharia mecânica, engenheiros testam homocedasticidade em regressões de fadiga de materiais (tensão vs ciclos de vida). Heteroscedasticidade detectada via Breusch-Pagan/White leva a MQO robusto, fornecendo previsões confiáveis de manutenção preditiva, evitando superestimação de durabilidade em componentes de alta variância."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.3.4",
                        "name": "Ausência de Autocorrelação e Normalidade dos Erros",
                        "description": "Os erros não apresentam autocorrelação serial (Cov(ε_i, ε_j)=0 para i≠j) e são normalmente distribuídos (ε ~ N(0,σ²)), necessários para inferência estatística e testes de hipóteses em séries temporais de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.3.4.1",
                            "name": "Definir ausência de autocorrelação",
                            "description": "Descrever a independência serial dos erros e suas implicações para eficiência em dados de séries temporais, como monitoramento de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de Correlação e Introduzir Autocorrelação",
                                  "subSteps": [
                                    "Estude a definição de correlação linear entre duas variáveis aleatórias independentes.",
                                    "Aprenda o conceito de autocorrelação como correlação entre uma variável e ela mesma em lags diferentes (ex: erro em t e t-1).",
                                    "Analise exemplos simples de séries temporais com e sem autocorrelação usando gráficos de autocorrelação (ACF).",
                                    "Diferencie correlação cruzada de autocorrelação."
                                  ],
                                  "verification": "Crie um gráfico ACF para uma série temporal simulada e identifique presença ou ausência de autocorrelação.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python ou R com bibliotecas statsmodels ou forecast",
                                    "Dados simulados de série temporal (ex: AR(1))"
                                  ],
                                  "tips": "Comece com lags pequenos (1-5) para visualizar picos significativos no ACF.",
                                  "learningObjective": "Compreender a autocorrelação como violação da independência serial em dados sequenciais.",
                                  "commonMistakes": [
                                    "Confundir autocorrelação com correlação simples entre variáveis independentes.",
                                    "Ignorar a significância estatística dos picos no ACF (use bandas de confiança)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender Autocorrelação nos Resíduos da Regressão Linear",
                                  "subSteps": [
                                    "Revise os pressupostos da regressão linear OLS, focando na independência dos erros.",
                                    "Simule dados com autocorrelação nos erros e ajuste um modelo OLS.",
                                    "Calcule e plote resíduos vs lags para visualizar padrões.",
                                    "Use teste de Durbin-Watson para quantificar autocorrelação serial."
                                  ],
                                  "verification": "Aplique teste Durbin-Watson em dados simulados e interprete o valor (próximo a 2 indica ausência).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Jupyter Notebook com statsmodels (Python)",
                                    "Dados simulados com erros AR(1)"
                                  ],
                                  "tips": "Gere erros autocorrelacionados usando modelo AR(1): e_t = ρ e_{t-1} + ε_t.",
                                  "learningObjective": "Identificar como autocorrelação nos resíduos afeta a validade do modelo OLS.",
                                  "commonMistakes": [
                                    "Assumir que resíduos aleatórios visuais implicam ausência de autocorrelação sem testes formais.",
                                    "Confundir heterocedasticidade com autocorrelação."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir Formalmente Ausência de Autocorrelação",
                                  "subSteps": [
                                    "Defina ausência de autocorrelação: Cov(e_t, e_{t-k}) = 0 para todo k ≠ 0, onde e são erros.",
                                    "Explique independência serial: erros não correlacionados sequencialmente.",
                                    "Escreva a matriz de covariância dos erros como diagonal sob este pressuposto.",
                                    "Discuta equivalência com ruído branco em contextos de séries temporais."
                                  ],
                                  "verification": "Escreva a definição matemática e prove que implica variância mínima dos estimadores OLS.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Folha de papel ou editor LaTeX para fórmulas",
                                    "Livro de Econometria (ex: Wooldridge)"
                                  ],
                                  "tips": "Lembre-se: independência serial é mais forte que ausência de autocorrelação (implica momentos independentes).",
                                  "learningObjective": "Formular precisamente a definição e suas propriedades matemáticas.",
                                  "commonMistakes": [
                                    "Confundir ausência de autocorrelação com independência condicional.",
                                    "Esquecer que aplica a erros, não a variáveis explicativas."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Implicações para Eficiência dos Estimadores",
                                  "subSteps": [
                                    "Explique que sob ausência, OLS é BLUE (Best Linear Unbiased Estimator).",
                                    "Simule cenários com e sem autocorrelação e compare variâncias dos coeficientes.",
                                    "Discuta ineficiência sob violação: variâncias superestimadas, ICs inválidos.",
                                    "Aprenda ajustes como GLS ou Newey-West para correção."
                                  ],
                                  "verification": "Compare variâncias de β em simulações com ρ=0 vs ρ=0.5.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python com numpy e statsmodels",
                                    "Scripts de simulação Monte Carlo"
                                  ],
                                  "tips": "Use 1000 replicações para precisão nas variâncias simuladas.",
                                  "learningObjective": "Compreender impactos na eficiência e inferência estatística.",
                                  "commonMistakes": [
                                    "Pensar que OLS permanece não viesado com autocorrelação (é verdade, mas ineficiente).",
                                    "Ignorar perda de poder em testes de hipóteses."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar a Séries Temporais em Monitoramento Industrial",
                                  "subSteps": [
                                    "Colete dados reais/simulados de processo industrial (ex: temperatura em linha de produção).",
                                    "Ajuste regressão linear e teste ausência de autocorrelação nos resíduos.",
                                    "Interprete implicações para monitoramento: previsões confiáveis sem padrões seriais.",
                                    "Proponha ações se violado: modelar ARIMA ou adicionar lags."
                                  ],
                                  "verification": "Gere relatório com teste DW, ACF resíduos e conclusão sobre pressuposto.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Dataset público de sensores industriais (ex: UCI ML repo)",
                                    "R ou Python com pacotes de TS"
                                  ],
                                  "tips": "Use dados horários/diários para capturar dependências seriais reais.",
                                  "learningObjective": "Conectar conceito a aplicações práticas em dados de séries temporais industriais.",
                                  "commonMistakes": [
                                    "Usar dados não estacionários sem diferenciação prévia.",
                                    "Subestimar autocorrelação em processos com inércia física."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de cimento, monitore temperatura do forno (Y) vs tempo de operação (X). Ajuste Y = β0 + β1 X + e. Se resíduos mostram ACF com pico em lag 1, autocorrelação existe devido a inércia térmica; ausência garante eficiência em detectar desvios para manutenção preditiva.",
                              "finalVerifications": [
                                "Definição correta de ausência de autocorrelação fornecida verbalmente.",
                                "Cálculo e interpretação precisa de teste Durbin-Watson em exemplo.",
                                "Explicação clara de independência serial dos erros.",
                                "Descrição das implicações para variância dos estimadores OLS.",
                                "Aplicação correta a um dataset de série temporal industrial."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática da definição (Cov(e_t, e_s)=0 para t≠s).",
                                "Correta distinção entre viés e ineficiência sob violação.",
                                "Uso apropriado de testes diagnósticos (DW, ACF, Ljung-Box).",
                                "Análise qualitativa/quantitativa de implicações em eficiência.",
                                "Conexão explícita com monitoramento industrial e decisões práticas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses para resíduos.",
                                "Séries Temporais: Modelos ARIMA para correção.",
                                "Engenharia de Processos: Controle estatístico de qualidade (SPC).",
                                "Econometria: Modelos com erros autocorrelacionados.",
                                "Machine Learning: Validação de resíduos em regressão."
                              ],
                              "realWorldApplication": "No monitoramento de processos industriais, como fornos ou linhas de montagem, a ausência de autocorrelação nos erros de regressão garante que estimadores de parâmetros (ex: taxa de aquecimento) sejam eficientes, permitindo detecção precoce de anomalias, otimização de energia e prevenção de falhas via manutenção preditiva confiável."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.4.2",
                            "name": "Testar autocorrelação e normalidade",
                            "description": "Aplicar testes como Durbin-Watson para autocorrelação e Jarque-Bera para normalidade em resíduos de regressões, usando exemplos de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar pressupostos da regressão e preparar conjunto de dados de engenharia",
                                  "subSteps": [
                                    "Estude os pressupostos da regressão linear: independência dos erros (ausência de autocorrelação) e normalidade dos resíduos.",
                                    "Selecione um dataset de engenharia, como dados de temperatura e vibração em uma linha de produção para prever falhas em máquinas.",
                                    "Carregue os dados usando pandas em Python e realize limpeza inicial (remover missing values, outliers).",
                                    "Divida os dados em variáveis dependente (falhas) e independentes (temperatura, vibração).",
                                    "Visualize os dados com plots de dispersão e séries temporais para identificar possíveis autocorrelações."
                                  ],
                                  "verification": "Dataset limpo carregado e visualizações geradas sem erros, com resumo estatístico exibido.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com pandas, matplotlib, seaborn",
                                    "Dataset de exemplo: dados de sensores industriais (CSV)"
                                  ],
                                  "tips": "Use datasets reais de repositórios como UCI Machine Learning para autenticidade.",
                                  "learningObjective": "Compreender a importância dos pressupostos e preparar dados adequados para testes.",
                                  "commonMistakes": [
                                    "Ignorar ordenação temporal nos dados levando a falsos positivos",
                                    "Não tratar outliers que distorcem resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar modelo de regressão linear e extrair resíduos",
                                  "subSteps": [
                                    "Instale e importe statsmodels para regressão.",
                                    "Ajuste o modelo OLS: sm.OLS(y, X).fit().",
                                    "Extraia os resíduos usando model.resid.",
                                    "Plote resíduos vs. valores ajustados e QQ-plot para inspeção visual inicial.",
                                    "Calcule estatísticas descritivas dos resíduos (média, variância)."
                                  ],
                                  "verification": "Modelo ajustado com summary() exibido e resíduos salvos em um array ou DataFrame.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Biblioteca statsmodels",
                                    "Jupyter Notebook ou script Python"
                                  ],
                                  "tips": "Sempre inclua constante no modelo com sm.add_constant(X).",
                                  "learningObjective": "Executar regressão OLS e isolar resíduos para testes subsequentes.",
                                  "commonMistakes": [
                                    "Esquecer de adicionar intercepto",
                                    "Usar resíduos não padronizados para testes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar teste de Durbin-Watson para autocorrelação",
                                  "subSteps": [
                                    "Calcule a estatística Durbin-Watson: from statsmodels.stats.diagnostic import durbin_watson; dw = durbin_watson(model.resid).",
                                    "Interprete o valor: DW ≈ 2 indica ausência de autocorrelação; <1.5 ou >2.5 sugere presença.",
                                    "Compare com tabelas críticas de Durbin-Watson para seu n e k (número de variáveis).",
                                    "Plote resíduos lag-1 para confirmação visual usando autocorrelation plot.",
                                    "Documente p-valor se disponível via pacotes adicionais."
                                  ],
                                  "verification": "Estatística DW calculada e interpretada corretamente em relatório curto.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels.stats.diagnostic",
                                    "Tabelas DW críticas (PDF ou online)"
                                  ],
                                  "tips": "Para séries temporais, considere testes Ljung-Box como complemento.",
                                  "learningObjective": "Detectar e quantificar autocorrelação nos resíduos.",
                                  "commonMistakes": [
                                    "Interpretar DW sem contexto de n/k",
                                    "Aplicar em dados não ordenados temporalmente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar teste de Jarque-Bera para normalidade dos resíduos",
                                  "subSteps": [
                                    "Calcule JB: from statsmodels.stats.diagnostic import jarque_bera; jb_stat, p_value = jarque_bera(model.resid).",
                                    "Interprete: p-value > 0.05 indica normalidade; estatística JB baixa confirma.",
                                    "Gere QQ-plot e histograma dos resíduos para validação visual.",
                                    "Compare com testes Shapiro-Wilk para amostras menores se aplicável.",
                                    "Registre resultados em um relatório com gráficos."
                                  ],
                                  "verification": "Teste JB executado com p-value reportado e gráficos de normalidade gerados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels.stats.diagnostic",
                                    "scipy.stats para QQ-plot"
                                  ],
                                  "tips": "Log-transforme resíduos se necessário para melhorar normalidade.",
                                  "learningObjective": "Avaliar normalidade dos erros usando teste estatístico padrão.",
                                  "commonMistakes": [
                                    "Confundir JB com teste de heterocedasticidade",
                                    "Ignorar tamanho da amostra (JB sensível a n grande)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados combinados e propor remediações",
                                  "subSteps": [
                                    "Combine resultados DW e JB: liste violações e impactos na inferência.",
                                    "Se autocorrelação: sugira Newey-West std errors ou modelo ARIMA.",
                                    "Se não normalidade: sugira regressão robusta ou transformações.",
                                    "Re-execute testes pós-ajustes e compare.",
                                    "Gere relatório final com conclusões e código reproduzível."
                                  ],
                                  "verification": "Relatório completo com interpretações, remediações e código em notebook compartilhável.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Notebook Jupyter para relatório",
                                    "Templates de relatório LaTeX ou Markdown"
                                  ],
                                  "tips": "Sempre valide com cross-validation para robustez.",
                                  "learningObjective": "Integrar testes e diagnosticar modelo de regressão.",
                                  "commonMistakes": [
                                    "Não propor soluções práticas",
                                    "Sobrepor testes sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados de sensores de uma turbina eólica (velocidade do vento vs. vibração), ajuste regressão para prever vibração. Teste DW revela autocorrelação (DW=1.2 devido a ventos sequenciais); JB mostra não-normalidade (p=0.01). Remediação: use erros robustos e log-transformação, melhorando DW para 1.9 e JB p=0.15.",
                              "finalVerifications": [
                                "Cálculo correto de DW e JB com valores plausíveis para dataset dado.",
                                "Interpretação precisa: identificar violações e limites críticos.",
                                "Gráficos visuais (QQ-plot, lag-plot) gerados e analisados.",
                                "Relatório reproduzível com código que roda sem erros.",
                                "Propostas de remediação testadas e validadas.",
                                "Conhecimento demonstrado em quiz sobre pressupostos."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de testes (erro <5%).",
                                "Qualidade da interpretação (correta em 90% dos casos).",
                                "Completude dos substeps e documentação.",
                                "Criatividade em exemplos de engenharia reais.",
                                "Eficiência temporal (dentro de estimados).",
                                "Integração de visualizações e estatísticas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: hipóteses nulas/alternativas nos testes.",
                                "Programação Computacional: uso de statsmodels em Python/R.",
                                "Engenharia de Processos: análise de séries temporais industriais.",
                                "Machine Learning: diagnósticos em modelos preditivos.",
                                "Econometria: extensões para dados panel."
                              ],
                              "realWorldApplication": "Em engenharia mecânica, testar resíduos em regressões de dados de manutenção preditiva garante previsões confiáveis de falhas em equipamentos, evitando downtime custoso em fábricas ou usinas, como otimizar manutenção de turbinas baseadas em vibração e temperatura."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.4.3",
                            "name": "Interpretar violações e correções",
                            "description": "Explicar impactos em intervalos de confiança e p-valores, propondo soluções como erros padrão robustos ou modelos ARIMA para dados de engenharia com dependência temporal.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos de Ausência de Autocorrelação e Normalidade dos Erros",
                                  "subSteps": [
                                    "Explique o pressuposto de ausência de autocorrelação: erros independentes entre si.",
                                    "Descreva a normalidade dos erros: resíduos seguem distribuição normal.",
                                    "Liste consequências de violações: viés em inferências estatísticas.",
                                    "Revise fórmulas chave: covariância dos erros e teste de normalidade (Shapiro-Wilk).",
                                    "Identifique contextos comuns em dados de engenharia: séries temporais com dependência."
                                  ],
                                  "verification": "Resuma os pressupostos em um diagrama mental ou tabela, confirmando independência e normalidade.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notas de aula sobre regressão linear, calculadora ou software como Python (statsmodels).",
                                  "tips": "Use analogias como 'erros como ruído branco' para fixar conceitos.",
                                  "learningObjective": "Compreender os fundamentos teóricos dos pressupostos para basear diagnósticos.",
                                  "commonMistakes": "Confundir autocorrelação com heterocedasticidade; ignorar dependência temporal em dados sequenciais."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diagnosticar Violações nos Resíduos",
                                  "subSteps": [
                                    "Calcule resíduos do modelo OLS: e = y - ŷ.",
                                    "Teste autocorrelação: use Durbin-Watson ou ACF plot.",
                                    "Teste normalidade: QQ-plot, Shapiro-Wilk ou Kolmogorov-Smirnov.",
                                    "Visualize padrões: plot de resíduos vs tempo ou lagged residuals.",
                                    "Quantifique: calcule p-valores dos testes e interprete (p < 0.05 indica violação)."
                                  ],
                                  "verification": "Gere gráficos e testes mostrando evidência clara de violação (ex: ACF com lags significativos).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dataset de exemplo (CSV com séries temporais), Python/R com bibliotecas statsmodels/forecast.",
                                  "tips": "Sempre plote resíduos ordenados por tempo para detectar autocorrelação serial.",
                                  "learningObjective": "Identificar violações de forma empírica usando ferramentas estatísticas.",
                                  "commonMistakes": "Interpretar erroneamente testes (ex: ignorar tamanho de amostra pequeno); não padronizar resíduos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar Impactos em Intervalos de Confiança e P-valores",
                                  "subSteps": [
                                    "Explique subestimação de erros padrão em autocorrelação: IC mais estreitos, p-valores menores.",
                                    "Discuta não-normalidade: distorção em testes t e F, invalidação de inferências.",
                                    "Simule cenários: compare OLS padrão vs violado em termos de cobertura de IC.",
                                    "Calcule métricas afetadas: ajuste IC bootstrap para robustez.",
                                    "Documente impactos: tabela comparativa de p-valores antes/depois violação."
                                  ],
                                  "verification": "Produza relatório explicando como violações levam a falsos positivos/negativos em inferências.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Simulador em Python (numpy, matplotlib), exemplos de datasets com violações conhecidas.",
                                  "tips": "Use simulações Monte Carlo para visualizar inflação de Type I error.",
                                  "learningObjective": "Quantificar e explicar efeitos das violações em resultados estatísticos.",
                                  "commonMistakes": "Superestimar robustez do OLS; ignorar que p-valores baixos podem ser artefatos de autocorrelação."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Propor e Aplicar Correções Adequadas",
                                  "subSteps": [
                                    "Para autocorrelação: aplique erros padrão robustos (HCSE) ou Newey-West.",
                                    "Para dependência temporal: ajuste modelo ARIMA ou GLS.",
                                    "Implemente em código: refaça regressão com correções e compare.",
                                    "Escolha baseada em diagnóstico: ARIMA para séries fortes, robust SE para fracas.",
                                    "Avalie melhoria: re-teste resíduos corrigidos."
                                  ],
                                  "verification": "Execute modelo corrigido e confirme testes de resíduos passam (DW ~2, p-normalidade >0.05).",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Python (statsmodels.tsa.arima, robustcov), dataset real de engenharia.",
                                  "tips": "Comece com robust SE por simplicidade; escale para ARIMA se ACF persistir.",
                                  "learningObjective": "Selecionar e implementar soluções targeted para violações específicas.",
                                  "commonMistakes": "Aplicar ARIMA sem estacionariedade; não verificar resíduos pós-correção."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Documentar a Correção",
                                  "subSteps": [
                                    "Re-teste todos pressupostos nos resíduos corrigidos.",
                                    "Compare métricas: R² ajustado, IC corrigidos, p-valores.",
                                    "Gere relatório: antes/depois com gráficos e tabelas.",
                                    "Discuta limitações: trade-offs como perda de graus de liberdade.",
                                    "Planeje monitoramento: para dados futuros em engenharia."
                                  ],
                                  "verification": "Relatório completo mostra resolução de violações e inferências confiáveis.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Template de relatório Jupyter Notebook, software de visualização.",
                                  "tips": "Sempre inclua código reproduzível para transparência.",
                                  "learningObjective": "Garantir robustez final e comunicar resultados efetivamente.",
                                  "commonMistakes": "Declarar sucesso sem re-testes; omitir comparações quantitativas."
                                }
                              ],
                              "practicalExample": "Em um dataset de medições de vibração em uma turbina eólica ao longo de 1 ano (dados horários), ajuste OLS para prever vibração por vento. Diagnostique autocorrelação (DW=1.2), não-normalidade (QQ-plot curvado). Impacto: p-valores subestimados levam a falsos significativos. Corrija com ARIMA(1,0,0) nos erros, obtendo IC mais largos e p-valores ajustados.",
                              "finalVerifications": [
                                "Resíduos corrigidos mostram DW entre 1.5-2.5 e p-Shapiro >0.05.",
                                "IC e p-valores corrigidos diferem logicamente dos originais.",
                                "Modelo corrigido mantém poder preditivo (MSE similar ou melhor).",
                                "Relatório inclui gráficos ACF/QQ antes/depois.",
                                "Soluções propostas justificadas pelo diagnóstico.",
                                "Trade-offs discutidos (ex: complexidade ARIMA vs robust SE)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de violações (testes corretos usados).",
                                "Explicação clara de impactos em IC/p-valores com evidências.",
                                "Seleção apropriada de correções baseada em contexto (engenharia temporal).",
                                "Implementação técnica sem erros de código.",
                                "Relatório completo e profissional.",
                                "Criatividade em exemplos reais e conexões interdisciplinares."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia: Análise de séries temporais em monitoramento de equipamentos.",
                                "Programação: Uso de statsmodels em Python para automação de diagnósticos.",
                                "Estatística Avançada: Extensão a modelos GARCH para volatilidade.",
                                "Ciência de Dados: Integração com machine learning para previsão híbrida."
                              ],
                              "realWorldApplication": "Em engenharia de processos, detectar autocorrelação em dados de sensores permite correções precisas, evitando falsos alarmes em sistemas de controle preditivo, otimizando manutenção e reduzindo downtime em indústrias como óleo/gás ou manufatura."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.3.4.4",
                            "name": "Visualizar distribuições de resíduos",
                            "description": "Construir Q-Q plots e gráficos de autocorrelação de resíduos para diagnosticar violações em contextos práticos de análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente e preparar dados para análise de regressão",
                                  "subSteps": [
                                    "Instalar e importar bibliotecas necessárias: pandas, numpy, matplotlib, seaborn, statsmodels e scipy",
                                    "Carregar um dataset prático de engenharia, como dados de resistência de concreto (disponível em repositórios como UCI ML)",
                                    "Explorar dados com info(), describe() e verificar missing values",
                                    "Preparar variáveis: definir X (independentes, e.g., cimento, água) e y (dependente, e.g., resistência)",
                                    "Tratar outliers ou escalar variáveis se necessário"
                                  ],
                                  "verification": "Dataset carregado, X e y prontos como DataFrames/arrays sem erros de shape incompatível.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python 3.x com Jupyter Notebook",
                                    "Bibliotecas: pandas, numpy, matplotlib, seaborn, statsmodels, scipy",
                                    "Dataset exemplo: concrete.csv"
                                  ],
                                  "tips": "Use pd.read_csv() com index_col para facilitar; sempre verifique shapes com .shape.",
                                  "learningObjective": "Preparar ambiente computacional e dados limpos para modelagem de regressão linear.",
                                  "commonMistakes": [
                                    "Esquecer de importar statsmodels.api como sm",
                                    "Não tratar NaN values com dropna() ou imputação",
                                    "Confundir X e y na definição"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar modelo de regressão linear e extrair resíduos",
                                  "subSteps": [
                                    "Adicionar constante a X com sm.add_constant(X)",
                                    "Ajustar modelo OLS: model = sm.OLS(y, X).fit()",
                                    "Extrair resíduos: residuals = model.resid",
                                    "Verificar summary do modelo para R-squared e p-values",
                                    "Salvar resíduos em uma Series com índice temporal se aplicável"
                                  ],
                                  "verification": "Modelo ajustado com residuals como array/Series de tamanho igual a n_amostras.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código Python do Step 1",
                                    "statsmodels.formula.api ou sm.OLS"
                                  ],
                                  "tips": "Use model.summary() para diagnóstico inicial; armazene model em variável para reutilização.",
                                  "learningObjective": "Implementar regressão OLS e isolar resíduos para análise diagnóstica.",
                                  "commonMistakes": [
                                    "Esquecer sm.add_constant() causando erro de intercepto",
                                    "Usar .predict() em vez de .resid",
                                    "Ignorar multicolinearidade em X"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir Q-Q Plot para avaliar normalidade dos resíduos",
                                  "subSteps": [
                                    "Importar from scipy import stats",
                                    "Gerar Q-Q plot: stats.probplot(residuals, dist='norm', plot=plt)",
                                    "Customizar: adicionar plt.title('Q-Q Plot de Resíduos'), plt.xlabel('Quantis Teóricos'), plt.ylabel('Quantis Amostra')",
                                    "Adicionar linha de referência: line = stats.probplot(residuals, dist='norm')[1]; plt.plot(line[0], line[1], 'r--')",
                                    "Salvar figura: plt.savefig('qq_plot.png')"
                                  ],
                                  "verification": "Q-Q plot gerado com linha vermelha de referência e salvo sem erros.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Resíduos do Step 2",
                                    "Matplotlib e SciPy"
                                  ],
                                  "tips": "Use dist='norm' para normalidade; zoom nas caudas para desvios.",
                                  "learningObjective": "Visualizar e interpretar desvios da normalidade via Q-Q plot.",
                                  "commonMistakes": [
                                    "Não plotar linha de referência, dificultando julgamento",
                                    "Usar histograma em vez de Q-Q para normalidade",
                                    "Ignorar labels nos eixos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir Gráfico de Autocorrelação (ACF) dos resíduos",
                                  "subSteps": [
                                    "Importar from statsmodels.tsa.stattools import acf",
                                    "Calcular ACF: acf_values = acf(residuals, nlags=20, alpha=0.05)",
                                    "Plotar: from statsmodels.graphics.tsaplots import plot_acf; plot_acf(residuals, lags=20, ax=plt.gca())",
                                    "Customizar: plt.title('ACF de Resíduos'), plt.xlabel('Lags'), plt.ylabel('Autocorrelação')",
                                    "Salvar: plt.savefig('acf_plot.png')"
                                  ],
                                  "verification": "ACF plot com bandas de confiança e sem picos significativos além delas (se modelo bom).",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Resíduos do Step 2",
                                    "statsmodels.tsa"
                                  ],
                                  "tips": "Defina lags= min(20, n/5) para evitar overfitting; foque em lags iniciais.",
                                  "learningObjective": "Detectar autocorrelação serial nos resíduos via ACF.",
                                  "commonMistakes": [
                                    "Usar lags excessivos para poucos dados",
                                    "Confundir ACF com PACF",
                                    "Não incluir bandas de confiança (alpha=0.05)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar gráficos e diagnosticar violações dos pressupostos",
                                  "subSteps": [
                                    "Analisar Q-Q: verificar alinhamento linear, desvios nas caudas indicam não-normalidade",
                                    "Analisar ACF: picos fora das bandas azuis indicam autocorrelação",
                                    "Documentar achados: 'Resíduos normais? Independentes?'",
                                    "Sugerir ações: log-transform y se não-normal; incluir lags se autocorr.",
                                    "Gerar relatório em Markdown ou notebook cell"
                                  ],
                                  "verification": "Relatório escrito com conclusões claras sobre violações.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Gráficos dos Steps 3-4",
                                    "Notebook Jupyter"
                                  ],
                                  "tips": "Compare com testes formais como Shapiro-Wilk para corroborar.",
                                  "learningObjective": "Diagnosticar e propor soluções para violações de normalidade e independência.",
                                  "commonMistakes": [
                                    "Interpretar visualmente sem considerar tamanho amostral",
                                    "Ignorar autocorr. em dados não-temporais",
                                    "Não propor correções específicas"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia civil, ajuste regressão linear para prever resistência à compressão de concreto usando features como quantidade de cimento (kg/m³), água e idade (dias). Extraia resíduos, gere Q-Q plot (verifica normalidade para inferências válidas) e ACF (detecta dependência serial em testes sequenciais), diagnosticando se o modelo atende pressupostos para designs seguros de estruturas.",
                              "finalVerifications": [
                                "Q-Q plot exibe pontos alinhados à linha diagonal com desvios mínimos nas caudas",
                                "ACF plot mostra todas autocorrelações dentro das bandas de 95% confiança",
                                "Gráficos incluem títulos, labels e linhas de referência adequados",
                                "Relatório identifica corretamente ausência/presença de violações",
                                "Código reproduzível gera os mesmos plots sem erros",
                                "Resíduos centrados em zero com variância constante visualmente"
                              ],
                              "assessmentCriteria": [
                                "Implementação precisa dos plots Q-Q e ACF usando bibliotecas corretas",
                                "Qualidade visual: legibilidade, customizações e salvamento de figuras",
                                "Interpretação precisa: ligação visual com pressupostos de normalidade e independência",
                                "Tratamento adequado de dados e modelo OLS sem erros comuns",
                                "Relatório diagnóstico claro, com sugestões acionáveis",
                                "Eficiência temporal e código limpo/ comentado"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de normalidade (Shapiro-Wilk) e Ljung-Box para autocorr.",
                                "Programação Computacional: Python para visualização de dados (matplotlib/seaborn)",
                                "Engenharia de Dados: pré-processamento e modelagem preditiva em contextos reais",
                                "Análise de Séries Temporais: extensão do ACF para modelagem ARIMA se violações",
                                "Matemática Aplicada: propriedades assintóticas de mínimos quadrados"
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, visualize resíduos de modelo prevendo vibrações em asas de aeronaves baseadas em velocidade e ângulo de ataque; Q-Q e ACF detectam violações, garantindo previsões confiáveis para certificação de segurança e evitando falhas catastróficas em voo."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.4",
                    "name": "Propriedades Estatísticas dos Estimadores MQO",
                    "description": "Características como insesgadez, consistência, eficiência e propriedades assintóticas dos coeficientes estimados.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.4.1",
                        "name": "Insesgadez dos Estimadores MQO",
                        "description": "A insesgadez refere-se à propriedade pela qual o valor esperado dos estimadores de mínimos quadrados ordinários (MQO) é igual ao verdadeiro valor dos parâmetros populacionais, sob os pressupostos clássicos lineares da regressão.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.1.1",
                            "name": "Definir insesgadez em estimadores",
                            "description": "Explicar o conceito de insesgadez como E(β̂) = β, onde β̂ é o estimador MQO e β o parâmetro verdadeiro, no contexto de regressão linear simples e múltipla aplicada à análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Básicos de Estimadores e Expectativa Matemática",
                                  "subSteps": [
                                    "Revise a definição de um estimador: uma função dos dados amostrais que estima um parâmetro populacional.",
                                    "Entenda a expectativa matemática E(X) como o valor médio populacional de uma variável aleatória X.",
                                    "Diferencie expectativa condicional E(β̂ | X) e incondicional E(β̂), destacando que para insesgadez usamos a incondicional.",
                                    "Estude o modelo de regressão linear simples: Y = β₀ + β₁X + ε, com E(ε) = 0.",
                                    "Identifique β̂₀ e β̂₁ como estimadores MQO."
                                  ],
                                  "verification": "Resuma em suas palavras os conceitos de estimador e expectativa, e escreva a fórmula do modelo de regressão simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de Econometria ou Estatística (capítulo de regressão)",
                                    "Caderno para anotações",
                                    "Calculadora"
                                  ],
                                  "tips": "Use analogias: pense na expectativa como o 'centro de massa' de uma distribuição de probabilidades.",
                                  "learningObjective": "Dominar os fundamentos teóricos necessários para a definição de insesgadez.",
                                  "commonMistakes": [
                                    "Confundir expectativa condicional com incondicional",
                                    "Ignorar que ε é uma variável aleatória com média zero"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir Formalmente a Insesgadez de um Estimador",
                                  "subSteps": [
                                    "Escreva a definição: Um estimador β̂ é insesgado se E(β̂) = β para todo β verdadeiro.",
                                    "Explique que isso significa que, em média, sobre repetidas amostras, β̂ equals β.",
                                    "Discuta insesgadez para β̂₀ e β̂₁ individualmente.",
                                    "Relacione com o viés: Viés = E(β̂) - β; insesgado se viés = 0.",
                                    "Visualize com um diagrama: centro da distribuição de β̂ coincide com β."
                                  ],
                                  "verification": "Escreva a definição matemática exata e explique verbalmente para um colega fictício.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Folha de papel para diagrama",
                                    "Software de desenho simples (ex: Draw.io)"
                                  ],
                                  "tips": "Memorize a fórmula E(β̂) = β como mantra; pratique escrevendo-a 10 vezes.",
                                  "learningObjective": "Capacitar-se a enunciar precisamente o conceito de insesgadez.",
                                  "commonMistakes": [
                                    "Definir insesgadez como Var(β̂) = 0 (isso é consistência)",
                                    "Esquecer que vale para todo β"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar a Insesgadez dos Estimadores MQO na Regressão Linear",
                                  "subSteps": [
                                    "Lembre os pressupostos clássicos: linearidade, exogeneidade estrita (E(ε|X)=0), homocedasticidade (não necessária para insesgadez).",
                                    "Derive E(β̂₁) = β₁: β̂₁ = Σ(Y_i - Ȳ)(X_i - X̄)/Σ(X_i - X̄)²; substitua Y_i e simplifique.",
                                    "Mostre E(β̂₀) = β₀ similarmente.",
                                    "Estenda para regressão múltipla: β̂ = (X'X)^{-1}X'Y; prove E(β̂) = β sob E(ε)=0.",
                                    "Simule numericamente em Python/R para verificar."
                                  ],
                                  "verification": "Complete a derivação em um papel e rode uma simulação simples confirmando E(β̂) ≈ β.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python ou R com bibliotecas statsmodels/sklearn",
                                    "Dataset simulado (gerar 1000 amostras)"
                                  ],
                                  "tips": "Na derivação, isole os termos de ε e use E(ε)=0; pratique com regressão simples primeiro.",
                                  "learningObjective": "Provar matematicamente a insesgadez sob os pressupostos MQO.",
                                  "commonMistakes": [
                                    "Esquecer de condicionar em X na expectativa",
                                    "Não simplificar corretamente os somatórios"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Verificar Insesgadez em Contextos de Engenharia",
                                  "subSteps": [
                                    "Aplique a dados reais de engenharia: ex., prever resistência de materiais vs. temperatura.",
                                    "Estime MQO e compare médias de múltiplas amostras simuladas com β verdadeiro.",
                                    "Discuta violações: se E(ε|X) ≠ 0, insesgadez falha (endogeneidade).",
                                    "Compare com outros estimadores (ex: média amostral para μ).",
                                    "Documente achados em um relatório curto."
                                  ],
                                  "verification": "Gere relatório com simulações mostrando E(β̂) próximo a β em 1000 runs.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Dataset de engenharia (ex: de Kaggle sobre materiais)"
                                  ],
                                  "tips": "Use np.mean(bootstrap_estimates) para aproximar E(β̂); aumente amostras para precisão.",
                                  "learningObjective": "Integrar teoria com prática em análise de dados de engenharia.",
                                  "commonMistakes": [
                                    "Usar poucos simulations (precisa ≥500 para boa aproximação)",
                                    "Ignorar pressupostos na aplicação real"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia mecânica, para prever a tensão (Y) em uma viga baseada na carga aplicada (X), ajuste MQO: Y = β₀ + β₁X + ε. Simule 1000 datasets com β₁=0.5 verdadeiro; calcule β̂₁ médio ≈0.5, confirmando insesgadez e garantindo previsões imparciais para design seguro.",
                              "finalVerifications": [
                                "Explique verbalmente a definição E(β̂)=β com exemplo numérico.",
                                "Derive corretamente E(β̂₁) para regressão simples em <5 minutos.",
                                "Simule em software e mostre E(β̂) ≈ β em múltiplas runs.",
                                "Identifique quando insesgadez falha (ex: endogeneidade).",
                                "Aplique a um dataset real de engenharia e interprete.",
                                "Diferencie insesgadez de consistência e eficiência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição formal (100% match com E(β̂)=β).",
                                "Correção na derivação matemática (sem erros algébricos).",
                                "Qualidade da simulação prática (média de β̂ dentro de 1% de β).",
                                "Compreensão de pressupostos e violações.",
                                "Clareza na explicação oral/escrita.",
                                "Relevância ao contexto de engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Expectativa e propriedades de variáveis aleatórias.",
                                "Programação: Simulações em Python/R para verificação empírica.",
                                "Engenharia: Modelagem preditiva em análise de falhas materiais.",
                                "Econometria: Extensão para modelos causais em dados observacionais."
                              ],
                              "realWorldApplication": "Na engenharia civil, estimadores insesgados MQO garantem que modelos de regressão para prever deformação de estruturas sob carga sejam confiáveis em média, evitando sub ou superestimação de riscos e otimizando designs sustentáveis."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.1.2",
                            "name": "Provar insesgadez sob pressupostos clássicos",
                            "description": "Derivar matematicamente a insesgadez dos estimadores MQO assumindo exogeneidade dos regressores (E(ε|X) = 0) e linearidade no parâmetro, utilizando matrizes e propriedades de esperança condicional.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Estabelecer o modelo linear e pressupostos clássicos",
                                  "subSteps": [
                                    "Defina o modelo de regressão linear: Y = Xβ + ε, onde Y é n×1, X é n×k com primeira coluna de 1s, β é k×1, ε é n×1.",
                                    "Liste os pressupostos: (i) Linearidade condicional em parâmetros: E(Y|X) = Xβ; (ii) Exogeneidade: E(ε|X) = 0.",
                                    "Explique que esses implicam esperança não condicional E(ε) = 0 e Cov(X, ε) = 0.",
                                    "Verifique dimensionalidade das matrizes para consistência.",
                                    "Anote que X é não estocástico ou condicionado sobre X para a prova."
                                  ],
                                  "verification": "Escreva o modelo e pressupostos em notação matricial correta sem erros dimensionais.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Quadro ou papel para anotações",
                                    "Livro de referência como Wooldridge 'Introdução à Econometria' Capítulo 3"
                                  ],
                                  "tips": "Sempre condicione sobre X para tratar regressores como fixos na amostra.",
                                  "learningObjective": "Compreender e articular os pressupostos fundamentais para insesgadez MQO.",
                                  "commonMistakes": "Confundir exogeneidade estrita (E(ε|X)=0) com E(ε)=0; ignorar a coluna de 1s em X."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a fórmula do estimador MQO",
                                  "subSteps": [
                                    "Minimize a soma de quadrados: S(β) = (Y - Xβ)'(Y - Xβ).",
                                    "Tome derivada matricial: ∂S/∂β = -2X'(Y - Xβ) = 0.",
                                    "Resolva para β: β_hat = (X'X)^{-1} X'Y, assumindo X'X invertível.",
                                    "Confirme que é o mínimo via segunda derivada: 2X'X positiva definida.",
                                    "Escreva em termos compactos."
                                  ],
                                  "verification": "Derive β_hat a partir da minimização e verifique invertibilidade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora matricial ou software como MATLAB/R",
                                    "Tabela de derivadas matriciais"
                                  ],
                                  "tips": "Lembre que derivada de (Y - Xβ)'(Y - Xβ) w.r.t. β é -2X'(Y - Xβ).",
                                  "learningObjective": "Derivar o estimador MQO via otimização matricial.",
                                  "commonMistakes": "Esquecer o fator -2 na derivada ou inverter incorretamente para β_hat."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Expressar β_hat em termos de β e ε",
                                  "subSteps": [
                                    "Substitua Y = Xβ + ε na fórmula: β_hat = (X'X)^{-1} X'(Xβ + ε).",
                                    "Distribua: β_hat = (X'X)^{-1} (X'X β + X'ε) = β + (X'X)^{-1} X'ε.",
                                    "Identifique o termo de viés: (X'X)^{-1} X'ε.",
                                    "Note que β é constante (parâmetro verdadeiro).",
                                    "Verifique algebraicamente a expansão."
                                  ],
                                  "verification": "Mostre β_hat = β + (X'X)^{-1} X'ε corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel para álgebra matricial"
                                  ],
                                  "tips": "Use propriedades distributivas de X' sobre soma.",
                                  "learningObjective": "Reescrever o estimador para isolar o erro.",
                                  "commonMistakes": "Erro na distribuição: esquecer X'X β ou mal posicionar parênteses."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular a esperança condicional E(β_hat | X)",
                                  "subSteps": [
                                    "Tome E(β_hat | X) = E[β + (X'X)^{-1} X'ε | X].",
                                    "Pela linearidade da esperança: E(β | X) + (X'X)^{-1} X' E(ε | X), pois X fixo.",
                                    "E(β | X) = β (constante); E(ε | X) = 0 pelo pressuposto.",
                                    "Logo, E(β_hat | X) = β + (X'X)^{-1} X' * 0 = β.",
                                    "Conclua insesgadez condicional, implicando não condicional."
                                  ],
                                  "verification": "Derive E(β_hat | X) = β passo a passo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Notas sobre propriedades de esperança condicional",
                                    "Exemplo numérico simples para validar"
                                  ],
                                  "tips": "Condicione sempre sobre X; esperança de constante é ela mesma.",
                                  "learningObjective": "Aplicar propriedades de esperança para provar insesgadez.",
                                  "commonMistakes": "Tomar E incondicional cedo demais ou assumir E(X'ε)=0 sem condicionar."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar e generalizar a prova",
                                  "subSteps": [
                                    "Discuta necessidade de rank(X)=k para invertibilidade.",
                                    "Note que insesgadez é condicional; válida em amostras grandes.",
                                    "Considere extensão para sem intercepto ou múltiplos regressores.",
                                    "Compare com prova escalar para regressão simples.",
                                    "Resuma os passos chave da prova."
                                  ],
                                  "verification": "Explique condições adicionais e generalize corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Exemplo de regressão simples Y=β0 + β1 X + ε"
                                  ],
                                  "tips": "Sempre verifique rank e dimensionalidade no final.",
                                  "learningObjective": "Entender limitações e extensões da prova de insesgadez.",
                                  "commonMistakes": "Ignorar multicolinearidade perfeita que viola invertibilidade."
                                }
                              ],
                              "practicalExample": "Considere regressão simples: Y_i = β0 + β1 X_i + ε_i, n=100. Calcule β_hat1 = (∑(X_i - Xbar)(Y_i - Ybar))/∑(X_i - Xbar)^2. Substitua Y_i, tome E(β_hat1 | X) = β1 + [cov term] E(ε|X)=β1, provando insesgadez.",
                              "finalVerifications": [
                                "Deriva corretamente β_hat = (X'X)^{-1} X'Y.",
                                "Mostra β_hat = β + (X'X)^{-1} X'ε.",
                                "Calcula E(β_hat | X) = β usando E(ε|X)=0.",
                                "Identifica pressupostos chave: linearidade e exogeneidade.",
                                "Discute invertibilidade de X'X.",
                                "Generaliza para k regressores."
                              ],
                              "assessmentCriteria": [
                                "Precisão algébrica em todas as derivações matriciais (sem erros dimensionais).",
                                "Correta aplicação de esperança condicional E(·|X).",
                                "Clareza na identificação de pressupostos e seu uso.",
                                "Tratamento adequado de invertibilidade e rank(X).",
                                "Capacidade de generalizar para casos simples/escalares.",
                                "Ausência de confusão entre condicional e não condicional."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Operações matriciais, invertibilidade, derivadas.",
                                "Probabilidade: Esperança condicional, propriedades lineares.",
                                "Econometria: Modelos de regressão e violações de pressupostos.",
                                "Estatística: Propriedades amostrais de estimadores.",
                                "Programação: Implementar MQO em R/Python para simular insesgadez."
                              ],
                              "realWorldApplication": "Em análise de dados econômicos, como estimar impacto de educação no salário via regressão, a insesgadez garante que β_hat converge para o verdadeiro efeito em amostras grandes, essencial para políticas públicas confiáveis."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.1.3",
                            "name": "Interpretar violações de insesgadez",
                            "description": "Analisar cenários em engenharia onde a insesgadez falha, como endogeneidade em modelos de sistemas dinâmicos, e discutir impactos em previsões de desempenho de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar definição de insesgadez e condições necessárias em MQO",
                                  "subSteps": [
                                    "Explicar que insesgadez significa E[β̂] = β verdadeiros.",
                                    "Listar condições: exogeneidade estrita (Cov(x, ε) = 0), sem variáveis omitidas relevantes, homocedasticidade (não estrita para insesgadez).",
                                    "Derivar matematicamente a expectativa do estimador MQO sob condições ideais.",
                                    "Discutir por que violações levam a E[β̂] ≠ β.",
                                    "Identificar cenários iniciais de violação como endogeneidade."
                                  ],
                                  "verification": "Capacidade de derivar e explicar a fórmula de insesgadez em um quadro branco ou documento.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Livro de Econometria (ex: Wooldridge), Python com statsmodels, quadro branco.",
                                  "tips": "Use notação matricial para clareza: β̂ = (X'X)^(-1)X'y.",
                                  "learningObjective": "Compreender fundamentos teóricos da insesgadez para detectar violações.",
                                  "commonMistakes": "Confundir insesgadez com consistência ou eficiência."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar violações específicas, focando endogeneidade em sistemas dinâmicos",
                                  "subSteps": [
                                    "Definir endogeneidade: correlação entre regressores e erro (Cov(x, ε) ≠ 0).",
                                    "Exemplificar em sistemas dinâmicos: inclusão de lags (y_{t-1}) causa endogeneidade por feedback.",
                                    "Simular dados com endogeneidade usando Python: gerar y_t = β x_t + ρ y_{t-1} + ε_t.",
                                    "Testar diagnósticos: Hausman ou Durbin-Watson para autocorrelação.",
                                    "Classificar outras violações: variáveis omitidas, measurement error."
                                  ],
                                  "verification": "Gerar simulação em Python mostrando E[β̂] ≠ β.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python/Jupyter Notebook com numpy, pandas, statsmodels; dataset sintético.",
                                  "tips": "Comece com ρ pequeno (0.3) para observar viés sutil.",
                                  "learningObjective": "Reconhecer endogeneidade em modelos dinâmicos de engenharia.",
                                  "commonMistakes": "Ignorar lags como fonte de endogeneidade em processos sequenciais."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar impactos das violações em previsões de desempenho",
                                  "subSteps": [
                                    "Explicar viés ascendente/descendente: em endogeneidade positiva, β̂ superestima β.",
                                    "Calcular previsões enviesadas: ŷ = X β̂ leva a erros sistemáticos.",
                                    "Quantificar impacto: decompor viés via Plim(β̂ - β) = (E[X'X])^(-1) E[X'ε].",
                                    "Discutir em contexto de processos: previsões erradas de yield levam a decisões ruins.",
                                    "Comparar MQO enviesado vs. métodos corrigidos (IV, GMM)."
                                  ],
                                  "verification": "Produzir gráfico comparando previsões MQO vs. verdadeiras em simulação.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Python com matplotlib para plots, calculadora matricial.",
                                  "tips": "Use loop temporal para simular múltiplas runs e médias.",
                                  "learningObjective": "Avaliar consequências práticas das violações em engenharia.",
                                  "commonMistakes": "Subestimar propagação de viés em previsões de longo prazo."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar análise em cenários de engenharia e propor discussões",
                                  "subSteps": [
                                    "Aplicar a processo real: modelar desempenho de reator químico com lags endógenos.",
                                    "Discutir impactos: superestimação de eficiência leva a investimentos errados.",
                                    "Propor soluções: variáveis instrumentais (ex: choques exógenos), modelos VAR.",
                                    "Redigir relatório curto: 'cenário, violação, impacto, recomendação'.",
                                    "Debater limitações: trade-off viés-variância."
                                  ],
                                  "verification": "Escrever parágrafo coeso explicando um cenário completo.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Artigo acadêmico sobre MQO em engenharia, editor de texto.",
                                  "tips": "Estruture como 'Problema > Causa > Efeito > Solução'.",
                                  "learningObjective": "Integrar teoria a aplicações práticas em processos.",
                                  "commonMistakes": "Focar só em teoria sem ligar a engenharia."
                                }
                              ],
                              "practicalExample": "Em uma planta de produção química, modelar rendimento (y) como função de temperatura (x1) e pressão ajustada por yields anteriores (x2 lagged). Endogeneidade surge porque pressão responde a erros passados, violando insesgadez: MQO superestima impacto da temperatura, levando a previsões de 10% acima do real e desperdício de energia.",
                              "finalVerifications": [
                                "Explica corretamente endogeneidade em sistemas dinâmicos.",
                                "Identifica pelo menos 3 violações comuns de insesgadez.",
                                "Quantifica impacto em previsões com exemplo numérico.",
                                "Propõe pelo menos uma correção válida (ex: IV).",
                                "Discute aplicação em engenharia de processos.",
                                "Simula dados mostrando viés."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (correta definição e derivação).",
                                "Profundidade de análise (impactos quantificados).",
                                "Uso de terminologia técnica adequada (ex: exogeneidade estrita).",
                                "Relevância ao contexto de engenharia.",
                                "Criatividade em exemplos práticos.",
                                "Clareza na comunicação escrita/oral."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: testes de endogeneidade (Hausman).",
                                "Engenharia de Controle: modelos ARMAX dinâmicos.",
                                "Estatística Computacional: simulações Monte Carlo.",
                                "Ciência de Dados: machine learning com causalidade (DoWhy)."
                              ],
                              "realWorldApplication": "Na otimização de processos industriais, como previsão de desempenho em fábricas de semicondutores, onde ignorar endogeneidade em loops de feedback resulta em modelos que superestimam eficiência, causando alocações ineficientes de recursos e falhas em metas de produção."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.4.2",
                        "name": "Consistência dos Estimadores MQO",
                        "description": "A consistência indica que, à medida que o tamanho da amostra aumenta, os estimadores MQO convergem em probabilidade para os verdadeiros parâmetros populacionais.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.2.1",
                            "name": "Definir consistência em probabilidade",
                            "description": "Descrever plim(n→∞) β̂ = β, explicando convergência em probabilidade e sua relevância em grandes amostras de dados de engenharia, como sensores em sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Básicos de Convergência em Probabilidade",
                                  "subSteps": [
                                    "Revise a definição de uma sequência de variáveis aleatórias convergindo em probabilidade para um valor constante.",
                                    "Estude a noção de probabilidade convergindo para 1 à medida que n aumenta.",
                                    "Diferencie convergência em probabilidade de convergência quase certa e em distribuição.",
                                    "Explore exemplos simples, como a Lei dos Grandes Números.",
                                    "Discuta o papel do tamanho da amostra n no processo de convergência."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre convergência em probabilidade e convergência em média quadrática, com um exemplo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de Estatística Assintótica (ex: Asymptotic Statistics de Van der Vaart), notas de aula sobre inferência estatística.",
                                  "tips": "Use diagramas de Venn para visualizar os tipos de convergência.",
                                  "learningObjective": "Compreender a definição formal e intuitiva de convergência em probabilidade.",
                                  "commonMistakes": "Confundir convergência em probabilidade com convergência determinística."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Dominar a Notação plim e Sua Aplicação aos Estimadores",
                                  "subSteps": [
                                    "Aprenda a notação plim(n→∞) X_n = c, significando que P(|X_n - c| > ε) → 0 para todo ε > 0.",
                                    "Aplique isso ao estimador β̂ em regressão linear simples: plim(n→∞) β̂ = β.",
                                    "Derive intuitivamente por que isso ocorre sob suposições padrão do MQO (ex: exogeneidade, homocedasticidade).",
                                    "Pratique reescrevendo a definição em termos de probabilidades limite.",
                                    "Resolva exercícios analíticos para estimadores consistentes."
                                  ],
                                  "verification": "Escreva a definição formal de plim(n→∞) β̂ = β e prove-a para um caso simples de regressão sem intercepto.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Apostila de Econometria (ex: Wooldridge), calculadora simbólica como SymPy.",
                                  "tips": "Memorize a estrutura: 'para todo ε > 0, P(|β̂ - β| > ε) → 0 quando n → ∞'.",
                                  "learningObjective": "Definir e notate corretamente a consistência em probabilidade para estimadores MQO.",
                                  "commonMistakes": "Esquecer o 'para todo ε > 0' na definição formal."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar as Condições e Provas de Consistência no MQO",
                                  "subSteps": [
                                    "Liste as suposições de Gauss-Markov estendidas necessárias para consistência (ex: E[ε|X] = 0, Var(ε|X) < ∞).",
                                    "Derive a consistência usando a decomposição β̂ - β = (X'X/n)^{-1}(X'ε/n).",
                                    "Analise o comportamento assintótico de X'X/n → Q (matriz não-singular) e X'ε/n → 0 em probabilidade.",
                                    "Simule numericamente em software para visualizar a convergência.",
                                    "Discuta violações comuns, como endogeneidade, que quebram a consistência."
                                  ],
                                  "verification": "Simule uma regressão linear com n=1000 e verifique se |β̂ - β| < 0.01 com alta probabilidade.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python com NumPy, SciPy e Matplotlib; dataset sintético de regressão.",
                                  "tips": "Aumente n iterativamente (10, 100, 1000) para plotar a evolução de β̂.",
                                  "learningObjective": "Explicar as condições matemáticas que garantem plim β̂ = β.",
                                  "commonMistakes": "Ignorar a necessidade de normalizar por n em X'X/n."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar à Relevância em Grandes Amostras de Engenharia",
                                  "subSteps": [
                                    "Contextualize com dados de sensores em sistemas de controle, onde n é grande (milhares de leituras).",
                                    "Discuta como a consistência justifica o uso de MQO em calibração de modelos com big data.",
                                    "Analise um exemplo: estimar parâmetros de um modelo de controle PID a partir de dados de sensores.",
                                    "Avalie limitações em amostras finitas e estratégias de mitigação.",
                                    "Conecte à prática: por que grandes n em IoT/engenharia garante estimativas confiáveis."
                                  ],
                                  "verification": "Descreva um cenário de engenharia onde a consistência é crucial e justifique com plim.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Artigos sobre análise de dados em engenharia de controle, dataset real de sensores (ex: Kaggle).",
                                  "tips": "Pense em aplicações reais como monitoramento de temperatura em plantas industriais.",
                                  "learningObjective": "Relacionar consistência em probabilidade a aplicações práticas em engenharia.",
                                  "commonMistakes": "Superestimar a precisão em amostras pequenas apesar da consistência assintótica."
                                }
                              ],
                              "practicalExample": "Simule em Python uma regressão linear Y = β0 + β1 X + ε, com β1=2, n=10000 pontos de X~N(0,1), ε~N(0,1). Estime β̂1 via MQO e plote histogramas de β̂1 para n=100, 1000, 10000, mostrando convergência para 2. Em um contexto de engenharia, X representa leituras de sensores de tensão, Y de corrente em um sistema de controle.",
                              "finalVerifications": [
                                "Defina corretamente plim(n→∞) β̂ = β sem erros na notação.",
                                "Explique as suposições chave para consistência do MQO.",
                                "Simule e demonstre numericamente a convergência em um exemplo com n>5000.",
                                "Identifique cenários onde a consistência falha (ex: endogeneidade).",
                                "Relacione à relevância em dados de sensores de engenharia.",
                                "Diferencie consistência de não-viés e eficiência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição formal de convergência em probabilidade (90%+ correto).",
                                "Correta derivação assintótica de β̂ (incluindo normalização por n).",
                                "Qualidade da simulação numérica (gráficos mostram convergência clara).",
                                "Profundidade na discussão de aplicações em engenharia (2+ exemplos concretos).",
                                "Identificação de pelo menos 3 erros comuns e como evitá-los.",
                                "Conexões interdisciplinares bem articuladas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Ligação com teoremas limite centrais.",
                                "Engenharia de Controle: Calibração de modelos com dados de sensores em tempo real.",
                                "Machine Learning: Consistência em regressão como base para algoritmos de aprendizado supervisionado.",
                                "Computação Científica: Simulações Monte Carlo para verificação assintótica."
                              ],
                              "realWorldApplication": "Em sistemas de controle industrial, como monitoramento de sensores IoT em turbinas eólicas, grandes amostras (n>10^5) de dados de vibração permitem estimar parâmetros β de modelos de falha via MQO com plim β̂=β, garantindo previsões confiáveis para manutenção preditiva e otimizando downtime em milhões de dólares."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.2.2",
                            "name": "Provar consistência sob pressupostos fracos",
                            "description": "Demonstrar a consistência utilizando a lei dos grandes números e assumindo ergodicidade e homocedasticidade condicional fraca, com aplicações em regressões com grandes datasets.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Fracos para Consistência",
                                  "subSteps": [
                                    "Defina ergodicidade: processo estocástico onde médias amostrais convergem para expectativas.",
                                    "Explique homocedasticidade condicional fraca: Var(ε_i | X_i) = σ² constante.",
                                    "Liste pressupostos mínimos: E[ε_i | X_i] = 0, independência fraca ou ergodicidade.",
                                    "Compare com pressupostos clássicos MQO (exogenidade estrita, homocedasticidade forte).",
                                    "Discuta relevância para grandes datasets onde violações são comuns."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras listando e justificando cada pressuposto.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Notas de aula sobre MQO, livro 'Introdução à Econometria' de Wooldridge (cap. 3).",
                                  "tips": "Use diagramas para visualizar ergodicidade como 'médias temporais = médias populacionais'.",
                                  "learningObjective": "Compreender os pressupostos mínimos necessários para consistência sem assumir normalidade ou i.i.d. forte.",
                                  "commonMistakes": "Confundir ergodicidade com estacionariedade; assumir i.i.d. quando só ergodicidade basta."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Expressar Estimador MQO como Média Amostral",
                                  "subSteps": [
                                    "Lembre o modelo Y_i = X_i' β + ε_i.",
                                    "Derive β_hat = (X'X/n)^{-1} (X'Y/n) = (média X'X)^{-1} (média X'Y).",
                                    "Mostre plim (X'X/n) = E[X_i X_i'] = Q (matriz de probabilidade positiva definida).",
                                    "Mostre plim (X'Y/n) = plim (X'(Xβ + ε)/n) = Q β + plim (X'ε/n).",
                                    "Identifique X'ε/n como média de X_i ε_i."
                                  ],
                                  "verification": "Derive algebricamente β_hat em termos de médias amostrais e verifique com n=100 simulado.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Lápis e papel, Python/Jupyter com NumPy para simulação básica.",
                                  "tips": "Normalize X para simplificar inversão; foque em notação plim.",
                                  "learningObjective": "Reformular β_hat para aplicação direta da Lei dos Grandes Números.",
                                  "commonMistakes": "Esquecer divisão por n em X'X/n; ignorar inversibilidade de Q."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Lei dos Grandes Números (LLN)",
                                  "subSteps": [
                                    "Enuncie LLN para variáveis ergodicas: plim (1/n ∑ Z_i) = E[Z_i].",
                                    "Aplique a Z_i = X_i X_i': plim X'X/n = E[X X'].",
                                    "Aplique a Z_i = X_i ε_i: sob E[ε|X]=0 e ergodicidade, plim X'ε/n = 0.",
                                    "Justifique homocedasticidade fraca para momentos finitos de X_i ε_i.",
                                    "Conclua plim β_hat = Q^{-1} (Q β + 0) = β."
                                  ],
                                  "verification": "Escreva a prova completa em LaTeX ou Markdown, com cada plim justificado.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Software LaTeX ou Overleaf, referência 'Asymptotic Theory for Econometricians' de Hamilton.",
                                  "tips": "Use Slutsky's theorem para plim (A_n^{-1} B_n) = (plim A_n)^{-1} plim B_n.",
                                  "learningObjective": "Provar consistência usando LLN sob pressupostos fracos.",
                                  "commonMistakes": "Aplicar LLN sem verificar ergodicidade; assumir independência forte."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Simular e Verificar em Grandes Datasets",
                                  "subSteps": [
                                    "Gere dados simulados: n=10^6, X ~ N(0,1), ε ~ N(0,1) condicional em X.",
                                    "Estime β_hat MQO e compare com β verdadeiro.",
                                    "Repita 1000 vezes, plote histograma de √n (β_hat - β).",
                                    "Teste violações: adicione heterocedasticidade fraca e verifique convergência.",
                                    "Discuta escalabilidade computacional para big data."
                                  ],
                                  "verification": "Produza gráfico mostrando convergência para β=0 à medida que n aumenta.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python (scikit-learn, matplotlib), dataset simulado ou Kaggle big data.",
                                  "tips": "Use vectorização NumPy para n grande; paralelize simulações com joblib.",
                                  "learningObjective": "Validar prova teórica empiricamente em contextos de big data.",
                                  "commonMistakes": "n muito pequeno (<10^4); não normalizar √n para visualizar taxa."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Explorar Aplicações e Limitações",
                                  "subSteps": [
                                    "Aplique em regressão real: dataset de房价 ou finanças com n>10^5.",
                                    "Discuta quando pressupostos falham (ex: dependência serial).",
                                    "Compare com métodos robustos (LAD, robust SE).",
                                    "Resuma prova em 1 página para comunicação.",
                                    "Identifique extensões: consistência em GMM ou ML."
                                  ],
                                  "verification": "Analise dataset real e escreva relatório de 1 página com achados.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Dataset público (UCI ML repo), R ou Python statsmodels.",
                                  "tips": "Comece com dados limpos; foque em interpretação prática.",
                                  "learningObjective": "Conectar teoria à prática em análise de dados reais.",
                                  "commonMistakes": "Ignorar multicolinearidade em dados reais; superestimar robustez."
                                }
                              ],
                              "practicalExample": "Em um dataset de 1 milhão de observações de salários (Y) vs. anos de educação (X), prove consistência de β_hat sob ergodicidade (amostras longitudinais simuladas) e homocedasticidade fraca (variância constante condicional). Simule: gere dados, estime β_hat, mostre |β_hat - β_true| < 0.01 para n grande.",
                              "finalVerifications": [
                                "Derivação completa da prova usando LLN sem erros algébricos.",
                                "Simulação converge para β verdadeiro com n>10^5.",
                                "Explicação clara de ergodicidade vs. i.i.d.",
                                "Identificação correta de papéis de homocedasticidade fraca.",
                                "Aplicação bem-sucedida em dataset real com relatório.",
                                "Resumo de 1 página comunicável a não-especialistas."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação de plim β_hat = β (90%+).",
                                "Profundidade de substeps em cada prova (mín. 4 por step).",
                                "Validade da simulação: convergência demonstrada graficamente.",
                                "Justificativa adequada dos pressupostos fracos.",
                                "Criatividade na aplicação real-world.",
                                "Clareza e organização do JSON/relatório final."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Lei dos Grandes Números e ergodicidade.",
                                "Estatística: Propriedades assintóticas de estimadores.",
                                "Machine Learning: Consistência em regressão linear de alto volume.",
                                "Econometria: Regressões com dados de painel ou time-series.",
                                "Computação: Simulações eficientes em big data (NumPy/Pandas)."
                              ],
                              "realWorldApplication": "Em análise de risco financeiro com milhões de transações diárias (ex: predizer retornos de ações), prova consistência garante que β_hat MQO convirja para parâmetros verdadeiros mesmo com ruído heterocedástico fraco, permitindo previsões confiáveis em trading algorítmico ou modelagem epidemiológica com dados de saúde pública massivos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.2.3",
                            "name": "Avaliar consistência em prática",
                            "description": "Simular em software (ex: R) o comportamento assintótico de estimadores MQO em cenários de engenharia, comparando estimativas em amostras crescentes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente R e definir modelo MQO teórico",
                                  "subSteps": [
                                    "Instalar e carregar pacotes necessários: ggplot2, dplyr para visualização e manipulação de dados.",
                                    "Definir o modelo linear teórico: Y = β0 + β1 X + ε, com valores verdadeiros β0=2, β1=3, ε ~ N(0,1).",
                                    "Escolher cenários de engenharia: ex. tensão (Y) vs. carga (X) em testes de materiais.",
                                    "Preparar script base com função lm() para MQO.",
                                    "Testar modelo com amostra pequena (n=10) para validar sintaxe."
                                  ],
                                  "verification": "Executar código sem erros e obter coeficientes próximos aos verdadeiros.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Pacotes: ggplot2, dplyr"
                                  ],
                                  "tips": "Use set.seed(123) para reprodutibilidade em simulações.",
                                  "learningObjective": "Compreender e configurar o framework teórico para simulação de MQO.",
                                  "commonMistakes": [
                                    "Esquecer de carregar pacotes",
                                    "Não definir seed para reprodutibilidade",
                                    "Usar dados não centrados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar dados simulados com tamanhos de amostra crescentes",
                                  "subSteps": [
                                    "Definir vetor de tamanhos de amostra: n = c(10, 50, 100, 500, 1000, 5000).",
                                    "Gerar X ~ Uniform(0,10) ou cenários reais como cargas em engenharia (0-100kN).",
                                    "Simular Y = 2 + 3*X + rnorm(n,0,1) para cada n.",
                                    "Salvar datasets em lista para reutilização.",
                                    "Visualizar scatterplots iniciais para cada n."
                                  ],
                                  "verification": "Datasets gerados corretamente, com dimensões verificadas via str() ou dim().",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Script R do Step 1"
                                  ],
                                  "tips": "Escolha X relevante para engenharia, como variáveis físicas mensuráveis.",
                                  "learningObjective": "Dominar geração de dados sintéticos que mimetizam cenários reais de engenharia.",
                                  "commonMistakes": [
                                    "Gerar X constante",
                                    "Erro na escala de ruído",
                                    "Não variar n corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar simulação Monte Carlo de MQO",
                                  "subSteps": [
                                    "Criar função que, para cada n, faz B=1000 réplicas: gera dados, aplica lm(), extrai coeficientes.",
                                    "Calcular para cada réplica: bias (β_hat - β_true), variância e MSE.",
                                    "Armazenar resultados em data.frame com colunas: n, replica, beta0_hat, beta1_hat, bias0, bias1.",
                                    "Executar função para todos n.",
                                    "Verificar tempo de computação e otimizar se necessário (ex: vectorização)."
                                  ],
                                  "verification": "Data.frame final com 1000*B linhas por n, sem NAs em coeficientes.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Scripts anteriores",
                                    "Computador com R otimizado"
                                  ],
                                  "tips": "Use replicate() ou loop paralelo (foreach) para acelerar Monte Carlo.",
                                  "learningObjective": "Implementar simulações assintóticas para demonstrar propriedades de estimadores.",
                                  "commonMistakes": [
                                    "Poucas réplicas (B<500)",
                                    "Não subtrair β_true corretamente",
                                    "Ignorar warnings de lm()"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar e visualizar convergência assintótica",
                                  "subSteps": [
                                    "Resumir por n: mean(bias), sd(β_hat), boxplots de distribuições.",
                                    "Criar plots: β_hat vs. n (scatter com LOESS), bias vs. log(n), variância vs. 1/n.",
                                    "Testar estatisticamente: t-test para bias=0 em n grandes.",
                                    "Interpretar: consistência se β_hat → β_true e variância → 0.",
                                    "Exportar gráficos como PNG/PDF."
                                  ],
                                  "verification": "Plots mostram convergência clara (bias próximo de 0, spreads estreitos para n grande).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Resultados do Step 3",
                                    "ggplot2"
                                  ],
                                  "tips": "Use facet_wrap(~n) para múltiplos plots; log-scale para n.",
                                  "learningObjective": "Interpretar evidências empíricas de consistência em MQO.",
                                  "commonMistakes": [
                                    "Escalas erradas nos plots",
                                    "Média errada de bias",
                                    "Ignorar variância"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar em cenário de engenharia realista e relatar",
                                  "subSteps": [
                                    "Adaptar para modelo com multicolinearidade leve (adicionar X2).",
                                    "Comparar com n pequeno vs. grande em contexto: prever falha estrutural.",
                                    "Calcular intervalos de confiança e cobertura.",
                                    "Escrever relatório curto: conclusões sobre consistência.",
                                    "Compartilhar código no GitHub ou relatório PDF."
                                  ],
                                  "verification": "Relatório explica como consistência afeta decisões de engenharia.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Todos scripts",
                                    "Ferramenta de relatório como R Markdown"
                                  ],
                                  "tips": "Relacione com normas de engenharia (ex. confiabilidade preditiva).",
                                  "learningObjective": "Aplicar simulação prática a problemas interdisciplinares.",
                                  "commonMistakes": [
                                    "Não contextualizar engenharia",
                                    "Relatório sem plots",
                                    "Código não reproduzível"
                                  ]
                                }
                              ],
                              "practicalExample": "Em testes de fadiga de vigas de aço, simule tensão (Y) vs. ciclos de carga (X). Com n=50, β1_hat=2.8 (bias=0.2); com n=5000, β1_hat=3.01 (bias=0.01), variância cai de 0.15 para 0.001, confirmando consistência para predições seguras.",
                              "finalVerifications": [
                                "Coeficientes MQO convergem para valores verdadeiros em plots vs. n.",
                                "Bias médio próximo de zero para n>1000.",
                                "Variância das estimativas diminui monotonicamente com n.",
                                "MSE total reduz para <0.01 em n grande.",
                                "Intervalos de confiança encolhem e cobrem β_true >95%.",
                                "Código reproduz resultados com set.seed().",
                                "Interpretação correta de assintótica em relatório."
                              ],
                              "assessmentCriteria": [
                                "Precisão da implementação Monte Carlo (B>=500 réplicas).",
                                "Qualidade dos plots: claros, legendados, escalas adequadas.",
                                "Correção matemática: fórmulas de bias/MSE aplicadas direito.",
                                "Contexto de engenharia integrado realisticamente.",
                                "Eficiência computacional (tempo <10min para simulações).",
                                "Relatório conciso com conclusões baseadas em evidências."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Uso avançado de R para simulações numéricas.",
                                "Estatística: Teorema do Limite Central e propriedades assintóticas.",
                                "Engenharia: Modelagem preditiva em mecânica dos materiais.",
                                "Visualização de Dados: ggplot2 para análise exploratória.",
                                "Computação Científica: Otimização de loops e paralelização."
                              ],
                              "realWorldApplication": "Em engenharia civil, simulações avaliam se modelos MQO com dados limitados (ex. sensores IoT) convergem para parâmetros reais de estruturas, garantindo predições confiáveis de vida útil e evitando falhas catastróficas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.4.3",
                        "name": "Eficiência dos Estimadores MQO",
                        "description": "A eficiência mede a precisão dos estimadores MQO, sendo eles os mais eficientes lineares não viesados sob os pressupostos de Gauss-Markov.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.3.1",
                            "name": "Explicar teorema de Gauss-Markov",
                            "description": "Enunciar e interpretar o teorema que estabelece a eficiência dos MQO como BLUE (Best Linear Unbiased Estimator) sob lineariedade, exogeneidade e homocedasticidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as Premissas do Modelo de Regressão Linear Clássico",
                                  "subSteps": [
                                    "Estude a premissa de lineariedade nos parâmetros: o modelo é E[Y|X] = Xβ.",
                                    "Analise a exogeneidade estrita: E[ε_i | X] = 0 para todo i.",
                                    "Explique homocedasticidade: Var(ε_i | X) = σ² para todo i, sem dependência de X.",
                                    "Discuta ausência de autocorrelação: Cov(ε_i, ε_j | X) = 0 para i ≠ j.",
                                    "Verifique esfericidade dos erros: combinação das duas últimas."
                                  ],
                                  "verification": "Liste e defina corretamente as quatro premissas principais em um papel ou documento.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Notas de regressão linear",
                                    "Livro de econometria (ex: Wooldridge)",
                                    "Slides sobre MQO"
                                  ],
                                  "tips": [
                                    "Use mnemônicos como 'LEHS' (Linearity, Exogeneity, Homoscedasticity, Spherical errors).",
                                    "Desenhe diagramas de resíduos para visualizar premissas."
                                  ],
                                  "learningObjective": "Identificar e descrever precisamente as premissas necessárias para o teorema.",
                                  "commonMistakes": [
                                    "Confundir exogeneidade com não-correlacionado.",
                                    "Ignorar a conditionalidade nas premissas.",
                                    "Pensar que homocedasticidade é sempre verdadeira."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Enunciar Formalmente o Teorema de Gauss-Markov",
                                  "subSteps": [
                                    "Defina o estimador MQO: β̂ = (X'X)^{-1}X'Y.",
                                    "Explique 'não-viesado': E[β̂] = β.",
                                    "Defina 'linear': β̂ é combinação linear de Y.",
                                    "Descreva 'melhor' como menor variância: Var(β̂) ≤ Var(β̃) para qualquer outro linear não-viesado β̃.",
                                    "Enuncie completo: Sob premissas, MQO é BLUE."
                                  ],
                                  "verification": "Escreva o enunciado formal do teorema, incluindo definições de BLUE.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Fórmulas de álgebra matricial",
                                    "Artigo ou wiki sobre Gauss-Markov"
                                  ],
                                  "tips": [
                                    "Memorize: Best Linear Unbiased Estimator.",
                                    "Pratique escrevendo em notação matricial."
                                  ],
                                  "learningObjective": "Enunciar o teorema com precisão matemática.",
                                  "commonMistakes": [
                                    "Omitir 'linear' na definição de BLUE.",
                                    "Confundir variância com viés.",
                                    "Esquecer que é condicional às premissas."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar a Prova Intuitiva e Formal do Teorema",
                                  "subSteps": [
                                    "Revise a variância de estimadores lineares: Var(β̃) = (C'X'X C)^{-1} C'X' Σ C (X'X C)^{-1}, mas simplificado.",
                                    "Mostre que para MQO, C = (X'X)^{-1}X, minimiza a variância.",
                                    "Use decomposição: qualquer β̃ = β̂ + Dε, onde D perpendicular a X.",
                                    "Demonstre que Var(Dε) ≥ 0, logo MQO tem menor variância.",
                                    "Simule numericamente em software para validar."
                                  ],
                                  "verification": "Resuma os passos chave da prova em bullet points.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software R ou Python (lm() ou statsmodels)",
                                    "Prova detalhada de Greene ou similar"
                                  ],
                                  "tips": [
                                    "Comece com prova escalar (simples regressão) antes de matricial.",
                                    "Use simulações para intuição visual."
                                  ],
                                  "learningObjective": "Compreender por que MQO minimiza variância entre lineares não-viesados.",
                                  "commonMistakes": [
                                    "Ignorar projeção ortogonal em X.",
                                    "Confundir prova com teorema de Cochrane-Orcutt.",
                                    "Pular passos matriciais."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Implicações e Aplicar o Teorema",
                                  "subSteps": [
                                    "Explique eficiência: menor variância significa intervalos de confiança mais estreitos.",
                                    "Discuta limitações: falha sob heterocedasticidade ou endogeneidade.",
                                    "Compare com GLS (Generalized LS) quando premissas falham.",
                                    "Aplique em exemplo: calcule variâncias de dois estimadores.",
                                    "Reflita: por que MQO é padrão inicial em regressão."
                                  ],
                                  "verification": "Explique em palavras próprias o que significa MQO ser BLUE.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Dados simulados para regressão",
                                    "Calculadora matricial online"
                                  ],
                                  "tips": [
                                    "Pense em termos de precisão: BLUE é o 'mais preciso' linear imparcial.",
                                    "Conecte a testes de hipóteses."
                                  ],
                                  "learningObjective": "Interpretar o teorema e suas consequências práticas.",
                                  "commonMistakes": [
                                    "Achar que MQO é sempre o melhor absoluto.",
                                    "Confundir eficiência com consistência.",
                                    "Ignorar que não garante normalidade."
                                  ]
                                }
                              ],
                              "practicalExample": "Considere Y = β0 + β1 X + ε, com n=100 observações simuladas sob premissas. O MQO β̂1 tem Var(β̂1) = σ² / Σ(x_i - x̄)^2. Um outro linear β̃1 = 0.5 β̂1 + 0.5 Ȳ terá maior variância, demonstrando que MQO é BLUE.",
                              "finalVerifications": [
                                "Enuncie corretamente o teorema e liste as premissas.",
                                "Explique BLUE em termos de viés e variância.",
                                "Resuma a prova em 3 passos principais.",
                                "Identifique cenários onde o teorema não se aplica.",
                                "Aplique em um exemplo numérico simples.",
                                "Discuta implicações para inferência estatística."
                              ],
                              "assessmentCriteria": [
                                "Precisão no enunciado formal (matemático correto).",
                                "Compreensão clara das premissas e sua conditionalidade.",
                                "Explicação intuitiva da prova com elementos matriciais.",
                                "Interpretação correta de eficiência e limitações.",
                                "Uso de exemplos práticos para ilustrar BLUE.",
                                "Conexão com aplicações reais em análise de dados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: propriedades assintóticas de estimadores.",
                                "Álgebra Linear: projeções ortogonais e variâncias matriciais.",
                                "Econometria: avaliação de causalidade e IV quando premissas falham.",
                                "Machine Learning: regressão linear como baseline eficiente.",
                                "Probabilidade: variância condicional e esfericidade."
                              ],
                              "realWorldApplication": "Em previsões econômicas, como estimar o impacto do PIB no desemprego usando MQO garante estimadores com menor variância, levando a políticas públicas mais confiáveis, desde que dados atendam lineariedade, exogeneidade e homocedasticidade."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.3.2",
                            "name": "Calcular variância dos estimadores",
                            "description": "Derivar a matriz de covariância Var(β̂) = σ² (X'X)^(-1) e comparar eficiência com outros estimadores lineares em contextos de modelagem de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o modelo de regressão linear e o estimador MQO",
                                  "subSteps": [
                                    "Relembre o modelo Y = Xβ + ε, onde ε ~ N(0, σ²I).",
                                    "Identifique β̂ = (X'X)^{-1}X'Y como o estimador de Mínimos Quadrados Ordinários (MQO).",
                                    "Verifique as premissas Gauss-Markov: linearidade, exogeneidade, homocedasticidade e não-colinearidade.",
                                    "Escreva a matriz X com a coluna de 1s para o intercepto.",
                                    "Discuta por que β̂ é não-viesado: E(β̂) = β."
                                  ],
                                  "verification": "Escreva o modelo e prove que E(β̂) = β usando expectativa linear.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Folha de papel, calculadora, notas de aula sobre regressão linear",
                                  "tips": "Use notação matricial consistente para evitar confusões com vetores.",
                                  "learningObjective": "Compreender as bases teóricas do estimador MQO antes da derivação da variância.",
                                  "commonMistakes": "Esquecer a premissa de erros independentes ou confundir viés com variância."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a matriz de covariância Var(β̂)",
                                  "subSteps": [
                                    "Comece com β̂ = (X'X)^{-1}X'Y e substitua Y = Xβ + ε.",
                                    "Calcule Cov(β̂) = E[(β̂ - E(β̂))(β̂ - E(β̂))'].",
                                    "Simplifique para Cov(β̂) = (X'X)^{-1}X' Cov(ε) X (X'X)^{-1}.",
                                    "Assuma Cov(ε) = σ²I, resultando em Var(β̂) = σ² (X'X)^{-1}.",
                                    "Estime σ² usando o resíduo médio quadrado (MSE)."
                                  ],
                                  "verification": "Derive a fórmula completa passo a passo e confira com um livro-texto.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Software como Python (NumPy) ou MATLAB para simular, quadro branco",
                                  "tips": "Pratique a álgebra matricial expandindo para regressão simples (p=1) primeiro.",
                                  "learningObjective": "Dominar a derivação analítica da variância do estimador MQO.",
                                  "commonMistakes": "Invertar a ordem das matrizes ou esquecer o fator σ²."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar e calcular a variância em um exemplo numérico",
                                  "subSteps": [
                                    "Crie um dataset simples: X com 5 observações, 2 preditores.",
                                    "Calcule X'X, inverta e multiplique por σ² (use σ²=1 para simplicidade).",
                                    "Extraia variâncias marginais (diagonal) e covariâncias (fora da diagonal).",
                                    "Simule dados no Python/R e compare variância amostral com teórica.",
                                    "Discuta impacto de multicolinearidade (X'X mal condicionado)."
                                  ],
                                  "verification": "Gere a matriz Var(β̂) numérica e verifique se os elementos diagonais são positivos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python com NumPy/SciPy ou R, dataset exemplo (CSV simples)",
                                  "tips": "Use np.linalg.inv() mas verifique cond(X'X) para estabilidade numérica.",
                                  "learningObjective": "Aplicar a fórmula para interpretar incertezas nos coeficientes.",
                                  "commonMistakes": "Não centralizar X ou ignorar a coluna de intercepto."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar eficiência com outros estimadores lineares",
                                  "subSteps": [
                                    "Revise propriedades BLUE (Best Linear Unbiased Estimator) do MQO.",
                                    "Compare com estimadores viesados como Ridge (adiciona λI a X'X).",
                                    "Calcule variância de Ridge vs MQO em dados com multicolinearidade.",
                                    "Discuta trade-off viés-variância em contextos de engenharia.",
                                    "Simule MSE total: E[(β̂ - β)^2] para ambos."
                                  ],
                                  "verification": "Em um simulação, mostre que Ridge tem menor MSE em alta colinearidade.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Python com scikit-learn para Ridge, gráficos de variância",
                                  "tips": "Use grid search para λ ótimo e plote curvas de viés-variância.",
                                  "learningObjective": "Avaliar quando MQO é eficiente e quando alternativas são melhores.",
                                  "commonMistakes": "Confundir eficiência (menor variância entre não-viesados) com MSE total."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar em modelagem de engenharia",
                                  "subSteps": [
                                    "Carregue dataset real de engenharia (ex: resistência de materiais vs carga/tempo).",
                                    "Ajuste MQO, calcule Var(β̂) e intervalos de confiança.",
                                    "Compare com Ridge se houver colinearidade.",
                                    "Interprete: variância alta indica necessidade de mais dados.",
                                    "Relate eficiência em termos de precisão preditiva."
                                  ],
                                  "verification": "Produza relatório com matriz de covariância e comparação de MSE.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Dataset engenharia (ex: de UCI ML repo), Jupyter Notebook",
                                  "tips": "Escalone preditores para melhor interpretação da variância.",
                                  "learningObjective": "Integrar cálculo de variância em problemas práticos de engenharia.",
                                  "commonMistakes": "Usar σ² errado (ex: não estimado dos resíduos)."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para prever tensão em vigas de aço: Y (tensão) ~ X1 (carga), X2 (espessura). Calcule Var(β̂) = σ² (X'X)^{-1}, obtenha Var(β1)=0.05, indicando incerteza moderada no coeficiente de carga. Compare com Ridge, que reduz para 0.03 mas introduz viés.",
                              "finalVerifications": [
                                "Derivação correta de Var(β̂) = σ² (X'X)^{-1} sem erros algébricos.",
                                "Cálculo numérico exato para dataset exemplo com match teórico-amostral.",
                                "Comparação válida de eficiência MQO vs Ridge em simulação.",
                                "Interpretação correta de elementos da matriz (variâncias e covariâncias).",
                                "Aplicação bem-sucedida em dataset de engenharia com relatório claro.",
                                "Identificação de multicolinearidade impactando variância."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação teórica (100% dos passos corretos).",
                                "Correção numérica e uso apropriado de software (erro <1%).",
                                "Profundidade na comparação de eficiência (inclui trade-offs).",
                                "Clareza na interpretação e contexto de engenharia.",
                                "Criatividade em exemplos e verificações práticas.",
                                "Completude de todos os substeps e campos."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses baseados em Var(β̂).",
                                "Programação: Implementação em Python/R para álgebra linear.",
                                "Engenharia: Modelagem preditiva em estruturas e materiais.",
                                "Econometria: Aplicações em séries temporais com autocorrelação.",
                                "Machine Learning: Extensão para regularização e validação cruzada."
                              ],
                              "realWorldApplication": "Em engenharia civil, calcular Var(β̂) em modelos de regressão para prever falhas em pontes permite quantificar incerteza nos coeficientes de carga e fadiga, auxiliando decisões de manutenção preventiva e otimizando alocação de recursos com base na eficiência relativa a métodos regularizados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.3.3",
                            "name": "Discutir eficiência assintótica",
                            "description": "Analisar a eficiência em grandes amostras, incluindo normalidade assintótica √n (β̂ - β) ~ N(0, AsyVar), aplicada a otimização de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos fundamentais de eficiência assintótica",
                                  "subSteps": [
                                    "Definir convergência assintótica e consistência de estimadores.",
                                    "Explicar eficiência assintótica como a menor variância possível em amostras grandes.",
                                    "Diferenciar eficiência de consistência e não-viés.",
                                    "Revisar teorema do limite central aplicado a estimadores.",
                                    "Discutir por que eficiência importa em grandes n."
                                  ],
                                  "verification": "Resumir em 3 frases os conceitos chave e dar um exemplo simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas de aula sobre MQO",
                                    "Livro de econometria ou estatística assintótica",
                                    "Calculadora"
                                  ],
                                  "tips": "Use analogias como 'com mais dados, o tiro fica mais preciso no alvo'.",
                                  "learningObjective": "Dominar definições básicas para contextualizar eficiência.",
                                  "commonMistakes": "Confundir eficiência com precisão finita-amostral."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar normalidade assintótica do estimador MQO",
                                  "subSteps": [
                                    "Derivar a distribuição √n (β̂ - β) ~ N(0, AsyVar).",
                                    "Explicar o papel do teorema de Slutsky e CLT multivariado.",
                                    "Mostrar como MQO atinge normalidade sob suposições padrão (homocedasticidade, etc.).",
                                    "Discutir condições para validade (iid, momentos finitos).",
                                    "Simular numericamente em software para visualizar."
                                  ],
                                  "verification": "Derivar a fórmula no papel e plotar histograma de simulação.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Software R ou Python (pacotes statsmodels ou lmtest)",
                                    "Dados simulados de regressão"
                                  ],
                                  "tips": "Comece com regressão simples univariada para intuition.",
                                  "learningObjective": "Entender a base probabilística da normalidade assintótica.",
                                  "commonMistakes": "Ignorar suposições como exogeneidade ou spherical errors."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e interpretar a variância assintótica (AsyVar)",
                                  "subSteps": [
                                    "Calcular AsyVar = (plim X'X/n)^{-1} σ² para MQO.",
                                    "Interpretar componentes: informação de Fisher e variância residual.",
                                    "Comparar eficiência MQO vs. outros estimadores (ex: máxima verossimilhança).",
                                    "Estimar AsyVar empiricamente com sandwich estimator.",
                                    "Analisar impacto de multicolinearidade na AsyVar."
                                  ],
                                  "verification": "Computar AsyVar para um dataset exemplo e discutir implicações.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Python/R com dados de regressão real",
                                    "Documentação de vcovHC"
                                  ],
                                  "tips": "Use matrizes para visualizar inversa de X'X/n.",
                                  "learningObjective": "Aplicar fórmulas para quantificar eficiência.",
                                  "commonMistakes": "Esquecer plim ou confundir com variância finita."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar eficiência assintótica à otimização industrial",
                                  "subSteps": [
                                    "Modelar processo industrial (ex: tempo produção vs. temperatura, carga).",
                                    "Simular grandes n para mostrar convergência √n.",
                                    "Otimizar parâmetros β usando intervalos assintóticos.",
                                    "Discutir trade-offs: custo de dados grandes vs. eficiência ganha.",
                                    "Propor melhorias baseadas em AsyVar reduzida."
                                  ],
                                  "verification": "Relatório curto com simulação e conclusões otimizadas.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Dataset industrial simulado ou real (ex: de sensores)",
                                    "Software de simulação"
                                  ],
                                  "tips": "Escolha variáveis relevantes para indústria (manufatura).",
                                  "learningObjective": "Conectar teoria à prática industrial.",
                                  "commonMistakes": "Aplicar fórmulas sem checar suposições nos dados."
                                }
                              ],
                              "practicalExample": "Em uma linha de produção de automóveis, modele o tempo de montagem (Y) como regressão linear em temperatura ambiente (X1) e velocidade da esteira (X2). Com n=10.000 observações de sensores, discuta como √n (β̂ - β) ~ N(0, AsyVar) permite inferências precisas para otimizar velocidades, reduzindo AsyVar via design experimental.",
                              "finalVerifications": [
                                "Explicar corretamente a distribuição assintótica √n (β̂ - β).",
                                "Calcular AsyVar para um modelo simples.",
                                "Identificar suposições necessárias para eficiência MQO.",
                                "Simular e plotar convergência em n grande.",
                                "Aplicar a um caso industrial com otimização proposta.",
                                "Comparar eficiência com estimador não-eficiente."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação da normalidade assintótica (80% correto).",
                                "Correta interpretação de AsyVar e seus componentes.",
                                "Qualidade da simulação numérica e visualizações.",
                                "Relevância da aplicação industrial e insights práticos.",
                                "Clareza na discussão de limitações e suposições.",
                                "Profundidade na comparação com outros estimadores."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Teorema do Limite Central.",
                                "Engenharia Industrial: Otimização de processos.",
                                "Programação Computacional: Simulações em R/Python.",
                                "Econometria: Estimadores eficientes em grandes dados."
                              ],
                              "realWorldApplication": "Na otimização de fábricas inteligentes (Indústria 4.0), analise grandes volumes de dados IoT com MQO para estimar parâmetros de eficiência operacional, usando normalidade assintótica para testes de hipótese rápidos e confiáveis em previsões de manutenção preditiva e redução de desperdícios."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.4.4",
                        "name": "Propriedades Assintóticas dos Estimadores MQO",
                        "description": "Propriedades que os estimadores MQO exibem em amostras grandes, incluindo normalidade assintótica e convergência em distribuição.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.4.4.1",
                            "name": "Descrever normalidade assintótica",
                            "description": "Explicar a distribuição assintótica normal dos estimadores MQO e sua utilidade para inferência em grandes datasets de engenharia, como análise de séries temporais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Convergência Assintótica",
                                  "subSteps": [
                                    "Revise os conceitos básicos de convergência em probabilidade e convergência em distribuição.",
                                    "Estude o Teorema Central do Limite (TCL) e sua relação com médias amostrais.",
                                    "Identifique como o TCL se aplica a estimadores lineares como o MQO em amostras grandes.",
                                    "Defina formalmente a normalidade assintótica: √n (β̂ - β) →ᵈ N(0, Σ), onde Σ é a matriz de variância assintótica.",
                                    "Discuta o papel do tamanho da amostra (n → ∞) na aproximação normal."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre consistência e normalidade assintótica, com um exemplo simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge), notas de aula sobre TCL, calculadora científica."
                                  ],
                                  "tips": "Use analogias como 'a lei dos grandes números para distribuições' para fixar o conceito.",
                                  "learningObjective": "Entender as bases probabilísticas que levam à normalidade assintótica dos estimadores MQO.",
                                  "commonMistakes": "Confundir convergência em probabilidade (consistência) com convergência em distribuição (normalidade)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Normalidade Assintótica do Estimador MQO",
                                  "subSteps": [
                                    "Lembre a fórmula do estimador MQO: β̂ = (X'X)^{-1} X'y.",
                                    "Expresse β̂ - β = (X'X)^{-1} X'ε, onde ε são os erros.",
                                    "Aplique o TCL à média de √n (X_i' ε_i / n), assumindo E[ε_i|X]=0.",
                                    "Mostre que √n (β̂ - β) = (1/n ∑ X_i X_i')^{-1} (1/√n ∑ X_i ε_i) →ᵈ N(0, σ² Q^{-1}), onde Q = plim (X'X/n).",
                                    "Verifique as condições: exogeneidade, não-colinearidade e momentos finitos."
                                  ],
                                  "verification": "Derive a expressão assintótica em um quadro ou papel e confira com uma referência padrão.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Lápis e papel para derivação, software como R ou Python para simular (opcional), slides de aula sobre MQO."
                                  ],
                                  "tips": "Comece com o caso univariado para simplificar antes de generalizar para multivariado.",
                                  "learningObjective": "Dominar a derivação matemática da distribuição assintótica normal do MQO.",
                                  "commonMistakes": "Esquecer a normalização por √n ou ignorar a matriz de covariância assintótica."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Condições e Utilidade para Inferência Estatística",
                                  "subSteps": [
                                    "Liste as hipóteses assintóticas: homocedasticidade condicional, independência serial (para séries temporais), ergodicidade.",
                                    "Discuta implicações para testes t e F assintóticos em grandes amostras.",
                                    "Explique intervalos de confiança assintóticos: β̂ ± z_{α/2} * se(β̂).",
                                    "Compare com propriedades finitas (ex: t-Student vs normal).",
                                    "Aplique a grandes datasets: robustez em n > 1000, como em engenharia."
                                  ],
                                  "verification": "Resolva um exercício: dada uma regressão, construa um IC assintótico e interprete.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Tabela de valores críticos da normal padrão, dataset de exemplo em CSV, Excel ou R."
                                  ],
                                  "tips": "Use simuladores online para visualizar como a distribuição se aproxima da normal com n crescente.",
                                  "learningObjective": "Aplicar a normalidade assintótica em procedimentos de inferência para grandes datasets.",
                                  "commonMistakes": "Aplicar aproximações assintóticas em amostras pequenas (n < 30) sem justificativa."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Contextos de Engenharia, como Séries Temporais",
                                  "subSteps": [
                                    "Carregue um dataset de séries temporais (ex: dados de sensores de temperatura).",
                                    "Estime uma regressão linear com lags ou tendências usando MQO.",
                                    "Calcule erros-padrão assintóticos e realize testes de significância.",
                                    "Valide a normalidade dos resíduos com QQ-plot para grandes n.",
                                    "Discuta limitações em séries temporais: autocorrelação e como usar erros robustos."
                                  ],
                                  "verification": "Gere um relatório curto com output da regressão, ICs e interpretação assintótica.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Python (statsmodels ou scikit-learn), dataset de séries temporais (ex: de Kaggle), Jupyter Notebook."
                                  ],
                                  "tips": "Use o comando robust=True em statsmodels para covariâncias HC assintóticas.",
                                  "learningObjective": "Demonstrar a utilidade prática da normalidade assintótica em análise de dados de engenharia.",
                                  "commonMistakes": "Ignorar dependência serial em séries temporais, violando hipóteses assintóticas."
                                }
                              ],
                              "practicalExample": "Em uma análise de séries temporais de vibrações em uma turbina eólica (n=5000 observações), use MQO para regressar amplitude de vibração em velocidade do vento e lags. A normalidade assintótica permite testes t para coeficientes, confirmando que lags de 1 dia são significativos (p<0.01), guiando manutenção preditiva.",
                              "finalVerifications": [
                                "Derive corretamente a distribuição assintótica do MQO.",
                                "Liste e explique pelo menos 4 condições para validade assintótica.",
                                "Construa e interprete um intervalo de confiança assintótico.",
                                "Aplique em um dataset real e discuta resultados.",
                                "Diferencie inferência finita de assintótica em contextos de engenharia.",
                                "Identifique quando a aproximação falha (ex: heterocedasticidade)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação matemática (30%)",
                                "Correta identificação de condições e limitações (25%)",
                                "Aplicação prática em dataset com interpretação (20%)",
                                "Clareza na explicação verbal/escrita (15%)",
                                "Uso apropriado de ferramentas computacionais (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema Central do Limite e convergência em distribuição.",
                                "Estatística: Inferência em regressão e testes de hipóteses.",
                                "Engenharia: Análise de séries temporais em sistemas dinâmicos.",
                                "Programação: Implementação em Python/R para simulações assintóticas.",
                                "Econometria: Extensões para modelos com erros robustos."
                              ],
                              "realWorldApplication": "Em engenharia, a normalidade assintótica do MQO é crucial para inferência em grandes datasets de IoT, como monitoramento de redes elétricas ou previsão de falhas em manufatura, permitindo testes confiáveis de hipóteses sobre parâmetros em amostras massivas onde propriedades finitas falham."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.4.2",
                            "name": "Derivar matriz de variância assintótica",
                            "description": "Calcular AsyVar(β̂) = plim (1/n X'X)^(-1) σ² plim (1/n X'X)^(-1), considerando heteroscedasticidade robusta em aplicações práticas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos de convergência em probabilidade e pressupostos do MQO",
                                  "subSteps": [
                                    "Relembre a definição de convergência em probabilidade (plim) para sequências aleatórias.",
                                    "Liste os pressupostos padrão do MQO: exogeneidade, não-colinearidade e convergência de momentos.",
                                    "Verifique a consistência assintótica de β̂: plim β̂ = β.",
                                    "Entenda que plim (1/n X'X) = Q, uma matriz finita e positiva definida.",
                                    "Discuta o papel de σ² na variância dos erros."
                                  ],
                                  "verification": "Escreva as definições e prove que plim (1/n X'X) existe sob pressupostos regulares.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de econometria (ex: Wooldridge), papel e caneta, calculadora.",
                                  "tips": "Use notação matricial consistente para evitar confusões.",
                                  "learningObjective": "Compreender as bases assintóticas necessárias para a derivação da variância.",
                                  "commonMistakes": "Confundir plim com E[ ], ignorando variância infinita em amostras finitas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a matriz de variância assintótica no caso homocedástico",
                                  "subSteps": [
                                    "Comece com a representação: √n (β̂ - β) = (1/n X'X)^{-1} (1/√n X'u).",
                                    "Mostre que plim (1/√n X'u) = N(0, σ² Q).",
                                    "Derive AsyVar(√n (β̂ - β)) = Q^{-1} σ² Q^{-1}.",
                                    "Divida por n para obter AsyVar(β̂) = (1/n) Q^{-1} σ² Q^{-1}.",
                                    "Estime σ² com resíduo médio quadrado."
                                  ],
                                  "verification": "Escreva a derivação completa e substitua plim (1/n X'X) por Q.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Quadro branco ou software LaTeX para equações, exemplos de regressão simples.",
                                  "tips": "Desenhe o teorema do delta ou use CLT para a normalidade assintótica.",
                                  "learningObjective": "Derivar precisamente a fórmula da variância assintótica sob homocedasticidade.",
                                  "commonMistakes": "Esquecer o fator 1/n na variância final ou inverter a ordem das matrizes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estender para heteroscedasticidade com estimador robusto (sandwich)",
                                  "subSteps": [
                                    "Introduza erros heteroscedásticos: Var(u_i | X_i) = σ_i² ≠ σ² constante.",
                                    "Mostre que a variância homocedástica falha: plim (1/n X'u X'u / σ²) ≠ Q.",
                                    "Derive o estimador robusto: AsyVar(β̂) = Q^{-1} S Q^{-1}, onde S = plim (1/n ∑ x_i x_i u_i²).",
                                    "Estime S com ∑ ê_i² x_i x_i / n, onde ê são resíduos.",
                                    "Compare com HC0, HC1, etc., em pacotes como lmtest no R."
                                  ],
                                  "verification": "Calcule manualmente para um modelo com 2 variáveis e verifique contra software.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Software R ou Python (statsmodels), dataset pequeno com heteroscedasticidade simulada.",
                                  "tips": "Simule dados com σ_i² = exp(X_i β) para testar.",
                                  "learningObjective": "Adaptar a derivação para erros heteroscedásticos em prática.",
                                  "commonMistakes": "Usar σ̂² global em vez de pesos individuais nos resíduos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e interpretar em um exemplo computacional",
                                  "subSteps": [
                                    "Carregue um dataset (ex: salários vs. educação) e ajuste MQO.",
                                    "Calcule Q̂ = (X'X)/n e Ŝ = (1/n) ∑ x_i x_i ê_i².",
                                    "Compute AsyVar(β̂) = Q̂^{-1} Ŝ Q̂^{-1}.",
                                    "Compare intervalos de confiança homocedástico vs. robusto.",
                                    "Interprete: coeficientes com erros padrão robustos."
                                  ],
                                  "verification": "Reproduza resultados em R/Python e confira se matriz é simétrica positiva definida.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "R com pacotes sandwich/lmtest ou Python statsmodels, dataset Wages (Wooldridge).",
                                  "tips": "Use vcovHC() no R para validar sua derivação manual.",
                                  "learningObjective": "Implementar a derivação em código e interpretar resultados práticos.",
                                  "commonMistakes": "Não centralizar variáveis ou ignorar intercepto na matriz X."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar robustez e generalizações",
                                  "subSteps": [
                                    "Teste para autocorrelação ou clusters com Newey-West.",
                                    "Discuta limitações: amostras pequenas ou violações de plim.",
                                    "Generalize para IV ou GMM.",
                                    "Crie um script reutilizável para qualquer regressão.",
                                    "Documente diferenças numéricas entre teoria e estimação."
                                  ],
                                  "verification": "Aplique a um segundo dataset e compare com output padrão de software.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Scripts anteriores, datasets adicionais (ex: housing prices).",
                                  "tips": "Sempre cheque det(Q̂) > 0 para não-colinearidade.",
                                  "learningObjective": "Garantir aplicação robusta em cenários reais variados.",
                                  "commonMistakes": "Sobrepor robustez sem testar pressupostos subjacentes."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão de salário (log(wage)) sobre anos de educação e experiência usando dados do CPS: Calcule Q̂ = [[1, 12.5, 10], [12.5, 165, 110], [10, 110, 105]], estime Ŝ com resíduos, obtenha Var(β̂_educ) ≈ 0.0012 robusta vs. 0.0009 homocedástica, ampliando IC de 95%.",
                              "finalVerifications": [
                                "Derivação da fórmula AsyVar(β̂) está correta e completa.",
                                "Cálculo numérico em exemplo bate com software (erro < 1e-6).",
                                "Matriz de variância é simétrica e positiva semi-definida.",
                                "Intervalos de confiança robustos são mais largos onde heteroscedasticidade existe.",
                                "Script computacional é reproduzível e comentado.",
                                "Interpretação correta dos erros padrão assintóticos."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (100% das etapas corretas).",
                                "Correta implementação computacional (resultados validados).",
                                "Compreensão de plim e CLT demonstrada em explicações.",
                                "Identificação e correção de heteroscedasticidade em exemplo.",
                                "Generalização para casos relacionados (ex: clusters).",
                                "Clareza na documentação e interpretação prática."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teorema Central do Limite e inferência assintótica.",
                                "Econometria: Estimadores robustos em painel e IV.",
                                "Machine Learning: Variância em regressão linear e regularização.",
                                "Computação Científica: Otimização matricial em NumPy/SciPy.",
                                "Finanças: Modelos de risco com erros condicionais variáveis."
                              ],
                              "realWorldApplication": "Em análises econômicas, como prever impacto de políticas educacionais em salários, onde erros são heteroscedásticos (cidades grandes vs. rurais); usa-se variância robusta para intervalos de confiança confiáveis em relatórios para governos ou empresas, evitando subestimação de incerteza."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.4.4.3",
                            "name": "Aplicar em testes de inferência assintóticos",
                            "description": "Utilizar propriedades assintóticas para construir testes t e F em regressões com pressupostos relaxados, exemplificando com dados de sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar propriedades assintóticas dos estimadores MQO",
                                  "subSteps": [
                                    "Relembrar consistência assintótica: plim β_hat = β quando n → ∞.",
                                    "Estudar normalidade assintótica: √n (β_hat - β) ~ N(0, σ² (X'X/n)^{-1}).",
                                    "Analisar variância assintótica e matriz de covariância.",
                                    "Discutir relaxamento de pressupostos: independência serial, heterocedasticidade permitida.",
                                    "Exemplificar com equação de regressão linear Y = Xβ + ε."
                                  ],
                                  "verification": "Resumir em um parágrafo as 4 propriedades chave e listar pressupostos relaxados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de Econometria (ex: Wooldridge), notas de aula, calculadora.",
                                  "tips": "Use diagramas para visualizar convergência assintótica.",
                                  "learningObjective": "Compreender base teórica para testes assintóticos em MQO.",
                                  "commonMistakes": "Confundir propriedades finitas com assintóticas; ignorar √n na normalidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir teste t assintótico para coeficientes individuais",
                                  "subSteps": [
                                    "Derivar estatística t: t = (β_hat_j - β_j0) / se_assint(β_hat_j), onde se_assint = √[σ² (X'X/n)^{-1}_{jj}].",
                                    "Estimar σ² assintoticamente com resíduos: σ_hat² = (1/n) Σ e_hat_i².",
                                    "Definir hipótese nula H0: β_j = β_j0 vs. Ha: ≠.",
                                    "Calcular p-value usando distribuição N(0,1) assintótica.",
                                    "Implementar fórmula em pseudocódigo."
                                  ],
                                  "verification": "Calcular manualmente t para um coeficiente simples e comparar com N(0,1).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Software R/Python (pacotes lmtest ou statsmodels), planilha Excel.",
                                  "tips": "Sempre padronize pela √n implícita na se.",
                                  "learningObjective": "Dominar construção e justificativa do teste t assintótico.",
                                  "commonMistakes": "Usar se finita em vez de assintótica; esquecer normalização por n."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir teste F assintótico para restrições lineares",
                                  "subSteps": [
                                    "Recordar estatística F: F = [ (RSS_r - RSS_u)/q ] / [ RSS_u / (n-k) ] → χ²(q)/q assintoticamente.",
                                    "Adaptar para assintótico: usar σ_hat² consistente e (X'X/n)^{-1}.",
                                    "Definir restrições Rβ = r, com q restrições.",
                                    "Derivar distribuição assintótica χ²(q) sob H0.",
                                    "Comparar com versão finita e discutir quando usar assintótica."
                                  ],
                                  "verification": "Derivar F para teste de significância global e verificar limite χ²(1).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Notas teóricas, software para simulação Monte Carlo.",
                                  "tips": "Simule dados grandes (n=10000) para validar assintótica.",
                                  "learningObjective": "Aplicar teste F assintótico em hipóteses múltiplas.",
                                  "commonMistakes": "Confundir graus de liberdade F finita com χ²; não escalar por n."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar testes a dados de sistemas de controle",
                                  "subSteps": [
                                    "Carregar dataset exemplo: regressão de saída de controlador PID em entradas (ex: temperatura vs. setpoint, ruído).",
                                    "Ajustar modelo MQO com n grande (>500 obs), relaxar normalidade.",
                                    "Computar testes t e F assintóticos usando software.",
                                    "Interpretar: rejeitar H0 se p-value < 0.05, discutir poder.",
                                    "Comparar com testes finitos para validar."
                                  ],
                                  "verification": "Gerar relatório com tabelas de testes e gráfico de resíduos.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Dataset simulado (Python: numpy/pandas/sklearn), R (lmtest, sandwich).",
                                  "tips": "Use robust se para heterocedasticidade com pacote sandwich.",
                                  "learningObjective": "Implementar testes em contexto real de engenharia de controle.",
                                  "commonMistakes": "n pequeno invalidando assintótica; ignorar autocorrelação em séries temporais."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e validar robustez",
                                  "subSteps": [
                                    "Analisar significância: coeficientes de ganhos em controlador.",
                                    "Verificar suposições relaxadas via QQ-plot assintótico ou bootstrap.",
                                    "Discutir limitações: taxa de convergência lenta em alguns casos.",
                                    "Sensibilidade: variar n e observar p-values estabilizando.",
                                    "Concluir implicações para design de sistemas de controle."
                                  ],
                                  "verification": "Escrever conclusão de 200 palavras com evidências numéricas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Gráficos (matplotlib/ggplot), relatório template.",
                                  "tips": "Sempre reporte intervalos de confiança assintóticos.",
                                  "learningObjective": "Interpretar testes no contexto aplicado e avaliar validade.",
                                  "commonMistakes": "Superinterpretar rejeição como causalidade; negligenciar tamanho do efeito."
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de temperatura industrial, regredir temperatura medida (Y) em setpoint (X1), carga térmica (X2) e ruído (ε). Com n=1000 obs, testar H0: coef_X2=0 (carga insignificante) via t assintótico; testar joint significância via F. Resultado: rejeitar H0, ajustando PID adequadamente.",
                              "finalVerifications": [
                                "Testes t e F computados corretamente com fórmulas assintóticas.",
                                "p-values consistentes com simulações Monte Carlo (n>5000).",
                                "Interpretação alinhada com propriedades relaxadas (sem normalidade).",
                                "Resultados reproduzíveis em código compartilhado.",
                                "Gráficos de resíduos mostram ausência de padrões fortes.",
                                "Comparação com testes bootstrap valida convergência."
                              ],
                              "assessmentCriteria": [
                                "Precisão teórica: derivações corretas (80%).",
                                "Implementação computacional sem erros (90%).",
                                "Interpretação contextualizada em controle (85%).",
                                "Uso apropriado de assintóticos vs. finitos (100%).",
                                "Relatório claro e completo (75%).",
                                "Criatividade em validação robustez (extra)."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Controle: modelagem PID via regressão.",
                                "Programação Estatística: R/Python para inferência robusta.",
                                "Econometria: testes em painel/time-series relaxados.",
                                "Machine Learning: validação assintótica em regressores lineares."
                              ],
                              "realWorldApplication": "Em indústrias como automotiva ou aeroespacial, analistas usam testes assintóticos em grandes datasets de sensores para validar modelos de controle preditivo, otimizando estabilidade sem pressupor normalidade perfeita, reduzindo tempo de calibração em 30%."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.1.5",
                    "name": "Inferência Estatística em Regressão Linear",
                    "description": "Construção de intervalos de confiança e testes de hipóteses (t e F) para parâmetros e significância do modelo.",
                    "individualConcepts": [
                      {
                        "id": "10.1.1.5.1",
                        "name": "Intervalos de Confiança para Parâmetros da Regressão Linear",
                        "description": "Construção e interpretação de intervalos de confiança para os coeficientes de regressão (β) sob os pressupostos dos Mínimos Quadrados Ordinários (MQO), utilizando a distribuição t de Student.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.5.1.1",
                            "name": "Calcular a variância dos estimadores MQO",
                            "description": "Derivar e computar a variância amostral dos estimadores β̂ usando a matriz de covariância (σ²(X'X)^{-1}), considerando os resíduos quadráticos e graus de liberdade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os estimadores OLS e preparar a matriz de design X",
                                  "subSteps": [
                                    "Colete o dataset com variável dependente y (n observações) e preditoras X (incluindo intercepto).",
                                    "Construa a matriz X de design (n x (k+1)), adicionando coluna de 1s para intercepto.",
                                    "Ajuste o modelo OLS: β̂ = (X'X)^{-1} X'y.",
                                    "Verifique dimensionalidade: X deve ser n x p, onde p = k+1.",
                                    "Salve β̂ para referência futura."
                                  ],
                                  "verification": "Confirme que β̂ foi calculado corretamente comparando com output de software (ex: lm() no R).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset em CSV ou Excel",
                                    "Software estatístico (R, Python com statsmodels ou scikit-learn)",
                                    "Calculadora matricial opcional"
                                  ],
                                  "tips": [
                                    "Sempre inclua intercepto na matriz X para modelos com termo constante.",
                                    "Use funções prontas como solve(t(X)%*%X) no R para evitar erros manuais."
                                  ],
                                  "learningObjective": "Entender a estrutura da matriz X e estimadores β̂ como base para variância.",
                                  "commonMistakes": [
                                    "Esquecer coluna de 1s para intercepto.",
                                    "Confundir X com X'X prematuramente."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular resíduos e Soma dos Quadrados dos Resíduos (RSS)",
                                  "subSteps": [
                                    "Compute fitted values: ŷ = X β̂.",
                                    "Calcule resíduos: e = y - ŷ.",
                                    "Compute RSS = e' e = sum(e_i²).",
                                    "Verifique que média dos resíduos é aproximadamente zero.",
                                    "Salve RSS para estimativa de σ²."
                                  ],
                                  "verification": "RSS deve ser positivo e menor que TSS (soma quadrados total).",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Mesmo dataset e software do Step 1",
                                    "Funções como residuals() no R"
                                  ],
                                  "tips": [
                                    "Use vectorização em software para eficiência.",
                                    "Plot resíduais vs fitted para inspeção visual rápida."
                                  ],
                                  "learningObjective": "Dominar cálculo de resíduos como base para inferência.",
                                  "commonMistakes": [
                                    "Usar y em vez de ŷ nos resíduos.",
                                    "Ignorar resíduos zero em observações perfeitas."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimar a variância dos erros σ² usando resíduos e graus de liberdade",
                                  "subSteps": [
                                    "Determine graus de liberdade: df = n - p, onde p = k+1 (número de parâmetros).",
                                    "Calcule variância amostral: s² = RSS / df.",
                                    "Confirme que s² > 0 e razoável em escala de y.",
                                    "Compare s² com variância de y para plausibilidade.",
                                    "Salve s² como estimativa de σ²."
                                  ],
                                  "verification": "s² deve ser consistente com plots de resíduais (homocedasticidade aproximada).",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Resultados dos steps anteriores",
                                    "Calculadora simples"
                                  ],
                                  "tips": [
                                    "df = n - k - 1 para intercepto incluso.",
                                    "s² é viés corrigido, use RSS/n apenas para σ² populacional aproximado."
                                  ],
                                  "learningObjective": "Aplicar correção por graus de liberdade na estimativa de variância.",
                                  "commonMistakes": [
                                    "Usar df = n em vez de n - p.",
                                    "Confundir RSS com σ² diretamente."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Computar a matriz de covariância amostral dos estimadores",
                                  "subSteps": [
                                    "Calcule X'X.",
                                    "Inverta: (X'X)^{-1}.",
                                    "Multiplique pela estimativa: Var(β̂) = s² (X'X)^{-1}.",
                                    "Extraia variâncias diagonais para Var(β̂_j).",
                                    "Verifique simetria e positividade semi-definida."
                                  ],
                                  "verification": "Elementos diagonais positivos; off-diagonais mostram covariâncias.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software com inversão matricial (solve() no R, np.linalg.inv() no Python)"
                                  ],
                                  "tips": [
                                    "Para grandes n, use decomposição QR para estabilidade numérica.",
                                    "Diagonal dá erros padrão: se(sqrt(Var(β̂_j)))."
                                  ],
                                  "learningObjective": "Derivar matriz de variância completa dos estimadores OLS.",
                                  "commonMistakes": [
                                    "Inverter X'X sem escalar por s².",
                                    "Erro numérico em matrizes singulares (multicolinearidade)."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e interpretar a matriz de variância",
                                  "subSteps": [
                                    "Compare com output padrão de summary(lm()) no R.",
                                    "Calcule erros padrão individuais.",
                                    "Interprete: variâncias altas indicam precisão baixa.",
                                    "Teste multicolinearidade via cond(X'X).",
                                    "Documente para intervalos de confiança subsequentes."
                                  ],
                                  "verification": "Erros padrão coincidem com software estatístico.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Resultados finais",
                                    "Documentação de software"
                                  ],
                                  "tips": [
                                    "Alta variância em β̂_j sugere preditoras correlacionadas.",
                                    "Salve matriz para testes t e ICs."
                                  ],
                                  "learningObjective": "Interpretar variâncias no contexto de inferência.",
                                  "commonMistakes": [
                                    "Ignorar covariâncias off-diagonal em ICs múltiplos.",
                                    "Confundir variância com erro padrão."
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset mtcars (R): modele mpg ~ wt + hp. Calcule β̂, RSS=293.49, df=29, s²=10.12, (X'X)^{-1} leva a Var(β̂_wt)=0.0018, se(β̂_wt)=0.042.",
                              "finalVerifications": [
                                "Matriz Var(β̂) é simétrica com diagonal positiva.",
                                "s² calculado coincide com software (ex: sigma(lm)^2).",
                                "Erros padrão batem com summary(modelo).",
                                "RSS > 0 e df = n - p correto.",
                                "Nenhuma NaN ou Inf na inversa.",
                                "Variâncias aumentam com s² ou multicolinearidade."
                              ],
                              "assessmentCriteria": [
                                "Correção na estimativa de s² (penalize df errado).",
                                "Inversão precisa de X'X sem erros numéricos.",
                                "Interpretação coerente de variâncias (alta = baixa precisão).",
                                "Uso adequado de graus de liberdade.",
                                "Validação cruzada com software.",
                                "Clareza na documentação de passos."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuição Normal Assumida para β̂.",
                                "Programação: NumPy/SciPy para computação matricial.",
                                "Econometria: Testes de significância em modelos econômicos.",
                                "Machine Learning: Regularização para reduzir variância.",
                                "Cálculo: Derivadas matriciais na prova da fórmula."
                              ],
                              "realWorldApplication": "Em previsão de vendas, calcular Var(β̂_preço) ajuda a quantificar incerteza no impacto do preço nas vendas, essencial para decisões de precificação em empresas como Amazon ou varejo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.1.2",
                            "name": "Construir intervalos de confiança para β",
                            "description": "Aplicar a fórmula IC = β̂ ± t_{α/2, n-k-1} * SE(β̂), onde SE é o erro padrão, e explicar o nível de confiança no contexto econométrico aplicado à engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os componentes da fórmula de intervalo de confiança",
                                  "subSteps": [
                                    "Identifique β̂ como o estimador pontual do coeficiente β da regressão linear.",
                                    "Revise SE(β̂), o erro padrão, calculado a partir da matriz de variância-covariância ou fórmula específica.",
                                    "Entenda t_{α/2, n-k-1} como o valor crítico da distribuição t-Student para o nível de confiança (1-α).",
                                    "Defina n como número de observações e k como número de regressores (excluindo intercepto).",
                                    "Explique o contexto: em econometria para engenharia, mede incerteza em relações causais como custo vs. produção."
                                  ],
                                  "verification": "Liste corretamente todos os componentes com suas definições e fórmulas associadas em um quadro-resumo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão linear",
                                    "Tabela de distribuição t-Student",
                                    "Calculadora ou software como Excel/R"
                                  ],
                                  "tips": "Use um exemplo numérico simples para memorizar cada termo; visualize com gráfico da distribuição t.",
                                  "learningObjective": "Dominar os elementos fundamentais da fórmula IC para β̂ e seu significado estatístico.",
                                  "commonMistakes": [
                                    "Confundir SE(β̂) com desvio padrão dos resíduos",
                                    "Ignorar k ao calcular graus de liberdade",
                                    "Esquecer que α é o nível de significância bilateral"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os graus de liberdade e definir o nível de confiança",
                                  "subSteps": [
                                    "Calcule df = n - k - 1, onde n é o tamanho da amostra e k o número de variáveis independentes.",
                                    "Escolha α (ex: 0.05 para 95% de confiança) baseado no contexto de risco em engenharia.",
                                    "Determine α/2 para intervalo bilateral (ex: 0.025).",
                                    "Verifique se as suposições da regressão (normalidade, homocedasticidade) sustentam o uso da t-Student.",
                                    "Discuta implicações: df menores aumentam a largura do IC devido a mais incerteza."
                                  ],
                                  "verification": "Mostre cálculo de df para um dataset exemplo e justifique escolha de α com trade-off precisão vs. conservadorismo.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Dataset de regressão exemplo (ex: Excel com n=30, k=1)",
                                    "Documentação de suposições OLS"
                                  ],
                                  "tips": "Sempre valide df > 30 para aproximação normal, mas use t exata em engenharia para precisão.",
                                  "learningObjective": "Calcular df corretamente e selecionar α apropriado para aplicações econométricas em engenharia.",
                                  "commonMistakes": [
                                    "Usar df = n-1 em vez de n-k-1",
                                    "Confundir α com nível de confiança",
                                    "Ignorar violações de suposições"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Obter o valor crítico t_{α/2, df}",
                                  "subSteps": [
                                    "Consulte tabela t-Student para t_{α/2, df} ou use função inversa (ex: =T.INV.2T(α, df) no Excel).",
                                    "Em software: qt(1-α/2, df) no R ou stats.t.ppf(1-α/2, df) no Python.",
                                    "Compare com valor z para df grandes (aproximação normal).",
                                    "Anote o valor exato e arredonde apenas na etapa final.",
                                    "Teste sensibilidade: varie α para ver impacto na largura do IC."
                                  ],
                                  "verification": "Reproduza t crítico para df=28, α=0.05 (≈2.048) usando pelo menos duas fontes (tabela e software).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Tabela t-Student impressa",
                                    "Software R/Python/Excel instalado",
                                    "Calculadora científica"
                                  ],
                                  "tips": "Memorize valores comuns: t_{0.025, ∞} ≈1.96; para df baixos, t é maior.",
                                  "learningObjective": "Localizar e calcular precisamente o quantil t crítico para qualquer df e α.",
                                  "commonMistakes": [
                                    "Usar distribuição normal z em vez de t",
                                    "Erros de lookup na tabela (coluna errada)",
                                    "Arredondar prematuramente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a fórmula e construir o intervalo de confiança",
                                  "subSteps": [
                                    "Calcule margem de erro: t * SE(β̂).",
                                    "Some e subtraia da fórmula: LI = β̂ - margem; LS = β̂ + margem.",
                                    "Reporte IC como (LI, LS) com precisão decimal adequada (ex: 2 casas).",
                                    "Verifique se 0 está no IC (implicação de insignificância).",
                                    "Automatize em código para repetibilidade em análises de engenharia."
                                  ],
                                  "verification": "Construa IC para exemplo dado e confira com output de software de regressão.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Valores de β̂ e SE de um modelo OLS",
                                    "Script R/Python para lm() e confint()"
                                  ],
                                  "tips": "Sempre inclua unidades (ex: $/hora) nos limites para contexto engenheiro-econômico.",
                                  "learningObjective": "Executar cálculo numérico preciso da fórmula IC = β̂ ± t * SE(β̂).",
                                  "commonMistakes": [
                                    "Inverter sinal da margem",
                                    "Usar β̂ errado (confundir com intercepto)",
                                    "Esquecer multiplicar por t"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar o intervalo no contexto econométrico de engenharia",
                                  "subSteps": [
                                    "Explique: 'Com 95% confiança, o verdadeiro β está entre LI e LS, baseado em amostra'.",
                                    "Discuta largura: reflete precisão; estreite com mais dados ou modelo melhor.",
                                    "Aplique a engenharia: ex, IC para custo/hora guia dimensionamento de projetos.",
                                    "Compare com teste t: IC exclui 0 ⇒ β significativo.",
                                    "Considere limitações: suposições OLS, multicolinearidade em dados engenharia."
                                  ],
                                  "verification": "Escreva parágrafo de interpretação correta para um IC exemplo, ligando a decisão engenheira.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Relatório de regressão exemplo",
                                    "Artigos econométricos em engenharia industrial"
                                  ],
                                  "tips": "Evite dizer '95% probabilidade que β está no IC' – é confiança na procedure, não probabilidade posterior.",
                                  "learningObjective": "Interpretar IC corretamente, evitando erros comuns, e aplicar a cenários reais de engenharia.",
                                  "commonMistakes": [
                                    "Interpretar como probabilidade para β específico",
                                    "Ignorar contexto de engenharia",
                                    "Confundir confiança com predição"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de engenharia mecânica, regressão linear modela custo de produção Y ($1000) vs. horas de máquina X: β̂ = 5.2 ($/hora), SE(β̂) = 0.8, n=30 observações, k=1, α=0.05. df=28, t_{0.025,28}≈2.05. Margem=2.05*0.8=1.64. IC=(5.2-1.64, 5.2+1.64)=(3.56, 6.84). Interpretação: Com 95% confiança, custo marginal por hora está entre $3.56 e $6.84 mil, guiando orçamentos de produção.",
                              "finalVerifications": [
                                "Calcular df corretamente para dados dados.",
                                "Obter t crítico preciso (±0.01 erro).",
                                "Construir IC exato via fórmula manual.",
                                "Interpretar IC sem erros probabilísticos.",
                                "Validar com output de software (R confint()).",
                                "Explicar implicações para decisão em engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos (100% correto).",
                                "Compreensão conceitual demonstrada na interpretação.",
                                "Uso correto de ferramentas/software.",
                                "Identificação de suposições e limitações.",
                                "Aplicação contextual a engenharia/econometria.",
                                "Clareza e completude na documentação."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Implementar em Python (statsmodels) ou R para automação.",
                                "Economia: Modelos de produção Cobb-Douglas com IC para elasticidades.",
                                "Engenharia Industrial: Análise de regressão em controle de processos.",
                                "Estatística Avançada: Bootstrap para IC robustos.",
                                "Gestão de Projetos: Previsão de custos com incerteza."
                              ],
                              "realWorldApplication": "Em engenharia, construtores de IC para β em regressões de custo vs. inputs (ex: energia vs. output) permitem dimensionar projetos com margens de segurança, otimizar alocação de recursos sob incerteza e validar hipóteses econométricas em auditorias de eficiência fabril, reduzindo overruns de orçamento em até 20%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.1.3",
                            "name": "Interpretar intervalos de confiança",
                            "description": "Analisar se o intervalo contém zero, implicando insignificância prática, e relacionar com incerteza em previsões de modelos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a definição e construção de intervalos de confiança para parâmetros de regressão",
                                  "subSteps": [
                                    "Revise a fórmula do intervalo de confiança para um coeficiente β: β̂ ± t * SE(β̂), onde t é o valor crítico da distribuição t e SE é o erro padrão.",
                                    "Identifique os componentes: estimativa pontual β̂, nível de confiança (ex: 95%), e grau de liberdade.",
                                    "Discuta o significado probabilístico: o IC contém o verdadeiro β com probabilidade 95% em repetições.",
                                    "Pratique com um exemplo simples usando software para gerar ICs.",
                                    "Compare ICs estreitos (alta precisão) vs. largos (alta incerteza)."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o que o IC representa e calcule manualmente para um coeficiente dado.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notebook Jupyter com statsmodels ou scikit-learn, dataset de regressão linear simples (ex: Boston Housing).",
                                  "tips": "Sempre verifique o nível de confiança; 95% é padrão, mas ajuste para contextos conservadores.",
                                  "learningObjective": "Dominar a interpretação conceitual de ICs como medida de incerteza nos parâmetros.",
                                  "commonMistakes": "Confundir IC com intervalo de predição; achar que o IC 'contém' o valor verdadeiro com certeza em um único cálculo."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar se o intervalo de confiança contém zero",
                                  "subSteps": [
                                    "Examine o limite inferior e superior do IC para o coeficiente de interesse.",
                                    "Se 0 estiver dentro do IC, classifique como 'contém zero'; caso contrário, 'não contém zero'.",
                                    "Calcule a distância de β̂ até zero e compare com a margem de erro.",
                                    "Teste hipóteses nulas (H0: β=0) usando o IC: rejeitar se 0 não estiver no IC.",
                                    "Documente em uma tabela: coeficiente, IC, contém zero? (Sim/Não)."
                                  ],
                                  "verification": "Para um modelo dado, liste ICs e marque corretamente quais contêm zero.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Output de regressão linear de Python/R (ex: summary() no statsmodels), calculadora.",
                                  "tips": "Visualize ICs em um gráfico de erro para intuição rápida.",
                                  "learningObjective": "Identificar visual e numericamente se o IC inclui zero.",
                                  "commonMistakes": "Ignorar o sinal do coeficiente; focar só no limite superior se β̂ positivo."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar implicações de insignificância prática quando IC contém zero",
                                  "subSteps": [
                                    "Explique: IC contendo zero implica que β pode ser zero, sugerindo falta de evidência de efeito.",
                                    "Discuta p-valor > 0.05 como consistente com isso, mas priorize IC para magnitude.",
                                    "Avalie largura do IC: mesmo contendo zero, se estreito, incerteza baixa em torno de zero.",
                                    "Diferencie insignificância estatística de irrelevância prática.",
                                    "Escreva uma conclusão: 'Não há evidência estatística de relação significativa.'"
                                  ],
                                  "verification": "Redija uma interpretação completa para 2-3 ICs, justificando insignificância.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Exemplos de outputs de modelos com ICs variados, template de relatório.",
                                  "tips": "Use frases padronizadas para relatórios profissionais.",
                                  "learningObjective": "Traduzir análise de IC em linguagem de decisão prática.",
                                  "commonMistakes": "Equivocar ausência de evidência com evidência de ausência; ignorar tamanho do efeito."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar intervalos de confiança com incerteza em previsões de modelos de engenharia",
                                  "subSteps": [
                                    "Compare IC para parâmetros com intervalos de predição (IP) para y-hat.",
                                    "Mostre como ICs largos propagam incerteza para previsões: var(IP) inclui var(β).",
                                    "Aplique a um caso de engenharia: prever fadiga de material baseado em ciclos de carga.",
                                    "Simule cenários: ajuste confiança e observe impacto em decisões de design.",
                                    "Integre em workflow: use ICs para tolerâncias em engenharia de confiabilidade."
                                  ],
                                  "verification": "Crie um relatório ligando ICs de um modelo de engenharia a recomendações de previsão.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Dataset de engenharia (ex: fadiga de metais do UCI ML Repo), Python com matplotlib para plots.",
                                  "tips": "Sempre relacione de volta ao problema de negócio: custo de incerteza alta.",
                                  "learningObjective": "Conectar inferência paramétrica a incertezas preditivas em contextos aplicados.",
                                  "commonMistakes": "Confundir IC de parâmetros com IP; subestimar propagação de variância."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão linear prevendo a resistência à tração (y) de vigas de aço baseado na temperatura de cura (x), o IC para o coeficiente de x é [-0.5, 1.2] a 95%. Como contém zero, não há evidência estatística de que a temperatura afeta significativamente a resistência, implicando alta incerteza em previsões para novos designs de vigas.",
                              "finalVerifications": [
                                "Corretamente identifica se ICs contêm zero em 100% dos casos testados.",
                                "Interpreta implicações de insignificância sem ambiguidades.",
                                "Relaciona ICs a incertezas preditivas com exemplo quantitativo.",
                                "Produz conclusões práticas para engenharia.",
                                "Evita erros comuns como confundir IC com p-valor isolado.",
                                "Documenta análise em formato profissional."
                              ],
                              "assessmentCriteria": [
                                "Precisão na verificação de 'contém zero' (30%)",
                                "Profundidade na interpretação de insignificância prática (25%)",
                                "Conexão clara com incerteza em previsões (20%)",
                                "Uso correto de terminologia estatística (15%)",
                                "Clareza e estrutura do relatório (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade e Estatística: Distribuição t e testes de hipóteses.",
                                "Engenharia Mecânica: Modelagem de fadiga e confiabilidade de materiais.",
                                "Programação Computacional: Implementação em Python/R para análise.",
                                "Gestão de Projetos: Tomada de decisão sob incerteza."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, interpretar ICs em modelos de regressão para coeficientes de arrasto garante que previsões de desempenho de asas sejam confiáveis, evitando designs com incerteza alta que poderiam levar a falhas estruturais ou custos excessivos em testes."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.5.2",
                        "name": "Testes de Hipóteses t para Coeficientes Individuais",
                        "description": "Realização de testes t para verificar a significância estatística de parâmetros individuais em regressão linear, testando H0: β_j = 0 contra H1: β_j ≠ 0.",
                        "specificSkills": [
                          {
                            "id": "10.1.1.5.2.1",
                            "name": "Formular hipóteses e calcular estatística t",
                            "description": "Definir H0 e H1, computar t = β̂_j / SE(β̂_j) e comparar com valores críticos da t de Student com n-k-1 graus de liberdade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o contexto e formular as hipóteses H0 e H1",
                                  "subSteps": [
                                    "Identifique o coeficiente β̂_j de interesse no modelo de regressão linear.",
                                    "Defina a hipótese nula H0: β_j = 0 (o coeficiente não é significativo).",
                                    "Defina a hipótese alternativa H1: β_j ≠ 0 (teste bicaudal) ou β_j > 0 / β_j < 0 (unicaudal).",
                                    "Especifique o nível de significância α (ex: 0,05).",
                                    "Documente as hipóteses claramente."
                                  ],
                                  "verification": "Verifique se H0 e H1 estão escritas corretamente e coerentes com o coeficiente testado.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Modelo de regressão ajustado",
                                    "Documentação do dataset"
                                  ],
                                  "tips": "Sempre use notação padrão: H0: β_j = 0 vs H1: β_j ≠ 0 para testes bicaudais.",
                                  "learningObjective": "Formular hipóteses claras e apropriadas para testes de significância de coeficientes.",
                                  "commonMistakes": [
                                    "Confundir H0 com H1",
                                    "Esquecer de especificar o tipo de teste (bicaudal/unicaudal)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Obter os valores de β̂_j e SE(β̂_j)",
                                  "subSteps": [
                                    "Ajuste o modelo de regressão linear usando mínimos quadrados ordinários (MQO).",
                                    "Extraia o estimador β̂_j do output do modelo.",
                                    "Extraia o erro padrão SE(β̂_j) da tabela de summary.",
                                    "Confirme que os valores foram obtidos do modelo correto com n observações e k preditores.",
                                    "Registre os valores com precisão decimal adequada (ex: 4 casas)."
                                  ],
                                  "verification": "Compare os valores extraídos com o output do software para garantir exatidão.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Software de análise (Python com statsmodels, R ou Excel)",
                                    "Dataset de exemplo"
                                  ],
                                  "tips": "Use funções como summary() em R ou .summary() em Python para obter SE automaticamente.",
                                  "learningObjective": "Extrair corretamente estimadores e erros padrão de um modelo ajustado.",
                                  "commonMistakes": [
                                    "Usar β̂ em vez de SE(β̂)",
                                    "Confundir coeficientes de diferentes variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a estatística t",
                                  "subSteps": [
                                    "Aplique a fórmula t = β̂_j / SE(β̂_j).",
                                    "Realize a divisão com precisão numérica.",
                                    "Arredonde o valor de t para 3-4 casas decimais.",
                                    "Verifique o sinal do t (positivo ou negativo).",
                                    "Anote o valor calculado."
                                  ],
                                  "verification": "Recalcule manualmente ou use calculadora para confirmar o resultado.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Calculadora ou software (Python/R)",
                                    "Valores de β̂_j e SE(β̂_j)"
                                  ],
                                  "tips": "SE(β̂_j) nunca é zero; se for muito pequeno, verifique multicolinearidade.",
                                  "learningObjective": "Computar a estatística t de Student de forma precisa.",
                                  "commonMistakes": [
                                    "Dividir incorretamente (ex: SE pelo β)",
                                    "Ignorar o sinal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Determinar graus de liberdade, valor crítico e concluir o teste",
                                  "subSteps": [
                                    "Calcule graus de liberdade df = n - k - 1, onde n=amostra, k=preditores.",
                                    "Obtenha o valor crítico t_crítico da tabela t de Student para df e α/2 (bicaudal).",
                                    "Compare |t| com |t_crítico|: se |t| > |t_crítico|, rejeite H0.",
                                    "Alternativamente, calcule p-valor e compare com α.",
                                    "Interprete: 'Há evidência significativa de que β_j ≠ 0 ao nível α.'"
                                  ],
                                  "verification": "Confira df correto e consulte tabela ou função qt() em R/pt.t() em Python.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tabela da distribuição t",
                                    "Software para p-valor (scipy.stats.t em Python)"
                                  ],
                                  "tips": "Para grandes n, t aproxima normal; use p-valores para precisão.",
                                  "learningObjective": "Comparar estatística t com valores críticos e interpretar resultados.",
                                  "commonMistakes": [
                                    "Erro em df (ex: esquecer -1)",
                                    "Comparar t sem valor absoluto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão salário = β0 + β1*anos_experiencia + β2*educacao + e, com n=50, k=2: H0: β1=0, β̂1=1500, SE(β̂1)=300 → t=1500/300=5. df=50-2-1=47. t_crítico(α=0.05)=2.01. Como 5>2.01, rejeite H0: experiência afeta salário significativamente.",
                              "finalVerifications": [
                                "H0 e H1 formuladas corretamente para o coeficiente j.",
                                "β̂_j e SE(β̂_j) extraídos com precisão do modelo.",
                                "Estatística t calculada corretamente via fórmula.",
                                "Graus de liberdade df = n-k-1 exatos.",
                                "Comparação com t_crítico ou p-valor leva a conclusão válida.",
                                "Interpretação coerente com nível de significância."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação de hipóteses (100% correto).",
                                "Correção no cálculo de t (erro <0.01).",
                                "Cálculo exato de df e valor crítico.",
                                "Lógica na decisão de rejeitar/aceitar H0.",
                                "Clareza na interpretação e documentação.",
                                "Uso adequado de materiais e avoidance de erros comuns."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuição t de Student e testes de hipóteses.",
                                "Programação: Implementação em Python/R para automação de cálculos.",
                                "Econometria: Aplicação em modelos de regressão econômica.",
                                "Pesquisa Científica: Inferência em experimentos e dados observacionais."
                              ],
                              "realWorldApplication": "Em análise de dados de marketing, testar se o gasto em publicidade (β_j) impacta vendas significativamente, auxiliando decisões de orçamento em empresas como Amazon ou varejistas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.2.2",
                            "name": "Usar p-valores e regiões críticas",
                            "description": "Interpretar p-valores para rejeição de H0 a 5% de significância e delinear regiões de aceitação/rejeição em aplicações econométricas de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de p-valores e Regiões Críticas",
                                  "subSteps": [
                                    "Defina hipótese nula (H0) como o coeficiente βj = 0 em regressão linear.",
                                    "Explique p-valor como a probabilidade de observar o teste estatística sob H0.",
                                    "Descreva nível de significância α = 5% (0.05) e sua relação com rejeição de H0.",
                                    "Diferencie região de rejeição (p < α) da região de aceitação (p ≥ α).",
                                    "Revise distribuição t de Student para testes em amostras pequenas."
                                  ],
                                  "verification": "Resuma em suas palavras os conceitos e forneça um diagrama simples de regiões críticas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de econometria (ex: Wooldridge), notas de aula, calculadora.",
                                  "tips": "Use analogias como 'p-valor é o risco de erro tipo I' para fixar o conceito.",
                                  "learningObjective": "Dominar definições e interpretação básica de p-valores em testes t.",
                                  "commonMistakes": "Confundir p-valor com probabilidade de H0 ser verdadeira; sempre é sob H0."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar p-valores em Outputs de Regressão Linear",
                                  "subSteps": [
                                    "Execute uma regressão linear simples usando software (ex: OLS em Python ou R).",
                                    "Localize a coluna de p-valores na tabela de resultados (t-stat e p-value).",
                                    "Compare p-valor com α = 0.05: rejeite H0 se p < 0.05.",
                                    "Interprete economicamente: 'Coeficiente significativo implica relação causal presumida'.",
                                    "Registre decisões para múltiplos coeficientes."
                                  ],
                                  "verification": "Analise um output de regressão e justifique rejeição/aceitação para cada coeficiente.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python (statsmodels), R, dataset de regressão exemplo (ex: housing prices).",
                                  "tips": "Sempre cheque graus de liberdade para distribuição t correta.",
                                  "learningObjective": "Aplicar regra de decisão p-valor em saídas reais de software.",
                                  "commonMistakes": "Ignorar suposições de regressão (ex: normalidade de resíduos) antes de interpretar."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Delinear Regiões de Aceitação e Rejeição",
                                  "subSteps": [
                                    "Calcule estatística t = (β̂j - 0) / SE(β̂j) manualmente ou via software.",
                                    "Determine valores críticos t da tabela t para α/2 (bidirecional) e graus de liberdade.",
                                    "Desenhe eixo numérico com região de rejeição (|t| > t_crítico) e aceitação.",
                                    "Marque t-observado e p-valor correspondente no gráfico.",
                                    "Valide com quantis da distribuição t em software."
                                  ],
                                  "verification": "Crie um gráfico anotado mostrando regiões para um teste específico.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Tabela de distribuição t, software de plotagem (Matplotlib ou ggplot), calculadora.",
                                  "tips": "Para testes unilaterais, ajuste α para um lado só.",
                                  "learningObjective": "Visualizar e calcular regiões críticas para decisões de hipótese.",
                                  "commonMistakes": "Usar Z em vez de t para amostras pequenas; esqueça df = n - k - 1."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Contexto Econométrico de Engenharia",
                                  "subSteps": [
                                    "Selecione dataset de engenharia econômica (ex: investimento em infraestrutura vs. produtividade).",
                                    "Estime modelo OLS com coeficientes relevantes e teste H0: β_invest = 0.",
                                    "Interprete p-valor e regiões para recomendar políticas de engenharia.",
                                    "Discuta limitações como multicolinearidade ou heterocedasticidade.",
                                    "Gere relatório com conclusões baseadas em testes."
                                  ],
                                  "verification": "Produza relatório com interpretação correta e gráfico de regiões.",
                                  "estimatedTime": "1 hora 30 minutos",
                                  "materials": "Dataset real (ex: World Bank engineering econ data), Jupyter Notebook.",
                                  "tips": "Integre com intervalos de confiança para robustez.",
                                  "learningObjective": "Integrar p-valores e regiões em análises aplicadas de engenharia.",
                                  "commonMistakes": "Generalizar causalidade sem controles adequados."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão linear prevendo produtividade industrial (Y) por investimento em máquinas (X1) e horas de treinamento (X2), o output mostra p-valor de 0.03 para β_X1. Rejeite H0: β_X1=0 a 5%, indicando que investimento afeta significativamente a produtividade; delinhe regiões com t_crítico ≈ ±1.96 para df=50.",
                              "finalVerifications": [
                                "Corretamente rejeita H0 quando p < 0.05 em 5 exemplos.",
                                "Desenha regiões críticas precisas para testes t bidirecionais.",
                                "Explica interpretação econômica sem confundir significância com magnitude.",
                                "Identifica quando p-valor alto implica não-rejeição válida.",
                                "Valida cálculos com software e manualmente.",
                                "Discute implicações em contexto de engenharia econômica."
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de p-valores (90% acerto em testes).",
                                "Qualidade de diagramas de regiões críticas (clareza e exatidão).",
                                "Profundidade de sub-passos executados (todos completos).",
                                "Correção de erros comuns identificados e evitados.",
                                "Relatório final coerente com aplicações reais.",
                                "Tempo respeitado e eficiência demonstrada."
                              ],
                              "crossCurricularConnections": [
                                "Economia: Modelos de produção Cobb-Douglas em engenharia industrial.",
                                "Programação: Uso de statsmodels em Python para automação de testes.",
                                "Engenharia: Análise custo-benefício de projetos de infraestrutura.",
                                "Estatística: Extensão a testes F e robustez em regressão."
                              ],
                              "realWorldApplication": "Em projetos de engenharia civil, use p-valores para testar se o gasto em manutenção rodoviária reduz significativamente acidentes (regressão: acidentes ~ manutenção + tráfego), guiando alocação orçamentária com evidência estatística a 5% de significância."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.2.3",
                            "name": "Aplicar teste t em software",
                            "description": "Executar testes t em R ou similar, extrair coeficientes, erros padrão e p-valores de sumários de regressão.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e os dados para regressão",
                                  "subSteps": [
                                    "Instale e carregue o pacote necessário (ex: base R para lm()).",
                                    "Carregue o dataset (ex: mtcars).",
                                    "Explore os dados com summary() e plot() para verificar outliers ou multicolinearidade.",
                                    "Defina a fórmula do modelo (ex: mpg ~ wt + hp).",
                                    "Ajuste o modelo linear com lm(formula, data)."
                                  ],
                                  "verification": "Confirme que o objeto do modelo (ex: model <- lm(...)) foi criado sem erros e class(model) retorna 'lm'.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "R ou RStudio instalado, dataset mtcars (disponível no R base).",
                                  "tips": "Sempre use data = nome_do_dataset para evitar erros de scoping.",
                                  "learningObjective": "Configurar corretamente um modelo de regressão linear em software estatístico.",
                                  "commonMistakes": [
                                    "Esquecer de especificar data= no lm(), causando erros de variáveis não encontradas.",
                                    "Não verificar multicolinearidade antes do ajuste."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar o sumário do modelo para testes t",
                                  "subSteps": [
                                    "Execute summary(model) para obter a tabela de coeficientes.",
                                    "Identifique as colunas: Estimate (coeficiente), Std. Error (erro padrão), t value e Pr(>|t|) (p-valor).",
                                    "Registre os valores para cada preditor.",
                                    "Verifique o R-squared e F-statistic para overview do modelo.",
                                    "Salve o sumário em um objeto se necessário (ex: sum_model <- summary(model))."
                                  ],
                                  "verification": "A saída de summary() mostra tabela com coeficientes, SE, t e p-values sem NAs ou warnings.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Objeto do modelo ajustado do Step 1.",
                                  "tips": "Use capture.output(summary(model)) para salvar a saída em texto se precisar exportar.",
                                  "learningObjective": "Extrair estatísticas de inferência do sumário de regressão.",
                                  "commonMistakes": [
                                    "Confundir t-value com p-value.",
                                    "Ignorar o sinal do coeficiente ao interpretar."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Extrair e interpretar valores do teste t",
                                  "subSteps": [
                                    "Acesse coeficientes com coef(model), erros padrão com summary(model)$coefficients[,2].",
                                    "Calcule manualmente t = coef / SE para verificação.",
                                    "Interprete p-valores: <0.05 indica rejeição de H0 (coef=0).",
                                    "Extraia p-values com summary(model)$coefficients[,4].",
                                    "Crie um data.frame com os valores extraídos para relatório."
                                  ],
                                  "verification": "Crie um vetor ou tabela com valores extraídos e compare com summary() manualmente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Pacote base R, objeto summary do Step 2.",
                                  "tips": "Use broom::tidy(model) para tabela limpa e fácil extração.",
                                  "learningObjective": "Interpretar e extrair componentes do teste t para inferência sobre coeficientes.",
                                  "commonMistakes": [
                                    "Interpretar p-value sem contexto de significância (ex: sempre 0.05).",
                                    "Não considerar o nível de confiança ou múltiplos testes."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e relatar resultados do teste t",
                                  "subSteps": [
                                    "Teste resíduos com plot(model) para homocedasticidade e normalidade.",
                                    "Confirme significância: liste preditores com p<0.05.",
                                    "Escreva relatório: 'Coef de wt: X (SE=Y, t=Z, p=W) - significativo'.",
                                    "Compare com hipótese nula (beta=0).",
                                    "Salve resultados em CSV ou relatório Markdown."
                                  ],
                                  "verification": "Relatório escrito confirma interpretações corretas e resíduos OK (sem padrões nos plots).",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Gráficos de diagnóstico do modelo.",
                                  "tips": "Use confint(model) para intervalos de confiança complementares.",
                                  "learningObjective": "Validar e comunicar resultados de testes t em contexto de regressão.",
                                  "commonMistakes": [
                                    "Afirmar causalidade de correlação.",
                                    "Não checar suposições do modelo (ex: linearidade)."
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset mtcars: ajuste model <- lm(mpg ~ wt + hp, data=mtcars). Em summary(model), extraia para wt: coef=-5.34, SE=1.02, t=-5.24, p<0.001 (significativo); hp: coef=-0.03, SE=0.02, t=-1.71, p=0.10 (não significativo). Conclusão: peso afeta negativamente mpg.",
                              "finalVerifications": [
                                "Summary() exibe todos os valores corretos sem erros.",
                                "P-values interpretados corretamente (ex: <0.05 significativo).",
                                "Extração manual de coef, SE e p bate com summary().",
                                "Resíduos plots sem violações claras de suposições.",
                                "Relatório escrito resume achados com linguagem estatística precisa.",
                                "Intervalos de confiança consistentes com testes t."
                              ],
                              "assessmentCriteria": [
                                "Precisão na execução de lm() e summary() (100% match com output esperado).",
                                "Correta extração e cálculo de t-statistic (erro <1%).",
                                "Interpretação de p-values alinhada com nível de significância.",
                                "Validação de suposições do modelo via plots.",
                                "Relatório claro, conciso e com evidências numéricas.",
                                "Uso eficiente de comandos R sem código desnecessário."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Hipóteses nulas/alternativas e distribuição t.",
                                "Programação: Manipulação de objetos e extração de matrizes em R/Python.",
                                "Análise de Dados: Diagnóstico de modelos e validação.",
                                "Matemática: Álgebra linear em matrizes de covariância.",
                                "Ciência de Dados: Aplicação em machine learning para feature selection."
                              ],
                              "realWorldApplication": "Em pesquisa de mercado, testar se preço afeta vendas (regressão); em saúde, verificar se dose de medicamento impacta recuperação; em finanças, analisar se variáveis macroeconômicas predizem retornos de ações, guiando decisões baseadas em significância estatística."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.1.5.3",
                        "name": "Teste F para Significância Global do Modelo",
                        "description": "Teste F conjunto para avaliar se o modelo de regressão é estatisticamente significativo, testando H0: todos β_j = 0 (exceto intercepto).",
                        "specificSkills": [
                          {
                            "id": "10.1.1.5.3.1",
                            "name": "Derivar a estatística F",
                            "description": "Calcular F = (R² / k) / ((1-R²)/(n-k-1)), relacionando com a variância explicada e resíduos, sob pressupostos de normalidade e homocedasticidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de R² e Somas de Quadrados",
                                  "subSteps": [
                                    "Defina R² como a proporção da variância total explicada pelo modelo: R² = SSR / SST, onde SSR é a soma de quadrados da regressão e SST é a soma de quadrados total.",
                                    "Calcule SSE (soma de quadrados dos resíduos) como SST - SSR.",
                                    "Expresse R² em termos de variância: R² = 1 - (SSE / SST).",
                                    "Identifique k (número de preditores) e n (tamanho da amostra).",
                                    "Verifique a relação entre variância explicada e resíduos."
                                  ],
                                  "verification": "Escreva as fórmulas de SSR, SSE e SST para um dataset de exemplo e confirme que R² soma corretamente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Calculadora",
                                    "Dataset simples de regressão (ex: Excel ou CSV)"
                                  ],
                                  "tips": "Use um exemplo numérico pequeno (n=10) para visualizar as somas de quadrados.",
                                  "learningObjective": "Compreender como R² relaciona variância explicada e resíduos na regressão linear.",
                                  "commonMistakes": "Confundir SSR com SST ou esquecer que k exclui o intercepto."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar Estimativas de Variância para o Modelo e Resíduos",
                                  "subSteps": [
                                    "Calcule a variância explicada pelo modelo: MSR = SSR / k.",
                                    "Calcule a variância dos resíduos: MSE = SSE / (n - k - 1).",
                                    "Relacione MSR e MSE com R²: R² / k ≈ MSR / MST, onde MST = SST / (n-1).",
                                    "Discuta sob quais condições MSR > MSE indica ajuste bom.",
                                    "Simplifique expressões algébricas para preparar a razão F."
                                  ],
                                  "verification": "Compute MSR e MSE para o mesmo dataset e verifique se MSE é menor que MSR em um bom modelo.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Software estatístico (R ou Python com statsmodels)",
                                    "Papel para derivações algébricas"
                                  ],
                                  "tips": "Anote todas as divisões por graus de liberdade para evitar erros dimensionais.",
                                  "learningObjective": "Calcular estimativas de variância e relacioná-las com graus de liberdade.",
                                  "commonMistakes": "Esquecer de subtrair k+1 nos graus de liberdade para MSE."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Formular a Estatística F como Razão de Variâncias",
                                  "subSteps": [
                                    "Defina F como a razão MSR / MSE sob a hipótese nula (todos coeficientes β=0 exceto intercepto).",
                                    "Substitua R² na fórmula: F = [R² / k] / [(1 - R²) / (n - k - 1)].",
                                    "Derive algebricamente a partir de somas de quadrados: F = (SSR / k) / (SSE / (n - k - 1)).",
                                    "Confirme que sob H0, F ~ F(k, n-k-1).",
                                    "Teste a derivação com valores numéricos."
                                  ],
                                  "verification": "Derive a fórmula F passo a passo e aplique a um dataset para obter o valor exato.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Python/R para regressão",
                                    "Folha de cálculo para verificação manual"
                                  ],
                                  "tips": "Comece da definição de F e volte para R² para reforçar a conexão.",
                                  "learningObjective": "Derivar a fórmula exata de F e entender sua distribuição.",
                                  "commonMistakes": "Invertar numerador e denominador ou usar df incorretos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Incorporar Pressupostos e Interpretação do Teste F",
                                  "subSteps": [
                                    "Liste pressupostos: normalidade dos erros, homocedasticidade, independência e linearidade.",
                                    "Explique como violações afetam a validade de F (ex: heteroscedasticidade infla F).",
                                    "Interprete p-valor: rejeitar H0 se p < α indica modelo global significativo.",
                                    "Compare com testes t individuais.",
                                    "Pratique com software para output de F automatizado."
                                  ],
                                  "verification": "Aplique teste F em um dataset violando um pressuposto e discuta impactos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Tutoriais de R/Python para diagnóstico de resíduos",
                                    "Gráficos QQ e resíduos vs fitted"
                                  ],
                                  "tips": "Sempre verifique resíduos após derivar F para validar pressupostos.",
                                  "learningObjective": "Relacionar F com pressupostos e interpretar resultados práticos.",
                                  "commonMistakes": "Ignorar pressupostos ou confundir significância global com preditores individuais."
                                }
                              ],
                              "practicalExample": "Considere um dataset de 20 casas com preço (Y) predito por área (X1) e quartos (X2). Calcule R²=0.85, k=2, n=20. Então F = (0.85/2) / (0.15/17) ≈ 47.6. Use R: lm(preco ~ area + quartos, data=houses); summary(model) para verificar F e p-valor <0.001, confirmando modelo significativo.",
                              "finalVerifications": [
                                "Derivação correta da fórmula F a partir de R².",
                                "Cálculo numérico de F coincide com software.",
                                "Identificação precisa de graus de liberdade (k e n-k-1).",
                                "Explicação clara dos pressupostos de normalidade e homocedasticidade.",
                                "Interpretação correta: rejeição de H0 para R² alto.",
                                "Verificação de resíduos para validar F."
                              ],
                              "assessmentCriteria": [
                                "Precisão algébrica na derivação (100% das etapas corretas).",
                                "Uso correto de graus de liberdade e componentes de variância.",
                                "Integração de pressupostos com impacto na validade de F.",
                                "Exemplo prático com cálculo manual e software concordantes.",
                                "Explicação clara da relação entre F, R² e significância global.",
                                "Identificação de erros comuns evitados na derivação."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Implementar teste F em Python/R para análise de dados.",
                                "Econometria: Usar F em modelos de previsão econômica.",
                                "Probabilidade: Entender distribuição F central e não-central.",
                                "Visualização de Dados: Gráficos de resíduos para checar homocedasticidade."
                              ],
                              "realWorldApplication": "Em machine learning, o teste F determina se um modelo de regressão linear (ex: previsão de vendas baseado em marketing e sazonalidade) explica significativamente a variância dos dados antes de prosseguir para modelos mais complexos, economizando recursos computacionais em grandes datasets empresariais."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.3.2",
                            "name": "Interpretar teste F e R² ajustado",
                            "description": "Decidir sobre a significância do modelo via p-valor do F e analisar R² ajustado para penalizar complexidade em contextos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos do teste F em regressão linear",
                                  "subSteps": [
                                    "Defina a hipótese nula (H₀): todos os coeficientes dos preditores são zero (β₁ = β₂ = ... = βₖ = 0).",
                                    "Explique a estatística F como a razão entre a variância explicada pelo modelo e a variância residual.",
                                    "Identifique os graus de liberdade: numerador (k, número de preditores) e denominador (n - k - 1, onde n é o tamanho da amostra).",
                                    "Consulte a tabela F ou software para valores críticos.",
                                    "Relacione o teste F à significância global do modelo."
                                  ],
                                  "verification": "Resuma em uma frase o que o teste F avalia e liste as hipóteses envolvidas.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Software de regressão (R, Python com statsmodels ou Excel)",
                                    "Tabela de distribuição F"
                                  ],
                                  "tips": "Sempre comece pela H₀ para contextualizar a interpretação.",
                                  "learningObjective": "Entender o propósito e componentes matemáticos do teste F.",
                                  "commonMistakes": [
                                    "Confundir teste F com testes t individuais",
                                    "Ignorar graus de liberdade ao interpretar p-valor"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar o p-valor do teste F",
                                  "subSteps": [
                                    "Obtenha o p-valor da saída do modelo de regressão.",
                                    "Compare o p-valor com o nível de significância α (tipicamente 0.05).",
                                    "Se p < α, rejeite H₀: o modelo é significativo globalmente.",
                                    "Se p ≥ α, não rejeite H₀: o modelo não explica a variância significativamente.",
                                    "Documente a decisão em termos de evidência estatística."
                                  ],
                                  "verification": "Para um p-valor de 0.03 e α=0.05, decida e justifique corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Exemplo de saída de regressão (ANOVA table)"
                                  ],
                                  "tips": "Lembre-se: p-valor baixo indica que o modelo como um todo é útil.",
                                  "learningObjective": "Aplicar regras de decisão baseadas no p-valor do F.",
                                  "commonMistakes": [
                                    "Interpretar p-valor como probabilidade do modelo ser verdadeiro",
                                    "Usar α diferente sem justificativa"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Entender e calcular o R² ajustado",
                                  "subSteps": [
                                    "Recapitule R² como proporção da variância total explicada pelo modelo.",
                                    "Apresente a fórmula do R² ajustado: 1 - [(1 - R²)(n-1)/(n - k - 1)].",
                                    "Calcule R² ajustado manualmente para um exemplo simples.",
                                    "Compare R² e R² ajustado: o ajustado penaliza mais preditores.",
                                    "Interprete valores: próximo de 1 indica bom ajuste penalizado."
                                  ],
                                  "verification": "Calcule R² ajustado dado R²=0.85, n=50, k=3 e verifique se é menor que R².",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora ou planilha Excel",
                                    "Fórmulas impressas"
                                  ],
                                  "tips": "Use R² ajustado sempre que comparar modelos com diferentes números de variáveis.",
                                  "learningObjective": "Dominar a fórmula e interpretação do R² ajustado.",
                                  "commonMistakes": [
                                    "Confundir R² com R² ajustado em modelos complexos",
                                    "Ignorar o impacto de n pequeno"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar interpretações para decisão sobre o modelo em engenharia",
                                  "subSteps": [
                                    "Combine: se teste F significativo e R² ajustado alto (>0.7), modelo bom.",
                                    "Avalie trade-off: alto R² mas baixo ajustado sugere overfitting.",
                                    "Decida: rejeitar, aceitar ou simplificar o modelo.",
                                    "Considere contexto de engenharia: custo de preditores vs. precisão.",
                                    "Registre conclusão com justificativa estatística."
                                  ],
                                  "verification": "Dado um exemplo, recomende ação baseada em F e R² ajustado.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset de engenharia exemplo (ex: resistência vs. variáveis)"
                                  ],
                                  "tips": "Priorize R² ajustado em cenários com múltiplos preditores.",
                                  "learningObjective": "Tomar decisões holísticas sobre significância e ajuste do modelo.",
                                  "commonMistakes": [
                                    "Aceitar modelo só por F significativo sem checar R² ajustado",
                                    "Desconsiderar aplicação prática"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um estudo de engenharia mecânica, modelo de regressão prevê a resistência à tração (Y) de ligas metálicas com preditores temperatura (X1) e pressão (X2), n=40. Saída: F=12.5, p=0.001, R²=0.45, R² ajustado=0.42. Interpretação: Modelo significativo globalmente (rejeitar H₀), mas R² ajustado moderado sugere cautela; teste simplificação removendo X2.",
                              "finalVerifications": [
                                "Explicar corretamente H₀ do teste F e sua rejeição.",
                                "Interpretar p-valor=0.01 como evidência de significância.",
                                "Calcular R² ajustado e notar penalidade por complexidade.",
                                "Decidir sobre modelo dado F significativo mas R² ajustado baixo.",
                                "Relacionar a penalização do R² ajustado em contextos multivariados.",
                                "Identificar quando priorizar R² ajustado sobre R²."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e interpretação do teste F (30%)",
                                "Correta aplicação de regras de p-valor e decisão (25%)",
                                "Domínio da fórmula e cálculo de R² ajustado (20%)",
                                "Integração coerente das métricas para recomendação (15%)",
                                "Relevância ao contexto de engenharia (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade e Estatística: Distribuição F e testes de hipóteses.",
                                "Programação Computacional: Implementação em Python/R para regressão.",
                                "Engenharia Mecânica: Modelagem preditiva de materiais.",
                                "Análise de Dados: Seleção de modelos e validação cruzada."
                              ],
                              "realWorldApplication": "Em engenharia, usado para validar modelos preditivos de falhas estruturais (ex: fadiga em pontes), otimizando designs ao rejeitar modelos insignificantes ou overfitados, economizando recursos em testes físicos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.1.5.3.3",
                            "name": "Comparar testes t e F",
                            "description": "Explicar a relação entre testes t individuais e o teste F global, identificando inconsistências potenciais em modelos econométricos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos dos Testes t e F",
                                  "subSteps": [
                                    "Defina o teste t individual: hipótese nula de coeficiente igual a zero para cada variável independente.",
                                    "Explique o teste F global: testa se todos os coeficientes são conjuntamente zero.",
                                    "Compare estatísticas: t-statistic para uma variável vs F-statistic para o modelo inteiro.",
                                    "Discuta p-valores: significância individual vs global.",
                                    "Revise fórmulas básicas: t = β_hat / SE(β_hat), F = (SSR/RSS) * (n-k-1)/k."
                                  ],
                                  "verification": "Escreva definições curtas e fórmulas para t e F, confirmando com um textbook ou output de regressão.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de econometria",
                                    "Software R/Python com exemplo de regressão (lm() ou statsmodels)"
                                  ],
                                  "tips": "Use outputs reais de regressão para visualizar t e F lado a lado.",
                                  "learningObjective": "Compreender as diferenças fundamentais entre testes t individuais e F global.",
                                  "commonMistakes": [
                                    "Confundir significância individual com global",
                                    "Ignorar graus de liberdade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a Relação Matemática entre Testes t e F",
                                  "subSteps": [
                                    "Derive que F para uma variável única é o quadrado do t: F = t².",
                                    "Mostre que se todos t forem insignificantes, F pode ainda ser significativo (efeitos conjuntos).",
                                    "Demonstre matematicamente: F global é uma média ponderada dos F individuais.",
                                    "Calcule exemplos numéricos: use coeficientes e erros padrão para computar t e F.",
                                    "Interprete: F rejeita H0 só se pelo menos um t rejeita, mas não vice-versa."
                                  ],
                                  "verification": "Calcule t e F manualmente para um modelo com 1 variável e verifique F = t².",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Calculadora ou Excel",
                                    "Dados de regressão simples (ex: mtcars em R)"
                                  ],
                                  "tips": "Comece com modelo univariado para simplificar a derivação.",
                                  "learningObjective": "Dominar a equivalência matemática e as implicações relacionais.",
                                  "commonMistakes": [
                                    "Assumir que t significativos implicam sempre F significativo",
                                    "Erros em cálculos de graus de liberdade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar Inconsistências Potenciais em Modelos",
                                  "subSteps": [
                                    "Explique inconsistência tipo 1: Todos t insignificantes, mas F significativo (multicolinearidade ou efeitos conjuntos).",
                                    "Descreva inconsistência tipo 2: Algum t significativo, mas F insignificante (raro, indica problemas de especificação).",
                                    "Analise causas: multicolinearidade, amostra pequena, variáveis irrelevantes.",
                                    "Discuta implicações econométricas: risco de omitir variáveis ou overfit.",
                                    "Use diagnóstico: VIF para multicolinearidade quando F > t's."
                                  ],
                                  "verification": "Identifique pelo menos duas causas de inconsistência em um summary de regressão.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Output de regressão com multicolinearidade (ex: dados simulados)",
                                    "Documentação de VIF"
                                  ],
                                  "tips": "Simule dados com correlação alta entre X's para observar o fenômeno.",
                                  "learningObjective": "Reconhecer e diagnosticar discrepâncias entre t e F.",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade como causa principal",
                                    "Concluir modelo inválido prematuramente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Comparação em um Exemplo Prático",
                                  "subSteps": [
                                    "Carregue dados e rode regressão: salário ~ educação + experiência.",
                                    "Compare summary: cheque t's vs F global e p-valores.",
                                    "Interprete inconsistências: se F sig mas t's não, discuta efeitos conjuntos.",
                                    "Ajuste modelo: remova variáveis e re-compare t e F.",
                                    "Conclua sobre validade do modelo com base na comparação."
                                  ],
                                  "verification": "Gere relatório escrito comparando t e F no exemplo, destacando insights.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "R ou Python (statsmodels/OLS)",
                                    "Dataset WOE dataset ou similar"
                                  ],
                                  "tips": "Salve outputs em PDF para referência visual.",
                                  "learningObjective": "Aplicar conceitos para validar modelos econométricos reais.",
                                  "commonMistakes": [
                                    "Não checar pressupostos da regressão antes",
                                    "Sobreinterpretar p-valores sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão de salário sobre educação e experiência (dados simulados: n=100), observe t insignificantes para cada (p>0.05), mas F global significativo (p<0.01). Isso indica efeitos conjuntos: juntos explicam variância, mas individualmente não, devido a correlação entre preditores.",
                              "finalVerifications": [
                                "Explicar verbalmente a relação F = t² para k=1.",
                                "Identificar causa de 'todos t insignificantes, F significativo'.",
                                "Diagnosticar inconsistência em output de regressão real.",
                                "Propor ajuste de modelo baseado em comparação t/F.",
                                "Discutir implicações para inferência econométrica.",
                                "Calcular manualmente t e F de coeficientes dados."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação matemática (F=t² e generalização).",
                                "Correta identificação de inconsistências e causas (multicolinearidade).",
                                "Interpretação contextual em exemplos práticos.",
                                "Uso adequado de software para validação.",
                                "Clareza na explicação de implicações econométricas.",
                                "Ausência de erros comuns em fórmulas ou conceitos."
                              ],
                              "crossCurricularConnections": [
                                "Economia: Validação de modelos de produção ou demanda.",
                                "Programação: Implementação em R/Python para automação de testes.",
                                "Estatística Avançada: Extensão a testes de Chow ou Hausman.",
                                "Machine Learning: Paralelo com feature importance vs model R²."
                              ],
                              "realWorldApplication": "Em análise de políticas econômicas, como avaliar impacto conjunto de incentivos fiscais em investimento; inconsistências t/F alertam para multicolinearidade, evitando conclusões erradas sobre políticas isoladas."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.2",
                "name": "Propriedades Estatísticas e Inferência",
                "description": "Discute propriedades estatísticas dos estimadores, inferência estatística e testes de hipótese para validação de modelos.",
                "totalSkills": 37,
                "atomicTopics": [
                  {
                    "id": "10.1.2.1",
                    "name": "Propriedades Estatísticas dos Estimadores OLS",
                    "description": "Viés, consistência, eficiência e normalidade dos estimadores de mínimos quadrados ordinários sob pressupostos clássicos.",
                    "individualConcepts": [
                      {
                        "id": "11.2.1.1",
                        "name": "Viés dos Estimadores OLS",
                        "description": "Definição de viés e demonstração de que os estimadores de mínimos quadrados ordinários (OLS) são não viesados sob os pressupostos clássicos básicos de regressão linear, como linearidade condicional, amostra aleatória, ausência de multicolinearidade perfeita e exogeneidade dos erros.",
                        "specificSkills": [
                          {
                            "id": "11.2.1.1.1",
                            "name": "Definir o viés de um estimador",
                            "description": "Explicar a definição matemática de viés como a diferença entre o valor esperado do estimador e o verdadeiro parâmetro populacional, ou seja, Bias(β̂) = E(β̂) - β, e interpretar seu significado em termos de precisão pontual.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Conceitos Fundamentais: Parâmetro Populacional e Estimador",
                                  "subSteps": [
                                    "Defina o parâmetro populacional θ como uma quantidade desconhecida que descreve a população inteira.",
                                    "Explique o estimador θ̂ como uma função estatística calculada a partir de uma amostra aleatória.",
                                    "Diferencie população (todo o conjunto) de amostra (subconjunto observável).",
                                    "Discuta por que usamos estimadores: impossibilidade de observar toda a população.",
                                    "Ilustre com exemplo: θ = média populacional μ, θ̂ = média amostral x̄."
                                  ],
                                  "verification": "Escreva definições curtas para θ e θ̂ e forneça um exemplo numérico simples.",
                                  "estimatedTime": "20-25 minutos",
                                  "materials": [
                                    "Quadro branco ou papel para anotações",
                                    "Calculadora",
                                    "Livro de estatística básica (capítulo de inferência)"
                                  ],
                                  "tips": [
                                    "Use analogias cotidianas, como estimar altura média de uma cidade com uma amostra de moradores.",
                                    "Desenhe diagramas de população vs. amostra para visualização."
                                  ],
                                  "learningObjective": "Compreender a distinção entre parâmetro fixo e estimador aleatório.",
                                  "commonMistakes": [
                                    "Confundir estimador com estimativa pontual.",
                                    "Achar que amostra representa perfeitamente a população sem variabilidade."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Conceituar o Valor Esperado de um Estimador",
                                  "subSteps": [
                                    "Defina o valor esperado E(θ̂) como a média de longo prazo de θ̂ sobre muitas amostras repetidas.",
                                    "Explique que E(θ̂) é uma constante, mesmo que θ̂ varie entre amostras.",
                                    "Calcule E(x̄) = μ para a média amostral como exemplo de propriedade.",
                                    "Discuta repetições hipotéticas: simule lançando dados múltiplas vezes.",
                                    "Compare E(θ̂) com θ: igualdade indica 'não viesado'."
                                  ],
                                  "verification": "Simule 10 amostras pequenas e calcule a média das médias amostrais; verifique proximidade com μ assumido.",
                                  "estimatedTime": "25-30 minutos",
                                  "materials": [
                                    "Software como R ou Python (função mean() em loop)",
                                    "Planilha Excel para simulações",
                                    "Gerador de números aleatórios online"
                                  ],
                                  "tips": [
                                    "Pense em E(θ̂) como 'centro de gravidade' das distribuições de θ̂.",
                                    "Use simulações para intuição em vez de provas matemáticas iniciais."
                                  ],
                                  "learningObjective": "Dominar o conceito de expectativa como média teórica de estimadores.",
                                  "commonMistakes": [
                                    "Confundir E(θ̂) com uma média amostral única.",
                                    "Ignorar que expectativa requer amostragem infinita ideal."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir Matematicamente o Viés do Estimador",
                                  "subSteps": [
                                    "Escreva a fórmula: Bias(θ̂) = E(θ̂) - θ.",
                                    "Interprete: viés positivo significa superestimação sistemática; negativo, subestimação.",
                                    "Classifique: se Bias(θ̂) = 0 para todo θ, o estimador é não viesado.",
                                    "Derive para média amostral: Bias(x̄) = E(x̄) - μ = μ - μ = 0.",
                                    "Estenda para estimadores OLS: β̂ OLS é não viesado sob pressupostos lineares."
                                  ],
                                  "verification": "Escreva a fórmula Bias(β̂) = E(β̂) - β e compute para um estimador simples como x̄.",
                                  "estimatedTime": "20-25 minutos",
                                  "materials": [
                                    "Folha de fórmulas estatísticas",
                                    "Calculadora simbólica ou software SymPy",
                                    "Vídeo tutorial sobre expectativa (Khan Academy)"
                                  ],
                                  "tips": [
                                    "Memorize a fórmula como 'desvio sistemático da verdade'.",
                                    "Sempre subtraia θ de E(θ̂), não o inverso."
                                  ],
                                  "learningObjective": "Aplicar e memorizar a definição exata de viés.",
                                  "commonMistakes": [
                                    "Inverter a subtração: escrever E(θ̂) - θ como θ - E(θ̂).",
                                    "Confundir viés com variância."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar o Viés em Termos de Precisão Pontual",
                                  "subSteps": [
                                    "Explique precisão pontual: estimativas próximas do verdadeiro valor em repetições.",
                                    "Viés afeta precisão: mesmo com baixa variância, viés alto causa erro sistemático.",
                                    "Compare com MSE: MSE = Variância + [Bias]^2.",
                                    "Discuta implicações: viés leva a decisões erradas consistentemente.",
                                    "Exemplo: estimador viesado em polling eleitoral superestima apoio a um candidato."
                                  ],
                                  "verification": "Descreva verbalmente por que um estimador com viés ≠ 0 é impreciso, mesmo com variância zero.",
                                  "estimatedTime": "25-30 minutos",
                                  "materials": [
                                    "Gráficos de distribuições viesadas vs. não viesadas (plotar em Python/Matplotlib)",
                                    "Artigos sobre erros em eleições por viés amostral"
                                  ],
                                  "tips": [
                                    "Visualize: plote histogramas de θ̂ centrados longe de θ para viés.",
                                    "Ligue a intuição: 'tiro sempre ao lado do alvo'."
                                  ],
                                  "learningObjective": "Interpretar viés como falha na precisão pontual sistemática.",
                                  "commonMistakes": [
                                    "Achar que baixa variância compensa viés alto.",
                                    "Confundir precisão com acurácia (acurácia inclui viés)."
                                  ]
                                }
                              ],
                              "practicalExample": "Considere estimar a probabilidade θ de cara em uma moeda viciada usando a proporção amostral θ̂ em 10 lançamentos. Se a moeda tem θ=0.6 mas você usa um estimador enviesado θ̂ = proporção + 0.1, então E(θ̂)=0.7, Bias=0.1. Simule 1000 amostras: as estimativas clusterizam em 0.7, não 0.6, mostrando superestimação sistemática.",
                              "finalVerifications": [
                                "Escreve corretamente Bias(β̂) = E(β̂) - β.",
                                "Calcula bias para média amostral e confirma =0.",
                                "Explica verbalmente o impacto de bias≠0 na precisão.",
                                "Identifica exemplo real de estimador viesado (ex: amostragem não aleatória).",
                                "Diferencia bias de variância em uma frase.",
                                "Simula e plota distribuição de estimador viesado."
                              ],
                              "assessmentCriteria": [
                                "Precisão na fórmula matemática (100% correto).",
                                "Compreensão conceitual via explicação clara e sem erros comuns.",
                                "Capacidade de aplicar em exemplo numérico simples.",
                                "Interpretação qualitativa correta (sistemático vs. aleatório).",
                                "Uso de simulações para demonstrar intuição.",
                                "Conexão com propriedades desejáveis de estimadores."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Valor esperado como integral ou soma.",
                                "Machine Learning: Viés em modelos de regressão e trade-off bias-variance.",
                                "Econometria: Viés em regressões OLS com omitted variables.",
                                "Física: Erro sistemático em medições experimentais.",
                                "Programação: Simulações Monte Carlo em Python/R."
                              ],
                              "realWorldApplication": "Em pesquisas eleitorais, um estimador viesado por amostragem não representativa (ex: só telefonemas fixos) superestima apoio a certos candidatos, levando a previsões erradas como visto em eleições de 2016 nos EUA; correção requer entender e quantificar o bias para ajustes."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.2.1.1.2",
                            "name": "Identificar pressupostos para não viés do OLS",
                            "description": "Listar e descrever os pressupostos MLR.1 a MLR.4 (linearidade no parâmetro, amostra aleatória, sem multicolinearidade perfeita e E(u|X)=0) necessários para provar que E(β̂_OLS) = β.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Modelo OLS e Conceito de Viés no Estimador",
                                  "subSteps": [
                                    "Leia a definição do modelo de regressão linear múltipla (MLR): Y = Xβ + u.",
                                    "Entenda o estimador β̂_OLS = (X'X)^{-1}X'Y.",
                                    "Defina viés: E(β̂_OLS) - β ≠ 0.",
                                    "Discuta não viés: E(β̂_OLS | X) = β.",
                                    "Anote a importância da expectativa condicional."
                                  ],
                                  "verification": "Escreva uma definição resumida de viés e não viés em suas próprias palavras, incluindo a fórmula de β̂_OLS.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre OLS",
                                    "Livro de Econometria (ex: Wooldridge)",
                                    "Calculadora ou Python/Jupyter para fórmulas"
                                  ],
                                  "tips": "Visualize graficamente o modelo linear para fixar a estrutura.",
                                  "learningObjective": "Compreender a base conceitual necessária para analisar pressupostos de não viés.",
                                  "commonMistakes": "Confundir viés com inconsistência ou variância do estimador."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Descrever Pressuposto MLR.1: Linearidade nos Parâmetros",
                                  "subSteps": [
                                    "Defina MLR.1: O modelo é linear nos parâmetros: E(Y|X) = Xβ.",
                                    "Explique que isso permite a representação Y_i = X_i β + u_i.",
                                    "Discuta implicações: captura relações lineares; não assume linearidade em X.",
                                    "Forneça contraexemplo: modelo log-linear viola se forçado linear.",
                                    "Verifique em um dataset simples se a forma linear é adequada."
                                  ],
                                  "verification": "Esboce o modelo gráfico e confirme se E(Y|X) = Xβ é satisfeito.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Dataset exemplo (ex: salários vs educação)",
                                    "Gráficos scatterplot em Excel/Python"
                                  ],
                                  "tips": "Use resíduos vs preditos para checar linearidade futuramente.",
                                  "learningObjective": "Identificar e justificar o pressuposto de linearidade como base para OLS.",
                                  "commonMistakes": "Confundir linearidade nos parâmetros com linearidade nas variáveis explicativas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Descrever Pressuposto MLR.2: Amostra Aleatória",
                                  "subSteps": [
                                    "Defina MLR.2: (X_i, Y_i) são i.i.d. de uma população.",
                                    "Explique independência: observações não correlacionadas.",
                                    "Discuta idêntica distribuição: mesma população.",
                                    "Diferencie de amostragem não aleatória (ex: seletividade).",
                                    "Liste cenários reais: surveys aleatórios vs dados de painel."
                                  ],
                                  "verification": "Descreva como uma amostra não aleatória viola MLR.2 e afeta E(β̂).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Exemplos de datasets (aleatório vs não)",
                                    "Artigo sobre amostragem"
                                  ],
                                  "tips": "Pense em experimentos randomizados como ideal para MLR.2.",
                                  "learningObjective": "Reconhecer a necessidade de amostragem aleatória para validade estatística.",
                                  "commonMistakes": "Ignorar que MLR.2 é sobre população, não tamanho da amostra."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Descrever Pressuposto MLR.3: Sem Multicolinearidade Perfeita",
                                  "subSteps": [
                                    "Defina MLR.3: Não multicolinearidade perfeita; rank(X) = K (matriz X cheia de rank).",
                                    "Explique det(X'X) ≠ 0 para invertibilidade.",
                                    "Discuta multicolinearidade perfeita: X2 = a + b X1 torna β indeterminado.",
                                    "Verifique computacionalmente: compute det(X'X) ou VIF.",
                                    "Diferencie de multicolinearidade aproximada (não viola MLR.3)."
                                  ],
                                  "verification": "Crie uma matriz X com multicolinearidade perfeita e veja falha na inversa.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software R/Python (numpy.linalg.det)",
                                    "Matrizes exemplo 3x3"
                                  ],
                                  "tips": "Sempre cheque correlações entre X's antes de rodar OLS.",
                                  "learningObjective": "Entender como MLR.3 garante existência única de β̂_OLS.",
                                  "commonMistakes": "Confundir multicolinearidade perfeita com alta correlação (que afeta precisão, não viés)."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Descrever Pressuposto MLR.4 e Prova de Não Viés",
                                  "subSteps": [
                                    "Defina MLR.4: E(u|X) = 0 (zero média condicional do erro).",
                                    "Prove não viés: E(β̂_OLS | X) = β + (X'X)^{-1}X'E(u|X) = β.",
                                    "Explique papel conjunto: MLR.1-4 necessários para prova.",
                                    "Discuta violações: endogeneidade (corr(X,u)≠0).",
                                    "Resuma todos os 4 pressupostos em uma tabela."
                                  ],
                                  "verification": "Escreva a prova passo a passo e liste os 4 pressupostos com descrições.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Quadro branco para prova",
                                    "Python para simulação de viés"
                                  ],
                                  "tips": "Memorize: MLR.4 é o 'coração' para não viés; outros habilitam.",
                                  "learningObjective": "Sintetizar os pressupostos e provar matematicamente o não viés do OLS.",
                                  "commonMistakes": "Omitir condicionamento em X na expectativa ou ignorar MLR.3 na prova."
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (Y) vs anos de educação e experiência (X), verifique MLR.1 plotando Y vs X linear; MLR.2 confirmando amostragem aleatória do censo; MLR.3 checando det(X'X)≠0 e correlações <1; MLR.4 testando resíduos médios zero por grupos de X. Rode OLS em Python e simule violações para ver viés em β̂.",
                              "finalVerifications": [
                                "Liste corretamente MLR.1 a MLR.4 com descrições precisas.",
                                "Explique o papel de cada pressuposto na prova de E(β̂_OLS)=β.",
                                "Identifique violações comuns em um dataset real.",
                                "Prove não viés em 3 passos matemáticos.",
                                "Crie tabela comparativa de pressupostos para viés vs consistência.",
                                "Simule em software um caso com e sem MLR.4."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições exatas sem erros (80%).",
                                "Compreensão matemática: prova correta e identificação de dependências (90%).",
                                "Aplicação prática: análise de dataset com verificações (85%).",
                                "Profundidade: exemplos de violações e implicações (75%).",
                                "Síntese: tabela ou resumo claro integrando todos pressupostos (80%).",
                                "Criatividade: contraexemplos originais (70%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses sobre β.",
                                "Econometria: extensões para endogeneidade (IV).",
                                "Machine Learning: validação de premissas em regressão linear.",
                                "Programação: implementação de diagnósticos em R/Python (lmtest).",
                                "Matemática Linear: propriedades de matrizes e invertibilidade."
                              ],
                              "realWorldApplication": "Em análise de dados para empresas, como prever vendas baseadas em marketing e preço, identificar esses pressupostos garante que coeficientes β̂ reflitam causalidade real, evitando decisões erradas como superestimar impacto de preço devido a endogeneidade."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.2.1.1.3",
                            "name": "Derivar a não viés dos estimadores OLS",
                            "description": "Derivar matematicamente que E(β̂_OLS) = β usando projeção ortogonal e os pressupostos clássicos, aplicando em modelo Y = Xβ + u.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Estabelecer o modelo de regressão linear e pressupostos clássicos",
                                  "subSteps": [
                                    "Escreva o modelo Y = Xβ + u, onde Y é n×1, X é n×k com primeira coluna de 1s, β é k×1, u é n×1.",
                                    "Liste os pressupostos para unbiasedness: (1) E(u|X) = 0, (2) rank(X) = k (X'X invertível), (3) u não correlacionado com colunas de X.",
                                    "Explique projeção ortogonal: β̂ minimiza ||Y - Xβ̂||^2, então X'(Y - Xβ̂) = 0.",
                                    "Defina o espaço coluna de X (M) e o complementar ortogonal (M⊥)."
                                  ],
                                  "verification": "Confirme que o modelo e pressupostos estão corretamente anotados em um papel ou software como Jupyter Notebook.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta ou Jupyter Notebook com LaTeX",
                                    "Livro de Econometria (ex: Wooldridge)"
                                  ],
                                  "tips": "Anote os pressupostos em negrito para fácil referência posterior.",
                                  "learningObjective": "Compreender a estrutura do modelo e os pressupostos necessários para a derivação.",
                                  "commonMistakes": [
                                    "Esquecer E(u|X)=0",
                                    "Confundir rank(X)=k com invertibilidade direta",
                                    "Ignorar a coluna de 1s em X"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a fórmula do estimador OLS via projeção ortogonal",
                                  "subSteps": [
                                    "Parta da condição normal: X'(Y - Xβ̂) = 0, então X'Y = X'X β̂.",
                                    "Resolva para β̂_OLS = (X'X)^{-1} X' Y.",
                                    "Interprete geometricamente: β̂_OLS projeta Y ortogonalmente sobre o espaço coluna de X.",
                                    "Mostre que o resíduo e = Y - X β̂_OLS está em M⊥, ou seja, X'e = 0.",
                                    "Verifique que P = X(X'X)^{-1}X' é a matriz de projeção idempotente e simétrica."
                                  ],
                                  "verification": "Escreva e verifique algebricamente que X' (Y - X β̂_OLS) = 0.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora matricial ou Python (numpy.linalg)",
                                    "Quadro branco"
                                  ],
                                  "tips": "Use notação matricial consistente; pratique multiplicações matriciais.",
                                  "learningObjective": "Dominar a definição e propriedades geométricas/algébricas do OLS.",
                                  "commonMistakes": [
                                    "Esquecer inverso de X'X",
                                    "Confundir projeção com regressão simples",
                                    "Erro em X'e ≠ 0"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a expectativa E(β̂_OLS | X)",
                                  "subSteps": [
                                    "Substitua Y = Xβ + u na fórmula: β̂_OLS = (X'X)^{-1} X' (Xβ + u) = β + (X'X)^{-1} X' u.",
                                    "Tome expectativa condicional: E(β̂_OLS | X) = β + (X'X)^{-1} X' E(u | X).",
                                    "Pelo pressuposto E(u | X) = 0, então E(β̂_OLS | X) = β.",
                                    "Conclua que E(β̂_OLS) = E[ E(β̂_OLS | X) ] = β (lei das expectativas iteradas).",
                                    "Discuta implicações: unbiasedness significa que em média, β̂_OLS = β."
                                  ],
                                  "verification": "Derive passo a passo e confirme que o termo de viés é zero.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software como R ou MATLAB para simular",
                                    "Notas anteriores"
                                  ],
                                  "tips": "Mantenha X fixo (condicional) para evitar confusões com aleatoriedade em X.",
                                  "learningObjective": "Aplicar expectativa condicional para provar unbiasedness.",
                                  "commonMistakes": [
                                    "Usar E(u)=0 sem condicional",
                                    "Esquecer (X'X)^{-1}X' como projeção",
                                    "Confundir E(β̂|X) com E(β̂)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e sintetizar a derivação com exemplo prático",
                                  "subSteps": [
                                    "Aplique a um modelo simples: Y_i = β0 + β1 X_i + u_i, derive β̂1 = Σ(X_i - X̄)(Y_i - Ȳ) / Σ(X_i - X̄)^2.",
                                    "Mostre E(β̂1 | X) = β1 assumindo E(u_i | X_i)=0.",
                                    "Simule dados em software para verificar numericamente (média de muitas replicatas ≈ β).",
                                    "Discuta extensões: robustez sob violações de pressupostos.",
                                    "Escreva a prova completa em formato formal."
                                  ],
                                  "verification": "Execute simulação e confira que viés ≈ 0.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python (statsmodels ou sklearn) ou R",
                                    "Dados simulados"
                                  ],
                                  "tips": "Use seed para reprodutibilidade em simulações.",
                                  "learningObjective": "Consolidar a prova através de verificação numérica e síntese.",
                                  "commonMistakes": [
                                    "Erro na fórmula de regressão simples",
                                    "Simulação sem replicatas suficientes",
                                    "Ignorar normalização em X"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão de salário sobre anos de educação: salário_i = β0 + β1 edu_i + u_i. Derivando E(β̂1 | edu) = β1 garante que a estimativa do retorno à educação seja não viesada em média, sob E(u_i | edu_i)=0.",
                              "finalVerifications": [
                                "Prova escrita completa sem erros algébricos.",
                                "Explicação correta da projeção ortogonal.",
                                "Uso preciso dos pressupostos clássicos.",
                                "Verificação numérica via simulação com viés próximo de zero.",
                                "Interpretação verbal da unbiasedness.",
                                "Identificação de condições necessárias."
                              ],
                              "assessmentCriteria": [
                                "Correção matemática na derivação (peso 40%).",
                                "Clareza na explicação de passos e pressupostos (20%).",
                                "Uso apropriado de notação matricial (15%).",
                                "Exemplo prático relevante e verificado (15%).",
                                "Profundidade na interpretação e conexões (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Projeções ortogonais e matrizes idempotentes.",
                                "Probabilidade: Expectativas condicionais e lei iterada.",
                                "Estatística: Propriedades de estimadores e inferência.",
                                "Econometria: Modelos de regressão e causalidade.",
                                "Computação: Simulações Monte Carlo em Python/R."
                              ],
                              "realWorldApplication": "Na análise de políticas públicas, como avaliar o impacto de treinamento profissional no emprego, a unbiasedness dos OLS assegura que coeficientes estimados reflitam efeitos causais verdadeiros sob exogeneidade, guiando decisões baseadas em evidências confiáveis."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.2.1.2",
                        "name": "Consistência dos Estimadores OLS",
                        "description": "Propriedade de consistência dos estimadores OLS, que converge em probabilidade para o verdadeiro parâmetro à medida que o tamanho da amostra aumenta, sob pressupostos de exogeneidade e momentos finitos.",
                        "specificSkills": [
                          {
                            "id": "11.2.1.2.1",
                            "name": "Definir consistência de um estimador",
                            "description": "Explicar consistência como plim_{n→∞} β̂ = β, incluindo convergência em probabilidade e em média quadrática, e sua importância para inferência em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender a Definição Formal de Consistência",
                                  "subSteps": [
                                    "Leia a definição: Um estimador β̂ é consistente se plim_{n→∞} β̂ = β, onde plim denota o limite em probabilidade.",
                                    "Identifique os componentes: β̂ (estimador), β (parâmetro verdadeiro), n (tamanho da amostra).",
                                    "Diferencie consistência de viés e eficiência.",
                                    "Escreva a definição em suas próprias palavras.",
                                    "Compare com estimadores inconsistentes, como em modelos com variáveis omitidas."
                                  ],
                                  "verification": "Escreva a definição formal e explique intuitivamente em um parágrafo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de aula sobre propriedades de estimadores, vídeo introdutório de econometria (ex: Khan Academy ou YouTube).",
                                  "tips": "Visualize plim como 'a probabilidade de β̂ estar longe de β vai a zero à medida que n cresce'.",
                                  "learningObjective": "Definir precisamente consistência e sua notação probabilística.",
                                  "commonMistakes": "Confundir consistência com convergência quase certa; consistência é mais fraca."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Convergência em Probabilidade",
                                  "subSteps": [
                                    "Defina convergência em probabilidade: Para todo ε > 0, P(|β̂ - β| > ε) → 0 quando n → ∞.",
                                    "Relacione com a definição de consistência: plim β̂ = β equivale a essa convergência.",
                                    "Estude o Teorema de Slutsky para manipulações de limites probabilísticos.",
                                    "Resolva exercícios simples: Prove consistência da média amostral.",
                                    "Simule em software: Gere amostras crescentes e plote a distribuição de β̂."
                                  ],
                                  "verification": "Simule em Python/R e mostre que a variância de β̂ diminui com n.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (bibliotecas numpy, matplotlib) ou R, código de simulação de estimadores.",
                                  "tips": "Use histogramas para visualizar a contração da distribuição em torno de β.",
                                  "learningObjective": "Compreender e demonstrar convergência em probabilidade via simulação.",
                                  "commonMistakes": "Ignorar que consistência requer n → ∞; amostras finitas sempre têm variância."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Convergência em Média Quadrática",
                                  "subSteps": [
                                    "Defina: E[(β̂ - β)^2] → 0 quando n → ∞, implicando consistência (mais forte).",
                                    "Compare com convergência em probabilidade: MQ implica probabilidade, mas não vice-versa.",
                                    "Derive para OLS sob pressupostos clássicos: Var(β̂) = σ² (X'X)^{-1}, que → 0.",
                                    "Resolva prova: Mostre consistência MQ para média amostral.",
                                    "Discuta quando falha: heterocedasticidade ou dependência serial."
                                  ],
                                  "verification": "Escreva a prova de consistência MQ para um estimador simples e verifique condições.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Livro de Wooldridge 'Introductory Econometrics', papel e caneta para derivações.",
                                  "tips": "Lembre: MQ controla tanto viés quanto variância quadrática.",
                                  "learningObjective": "Diferenciar e provar consistência em média quadrática.",
                                  "commonMistakes": "Achar que toda consistência é MQ; há estimadores consistentes sem MQ."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Compreender a Importância para Inferência em Grandes Amostras",
                                  "subSteps": [
                                    "Explique: Em n grande, β̂ ≈ β, justificando intervalos de confiança assintóticos.",
                                    "Discuta teoremas assintóticos: CLT para distribuição normal de √n(β̂ - β).",
                                    "Aplique a OLS: Consistência garante inferência válida em big data.",
                                    "Analise cenários reais: Falha em consistência leva a inferências erradas.",
                                    "Sintetize: Resuma diferenças e implicações em um fluxograma."
                                  ],
                                  "verification": "Explique verbalmente por que consistência é crucial para machine learning em grandes datasets.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Artigos sobre econometria assintótica, exemplos de regressão em datasets reais (ex: Kaggle).",
                                  "tips": "Pense em 'lei dos grandes números para estimadores': amostras grandes 'média para verdade'.",
                                  "learningObjective": "Articular o papel da consistência na inferência estatística prática.",
                                  "commonMistakes": "Subestimar impacto de violações em dados reais, como endogeneidade."
                                }
                              ],
                              "practicalExample": "Considere o estimador da média amostral X̄ para μ. Simule n=10, 100, 1000 de uma normal(5,2): observe X̄ convergindo para 5 em probabilidade (histogramas se estreitam) e MQ (MSE → 0). Em regressão OLS simples, β̂_1 para inclinação converge para o verdadeiro β_1 à medida que n cresce.",
                              "finalVerifications": [
                                "Escreva e prove a definição de consistência para a média amostral.",
                                "Simule convergência em probabilidade e MQ em código, plotando resultados.",
                                "Diferencie consistência de viés zero e eficiência.",
                                "Explique por que OLS é consistente sob pressupostos básicos.",
                                "Discuta um exemplo de estimador inconsistente (ex: proxy variável em endogeneidade).",
                                "Resuma a importância para inferência assintótica em 3 frases."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição formal de plim e convergências (probabilidade vs MQ).",
                                "Capacidade de provar consistência em casos simples com rigor matemático.",
                                "Interpretação correta via simulações numéricas e gráficos.",
                                "Explicação clara da importância para grandes amostras e inferência.",
                                "Identificação de condições necessárias e violações comuns.",
                                "Síntese interdisciplinar com aplicações reais."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Limites probabilísticos e Leis dos Grandes Números.",
                                "Machine Learning: Consistência em algoritmos de regressão e validação cruzada.",
                                "Economia/Econometria: Inferência em modelos causais com dados observacionais.",
                                "Computação Científica: Simulações Monte Carlo para propriedades assintóticas."
                              ],
                              "realWorldApplication": "Em análise de dados de vendas, o OLS consistente permite inferir confiavelmente o impacto de preço nas vendas com grandes datasets de e-commerce (ex: Amazon), suportando decisões de precificação sem viés em amostras massivas."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.1"
                            ]
                          },
                          {
                            "id": "11.2.1.2.2",
                            "name": "Listar pressupostos para consistência do OLS",
                            "description": "Descrever pressupostos adicionais como exogeneidade estrita (E(u_i | X_1,...,X_n)=0), momentos finitos de X e u, e ausência de heterocedasticidade severa para garantir consistência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Consistência em Estimadores",
                                  "subSteps": [
                                    "Defina consistência como a propriedade onde o estimador converge em probabilidade para o verdadeiro parâmetro à medida que o tamanho da amostra aumenta.",
                                    "Revise a fórmula do estimador OLS: β̂ = (X'X/n)^(-1)(X'y/n).",
                                    "Explique por que a consistência requer que plim (X'X/n) seja não-singular e plim (X'u/n) = 0.",
                                    "Discuta a lei dos grandes números (LLN) aplicada a médias amostrais.",
                                    "Relacione com teorema de Slutsky para produtos de convergentes."
                                  ],
                                  "verification": "Escreva uma definição precisa de consistência e identifique os dois termos chave na convergência do OLS.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de econometria (ex: Wooldridge), calculadora, quadro branco.",
                                  "tips": "Use analogias como 'mira de um atirador melhorando com mais tiros'.",
                                  "learningObjective": "Entender a base probabilística da consistência do OLS.",
                                  "commonMistakes": "Confundir consistência com não-viés (consistência é assintótica)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e Descrever Exogeneidade Estrita",
                                  "subSteps": [
                                    "Defina exogeneidade estrita: E(u_i | X_i) = 0 para todo i.",
                                    "Explique que isso implica E(u_i | X_1, ..., X_n) = 0.",
                                    "Derive por que isso garante plim (X'u/n) = 0 via LLN condicional.",
                                    "Diferencie de exogeneidade ortogonal (E(X'u)=0), que é mais fraca.",
                                    "Forneça contraexemplo: endogeneidade causando plim ≠ 0."
                                  ],
                                  "verification": "Prove matematicamente que exogeneidade estrita leva a plim (X'u/n) = 0.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Livro de Wooldridge Cap. 3, software R/Python para simulação simples.",
                                  "tips": "Pense em u_i como erro 'não-correlacionado com X' em todos os momentos.",
                                  "learningObjective": "Dominar o pressuposto central de exogeneidade para consistência.",
                                  "commonMistakes": "Assumir que média zero de u basta (precisa condicional)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Pressupostos de Momentos Finitos",
                                  "subSteps": [
                                    "Liste momentos necessários: E(X'X/n) converge se E||X||^2 < ∞ e E||u||^2 < ∞.",
                                    "Explique ergodicidade estacionária para LLN aplicar.",
                                    "Discuta ordem de momentos: segundo momento para variância, mas finito para convergência.",
                                    "Verifique condições para (X'X/n)^(-1) ser bem-definido (rank completo).",
                                    "Simule em software um caso com momentos infinitos falhando."
                                  ],
                                  "verification": "Calcule E||X||^2 para uma distribuição e confirme finitude.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Software R (pacote moments), notas de teoria assintótica.",
                                  "tips": "Momentos finitos evitam 'caudas pesadas' destruindo convergência.",
                                  "learningObjective": "Entender requisitos probabilísticos para LLN no OLS.",
                                  "commonMistakes": "Ignorar que momentos infinitos quebram LLN mesmo com exogeneidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Ausência de Heterocedasticidade Severa e Sintetizar Lista",
                                  "subSteps": [
                                    "Defina heterocedasticidade severa: Var(u|X) crescendo rápido o suficiente para invalidar LLN.",
                                    "Explique que consistência requer Var(u_i|X_i) < ∞ uniformemente.",
                                    "Liste pressupostos completos: 1. Exogeneidade estrita; 2. Momentos finitos; 3. Sem heteroc. severa; 4. Rank(X)=k.",
                                    "Crie um mnemônico para memorizar: 'EXMO' (Exogeneidade, Momentos, Ordem/rank).",
                                    "Teste listando sem olhar notas."
                                  ],
                                  "verification": "Escreva a lista completa de 4 pressupostos com descrições breves.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Flashcards, resumo em papel.",
                                  "tips": "Heterocedasticidade leve OK para consistência, só afeta eficiência.",
                                  "learningObjective": "Listar e justificar todos os pressupostos para consistência OLS.",
                                  "commonMistakes": "Incluir não-viés (Gauss-Markov) como necessário para consistência."
                                }
                              ],
                              "practicalExample": "Em um modelo de salário = β0 + β1*educação + u, verifique exogeneidade (educação não afeta u condicionalmente), momentos finitos (distribuições normais OK), sem heteroc. severa (var(u|edu) constante), e X com rank 2. Simule n=1000 em R: OLS converge para verdadeiros β.",
                              "finalVerifications": [
                                "Liste verbalmente os 4 pressupostos principais sem hesitação.",
                                "Explique impacto de violar exogeneidade em uma regressão simulada.",
                                "Identifique momentos finitos em uma distribuição t(3) vs normal.",
                                "Diferencie condições para consistência vs eficiência.",
                                "Aplique a lista a um modelo real de dados (ex: mtcars).",
                                "Prove sucintamente plim(β̂)=β sob pressupostos."
                              ],
                              "assessmentCriteria": [
                                "Completude: Todos os pressupostos listados corretamente (90%).",
                                "Precisão: Definições matemáticas exatas, sem confusões (80%).",
                                "Profundidade: Explicações incluem derivações ou contraexemplos (70%).",
                                "Clareza: Lista organizada e mnemônicos úteis (60%).",
                                "Aplicação: Uso correto em exemplo prático (50%).",
                                "Originalidade: Conexões pessoais ou extensões (extra)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teoria assintótica e LLN/CLT.",
                                "Econometria: Modelos de regressão aplicados.",
                                "Machine Learning: Consistência em regressão linear vs métodos não-paramétricos.",
                                "Probabilidade: Condições ergodicidade e momentos.",
                                "Computação: Simulações Monte Carlo em R/Python."
                              ],
                              "realWorldApplication": "Em análise econômica, garante que estimadores OLS em painéis de salários ou PIB convirjam para parâmetros verdadeiros em grandes datasets governamentais, evitando políticas baseadas em estimativas inconsistentes devido a endogeneidade omitida."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.2"
                            ]
                          },
                          {
                            "id": "11.2.1.2.3",
                            "name": "Demonstrar consistência via lei dos grandes números",
                            "description": "Usar a lei dos grandes números e teorema do limite central para mostrar que plim (X'X/n)^{-1} (X'u/n) = 0, levando a plim β̂_OLS = β.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Recall the OLS Estimator and Decompose the Estimation Error",
                                  "subSteps": [
                                    "Write the population model: y = Xβ + u, where E(u|X) = 0.",
                                    "Express the OLS estimator: β̂_OLS = (X'X / n)^{-1} (X'y / n).",
                                    "Substitute y into the estimator to derive β̂_OLS - β = (X'X / n)^{-1} (X'u / n).",
                                    "Identify the two key terms: A_n = X'X / n and B_n = X'u / n.",
                                    "Normalize matrices by n to interpret as sample averages."
                                  ],
                                  "verification": "Correctly derive and write β̂_OLS - β = (X'X/n)^{-1} (X'u/n) on paper.",
                                  "estimatedTime": "45 minutes",
                                  "materials": [
                                    "Notebook and pen",
                                    "Textbook on econometrics (e.g., Wooldridge)",
                                    "Linear algebra reference"
                                  ],
                                  "tips": "Always divide by n to connect to law of large numbers; think in terms of sample moments.",
                                  "learningObjective": "Master the algebraic decomposition showing consistency hinges on plim(A_n^{-1} B_n) = 0.",
                                  "commonMistakes": [
                                    "Forgetting the inverse on X'X/n",
                                    "Omitting the division by n",
                                    "Confusing X'y/n with X'X/n"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "State and Verify Assumptions for the Law of Large Numbers (LLN)",
                                  "subSteps": [
                                    "List i.i.d. assumption: (X_i, u_i) are independent and identically distributed.",
                                    "State exogeneity: E(u_i | X_i) = 0 for all i.",
                                    "Ensure finite moments: E[||X_i||^2] < ∞ and E[|u_i|] < ∞.",
                                    "Explain LLN for vectors: plim (1/n ∑ Z_i) = E[Z_i] for Z_i = X_i u_i or X_i' X_i.",
                                    "Discuss weak LLN vs. strong LLN; use weak for probability limits."
                                  ],
                                  "verification": "List all assumptions correctly and justify why they enable LLN application.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Probability notes on LLN",
                                    "Python or R for assumption checks (optional)"
                                  ],
                                  "tips": "Focus on conditional expectations; bounded moments prevent LLN failure.",
                                  "learningObjective": "Understand prerequisites ensuring sample averages converge in probability to expectations.",
                                  "commonMistakes": [
                                    "Ignoring conditional exogeneity",
                                    "Assuming homoskedasticity (not needed for consistency)",
                                    "Overlooking finite variance requirement"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Apply LLN to Key Terms and Invoke Continuous Mapping Theorem",
                                  "subSteps": [
                                    "Apply LLN to B_n = X'u / n: plim B_n = E[X u] = E[X E[u|X]] = 0.",
                                    "Apply LLN to A_n = X'X / n: plim A_n = Q = E[X'X], assuming Q positive definite.",
                                    "Use continuous mapping: plim A_n^{-1} = Q^{-1} (Slutsky's theorem).",
                                    "Conclude plim (A_n^{-1} B_n) = Q^{-1} * 0 = 0.",
                                    "Mention role of CLT for asymptotic distribution if extending to inference."
                                  ],
                                  "verification": "Derive plim β̂_OLS = β step-by-step in a proof format.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Pen and paper for proof",
                                    "Matrix algebra cheat sheet"
                                  ],
                                  "tips": "Visualize as plim(average of X_i u_i) → 0; practice with scalar case first.",
                                  "learningObjective": "Demonstrate how LLN implies consistency via probabilistic limits.",
                                  "commonMistakes": [
                                    "Forgetting continuous mapping for inverse",
                                    "Assuming CLT for consistency (CLT is for normality)",
                                    "Not verifying Q is invertible"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verify Theoretically and Empirically via Simulation",
                                  "subSteps": [
                                    "Implement Monte Carlo: simulate y = Xβ + u, compute β̂ for increasing n.",
                                    "Plot β̂ - β vs. n; observe convergence to 0.",
                                    "Compute MSE(β̂) and show it decreases with n.",
                                    "Compare to inconsistent estimator (e.g., violate exogeneity).",
                                    "Document code and results with plots."
                                  ],
                                  "verification": "Run simulation showing ||β̂ - β|| → 0 as n → ∞.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Python (numpy, matplotlib) or R",
                                    "Jupyter notebook"
                                  ],
                                  "tips": "Use n = 10, 100, 1000, 10000; seed RNG for reproducibility.",
                                  "learningObjective": "Empirically confirm theoretical consistency using computational tools.",
                                  "commonMistakes": [
                                    "Insufficient n values",
                                    "Not averaging over replications",
                                    "Plotting without standardization"
                                  ]
                                }
                              ],
                              "practicalExample": "Simulate a simple regression: X ~ N(0,1), β = [1, 2], u ~ N(0,1), n=10000. Compute β̂_OLS repeatedly (1000 reps). True β = [1,2]; observe sample mean β̂ ≈ [1,2], std dev shrinks with larger n, illustrating plim β̂ = β.",
                              "finalVerifications": [
                                "Derive plim((X'X/n)^{-1} (X'u/n)) = 0 without errors.",
                                "List and justify all LLN assumptions for the context.",
                                "Run simulation code showing convergence for n>1000.",
                                "Explain why CLT complements but is not required for consistency.",
                                "Identify a violation (e.g., correlation(X,u)) causing inconsistency.",
                                "Write a one-paragraph summary of the proof."
                              ],
                              "assessmentCriteria": [
                                "Precision in algebraic derivation (no sign/inverse errors).",
                                "Correct application and justification of LLN assumptions.",
                                "Clarity and completeness of probabilistic limit proof.",
                                "Quality of simulation: plots, replications, convergence evidence.",
                                "Ability to connect to broader OLS properties (unbiasedness vs. consistency).",
                                "Insightful discussion of real-world assumption checks."
                              ],
                              "crossCurricularConnections": [
                                "Probability Theory: LLN and continuous mapping theorem.",
                                "Statistics: Asymptotic theory and Monte Carlo methods.",
                                "Computer Science: Numerical simulation and matrix computations.",
                                "Economics: Econometrics and causal inference in regressions.",
                                "Data Science: Validation of linear models in ML pipelines."
                              ],
                              "realWorldApplication": "In empirical economics or data science, this justifies using OLS for large datasets (e.g., predicting wages from education/experience in millions of observations), ensuring estimates converge to true parameters despite finite-sample bias, as in labor market studies or A/B testing."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.3"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "11.2.1.3",
                        "name": "Eficiência dos Estimadores OLS",
                        "description": "Eficiência relativa dos estimadores OLS, incluindo o teorema de Gauss-Markov que estabelece o OLS como o melhor estimador linear não viesado (BLUE) sob pressupostos de homocedasticidade e ausência de autocorrelação.",
                        "specificSkills": [
                          {
                            "id": "11.2.1.3.1",
                            "name": "Definir eficiência de um estimador",
                            "description": "Explicar eficiência como a menor variância entre estimadores não viesados, e eficiência relativa como comparação de variâncias.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de Estimadores e Variância",
                                  "subSteps": [
                                    "Defina um estimador como uma função de estatísticas amostrais que estima um parâmetro populacional.",
                                    "Explique viés como a diferença esperada entre o estimador e o verdadeiro parâmetro.",
                                    "Descreva variância como a dispersão do estimador em torno de seu valor esperado.",
                                    "Calcule a variância de um estimador simples, como a média amostral.",
                                    "Discuta por que estimadores não viesados são preferíveis para comparações de eficiência."
                                  ],
                                  "verification": "Resuma em uma frase o que é variância de um estimador e dê um exemplo numérico simples.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notas de aula sobre propriedades de estimadores",
                                    "Calculadora ou planilha Excel"
                                  ],
                                  "tips": "Use exemplos com distribuições normais para simplificar cálculos iniciais.",
                                  "learningObjective": "Compreender a base conceitual de variância como métrica chave para eficiência.",
                                  "commonMistakes": "Confundir variância com viés; lembrar que eficiência foca em não viesados."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir Eficiência Absoluta de um Estimador",
                                  "subSteps": [
                                    "Defina eficiência como possuir a menor variância possível entre todos os estimadores não viesados para o mesmo parâmetro.",
                                    "Introduza o Conceito de Estimador Eficiente de Cramer-Rao como limite inferior para variância.",
                                    "Compare variâncias de dois estimadores não viesados hipotéticos.",
                                    "Identifique quando um estimador atinge eficiência (ex: média amostral para média normal).",
                                    "Derive ou cite o limite de Cramer-Rao para variância mínima."
                                  ],
                                  "verification": "Escreva a definição formal de eficiência e verifique se ela exclui estimadores viesados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de estatística inferencial (ex: Casella & Berger)",
                                    "Software R ou Python para simulações"
                                  ],
                                  "tips": "Visualize variâncias com histogramas de distribuições de estimadores simulados.",
                                  "learningObjective": "Dominar a definição precisa de eficiência absoluta baseada em variância mínima.",
                                  "commonMistakes": "Ignorar a condição de não viés; eficiência não se aplica a viesados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explicar Eficiência Relativa entre Estimadores",
                                  "subSteps": [
                                    "Defina eficiência relativa como a razão das variâncias: eff(A,B) = Var(B)/Var(A), onde A é mais eficiente se >1.",
                                    "Calcule eficiência relativa para exemplos como média vs. mediana em distribuições normais.",
                                    "Interprete valores: eff=1 (iguais), eff>1 (A superior), eff<1 (B superior).",
                                    "Discuta limitações, como amostras finitas onde eficiência assintótica aplica.",
                                    "Compare eficiência relativa em contextos como OLS vs. outros regressores."
                                  ],
                                  "verification": "Compute eficiência relativa para dois estimadores dados e interprete o resultado.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha com dados simulados",
                                    "Código Python para variâncias amostrais"
                                  ],
                                  "tips": "Sempre normalize pela variância do benchmark para comparações claras.",
                                  "learningObjective": "Aplicar e interpretar eficiência relativa como métrica comparativa.",
                                  "commonMistakes": "Inverter a razão de variâncias; maior eficiência significa menor variância."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar e Aplicar Conceitos de Eficiência",
                                  "subSteps": [
                                    "Resuma diferenças entre eficiência absoluta e relativa.",
                                    "Crie uma tabela comparando estimadores comuns por eficiência.",
                                    "Discuta implicações para escolha de estimadores em análise de dados.",
                                    "Resolva um problema: identifique o estimador mais eficiente dado variâncias.",
                                    "Reflita sobre trade-offs (ex: eficiência vs. robustez)."
                                  ],
                                  "verification": "Explique em um parágrafo como eficiência impacta inferência estatística.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Papel e caneta para tabela",
                                    "Exemplos de problemas de estatística"
                                  ],
                                  "tips": "Use analogias: eficiência como 'economia de combustível' entre carros não viesados.",
                                  "learningObjective": "Integrar conceitos para avaliação crítica de estimadores.",
                                  "commonMistakes": "Generalizar eficiência sem contexto de não viés ou assintótico."
                                }
                              ],
                              "practicalExample": "Considere estimar a média μ de uma normal N(μ,1) com n=100. A média amostral tem Var=1/100=0.01. A mediana tem Var≈1.57/100=0.0157. Eficiência absoluta: média atinge Cramer-Rao. Relativa: eff(média,mediana)=0.0157/0.01=1.57 (média 57% mais eficiente). Simule em Python para verificar.",
                              "finalVerifications": [
                                "Defina eficiência absoluta corretamente, citando variância mínima entre não viesados.",
                                "Calcule eficiência relativa para dois estimadores dados.",
                                "Explique por que viés exclui comparação de eficiência.",
                                "Identifique um estimador eficiente real (ex: média para normal).",
                                "Discuta limite de Cramer-Rao em contexto.",
                                "Compare eficiência em um exemplo numérico."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições exatas sem erros (40%)",
                                "Cálculos corretos de variâncias e razões (30%)",
                                "Interpretação clara de eficiência absoluta vs. relativa (15%)",
                                "Uso de exemplos relevantes e simulações (10%)",
                                "Clareza na escrita e síntese (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Eficiência em regressão OLS vs. métodos robustos.",
                                "Machine Learning: Escolha de loss functions minimizando variância preditiva.",
                                "Probabilidade: Limites de variância via desigualdades (Cramer-Rao).",
                                "Computação Científica: Simulações Monte Carlo para variâncias empíricas."
                              ],
                              "realWorldApplication": "Em finanças, estimadores eficientes como máxima verossimilhança em modelos GARCH reduzem variância em previsões de volatilidade, melhorando decisões de investimento e gerenciamento de risco com menos dispersão nos retornos esperados."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.1"
                            ]
                          },
                          {
                            "id": "11.2.1.3.2",
                            "name": "Enunciar o teorema de Gauss-Markov",
                            "description": "Descrever os pressupostos MLR.1 a MLR.5 (adicionando homocedasticidade Var(u|X)=σ²I e sem autocorrelação) e provar que OLS tem menor variância que qualquer concorrente linear não viesado.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender e memorizar os pressupostos MLR.1 a MLR.5",
                                  "subSteps": [
                                    "Estude MLR.1: Linearidade nos parâmetros (Y = Xβ + u).",
                                    "Revise MLR.2: Exogeneidade estrita (E(u|X) = 0).",
                                    "Analise MLR.3: Homocedasticidade e ausência de autocorrelação (Var(u|X) = σ²I).",
                                    "Examine MLR.4: Não-colinearidade perfeita ((X'X) invertível).",
                                    "Discuta MLR.5: Amostra aleatória (observações iid).",
                                    "Escreva os pressupostos em suas próprias palavras."
                                  ],
                                  "verification": "Liste e descreva corretamente todos os 5 pressupostos em um papel ou documento.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge)",
                                    "Notas de aula sobre regressão linear múltipla",
                                    "Artigo da Wikipedia sobre Gauss-Markov"
                                  ],
                                  "tips": "Use mnemônicos para lembrar a ordem: Linearidade, Exogeneidade, Variância constante, Não-colinearidade, Amostra aleatória.",
                                  "learningObjective": "Identificar e explicar cada pressuposto necessário para o teorema de Gauss-Markov.",
                                  "commonMistakes": [
                                    "Confundir homocedasticidade com normalidade dos erros.",
                                    "Esquecer a ausência de autocorrelação em MLR.3.",
                                    "Ignorar a invertibilidade de X'X."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender estimadores lineares não viesados",
                                  "subSteps": [
                                    "Defina estimador linear: β_hat* = C Y, onde C é matriz fixa.",
                                    "Explique não viés: E(β_hat*) = β para todo β.",
                                    "Discuta a variância de um estimador linear: Var(β_hat*) = σ² C (X'X) C'.",
                                    "Compare com o estimador OLS: β_hat = (X'X)^{-1} X' Y.",
                                    "Mostre que OLS é linear e não viesado sob os pressupostos."
                                  ],
                                  "verification": "Prove algebricamente que OLS é não viesado usando MLR.1 e MLR.2.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Matriz de covariância básica",
                                    "Software como R ou Python (para simular)",
                                    "Folha de derivações matemáticas"
                                  ],
                                  "tips": "Visualize com regressão simples (uma variável) para intuitar antes de múltipla.",
                                  "learningObjective": "Diferenciar OLS de outros estimadores lineares e estabelecer sua não viés.",
                                  "commonMistakes": [
                                    "Confundir viés com variância.",
                                    "Esquecer que linearidade é em relação a Y, não a X."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Enunciar o Teorema de Gauss-Markov",
                                  "subSteps": [
                                    "Escreva o enunciado formal: Sob MLR.1-5, OLS é o melhor estimador linear não viesado (BLUE).",
                                    "Explique 'melhor': Menor variância (em norma quadrática média) que qualquer concorrente linear não viesado.",
                                    "Defina a matriz de variância-covariância do OLS: σ² (X'X)^{-1}.",
                                    "Discuta independência das observações implícita em MLR.3-5.",
                                    "Reescreva o teorema em palavras simples."
                                  ],
                                  "verification": "Enuncie o teorema verbalmente ou por escrito sem consultar materiais.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Resumo do teorema de Gauss-Markov",
                                    "Vídeo explicativo (Khan Academy ou similar)"
                                  ],
                                  "tips": "Lembre: Gauss-Markov não requer normalidade, só momentos de segunda ordem.",
                                  "learningObjective": "Enunciar precisamente o teorema e seus componentes chave.",
                                  "commonMistakes": [
                                    "Incluir normalidade como pressuposto (isso é para t-testes).",
                                    "Confundir 'melhor' com 'mínimo quadrados'."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Provar o teorema e comparar variâncias",
                                  "subSteps": [
                                    "Assuma qualquer estimador linear não viesado β_hat* = C Y com E(β_hat*) = β.",
                                    "Mostre que C = (X'X)^{-1} X' + D, onde D X = 0 (decomposição).",
                                    "Prove Var(β_hat*) = Var(β_hat) + σ² D D' ≥ Var(β_hat).",
                                    "Conclua que a variância é mínima para D=0 (OLS).",
                                    "Verifique com exemplo numérico simples (n=3 observações)."
                                  ],
                                  "verification": "Derive a desigualdade de variância em um caderno e confira com referência.",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "Caneta e papel para derivações",
                                    "Software MATLAB/R para matrizes",
                                    "Livro com prova detalhada"
                                  ],
                                  "tips": "Comece com regressão simples para praticar a prova antes da múltipla.",
                                  "learningObjective": "Dominar a prova algébrica de eficiência do OLS.",
                                  "commonMistakes": [
                                    "Erro na decomposição C = P + D.",
                                    "Esquecer σ² >0 na desigualdade."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para prever consumo (Y) por renda (X1) e preço (X2), simule dados com erros homocedásticos iid. Calcule OLS e um estimador linear alternativo (ex: média ponderada). Compare as matrizes de variância: OLS terá variância menor.",
                              "finalVerifications": [
                                "Enuncie o teorema completo sem erros.",
                                "Liste e justifique os 5 pressupostos MLR.",
                                "Explique a prova em 3 passos principais.",
                                "Mostre por que OLS é eficiente contra um rival específico.",
                                "Aplique em um exemplo numérico simples.",
                                "Identifique quando o teorema falha (ex: heterocedasticidade)."
                              ],
                              "assessmentCriteria": [
                                "Precisão no enunciado do teorema (100% correto).",
                                "Correção e completude dos pressupostos MLR.1-5.",
                                "Domínio da prova algébrica (derivada sem erros).",
                                "Capacidade de comparar variâncias quantitativamente.",
                                "Explicação intuitiva da eficiência do OLS.",
                                "Identificação de limitações do teorema."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses em regressão.",
                                "Álgebra Linear: Matrizes de variância e projeções.",
                                "Machine Learning: Fundamentos de regressão linear.",
                                "Econometria: Modelos de painel e violações de pressupostos.",
                                "Probabilidade: Propriedades de momentos condicionais."
                              ],
                              "realWorldApplication": "Em análises econométricas para prever impacto de políticas públicas (ex: efeito de salário mínimo no emprego), o teorema justifica o uso de OLS como estimador eficiente quando pressupostos são satisfeitos, minimizando incerteza nas previsões."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.2"
                            ]
                          },
                          {
                            "id": "11.2.1.3.3",
                            "name": "Calcular a variância do OLS e comparar eficiência",
                            "description": "Derivar Var(β̂_OLS) = σ² (X'X)^{-1} e demonstrar por que é mínima usando projeção ortogonal em espaço de mínimos quadrados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Modelo de Regressão Linear OLS e o Estimador β̂_OLS",
                                  "subSteps": [
                                    "Relembrar o modelo Y = Xβ + ε, onde ε ~ N(0, σ²I).",
                                    "Derivar β̂_OLS = (X'X)^{-1}X'Y explicitamente.",
                                    "Verificar premissas do teorema de Gauss-Markov: linearidade, exogeneidade, homocedasticidade e não-multicolinearidade perfeita.",
                                    "Calcular E(β̂_OLS) para confirmar não-viés.",
                                    "Discutir covariância amostral de β̂_OLS."
                                  ],
                                  "verification": "Escrever a fórmula de β̂_OLS e listar as 4 premissas de Gauss-Markov corretamente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Notas de álgebra matricial",
                                    "Handout de propriedades OLS",
                                    "Calculadora matricial ou software como R/MATLAB"
                                  ],
                                  "tips": "Comece com um exemplo numérico simples de 2 variáveis para visualizar.",
                                  "learningObjective": "Compreender a base do estimador OLS e suas premissas fundamentais.",
                                  "commonMistakes": [
                                    "Confundir E(β̂) com Var(β̂).",
                                    "Esquecer a inversa (X'X)^{-1}."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Variância do Estimador OLS: Var(β̂_OLS) = σ² (X'X)^{-1}",
                                  "subSteps": [
                                    "Partir de β̂_OLS = (X'X)^{-1}X'Y e substituir Y = Xβ + ε.",
                                    "Calcular Var(β̂_OLS) = (X'X)^{-1}X' Var(ε) X (X'X)^{-1}.",
                                    "Simplificar assumindo Var(ε) = σ²I, resultando em σ² (X'X)^{-1}.",
                                    "Interpretar: variância depende de σ² e da 'informação' em X.",
                                    "Verificar com simulação: gerar dados e estimar covariância empiricamente."
                                  ],
                                  "verification": "Derivar a fórmula passo a passo e confirmar com um exemplo matricial 2x2.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Folha de derivação matricial",
                                    "Software R ou Python (numpy.linalg) para verificação numérica"
                                  ],
                                  "tips": "Use propriedades de traço e expectativa para simplificações matriciais.",
                                  "learningObjective": "Derivar analiticamente a matriz de covariância do OLS.",
                                  "commonMistakes": [
                                    "Ignorar a independência dos erros.",
                                    "Erro na multiplicação matricial X' Var(ε) X."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir Projeção Ortogonal no Espaço dos Mínimos Quadrados",
                                  "subSteps": [
                                    "Definir espaço colunar de X e espaço ortogonal X⊥.",
                                    "Explicar projeção P = X(X'X)^{-1}X' sobre col(X).",
                                    "Mostrar que resíduos e = (I - P)Y são ortogonais a col(X).",
                                    "Visualizar geometricamente: β̂ minimiza ||Y - Xβ||² via projeção.",
                                    "Discutir norma euclidiana e propriedades de ortogonalidade."
                                  ],
                                  "verification": "Desenhar diagrama de projeção e provar e'X = 0.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Diagrama geométrico de regressão",
                                    "Livro de álgebra linear (ex: Strang)"
                                  ],
                                  "tips": "Pense em vetores: projeção é o 'melhor' aproximador linear.",
                                  "learningObjective": "Entender a interpretação geométrica dos mínimos quadrados.",
                                  "commonMistakes": [
                                    "Confundir projeção com regressão não-linear.",
                                    "Esquecer ortogonalidade dos resíduos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Demonstrar Eficiência do OLS via Teorema de Gauss-Markov e Projeção",
                                  "subSteps": [
                                    "Enunciar Gauss-Markov: entre estimadores lineares não-viésados, OLS tem variância mínima.",
                                    "Provar usando projeção: qualquer outro β̃ = Cy, Var(β̃) ≥ Var(β̂) por ortogonalidade.",
                                    "Decompor β̃ - β̂ ortogonal a β̂, aumentando variância.",
                                    "Comparar com estimadores alternativos (ex: ridge se violadas premissas).",
                                    "Simular comparação de variâncias em Monte Carlo."
                                  ],
                                  "verification": "Escrever prova esquemática e rodar simulação mostrando Var(OLS) ≤ Var(outro).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código R/Python para simulação Monte Carlo",
                                    "Artigo Gauss-Markov theorem"
                                  ],
                                  "tips": "Use desigualdade da variância: Var(a + b) = Var(a) + Var(b) se Cov(a,b)=0 e Var(b)>0.",
                                  "learningObjective": "Provar analítica e empiricamente a eficiência do OLS.",
                                  "commonMistakes": [
                                    "Aplicar Gauss-Markov sem premissas.",
                                    "Confundir eficiência com consistência."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários vs. anos de educação (n=50), calcule β̂_OLS para salário ~ educação. Derive Var(β̂) assumindo σ²=100 e X'X invertível. Simule 1000 datasets, compare variância de β̂_OLS com média móvel (outro linear), mostrando OLS menor.",
                              "finalVerifications": [
                                "Derivação correta de Var(β̂_OLS) = σ² (X'X)^{-1}.",
                                "Prova geométrica de ortogonalidade e mínimos quadrados.",
                                "Simulação Monte Carlo confirma eficiência.",
                                "Lista premissas Gauss-Markov e violações comuns.",
                                "Interpretação: diagonal de (X'X)^{-1} mostra precisão por coeficiente.",
                                "Comparação numérica com estimador alternativo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação matricial (sem erros algébricos).",
                                "Compreensão geométrica via diagrama de projeção.",
                                "Resultados de simulação coerentes (variância OLS mínima).",
                                "Explicação clara de por que eficiência é mínima.",
                                "Identificação correta de premissas e limitações.",
                                "Aplicação prática em exemplo real."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teorema de Gauss-Markov e inferência.",
                                "Álgebra Linear: Projeções ortogonais e autovalores.",
                                "Econometria: Eficiência em modelos de regressão.",
                                "Machine Learning: OLS como baseline para regressão linear."
                              ],
                              "realWorldApplication": "Em análise de dados financeiros, calcular Var(β̂_OLS) em regressão de retornos de ações vs. fatores macroeconômicos ajuda a construir intervalos de confiança precisos para previsões de risco, otimizando portfólios onde eficiência minimiza erro de estimativa."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.3"
                            ]
                          },
                          {
                            "id": "11.2.1.3.4",
                            "name": "Aplicar eficiência em contexto de engenharia",
                            "description": "Exemplo numérico de regressão linear em dados de engenharia (ex.: previsão de falhas) mostrando variância OLS vs. outro estimador.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos de Eficiência em Estimadores OLS",
                                  "subSteps": [
                                    "Defina eficiência como a propriedade de um estimador não viesado ter a menor variância possível entre todos os estimadores não viesados.",
                                    "Explique a variância assintótica do OLS em regressão linear simples e múltipla.",
                                    "Discuta condições para eficiência OLS: homocedasticidade, normalidade dos erros e exogeneidade.",
                                    "Compare com estimadores ineficientes como o de momentos ou ridge em cenários de multicolinearidade.",
                                    "Estude teoremas como Gauss-Markov que provam eficiência OLS sob suposições clássicas."
                                  ],
                                  "verification": "Resuma em um parágrafo os critérios de eficiência OLS e cite o teorema Gauss-Markov corretamente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge), notas de aula sobre regressão linear",
                                    "Notebook Jupyter para anotações"
                                  ],
                                  "tips": "Use diagramas de variância para visualizar eficiência (menor elipse de confiança).",
                                  "learningObjective": "Compreender teoricamente por que OLS é eficiente em contextos ideais.",
                                  "commonMistakes": "Confundir eficiência com consistência ou não considerar violações de homocedasticidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Dataset de Engenharia para Previsão de Falhas",
                                  "subSteps": [
                                    "Colete ou gere dados simulados: variáveis como horas de operação (X), temperatura (X2), ciclos de uso (X3) e indicador de falha (Y binário ou tempo até falha).",
                                    "Limpe dados: remova outliers, trate missing values com imputação média.",
                                    "Divida em treino/teste (80/20) e verifique multicolinearidade com VIF.",
                                    "Transforme variáveis se necessário (log para não-linearidades).",
                                    "Explore dados com histogramas e correlações para identificar heterocedasticidade potencial."
                                  ],
                                  "verification": "Crie um relatório com estatísticas descritivas e matriz de correlação; VIF < 5 para todas variáveis.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com pandas, numpy, matplotlib",
                                    "Dataset exemplo: simule 1000 amostras com numpy.random"
                                  ],
                                  "tips": "Simule heterocedasticidade leve nos erros para testar eficiência real.",
                                  "learningObjective": "Preparar dados reais de engenharia adequados para demonstrar eficiência.",
                                  "commonMistakes": "Ignorar multicolinearidade, que viola eficiência OLS."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e Avaliar Regressão Linear OLS",
                                  "subSteps": [
                                    "Ajuste modelo OLS usando statsmodels ou sklearn: Y ~ X1 + X2 + X3.",
                                    "Calcule variância dos coeficientes com .cov_params() no statsmodels.",
                                    "Estime erros padrão e intervalos de confiança.",
                                    "Teste suposições: Breusch-Pagan para homocedasticidade, Durbin-Watson para autocorrelação.",
                                    "Calcule R² ajustado e MSE para baseline."
                                  ],
                                  "verification": "Obtenha matriz de covariância OLS e confirme variâncias finitas e positivas.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Python: statsmodels, sklearn",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use summary() no statsmodels para output completo.",
                                  "learningObjective": "Implementar OLS e quantificar sua variância em dados de engenharia.",
                                  "commonMistakes": "Não escalar variáveis, levando a variâncias infladas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar Estimador Alternativo e Comparar Variâncias",
                                  "subSteps": [
                                    "Escolha estimador alternativo: Ridge Regression (para multicolinearidade) via sklearn Ridge.",
                                    "Ajuste Ridge com alpha=1.0 e calcule coeficientes e variâncias efetivas (via bootstrap ou approx).",
                                    "Implemente bootstrap (1000 reamostras) para estimar variâncias empíricas de ambos OLS e Ridge.",
                                    "Compare variâncias coeficiente a coeficiente: calcule ratio (Var_OLS / Var_Alt).",
                                    "Visualize com boxplots das distribuições bootstrap de variâncias."
                                  ],
                                  "verification": "Mostre tabela comparativa onde OLS tem menor variância na maioria dos casos sob homocedasticidade.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "sklearn.linear_model.Ridge",
                                    "scipy para bootstrap"
                                  ],
                                  "tips": "Use cross-validation para escolher alpha no Ridge.",
                                  "learningObjective": "Demonstrar numericamente a superioridade de eficiência do OLS vs. alternativo.",
                                  "commonMistakes": "Usar poucos bootstrap reps, levando a estimativas instáveis."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar Resultados e Aplicar em Contexto de Engenharia",
                                  "subSteps": [
                                    "Analise quando OLS é mais eficiente (baixa multicolinearidade) vs. quando falha (heterocedasticidade).",
                                    "Preveja falhas com ambos modelos e compare precisão em hold-out set.",
                                    "Discuta implicações: OLS para decisões de manutenção preditiva com menor incerteza.",
                                    "Gere relatório com gráficos de variâncias e previsões.",
                                    "Sugira melhorias: GLS se heterocedasticidade detectada."
                                  ],
                                  "verification": "Escreva conclusão: 'OLS mostrou 20-30% menor variância em 3/4 coeficientes'.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Matplotlib/Seaborn para plots",
                                    "Relatório em Markdown"
                                  ],
                                  "tips": "Foque em impacto: menor variância = previsões mais confiáveis para engenharia.",
                                  "learningObjective": "Aplicar conceito de eficiência para resolver problema de engenharia real.",
                                  "commonMistakes": "Generalizar eficiência OLS sem testar suposições."
                                }
                              ],
                              "practicalExample": "Em um conjunto de dados de 1000 turbinas eólicas: X1=horas operação, X2=temperatura média, X3=velocidade vento; Y=tempo até falha. OLS: var(β1)=0.0023; Ridge(α=1): var(β1)=0.0031 (bootstrap 1000x). OLS eficiente pois ratio=0.74 <1, melhor para agendar manutenções.",
                              "finalVerifications": [
                                "Código roda sem erros e reproduz variâncias comparáveis.",
                                "OLS exibe menor variância em pelo menos 70% dos coeficientes.",
                                "Suposições OLS testadas e reportadas.",
                                "Previsões em test set com MSE OLS menor que alternativo.",
                                "Relatório inclui tabelas, gráficos e interpretação.",
                                "Conclusão liga eficiência à redução de falhas em engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação de OLS e cálculo de variância (30%).",
                                "Correta comparação bootstrap com ratios <1 para OLS (25%).",
                                "Análise de suposições e limitações (20%).",
                                "Clareza do exemplo numérico e visualizações (15%).",
                                "Conexão explícita com aplicação em engenharia (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia Mecânica: Modelagem de falhas em equipamentos.",
                                "Programação: Uso de statsmodels/sklearn para análise estatística.",
                                "Física: Relação entre variáveis operacionais e degradação material.",
                                "Gestão de Projetos: Otimização de manutenção preditiva via inferência eficiente."
                              ],
                              "realWorldApplication": "Em indústrias como óleo&gás ou aeroespacial, usar OLS eficiente para prever falhas em bombas ou turbinas, minimizando downtime e custos de manutenção em milhões, ao fornecer coeficientes com menor variância para decisões confiáveis."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.3.3"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "11.2.1.4",
                        "name": "Normalidade dos Estimadores OLS",
                        "description": "Distribuição normal dos estimadores OLS em amostras finitas (sob normalidade dos erros) e assintótica para inferência estatística sob pressupostos clássicos.",
                        "specificSkills": [
                          {
                            "id": "11.2.1.4.1",
                            "name": "Explicar normalidade finita e assintótica do OLS",
                            "description": "Descrever que β̂_OLS ~ N(β, σ²(X'X)^{-1}) sob MLR.1-6 (u|X ~ N(0,σ²I)), e normalidade assintótica por TLC mesmo sem normalidade de u.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os Pressupostos MLR.1-6 para o Estimador OLS",
                                  "subSteps": [
                                    "Liste e explique brevemente cada um dos seis pressupostos MLR (MLR.1: Linearidade em parâmetros; MLR.2: E[u|X]=0; MLR.3: Homocedasticidade; MLR.4: Sem autocorrelação; MLR.5: Sem multicolinearidade perfeita; MLR.6: Não especificado ainda).",
                                    "Discuta como esses pressupostos garantem que β̂_OLS é Não-Viesado e Consistente.",
                                    "Identifique que MLR.1-5 são suficientes para propriedades de ponto, mas inferência requer mais.",
                                    "Prepare o terreno para o pressuposto adicional de normalidade dos erros para distribuição finita.",
                                    "Esboce a matriz de variância-covariância de β̂_OLS: σ²(X'X)^{-1}."
                                  ],
                                  "verification": "Crie um resumo escrito ou mapa mental listando MLR.1-6 com exemplos simples; verifique se cobre todos os seis.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre MLR",
                                    "Livro de Econometria (ex: Wooldridge)",
                                    "Quadro branco ou papel"
                                  ],
                                  "tips": "Use mnemônicos como 'Linha, Zero, Homo, Auto, Multi, Normal' para lembrar MLR.1-6.",
                                  "learningObjective": "Compreender os pressupostos fundamentais que sustentam as propriedades do OLS.",
                                  "commonMistakes": [
                                    "Confundir MLR.3 (homocedasticidade) com normalidade; ignorar MLR.4 em dados de séries temporais."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Normalidade Finita de β̂_OLS sob Normalidade dos Erros",
                                  "subSteps": [
                                    "Assuma o pressuposto adicional: u|X ~ N(0, σ²I) (erros i.i.d. normais condicional em X).",
                                    "Lembre que β̂_OLS = (X'X)^{-1}X'y = β + (X'X)^{-1}X'u.",
                                    "Mostre que (X'X)^{-1}X'u é uma combinação linear de u's normais, logo normal.",
                                    "Derive a distribuição exata: β̂_OLS ~ N(β, σ²(X'X)^{-1}).",
                                    "Discuta implicações para testes t, F e intervalos de confiança exatos em amostras finitas."
                                  ],
                                  "verification": "Derive algebricamente a distribuição em um papel ou software simbólico como SymPy; confira com fórmula padrão.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Cálculo matricial básico",
                                    "Software como R ou Python (opcional para simulação)",
                                    "Tabela de fórmulas OLS"
                                  ],
                                  "tips": "Visualize com vetores: X'u é normal pois u é, e (X'X)^{-1} é constante.",
                                  "learningObjective": "Derivar e explicar a normalidade exata de β̂_OLS sob pressupostos fortes.",
                                  "commonMistakes": [
                                    "Esquecer que normalidade é condicional em X; assumir normalidade sem i.i.d.."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explicar a Normalidade Assintótica via Teorema do Limite Central (TLC)",
                                  "subSteps": [
                                    "Relaxe o pressuposto de normalidade: assuma apenas MLR.1-5 e u i.i.d. com E[u]=0, Var(u)=σ² < ∞.",
                                    "Aplique TLC: √n (β̂_OLS - β) →^d N(0, σ² plim (X'X/n)^{-1}) à medida que n → ∞.",
                                    "Explique consistência de β̂_OLS e convergência em distribuição para inferência assintótica.",
                                    "Discuta quando usar: amostras grandes, erros não-normais (ex: t-Student, logística).",
                                    "Compare com normalidade finita: assintótica é robusta, mas aproximação pior em n pequeno."
                                  ],
                                  "verification": "Escreva uma prova esboçada do TLC aplicado a β̂_OLS; teste com simulação Monte Carlo em n=30 vs n=1000.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Teorema do Limite Central (notas)",
                                    "R ou Python para simulação (pacote 'lmtest')"
                                  ],
                                  "tips": "Pense em β̂_j como média de u_i x_{ik}/var(x), que é CLT-eligible.",
                                  "learningObjective": "Entender como o TLC fornece normalidade aproximada sem assumir normalidade de u.",
                                  "commonMistakes": [
                                    "Confundir consistência (ponto) com convergência em distribuição; ignorar √n na taxa."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar Normalidade Finita e Assintótica e Discutir Implicações Práticas",
                                  "subSteps": [
                                    "Crie uma tabela comparativa: condições, validade (finita vs n→∞), testes (t/F exatos vs assintóticos).",
                                    "Discuta cenários: Use finita para n pequeno + normalidade; assintótica para big data ou não-normalidade.",
                                    "Explore robustez: bootstrapping como alternativa à assintótica.",
                                    "Aplique a um exemplo: regredir salário em educação, checar QQ-plot de resíduos.",
                                    "Resuma: Finita para exatidão teórica; assintótica para praticidade real."
                                  ],
                                  "verification": "Gere a tabela e aplique a um dataset simples; explique diferenças em um parágrafo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset exemplo (Wage data de Wooldridge)",
                                    "R/Python para regressão e plots QQ"
                                  ],
                                  "tips": "Sempre cheque resíduos com QQ-plot para validar aproximações.",
                                  "learningObjective": "Sintetizar diferenças e escolher abordagem baseada no contexto empírico.",
                                  "commonMistakes": [
                                    "Aplicar testes finitos sem normalidade; superestimar exatidão assintótica em n<100."
                                  ]
                                }
                              ],
                              "practicalExample": "Em R, ajuste lm(wage ~ educ + exper, data=wooldridge::wage1). Teste normalidade finita com shapiro.test(residuals(model)). Para assintótica, simule 1000 datasets com n=50 (erros t(3)), plote histogramas de coefs e QQ vs N(0,1) escalado. Observe: finita falha sem normal u, assintótica OK em n grande.",
                              "finalVerifications": [
                                "Derive corretamente β̂_OLS ~ N(β, σ²(X'X)^{-1}) sob MLR.1-6 + normal u.",
                                "Explique TLC para √n(β̂_OLS - β) → N(0, AsyVar) sem normalidade.",
                                "Compare cenários finita vs assintótica em tabela.",
                                "Interprete QQ-plot de simulação mostrando convergência assintótica.",
                                "Discuta implicações para ICs e testes em dados reais.",
                                "Identifique quando usar cada uma (ex: n=30 finita se normal; n=1000 assintótica)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação da distribuição finita (inclui condicional em X).",
                                "Correta aplicação e interpretação do TLC para assintótica.",
                                "Clareza na comparação finita vs assintótica com exemplos.",
                                "Uso apropriado de simulações ou plots para ilustração.",
                                "Compreensão de limitações e robustez em contextos reais.",
                                "Capacidade de explicar implicações para inferência estatística."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Distribuições normais multivariadas e TLC.",
                                "Cálculo: Álgebra matricial e limites (plim).",
                                "Estatística Inferencial: Testes t/F exatos vs assintóticos.",
                                "Ciência de Dados: Validação de resíduos em ML (QQ-plots).",
                                "Econometria: Robustez em regressões aplicadas."
                              ],
                              "realWorldApplication": "Em análise de dados econômicos, como prever salários via OLS, use normalidade finita para ICs exatos em estudos pequenos com dados gaussianos; para big data de saúde (ex: COVID outcomes), aplique assintótica para testes robustos apesar de erros não-normais, permitindo políticas baseadas em inferência confiável."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.1.1"
                            ]
                          },
                          {
                            "id": "11.2.1.4.2",
                            "name": "Listar pressupostos para normalidade do OLS",
                            "description": "Identificar MLR.6 (normalidade condicional dos erros) para exatidão finita e condições para normalidade assintótica (momentos finitos).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Básicos do OLS (MLR.1 a MLR.5)",
                                  "subSteps": [
                                    "Liste os cinco primeiros pressupostos MLR.1 (linearidade condicional da média), MLR.2 (ausência de multicolinearidade perfeita), MLR.3 (variância homocedástica condicional), MLR.4 (sem autocorrelação condicional dos erros), MLR.5 (zero média condicional dos erros).",
                                    "Explique por que esses pressupostos são necessários para unbiasedness e eficiência dos estimadores OLS.",
                                    "Identifique cenários onde violações ocorrem, como heterocedasticidade em dados financeiros.",
                                    "Crie um fluxograma mental ligando esses pressupostos à normalidade.",
                                    "Anote exemplos de datasets onde esses pressupostos tipicamente seguram."
                                  ],
                                  "verification": "Conseguir recitar os 5 pressupostos sem consultar notas e dar um exemplo de violação para cada.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Notas de aula sobre MLR, vídeo introdutório de Wooldridge 'Introductory Econometrics' (cap. 4).",
                                  "tips": "Use mnemônicos como 'L2HZE' (Linearity, 2 no multicollinearity, Homoscedasticity, Zero error mean, Exogeneity) para memorizar.",
                                  "learningObjective": "Compreender a base sobre a qual a normalidade é construída.",
                                  "commonMistakes": "Confundir MLR.3 (homocedasticidade) com normalidade; lembrar que normalidade é MLR.6, não pré-requisito para consistência."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender MLR.6: Normalidade Condicional dos Erros para Exatidão Finita",
                                  "subSteps": [
                                    "Defina MLR.6 formalmente: ε | X ~ N(0, σ²I_n), onde erros são independentes e normalmente distribuídos condicional em X.",
                                    "Explique implicações: β_hat e σ_hat² seguem distribuições exatas Normal e Qui-quadrada/t-Student.",
                                    "Discuta testes para verificar: Q-Q plot, Shapiro-Wilk, Jarque-Bera.",
                                    "Simule um dataset em Python/R com e sem normalidade para comparar distribuições de β_hat.",
                                    "Registre a equação matemática: f(ε_i | X) = produto de densidades normais independentes."
                                  ],
                                  "verification": "Gerar um Q-Q plot de resíduos simulados e interpretar se segue linha reta.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (statsmodels, scipy.stats), R (lmtest), dataset exemplo como Boston Housing.",
                                  "tips": "Sempre centre os resíduos antes de plotar Q-Q para melhor visualização.",
                                  "learningObjective": "Dominar o pressuposto exato para inferência finita-sample.",
                                  "commonMistakes": "Assumir normalidade incondicional; é condicional em X que importa."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Condições para Normalidade Assintótica dos Estimadores OLS",
                                  "subSteps": [
                                    "Descreva teorema CLT para OLS: sob MLR.1-MLR.5 + erros i.i.d. com E(ε²|X)<∞, √n(β_hat - β) → N(0, AsyVar).",
                                    "Liste condições chave: momentos finitos até 2º ou 4º ordem, independência ou fraqueza de dependência.",
                                    "Compare finita vs assintótica: finita requer MLR.6; assintótica não, mas precisa n grande.",
                                    "Calcule variância assintótica: σ² (X'X/n)^{-1}.",
                                    "Teste em simulação: n=30 vs n=1000, plote histogramas de β_hat."
                                  ],
                                  "verification": "Simular 1000 regressões com n=100, verificar se histograma de β_hat é aproximadamente normal.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Jupyter Notebook com código de simulação Monte Carlo, referência Greene 'Econometric Analysis' (cap. 4).",
                                  "tips": "Use seed para reprodutibilidade em simulações.",
                                  "learningObjective": "Diferenciar normalidade exata de assintótica e suas condições.",
                                  "commonMistakes": "Ignorar que assintótica requer momentos finitos; erros pesados caudas violam CLT."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar e Listar Todos os Pressupostos para Normalidade do OLS",
                                  "subSteps": [
                                    "Compile lista completa: Para finita - MLR.1-6; Para assintótica - MLR.1-5 + i.i.d. erros com momentos finitos.",
                                    "Crie tabela comparativa: colunas finita/assintótica, linhas pressupostos.",
                                    "Explique implicações para testes t/F: exatos sob finita, assintóticos sem MLR.6.",
                                    "Aplique a um modelo real: regredir salário em educação/experiência, cheque pressupostos.",
                                    "Escreva parágrafo resumindo quando usar cada abordagem."
                                  ],
                                  "verification": "Produzir tabela e lista verbal sem erros em whiteboard ou papel.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Dataset Wage (Wooldridge), Excel/Google Sheets para tabela.",
                                  "tips": "Agrupe finita (MLR.6) vs assintótica (CLT) para facilitar memorização.",
                                  "learningObjective": "Listar fluentemente pressupostos e contextos de aplicação.",
                                  "commonMistakes": "Omitir condicionalidade em X; listar normalidade como MLR.1-5 apenas."
                                }
                              ],
                              "practicalExample": "Em um modelo OLS prevendo preço de casas (Y) por tamanho (X1) e quartos (X2): Verifique MLR.6 com Q-Q plot de resíduos; se não normal, use bootstrap para ICs assintóticos ou transforme variáveis para aproximar normalidade.",
                              "finalVerifications": [
                                "Recitar MLR.6 verbatim e explicar sua notação matemática.",
                                "Listar 3 condições para normalidade assintótica via CLT.",
                                "Diferenciar inferência finita vs assintótica em testes t.",
                                "Interpretar Q-Q plot de resíduos reais de um modelo OLS.",
                                "Criar tabela comparativa finita/assintótica sem erros.",
                                "Simular violação de momentos finitos e mostrar falha no CLT."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de MLR.6 (100% match com formulação padrão).",
                                "Correta distinção finita (MLR.6) vs assintótica (momentos finitos).",
                                "Uso correto de simulações para demonstrar conceitos.",
                                "Identificação de pelo menos 2 erros comuns em verificações de pressupostos.",
                                "Aplicação prática em dataset real com interpretação.",
                                "Clareza na tabela/lista de pressupostos."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema Central do Limite e distribuições assintóticas.",
                                "Estatística Inferencial: Testes t/F exatos vs robustos.",
                                "Econometria: Modelos de regressão e diagnósticos de resíduos.",
                                "Ciência de Dados: Validação de pressupostos em ML pipelines."
                              ],
                              "realWorldApplication": "Em análise de risco financeiro, verificar normalidade OLS em modelos de CAPM para ICs confiáveis em portfólios; sem MLR.6, usar métodos robustos como Newey-West para previsões de retornos de ações."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.2.2"
                            ]
                          },
                          {
                            "id": "11.2.1.4.3",
                            "name": "Derivar a distribuição normal do OLS",
                            "description": "Derivar a normalidade usando propriedades lineares de u normal e fraqueza da lei dos grandes números para covariâncias amostrais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o modelo OLS e a expressão do estimador",
                                  "subSteps": [
                                    "Escreva o modelo linear: y = Xβ + u, com E[u|X]=0 e Var(u|X)=σ²I.",
                                    "Derive a expressão do OLS: β̂ = (X'X)^{-1}X'y = β + (X'X)^{-1}X'u.",
                                    "Identifique β̂ - β = (X'X)^{-1}X'u como combinação linear de u.",
                                    "Liste as suposições chave: u ~ N(0, σ²I), independente de X.",
                                    "Verifique dimensionalidade: X é n x k, com rank k."
                                  ],
                                  "verification": "Escreva corretamente a expressão de β̂ e destaque a parte linear em u.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Papel e caneta, livro-texto de econometria (ex: Wooldridge), calculadora.",
                                  "tips": "Use notação matricial consistente para evitar confusões escalares.",
                                  "learningObjective": "Entender β̂ como função linear afim de u sob condicionamento em X.",
                                  "commonMistakes": "Esquecer de condicionar em X ou assumir homocedasticidade sem σ²I."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar propriedades lineares da distribuição normal",
                                  "subSteps": [
                                    "Lembre que se u ~ N(0, σ²I), então qualquer combinação linear Au ~ N(0, σ² A A').",
                                    "Defina A = (X'X)^{-1}X', então (β̂ - β) = A u.",
                                    "Compute Var(β̂ - β | X) = σ² (X'X)^{-1}.",
                                    "Conclua que β̂ | X ~ N(β, σ² (X'X)^{-1}).",
                                    "Discuta independência condicional: distribuição exata para qualquer n > k."
                                  ],
                                  "verification": "Derive a distribuição normal exata de β̂ | X e escreva sua média e variância.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Papel e caneta, software como R ou Python para simular (opcional), notas de estatística multivariada.",
                                  "tips": "Visualize com regressão simples (k=2) para intuicao: β̂1 normal.",
                                  "learningObjective": "Dominar como linearidade preserva normalidade.",
                                  "commonMistakes": "Confundir variância condicional com incondicional ou ignorar |X."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir covariâncias amostrais e Lei dos Grandes Números",
                                  "subSteps": [
                                    "Defina matriz de covariância amostral: S_{xx} = (1/n) X'X, convergindo para plim S_{xx} = Q por WLLN.",
                                    "Estenda para covariância de regressores: assuma E[x_i x_i'] = Q finita.",
                                    "Aplique Fraqueza da Lei dos Grandes Números (WLLN): (1/n) ∑ x_i x_i' → Q em probabilidade.",
                                    "Discuta implicações para Var(β̂): σ² (X'X/n)^{-1} ≈ σ² Q^{-1} para n grande.",
                                    "Verifique condições WLLN: i.i.d. regressores com momentos finitos."
                                  ],
                                  "verification": "Prove que S_{xx} →^p Q usando WLLN e escreva aproximação assintótica.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Papel e caneta, apostila de probabilidade assintótica, exemplos numéricos em Excel.",
                                  "tips": "Comece com regressão univariada para simplicidade em LLN.",
                                  "learningObjective": "Conectar consistência de covariâncias amostrais à normalidade.",
                                  "commonMistakes": "Usar LLN forte em vez de fraca ou ignorar i.i.d."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar normalidade exata com aproximações assintóticas",
                                  "subSteps": [
                                    "Combine: normalidade exata de β̂ | X com plim (X'X/n) = Q.",
                                    "Derive distribuição assintótica: √n (β̂ - β) →^d N(0, σ² Q^{-1}).",
                                    "Estenda para σ̂² usando resíduos e WLLN para consistência.",
                                    "Teste com exemplo: simule dados em Python/R e verifique normalidade.",
                                    "Resuma prova completa: linearidade + normal u + WLLN para cov."
                                  ],
                                  "verification": "Escreva a derivacão completa da normalidade do OLS e simule para validar.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Python/R com numpy/statsmodels, papel para prova final.",
                                  "tips": "Use QQ-plots na simulação para checar normalidade.",
                                  "learningObjective": "Sintetizar normalidade exata e assintótica do OLS.",
                                  "commonMistakes": "Misturar exata com assintótica sem √n ou esquecer plim."
                                }
                              ],
                              "practicalExample": "Em uma regressão linear simples y_i = β0 + β1 x_i + u_i com u_i ~ N(0,σ²), derive que β̂1 | X ~ N(β1, σ² / ∑(x_i - x̄)^2). Simule n=100 observações em Python, estime β̂1 e plote histograma para ver normalidade.",
                              "finalVerifications": [
                                "Escrever a prova completa da normalidade exata de β̂ | X.",
                                "Explicar papel da WLLN nas covariâncias amostrais.",
                                "Simular dados e confirmar distribuição via QQ-plot.",
                                "Derivar variância assintótica √n (β̂ - β) ~ N(0, σ² Q^{-1}).",
                                "Identificar suposições necessárias (normal u, i.i.d., momentos finitos).",
                                "Aplicar em regressão bivariada manualmente."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivacão linear de β̂ (100% correto).",
                                "Correta aplicação de propriedades normais (variância matricial).",
                                "Uso apropriado de WLLN para plim S_{xx} = Q.",
                                "Integração exata e assintótica sem erros conceituais.",
                                "Simulação prática com interpretação visual (QQ-plot).",
                                "Clareza na escrita da prova final."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: CLT e teoremas limite para extensões assintóticas.",
                                "Programação: Simulações em Python/R para validação empírica.",
                                "Economia: Inferência em modelos de regressão para políticas públicas.",
                                "Matemática: Álgebra linear matricial e distribuições multivariadas."
                              ],
                              "realWorldApplication": "Em análise de dados econômicos, como estimar impacto de educação no salário via OLS, a normalidade permite intervalos de confiança e testes t/F para inferência causal em grandes datasets do IBGE ou PNAD."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.1.3.3"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.2",
                    "name": "Inferência Estatística em Regressão Linear",
                    "description": "Distribuição dos estimadores e construção de intervalos de confiança para parâmetros do modelo.",
                    "individualConcepts": [
                      {
                        "id": "11.1.2.2.1",
                        "name": "Distribuição dos Estimadores OLS",
                        "description": "Análise da distribuição exata e assintótica dos estimadores de mínimos quadrados ordinários (OLS) sob os pressupostos da regressão linear clássica, incluindo normalidade condicional dos erros.",
                        "specificSkills": [
                          {
                            "id": "11.1.2.2.1.1",
                            "name": "Identificar pressupostos para normalidade dos estimadores",
                            "description": "Listar e explicar os quatro pressupostos principais da regressão linear clássica (linearidade, exogeneidade, homocedasticidade e normalidade dos erros) que garantem a distribuição normal dos estimadores OLS.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Teorema de Gauss-Markov e a Necessidade de Normalidade",
                                  "subSteps": [
                                    "Revise o teorema de Gauss-Markov: pressupostos para BLUE (Best Linear Unbiased Estimator).",
                                    "Identifique que normalidade dos estimadores requer pressupostos adicionais além de Gauss-Markov.",
                                    "Estude a matriz de covariância dos estimadores OLS e como ela leva à normalidade.",
                                    "Anote os quatro pressupostos principais que garantem normalidade exata.",
                                    "Compare normalidade exata (pequenas amostras) vs. assintótica (grandes amostras)."
                                  ],
                                  "verification": "Escreva um resumo de 1 parágrafo explicando por que normalidade é necessária para inferência.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Notas de aula sobre regressão linear, vídeo introdutório no YouTube (ex: 'OLS Assumptions').",
                                  "tips": "Use diagramas de Venn para visualizar pressupostos Gauss-Markov vs. normalidade.",
                                  "learningObjective": "Compreender o papel dos pressupostos na distribuição normal dos estimadores OLS.",
                                  "commonMistakes": "Confundir BLUE com normalidade; assumir normalidade sem pressupostos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Pressuposto de Linearidade",
                                  "subSteps": [
                                    "Defina linearidade: E(y|X) = Xβ (forma correta do modelo).",
                                    "Discuta violações: especificação incorreta (polinômios omitidos, interações).",
                                    "Aprenda a testar: gráficos de resíduos vs. ajustados, testes RESET.",
                                    "Explique impacto na normalidade: violar linearidade distorce a distribuição dos erros.",
                                    "Pratique identificando em um modelo simples."
                                  ],
                                  "verification": "Crie um gráfico de resíduos para um dataset simples e interprete se linearidade holds.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Software R/Python (lm() ou statsmodels), dataset exemplo (mtcars).",
                                  "tips": "Sempre plote primeiro: 'plot(model)' no R revela padrões não-lineares.",
                                  "learningObjective": "Identificar e testar o pressuposto de linearidade.",
                                  "commonMistakes": "Ignorar termos quadráticos ou logs quando dados sugerem não-linearidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar o Pressuposto de Exogeneidade",
                                  "subSteps": [
                                    "Defina exogeneidade: Cov(ε_i, X_i) = 0 (erros uncorrelated com regressores).",
                                    "Discuta violações: endogeneidade (omitted variables, measurement error).",
                                    "Aprenda testes: Hausman, Durbin-Wu-Hausman.",
                                    "Explique como violações levam a bias e não-normalidade.",
                                    "Simule um exemplo com variável instrumental."
                                  ],
                                  "verification": "Explique em 3 frases como exogeneidade afeta a normalidade dos β̂.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Livro 'Introductory Econometrics' (Wooldridge), Jupyter notebook com simulações.",
                                  "tips": "Pense em causalidade: 'Correlação não é causalidade' é chave aqui.",
                                  "learningObjective": "Reconhecer violações de exogeneidade e seu impacto na inferência.",
                                  "commonMistakes": "Confundir correlação com causalidade sem testar."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Investigar Homocedasticidade e Normalidade dos Erros",
                                  "subSteps": [
                                    "Defina homocedasticidade: Var(ε_i|X) = σ² constante.",
                                    "Testes: Breusch-Pagan, White; gráficos de scale-location.",
                                    "Defina normalidade dos erros: ε ~ N(0, σ²).",
                                    "Testes: Shapiro-Wilk, Q-Q plots, Jarque-Bera.",
                                    "Explique como ambos garantem normalidade dos estimadores via teorema central limite."
                                  ],
                                  "verification": "Aplique testes em um modelo real e liste resultados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "R (lmtest, car pacotes), Python (statsmodels diagnostics).",
                                  "tips": "Q-Q plots são visuais poderosos: desvios nas caudas indicam não-normalidade.",
                                  "learningObjective": "Testar e interpretar homocedasticidade e normalidade dos resíduos.",
                                  "commonMistakes": "Assumir homocedasticidade sem plotar resíduos vs. fitted."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar os Quatro Pressupostos e Verificar em um Exemplo",
                                  "subSteps": [
                                    "Liste os quatro: linearidade, exogeneidade, homocedasticidade, normalidade erros.",
                                    "Crie uma checklist para diagnóstico de modelo.",
                                    "Aplique a um dataset completo: ajuste modelo, teste todos pressupostos.",
                                    "Discuta remédios: robust SE, transformações, GLS.",
                                    "Resuma como violação de qualquer um invalida normalidade exata."
                                  ],
                                  "verification": "Produza relatório de 1 página com testes e conclusões para um modelo.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Dataset real (Boston Housing ou similar), relatório template.",
                                  "tips": "Use funis: comece com plots, avance para testes formais.",
                                  "learningObjective": "Integrar todos pressupostos em diagnóstico completo de regressão.",
                                  "commonMistakes": "Focar só em normalidade sem checar os outros três."
                                }
                              ],
                              "practicalExample": "Em um modelo de salário vs. anos de educação e experiência (dataset: Wage data de Wooldridge), ajuste OLS, plote resíduos para linearidade, teste Breusch-Pagan para homocedasticidade, Shapiro-Wilk para normalidade erros, e discuta exogeneidade via omitted variables como motivação intrínseca.",
                              "finalVerifications": [
                                "Liste corretamente os quatro pressupostos com definições breves.",
                                "Explique verbalmente como cada um contribui para normalidade dos OLS.",
                                "Aplique checklist a um novo modelo e identifique pelo menos uma violação.",
                                "Interprete saída de Q-Q plot e teste Jarque-Bera.",
                                "Proponha correção para violação de homocedasticidade.",
                                "Diferencie normalidade exata vs. assintótica em contexto de inferência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação dos quatro pressupostos (100% correto).",
                                "Profundidade na explicação de impactos na normalidade (exemplos dados).",
                                "Correta aplicação e interpretação de pelo menos 3 testes diagnósticos.",
                                "Qualidade dos substeps executados (todos completos e acionáveis).",
                                "Criatividade em exemplos práticos e conexões reais.",
                                "Clareza no relatório final (lógico, sem erros matemáticos)."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Distribuições normais e teorema central limite.",
                                "Machine Learning: Diagnóstico de modelos lineares em pipelines de features.",
                                "Economia: Endogeneidade em modelos causais (IV, RDD).",
                                "Computação: Implementação de testes em R/Python para data science.",
                                "Estatística Bayesiana: Priors normais condicionados nesses pressupostos."
                              ],
                              "realWorldApplication": "Em análise de dados para empresas (ex: previsão de vendas), verificar esses pressupostos garante inferência confiável em t-tests e ICs para coeficientes, evitando decisões erradas como precificar produtos baseado em modelos biased; comum em relatórios de econometria para políticas públicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.1.2",
                            "name": "Derivar a distribuição dos coeficientes beta",
                            "description": "Demonstrar matematicamente que, sob os pressupostos clássicos, os estimadores β̂ seguem uma distribuição normal N(β, σ²(X'X)^{-1}), com variância conhecida em termos da matriz de covariância.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os pressupostos clássicos do modelo de regressão linear e o estimador OLS",
                                  "subSteps": [
                                    "Liste os quatro pressupostos principais: linearidade, exogeneidade estrita (E(ε|X)=0), homocedasticidade (Var(ε_i|X)=σ²) e não-colinearidade (rank(X)=k).",
                                    "Escreva o modelo y = Xβ + ε, onde ε ~ N(0, σ²I_n).",
                                    "Derive o estimador OLS: β̂ = (X'X)^{-1}X'y.",
                                    "Verifique matematicamente que X'X é invertível sob não-colinearidade.",
                                    "Discuta a importância da normalidade dos erros para inferência."
                                  ],
                                  "verification": "Confirme que todos os pressupostos estão corretamente enunciados e o estimador β̂ está escrito sem erros.",
                                  "estimatedTime": "30 minutes",
                                  "materials": [
                                    "Papel e caneta",
                                    "Livro de regressão linear (ex: Wooldridge)",
                                    "Calculadora matricial ou software como MATLAB/R"
                                  ],
                                  "tips": "Comece pelos pressupostos mais fundamentais; memorize a distribuição assumida de ε.",
                                  "learningObjective": "Entender as bases teóricas necessárias para a derivação da distribuição de β̂.",
                                  "commonMistakes": "Esquecer a independência dos erros ou confundir homocedasticidade com heterocedasticidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estabelecer a representação do erro do estimador: β̂ - β = (X'X)^{-1}X'ε",
                                  "subSteps": [
                                    "Substitua y = Xβ + ε na fórmula de β̂ para obter β̂ = (X'X)^{-1}X'(Xβ + ε).",
                                    "Simplifique: β̂ = β + (X'X)^{-1}X'ε.",
                                    "Identifique o termo de erro linear: (X'X)^{-1}X'ε.",
                                    "Verifique dimensionalmente: X é n x k, X'ε é k x 1, (X'X)^{-1} é k x k.",
                                    "Discuta por que isso é uma combinação linear dos erros ε."
                                  ],
                                  "verification": "Escreva e simplifique corretamente a equação β̂ - β = (X'X)^{-1}X'ε.",
                                  "estimatedTime": "25 minutes",
                                  "materials": [
                                    "Papel e caneta",
                                    "Software de álgebra simbólica como SymPy (Python)"
                                  ],
                                  "tips": "Use propriedades matriciais básicas como X'Xβ = X'X β para simplificar.",
                                  "learningObjective": "Expressar o estimador como o verdadeiro parâmetro mais um erro linear dos resíduos.",
                                  "commonMistakes": "Erro na multiplicação matricial, como inverter a ordem de X'X."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Provar que o estimador é não viesado: E(β̂) = β",
                                  "subSteps": [
                                    "Tome a esperança: E(β̂) = E[β + (X'X)^{-1}X'ε] = β + (X'X)^{-1}X'E[ε].",
                                    "Use o pressuposto de exogeneidade: E[ε|X] = 0, logo E[ε] = 0.",
                                    "Conclua E(β̂) = β.",
                                    "Discuta condicionamento em X para robustez.",
                                    "Verifique com um exemplo univariado simples."
                                  ],
                                  "verification": "Derive E(β̂) = β mostrando os passos de expectativa corretamente.",
                                  "estimatedTime": "20 minutes",
                                  "materials": [
                                    "Papel e caneta"
                                  ],
                                  "tips": "Lembre-se que a expectativa é linear, mesmo para matrizes.",
                                  "learningObjective": "Demonstrar a propriedade de não-viesamento dos OLS.",
                                  "commonMistakes": "Confundir E[ε|X]=0 com Var(ε|X)=0."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Derivar a matriz de covariância: Var(β̂) = σ² (X'X)^{-1}",
                                  "subSteps": [
                                    "Defina Var(β̂) = E[(β̂ - β)(β̂ - β)'] = E[((X'X)^{-1}X'ε)((X'X)^{-1}X'ε)'].",
                                    "Simplifique: (X'X)^{-1}X' E[ε ε'] X (X'X)^{-1}.",
                                    "Use Var(ε) = σ² I: E[ε ε'] = σ² I.",
                                    "Resulte em σ² (X'X)^{-1} X' I X (X'X)^{-1} = σ² (X'X)^{-1}.",
                                    "Interprete: variância depende de σ² e design de X."
                                  ],
                                  "verification": "Calcule e simplifique Var(β̂) até σ² (X'X)^{-1}.",
                                  "estimatedTime": "40 minutes",
                                  "materials": [
                                    "Papel e caneta",
                                    "Calculadora matricial"
                                  ],
                                  "tips": "Pratique transposições: (AB)' = B'A'.",
                                  "learningObjective": "Obter a variância assintótica/exata dos coeficientes.",
                                  "commonMistakes": "Esquecer o fator σ² ou errar na transposição da matriz."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Concluir a distribuição normal de β̂ usando normalidade dos erros",
                                  "subSteps": [
                                    "Lembre que ε ~ MVN(0, σ² I).",
                                    "Como β̂ - β é combinação linear de ε: Aε onde A = (X'X)^{-1}X'.",
                                    "Propriedade da normal multivariada: Aε ~ MVN(0, A (σ² I) A').",
                                    "Simplifique covariância: σ² A I A' = σ² A A' = σ² (X'X)^{-1}.",
                                    "Conclua: β̂ ~ N(β, σ² (X'X)^{-1})."
                                  ],
                                  "verification": "Escreva a distribuição final e justifique com propriedades da normal.",
                                  "estimatedTime": "30 minutes",
                                  "materials": [
                                    "Papel e caneta",
                                    "Referência de estatística multivariada"
                                  ],
                                  "tips": "Visualize X'ε como soma ponderada dos erros.",
                                  "learningObjective": "Estabelecer a normalidade exata sob pressupostos clássicos.",
                                  "commonMistakes": "Ignorar que a normalidade é exata só com ε normal, não CLT."
                                }
                              ],
                              "practicalExample": "Considere um modelo simples y_i = β0 + β1 x_i + ε_i, n=100, X com intercepto e x_i ~ N(0,1). Simule em R/Python: gere ε ~ N(0,1), compute β̂ múltiplas vezes (ex: 1000 simulações), plote histograma de β̂1 e sobreponha N(β1, σ² / Σ(x_i - x̄)^2). Verifique que se ajusta perfeitamente.",
                              "finalVerifications": [
                                "Derive corretamente β̂ - β = (X'X)^{-1}X'ε.",
                                "Prove E(β̂) = β usando E[ε]=0.",
                                "Calcule Var(β̂) = σ² (X'X)^{-1} sem erros algébricos.",
                                "Justifique a normalidade de β̂ via linearidade e MVN de ε.",
                                "Explique verbalmente os pressupostos necessários.",
                                "Simule numericamente para validar em regressão univariada."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação de cada passo (sem erros de álgebra).",
                                "Compreensão clara dos pressupostos e seu papel na normalidade.",
                                "Capacidade de simplificar expressões matriciais complexas.",
                                "Interpretação correta da matriz de covariância.",
                                "Aplicação em exemplo numérico/simulado.",
                                "Comunicação clara da prova final."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Operações com matrizes, invertibilidade e transposições.",
                                "Probabilidade: Distribuição normal multivariada e propriedades lineares.",
                                "Estatística Inferencial: Uso para testes t, intervalos de confiança.",
                                "Programação Computacional: Simulação de distribuições em Python/R para verificação.",
                                "Econometria: Aplicação em modelos de regressão empíricos."
                              ],
                              "realWorldApplication": "Em análise de dados econômicos, como prever salários baseados em educação (β1), a distribuição N(β, σ²(X'X)^{-1}) permite construir intervalos de confiança precisos para β1, essenciais para políticas públicas, relatórios financeiros e machine learning interpretável."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.1.3",
                            "name": "Calcular variância dos estimadores em prática",
                            "description": "Usando dados de engenharia, estimar a variância dos estimadores OLS com a fórmula s²(X'X)^{-1}, onde s² é a variância amostral dos resíduos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados de engenharia e ajustar o modelo OLS",
                                  "subSteps": [
                                    "Selecione um conjunto de dados de engenharia, como medições de tensão e deformação em testes de materiais.",
                                    "Carregue os dados em Python usando pandas e numpy.",
                                    "Construa a matriz de design X (incluindo coluna de intercepto) e o vetor y.",
                                    "Calcule os coeficientes OLS: beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ y)."
                                  ],
                                  "verification": "Verifique se beta_hat tem dimensões corretas e se o R² do modelo é razoável (>0.7 para dados de engenharia típicos).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python 3.x",
                                    "NumPy",
                                    "Pandas",
                                    "Jupyter Notebook",
                                    "Dataset de engenharia (ex: fadiga de materiais CSV)"
                                  ],
                                  "tips": "Adicione uma coluna de 1s em X para o intercepto usando np.c_[np.ones(len(X)), X].",
                                  "learningObjective": "Dominar a preparação de dados e o cálculo dos estimadores OLS.",
                                  "commonMistakes": [
                                    "Esquecer a coluna de intercepto em X",
                                    "Não centralizar os dados se necessário",
                                    "Usar dados com multicolinearidade perfeita"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os resíduos e a variância amostral s²",
                                  "subSteps": [
                                    "Calcule os resíduos: e = y - X @ beta_hat.",
                                    "Verifique se os resíduos são aproximadamente normais (histograma ou QQ-plot).",
                                    "Calcule os graus de liberdade: df = n - p, onde n é o número de observações e p o número de parâmetros.",
                                    "Estime s² = (e.T @ e) / df."
                                  ],
                                  "verification": "Confirme que a média dos resíduos é próxima de zero e s² > 0.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "NumPy",
                                    "Matplotlib ou Seaborn para plots"
                                  ],
                                  "tips": "Use np.sum(e**2) / df para s² em vez de var(e, ddof=0) para evitar viés.",
                                  "learningObjective": "Entender o papel dos resíduos na inferência estatística.",
                                  "commonMistakes": [
                                    "Usar df incorreto (n em vez de n-p)",
                                    "Não dividir pelos graus de liberdade",
                                    "Ignorar heterocedasticidade nos resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar a matriz (X'X)^{-1}",
                                  "subSteps": [
                                    "Calcule X_trans_X = X.T @ X.",
                                    "Verifique se X_trans_X é invertível (determinante != 0).",
                                    "Inverta a matriz: XtX_inv = np.linalg.inv(X_trans_X).",
                                    "Confirme que XtX_inv é simétrica e positiva definida."
                                  ],
                                  "verification": "Multiplique XtX_inv @ X_trans_X e verifique se resulta na matriz identidade.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "NumPy"
                                  ],
                                  "tips": "Para estabilidade numérica, use np.linalg.pinv() se houver multicolinearidade.",
                                  "learningObjective": "Compreender a estrutura da matriz de informação de Fisher aproximada.",
                                  "commonMistakes": [
                                    "Invertibilidade falha devido a singularidade",
                                    "Confundir X'X com XX'",
                                    "Ignorar escalas das variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Estimar a matriz de variância-covariância e interpretar",
                                  "subSteps": [
                                    "Multiplique: var_beta = s² * XtX_inv.",
                                    "Extraia variâncias diagonais para erros padrão dos coeficientes.",
                                    "Calcule intervalos de confiança: beta_hat ± 1.96 * sqrt(var_beta diagonal).",
                                    "Interprete no contexto de engenharia, ex: precisão da previsão de tensão."
                                  ],
                                  "verification": "Verifique se var_beta é simétrica positiva definida e variâncias > 0.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "NumPy",
                                    "SciPy para intervalos"
                                  ],
                                  "tips": "Compare com statsmodels para validação: sm.OLS(y, X).fit().cov_params().",
                                  "learningObjective": "Aplicar a fórmula teórica para inferência prática em regressão.",
                                  "commonMistakes": [
                                    "Esquecer o fator s²",
                                    "Usar covariância em vez de variância",
                                    "Interpretar variâncias sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um experimento de fadiga de aço, com dados de ciclos até falha (y) vs. amplitude de tensão (X1) e temperatura (X2). Após OLS, s²=1500, (X'X)^{-1}=diag([0.01, 0.005]), var_beta=diag([15, 7.5]), indicando maior incerteza no coeficiente de temperatura.",
                              "finalVerifications": [
                                "Matriz var_beta é simétrica e positiva semi-definida.",
                                "Variâncias diagonais positivas e coerentes com escala dos dados.",
                                "Intervalos de confiança não incluem zero para coeficientes significativos.",
                                "Reprodutibilidade: recálculo com seed aleatória dá resultados similares.",
                                "Validação cruzada: MSE out-of-sample próximo a s².",
                                "Plots de resíduos sem padrões (randomness confirmado)."
                              ],
                              "assessmentCriteria": [
                                "Correção na implementação da fórmula s²(X'X)^{-1}.",
                                "Tratamento adequado de graus de liberdade e invertibilidade.",
                                "Interpretação precisa das variâncias no contexto de engenharia.",
                                "Código limpo, comentado e reproduzível.",
                                "Análise de resíduos e diagnósticos incluídos.",
                                "Tempo de execução eficiente (<1s para n=100)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência assintótica e teorema do limite central.",
                                "Programação: Álgebra linear numérica com NumPy.",
                                "Engenharia: Modelagem preditiva em mecânica dos materiais.",
                                "Matemática: Teoria de matrizes e otimização quadrática."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, estimar variância dos coeficientes em modelos de regressão para prever vida útil de componentes sob vibração, permitindo dimensionamento seguro com margens de incerteza quantificadas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.1.2.2.2",
                        "name": "Construção de Intervalos de Confiança",
                        "description": "Métodos para construir intervalos de confiança (IC) para os parâmetros do modelo de regressão linear, utilizando a distribuição t de Student para amostras finitas.",
                        "specificSkills": [
                          {
                            "id": "11.1.2.2.2.1",
                            "name": "Formular intervalos de confiança para β individual",
                            "description": "Calcular o IC de (1-α)% para um coeficiente β_j como β̂_j ± t_{n-k-1, α/2} * SE(β̂_j), explicando o papel do erro padrão e do quantil t.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os componentes fundamentais da fórmula do intervalo de confiança",
                                  "subSteps": [
                                    "Revise a estimativa puntual β̂_j obtida da regressão linear.",
                                    "Explique o erro padrão SE(β̂_j) como medida de variabilidade da estimativa.",
                                    "Identifique o quantil t_{n-k-1, α/2} da distribuição t de Student.",
                                    "Defina o nível de confiança (1-α)% e seu significado probabilístico.",
                                    "Escreva a fórmula completa: β̂_j ± t_{n-k-1, α/2} * SE(β̂_j)."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o papel de cada componente na fórmula.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de regressão linear",
                                    "Tabela de distribuição t",
                                    "Calculadora"
                                  ],
                                  "tips": "Visualize SE como o 'desvio padrão' da estimativa β̂_j para entender sua importância.",
                                  "learningObjective": "Compreender conceitualmente cada termo da fórmula do IC para β_j.",
                                  "commonMistakes": [
                                    "Confundir SE com desvio padrão dos resíduos",
                                    "Ignorar os graus de liberdade na escolha de t"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular o erro padrão SE(β̂_j)",
                                  "subSteps": [
                                    "Obtenha a matriz (X'X)^{-1} do modelo de regressão.",
                                    "Calcule a variância dos resíduos σ² a partir dos resíduos e.",
                                    "Extraia SE(β̂_j) = sqrt[ σ² * (X'X)^{-1}_{jj} ].",
                                    "Use software para automatizar se disponível (ex: summary(lm()) no R).",
                                    "Verifique unidades e escala do SE em relação a β̂_j."
                                  ],
                                  "verification": "Compare o SE calculado manualmente com o output de software.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dados de regressão de exemplo",
                                    "Software R ou Python (statsmodels)",
                                    "Planilha Excel para matrizes"
                                  ],
                                  "tips": "Sempre padronize variáveis se as escalas forem muito diferentes para facilitar interpretação.",
                                  "learningObjective": "Dominar o cálculo prático do erro padrão para coeficientes individuais.",
                                  "commonMistakes": [
                                    "Esquecer de multiplicar pela variância σ²",
                                    "Usar a diagonal errada da matriz (X'X)^{-1}"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Determinar o quantil crítico t",
                                  "subSteps": [
                                    "Calcule os graus de liberdade: df = n - k - 1, onde n é o número de observações e k o número de preditores.",
                                    "Escolha α (ex: 0.05 para 95% de confiança), então use α/2 para cauda bilateral.",
                                    "Consulte tabela t ou função qt(p, df) no R para obter t_{df, α/2}.",
                                    "Aproximação: para df grande (>30), use z_{α/2} da normal padrão.",
                                    "Registre o valor exato e justifique a escolha de df."
                                  ],
                                  "verification": "Confirme o quantil com pelo menos duas fontes (tabela e software).",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Tabela de quantis t-Student",
                                    "Calculadora estatística ou R/Python"
                                  ],
                                  "tips": "Para df > 100, t ≈ z para simplificar cálculos iniciais.",
                                  "learningObjective": "Selecionar corretamente o quantil t baseado em df e α.",
                                  "commonMistakes": [
                                    "Usar df = n-1 em vez de n-k-1",
                                    "Confundir α com α/2"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir e interpretar o intervalo de confiança",
                                  "subSteps": [
                                    "Multiplique t * SE(β̂_j) para obter a margem de erro.",
                                    "Some e subtraia a margem de β̂_j para obter limites inferior e superior.",
                                    "Interprete: 'Com (1-α)% de confiança, o verdadeiro β_j está entre [LI, LS]'",
                                    "Discuta implicações: se 0 no IC, β_j não significativo.",
                                    "Teste sensibilidade variando α (ex: 90% vs 99%)."
                                  ],
                                  "verification": "Calcule o IC e explique se β_j=0 é plausível.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resultados dos passos anteriores",
                                    "Papel e lápis para cálculos"
                                  ],
                                  "tips": "Sempre relacione o IC com testes de hipótese para H0: β_j=0.",
                                  "learningObjective": "Aplicar a fórmula para formular o IC e interpretá-lo corretamente.",
                                  "commonMistakes": [
                                    "Inverter os limites do IC",
                                    "Interpretar como probabilidade para β_j específico"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão simples y = β0 + β1 * publicidade + e, com n=30, k=1, β̂1=2.5, SE(β̂1)=0.8, α=0.05. df=28, t_{28,0.025}≈2.05. Margem=2.05*0.8=1.64. IC 95%: [2.5-1.64, 2.5+1.64] = [0.86, 4.14]. Interpretação: Com 95% de confiança, cada unidade extra de publicidade aumenta y em 0.86 a 4.14 unidades.",
                              "finalVerifications": [
                                "Calcula corretamente SE(β̂_j) a partir de dados brutos.",
                                "Seleciona o quantil t apropriado para df e α dados.",
                                "Formula o IC exato usando a fórmula padrão.",
                                "Interpreta o IC sem cair em erros probabilísticos comuns.",
                                "Aplica o IC para inferir significância de β_j.",
                                "Compara ICs para diferentes níveis de confiança."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de SE e quantil t (erro <5%).",
                                "Correta identificação de df = n-k-1.",
                                "Interpretação verbal clara e sem ambiguidades.",
                                "Uso adequado de software para validação.",
                                "Explicação do papel de SE e t na largura do IC.",
                                "Aplicação em exemplo real com interpretação contextual."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Distribuição t-Student e quantis.",
                                "Programação: Implementação em R (confint()) ou Python (statsmodels).",
                                "Análise de Dados: Inferência em machine learning.",
                                "Econometria: ICs em modelos de regressão econômica.",
                                "Estatística Aplicada: Conexão com testes de hipóteses."
                              ],
                              "realWorldApplication": "Em ciência de dados, formulamos ICs para coeficientes em modelos de previsão de vendas (ex: impacto do preço em demanda), permitindo decisões robustas como 'aumentar preço reduz vendas em 1-3% com 95% confiança', guiando estratégias empresariais sem risco excessivo."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.2.2",
                            "name": "Construir IC para intercepto e inclinação",
                            "description": "Aplicar a fórmula de IC em um modelo simples Y = β0 + β1 X + ε, usando software como R para dados empíricos de econometria em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente R e carregar dados empíricos",
                                  "subSteps": [
                                    "Instale e carregue pacotes necessários: stats (base) e possivelmente ggplot2 para visualização.",
                                    "Importe um dataset empírico de econometria em engenharia, como dados de custo de produção (Y) vs investimento em máquinas (X).",
                                    "Explore os dados: summary(), plot(X,Y) para verificar linearidade.",
                                    "Trate outliers ou missing values usando na.omit() ou subset.",
                                    "Defina sementes para reprodutibilidade: set.seed(123)."
                                  ],
                                  "verification": "Execute summary(dataset) e plot() sem erros; dados limpos e visualmente lineares.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "R/RStudio instalado, dataset CSV exemplo (ex: investimento.csv com colunas X e Y)",
                                  "tips": "Use read.csv() com header=TRUE; visualize sempre antes de modelar.",
                                  "learningObjective": "Configurar ambiente computacional para análise de regressão com dados reais.",
                                  "commonMistakes": "Ignorar missing values levando a erros no lm(); não verificar linearidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar o modelo de regressão linear simples",
                                  "subSteps": [
                                    "Defina a fórmula: Y ~ X.",
                                    "Ajuste o modelo: model <- lm(Y ~ X, data = dataset).",
                                    "Inspecione o modelo: summary(model) para ver β0, β1, p-values e R².",
                                    "Verifique premissas básicas: plot(model) para resíduos vs fitted, Q-Q plot.",
                                    "Calcule erros padrão: coef(summary(model))['β1','Std. Error']."
                                  ],
                                  "verification": "summary(model) mostra coeficientes significativos (p < 0.05) e R² > 0.5.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Dataset preparado do Step 1, funções lm() e summary() no R.",
                                  "tips": "Salve o modelo em objeto para reutilização; cheque multicolinearidade se aplicável.",
                                  "learningObjective": "Construir e diagnosticar um modelo Y = β0 + β1 X + ε.",
                                  "commonMistakes": "Não verificar premissas de regressão levando a IC inválidos; confundir Y e X."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir Intervalos de Confiança para intercepto e inclinação",
                                  "subSteps": [
                                    "Use confint(model, level=0.95) para IC automáticos de β0 e β1.",
                                    "Calcule manualmente: IC_β = β ± t_(n-2, 0.975) * SE_β, onde t de qt(0.975, df=n-2).",
                                    "Extraia df = model$df.residual; t_crit = qt(0.975, df).",
                                    "Para β0: se(intercepto) ± t_crit * SE_intercepto.",
                                    "Para β1: beta1 ± t_crit * SE_beta1; armazene em vetor ou data.frame.",
                                    "Compare resultados manual vs confint() para validação."
                                  ],
                                  "verification": "IC de confint() e manual coincidem em 4 casas decimais; não há erros numéricos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Modelo ajustado do Step 2, funções confint(), qt().",
                                  "tips": "Use level=0.95 explicitamente; arredonde para consistência.",
                                  "learningObjective": "Aplicar fórmula t-based para IC em β0 e β1 usando R.",
                                  "commonMistakes": "Usar z em vez de t; erro em df.residual; inverter SE de β0/β1."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar e reportar os Intervalos de Confiança",
                                  "subSteps": [
                                    "Interprete: 'Com 95% confiança, β1 está entre [LI, LS]', implicando relação positiva se LI>0.",
                                    "Verifique significância: se 0 não em IC, parâmetro significativo.",
                                    "Crie tabela: data.frame(coef, confint(model)) com labels.",
                                    "Visualize: plot com bandas de confiança usando predict(model, interval='confidence').",
                                    "Escreva relatório curto: contexto engenharia, conclusões econômicas."
                                  ],
                                  "verification": "Relatório explica IC corretamente; gráfico mostra bandas sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "IC do Step 3, funções predict(), ggplot2 opcional.",
                                  "tips": "Sempre contextualize: ex. 'inclinação indica custo por unidade investimento'.",
                                  "learningObjective": "Traduzir IC estatísticos em insights acionáveis para engenharia.",
                                  "commonMistakes": "Interpretar IC como probabilidade do valor verdadeiro; ignorar direção do IC."
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia civil, use dados de 50 pontes: Y = custo total (milhões R$), X = investimento em materiais (milhões R$). Ajuste lm(custo ~ investimento), obtenha IC_β1 = [1.2, 1.8], significando que cada milhão investido aumenta custo em 1.2-1.8 milhões com 95% confiança.",
                              "finalVerifications": [
                                "IC para β0 e β1 calculados corretamente via confint() e manualmente.",
                                "Interpretação correta: não inclui zero para significância.",
                                "Premissas de regressão verificadas (linearidade, homocedasticidade).",
                                "Resultados reproduzíveis com set.seed().",
                                "Relatório inclui tabela e gráfico de IC.",
                                "Comparação manual vs automático sem discrepâncias."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica dos IC (erro < 0.01).",
                                "Correta aplicação da distribuição t e df.",
                                "Diagnóstico completo de premissas do modelo.",
                                "Interpretação contextualizada para econometria em engenharia.",
                                "Código R limpo, comentado e executável.",
                                "Visualização clara de IC em gráfico."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência paramétrica e testes de hipóteses.",
                                "Programação: Manipulação de dados e funções em R.",
                                "Econometria: Modelos lineares para análise causal.",
                                "Engenharia: Aplicação em otimização de custos e previsão."
                              ],
                              "realWorldApplication": "Em engenharia de projetos, constrói IC para prever faixas confiáveis de custo por unidade de investimento, auxiliando decisões de orçamento e mitigação de riscos econômicos em infraestrutura."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.2.3",
                            "name": "Interpretar intervalos de confiança",
                            "description": "Explicar o significado probabilístico de um IC, como 'com 95% de confiança, o verdadeiro β1 está entre os limites', e discutir cobertura em repetidas amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Definição Fundamental de Intervalo de Confiança",
                                  "subSteps": [
                                    "Defina intervalo de confiança (IC) como um intervalo estimado para conter o parâmetro verdadeiro com certo nível de confiança.",
                                    "Explique que um IC 95% significa que, em repetidas amostras, 95% dos intervalos conterão o verdadeiro parâmetro.",
                                    "Diferencie confiança do parâmetro estar no intervalo (probabilidade condicional).",
                                    "Estude a fórmula básica: estimativa ± (valor crítico * erro padrão).",
                                    "Visualize com um gráfico simples de distribuição normal."
                                  ],
                                  "verification": "Crie um diagrama manual ou digital explicando a definição e compartilhe com um colega para feedback.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta ou software de desenho (ex: Draw.io)",
                                    "Calculadora ou planilha Excel"
                                  ],
                                  "tips": "Use analogias como 'pescar' intervalos que capturam o peixe verdadeiro na maioria das vezes.",
                                  "learningObjective": "Compreender a definição probabilística de IC sem ambiguidades comuns.",
                                  "commonMistakes": [
                                    "Confundir confiança com probabilidade de 95% que o parâmetro está no intervalo específico",
                                    "Ignorar o aspecto de repetidas amostras"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar o Significado Probabilístico para β1 em Regressão Linear",
                                  "subSteps": [
                                    "Identifique β1 como o coeficiente de inclinação em um modelo de regressão simples.",
                                    "Interprete um IC 95% para β1, ex: 'Com 95% de confiança, o verdadeiro β1 está entre limite inferior e superior'.",
                                    "Discuta implicações: se IC inclui zero, β1 pode não ser significativo.",
                                    "Calcule e interprete um IC de exemplo usando dados simulados.",
                                    "Escreva uma frase interpretativa clara para o contexto do modelo."
                                  ],
                                  "verification": "Escreva 3 interpretações corretas para ICs hipotéticos e valide com fórmula ou software.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software R ou Python (com bibliotecas statsmodels ou lmtest)",
                                    "Dataset simples de regressão (ex: mtcars)"
                                  ],
                                  "tips": "Sempre mencione o nível de confiança e o parâmetro específico para clareza.",
                                  "learningObjective": "Aplicar interpretação precisa de IC diretamente a coeficientes de regressão.",
                                  "commonMistakes": [
                                    "Dizer '95% de chance que β1 está no IC' em vez de linguagem de confiança",
                                    "Esquecer de contextualizar com o modelo de regressão"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Cobertura de IC em Repetidas Amostras",
                                  "subSteps": [
                                    "Simule 100 amostras de um modelo de regressão linear verdadeiro.",
                                    "Calcule IC 95% para β1 em cada amostra e plote os intervalos.",
                                    "Conte quantos ICs cobrem o β1 verdadeiro (deve ser ~95%).",
                                    "Analise casos onde o IC falha e discuta variância amostral.",
                                    "Compare cobertura para níveis 90%, 95% e 99%."
                                  ],
                                  "verification": "Gere um gráfico de cobertura e confirme que taxa está próxima de 95%; salve o código e output.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python (numpy, matplotlib, statsmodels) ou R",
                                    "Notebook Jupyter ou R Markdown"
                                  ],
                                  "tips": "Use sementes aleatórias para reprodutibilidade nas simulações.",
                                  "learningObjective": "Demonstrar empiricamente o conceito de cobertura longa-rodagem de ICs.",
                                  "commonMistakes": [
                                    "Interpretar cobertura como probabilidade para uma única amostra",
                                    "Usar amostras muito pequenas, levando a cobertura imprecisa"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar Interpretação Integrada e Discussão de Limitações",
                                  "subSteps": [
                                    "Escolha um dataset real (ex: salários vs. experiência).",
                                    "Ajuste modelo, compute IC para β1 e interprete completamente.",
                                    "Discuta limitações: suposições de normalidade, tamanho amostral.",
                                    "Compare IC com teste de hipótese para β1=0.",
                                    "Redija um relatório curto com interpretação e cobertura simulada."
                                  ],
                                  "verification": "Produza um relatório de 1 página com interpretação, gráfico e simulação; autoavalie com rubrica.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dataset real (ex: de Kaggle)",
                                    "Software estatístico (R/Python)"
                                  ],
                                  "tips": "Integre interpretação com contexto do problema para relevância.",
                                  "learningObjective": "Sintetizar interpretação de IC com simulação e limitações em contexto real.",
                                  "commonMistakes": [
                                    "Ignorar violações de suposições do modelo",
                                    "Sobre-generalizar resultados de uma amostra"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão linear prevendo salário (Y) por anos de experiência (X), obtemos β1 = 2500 com IC 95% [1800, 3200]. Interpretação: 'Estamos 95% confiantes que o verdadeiro aumento médio no salário por ano adicional de experiência está entre $1800 e $3200. Em repetidas amostras, 95% dos ICs assim calculados conterão o verdadeiro β1'. Simulação confirma cobertura ~94-96%.",
                              "finalVerifications": [
                                "Explicar verbalmente o significado de um IC 95% para β1 sem erros comuns.",
                                "Gerar e interpretar corretamente um IC de um modelo ajustado.",
                                "Simular 50+ amostras e plotar cobertura próxima de 95%.",
                                "Discutir quando um IC indica significância prática.",
                                "Identificar e corrigir interpretações erradas em exemplos fornecidos.",
                                "Redigir relatório interpretativo claro e contextualizado."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção entre confiança e probabilidade (90%+ acurácia).",
                                "Correta interpretação contextual de IC para β1 (incluindo implicações).",
                                "Qualidade da simulação: reprodutível, com cobertura adequada e visualizações claras.",
                                "Profundidade na discussão de cobertura e limitações (cobertura de 3+ pontos).",
                                "Clareza e profissionalismo na comunicação escrita/oral.",
                                "Integração de conceitos em exemplos práticos sem ambiguidades."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Distribuições sampling e propriedades assintóticas.",
                                "Programação Computacional: Simulações em Python/R para inferência.",
                                "Estatística Descritiva: Visualizações de intervalos e cobertura.",
                                "Análise de Dados: Aplicação em machine learning e modelagem preditiva.",
                                "Comunicação Científica: Relatórios e visualizações para stakeholders."
                              ],
                              "realWorldApplication": "Em ciência de dados, interpretar ICs de coeficientes em modelos de regressão ajuda decisores em negócios (ex: prever impacto de marketing no vendas), medicina (ex: efeito de um tratamento no risco relativo) e políticas públicas (ex: impacto de educação na renda), evitando conclusões erradas baseadas em estimativas pontuais incertas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.2.4",
                            "name": "IC para combinações lineares de parâmetros",
                            "description": "Construir IC para previsões ou combinações como β1 / β2, utilizando a variância da combinação linear dos estimadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisão de Intervalos de Confiança para Parâmetros Individuais",
                                  "subSteps": [
                                    "Relembre a fórmula padrão do IC para um parâmetro β_j: β̂_j ± t_{α/2, gl} * SE(β̂_j)",
                                    "Entenda a distribuição t de Student para amostras finitas e normal assintótica para grandes amostras",
                                    "Calcule SE(β̂_j) a partir da matriz de covariância dos estimadores",
                                    "Pratique com um exemplo simples de regressão linear univariada",
                                    "Verifique a interpretação probabilística do IC (cobertura de 95%)"
                                  ],
                                  "verification": "Construa manualmente o IC para β_0 e β_1 em um modelo dado e confira com software",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notas de aula sobre regressão linear, calculadora, software R ou Python (pacote statsmodels)",
                                  "tips": "Sempre verifique os graus de liberdade (n - k - 1) para o quantil t",
                                  "learningObjective": "Compreender e aplicar a construção básica de IC para parâmetros isolados",
                                  "commonMistakes": "Confundir distribuição normal com t; ignorar graus de liberdade"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definição e Representação de Combinações Lineares",
                                  "subSteps": [
                                    "Defina uma combinação linear como θ = a₁β₁ + a₂β₂ + ... + a_pβ_p",
                                    "Exemplifique com casos comuns: diferença β₁ - β₂, razão aproximada β₁/β₂ (linearizada)",
                                    "Estime θ̂ = a₁β̂₁ + a₂β̂₂ + ... + a_pβ̂_p",
                                    "Discuta aplicações como testes de hipóteses compostas (H0: β₁ = β₂)",
                                    "Represente em termos da matriz de design X"
                                  ],
                                  "verification": "Escreva θ̂ para β₁/β₂ ≈ (β₁ - r β₂)/(1 + r² Var(β̂₂)/Var(β̂₁)) onde r=β₂/β₁",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Folha de papel para anotações, exemplos de regressão múltipla",
                                  "tips": "Use vetores de coeficientes a = [a1, a2, ..., ap] para generalizar",
                                  "learningObjective": "Identificar e formular combinações lineares relevantes em modelos de regressão",
                                  "commonMistakes": "Não linearizar razões não-lineares como β₁/β₂ diretamente"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Cálculo da Variância da Combinação Linear",
                                  "subSteps": [
                                    "Lembre que Var(θ̂) = a' * Cov(β̂) * a, onde Cov(β̂) é a matriz de covariância",
                                    "Extraia a matriz de covariância de softwares (vcov() no R)",
                                    "Calcule o erro padrão SE(θ̂) = sqrt(Var(θ̂))",
                                    "Para previsões, inclua variância residual: Var(ŷ) = x' Cov(β̂) x + σ²",
                                    "Verifique simetria e propriedades da covariância empírica"
                                  ],
                                  "verification": "Compute Var(β̂₁ - β̂₂) usando matriz de covariância e confirme com fórmula analítica",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Software R/Python com dados de regressão, matriz de covariância impressa",
                                  "tips": "Use funções como vcov(model) no R para automatizar",
                                  "learningObjective": "Derivar e calcular a variância de estimadores lineares combinados",
                                  "commonMistakes": "Esquecer o termo de covariância Cov(β̂_i, β̂_j); usar Var individual somada"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construção do Intervalo de Confiança para θ",
                                  "subSteps": [
                                    "Aplique a fórmula: θ̂ ± t_{α/2, gl} * SE(θ̂)",
                                    "Escolha o nível de confiança (ex: 95%) e graus de liberdade",
                                    "Interprete o IC: com 95% de confiança, θ está no intervalo",
                                    "Compare com IC bootstrap para validação",
                                    "Ajuste para múltiplas comparações se necessário (Bonferroni)"
                                  ],
                                  "verification": "Construa IC para β₁ - β₂ e verifique se contém 0 (não rejeita H0)",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Software estatístico, tabela de quantis t",
                                  "tips": "Para grandes n, use z em vez de t para aproximação normal",
                                  "learningObjective": "Construir IC precisos para qualquer combinação linear de parâmetros",
                                  "commonMistakes": "Usar SE individual em vez de SE da combinação; inverter sinais nos limites"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicação Prática e Verificação",
                                  "subSteps": [
                                    "Carregue um dataset real (ex: mtcars no R)",
                                    "Ajuste modelo lm(mpg ~ hp + wt)",
                                    "Construa IC para β_hp - β_wt",
                                    "Compare com simulação Monte Carlo para cobertura",
                                    "Documente resultados em relatório"
                                  ],
                                  "verification": "O IC gerado cobre o verdadeiro θ em 95% das simulações bootstrap",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dataset exemplo (mtcars), script R/Python",
                                  "tips": "Salve a matriz de covariância para reutilização",
                                  "learningObjective": "Aplicar o método em cenários reais e validar resultados",
                                  "commonMistakes": "Ignorar heterocedasticidade; não escalar variáveis"
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para prever salário (log(salário) ~ anos_exp + educação), construa IC para β_exp - 0.5 β_educ, interpretando o efeito marginal líquido de experiência vs. educação.",
                              "finalVerifications": [
                                "Deriva corretamente Var(a β̂₁ + b β̂₂) usando matriz de covariância",
                                "Constrói IC para θ̂ = β̂₁ / β̂₂ com linearização apropriada",
                                "Interpreta corretamente os limites do IC em contexto",
                                "Valida com software e bootstrap",
                                "Identifica quando o IC contém valores de interesse (ex: 0)",
                                "Ajusta para previsões incluindo variância residual"
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de SE(θ̂) (erro < 5%)",
                                "Correta escolha de distribuição (t vs. normal)",
                                "Interpretação contextual sem erros probabilísticos",
                                "Generalização para p parâmetros",
                                "Validação computacional consistente",
                                "Relatório claro com fórmulas e código"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Propriedades de variância linear e distribuições assintóticas",
                                "Programação: Manipulação de matrizes em R/Python (numpy, pandas)",
                                "Econometria: Testes de hipóteses em modelos econômicos",
                                "Ciências de Dados: Inferência em machine learning (ex: LASSO)",
                                "Estatística Bayesiana: Paralelos com distribuições posteriores"
                              ],
                              "realWorldApplication": "Em marketing, construir IC para diferença de ROIs de duas campanhas (β1 - β2) para decidir alocação de orçamento; em medicina, IC para razão de hazard rates em survival analysis."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.1.2.2.3",
                        "name": "Inferência e Testes de Hipóteses",
                        "description": "Aplicação da inferência estatística para testar hipóteses sobre os parâmetros da regressão linear, integrando distribuição dos estimadores e IC.",
                        "specificSkills": [
                          {
                            "id": "11.1.2.2.3.1",
                            "name": "Realizar teste t para significância de parâmetros",
                            "description": "Executar o teste H0: β_j = 0 vs H1: β_j ≠ 0 usando a estatística t = β̂_j / SE(β̂_j), comparando com distribuição t crítica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Definir as hipóteses nula e alternativa para o parâmetro β_j",
                                  "subSteps": [
                                    "Identifique o parâmetro β_j de interesse no modelo de regressão linear.",
                                    "Estabeleça H0: β_j = 0 (o parâmetro não é significativo).",
                                    "Estabeleça H1: β_j ≠ 0 (o parâmetro é significativo).",
                                    "Especifique o nível de significância α (ex: 0.05).",
                                    "Anote o grau de liberdade df = n - k - 1, onde n é o número de observações e k o número de preditores."
                                  ],
                                  "verification": "Verifique se H0 e H1 estão corretamente escritas e α e df anotados em um relatório ou caderno.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Sumário da regressão (R, Python statsmodels ou Excel)",
                                    "Caderno de anotações"
                                  ],
                                  "tips": "Sempre use H0: β_j = 0 para testes de significância individual em regressão.",
                                  "learningObjective": "Compreender e formular corretamente as hipóteses para teste de significância de coeficientes.",
                                  "commonMistakes": [
                                    "Confundir H1 com β_j > 0 (use bilateral para ≠ 0)",
                                    "Esquecer de especificar α"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Extrair β̂_j e SE(β̂_j) do output da regressão",
                                  "subSteps": [
                                    "Execute o modelo de regressão linear e obtenha o sumário de coeficientes.",
                                    "Localize a linha correspondente ao β_j no output (coeficiente estimado).",
                                    "Registre o valor de β̂_j e seu erro padrão SE(β̂_j).",
                                    "Confirme o número de observações n e preditores k para df.",
                                    "Copie os valores com precisão decimal adequada (ex: 4 casas)."
                                  ],
                                  "verification": "Compare os valores extraídos com o output original; devem coincidir exatamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Software de regressão (R: lm() summary(), Python: statsmodels OLS summary(), Excel Data Analysis)",
                                    "Dados de exemplo"
                                  ],
                                  "tips": "Use summary() em R ou .summary() em Python para output completo.",
                                  "learningObjective": "Localizar e extrair com precisão os componentes necessários do sumário de regressão.",
                                  "commonMistakes": [
                                    "Confundir SE com desvio padrão dos resíduos",
                                    "Pegar o intercepto em vez do preditor desejado"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a estatística de teste t",
                                  "subSteps": [
                                    "Aplique a fórmula t = β̂_j / SE(β̂_j).",
                                    "Realize a divisão com calculadora ou software, mantendo 4 casas decimais.",
                                    "Anote o valor calculado de t.",
                                    "Verifique o sinal de t (deve coincidir com β̂_j).",
                                    "Compare com o t já fornecido no sumário para validação."
                                  ],
                                  "verification": "O t calculado deve igualar o t do sumário da regressão (diferença < 0.001).",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Calculadora ou software (R/Python)",
                                    "Valores extraídos do Step 2"
                                  ],
                                  "tips": "Arredonde SE para evitar erros de divisão; valide com output automático.",
                                  "learningObjective": "Executar o cálculo da estatística t manualmente com precisão.",
                                  "commonMistakes": [
                                    "Inverter numerador e denominador",
                                    "Ignorar sinal negativo"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com distribuição t crítica e decidir",
                                  "subSteps": [
                                    "Consulte tabela t ou função (qt() em R, scipy.stats.t em Python) para valor crítico t_crit com df e α/2 (bilateral).",
                                    "Calcule p-value usando pt(|t|, df, lower.tail=FALSE)*2 em R ou t.cdf em Python.",
                                    "Compare: rejeite H0 se |t| > t_crit ou p-value < α.",
                                    "Interprete: 'β_j é significativo ao nível α'.",
                                    "Registre decisão e p-value no relatório."
                                  ],
                                  "verification": "Simule em software: p-value deve coincidir; decisão lógica.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tabela t crítica ou software (R: qt(1-0.025, df), Python: from scipy.stats import t)",
                                    "Valor t do Step 3"
                                  ],
                                  "tips": "Para bilateral, use 2 * (1 - cdf(|t|)); prefira p-value para precisão.",
                                  "learningObjective": "Avaliar significância usando valores críticos ou p-values corretamente.",
                                  "commonMistakes": [
                                    "Usar distribuição normal Z em vez de t",
                                    "Esquecer multiplicar por 2 no p-value bilateral"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar e reportar o resultado do teste",
                                  "subSteps": [
                                    "Escreva uma conclusão em linguagem natural: 'Há evidência de que β_j ≠ 0 (t = X.XX, p = 0.XXX < 0.05)'.",
                                    "Discuta implicações para o modelo (incluir/excluir variável).",
                                    "Verifique suposições do teste t (normalidade resíduos, etc.).",
                                    "Inclua no relatório completo com output da regressão.",
                                    "Salve o relatório para portfólio."
                                  ],
                                  "verification": "Conclusão clara, correta e contextualizada; peer-review ou auto-checklist.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Relatório template (Word/Google Docs)",
                                    "Output completo da regressão"
                                  ],
                                  "tips": "Sempre relacione com o contexto dos dados (ex: 'experiência afeta salário').",
                                  "learningObjective": "Comunicar resultados estatísticos de forma clara e interpretativa.",
                                  "commonMistakes": [
                                    "Interpretar causalidade de correlação",
                                    "Ignorar magnitude de β̂_j"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (Y) vs. experiência (X1) e educação (X2), n=50, output mostra β̂_X1=2500, SE(β̂_X1)=600. Calcule t=2500/600=4.167. Com df=47, α=0.05, t_crit≈2.01, p-value≈0.0001 <0.05 → rejeite H0, experiência é significativa.",
                              "finalVerifications": [
                                "H0 e H1 definidas corretamente para β_j específico.",
                                "β̂_j e SE extraídos com precisão do sumário.",
                                "Estatística t calculada e igual ao output.",
                                "Decisão baseada em p-value ou t_crit correta.",
                                "Interpretação inclui implicações práticas.",
                                "Relatório completo sem erros aritméticos."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de t (100% pontuação se exato).",
                                "Correta formulação de hipóteses e df (20% da nota).",
                                "Uso apropriado de p-value vs. t_crit (25%).",
                                "Qualidade da interpretação e relatório (30%).",
                                "Validação com software/output original (15%).",
                                "Ausência de erros comuns listados (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Uso de distribuição t e p-values.",
                                "Programação: Implementação em R/Python para automação.",
                                "Econometria/Economia: Testes em modelos de previsão econômica.",
                                "Ciência de Dados: Inferência em machine learning regressão.",
                                "Estatística Descritiva: Conexão com intervalos de confiança."
                              ],
                              "realWorldApplication": "Em análise de dados para RH, testar se 'anos de experiência' impacta salário significativamente em modelos de regressão, auxiliando decisões de promoção e equidade salarial em empresas como Google ou bancos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.3.2",
                            "name": "Interpretar p-valores em regressão",
                            "description": "Analisar p-valores de coeficientes em saída de regressão OLS, decidindo rejeitar ou não H0 com nível de significância α=0.05 em contexto de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais: Hipótese Nula (H0) e p-valor",
                                  "subSteps": [
                                    "Defina H0 para coeficientes em regressão OLS: β_j = 0 (o preditor não tem efeito significativo).",
                                    "Explique o p-valor como a probabilidade de observar o coeficiente (ou mais extremo) assumindo H0 verdadeira.",
                                    "Entenda o nível de significância α=0.05: rejeite H0 se p < 0.05.",
                                    "Discuta o que significa rejeitar ou não rejeitar H0 em termos de evidência estatística.",
                                    "Diferencie p-valor de probabilidade de H0 ser verdadeira."
                                  ],
                                  "verification": "Resuma em suas palavras H0, p-valor e regra de decisão α=0.05, com um exemplo simples.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de estatística inferencial",
                                    "Vídeo tutorial sobre p-valores (Khan Academy ou similar)"
                                  ],
                                  "tips": "Lembre-se: p-valor baixo não prova causalidade, apenas associação estatística.",
                                  "learningObjective": "Compreender o significado estatístico de p-valores em testes de coeficientes de regressão.",
                                  "commonMistakes": [
                                    "Confundir p-valor com P(H0|dados)",
                                    "Ignorar que α é uma taxa de erro tipo I",
                                    "Pensar que p>0.05 prova H0"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Localizar e Ler a Saída de Regressão OLS",
                                  "subSteps": [
                                    "Execute uma regressão OLS simples usando Python (statsmodels) ou R (lm()).",
                                    "Identifique seções na saída: coeficientes, std err, t-value, P>|t| (p-valor).",
                                    "Anote p-valores para intercepto e cada preditor.",
                                    "Verifique suposições básicas da regressão (linearidade, independência) brevemente.",
                                    "Copie a tabela de summary para análise."
                                  ],
                                  "verification": "Extraia e liste corretamente todos os p-valores da saída de uma regressão exemplo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python/R com statsmodels/lm",
                                    "Dataset exemplo: resistência de material vs temperatura/pressão"
                                  ],
                                  "tips": "Use summary() em R ou .summary() em statsmodels para saída padronizada.",
                                  "learningObjective": "Habilidade para extrair p-valores de saídas padrão de software estatístico.",
                                  "commonMistakes": [
                                    "Confundir p-valor com t-value",
                                    "Ignorar estrelas de significância (*, **, ***)",
                                    "Ler colunas erradas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar p-valores e Decidir sobre H0",
                                  "subSteps": [
                                    "Para cada coeficiente, compare p-valor com α=0.05.",
                                    "Classifique: significativo (p<0.05, rejeite H0) ou não significativo (p≥0.05, falhe em rejeitar H0).",
                                    "Calcule intervalo de confiança (95%) para confirmar (não inclui 0 se significativo).",
                                    "Reporte: 'O preditor X é estatisticamente significativo ao nível de 5%'.",
                                    "Considere magnitude do coeficiente junto com significância."
                                  ],
                                  "verification": "Para uma saída dada, liste preditores significativos e justifique decisões.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Saída de regressão impressa",
                                    "Calculadora para IC manual se necessário"
                                  ],
                                  "tips": "Sempre reporte p-valor exato, não só 'significativo'.",
                                  "learningObjective": "Aplicar teste de significância corretamente para múltiplos coeficientes.",
                                  "commonMistakes": [
                                    "Rejeitar H0 baseado só em magnitude, ignorando p",
                                    "Aplicar α diferente de 0.05 sem justificativa",
                                    "Interpretar falha em rejeitar como 'sem efeito'"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Contextualizar Interpretação em Engenharia",
                                  "subSteps": [
                                    "Relacione significância com pergunta de pesquisa: 'Temperatura afeta resistência?'",
                                    "Discuta limitações: tamanho amostral, multicolinearidade, poder estatístico.",
                                    "Considere correção múltipla se >5 preditores (ex: Bonferroni).",
                                    "Escreva conclusão prática: implicações para design engenheiro.",
                                    "Valide com gráfico de resíduos ou R²."
                                  ],
                                  "verification": "Escreva parágrafo de interpretação contextual para um modelo exemplo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Contexto do dataset engenheiro",
                                    "Gráficos de regressão (matplotlib/ggplot)"
                                  ],
                                  "tips": "Sempre volte à pergunta de pesquisa; estatística serve ao contexto.",
                                  "learningObjective": "Integrar inferência estatística com aplicações práticas em engenharia.",
                                  "commonMistakes": [
                                    "Overinterpretação de significância como causalidade",
                                    "Ignorar viés de seleção de modelo",
                                    "Generalizar sem considerar domínio"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um experimento de engenharia mecânica, regressão OLS prevê resistência à tração (Y) de um aço baseado em temperatura (X1) e pressão (X2): saída mostra p=0.03 para X1 e p=0.12 para X2. Conclusão: temperatura é significativa (rejeite H0), pressão não é; otimize processo focando temperatura.",
                              "finalVerifications": [
                                "Explicar H0 para um coeficiente específico.",
                                "Identificar corretamente p-valores <0.05 em uma saída real.",
                                "Justificar rejeição/não rejeição de H0 com α=0.05.",
                                "Interpretar implicações em contexto engenheiro.",
                                "Reconhecer limitações como poder baixo.",
                                "Calcular/interpretar IC 95% para coeficiente."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e comparação de p-valores (100% correto).",
                                "Correta decisão sobre H0 com justificativa estatística.",
                                "Interpretação contextual relevante para engenharia.",
                                "Identificação de pelo menos 2 limitações potenciais.",
                                "Clareza na comunicação escrita da conclusão.",
                                "Uso apropriado de termos técnicos sem jargão excessivo."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Implementação em Python/R (statsmodels, lm).",
                                "Engenharia Mecânica: Análise de dados experimentais de materiais.",
                                "Machine Learning: Seleção de features baseada em significância.",
                                "Probabilidade: Distribuição t-student para testes.",
                                "Design Experimental: Planejamento para alto poder estatístico."
                              ],
                              "realWorldApplication": "Em engenharia, interpretar p-valores valida modelos preditivos para otimizar designs de materiais (ex: prever falhas em pontes sob carga/temperatura), reduzindo custos de protótipos e melhorando segurança via análise estatística robusta de dados de testes."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.2.2.3.3",
                            "name": "Relacionar IC com testes de hipótese",
                            "description": "Demonstrar que se 0 não está no IC de 95%, rejeita-se H0: β=0 ao nível 5%, unificando conceitos de inferência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de IC e Testes de Hipótese",
                                  "subSteps": [
                                    "Defina Intervalo de Confiança (IC) de 95% para um coeficiente β em regressão linear: IC = β̂ ± t*(SE(β̂)), onde t é o valor crítico da t-Student para α=0.05.",
                                    "Explique o teste de hipótese H0: β=0 vs H1: β≠0, usando estatística t = β̂ / SE(β̂) e p-value.",
                                    "Discuta o nível de significância α=5% e como ele se relaciona com o IC de 95% (1-α).",
                                    "Identifique pressupostos comuns: normalidade dos resíduos, homocedasticidade e independência."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula do IC e do teste t, e relacione α com o IC.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão linear",
                                    "Calculadora ou software como R/Python",
                                    "Tabela de valores t-Student"
                                  ],
                                  "tips": "Lembre-se: IC de 95% corresponde a α=0.05 em testes bilaterais.",
                                  "learningObjective": "Compreender as bases matemáticas e interpretativas de IC e testes de hipótese para β.",
                                  "commonMistakes": [
                                    "Confundir IC com predição de valores individuais",
                                    "Ignorar que p-value <0.05 é equivalente a 0 fora do IC"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir e Interpretar IC para Coeficiente β",
                                  "subSteps": [
                                    "Obtenha saídas de regressão (β̂, SE(β̂), df) de um modelo linear simples.",
                                    "Calcule manualmente o IC de 95%: encontre t_crítico para df e α/2=0.025.",
                                    "Verifique se 0 está dentro ou fora do IC e interprete: 'Se 0 não está no IC, β é significativo ao 5%'.",
                                    "Compare com p-value da saída do software."
                                  ],
                                  "verification": "Calcule o IC para um exemplo dado e confirme se coincide com software; interprete corretamente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Dados de exemplo (e.g., mtcars em R)",
                                    "Software R ou Python (statsmodels/sklearn)",
                                    "Planilha Excel para cálculos manuais"
                                  ],
                                  "tips": "Use funções prontas como confint() em R para validar cálculos manuais.",
                                  "learningObjective": "Dominar cálculo e interpretação de IC para inferência sobre β.",
                                  "commonMistakes": [
                                    "Usar Z em vez de t para amostras pequenas",
                                    "Invertar limites do IC (limite inferior > superior)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar Teste de Hipótese e Relacionar com IC",
                                  "subSteps": [
                                    "Formule H0: β=0 e calcule t = β̂ / SE(β̂).",
                                    "Encontre p-value ou compare t com t_crítico.",
                                    "Demonstre logicamente: rejeitar H0 se |t| > t_crítico, o que é equivalente a 0 fora do IC.",
                                    "Prove a equivalência: IC exclui 0 iff p-value < α."
                                  ],
                                  "verification": "Para um conjunto de saídas, mostre que '0 no IC' ⇔ 'não rejeita H0' em pelo menos 3 casos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Saídas de regressão de exemplos variados",
                                    "Tabela t-Student ou função pt() em R",
                                    "Papel e caneta para derivação"
                                  ],
                                  "tips": "Desenhe o gráfico da distribuição t para visualizar a relação.",
                                  "learningObjective": "Estabelecer a unificação conceitual entre IC e testes de hipótese.",
                                  "commonMistakes": [
                                    "Confundir teste unilateral com bilateral",
                                    "Interpretar p-value como probabilidade de H0 ser verdadeira"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a Relação em Exemplo Prático de Regressão",
                                  "subSteps": [
                                    "Carregue dados reais (e.g., salário vs experiência).",
                                    "Ajuste modelo lm(salario ~ experiencia) e extraia IC e p-value para β_experiencia.",
                                    "Conclua: se IC não inclui 0 e p<0.05, rejeite H0.",
                                    "Discuta implicações: experiência afeta salário significativamente."
                                  ],
                                  "verification": "Gere relatório com IC, p-value e conclusão coerente sobre rejeição de H0.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Dataset CSV de salário/experiência",
                                    "Jupyter Notebook ou RStudio",
                                    "Bibliotecas: pandas/statsmodels ou lm()"
                                  ],
                                  "tips": "Sempre cheque resíduos para validar pressupostos antes de inferir.",
                                  "learningObjective": "Aplicar a relação IC-teste em contexto real de regressão linear.",
                                  "commonMistakes": [
                                    "Não verificar pressupostos do modelo",
                                    "Generalizar resultados sem considerar tamanho da amostra"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Generalizar e Verificar Compreensão",
                                  "subSteps": [
                                    "Estenda para IC de outros níveis (e.g., 99% ~ α=1%).",
                                    "Discuta limitações: IC não prova causalidade.",
                                    "Crie fluxograma: 'Calcule IC → 0 dentro? → Não rejeita H0'.",
                                    "Resolva exercício inverso: dado p-value, infira sobre IC."
                                  ],
                                  "verification": "Crie e explique fluxograma; resolva 2 exercícios corretamente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Papel para fluxograma",
                                    "Exercícios impressos ou online",
                                    "Software para validação"
                                  ],
                                  "tips": "Unifique: 'IC é uma família de testes de hipótese para vários valores de β'.",
                                  "learningObjective": "Generalizar a equivalência para inferência robusta em regressão.",
                                  "commonMistakes": [
                                    "Achar que IC=95% significa '95% de chance de β verdadeiro'",
                                    "Ignorar múltiplos testes e ajuste de α"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão Salary ~ YearsExperience, obtemos β̂=2000, SE=500, t=4, p=0.001, IC95%=[1200, 2800]. Como 0 não está no IC e p<0.05, rejeitamos H0: β=0 ao 5%, concluindo que cada ano extra aumenta salário em $2000 em média.",
                              "finalVerifications": [
                                "Calcule IC95% manualmente e verifique com software.",
                                "Interprete corretamente se 0 no IC implica rejeição de H0.",
                                "Explique equivalência: p<α iff 0 fora do IC (1-α).",
                                "Aplique em novo dataset e conclua sobre significância de β.",
                                "Crie fluxograma relacionando IC e teste t.",
                                "Discuta limitação: IC não implica causalidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de IC e t-statistic (erro <1%).",
                                "Compreensão conceitual: explica equivalência sem erros lógicos.",
                                "Aplicação prática: interpreta corretamente em exemplos reais.",
                                "Generalização: estende para outros níveis de confiança.",
                                "Clareza na comunicação: fluxograma ou relatório bem estruturado."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: uso de distribuições t-Student e valores críticos.",
                                "Álgebra Linear: matrizes de regressão e variância de β̂.",
                                "Programação Computacional: implementação em R/Python para automação.",
                                "Análise de Dados: feature selection via significância em ML.",
                                "Econometria: inferência em modelos econômicos."
                              ],
                              "realWorldApplication": "Em ciência de dados, relacionar IC e testes permite selecionar variáveis significativas em modelos preditivos para negócios (e.g., prever vendas por marketing), saúde (efeito de tratamento) ou finanças (risco de investimentos), unificando inferência para decisões baseadas em evidências sem redundância computacional."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.3",
                    "name": "Testes de Hipótese para Coeficientes Individuais",
                    "description": "Teste t-Student para significância estatística de parâmetros regressores.",
                    "individualConcepts": [
                      {
                        "id": "11.2.3.1",
                        "name": "Formulação das Hipóteses para Coeficientes Individuais",
                        "description": "Definição das hipóteses nula e alternativa para testar a significância estatística de um coeficiente regressor específico em um modelo de regressão linear estimado por Mínimos Quadrados Ordinários (MQO), no contexto de econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "11.2.3.1.1",
                            "name": "Definir Hipótese Nula e Alternativa",
                            "description": "Formular corretamente a hipótese nula H₀: βⱼ = 0 (o regressor j não afeta a variável dependente) e a alternativa bilateral H₁: βⱼ ≠ 0, ou unilaterais conforme o contexto, para análise de significância em modelos de regressão linear.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Contexto do Modelo de Regressão Linear e os Coeficientes βⱼ",
                                  "subSteps": [
                                    "Relembrar a equação do modelo: Y_i = β₀ + β₁X_{i1} + ... + βⱼX_{ij} + ε_i",
                                    "Identificar βⱼ como o coeficiente de inclinação para o regressor Xⱼ, representando a mudança em Y por unidade de Xⱼ",
                                    "Explicar a hipótese de significância: testar se βⱼ é diferente de zero",
                                    "Diferenciar testes bilaterais (efeito em qualquer direção) de unilaterais (direção específica)",
                                    "Analisar um exemplo simples com dados fictícios"
                                  ],
                                  "verification": "Resuma por escrito o papel de βⱼ e justifique por que testamos se ele é zero",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Folha com equação de regressão",
                                    "Dataset exemplo em Excel ou CSV",
                                    "Calculadora ou software como R/Python"
                                  ],
                                  "tips": "Sempre relacione βⱼ ao contexto prático do problema para fixar o conceito",
                                  "learningObjective": "Entender o significado estatístico e interpretativo dos coeficientes em regressão linear",
                                  "commonMistakes": [
                                    "Confundir βⱼ com a média de Y",
                                    "Ignorar que βⱼ assume ceteris paribus",
                                    "Esquecer o papel do erro ε"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a Hipótese Nula H₀",
                                  "subSteps": [
                                    "Definir H₀ explicitamente como βⱼ = 0",
                                    "Interpretar H₀: 'o regressor Xⱼ não tem efeito linear significativo sobre Y'",
                                    "Escrever a notação matemática usando subscrito j: H₀: βⱼ = 0",
                                    "Confirmar que H₀ é sempre a ausência de efeito para testes de significância individual",
                                    "Praticar com um modelo específico, substituindo j pelo regressor real"
                                  ],
                                  "verification": "Escreva H₀ para um modelo dado e explique sua interpretação verbalmente",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Modelo de regressão exemplo impresso",
                                    "Caneta e papel para anotações"
                                  ],
                                  "tips": "Use sempre a notação exata com subscrito para evitar ambiguidades",
                                  "learningObjective": "Dominar a formulação padrão e interpretação da hipótese nula",
                                  "commonMistakes": [
                                    "Escrever H₀ como βⱼ ≠ 0",
                                    "Confundir com teste de intercepto β₀",
                                    "Omitir o subscrito j"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Formular a Hipótese Alternativa H₁",
                                  "subSteps": [
                                    "Para teste bilateral: definir H₁: βⱼ ≠ 0 (efeito em qualquer direção)",
                                    "Para unilateral direita: H₁: βⱼ > 0 (efeito positivo esperado)",
                                    "Para unilateral esquerda: H₁: βⱼ < 0 (efeito negativo esperado)",
                                    "Escolher o tipo baseado no contexto teórico ou pesquisa",
                                    "Escrever pares H₀/H₁ completos para um exemplo dado"
                                  ],
                                  "verification": "Formule H₀ e H₁ para dois cenários: um bilateral e um unilateral",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Lista de contextos de pesquisa",
                                    "Software de regressão como R (lm()) para visualização"
                                  ],
                                  "tips": "Pergunte: 'Existe teoria prévia para direção do efeito?' para decidir unilateral",
                                  "learningObjective": "Selecionar e formular corretamente H₁ de acordo com o contexto",
                                  "commonMistakes": [
                                    "Usar bilateral quando teoria sugere direção",
                                    "Escrever H₁ como βⱼ = 0",
                                    "Inverter símbolos de desigualdade"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e Praticar a Formulação Completa das Hipóteses",
                                  "subSteps": [
                                    "Combinar H₀ e H₁ em um par coeso para um modelo completo",
                                    "Verificar consistência: H₀ sempre igualdade, H₁ desigualdade",
                                    "Aplicar em um dataset real: identificar j e formular",
                                    "Discutir implicações para o p-valor no teste t",
                                    "Autoavaliar com checklist: notação, interpretação, adequação ao contexto"
                                  ],
                                  "verification": "Crie um par de hipóteses para um problema novo e peer-review com colega",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dataset real (ex: mtcars em R)",
                                    "Checklist de verificação impressa"
                                  ],
                                  "tips": "Sempre valide com a pergunta de pesquisa original",
                                  "learningObjective": "Integrar formulação de hipóteses em um fluxo de teste de significância",
                                  "commonMistakes": [
                                    "Incluir múltiplos coeficientes em um teste individual",
                                    "Esquecer contexto do modelo múltiplo",
                                    "Confundir com testes F globais"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para prever salário (Y) baseado em anos de experiência (Xⱼ), formule: H₀: β_experiência = 0 (experiência não afeta salário); H₁: β_experiência > 0 (experiência aumenta salário, unilateral direita baseada em teoria econômica).",
                              "finalVerifications": [
                                "H₀ está corretamente escrita como βⱼ = 0 com subscrito",
                                "H₁ usa desigualdade apropriada (≠, > ou <) conforme contexto",
                                "Interpretação verbal de H₀ e H₁ está precisa e contextualizada",
                                "Tipo de teste (bilateral/unilateral) justificado teoricamente",
                                "Notação matemática consistente e sem erros tipográficos",
                                "Par H₀/H₁ alinhado com um modelo de regressão específico"
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação matemática (100% correto ganha nota máxima)",
                                "Correta distinção entre bilateral e unilateral (baseado em contexto)",
                                "Interpretação conceitual clara e sem ambiguidades",
                                "Adequação ao contexto do problema (relevância prática)",
                                "Ausência de erros comuns como inversão de hipóteses",
                                "Capacidade de aplicar em exemplo novo independentemente"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Integra com testes t e distribuição t-Student",
                                "Programação Computacional: Implementação em R (summary(lm())) ou Python (statsmodels)",
                                "Econometria: Aplicação em modelos de demanda e oferta",
                                "Ciência de Dados: Pré-teste para feature selection em ML",
                                "Pesquisa Científica: Formulação padrão em papers acadêmicos"
                              ],
                              "realWorldApplication": "Em análises de marketing, testar se gasto em anúncios (Xⱼ) impacta vendas (Y): H₀: β_anúncios = 0 guia decisões de orçamento; em saúde pública, verificar se dose de medicamento afeta recuperação de pacientes."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.2.3.1.2",
                            "name": "Interpretar Significado Econômico/Engenharia das Hipóteses",
                            "description": "Explicar o impacto prático de rejeitar H₀ em aplicações de engenharia, como determinar se uma variável explicativa (ex.: temperatura em processo industrial) influencia significativamente a resposta (ex.: eficiência energética).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Formulação das Hipóteses e Decisão de Rejeição",
                                  "subSteps": [
                                    "Identifique H₀ para um coeficiente específico (ex.: β_j = 0, significando que a variável explicativa não afeta a resposta).",
                                    "Explique H₁ (β_j ≠ 0) e o papel do teste t ou equivalente.",
                                    "Discuta o p-valor: se p < α (ex.: 0.05), rejeite H₀.",
                                    "Pratique com um dataset simples de regressão linear.",
                                    "Registre a interpretação estatística da rejeição."
                                  ],
                                  "verification": "Confirme se o aluno corretamente identifica H₀/H₁ e calcula/decide rejeição com p-valor em um exemplo dado.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Planilha Excel ou Python (statsmodels/pandas), dataset de exemplo com regressão.",
                                  "tips": "Sempre relacione H₀ com 'nenhum efeito' para clareza.",
                                  "learningObjective": "Compreender a base estatística para rejeitar H₀ em coeficientes individuais.",
                                  "commonMistakes": "Confundir rejeição de H₀ com causalidade comprovada."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Contextualizar Hipóteses em Aplicações de Engenharia",
                                  "subSteps": [
                                    "Escolha um processo industrial (ex.: temperatura afetando eficiência energética).",
                                    "Mapeie a variável explicativa (temperatura) como X_j e resposta (eficiência) como Y.",
                                    "Formule H₀ no contexto: 'temperatura não influencia eficiência'.",
                                    "Colete ou simule dados reais de um processo.",
                                    "Execute regressão e rejeite H₀ se aplicável."
                                  ],
                                  "verification": "O aluno descreve o contexto de engenharia corretamente e liga à hipótese.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Software R ou Python (scikit-learn), dados simulados de processo industrial.",
                                  "tips": "Use unidades reais (ex.: °C, kWh) para tornar concreto.",
                                  "learningObjective": "Aplicar hipóteses estatísticas a cenários de engenharia práticos.",
                                  "commonMistakes": "Ignorar multicolinearidade ou outros vieses no modelo."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar Impacto Prático e Econômico da Rejeição",
                                  "subSteps": [
                                    "Calcule o tamanho do efeito: magnitude de β_j e intervalo de confiança.",
                                    "Traduza para impacto: 'aumento de 1°C melhora eficiência em X%'.",
                                    "Estime custos/benefícios: redução de energia = economia anual de $Y.",
                                    "Compare com benchmarks industriais.",
                                    "Documente em relatório com gráficos de efeito."
                                  ],
                                  "verification": "Relatório mostra quantificação econômica clara da rejeição de H₀.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Calculadora financeira, gráficos em Matplotlib/ggplot, relatórios industriais.",
                                  "tips": "Use ROI (Return on Investment) para quantificar impacto econômico.",
                                  "learningObjective": "Traduzir significância estatística em decisões de engenharia acionáveis.",
                                  "commonMistakes": "Focar só em p-valor, ignorando tamanho do efeito."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar Interpretação com Análise de Sensibilidade",
                                  "subSteps": [
                                    "Teste robustez: varie α ou use bootstrap para IC de β_j.",
                                    "Avalie cenários: o que se H₀ não rejeitada?",
                                    "Integre com otimização: ajuste processo baseado em β_j.",
                                    "Crie visualizações de impacto (ex.: gráfico de eficiência vs. temperatura).",
                                    "Resuma lições para decisões futuras."
                                  ],
                                  "verification": "Análise de sensibilidade confirma interpretação estável.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python (seaborn para plots), ferramentas de otimização como PuLP.",
                                  "tips": "Sempre pergunte: 'Isso muda a prática industrial?'",
                                  "learningObjective": "Garantir interpretações robustas para aplicações reais.",
                                  "commonMistakes": "Superestimar impacto sem considerar variância."
                                }
                              ],
                              "practicalExample": "Em uma fábrica de cimento, teste se temperatura do forno (X) afeta eficiência energética (Y, kWh/tonelada). H₀: β_temp = 0. Rejeição (p=0.03) indica que cada 10°C reduz consumo em 5%, economizando $50k/ano.",
                              "finalVerifications": [
                                "Explica corretamente impacto de rejeitar H₀ em termos de influência da variável.",
                                "Quantifica tamanho do efeito com IC 95%.",
                                "Liga rejeição a decisão prática de engenharia.",
                                "Identifica quando não rejeitar H₀ muda nada.",
                                "Usa exemplo realista com números econômicos.",
                                "Evita confundir significância com importância prática."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação e interpretação de H₀/H₁ (30%).",
                                "Quantificação correta de impacto prático/econômico (25%).",
                                "Uso de evidências estatísticas (p-valor, β, IC) (20%).",
                                "Clareza na ligação engenharia-mundo real (15%).",
                                "Análise de limitações e robustez (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Processos: Otimização de variáveis industriais.",
                                "Economia Empresarial: Análise custo-benefício e ROI.",
                                "Gestão de Projetos: Tomada de decisão baseada em dados.",
                                "Física Aplicada: Relações termodinâmicas em eficiência energética."
                              ],
                              "realWorldApplication": "Engenheiros químicos usam isso para otimizar fornos industriais, reduzindo custos energéticos em 10-20% em plantas como siderúrgicas ou petroquímicas, impactando bilhões em eficiência global."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.2.3.2",
                        "name": "Cálculo da Estatística de Teste t-Student",
                        "description": "Derivação e computação da estatística t para avaliar a significância de parâmetros individuais sob os pressupostos clássicos da regressão linear (linearidade, exogeneidade, homocedasticidade, normalidade dos erros).",
                        "specificSkills": [
                          {
                            "id": "11.2.3.2.1",
                            "name": "Calcular a Estatística t",
                            "description": "Aplicar a fórmula t = (β̂ⱼ - βⱼ⁰) / SE(β̂ⱼ), onde βⱼ⁰=0 sob H₀, utilizando saídas de software como R ou equações manuais para dados de regressão em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a fórmula da estatística t e a hipótese nula",
                                  "subSteps": [
                                    "Revise a fórmula t = (β̂ⱼ - βⱼ⁰) / SE(β̂ⱼ), onde βⱼ⁰ = 0 sob H₀: βⱼ = 0.",
                                    "Identifique os componentes: β̂ⱼ (estimativa do coeficiente), SE(β̂ⱼ) (erro padrão).",
                                    "Explique verbalmente o significado: mede quão distante β̂ⱼ está de 0 em unidades de erro padrão.",
                                    "Anote exemplos de contextos em regressão linear simples e múltipla.",
                                    "Compare com teste z para grandes amostras."
                                  ],
                                  "verification": "Escreva a fórmula completa e defina H₀ em suas próprias palavras, sem erros.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Folha de papel ou editor de texto",
                                    "Documentação de regressão linear (ex: notas de aula)"
                                  ],
                                  "tips": "Lembre-se: H₀ sempre assume βⱼ = 0 para testar relevância da variável.",
                                  "learningObjective": "Dominar os componentes teóricos da estatística t para testes de coeficientes.",
                                  "commonMistakes": [
                                    "Confundir β̂ⱼ com SE",
                                    "Esquecer que βⱼ⁰ = 0 sob H₀",
                                    "Ignorar distribuição t-Student"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar dados e executar regressão para obter β̂ⱼ e SE(β̂ⱼ)",
                                  "subSteps": [
                                    "Carregue um dataset de regressão em engenharia (ex: dados de tensão vs. strain).",
                                    "Execute regressão linear no R: lm(y ~ x, data=dataset) ou manualmente para pequenos dados.",
                                    "Extraia summary() para identificar β̂ⱼ e SE(β̂ⱼ) da saída (colunas Estimate e Std. Error).",
                                    "Registre graus de liberdade (n - k - 1) para distribuição t.",
                                    "Valide os dados: verifique ausência de missing values e multicolinearidade básica."
                                  ],
                                  "verification": "Mostre a saída do summary() com β̂ⱼ e SE(β̂ⱼ) destacados corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "R ou RStudio instalado",
                                    "Dataset exemplo (ex: mtcars ou custom de engenharia)"
                                  ],
                                  "tips": "Use summary(modelo) imediatamente após lm() para ver todas as estatísticas.",
                                  "learningObjective": "Extrair com precisão os valores necessários de saídas de software de regressão.",
                                  "commonMistakes": [
                                    "Selecionar a linha errada no summary()",
                                    "Confundir intercepto com coeficiente",
                                    "Não ajustar por variáveis múltiplas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a estatística t manualmente",
                                  "subSteps": [
                                    "Substitua valores: t = (β̂ⱼ - 0) / SE(β̂ⱼ) = β̂ⱼ / SE(β̂ⱼ).",
                                    "Realize o cálculo aritmético passo a passo (ex: 0.5 / 0.1 = 5).",
                                    "Compare o t calculado com o fornecido no summary() para validação.",
                                    "Calcule para múltiplos coeficientes se regressão múltipla.",
                                    "Registre o valor exato com 3 casas decimais."
                                  ],
                                  "verification": "O t calculado manualmente coincide com o do software (tolerância ±0.001).",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Calculadora ou R para verificação",
                                    "Saída do summary() do step anterior"
                                  ],
                                  "tips": "Sempre divida por SE, não multiplique; sinal de t segue sinal de β̂ⱼ.",
                                  "learningObjective": "Aplicar a fórmula corretamente para obter t a partir de valores extraídos.",
                                  "commonMistakes": [
                                    "Subtrair errado (esquecer βⱼ⁰=0)",
                                    "Inverter numerador/denominador",
                                    "Arredondar prematuramente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e interpretar o resultado da estatística t",
                                  "subSteps": [
                                    "Compare |t| com valor crítico t de tabelas (ex: t_{0.025, df=20} ≈ 2.086).",
                                    "Calcule p-valor aproximado ou use pt() no R para confirmação.",
                                    "Interprete: se |t| > crítico ou p < α, rejeite H₀ (coeficiente significativo).",
                                    "Documente conclusão em contexto de engenharia (ex: 'variável afeta resposta').",
                                    "Teste sensibilidade alterando dados ligeiramente."
                                  ],
                                  "verification": "Forneça interpretação correta: rejeitar/aceitar H₀ com justificativa numérica.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Tabela de distribuição t",
                                    "Função pt() no R"
                                  ],
                                  "tips": "Use 95% confiança (α=0.05) como padrão; verifique df correto.",
                                  "learningObjective": "Validar e contextualizar o cálculo t em testes de hipótese.",
                                  "commonMistakes": [
                                    "Ignorar sinal de t",
                                    "Usar df errado",
                                    "Confundir t com p-valor diretamente"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um estudo de engenharia mecânica, modele a deformação (y) em função da carga aplicada (x1) e temperatura (x2) com dados: n=30 observações. No R: modelo <- lm(deformacao ~ carga + temp, data=eng_data); summary(modelo) dá β̂_carga = 0.02, SE=0.005. Calcule t_carga = 0.02 / 0.005 = 4.0. Com df=27, |t|=4.0 > 2.052 (α=0.05), rejeite H₀: carga afeta deformação significativamente.",
                              "finalVerifications": [
                                "Calcula t corretamente para 3 coeficientes diferentes.",
                                "Extrai β̂ⱼ e SE de summary() sem erros.",
                                "Interpreta corretamente rejeição/aceitação de H₀.",
                                "Valida manual vs. software com precisão.",
                                "Aplica em dataset próprio de engenharia.",
                                "Explica fórmula e componentes verbalmente."
                              ],
                              "assessmentCriteria": [
                                "Precisão aritmética no cálculo de t (100% match com software).",
                                "Correta extração de valores de saídas de R.",
                                "Interpretação coerente com níveis de significância.",
                                "Uso adequado de df e distribuição t-Student.",
                                "Documentação clara de passos e conclusões.",
                                "Aplicação contextual em cenários de engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: distribuição t-Student e p-valores.",
                                "Programação Computacional: manipulação de dados em R.",
                                "Engenharia: modelagem preditiva em regressão.",
                                "Métodos Numéricos: cálculo de erros padrão.",
                                "Análise de Dados: validação de modelos lineares."
                              ],
                              "realWorldApplication": "Na engenharia, engenheiros usam a estatística t para testar se fatores como pressão ou material influenciam significativamente o desempenho de estruturas (ex: em simulações de fadiga), otimizando designs e reduzindo custos em indústrias aeroespacial e automotiva."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.3.1.1"
                            ]
                          },
                          {
                            "id": "11.2.3.2.2",
                            "name": "Determinar o Erro Padrão do Estimador",
                            "description": "Calcular SE(β̂ⱼ) = √[σ̂² × (X'X)^{-1}_{jj}], estimando σ̂² a partir dos resíduos do MQO, e verificar dependência nos graus de liberdade n-k-1.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Ajustar o modelo MQO e calcular os resíduos",
                                  "subSteps": [
                                    "Colete os dados de y (vetor resposta) e X (matriz de regressores incluindo intercepto).",
                                    "Ajuste o modelo de regressão linear usando MQO para obter os coeficientes β̂.",
                                    "Calcule os resíduos e = y - Xβ̂ para cada observação.",
                                    "Verifique se os resíduos foram calculados corretamente somando-os (deve ser próximo de zero)."
                                  ],
                                  "verification": "Confira se a soma dos resíduos é aproximadamente zero e plote-os para checar padrões.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software estatístico (R, Python com statsmodels ou scikit-learn)",
                                    "Dataset de exemplo com pelo menos 10 observações"
                                  ],
                                  "tips": "Sempre inclua a coluna de 1s para o intercepto em X.",
                                  "learningObjective": "Compreender o ajuste inicial do modelo e a obtenção de resíduos como base para estimativas de variância.",
                                  "commonMistakes": [
                                    "Esquecer de incluir o intercepto na matriz X",
                                    "Usar ŷ em vez de e para resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar a variância dos erros σ̂² a partir dos resíduos",
                                  "subSteps": [
                                    "Calcule a Soma dos Quadrados dos Resíduos (RSS) = Σ e_i².",
                                    "Determine os graus de liberdade: df = n - k - 1, onde n é o número de observações e k o número de regressores excluindo intercepto.",
                                    "Estime σ̂² = RSS / df.",
                                    "Interprete o valor: valores altos indicam heteroscedasticidade possível."
                                  ],
                                  "verification": "Compare σ̂² com o RSS: deve ser RSS dividido pelos df corretos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora ou software para somas quadráticas",
                                    "Resíduos do passo anterior"
                                  ],
                                  "tips": "Use funções prontas como residuals() no R para validar cálculos manuais.",
                                  "learningObjective": "Dominar a estimação não viesada da variância dos erros considerando graus de liberdade.",
                                  "commonMistakes": [
                                    "Confundir k com número total de colunas em X (incluindo intercepto)",
                                    "Dividir RSS por n em vez de df"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a matriz inversa (X'X)^{-1}",
                                  "subSteps": [
                                    "Construa a matriz X'X multiplicando X transposta por X.",
                                    "Inverta a matriz X'X para obter (X'X)^{-1}.",
                                    "Verifique se a inversa está correta multiplicando X'X por (X'X)^{-1} (deve dar identidade).",
                                    "Identifique os elementos diagonais relevantes para cada β̂ⱼ."
                                  ],
                                  "verification": "Multiplicação resulta em matriz identidade; diagonais positivas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software com álgebra linear (NumPy, R base)",
                                    "Matriz X do dataset"
                                  ],
                                  "tips": "Para datasets pequenos, calcule manualmente; para grandes, use funções como solve() ou inv().",
                                  "learningObjective": "Entender a matriz de variância-covariância dos estimadores como base para erros padrão.",
                                  "commonMistakes": [
                                    "X não centrada ou com multicolinearidade perfeita (inversível)",
                                    "Erro na transposição de X"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular o erro padrão SE(β̂ⱼ) e validar",
                                  "subSteps": [
                                    "Selecione o índice j para o coeficiente desejado e extraia (X'X)^{-1}_{jj}.",
                                    "Calcule a variância de β̂ⱼ = σ̂² × (X'X)^{-1}_{jj}.",
                                    "Obtenha SE(β̂ⱼ) = √[variância de β̂ⱼ].",
                                    "Confirme dependência em df = n - k - 1 para inferência futura."
                                  ],
                                  "verification": "Compare com output de software (ex: summary(lm()) no R) para o SE exato.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Resultados dos passos anteriores",
                                    "Calculadora de raízes"
                                  ],
                                  "tips": "Registre df para testes t subsequentes.",
                                  "learningObjective": "Aplicar a fórmula completa do erro padrão e integrá-la à inferência estatística.",
                                  "commonMistakes": [
                                    "Esquecer a raiz quadrada",
                                    "Usar σ² em vez de σ̂²"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dataset: y = [2.1, 3.2, 4.1, 5.0], X = [[1,1], [1,2], [1,3], [1,4]] (intercepto e x1). MQO dá β̂0=1.9, β̂1=0.8. Resíduos: [-0.1, 0.0, 0.1, 0.0]. RSS=0.02, n=4, k=1, df=2, σ̂²=0.01. X'X = [[4,10],[10,30]], (X'X)^{-1}=[[2.5,-0.833],[-0.833,0.333]]. Para j=1 (β̂1), SE=√[0.01*0.333]≈0.182.",
                              "finalVerifications": [
                                "Calcula corretamente σ̂² com df apropriado.",
                                "Obtém (X'X)^{-1} validada por multiplicação identidade.",
                                "Extraí elemento jj correto da diagonal.",
                                "Aplica fórmula SE exata e compara com software.",
                                "Explica dependência em n-k-1 para inferência."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica nos cálculos intermediários (±0.01).",
                                "Correta identificação de df e uso em σ̂².",
                                "Validação da inversa matricial.",
                                "Interpretação correta do SE no contexto de testes t.",
                                "Eficiência no uso de subpassos sem erros comuns.",
                                "Capacidade de replicar em dataset novo."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Base para testes t e intervalos de confiança.",
                                "Álgebra Linear: Inversão de matrizes e produtos matriciais.",
                                "Programação Computacional: Implementação em Python/R para automação.",
                                "Econometria: Aplicação em modelos de regressão econômica."
                              ],
                              "realWorldApplication": "Em análises de dados econômicos, como avaliar a significância do impacto de uma variável (ex: PIB sobre inflação), onde SE preciso permite testes t para políticas públicas confiáveis."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.3.1.1"
                            ]
                          },
                          {
                            "id": "11.2.3.2.3",
                            "name": "Verificar Pressupostos para Validade do Teste t",
                            "description": "Identificar e validar os pressupostos do Teorema de Gauss-Markov e normalidade dos erros para garantir que a estatística t siga a distribuição t-Student com n-k-1 graus de liberdade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar os Pressupostos do Teorema de Gauss-Markov",
                                  "subSteps": [
                                    "Liste os quatro pressupostos principais: linearidade condicional nos parâmetros, exogeneidade estrita (E(ε|X)=0), homocedasticidade (Var(ε|X)=σ²) e não-autocorrelação (Cov(ε_i, ε_j|X)=0 para i≠j).",
                                    "Explique como cada pressuposto garante que os estimadores OLS sejam BLUE (Best Linear Unbiased Estimators).",
                                    "Crie um checklist visual para cada pressuposto com critérios de verificação.",
                                    "Revise o teorema de Gauss-Markov e anote as implicações para a variância dos estimadores.",
                                    "Compare com pressupostos para inferência (notando que GM é para unbiasedness, não distribuição)."
                                  ],
                                  "verification": "Checklist completo com explicações escritas para cada pressuposto.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge), Notas de aula, Caneta e papel"
                                  ],
                                  "tips": "Use mnemônicos como 'LEHN' (Linearity, Exogeneity, Homoscedasticity, No autocorrelation) para memorizar.",
                                  "learningObjective": "Compreender precisamente os pressupostos que garantem propriedades BLUE dos OLS.",
                                  "commonMistakes": [
                                    "Confundir homocedasticidade com normalidade",
                                    "Omitir não-autocorrelação em dados em painel",
                                    "Achar que GM garante consistência"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Validar os Pressupostos de Gauss-Markov no Conjunto de Dados",
                                  "subSteps": [
                                    "Execute regressão OLS no software e obtenha resíduos padronizados.",
                                    "Verifique linearidade: plote resíduos vs valores ajustados e procure padrões não-lineares.",
                                    "Teste exogeneidade: use teste de Ramsey RESET para especificação; verifique correlação serial com Durbin-Watson.",
                                    "Teste homocedasticidade: Breusch-Pagan ou White test; plote resíduos vs ajustados para funil.",
                                    "Confirme não-autocorrelação em dados não-seriais ou ajuste se necessário."
                                  ],
                                  "verification": "Relatório com p-valores de testes >0.05 ou gráficos sem violações evidentes.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Software R ou Python (lmtest, statsmodels), Dataset de regressão exemplo"
                                  ],
                                  "tips": "Sempre padronize resíduos antes de plots para melhor visualização.",
                                  "learningObjective": "Aplicar testes diagnósticos para validar GM empiricamente.",
                                  "commonMistakes": [
                                    "Ignorar outliers que violam homocedasticidade",
                                    "Usar teste errado para autocorrelação em cross-section",
                                    "Não reportar p-valores com significância"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificar Normalidade dos Resíduos",
                                  "subSteps": [
                                    "Gere resíduos da regressão OLS.",
                                    "Plote Q-Q plot e histograma dos resíduos para inspeção visual.",
                                    "Aplique teste formal: Shapiro-Wilk ou Jarque-Bera (p>0.05 indica normalidade).",
                                    "Se violado, discuta robustez assintótica ou transformações (log, Box-Cox).",
                                    "Documente graus de liberdade residuais: n - k - 1, onde k é número de regressores."
                                  ],
                                  "verification": "Gráficos e p-valores documentados; conclusão explícita sobre normalidade.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "R (shapiro.test) ou Python (scipy.stats.normaltest), Resíduos salvos"
                                  ],
                                  "tips": "Para n pequeno (<30), priorize testes exatos; para grande n, CLT ajuda.",
                                  "learningObjective": "Avaliar se resíduos seguem normalidade para distribuição t exata.",
                                  "commonMistakes": [
                                    "Testar normalidade em Y em vez de resíduos",
                                    "Ignorar assimetria em Q-Q plot",
                                    "Confundir com GM"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Confirmar Validade da Estatística t e Graus de Liberdade",
                                  "subSteps": [
                                    "Calcule df = n - k - 1 e verifique se t segue t-Student sob pressupostos.",
                                    "Gere estatística t para coeficiente e compare com critical values de t(df).",
                                    "Se pressupostos falham, sugira alternativas: t-robusto (HCSE), bootstrap.",
                                    "Escreva relatório final de validade do teste t.",
                                    "Simule em software para ilustrar impacto de violações."
                                  ],
                                  "verification": "Cálculo de df correto e conclusão sobre validade do teste.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Tabela t-Student, Software para simulação (replicate em R)"
                                  ],
                                  "tips": "Use summary(lm) no R para df automático.",
                                  "learningObjective": "Integrar verificações para garantir inferência t válida.",
                                  "commonMistakes": [
                                    "Errar contagem de k (incluir intercepto)",
                                    "Assumir validade sem testes",
                                    "Não considerar amostra pequena"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários vs anos de educação e experiência (n=100, k=2), após OLS, plote resíduos (sem funil), Durbin-Watson=1.9 (ok), Breusch-Pagan p=0.12 (homocedástico), Shapiro p=0.08 (normal), df=96, confirmando t válido para testar β_educação ≠0.",
                              "finalVerifications": [
                                "Todos 4 pressupostos Gauss-Markov validados por testes/gráficos.",
                                "Normalidade dos resíduos confirmada (p>0.05 em teste apropriado).",
                                "Graus de liberdade calculados corretamente como n-k-1.",
                                "Nenhuma violação crítica identificada ou mitigada.",
                                "Relatório inclui evidências visuais e estatísticas.",
                                "Conclusão explícita sobre validade da distribuição t-Student."
                              ],
                              "assessmentCriteria": [
                                "Identificação precisa e completa dos pressupostos GM (100%).",
                                "Execução correta de pelo menos 3 testes diagnósticos com interpretação.",
                                "Análise visual de plots sem erros de interpretação.",
                                "Cálculo exato de df e ligação com distribuição t.",
                                "Relatório claro, conciso e com recomendações se violações.",
                                "Uso adequado de software sem erros de código."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Distribuições t-Student e propriedades assintóticas.",
                                "Programação: Scripts em R/Python para diagnósticos automatizados.",
                                "Análise de Dados: Limpeza e pré-processamento para evitar violações.",
                                "Econometria: Aplicações em modelos causais e IV se endogeneidade.",
                                "Visualização de Dados: Plots diagnósticos com ggplot/seaborn."
                              ],
                              "realWorldApplication": "Em análises de marketing para prever vendas por gasto em ads, verificar pressupostos garante que testes t sobre coeficientes sejam confiáveis, evitando decisões erradas como investir em canais ineficazes baseados em significância falsa."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.3.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "11.2.3.3",
                        "name": "Decisão, p-valor e Interpretação dos Resultados",
                        "description": "Uso da distribuição t-Student para rejeição de hipóteses, cálculo de p-valores e interpretação prática dos testes de significância em modelos econométricos para engenharia.",
                        "specificSkills": [
                          {
                            "id": "11.2.3.3.1",
                            "name": "Comparar com Valores Críticos da Distribuição t",
                            "description": "Consultar tabelas ou funções de software para obter o valor crítico t_{α/2, n-k-1} (ex.: α=0.05) e decidir rejeitar H₀ se |t| > crítico.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar Parâmetros Necessários para o Valor Crítico",
                                  "subSteps": [
                                    "Determine o nível de significância α (exemplo: 0.05 para 95% de confiança)",
                                    "Calcule os graus de liberdade df = n - k - 1, onde n é o tamanho da amostra e k o número de parâmetros no modelo",
                                    "Confirme se o teste é bilateral, usando t_{α/2, df}",
                                    "Registre os valores de α, n, k e df em uma tabela ou anotação"
                                  ],
                                  "verification": "Verifique se df está corretamente calculado e α apropriado para o contexto do teste",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Dados do modelo de regressão",
                                    "Calculadora ou planilha para df"
                                  ],
                                  "tips": "Sempre inclua o intercepto em k; verifique se n > k+1 para validade",
                                  "learningObjective": "Compreender o cálculo de graus de liberdade em testes t para regressão",
                                  "commonMistakes": [
                                    "Esquecer de subtrair k+1 de n",
                                    "Usar α em vez de α/2 para testes bilaterais"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Consultar Tabela ou Software para Obter o Valor Crítico",
                                  "subSteps": [
                                    "Abra a tabela de distribuição t e localize a linha correspondente a df",
                                    "Encontre a coluna para α/2 (ex: 0.025 para α=0.05)",
                                    "Anote o valor crítico t_{α/2, df}",
                                    "Alternativamente, use software: no R, qt(1 - α/2, df); no Python, stats.t.ppf(1 - α/2, df)",
                                    "Compare resultados da tabela e software para consistência"
                                  ],
                                  "verification": "O valor crítico obtido coincide com pelo menos duas fontes (tabela e software)",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Tabela de distribuição t impressa ou PDF",
                                    "Software R/Python com bibliotecas statsmodels ou scipy"
                                  ],
                                  "tips": "Para df grandes (>30), aproxime com distribuição normal z",
                                  "learningObjective": "Saber consultar e calcular valores críticos usando ferramentas manuais e computacionais",
                                  "commonMistakes": [
                                    "Ler a coluna errada (unilateral vs bilateral)",
                                    "Usar df incorreto na função de software"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar o Valor |t| Calculado com o Valor Crítico",
                                  "subSteps": [
                                    "Obtenha o valor t calculado do output do modelo de regressão",
                                    "Calcule |t| se necessário (para testes bilaterais)",
                                    "Compare: se |t| > t_crítico, marque como significativo",
                                    "Se |t| ≤ t_crítico, marque como não significativo",
                                    "Documente a comparação em uma tabela: t_calc, t_crit, decisão"
                                  ],
                                  "verification": "Tabela de comparação mostra |t| > t_crítico corretamente resolvida",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Output do modelo de regressão (R, Python, Excel)"
                                  ],
                                  "tips": "Sempre use valor absoluto para testes bilaterais",
                                  "learningObjective": "Aplicar a regra de decisão estatística com precisão",
                                  "commonMistakes": [
                                    "Esquecer o valor absoluto de t",
                                    "Comparar t com p-valor em vez de crítico"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Decidir sobre a Hipótese Nula e Interpretar o Resultado",
                                  "subSteps": [
                                    "Se |t| > t_crítico, rejeite H₀: o coeficiente é estatisticamente significativo",
                                    "Se |t| ≤ t_crítico, não rejeite H₀: evidência insuficiente",
                                    "Escreva uma interpretação: 'O coeficiente β_j é significativo ao nível α=0.05'",
                                    "Discuta implicações para o modelo (ex: variável relevante)",
                                    "Registre a decisão final em relatório"
                                  ],
                                  "verification": "Interpretação escrita está alinhada com a comparação e inclui nível de significância",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Modelo de regressão completo",
                                    "Template de relatório estatístico"
                                  ],
                                  "tips": "Evite dizer 'provar'; use 'evidência suficiente para rejeitar'",
                                  "learningObjective": "Interpretar resultados de testes t no contexto de inferência estatística",
                                  "commonMistakes": [
                                    "Rejeitar H₀ baseado em intuição em vez de regra",
                                    "Ignorar o nível α na interpretação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma regressão linear simples com n=30 observações, k=1 preditor, α=0.05: df=30-1-1=28, t_crítico ≈2.048 (tabela ou qt(0.975,28) no R). Se t_calculado=2.5, então |2.5|>2.048 → rejeite H₀: o preditor é significativo.",
                              "finalVerifications": [
                                "Parâmetros α, df calculados corretamente",
                                "Valor crítico obtido de tabela e software coincidem",
                                "Comparação |t| vs t_crítico é precisa",
                                "Decisão sobre H₀ justificada com interpretação clara",
                                "Relatório inclui todos os passos documentados",
                                "Teste bilateral aplicado corretamente"
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de df (100% correto)",
                                "Valor crítico exato ou dentro de 0.01 de referência",
                                "Regra de decisão aplicada sem erros lógicos",
                                "Interpretação contextualizada e sem jargão excessivo",
                                "Documentação completa com tabelas/comparações",
                                "Tempo total dentro de 60 minutos"
                              ],
                              "crossCurricularConnections": [
                                "Programação: Uso de funções em R/Python para automação",
                                "Econometria: Testes em modelos de regressão para previsão econômica",
                                "Ciências Biológicas: Inferência em experimentos com dados de regressão",
                                "Engenharia: Análise de confiabilidade de modelos preditivos"
                              ],
                              "realWorldApplication": "Em marketing, analisar se o gasto em anúncios de TV afeta significativamente as vendas (regressão), rejeitando H₀ se |t|>crítico para justificar alocação de orçamento."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.3.2.1"
                            ]
                          },
                          {
                            "id": "11.2.3.3.2",
                            "name": "Calcular e Interpretar o p-valor",
                            "description": "Computar o p-valor como P(|T| > |t_obs|) usando distribuição t-Student e interpretar: p < 0.05 indica significância ao nível de 5%, comum em análises de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Conceito de p-valor e Estatística t",
                                  "subSteps": [
                                    "Defina p-valor como a probabilidade de observar uma estatística t pelo menos tão extrema quanto a observada, assumindo H0 verdadeira.",
                                    "Revise a estatística t para coeficientes: t_obs = (β_hat - β0) / SE(β_hat), onde β0=0 para teste de significância.",
                                    "Entenda a distribuição t-Student com graus de liberdade n-k-1 em regressão linear.",
                                    "Diferencie p-valor de nível de significância α (ex: 0.05).",
                                    "Estude simetria: p-valor = P(|T| > |t_obs|) para testes bilaterais."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o que significa p-valor < 0.05 em contexto de teste de hipótese.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre testes t",
                                    "Tabela de distribuição t-Student",
                                    "Calculadora ou software como Python/R"
                                  ],
                                  "tips": "Visualize a área da cauda na curva t-Student para intuitivamente entender o p-valor.",
                                  "learningObjective": "Compreender a definição e interpretação probabilística do p-valor no contexto de testes t.",
                                  "commonMistakes": [
                                    "Confundir p-valor com probabilidade de H0 ser verdadeira",
                                    "Ignorar bilateral vs unilateral",
                                    "Confundir com intervalo de confiança"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a Estatística t Observada",
                                  "subSteps": [
                                    "Colete dados de regressão: coeficiente β_hat e erro padrão SE(β_hat) de output de software.",
                                    "Defina H0: β = 0.",
                                    "Compute t_obs = β_hat / SE(β_hat).",
                                    "Determine graus de liberdade df = n - k - 1, onde n=amostra, k=preditores.",
                                    "Verifique sinal de t_obs para contexto (positivo/negativo)."
                                  ],
                                  "verification": "Calcule t_obs manualmente para um exemplo dado e compare com output de software.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Dados de exemplo de regressão linear",
                                    "Output de regressão de Python (statsmodels) ou R",
                                    "Planilha Excel"
                                  ],
                                  "tips": "Sempre confira SE(β_hat) do summary de regressão para evitar erros de entrada.",
                                  "learningObjective": "Calcular corretamente a estatística t observada a partir de resultados de regressão.",
                                  "commonMistakes": [
                                    "Usar β_hat em vez de t_obs diretamente",
                                    "Erro em df",
                                    "Esquecer de dividir por SE"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar o p-valor Usando Distribuição t-Student",
                                  "subSteps": [
                                    "Use função de sobrevivência da t-Student: 2 * (1 - cdf(|t_obs|, df)).",
                                    "Em software: Python - scipy.stats.t.cdf(-abs(t_obs), df)*2; R - 2*pt(abs(t_obs), df, lower.tail=FALSE).",
                                    "Para cálculo manual: consulte tabela t para valor crítico e aproxime área da cauda.",
                                    "Confirme bilateral: multiplique cauda por 2.",
                                    "Registre p-valor com precisão de 4 casas decimais."
                                  ],
                                  "verification": "Reproduza p-valor de um output de software manualmente ou via código, com erro < 0.001.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Biblioteca scipy (Python) ou pt() (R)",
                                    "Tabela t-Student impressa",
                                    "Calculadora científica"
                                  ],
                                  "tips": "Teste com t_obs=0 (p=1) e t_obs grande (p≈0) para validar código.",
                                  "learningObjective": "Computar p-valor exato usando ferramentas computacionais e tabelas.",
                                  "commonMistakes": [
                                    "Usar distribuição normal Z em vez de t",
                                    "Esquecer o fator 2 para bilateral",
                                    "Erro em lower.tail"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar o p-valor e Tomar Decisão",
                                  "subSteps": [
                                    "Compare p com α=0.05: se p < α, rejeite H0 (significativo).",
                                    "Reporte: 'p = 0.023 < 0.05, coeficiente significativo ao nível de 5%'.",
                                    "Considere contexto: engenharia (ex: coeficiente de resistência em modelo preditivo).",
                                    "Discuta limitações: p-hacking, dependência de amostra.",
                                    "Integre com CI: se CI não inclui 0, consistente com rejeição H0."
                                  ],
                                  "verification": "Interprete p-valor de 3 cenários diferentes (p<0.05, p>0.05, p≈0.05) em relatório curto.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Exemplos de outputs de regressão",
                                    "Template de relatório de interpretação"
                                  ],
                                  "tips": "Sempre declare α explicitamente e evite dizer 'prova' ou 'confirma'.",
                                  "learningObjective": "Interpretar p-valor corretamente para decisão em testes de hipótese.",
                                  "commonMistakes": [
                                    "Interpretar p como P(H0|dados)",
                                    "Ignorar múltiplos testes",
                                    "Confundir com efeito prático"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para prever tensão em vigas de engenharia: dados de 30 testes com preditor 'espessura'. Output: β_hat=2.45, SE=1.12, t_obs=2.19, df=28. p-valor=0.037. Interpretação: espessura significativa (p<0.05), aumenta tensão em 2.45 unidades por mm.",
                              "finalVerifications": [
                                "Calcule p-valor corretamente para 3 conjuntos de dados dados (t_obs e df variados).",
                                "Explique diferença entre p=0.04 e p=0.06 em contexto de engenharia.",
                                "Gere código Python/R que compute e plote distribuição t com área de rejeição.",
                                "Identifique erro em interpretação de p-valor em relatório fornecido.",
                                "Compare p-valor com valor crítico t de tabela para df=20, α=0.05."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de t_obs e p-valor (erro <0.001).",
                                "Correta identificação de bilateral e df.",
                                "Interpretação clara e sem falácias comuns (ex: não confundir com P(H0)).",
                                "Uso apropriado de software com código reproduzível.",
                                "Relatório conciso integrando p-valor com contexto prático.",
                                "Reconhecimento de limitações (tamanho amostra, múltiplos testes)."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Implementação em Python (scipy.stats) ou R para automação.",
                                "Engenharia: Aplicação em regressão para modelagem preditiva de materiais.",
                                "Estatística Descritiva: Ligação com SE e variância de resíduos.",
                                "Probabilidade: Compreensão de distribuições e caudas.",
                                "Ciência de Dados: Integração em pipelines de ML para feature selection."
                              ],
                              "realWorldApplication": "Em análises de engenharia civil, calcular p-valor para coeficiente de 'carga aplicada' em modelo de regressão garante que apenas variáveis significativas sejam usadas no design de estruturas, evitando sobrecarga computacional e erros de projeto custosos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.3.2.1"
                            ]
                          },
                          {
                            "id": "11.2.3.3.3",
                            "name": "Aplicar Teste t em Contextos de Engenharia",
                            "description": "Executar e interpretar teste t em exemplo real, como regressão de custos de manutenção versus horas de uso em sistemas mecânicos, usando dados e software R conforme bibliografia (Gujarati, Greene).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Formulação do Problema e Hipóteses",
                                  "subSteps": [
                                    "Identifique o contexto de engenharia, como regressão de custos de manutenção (Y) versus horas de uso (X) em sistemas mecânicos.",
                                    "Defina as hipóteses nula (H0: β1 = 0, sem relação) e alternativa (Ha: β1 ≠ 0).",
                                    "Colete ou simule dados reais compatíveis com a bibliografia (Gujarati, Greene).",
                                    "Verifique premissas do teste t: normalidade dos resíduos e independência.",
                                    "Documente o modelo de regressão linear simples: Y = β0 + β1 X + ε."
                                  ],
                                  "verification": "Hipóteses H0 e Ha escritas claramente e premissas listadas em um documento.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Software R instalado",
                                    "Dados de exemplo (CSV com custos e horas)",
                                    "Livros: Gujarati e Greene (capítulos de regressão)"
                                  ],
                                  "tips": "Use exemplos reais de engenharia para tornar as hipóteses relevantes e testáveis.",
                                  "learningObjective": "Formular hipóteses precisas para teste t em regressão linear aplicada.",
                                  "commonMistakes": [
                                    "Confundir H0 com Ha",
                                    "Ignorar premissas como normalidade",
                                    "Usar dados não representativos do contexto"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparação e Carregamento dos Dados no R",
                                  "subSteps": [
                                    "Instale pacotes necessários: lmtest, car (se preciso).",
                                    "Carregue os dados com read.csv() e visualize com summary() e plot().",
                                    "Crie o modelo de regressão: model <- lm(Y ~ X, data = dados).",
                                    "Gere resumo do modelo com summary(model) para inspecionar coeficientes iniciais.",
                                    "Teste premissas: plot(model) para resíduos e shapiro.test(residuals(model)) para normalidade."
                                  ],
                                  "verification": "Script R executado sem erros e premissas confirmadas (p-valor Shapiro > 0.05).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R e RStudio",
                                    "Arquivo CSV de dados simulados (ex: 50 observações de custos e horas)",
                                    "Documentação R para lm()"
                                  ],
                                  "tips": "Sempre visualize os dados com scatterplot para detectar outliers antes da modelagem.",
                                  "learningObjective": "Preparar dados e verificar premissas para validade do teste t.",
                                  "commonMistakes": [
                                    "Não testar normalidade dos resíduos",
                                    "Ignorar multicolinearidade em dados simples",
                                    "Usar dados com valores ausentes sem tratamento"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Execução do Teste t para Coeficientes",
                                  "subSteps": [
                                    "Extraia o p-valor do teste t do summary(model)$coefficients[2,4].",
                                    "Execute teste t manualmente com t.test() se aplicável, ou coef.test(model).",
                                    "Calcule intervalo de confiança: confint(model, level=0.95).",
                                    "Compare p-valor com nível de significância (α=0.05).",
                                    "Registre estatística t, graus de liberdade e decisão (rejeitar ou não H0)."
                                  ],
                                  "verification": "P-valor e decisão documentados no output do R, com IC calculado.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Script R com modelo lm()",
                                    "Funções: summary(), confint()",
                                    "Referências: Greene cap. sobre testes em regressão"
                                  ],
                                  "tips": "Copie o output exato do summary() para evitar erros de transcrição manual.",
                                  "learningObjective": "Executar e extrair resultados do teste t em regressão via R.",
                                  "commonMistakes": [
                                    "Confundir p-valor com valor t",
                                    "Usar α errado (ex: 0.1 em vez de 0.05)",
                                    "Interpretar IC sem contexto"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretação dos Resultados e Relatório",
                                  "subSteps": [
                                    "Interprete: se p < 0.05, conclua que horas de uso afetam significativamente custos.",
                                    "Discuta implicações para engenharia: predição de manutenção.",
                                    "Gere gráficos: plot(model) e abline() para visualização.",
                                    "Escreva relatório com decisão, p-valor, IC e limitações.",
                                    "Valide com dados alternativos ou simulações conforme Gujarati."
                                  ],
                                  "verification": "Relatório completo com interpretação correta e gráficos salvos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R para plots",
                                    "Template de relatório (Word ou Markdown)",
                                    "Bibliografia para interpretação"
                                  ],
                                  "tips": "Sempre relacione resultados ao contexto real de engenharia para maior relevância.",
                                  "learningObjective": "Interpretar teste t e comunicar achados de forma acionável.",
                                  "commonMistakes": [
                                    "Ignorar significância prática além estatística",
                                    "Generalizar sem considerar limitações dos dados",
                                    "Esquecer IC na interpretação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em sistemas mecânicos de uma fábrica, use dados de 50 máquinas: custos de manutenção (Y, em R$) vs. horas de uso (X, em h). Modelo: lm(custos ~ horas). Teste t para β1: se p<0.05, horas de uso impactam custos significativamente, guiando planejamento de manutenção.",
                              "finalVerifications": [
                                "Hipóteses H0/Ha corretamente definidas e testadas.",
                                "Premissas do teste t (normalidade, independência) verificadas no R.",
                                "P-valor, estatística t e IC de 95% calculados e registrados.",
                                "Decisão explícita (rejeitar/aceitar H0) com interpretação contextual.",
                                "Relatório com gráficos e código R reproduzível.",
                                "Validação com bibliografia (Gujarati/Greene)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação de hipóteses (100% alinhado ao contexto).",
                                "Correta execução do modelo lm() e extração de p-valor (sem erros de código).",
                                "Interpretação adequada do p-valor e decisão (α=0.05).",
                                "Verificação completa de premissas com testes estatísticos.",
                                "Relatório claro, com implicações práticas para engenharia.",
                                "Código R limpo e comentado."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia Mecânica: Modelagem preditiva de falhas e manutenção.",
                                "Economia/Gestão: Análise de regressão para custos operacionais.",
                                "Programação: Uso de R para análise estatística aplicada.",
                                "Física: Relações lineares em desgaste de materiais.",
                                "Gestão de Projetos: Decisões baseadas em inferência estatística."
                              ],
                              "realWorldApplication": "Em indústrias de manufatura, aplicar teste t em regressões para validar se variáveis como horas de uso preveem custos de manutenção, otimizando orçamentos, reduzindo downtime e melhorando eficiência operacional em sistemas mecânicos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.2.3.2.2",
                              "11.2.3.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.2.4",
                    "name": "Testes de Hipótese para Validação do Modelo",
                    "description": "Teste F para adequação global e testes de especificação do modelo de regressão.",
                    "individualConcepts": [
                      {
                        "id": "10.1.2.4.1",
                        "name": "Teste F para Adequação Global",
                        "description": "O Teste F avalia a significância global do modelo de regressão linear, testando a hipótese nula de que todos os coeficientes dos regressores são iguais a zero (exceto o intercepto), contra a alternativa de que pelo menos um é diferente de zero. Utiliza a estatística F calculada como razão entre a variância explicada e a não explicada, comparada à distribuição F com graus de liberdade apropriados.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.4.1.1",
                            "name": "Formular as hipóteses do Teste F global",
                            "description": "Definir H0: β1 = β2 = ... = βk = 0 (todos os coeficientes dos regressores são nulos) e Ha: pelo menos um βj ≠ 0, identificando os graus de liberdade (k e n-k-1) para a distribuição F no contexto de MQO.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o modelo de regressão linear múltipla e seus parâmetros",
                                  "subSteps": [
                                    "Revise a forma geral do modelo MQO: Y = β0 + β1X1 + β2X2 + ... + βkXk + ε",
                                    "Identifique β0 como o intercepto e β1 a βk como os coeficientes dos k regressores",
                                    "Entenda que o Teste F global avalia se o modelo como um todo é útil (explicação da variância de Y)",
                                    "Diferencie os regressores (X1 a Xk) da variável dependente Y e do erro ε",
                                    "Anote o número de observações n e o número de regressores k para uso posterior"
                                  ],
                                  "verification": "Escreva o modelo com notação correta e liste todos os parâmetros envolvidos",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Folha de papel ou editor de texto",
                                    "Exemplo de modelo de regressão de um textbook de econometria"
                                  ],
                                  "tips": "Sempre comece pelo modelo completo antes de formular hipóteses para manter o contexto claro",
                                  "learningObjective": "Dominar a estrutura do modelo MQO e identificar corretamente os coeficientes βj",
                                  "commonMistakes": [
                                    "Confundir β0 com os βj dos regressores",
                                    "Ignorar o número de regressores k"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a hipótese nula H0 para o Teste F global",
                                  "subSteps": [
                                    "Defina H0 como a hipótese de que nenhum regressor é útil: β1 = β2 = ... = βk = 0",
                                    "Explique verbalmente: sob H0, Y é explicado apenas pelo intercepto e erro (modelo nulo)",
                                    "Escreva H0 matematicamente: H0: β1 = β2 = ⋯ = βk = 0",
                                    "Confirme que β0 não está incluído em H0, pois o modelo nulo ainda tem intercepto",
                                    "Compare com o modelo completo para visualizar a restrição"
                                  ],
                                  "verification": "Escreva H0 corretamente e explique por que todos os βj de 1 a k são zero",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Notas do Step 1",
                                    "Software como R ou Python para visualizar modelo nulo (opcional)"
                                  ],
                                  "tips": "Lembre-se: H0 testa se o modelo restrito (apenas intercepto) é suficiente",
                                  "learningObjective": "Formular precisamente H0, reconhecendo que testa a insignificância conjunta dos regressores",
                                  "commonMistakes": [
                                    "Incluir β0 em H0",
                                    "Escrever H0 como todos βj=0 incluindo intercepto"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Formular a hipótese alternativa Ha",
                                  "subSteps": [
                                    "Defina Ha como: pelo menos um βj ≠ 0, para j=1,2,...,k",
                                    "Escreva Ha matematicamente: Ha: pelo menos um βj ≠ 0 (j=1,...,k)",
                                    "Explique que Ha suporta o modelo completo com regressores relevantes",
                                    "Diferencie de testes t individuais, que testam βj=0 separadamente",
                                    "Verifique consistência com H0: Ha é o complemento de H0"
                                  ],
                                  "verification": "Escreva Ha e justifique por que é 'pelo menos um' em vez de 'todos ≠0'",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Notas dos Steps 1 e 2",
                                    "Exemplo de rejeição de H0 em um caso real"
                                  ],
                                  "tips": "Ha é sempre o oposto de H0; evite especificar qual βj é diferente",
                                  "learningObjective": "Entender e formular Ha como a rejeição da insignificância global do modelo",
                                  "commonMistakes": [
                                    "Escrever Ha como todos βj ≠0 (isso é teste diferente)",
                                    "Confundir com hipótese alternativa de teste t"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar os graus de liberdade para a estatística F",
                                  "subSteps": [
                                    "Determine o numerador df: k (número de restrições sob H0)",
                                    "Determine o denominador df: n - k - 1 (graus de liberdade do resíduo no modelo completo)",
                                    "Escreva a distribuição F ~ F(k, n-k-1) sob H0",
                                    "Calcule para um exemplo: se n=50, k=3, df=(3,46)",
                                    "Confirme com fórmula geral e contexto do Teste F global"
                                  ],
                                  "verification": "Calcule df para um dataset fictício e escreva a distribuição F completa",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora",
                                    "Dataset de exemplo com n e k conhecidos"
                                  ],
                                  "tips": "Sempre subtraia 1 extra por β0 no denominador",
                                  "learningObjective": "Calcular e interpretar corretamente os graus de liberdade k e n-k-1",
                                  "commonMistakes": [
                                    "Usar n-k ao invés de n-k-1",
                                    "Confundir df numerador com k+1"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo prevendo salário (Y) por anos de educação (X1) e experiência (X2), k=2, n=100: H0: β1=β2=0 (salário não depende de educação/experiência); Ha: pelo menos um βj≠0; F ~ F(2,97).",
                              "finalVerifications": [
                                "Escreva H0 e Ha corretamente para um modelo com k=3 regressores",
                                "Identifique df para n=30, k=4 (4, 25)",
                                "Explique verbalmente o significado do Teste F global",
                                "Diferencie H0 do modelo nulo vs. modelo completo",
                                "Calcule df em um exemplo dado",
                                "Confirme que Ha é o complemento de H0"
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação de H0 e Ha (todos β1 a βk)",
                                "Correta exclusão de β0 das hipóteses",
                                "Cálculo exato de graus de liberdade (k e n-k-1)",
                                "Explicação clara do contexto MQO e Teste F global",
                                "Identificação de pelo menos um erro comum evitado",
                                "Consistência lógica entre steps"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Integra com testes t e qui-quadrado",
                                "Econometria: Aplicação em validação de modelos econômicos",
                                "Ciência de Dados: Pré-requisito para feature selection em ML",
                                "Matemática: Distribuições F e propriedades assintóticas",
                                "Programação: Implementação em R (lm()$fstatistic) ou Python (statsmodels)"
                              ],
                              "realWorldApplication": "Em análise de dados de marketing, testar se variáveis como preço, publicidade e localização explicam vendas (rejeitar H0 indica modelo útil para previsões e decisões estratégicas)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.1.2",
                            "name": "Calcular a estatística F e p-valor",
                            "description": "Computar F = (QME / QMR) onde QME é a soma quadrados média explicada e QMR a dos resíduos, ou usar R²: F = [R²/k] / [(1-R²)/(n-k-1)], e determinar o p-valor ou valor crítico da tabela F para rejeitar ou não H0.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e componentes necessários",
                                  "subSteps": [
                                    "Identifique o número de observações n e preditores k (excluindo intercepto ou incluindo conforme convenção)",
                                    "Obtenha ou calcule R² do modelo de regressão",
                                    "Calcule SSR (soma de quadrados dos resíduos explicados) e SSE (soma de quadrados dos resíduos), se não tiver R²: TSS = SSR + SSE",
                                    "Verifique graus de liberdade: df_modelo = k, df_resíduos = n - k - 1",
                                    "Confirme que n > k + 1 para evitar divisão por zero"
                                  ],
                                  "verification": "Liste os valores de n, k, R² (ou SSR, SSE) e graus de liberdade em uma tabela e confirme cálculos manuais ou via software.",
                                  "estimatedTime": "15-20 minutos",
                                  "materials": [
                                    "Dados do modelo de regressão (planilha Excel ou dataset em CSV)",
                                    "Calculadora, Excel, R ou Python (pandas, statsmodels)"
                                  ],
                                  "tips": "Salve os valores em uma tabela organizada para evitar erros de transcrição.",
                                  "learningObjective": "Preparar com precisão todos os insumos necessários para o cálculo da estatística F.",
                                  "commonMistakes": [
                                    "Confundir k com o número total de parâmetros (incluindo intercepto)",
                                    "Usar n incorreto, esquecendo de excluir observações com missing values",
                                    "Calcular TSS errado ao ignorar SSE"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular QME e QMR",
                                  "subSteps": [
                                    "Calcule QME (Quadrados Média Explicada) = SSR / k",
                                    "Calcule QMR (Quadrados Média Resíduos) = SSE / (n - k - 1)",
                                    "Alternativa com R²: confirme equivalência via R² = SSR / TSS",
                                    "Registre valores com pelo menos 4 casas decimais para precisão",
                                    "Valide: QME deve ser maior que QMR se o modelo for bom"
                                  ],
                                  "verification": "Compare QME e QMR calculados manualmente com saída de software (ex: summary(lm()) no R).",
                                  "estimatedTime": "10-15 minutos",
                                  "materials": [
                                    "Resultados de regressão de Step 1",
                                    "Software estatístico (R: lm(), Python: statsmodels.api.OLS)"
                                  ],
                                  "tips": "Use fórmulas exatas; evite arredondamentos prematuros.",
                                  "learningObjective": "Dominar o cálculo das médias quadráticas para ANOVA de regressão.",
                                  "commonMistakes": [
                                    "Dividir SSR por df_resíduos em vez de df_modelo",
                                    "Esquecer o -1 nos graus de liberdade dos resíduos",
                                    "Usar R² ajustado incorretamente para QME"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar a estatística F",
                                  "subSteps": [
                                    "Aplique a fórmula principal: F = QME / QMR",
                                    "Alternativa com R²: F = [R² / k] / [(1 - R²) / (n - k - 1)]",
                                    "Calcule manualmente e confirme com software",
                                    "Interprete: F > 1 sugere modelo melhor que intercepto-only",
                                    "Registre F com precisão"
                                  ],
                                  "verification": "Execute regressão em software e compare seu F calculado com o F do summary.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Valores de QME e QMR do Step 2",
                                    "Calculadora ou script Python/R"
                                  ],
                                  "tips": "A fórmula com R² é útil quando só se tem R² disponível.",
                                  "learningObjective": "Executar o cálculo da estatística F de forma precisa e entender suas duas formas equivalentes.",
                                  "commonMistakes": [
                                    "Inverter QME e QMR",
                                    "Usar df incorretos na fórmula R²",
                                    "Confundir F com t-statistic"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Determinar o p-valor ou valor crítico e interpretar",
                                  "subSteps": [
                                    "Use tabela F para valor crítico (df1=k, df2=n-k-1, α=0.05)",
                                    "Ou calcule p-valor computacionalmente: R: 1 - pf(F, k, n-k-1); Python: 1 - f.cdf(F, k, n-k-1)",
                                    "Compare: se p < α ou F > F_crítico, rejeite H0 (modelo inadequado)",
                                    "Documente decisão e graus de liberdade usados",
                                    "Teste sensibilidade variando α (0.01, 0.10)"
                                  ],
                                  "verification": "Replique p-valor em dois softwares diferentes e confirme consistência.",
                                  "estimatedTime": "15-20 minutos",
                                  "materials": [
                                    "Tabela F crítica (impressa ou online)",
                                    "R ou Python (stats: pf, scipy.stats.f)",
                                    "F calculado do Step 3"
                                  ],
                                  "tips": "Sempre reporte df1 e df2 com o p-valor para reprodutibilidade.",
                                  "learningObjective": "Avaliar significância do modelo via p-valor e interpretação do teste F.",
                                  "commonMistakes": [
                                    "Usar distribuição t em vez de F",
                                    "Esquecer inverter a CDF para p-valor (1 - cdf)",
                                    "Ignorar df2 finito em tabelas"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere regressão linear simples: y ~ x, n=30 observações, k=1 preditor (+intercepto), R²=0.65. Então F = [0.65/1] / [(1-0.65)/(30-1-1)] = 0.65 / (0.35/28) ≈ 0.65 / 0.0125 ≈ 52. p-valor ≈ 1 - pf(52,1,28) < 0.001, rejeite H0: modelo significativo.",
                              "finalVerifications": [
                                "Calcula F corretamente a partir de QME/QMR ou R² para dados dados",
                                "Obtém p-valor consistente com software para df1=2, df2=27",
                                "Interpreta corretamente rejeição de H0 quando F> F_crítico(0.05)",
                                "Identifica erros em cálculos de pares (ex: F=1.2 com p>0.05)",
                                "Explica equivalência das duas fórmulas de F",
                                "Aplica em dataset real de regressão múltipla"
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de QME, QMR e F (erro <0.01)",
                                "Correta determinação de p-valor ou comparação com crítico",
                                "Uso apropriado de graus de liberdade",
                                "Interpretação clara da decisão de hipótese",
                                "Documentação completa com fórmulas e valores",
                                "Validação cruzada com software"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: ANOVA e testes paramétricos",
                                "Programação Computacional: Funções em R/Python para distribuições F",
                                "Análise de Regressão e Modelagem Linear",
                                "Machine Learning: Validação de modelos lineares",
                                "Matemática Aplicada: Cálculo de somas de quadrados"
                              ],
                              "realWorldApplication": "Em ciências de dados, economia e engenharia, o teste F valida se um modelo de regressão explica significativamente a variabilidade dos dados (ex: prever vendas por publicidade, rejeitando modelo nulo; em epidemiologia, testar adequação de modelos de risco)."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.1.3",
                            "name": "Interpretar resultados do Teste F",
                            "description": "Analisar se p-valor < α (ex: 0.05) implica rejeição de H0, indicando que o modelo explica variabilidade na variável dependente, com exemplos em dados de engenharia econômica como previsão de custos de produção.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar as Hipóteses do Teste F",
                                  "subSteps": [
                                    "Defina a hipótese nula (H0): Todos os coeficientes de regressão (β1, β2, ..., βk) são iguais a zero, significando que o modelo não explica variabilidade na variável dependente.",
                                    "Defina a hipótese alternativa (H1): Pelo menos um coeficiente βi ≠ 0, indicando que o modelo explica parte da variabilidade.",
                                    "Escolha o nível de significância α (tipicamente 0.05 ou 0.01) com base no contexto do problema.",
                                    "Entenda que rejeitar H0 sugere adequação global do modelo, mas não prova causalidade.",
                                    "Relacione com R²: Teste F complementa ao testar se R² > 0 significativamente."
                                  ],
                                  "verification": "Escreva H0 e H1 em suas próprias palavras e explique o que significa rejeitar H0 em um modelo de regressão.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Notas de aula sobre testes de hipótese",
                                    "Tabela de valores críticos de F (opcional)",
                                    "Software de regressão como R ou Python (ex: statsmodels)"
                                  ],
                                  "tips": "Lembre-se: Teste F é global; use testes t para coeficientes individuais.",
                                  "learningObjective": "Compreender a base teórica das hipóteses para interpretação correta.",
                                  "commonMistakes": [
                                    "Confundir H0 do Teste F com testes univariados",
                                    "Ignorar que rejeição não implica bons coeficientes individuais",
                                    "Escolher α arbitrariamente sem justificativa"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar e Ler os Componentes da Saída do Teste F",
                                  "subSteps": [
                                    "Localize a estatística F (F-statistic) na tabela ANOVA ou sumário da regressão.",
                                    "Identifique o p-valor associado ao Teste F.",
                                    "Note os graus de liberdade: numerador (k, número de preditores) e denominador (n-k-1, onde n é tamanho da amostra).",
                                    "Registre valores relacionados como R² e R² ajustado para contexto.",
                                    "Verifique se a saída inclui intervalos de confiança ou valores críticos de F."
                                  ],
                                  "verification": "Em uma saída de software exemplo, circule e rotule F, p-valor e graus de liberdade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Saída exemplo de regressão (R, Python, Excel)",
                                    "Documentação do software usado",
                                    "Dados de exemplo em CSV"
                                  ],
                                  "tips": "Sempre verifique unidades e escalas; p-valor é o foco principal para decisão.",
                                  "learningObjective": "Localizar e interpretar precisamente os valores chave da saída.",
                                  "commonMistakes": [
                                    "Confundir p-valor de F com p-valores de coeficientes",
                                    "Ignorar graus de liberdade ao interpretar F",
                                    "Ler F bruto sem p-valor"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar a Regra de Decisão Baseada no p-valor",
                                  "subSteps": [
                                    "Compare o p-valor com α: se p < α, rejeite H0.",
                                    "Se p ≥ α, falhe em rejeitar H0 (não conclua que o modelo é inútil).",
                                    "Calcule ou note o valor crítico de F se p-valor não estiver disponível.",
                                    "Documente a decisão: 'Rejeitamos H0 ao nível α=0.05 pois p=0.001 < 0.05'.",
                                    "Considere robustez: verifique suposições como normalidade dos resíduos."
                                  ],
                                  "verification": "Dado p=0.03 e α=0.05, declare corretamente a decisão e justifique.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Calculadora ou software para comparação",
                                    "Tabela de distribuição F",
                                    "Exemplos de saídas variadas"
                                  ],
                                  "tips": "p-valor pequeno ≠ efeito grande; combine com R² para magnitude.",
                                  "learningObjective": "Executar decisão estatística de forma objetiva e precisa.",
                                  "commonMistakes": [
                                    "Rejeitar H0 baseado só em F grande sem p-valor",
                                    "Usar α=0.05 rigidamente sem contexto",
                                    "Confundir 'falhar em rejeitar' com 'aceitar H0'"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Implicações no Contexto dos Dados",
                                  "subSteps": [
                                    "Relacione rejeição de H0 à variável dependente: 'O modelo explica significativamente a variabilidade nos custos de produção'.",
                                    "Discuta força via R²: ex., '65% da variância explicada'.",
                                    "Considere limitações: multicolinearidade, amostra pequena, outliers.",
                                    "Contextualize com domínio: em engenharia econômica, implica confiabilidade para previsão de custos.",
                                    "Planeje próximos passos: análise de resíduos, testes adicionais."
                                  ],
                                  "verification": "Escreva um parágrafo de interpretação completa para um exemplo dado.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Dados reais de exemplo (custos de produção)",
                                    "Gráficos de resíduos",
                                    "Relatório modelo em template"
                                  ],
                                  "tips": "Sempre volte aos dados originais para interpretação significativa.",
                                  "learningObjective": "Conectar resultados estatísticos a aplicações práticas.",
                                  "commonMistakes": [
                                    "Super-generalizar: 'modelo perfeito'",
                                    "Ignorar suposições violadas",
                                    "Não mencionar R² na interpretação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia econômica com 50 observações de custos de produção (variável dependente: custo total em R$/unidade; preditores: horas de trabalho, custo de materiais, eficiência da máquina). Saída da regressão: F(3,46)=12.45, p-valor=0.0001 < 0.05, R²=0.62. Interpretação: Rejeitamos H0; o modelo explica significativamente 62% da variabilidade nos custos, útil para previsão orçamentária.",
                              "finalVerifications": [
                                "Explicar corretamente H0 e implicações de rejeição em contexto de regressão múltipla.",
                                "Identificar e usar p-valor para decisão em saídas reais de software.",
                                "Interpretar Teste F junto com R² em exemplo de dados de engenharia econômica.",
                                "Discutir limitações como suposições não testadas.",
                                "Aplicar interpretação a um novo dataset similar.",
                                "Escrever relatório sucinto com decisão e implicações."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de hipóteses e regra de decisão (p vs α).",
                                "Correta localização e uso de F, p-valor e graus de liberdade.",
                                "Profundidade da interpretação contextual, incluindo R² e domínio.",
                                "Identificação de erros comuns e limitações.",
                                "Clareza e estrutura na comunicação da análise.",
                                "Aplicação prática em exemplo realista."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia Econômica: Validação de modelos para previsão de custos e orçamentos.",
                                "Machine Learning: Adequação global em regressão linear antes de tuning.",
                                "Econometria: Testes de significância em análise de painéis de produção.",
                                "Gestão de Projetos: Decisão baseada em evidência para alocação de recursos."
                              ],
                              "realWorldApplication": "Na indústria manufatureira, engenheiros econômicos usam o Teste F para validar modelos de regressão que preveem custos de produção baseados em insumos variáveis. Rejeitar H0 confirma que fatores como horas de trabalho e materiais explicam custos, permitindo otimizar orçamentos, reduzir desperdícios e melhorar competitividade em licitações."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.2.4.2",
                        "name": "Testes de Especificação do Modelo",
                        "description": "Testes que verificam se o modelo de regressão está corretamente especificado, incluindo detecção de variáveis omitidas, formas funcionais erradas ou heterocedasticidade, como o Teste RESET de Ramsey, que adiciona potências da variável predita ajustada aos regressores.",
                        "specificSkills": [
                          {
                            "id": "10.1.2.4.2.1",
                            "name": "Realizar o Teste RESET de Ramsey",
                            "description": "Executar regressão auxiliar com ŷ, ŷ², ..., ŷ^p adicionados aos regressores originais, calcular F ou t para os coeficientes extras sob H0: γ2=...=γp=0, rejeitando se significativo, indicando misspecification.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Ajustar o Modelo de Regressão Original e Obter Valores Ajustados",
                                  "subSteps": [
                                    "Carregue o conjunto de dados relevante em um software estatístico (ex: Python com statsmodels ou R).",
                                    "Especifique o modelo linear original: Y = β₀ + β₁X₁ + ... + βₖXₖ + ε.",
                                    "Ajuste o modelo usando OLS (Mínimos Quadrados Ordinários).",
                                    "Extraia os valores ajustados ŷ (fitted values) do modelo.",
                                    "Verifique a adequação inicial do modelo com R² e resíduos."
                                  ],
                                  "verification": "Confirme que os valores ajustados ŷ foram extraídos corretamente comparando a soma de ŷ com a média de Y multiplicada pelo número de observações.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Software estatístico (Python: statsmodels, pandas; R: lm()), conjunto de dados com variáveis explicativas e dependente"
                                  ],
                                  "tips": "Salve o modelo ajustado em uma variável para reutilização fácil; plote ŷ vs Y para inspeção visual.",
                                  "learningObjective": "Compreender como ajustar um modelo linear e extrair previsões para testes subsequentes.",
                                  "commonMistakes": [
                                    "Esquecer de incluir intercepto no modelo",
                                    "Usar dados com multicolinearidade extrema sem pré-teste",
                                    "Confundir Y observada com ŷ"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular as Potências dos Valores Ajustados",
                                  "subSteps": [
                                    "Selecione o número de potências p (tipicamente p=3 ou 4).",
                                    "Calcule ŷ², ŷ³, ..., ŷᵖ para cada observação.",
                                    "Opcionalmente, centre as potências subtraindo a média de ŷ para evitar multicolinearidade (embora não obrigatório no teste padrão).",
                                    "Crie uma matriz ou data frame com as colunas das potências.",
                                    "Inspecione correlações entre potências para detectar problemas."
                                  ],
                                  "verification": "Verifique se as potências foram calculadas corretamente computando a média de cada ŷᵏ (deve ser próxima de zero se centrado).",
                                  "estimatedTime": "10-15 minutos",
                                  "materials": [
                                    "Mesmo software do Step 1, funções de potência (np.power() em Python, ^ em R)"
                                  ],
                                  "tips": "Use loops ou apply para eficiência em grandes datasets; evite p muito alto (>4) para não inflar dimensões.",
                                  "learningObjective": "Dominar a geração de termos não-lineares a partir de previsões lineares para detecção de misspecification.",
                                  "commonMistakes": [
                                    "Calcular potências de Y em vez de ŷ",
                                    "Não tratar valores extremos que possam causar overflow",
                                    "Ignorar centramento levando a instabilidade numérica"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir e Ajustar a Regressão Auxiliar",
                                  "subSteps": [
                                    "Combine os regressores originais (X₁, ..., Xₖ) com as potências adicionais (ŷ², ..., ŷᵖ).",
                                    "Especifique a regressão auxiliar: Y = β₀ + β₁X₁ + ... + βₖXₖ + γ₂ŷ² + ... + γₚŷᵖ + u.",
                                    "Ajuste o modelo auxiliar usando OLS.",
                                    "Extraia os coeficientes γ₂ até γₚ, seus erros-padrão e estatísticas t ou a estatística F conjunta.",
                                    "Confira a matriz de variância-covariância para os γ's."
                                  ],
                                  "verification": "Confirme que apenas os coeficientes γ extras foram isolados e que o modelo roda sem erros de singularidade.",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Mesmo software, fórmula para lm() ou sm.OLS() incluindo novas colunas"
                                  ],
                                  "tips": "Nomeie as novas variáveis claramente (ex: yhat2, yhat3); use summary() para overview rápido.",
                                  "learningObjective": "Aprender a expandir um modelo com termos de teste para verificação de especificação funcional.",
                                  "commonMistakes": [
                                    "Incluir ŷ¹ (que é linearmente dependente dos X's)",
                                    "Usar Y em vez de ŷ nas potências",
                                    "Esquecer de ajustar a auxiliar após adicionar termos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Realizar o Teste de Hipótese e Interpretar",
                                  "subSteps": [
                                    "Defina H₀: γ₂ = γ₃ = ... = γₚ = 0 (sem misspecification não-linear).",
                                    "Calcule a estatística F para o conjunto de γ's ou testes t individuais.",
                                    "Obtenha o p-valor associado (graus de liberdade: p-1 numerador, n-k-p denominador).",
                                    "Compare com nível de significância α (ex: 0.05); rejeite H₀ se p < α.",
                                    "Interprete: rejeição indica necessidade de termos não-lineares ou modelo alternativo."
                                  ],
                                  "verification": "Reproduza o p-valor manualmente usando a fórmula F = (RSS_restrito - RSS_nao_restrito)/(p-1) / (RSS_nao_restrito/(n-k-p)).",
                                  "estimatedTime": "15-20 minutos",
                                  "materials": [
                                    "Funções de teste F (anova() em R, statsmodels em Python)"
                                  ],
                                  "tips": "Prefira teste F conjunto sobre t's individuais para poder maior; documente graus de liberdade.",
                                  "learningObjective": "Aplicar inferência estatística para validar especificação de modelo via teste RESET.",
                                  "commonMistakes": [
                                    "Confundir H₀ com rejeição automática",
                                    "Usar t em vez de F para múltiplos coeficientes",
                                    "Ignorar tamanho da amostra pequeno afetando poder do teste"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados de salários (Y) vs anos de educação (X). Modelo original: salário = 20000 + 1000*edu. ŷ calculado. Auxiliar: salário = 20000 + 1000*edu + γ₂ŷ² + γ₃ŷ³. Se F(2, n-4)=5.2, p=0.007 <0.05, rejeite H₀: modelo linear misspecified; sugira polinomial em edu.",
                              "finalVerifications": [
                                "Valores ajustados ŷ extraídos e potências calculadas corretamente.",
                                "Regressão auxiliar ajustada sem erros e coeficientes γ obtidos.",
                                "Estatística F ou t calculada com p-valor preciso.",
                                "Decisão de rejeição/aceitação de H₀ baseada em α=0.05 documentada.",
                                "Interpretação liga resultado a implicações para o modelo original.",
                                "Código reproduzível gera mesmos resultados."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação dos steps (sem erros em cálculos).",
                                "Compreensão conceitual evidenciada em interpretação de resultados.",
                                "Eficiência no uso de software e manipulação de dados.",
                                "Identificação correta de common mistakes evitados.",
                                "Qualidade da documentação e verificações finais.",
                                "Criatividade na extensão para p>3 se apropriado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes F e inferência em regressão múltipla.",
                                "Programação: Manipulação de data frames e funções vetoriais.",
                                "Econometria: Diagnósticos de modelo e especificação funcional.",
                                "Matemática: Expansões polinomiais e aproximação Taylor.",
                                "Ciência de Dados: Validação de modelos preditivos."
                              ],
                              "realWorldApplication": "Em econometria, usado para validar modelos de previsão de PIB, salários ou demanda; ex: detectar se relação linear entre renda e consumo é inadequada, guiando para modelos não-lineares em políticas públicas ou finanças."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.2.2",
                            "name": "Aplicar teste de variáveis omitidas",
                            "description": "Testar inclusão de variável suspeita via t ou F, ou usar critério de Lagrange Multiplicador (LM), comparando modelos aninhados para validar especificação em contextos de engenharia como análise de eficiência energética.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar suspeita de variável omitida e formular hipóteses",
                                  "subSteps": [
                                    "Analise o modelo atual e identifique variáveis teoricamente relevantes ausentes com base no contexto (ex: eficiência energética).",
                                    "Formule a hipótese nula (H0): a variável omitida não afeta o modelo (coeficiente β = 0).",
                                    "Defina a hipótese alternativa (H1): β ≠ 0, justificando com evidências teóricas ou empíricas.",
                                    "Determine se usar teste t/F (uma variável) ou LM (múltiplas ou restrições).",
                                    "Documente a suspeita e critérios de decisão (nível de significância α = 0.05)."
                                  ],
                                  "verification": "Hipóteses H0 e H1 documentadas claramente, com justificativa teórica.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Literatura teórica do domínio (ex: artigos sobre eficiência energética)",
                                    "Software estatístico (R, Python com statsmodels)"
                                  ],
                                  "tips": "Consulte teoria econômica/engenharia para embasar a suspeita; evite variáveis colineares.",
                                  "learningObjective": "Compreender quando e por que variáveis podem ser omitidas, formulando testes adequados.",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade",
                                    "Escolher variável sem base teórica",
                                    "Definir H0 incorretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir modelos restrito e irrestrito",
                                  "subSteps": [
                                    "Estime o modelo restrito (sem a variável suspeita) via Mínimos Quadrados Ordinários (MQO).",
                                    "Inclua a variável suspeita no modelo irrestrito e estime via MQO.",
                                    "Verifique se os modelos são aninhados (irrestrito contém o restrito).",
                                    "Calcule resíduos e diagnósticos iniciais (normalidade, heterocedasticidade).",
                                    "Salve estatísticas como R², SSE (Soma de Quadrados dos Resíduos) para ambos."
                                  ],
                                  "verification": "Dois modelos estimados com outputs completos (coeficientes, R², SSE).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Dados reais/simulados (ex: dataset de consumo energético)",
                                    "R (lm()), Python (statsmodels.api.OLS)"
                                  ],
                                  "tips": "Use dados balanceados; padronize variáveis para comparação.",
                                  "learningObjective": "Construir modelos aninhados corretamente para testes de especificação.",
                                  "commonMistakes": [
                                    "Modelos não aninhados",
                                    "Omissão de controles essenciais",
                                    "Não salvar SSE"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste estatístico (t/F ou LM)",
                                  "subSteps": [
                                    "Para uma variável: aplique teste t no coeficiente da variável no irrestrito ou F comparando SSE.",
                                    "Para LM: estime restrito, gere predições, regresse resíduos quadrados no irrestrito e teste significância.",
                                    "Calcule estatística do teste: F = [(SSE_r - SSE_u)/q] / [SSE_u/(n-k_u)], com q=graus de liberdade.",
                                    "Obtenha p-value e compare com α.",
                                    "Use função pronta: em R lmtest::resettest() ou Python statsmodels para LM."
                                  ],
                                  "verification": "Estatística F/LM, p-value e df calculados e reportados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacotes: R (lmtest, car), Python (statsmodels, scipy.stats)"
                                  ],
                                  "tips": "Prefira LM para restrições complexas; verifique tamanho amostral (>30).",
                                  "learningObjective": "Aplicar e calcular testes de especificação estatisticamente rigorosos.",
                                  "commonMistakes": [
                                    "Confundir t com F",
                                    "Erro em df",
                                    "Ignorar distribuição qui-quadrado no LM"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e validar especificação do modelo",
                                  "subSteps": [
                                    "Se p-value < α, rejeite H0: variável omitida é relevante, reespecifique modelo.",
                                    "Se p-value ≥ α, aceite H0: modelo restrito é adequado.",
                                    "Compare R² ajustado, AIC/BIC entre modelos.",
                                    "Reporte conclusão com intervalo de confiança e implicações.",
                                    "Documente relatório final com gráficos (resíduos vs. fitted)."
                                  ],
                                  "verification": "Conclusão clara sobre especificação, com relatório e gráficos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Ferramentas de plot: ggplot2 (R), matplotlib/seaborn (Python)"
                                  ],
                                  "tips": "Considere poder do teste; valide com testes robustos (ex: RESET).",
                                  "learningObjective": "Interpretar testes para decisões de modelagem robustas.",
                                  "commonMistakes": [
                                    "Ignorar evidência fraca (p próximo a α)",
                                    "Não reportar múltiplos critérios",
                                    "Conclusão sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em análise de eficiência energética de edifícios, modelo restrito: Consumo = β0 + β1*Área + ε. Suspeita: omitiu Isolamento. Irrestrito: + β2*Isolamento. Teste F rejeita H0 (p<0.01), indicando necessidade de inclusão para predições precisas.",
                              "finalVerifications": [
                                "Hipóteses corretamente formuladas e testadas.",
                                "Modelos aninhados estimados com diagnósticos.",
                                "Estatística do teste (F/LM) e p-value calculados.",
                                "Conclusão alinhada com resultados e teoria.",
                                "Relatório com R², SSE e gráficos de resíduos.",
                                "Implicações para contexto (ex: engenharia energética) discutidas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação de H0/H1 (30%).",
                                "Correta construção e estimação de modelos (25%).",
                                "Execução impecável do teste estatístico (20%).",
                                "Interpretação contextualizada e decisão robusta (15%).",
                                "Relatório claro com visualizações (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Testes de especificação em regressão.",
                                "Engenharia Elétrica: Modelagem de sistemas energéticos.",
                                "Ciência de Dados: Validação de features em ML.",
                                "Estatística Aplicada: Inferência em dados observacionais."
                              ],
                              "realWorldApplication": "Na engenharia de energia, valida modelos de previsão de consumo em edifícios inteligentes, evitando subestimação de eficiência devido a omissões, otimizando designs sustentáveis e políticas de retrofit."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.2.4.2.3",
                            "name": "Interpretar falhas de especificação e correções",
                            "description": "Diagnosticar problemas como não-linearidade ou multicolinearidade via testes e propor correções como polinômios, logs ou MQG, com referência a Gujarati e Greene para aplicações em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar falhas comuns de especificação em modelos de regressão",
                                  "subSteps": [
                                    "Estude definições de falhas como não-linearidade funcional, multicolinearidade e variáveis omitidas.",
                                    "Revise capítulos relevantes em Gujarati (Cap. 8-9) e Greene (Cap. 4-5) sobre especificação de modelos.",
                                    "Liste exemplos de impactos: viés nos coeficientes, ineficiência ou inconsistência.",
                                    "Classifique falhas por tipo usando diagramas de Venn para sobreposições.",
                                    "Anote sintomas observáveis nos resíduos ou matriz de correlação."
                                  ],
                                  "verification": "Crie um mapa mental resumindo 5 falhas principais com exemplos e referências aos livros.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livros: Gujarati 'Basic Econometrics', Greene 'Econometric Analysis'; caderno ou ferramenta digital como MindMeister.",
                                  "tips": "Comece com não-linearidade, pois é comum em dados de engenharia não-lineares.",
                                  "learningObjective": "Compreender as causas e consequências das principais falhas de especificação.",
                                  "commonMistakes": "Confundir multicolinearidade com correlação perfeita; ignorar variáveis omitidas endógenas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar testes diagnósticos para falhas de especificação",
                                  "subSteps": [
                                    "Implemente teste de Ramsey RESET para não-linearidade em Python (statsmodels) ou R.",
                                    "Calcule VIF (Variance Inflation Factor) para multicolinearidade, threshold >5 ou >10.",
                                    "Aplique teste de Hausman ou LM para variáveis omitidas.",
                                    "Gere gráficos de resíduos vs. preditos e Q-Q plots para inspeção visual.",
                                    "Documente p-valores e estatísticas em uma tabela comparativa."
                                  ],
                                  "verification": "Execute testes em um dataset de amostra e produza relatório com resultados numéricos e gráficos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (statsmodels, pandas), R (lmtest, car); dataset exemplo como 'mtcars' adaptado para engenharia.",
                                  "tips": "Use VIF iterativamente: remova variáveis com VIF alto uma a uma.",
                                  "learningObjective": "Dominar testes estatísticos para diagnosticar falhas específicas.",
                                  "commonMistakes": "Interpretar p-valor <0.05 como falha sem contexto de poder do teste; ignorar tamanho da amostra."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar resultados dos testes e diagnosticar problemas",
                                  "subSteps": [
                                    "Analise p-valores: rejeite H0 se evidência de falha (ex: RESET p<0.05 indica não-linearidade).",
                                    "Correlacione achados visuais (curvas em resíduos) com testes formais.",
                                    "Priorize falhas: multicolinearidade primeiro se VIF alto, depois funcional form.",
                                    "Referencie Gujarati (p. 225-230) para interpretação em contextos de engenharia.",
                                    "Escreva diagnóstico narrativo: 'Evidência de não-linearidade devido a RESET F=4.2, p=0.01'."
                                  ],
                                  "verification": "Redija um parágrafo diagnóstico para um output de teste simulado.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Resultados de testes do Step 2; Greene Cap. 7 para exemplos.",
                                  "tips": "Sempre cheque múltiplos testes para confirmação cruzada.",
                                  "learningObjective": "Interpretar outputs de testes para identificar falhas precisas.",
                                  "commonMistakes": "Sobre-generalizar uma falha única; negligenciar interações entre falhas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Propor e implementar correções para falhas diagnosticadas",
                                  "subSteps": [
                                    "Para não-linearidade: adicione termos polinomiais (x^2) ou transforms log (log(y)).",
                                    "Para multicolinearidade: use ridge regression ou remova variáveis.",
                                    "Implemente MQG (Modelos Generalizados de Quantile) via statsmodels para heteroscedasticidade associada.",
                                    "Re-teste o modelo corrigido e compare AIC/BIC.",
                                    "Documente mudanças com referência a Greene (Cap. 9) para aplicações em dados de engenharia."
                                  ],
                                  "verification": "Aplique correção em dataset, mostre melhora em testes (ex: VIF reduzido).",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Python/R com statsmodels.quantreg; Gujarati Cap. 10.",
                                  "tips": "Comece com transforms simples antes de MQG complexo.",
                                  "learningObjective": "Selecionar e aplicar correções apropriadas com validação.",
                                  "commonMistakes": "Aplicar polinômios sem centrar variáveis (multicolinearidade induzida); ignorar overfitting."
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia de produção de energia (ex: kW vs. temperatura, carga), detecte não-linearidade via RESET (p=0.002), adicione log(temperatura), re-teste VIF=1.2 (melhora de 8.5), aplicando MQG para prever quantis de falha em turbinas.",
                              "finalVerifications": [
                                "Testes pós-correção mostram p>0.05 em falhas originais.",
                                "VIF de todas variáveis <5.",
                                "Resíduos aleatórios em plots (sem padrões).",
                                "AIC/BIC reduzido em >10%.",
                                "Referências a Gujarati/Greene citadas corretamente.",
                                "Diagnóstico escrito explica causalidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de falhas (90% match com testes reais).",
                                "Correções apropriadas e justificadas (alinhadas a livros).",
                                "Implementação código sem erros e reproduzível.",
                                "Interpretação clara de resultados numéricos/visuais.",
                                "Melhoria mensurável no modelo (R² ajustado +5%).",
                                "Narrativa conecta teoria a prática de engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Uso de statsmodels em Python para automação de testes.",
                                "Engenharia: Aplicação em modelagem preditiva de sistemas mecânicos.",
                                "Estatística: Integração com inferência bayesiana para robustez.",
                                "Economia: Paralelos com econometria em otimização de custos."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, diagnosticar multicolinearidade em modelos de regressão para previsão de fadiga de materiais, corrigindo com logs/polinômios para evitar subestimação de riscos, economizando milhões em redesigns (ex: NASA datasets)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.3",
                "name": "Seleção de Modelos e Métodos Avançados",
                "description": "Aborda seleção de modelos, maximização de verossimilhança e métodos generalizados dos momentos para estimação robusta.",
                "totalSkills": 45,
                "atomicTopics": [
                  {
                    "id": "10.1.3.1",
                    "name": "Seleção de Modelos",
                    "description": "Técnicas e critérios para escolher o modelo estatístico mais adequado em regressões lineares e econométricas.",
                    "individualConcepts": [
                      {
                        "id": "11.3.1.1",
                        "name": "Critérios de Informação",
                        "description": "Critérios como AIC (Critério de Informação de Akaike) e BIC (Critério de Informação Bayesiano) utilizados para comparar modelos estatísticos, penalizando a complexidade para evitar overfitting em regressões lineares e econométricas.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.1.1",
                            "name": "Calcular o AIC de um modelo de regressão",
                            "description": "Aplicar a fórmula AIC = -2 ln(L) + 2k, onde L é a verossimilhança máxima e k o número de parâmetros, para avaliar a adequação de um modelo linear estimado por Mínimos Quadrados Ordinários (MQO).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e ajustar o modelo de regressão por MQO",
                                  "subSteps": [
                                    "Colete um conjunto de dados com variável dependente Y e independentes X1, X2, ..., Xp.",
                                    "Verifique premissas de MQO: linearidade, homocedasticidade, normalidade dos resíduos (opcional para AIC).",
                                    "Ajuste o modelo usando MQO para obter coeficientes β, número de observações n e Soma dos Quadrados dos Resíduos (RSS).",
                                    "Calcule n (número de observações) e p (número de parâmetros em β, incluindo intercepto).",
                                    "Registre RSS = Σ (Y_i - Ŷ_i)^2."
                                  ],
                                  "verification": "Confirme que o modelo foi ajustado corretamente comparando coeficientes com software padrão (ex: statsmodels em Python) e que RSS é positivo e finito.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Conjunto de dados (CSV ou Excel)",
                                    "Python com numpy, pandas, statsmodels ou R com lm()",
                                    "Calculadora para verificação manual"
                                  ],
                                  "tips": "Use funções prontas como sm.OLS em Python para agilizar; sempre centre as variáveis se necessário para estabilidade numérica.",
                                  "learningObjective": "Dominar o ajuste de modelo linear MQO e extração de estatísticas essenciais como RSS, n e p.",
                                  "commonMistakes": [
                                    "Esquecer o intercepto no count de p",
                                    "Usar n-p-1 em vez de n para σ² (MLE usa /n)",
                                    "Ignorar observações com missing values"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a estimativa de máxima verossimilhança para σ² e ln(L)",
                                  "subSteps": [
                                    "Calcule σ²_hat = RSS / n (estimador de máxima verossimilhança para variância).",
                                    "Compute o termo logarítmico: log(2π * σ²_hat).",
                                    "Calcule ln(L_max) = - (n/2) * log(2π * σ²_hat) - (n/2).",
                                    "Verifique numericamente se ln(L) é negativo (esperado para verossimilhança normalizada).",
                                    "Registre o valor exato de ln(L) com precisão decimal."
                                  ],
                                  "verification": "Compare ln(L) com fórmula implementada em software (ex: logLik em R) para modelo equivalente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Calculadora científica ou Python (numpy.log, math.pi)",
                                    "Planilha Excel para cálculos intermediários"
                                  ],
                                  "tips": "Use log(2π) ≈ 1.8379 pré-calculado; evite overflow dividindo cálculos grandes.",
                                  "learningObjective": "Entender e aplicar a fórmula de log-verossimilhança para erros normais em MQO.",
                                  "commonMistakes": [
                                    "Usar RSS/(n-p-1) em vez de RSS/n para MLE",
                                    "Esquecer o fator -n/2 no segundo termo",
                                    "Confundir log natural (ln) com log10"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Determinar o número de parâmetros k",
                                  "subSteps": [
                                    "Conte p = número de coeficientes β (intercepto + regressores).",
                                    "Adicione 1 para σ², totalizando k = p + 2 (padrão para modelo gaussiano MQO).",
                                    "Confirme se o modelo inclui intercepto; ajuste k se não.",
                                    "Documente k explicitamente, ex: para regressão simples com intercepto, k=3.",
                                    "Compare com documentação de software para consistência."
                                  ],
                                  "verification": "Verifique k manualmente listando parâmetros e comparando com output de AIC em pacotes como statsmodels.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Output do modelo ajustado",
                                    "Documentação de AIC para regressão linear"
                                  ],
                                  "tips": "Lembre: k inclui variância sempre em modelos normais; ignore para comparações relativas se consistente.",
                                  "learningObjective": "Identificar corretamente todos os parâmetros livres no modelo para penalização AIC.",
                                  "commonMistakes": [
                                    "Contar apenas regressores, esquecendo intercepto e σ²",
                                    "Usar k=p+1 sem σ²",
                                    "Variar k entre modelos inconsistemente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a fórmula AIC e interpretar o resultado",
                                  "subSteps": [
                                    "Calcule o termo de ajuste: 2 * k.",
                                    "Compute AIC = -2 * ln(L_max) + 2 * k.",
                                    "Arredonde para 2 casas decimais se necessário.",
                                    "Compare AIC com outro modelo (menor AIC indica melhor ajuste penalizado).",
                                    "Interprete: diferença ΔAIC > 2 sugere superioridade."
                                  ],
                                  "verification": "Replique AIC exato usando função pronta (ex: model.aic em statsmodels) e confirme igualdade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Valores de ln(L) e k do passo anterior",
                                    "Python/R para validação automática"
                                  ],
                                  "tips": "AIC é relativo; use para ranking, não absoluto; valores negativos são comuns.",
                                  "learningObjective": "Executar o cálculo final do AIC e usá-lo para seleção de modelos.",
                                  "commonMistakes": [
                                    "Inverter sinal: usar +2 ln(L)",
                                    "Esquecer multiplicar por 2 em ambos termos",
                                    "Interpretar AIC como erro absoluto"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados de 30 funcionários: Y = salário (R$/mês), X = anos de experiência. Modelo: salário = 2000 + 100*experiência + ε. Após MQO: n=30, RSS=50000, p=2 (intercepto+1 regressor), σ²_hat=50000/30≈1666.67, ln(L)≈ -142.5, k=3, AIC≈ -2*(-142.5) + 2*3 = 292.",
                              "finalVerifications": [
                                "AIC calculado bate com software padrão (diferença <0.01).",
                                "ln(L) negativo e magnitude razoável para n.",
                                "k correto (p+2 para MQO gaussiano).",
                                "RSS positivo e σ²_hat >0.",
                                "Fórmula aplicada sem erros aritméticos.",
                                "Comparação com modelo nulo mostra penalização por complexidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de ln(L) e k (100% correto).",
                                "Explicação clara das premissas MQO e MLE.",
                                "Uso correto de substeps em todos os passos.",
                                "Interpretação adequada do AIC em contexto de seleção.",
                                "Identificação de erros comuns evitados.",
                                "Exemplo prático reproduzível e validado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses para resíduos.",
                                "Programação: Implementação em Python/R para automação.",
                                "Machine Learning: Seleção de features e overfitting avoidance.",
                                "Econometria: Aplicação em modelos de painel e séries temporais.",
                                "Cálculo: Derivação da log-verossimilhança via maximização."
                              ],
                              "realWorldApplication": "Em data science, calcular AIC para escolher entre modelos lineares em previsão de vendas (ex: comparar com e sem variáveis sazonais), evitando overfitting em análises de risco financeiro ou epidemiologia (selecionar melhores preditores de infecções)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.2",
                            "name": "Calcular o BIC de um modelo de regressão",
                            "description": "Utilizar a fórmula BIC = -2 ln(L) + k ln(n), com n como tamanho da amostra, para selecionar modelos em contextos econométricos aplicados à engenharia, comparando com AIC.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a fórmula BIC e seus componentes",
                                  "subSteps": [
                                    "Estude a fórmula BIC = -2 * ln(L) + k * ln(n), onde L é a verossimilhança máxima, k é o número de parâmetros e n é o tamanho da amostra.",
                                    "Identifique diferenças entre BIC e AIC: BIC penaliza mais modelos complexos devido a ln(n) em vez de 2.",
                                    "Revise conceitos de log-verossimilhança em regressão linear: ln(L) = -n/2 * ln(2πσ²) - RSS/(2σ²).",
                                    "Liste exemplos de contextos econométricos em engenharia, como seleção de modelos para previsão de demanda energética.",
                                    "Anote definições de n (número de observações) e k (intercepto + preditores + variância)."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula BIC, seus componentes e diferença para AIC, com um exemplo simples.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Documentação de econometria (ex: Wooldridge)",
                                    "Notebook Jupyter ou papel para anotações"
                                  ],
                                  "tips": "Memorize a penalização extra do BIC para amostras grandes, favorecendo parcimônia.",
                                  "learningObjective": "Dominar os componentes teóricos do BIC para aplicação em seleção de modelos.",
                                  "commonMistakes": [
                                    "Confundir k (parâmetros) com número de preditores",
                                    "Ignorar o termo ln(n) na penalização",
                                    "Confundir ln(L) com L diretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar dados e ajustar modelo de regressão",
                                  "subSteps": [
                                    "Carregue um dataset econométrico relevante, como dados de produção industrial vs. investimento em engenharia (ex: dataset do Banco Mundial).",
                                    "Divida em treino/teste e ajuste um modelo de regressão linear usando biblioteca como statsmodels em Python.",
                                    "Extraia sumário do modelo: número de observações (n), parâmetros estimados (k), log-likelihood (ln(L)).",
                                    "Calcule resíduos e variância residual (σ²) se necessário para verificar ln(L).",
                                    "Repita para um modelo baseline simples para comparação futura."
                                  ],
                                  "verification": "Execute o código e confirme que o sumário mostra n, k e log-likelihood corretos.",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": [
                                    "Python com statsmodels/sklearn",
                                    "Dataset CSV de exemplo (ex: produção vs. PIB)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use sm.OLS para regressão com log-likelihood automático; verifique n > 30 para validade assintótica.",
                                  "learningObjective": "Adquirir prática em ajuste de modelos e extração de métricas essenciais para BIC.",
                                  "commonMistakes": [
                                    "Incluir variáveis com multicolinearidade sem checagem",
                                    "Esquecer de contar o intercepto em k",
                                    "Usar dados com missing values sem tratamento"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular o BIC usando a fórmula",
                                  "subSteps": [
                                    "Obtenha valores: ln(L) do sumário, k = len(params) + 1 (variância), n = len(dados).",
                                    "Compute termo 1: -2 * ln(L).",
                                    "Compute termo 2: k * log(n) (use np.log para ln natural).",
                                    "Some os termos: BIC = termo1 + termo2.",
                                    "Implemente em código ou calculadora, arredondando para 2 casas decimais."
                                  ],
                                  "verification": "Compare BIC calculado manualmente com o BIC automático da biblioteca (model.bic).",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Código Python do Step 2",
                                    "Calculadora ou função np.log",
                                    "Documentação statsmodels"
                                  ],
                                  "tips": "Sempre use log natural (ln), não log10; valide com modelo conhecido (ex: BIC ~ 100-200 para bons fits).",
                                  "learningObjective": "Executar cálculo preciso do BIC a partir de outputs de modelo.",
                                  "commonMistakes": [
                                    "Usar log-likelihood em vez de ln(L)",
                                    "Contar k errado (esquecer variância)",
                                    "Confundir n com tamanho de treino apenas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar BIC com AIC e interpretar resultados",
                                  "subSteps": [
                                    "Calcule AIC do mesmo modelo: AIC = -2*ln(L) + 2*k para comparação.",
                                    "Compare BIC de múltiplos modelos: menor BIC indica melhor modelo.",
                                    "Interprete: BIC favorece modelos mais simples em n grande; discuta trade-off viés-variância.",
                                    "Aplique em contexto engenharia: selecione modelo para previsão de custos em projetos econométricos.",
                                    "Documente conclusão: 'Modelo X com BIC=150 é preferível ao Y com BIC=170'."
                                  ],
                                  "verification": "Gere tabela comparativa de BIC/AIC e justifique seleção do melhor modelo.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Resultados dos Steps anteriores",
                                    "Excel ou pandas para tabela"
                                  ],
                                  "tips": "ΔBIC < 2: similar; 2-6: forte evidência; >10: decisiva contra modelo pior.",
                                  "learningObjective": "Usar BIC para seleção de modelos em cenários reais de engenharia econômica.",
                                  "commonMistakes": [
                                    "Preferir modelo com menor k sem checar fit",
                                    "Ignorar tamanho n na interpretação",
                                    "Confundir BIC menor com melhor fit absoluto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de 200 observações de consumo energético industrial (Y) vs. investimento em infraestrutura (X1), PIB (X2) e taxa de juros (X3), ajuste M1: apenas X1 (k=2); M2: todos (k=5). Calcule BIC_M1 = -2*(-150) + 2*ln(200) ≈ 300 + 10.6 = 310.6; BIC_M2 ≈ 290 + 26.5 = 316.5. Selecione M1 por BIC menor, ideal para previsão parsimoniosa em engenharia.",
                              "finalVerifications": [
                                "Calcule BIC corretamente para um modelo dado com ln(L)=-100, k=4, n=100 (resposta esperada: ≈ 248.4).",
                                "Explique por que BIC penaliza mais que AIC em n=1000.",
                                "Compare BIC de dois modelos e selecione o melhor justificando.",
                                "Identifique k corretamente em um sumário de regressão múltipla.",
                                "Aplique BIC em um mini-dataset manual de 10 linhas.",
                                "Verifique consistência com biblioteca statsmodels.bic."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo da fórmula BIC (erro <1%).",
                                "Correta extração de n, k e ln(L) do modelo ajustado.",
                                "Interpretação adequada da comparação BIC vs. AIC.",
                                "Aplicação contextual em econometria de engenharia.",
                                "Código reproduzível e documentado.",
                                "Identificação de erros comuns evitados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência bayesiana aproximada via BIC.",
                                "Engenharia Econômica: Seleção de modelos preditivos para otimização de projetos.",
                                "Computação: Implementação numérica em Python/R para análise de dados.",
                                "Economia: Econometria para testes de hipóteses em séries temporais.",
                                "Matemática: Otimização e funções logarítmicas."
                              ],
                              "realWorldApplication": "Em engenharia de projetos sustentáveis, use BIC para selecionar o melhor modelo econométrico que prevê demanda de energia baseada em variáveis macroeconômicas, evitando overfitting e garantindo previsões robustas para planejamento de infraestrutura com orçamentos limitados."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.3",
                            "name": "Comparar modelos usando AIC e BIC",
                            "description": "Interpretar valores de AIC e BIC para escolher o modelo com menor critério, considerando penalidades por parâmetros extras em regressões lineares com dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de AIC e BIC",
                                  "subSteps": [
                                    "Estude a fórmula do AIC: AIC = 2k - 2 ln(L), onde k é o número de parâmetros e L é a verossimilhança máxima.",
                                    "Analise a fórmula do BIC: BIC = k ln(n) - 2 ln(L), destacando a penalidade maior por parâmetros extras com n (tamanho da amostra).",
                                    "Compare as diferenças: BIC penaliza mais modelos complexos, favorecendo simplicidade em amostras grandes.",
                                    "Revise interpretações: menor valor indica melhor equilíbrio entre ajuste e complexidade.",
                                    "Examine exemplos teóricos com regressões lineares simples."
                                  ],
                                  "verification": "Escreva um resumo de 100 palavras explicando a diferença entre AIC e BIC, incluindo fórmulas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Documentação oficial de AIC/BIC (Wikipedia ou statsmodels docs)",
                                    "Notebook Jupyter para anotações"
                                  ],
                                  "tips": "Visualize as penalidades plotando k vs. penalidade para diferentes n.",
                                  "learningObjective": "Dominar as fórmulas matemáticas e interpretações conceituais de AIC e BIC.",
                                  "commonMistakes": [
                                    "Confundir verossimilhança com RSS (Residual Sum of Squares)",
                                    "Ignorar que ambos assumem normalidade nos erros",
                                    "Achar que menor AIC sempre significa melhor previsão fora da amostra"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Dados de Engenharia e Ajustar Modelos Lineares",
                                  "subSteps": [
                                    "Carregue um dataset de engenharia, como dados de tensão vs. deformação em materiais.",
                                    "Explore os dados: verifique multicolinearidade, outliers e distribuições com plots (scatter, histogram).",
                                    "Defina dois modelos lineares: M1 simples (1 preditora) e M2 complexo (2+ preditoras).",
                                    "Ajuste os modelos usando statsmodels em Python: sm.OLS(y, X).fit().",
                                    "Extraia log-likelihood e número de parâmetros de cada modelo ajustado."
                                  ],
                                  "verification": "Confirme que ambos os modelos foram ajustados sem erros e extraia summary() para cada um.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com statsmodels e pandas",
                                    "Dataset exemplo: dados de engenharia (e.g., concrete strength do UCI ML Repo)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Padronize variáveis preditoras para melhor convergência.",
                                  "learningObjective": "Preparar dados reais de engenharia e ajustar múltiplos modelos lineares comparáveis.",
                                  "commonMistakes": [
                                    "Não tratar missing values ou outliers",
                                    "Incluir variáveis irrelevantes sem justificativa",
                                    "Usar sklearn em vez de statsmodels (que não tem AIC/BIC nativo)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e Comparar Valores de AIC e BIC",
                                  "subSteps": [
                                    "Acesse .aic e .bic diretamente dos modelos ajustados em statsmodels.",
                                    "Calcule manualmente para validar: use np.log() para ln(L) e len(params) para k.",
                                    "Crie uma tabela comparativa: colunas para Modelo, k, ln(L), AIC, BIC.",
                                    "Identifique o modelo com menor AIC e menor BIC separadamente.",
                                    "Analise discrepâncias: se AIC e BIC divergem, discuta impacto de n."
                                  ],
                                  "verification": "Gere uma tabela Pandas mostrando AIC/BIC para ambos modelos, com o menor destacado.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código Python do Step 2",
                                    "Bibliotecas: statsmodels, pandas, numpy"
                                  ],
                                  "tips": "Salve resultados em DataFrame para fácil visualização e exportação.",
                                  "learningObjective": "Executar cálculos precisos de AIC/BIC e organizar comparações.",
                                  "commonMistakes": [
                                    "Esquecer de incluir intercepto em k",
                                    "Usar ln(n) incorreto (n deve ser len(y))",
                                    "Comparar AIC entre datasets de tamanhos diferentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Selecionar o Melhor Modelo",
                                  "subSteps": [
                                    "Escolha o modelo com menor BIC (mais conservador para engenharia).",
                                    "Avalie trade-offs: ajuste (R²) vs. penalidade por parâmetros extras.",
                                    "Teste robustez: use cross-validation para validar escolha fora da amostra.",
                                    "Documente razões: e.g., 'M1 escolhido por BIC 10% menor apesar de R² ligeiramente inferior'.",
                                    "Discuta limitações em dados de engenharia (e.g., não-estacionariedade)."
                                  ],
                                  "verification": "Escreva um parágrafo justificando a seleção final do modelo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resultados dos steps anteriores",
                                    "Funções de CV do scikit-learn"
                                  ],
                                  "tips": "Priorize BIC em amostras >100 para evitar overfitting em aplicações de engenharia.",
                                  "learningObjective": "Interpretar critérios no contexto de dados reais e selecionar modelo otimizado.",
                                  "commonMistakes": [
                                    "Escolher sempre o modelo mais complexo por melhor ajuste",
                                    "Ignorar tamanho da amostra na escolha entre AIC/BIC",
                                    "Não considerar diagnósticos residuais pós-seleção"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia de materiais (e.g., compressive strength de concreto com variáveis como cimento, água, idade), ajuste M1: strength ~ cement, e M2: strength ~ cement + water + age. Calcule AIC/BIC; se BIC_M1=250 e BIC_M2=260, selecione M1 por menor penalidade, interpretando que parâmetros extras não justificam ganho em verossimilhança.",
                              "finalVerifications": [
                                "Calcular manualmente AIC/BIC para um modelo dado e coincidir com statsmodels.",
                                "Comparar corretamente dois modelos e justificar escolha com tabela.",
                                "Explicar por que BIC penaliza mais em n=200 vs. AIC.",
                                "Identificar overfitting em modelo com AIC baixo mas BIC alto.",
                                "Aplicar a um novo dataset de engenharia e documentar processo.",
                                "Discutir limitações (e.g., assume erros normais)."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de AIC/BIC (erro <1%).",
                                "Correta interpretação de penalidades por k e n.",
                                "Justificativa contextual para seleção em dados de engenharia.",
                                "Uso adequado de ferramentas computacionais sem erros.",
                                "Análise de trade-offs entre simplicidade e ajuste.",
                                "Documentação clara com tabelas e plots."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses para validação.",
                                "Programação: Implementação em Python/R com statsmodels.",
                                "Engenharia: Modelagem preditiva para otimização de processos.",
                                "Ciência de Dados: Feature selection e validação cruzada.",
                                "Matemática: Otimização e funções logarítmicas."
                              ],
                              "realWorldApplication": "Em engenharia civil, comparar modelos para prever resistência de vigas sob carga; modelo com menor BIC otimiza design, reduzindo custos computacionais e riscos de overfitting em simulações de falhas estruturais."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.2",
                        "name": "R² Ajustado e Testes de Significância",
                        "description": "Uso do coeficiente de determinação ajustado (R² ajustado) e testes F para avaliar a significância global do modelo e seleção de variáveis relevantes em regressões econométricas.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.2.1",
                            "name": "Calcular e interpretar R² ajustado",
                            "description": "Computar R² ajustado = 1 - [(1 - R²)(n-1)/(n-k-1)] para penalizar a inclusão de variáveis irrelevantes em modelos de regressão linear.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o R² e suas limitações",
                                  "subSteps": [
                                    "Revise a definição de R² como a proporção da variância total explicada pelo modelo.",
                                    "Identifique limitações: R² sempre aumenta com mais variáveis, mesmo irrelevantes.",
                                    "Discuta overfitting e necessidade de penalização por número de preditores.",
                                    "Explique os termos n (número de observações) e k (número de preditores).",
                                    "Compare R² vs R² ajustado em cenários simples."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito por que R² não penaliza complexidade e dê um exemplo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão linear",
                                    "Gráfico comparativo de R²"
                                  ],
                                  "tips": "Use analogias como 'adicionar ingredientes ruins a uma receita sempre 'melhora' o sabor no R²'.",
                                  "learningObjective": "Entender por que o R² ajustado é necessário para seleção de modelos justa.",
                                  "commonMistakes": [
                                    "Confundir R² com precisão absoluta do modelo.",
                                    "Ignorar que k inclui apenas preditores, não a constante."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Memorizar e derivar a fórmula do R² ajustado",
                                  "subSteps": [
                                    "Escreva a fórmula: R²_adj = 1 - [(1 - R²)(n-1)/(n-k-1)].",
                                    "Derive intuitivamente: divide graus de liberdade (n-1)/(n-k-1) para penalizar k.",
                                    "Identifique componentes: R² original, n (amostra), k (preditores).",
                                    "Pratique reescrevendo a fórmula de memória.",
                                    "Calcule os graus de liberdade para exemplos simples (ex: n=10, k=1)."
                                  ],
                                  "verification": "Reescreva a fórmula corretamente e explique cada termo.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Fórmula impressa para referência inicial"
                                  ],
                                  "tips": "Lembre-se: denominador n-k-1 é graus de liberdade do resíduo.",
                                  "learningObjective": "Dominar a fórmula e sua lógica de penalização.",
                                  "commonMistakes": [
                                    "Usar k incluindo intercepto (não incluir).",
                                    "Confundir n-1 com n no numerador."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar o cálculo do R² ajustado",
                                  "subSteps": [
                                    "Obtenha valores: R², n e k de um modelo de exemplo.",
                                    "Calcule (1 - R²).",
                                    "Multiplique por (n-1)/(n-k-1).",
                                    "Subtraia de 1 para obter R²_adj.",
                                    "Verifique se R²_adj < R² quando k aumenta."
                                  ],
                                  "verification": "Calcule R²_adj para dados dados e confira com software.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora ou Excel",
                                    "Dados de exemplo: n=30, k=3, R²=0.75"
                                  ],
                                  "tips": "Use parênteses para evitar erros de ordem de operações.",
                                  "learningObjective": "Executar o cálculo manual com precisão.",
                                  "commonMistakes": [
                                    "Erro aritmético no denominador (n-k-1).",
                                    "Usar valores errados de k."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar e aplicar o R² ajustado",
                                  "subSteps": [
                                    "Compare R²_adj com R²: menor indica penalização por complexidade.",
                                    "Interprete valores: >0.8 bom ajuste ajustado; queda grande sugere variáveis desnecessárias.",
                                    "Decida: prefira modelo com maior R²_adj entre candidatos.",
                                    "Discuta limites: não mede causalidade, sensível a n pequeno.",
                                    "Aplique em seleção stepwise ou comparação de modelos."
                                  ],
                                  "verification": "Interprete dois modelos: um com R²_adj=0.82, outro 0.78, escolhendo o melhor.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Tabela de modelos comparativos",
                                    "Software como R ou Python para validação"
                                  ],
                                  "tips": "Sempre reporte R²_adj em relatórios, não só R².",
                                  "learningObjective": "Usar R²_adj para decisões de modelagem.",
                                  "commonMistakes": [
                                    "Interpretar como probabilidade de previsão.",
                                    "Ignorar contexto de n pequeno (penalização exagerada)."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de 50 salários (n=50) com 4 preditores (k=4), R²=0.85. Calcule: (1-0.85)=0.15; (49/45)=1.0889; 0.15*1.0889=0.1633; R²_adj=1-0.1633=0.8367. Note queda de 0.85 para 0.8367 devido à penalização.",
                              "finalVerifications": [
                                "Calcule corretamente R²_adj para 3 exemplos variados.",
                                "Explique por que R²_adj cai com mais k.",
                                "Compare dois modelos e selecione o melhor por R²_adj.",
                                "Identifique erros comuns na fórmula.",
                                "Aplique em contexto real de regressão."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo da fórmula (100% correto).",
                                "Compreensão conceitual demonstrada em explicações.",
                                "Capacidade de interpretação comparativa.",
                                "Identificação de limitações e erros potenciais.",
                                "Aplicação prática em exemplos.",
                                "Clareza na comunicação de resultados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes F para significância.",
                                "Programação: Implementar em Python (statsmodels) ou R.",
                                "Machine Learning: Seleção de features e AIC/BIC.",
                                "Econometria: Modelos de painel e multicolinearidade."
                              ],
                              "realWorldApplication": "Em análise preditiva de vendas, use R² ajustado para escolher entre modelos com 5 vs 10 variáveis, evitando overfitting e garantindo generalização em novos dados de mercado."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.2",
                            "name": "Realizar teste F para significância global",
                            "description": "Aplicar o teste F = [R²/k] / [(1-R²)/(n-k-1)] para verificar se o modelo como um todo explica a variabilidade dos dados em contextos de análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e calcular estatísticas preliminares",
                                  "subSteps": [
                                    "Colete os dados de regressão linear múltipla ou simples do modelo ajustado.",
                                    "Calcule o coeficiente de determinação R² usando software ou fórmula manual.",
                                    "Identifique o número de observações n e o número de parâmetros k (incluindo intercepto).",
                                    "Verifique a adequação dos dados, removendo outliers se necessário.",
                                    "Registre todos os valores em uma tabela organizada."
                                  ],
                                  "verification": "Compare R², n e k com saída de software como Python (statsmodels) ou R para confirmar exatidão.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Conjunto de dados de exemplo em CSV",
                                    "Software: Python com pandas/statsmodels ou Excel/R",
                                    "Calculadora científica"
                                  ],
                                  "tips": "Sempre inclua o intercepto em k; use funções prontas para validar cálculos manuais.",
                                  "learningObjective": "Compreender e coletar os insumos necessários (R², n, k) para o teste F.",
                                  "commonMistakes": [
                                    "Confundir k com número de variáveis independentes sem intercepto",
                                    "Usar n incorreto excluindo observações inválidas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os componentes da estatística F",
                                  "subSteps": [
                                    "Calcule o numerador: R² / k.",
                                    "Calcule o denominador: (1 - R²) / (n - k - 1).",
                                    "Divida numerador por denominador para obter F observado.",
                                    "Anote os graus de liberdade: df1 = k, df2 = n - k - 1.",
                                    "Valide o cálculo com uma segunda ferramenta computacional."
                                  ],
                                  "verification": "F calculado deve coincidir com output de função de regressão (ex: f_statistic em statsmodels).",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Folha de cálculo ou caderno para anotações",
                                    "Tabelas de distribuição F (opcional)",
                                    "Software de regressão"
                                  ],
                                  "tips": "Use frações exatas antes de arredondar para evitar erros de precisão.",
                                  "learningObjective": "Dominar a fórmula F = (R²/k) / ((1-R²)/(n-k-1)) e seus componentes.",
                                  "commonMistakes": [
                                    "Arredondar prematuramente levando a discrepâncias",
                                    "Invertar numerador e denominador"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Determinar valor crítico ou p-value",
                                  "subSteps": [
                                    "Escolha o nível de significância α (ex: 0.05).",
                                    "Consulte tabela F ou use função para valor crítico com df1=k, df2=n-k-1.",
                                    "Calcule p-value usando software (ex: 1 - f.cdf(F_obs, df1, df2) em SciPy).",
                                    "Compare F_obs com F_crítico ou verifique se p-value < α.",
                                    "Registre a decisão preliminar (rejeitar H0 ou não)."
                                  ],
                                  "verification": "p-value deve bater com software padrão; teste com dados conhecidos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Tabela de distribuição F impressa ou online",
                                    "Python com scipy.stats ou R",
                                    "Calculadora gráfica"
                                  ],
                                  "tips": "Prefira p-value a tabelas para precisão; memorize df para casos comuns.",
                                  "learningObjective": "Aplicar testes de hipótese usando distribuição F para significância.",
                                  "commonMistakes": [
                                    "Usar df incorretos",
                                    "Confundir α com p-value na interpretação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultado e concluir significância global",
                                  "subSteps": [
                                    "Enuncie hipóteses: H0 (modelo não significativo) vs HA (modelo significativo).",
                                    "Baseado em p-value ou F_obs > F_crítico, decida rejeitar H0.",
                                    "Discuta implicações: modelo explica variabilidade? Qual %?",
                                    "Reporte F, df, p-value em formato padrão (ex: F(k, n-k-1) = valor, p = valor).",
                                    "Sugira próximos passos se não significativo (ex: adicionar variáveis)."
                                  ],
                                  "verification": "Conclusão alinhada com critérios estatísticos padrão e justificada por escrito.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Modelo de relatório estatístico",
                                    "Software para gerar sumário de regressão"
                                  ],
                                  "learningObjective": "Interpretar teste F no contexto de validação de modelo de regressão.",
                                  "commonMistakes": [
                                    "Ignorar premissas do teste F (normalidade, etc.)",
                                    "Concluir causalidade de significância"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia mecânica, modelo de regressão para prever resistência à tração (Y) de ligas baseado em temperatura (X1) e tempo de tratamento (X2). Dados: n=25, k=3 (intercepto + 2 vars), R²=0.82. Calcule F = (0.82/2) / ((1-0.82)/(25-3-1)) ≈ 14.5. df1=2, df2=21. p-value ≈ 0.0001 < 0.05 → modelo globalmente significativo.",
                              "finalVerifications": [
                                "F calculado corretamente com fórmula exata.",
                                "Graus de liberdade df1=k e df2=n-k-1 identificados.",
                                "p-value ou comparação com F_crítico precisa.",
                                "Hipótese nula rejeitada/aceita com justificativa.",
                                "Relatório inclui todos valores chave (F, df, p, R²).",
                                "Premissas do teste (linearidade, homocedasticidade) mencionadas."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática em todos cálculos (>95% exatidão).",
                                "Correta identificação e uso de n, k, R².",
                                "Interpretação estatística apropriada (rejeição H0).",
                                "Clareza no relatório com formatação padrão.",
                                "Validação cruzada com software.",
                                "Consideração de limitações do teste F."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Hipóteses e distribuições.",
                                "Programação: Implementação em Python/R para automação.",
                                "Engenharia de Dados: Validação de modelos preditivos.",
                                "Matemática Aplicada: Álgebra linear em regressão.",
                                "Ciência de Dados: Integração com R² ajustado."
                              ],
                              "realWorldApplication": "Na indústria aeroespacial, engenheiros usam teste F para validar modelos de regressão que preveem falhas estruturais baseados em variáveis como estresse e fadiga, garantindo que o modelo explique >70% da variabilidade antes de deploy em simulações de segurança."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.3",
                            "name": "Interpretar testes t para seleção de variáveis",
                            "description": "Usar estatísticas t individuais para eliminar variáveis não significativas (p-valor > 0.05), auxiliando na simplificação do modelo econométrico.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os componentes do teste t em regressão linear",
                                  "subSteps": [
                                    "Estude a hipótese nula (H0: coeficiente β = 0) e hipótese alternativa (H1: β ≠ 0).",
                                    "Identifique as colunas na saída de summary(): 'Estimate' (coeficiente), 'Std. Error', 't value' (estatística t) e 'Pr(>|t|)' (p-valor).",
                                    "Revise a fórmula da estatística t: t = β / SE(β).",
                                    "Pratique interpretando um exemplo simples de output de regressão.",
                                    "Anote o nível de significância convencional (α = 0.05)."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito os quatro componentes principais do teste t e seu significado.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "RStudio ou Jupyter Notebook com Python (statsmodels)",
                                    "Documentação de lm() no R ou statsmodels OLS",
                                    "Dataset exemplo: mtcars ou dados econômicos simples"
                                  ],
                                  "tips": "Use gráficos de distribuição t para visualizar rejeição de H0.",
                                  "learningObjective": "Dominar os fundamentos teóricos do teste t para interpretação precisa.",
                                  "commonMistakes": [
                                    "Confundir estatística t com p-valor",
                                    "Ignorar o grau de liberdade na distribuição t",
                                    "Assumir normalidade sem verificação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Extrair e analisar p-valores individuais das variáveis",
                                  "subSteps": [
                                    "Execute um modelo de regressão com múltiplas variáveis (ex: lm(y ~ x1 + x2 + x3)).",
                                    "Capture a tabela de summary() e liste p-valores para cada variável.",
                                    "Classifique variáveis: p ≤ 0.05 (significativa), p > 0.05 (não significativa).",
                                    "Calcule manualmente t para uma variável e compare com output.",
                                    "Registre razões potenciais para não significância (multicolinearidade, amostra pequena)."
                                  ],
                                  "verification": "Gere um relatório com lista de p-valores e classificação de cada variável.",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": [
                                    "R ou Python script pronto",
                                    "Dataset com 5+ variáveis preditoras (ex: dados de salários vs educação, experiência)"
                                  ],
                                  "tips": "Sempre inclua intercepto e verifique diagnósticos residuais primeiro.",
                                  "learningObjective": "Habilitar extração precisa e análise inicial de significância estatística.",
                                  "commonMistakes": [
                                    "Ler p-valor errado (ex: confundir com estrelas de significância)",
                                    "Ignorar variáveis com p próximo a 0.05",
                                    "Não considerar direção do coeficiente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar critério de eliminação baseado em p-valor > 0.05",
                                  "subSteps": [
                                    "Selecione variáveis com p > 0.05 para remoção, priorizando as maiores.",
                                    "Reexecute o modelo sem essas variáveis (iterativo se necessário).",
                                    "Compare R² ajustado antes/depois para confirmar simplificação sem perda de ajuste.",
                                    "Documente a decisão em um log: 'Variável X removida, p=0.12 > 0.05'.",
                                    "Teste sensibilidade variando α (0.01 vs 0.10)."
                                  ],
                                  "verification": "Produza dois modelos: completo e simplificado, com tabela comparativa de p-valores e R² ajustado.",
                                  "estimatedTime": "25-40 minutos",
                                  "materials": [
                                    "Script R/Python para refit",
                                    "Mesma dataset do step 2"
                                  ],
                                  "tips": "Elimine uma por vez para rastrear mudanças; evite stepwise automático inicialmente.",
                                  "learningObjective": "Desenvolver habilidade em tomada de decisão baseada em testes t para seleção stepwise backward.",
                                  "commonMistakes": [
                                    "Remover todas de uma vez sem iteração",
                                    "Esquecer verificar multicolinearidade pós-remoção",
                                    "Priorizar magnitude de t sobre p-valor"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar simplificação e interpretar impacto no modelo econométrico",
                                  "subSteps": [
                                    "Avalie F-test global e R² ajustado no modelo final.",
                                    "Interprete coeficientes restantes no contexto econômico.",
                                    "Verifique suposições (normalidade resíduos, homocedasticidade).",
                                    "Simule cenários: adicione ruído para testar robustez da seleção.",
                                    "Escreva conclusão: 'Modelo simplificado com 3 variáveis significativas.'"
                                  ],
                                  "verification": "Crie um relatório final com modelo selecionado, justificativas e métricas comparativas.",
                                  "estimatedTime": "20-35 minutos",
                                  "materials": [
                                    "Ferramentas de diagnóstico: plot() no R ou residuals plots",
                                    "Dataset original"
                                  ],
                                  "tips": "Use AIC/BIC como complemento ao R² ajustado para seleção.",
                                  "learningObjective": "Garantir que a seleção resulte em modelo parcimonioso e interpretável.",
                                  "commonMistakes": [
                                    "Aceitar modelo sem diagnósticos",
                                    "Overfitting por não simplificar o suficiente",
                                    "Ignorar viés de seleção em inferência causal"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para prever salário (y) com educação (x1, p=0.03), experiência (x2, p=0.08), gênero (x3, p=0.62) e região (x4, p=0.12): remova x3 e x4 (p>0.05), reexecute lm(salario ~ educ + exp), confirme R² ajustado estável e todos p<0.05.",
                              "finalVerifications": [
                                "Pode listar e classificar p-valores corretamente de um output de regressão?",
                                "Executa seleção stepwise backward manualmente sem erros?",
                                "Explica por que p>0.05 justifica eliminação em termos de H0?",
                                "Compara R² ajustado pré/pós-seleção adequadamente?",
                                "Identifica pelo menos 3 erros comuns em interpretação de testes t?",
                                "Produz relatório com modelo simplificado válido?"
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de p-valores (100% correto)",
                                "Correta aplicação do critério de eliminação (nenhuma variável inválida mantida/removida)",
                                "Melhoria ou estabilidade no R² ajustado demonstrada",
                                "Relatório claro com justificativas e outputs",
                                "Validação de suposições do modelo (resíduos ok)",
                                "Tempo de execução eficiente e decisões iterativas lógicas"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Hipóteses e distribuições t",
                                "Programação: Manipulação de dataframes em R/Python",
                                "Econometria: Modelos lineares e diagnósticos",
                                "Machine Learning: Feature selection e regularização (Lasso)",
                                "Economia Aplicada: Interpretação causal em políticas públicas"
                              ],
                              "realWorldApplication": "Em análises econométricas para bancos centrais ou consultorias, refinar modelos de previsão de inflação ou crescimento PIB, removendo variáveis irrelevantes para relatórios regulatórios concisos e decisões de política monetária mais precisas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.3",
                        "name": "Métodos de Seleção Sequencial",
                        "description": "Técnicas stepwise, forward e backward para seleção automática de variáveis em regressões lineares, considerando pressupostos econométricos como multicolinearidade.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.3.1",
                            "name": "Aplicar seleção forward stepwise",
                            "description": "Iniciar com modelo nulo e adicionar variáveis uma a uma com base no maior incremento no R² ajustado ou menor p-valor, até critério de parada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente de trabalho e os dados",
                                  "subSteps": [
                                    "Instalar e carregar bibliotecas necessárias (ex: stats, lmtest em R ou statsmodels em Python).",
                                    "Importar o dataset com variável resposta e preditoras candidatas.",
                                    "Realizar limpeza de dados: tratar valores ausentes, remover outliers e codificar variáveis categóricas.",
                                    "Dividir dados em treino e teste (opcional para validação inicial).",
                                    "Explorar correlações iniciais entre preditoras e resposta."
                                  ],
                                  "verification": "Dataset limpo carregado sem erros, com resumo estatístico exibido.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "RStudio ou Jupyter Notebook",
                                    "Dataset exemplo (mtcars ou Boston Housing)"
                                  ],
                                  "tips": "Use datasets built-in como mtcars para testes rápidos e evite overfitting inicial.",
                                  "learningObjective": "Configurar um ambiente pronto e dados preparados para seleção stepwise.",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade entre preditoras",
                                    "Não tratar valores ausentes",
                                    "Usar todo dataset sem divisão"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar o modelo nulo e definir critérios de seleção",
                                  "subSteps": [
                                    "Ajustar modelo nulo (intercepto apenas: lm(y ~ 1, data)).",
                                    "Calcular métricas baseline: R² ajustado, AIC, BIC e resíduos.",
                                    "Definir critérios de parada: threshold para p-valor (ex: 0.05), incremento mínimo em R² adj ou AIC.",
                                    "Listar todas as preditoras candidatas disponíveis.",
                                    "Preparar estrutura para rastrear histórico de seleções."
                                  ],
                                  "verification": "Modelo nulo ajustado com métricas baseline registradas e critérios definidos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Funções lm() em R ou OLS em statsmodels",
                                    "Planilha ou lista para histórico"
                                  ],
                                  "tips": "Registre todas as métricas em uma tabela para visualização clara do progresso.",
                                  "learningObjective": "Estabelecer baseline e regras claras para iterações forward.",
                                  "commonMistakes": [
                                    "Escolher threshold muito permissivo",
                                    "Esquecer de usar R² ajustado",
                                    "Não verificar normalidade dos resíduos iniciais"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar iterações forward de adição de variáveis",
                                  "subSteps": [
                                    "Para cada iteração: testar adição de cada preditora restante ao modelo atual.",
                                    "Calcular incremento em R² ajustado e p-valor do teste F ou t para a nova variável.",
                                    "Selecionar e adicionar a variável com maior incremento em R² adj ou menor p-valor.",
                                    "Atualizar modelo, métricas e histórico; remover variável da lista de candidatas.",
                                    "Repetir até que nenhuma variável atenda ao critério de entrada."
                                  ],
                                  "verification": "Histórico de iterações completo com variáveis adicionadas sequencialmente e métricas melhoradas.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Loop for/while em R ou Python",
                                    "Funções anova() ou summary() para testes"
                                  ],
                                  "tips": "Implemente em loop automatizado para eficiência; plote R² adj vs. número de variáveis.",
                                  "learningObjective": "Aplicar lógica sequencial forward para construção iterativa do modelo.",
                                  "commonMistakes": [
                                    "Adicionar variável com p-valor alto",
                                    "Não penalizar por complexidade (use R² adj)",
                                    "Parar prematuramente sem testar todas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar critério de parada e avaliar modelo final",
                                  "subSteps": [
                                    "Confirmar que critério de parada foi atingido (nenhuma variável melhora significativamente).",
                                    "Realizar diagnósticos: resíduos vs. fitted, Q-Q plot, VIF para multicolinearidade.",
                                    "Comparar com modelo completo ou backward para validação cruzada.",
                                    "Testar em conjunto de teste e calcular métricas out-of-sample.",
                                    "Documentar modelo final com coeficientes e predições exemplo."
                                  ],
                                  "verification": "Modelo final validado sem violações graves e métricas out-of-sample registradas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Funções plot(), vif() em car package (R)",
                                    "Cross-validation functions"
                                  ],
                                  "tips": "Sempre valide com hold-out set para evitar overfitting.",
                                  "learningObjective": "Finalizar e validar o modelo stepwise garantindo robustez.",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade no modelo final",
                                    "Não testar generalização",
                                    "Aceitar modelo sem diagnósticos"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset mtcars (R), preveja mpg (consumo) iniciando com modelo nulo. Adicione wt (peso) primeiro (maior ΔR² adj), depois qsec (aceleração), parando quando p-valor > 0.05. Modelo final: mpg ~ wt + qsec, com R² adj = 0.75.",
                              "finalVerifications": [
                                "R² ajustado aumentou monotonicamente em cada iteração.",
                                "Todas adições tiveram p-valor < threshold definido.",
                                "Nenhuma variável restante melhora o modelo significativamente.",
                                "Diagnósticos de resíduos mostram homocedasticidade e normalidade.",
                                "VIF < 5 para todas variáveis no modelo final.",
                                "Predições em teste têm erro RMSE baixo."
                              ],
                              "assessmentCriteria": [
                                "Implementação correta do loop forward com critérios precisos (R² adj ou p-valor).",
                                "Histórico completo de métricas por iteração.",
                                "Uso adequado de testes estatísticos (F ou t-test).",
                                "Validação final com diagnósticos e cross-validation.",
                                "Código reproduzível e comentado.",
                                "Interpretação correta dos resultados stepwise."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial (testes de hipóteses, p-valores)",
                                "Programação Computacional (loops e funções em R/Python)",
                                "Machine Learning (seleção de features e overfitting)",
                                "Análise de Regressão Linear (modelos e diagnósticos)",
                                "Matemática Aplicada (otimização stepwise)"
                              ],
                              "realWorldApplication": "Em análise de risco de crédito bancário, selecione variáveis como renda, idade e score para prever default, adicionando iterativamente as mais preditivas para modelos regulatórios eficientes e interpretáveis."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.2",
                            "name": "Aplicar seleção backward stepwise",
                            "description": "Começar com modelo completo e remover variáveis com menor significância (teste t ou F), iterando até otimização em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o dataset e ajustar o modelo completo",
                                  "subSteps": [
                                    "Carregue o conjunto de dados de engenharia em um ambiente de programação como Python (statsmodels) ou R.",
                                    "Explore as variáveis independentes e dependente, verificando multicolinearidade inicial com VIF.",
                                    "Ajuste o modelo de regressão linear completo incluindo todas as variáveis preditoras.",
                                    "Obtenha os diagnósticos iniciais: resíduos, R², F-statistic.",
                                    "Defina o limiar de significância (ex: α = 0.05 para p-value)."
                                  ],
                                  "verification": "Modelo completo ajustado com summary() mostrando todos coeficientes e p-values.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com statsmodels, pandas, numpy",
                                    "Ou R com lm()",
                                    "Dataset de exemplo (ex: CSV com dados de engenharia)"
                                  ],
                                  "tips": "Padronize variáveis se escalas diferirem para evitar viés em testes t.",
                                  "learningObjective": "Construir e diagnosticar um modelo de regressão completo pronto para seleção backward.",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade alta, que infla p-values.",
                                    "Não tratar outliers antes do ajuste inicial.",
                                    "Esquecer de salvar o modelo inicial para comparação posterior."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Avaliar significância das variáveis no modelo atual",
                                  "subSteps": [
                                    "Extraia a tabela de summary do modelo: coeficientes, std errors, t-stats e p-values.",
                                    "Identifique a variável com o maior p-value (menos significativa, teste t ou F parcial).",
                                    "Verifique se o p-value > α (ex: 0.05); se todas < α, pare.",
                                    "Calcule métricas adicionais como AIC, BIC para rastrear melhorias.",
                                    "Registre a variável candidata para remoção."
                                  ],
                                  "verification": "Lista de p-values ordenada, com identificação clara da variável mais insignificante.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Funções summary() em statsmodels ou R",
                                    "Planilha para log de iterações"
                                  ],
                                  "tips": "Use teste F parcial para remoções múltiplas se necessário, priorizando p-value mais alto.",
                                  "learningObjective": "Interpretar testes de significância para priorizar remoções.",
                                  "commonMistakes": [
                                    "Confundir p-value de t com F global.",
                                    "Remover variáveis com p-value borderline sem contexto.",
                                    "Não registrar iterações para auditoria."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Remover variável e reavaliar o modelo iterativamente",
                                  "subSteps": [
                                    "Remova a variável com maior p-value do modelo.",
                                    "Reajuste o modelo com as variáveis restantes.",
                                    "Repita a avaliação de significância (Step 2) no novo modelo.",
                                    "Continue iterando até que todas p-values ≤ α ou critério de parada (ex: AIC não diminui).",
                                    "Monitore mudanças em R² ajustado e diagnósticos de resíduos."
                                  ],
                                  "verification": "Log de pelo menos 3-5 iterações mostrando remoções sucessivas e p-values decrescentes.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Loop em Python (while) ou função step() em R",
                                    "Gráficos de AIC por iteração"
                                  ],
                                  "tips": "Implemente em loop automatizado para eficiência, mas entenda cada iteração manualmente primeiro.",
                                  "learningObjective": "Executar remoções sequenciais mantendo integridade estatística.",
                                  "commonMistakes": [
                                    "Remover variáveis erradas por erro de indexação.",
                                    "Parar prematuramente se AIC oscila ligeiramente.",
                                    "Ignorar aumento em variância de resíduos pós-remoção."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar o modelo final e interpretar resultados",
                                  "subSteps": [
                                    "Compare modelo final com completo e nulo: ΔAIC, R², testes F.",
                                    "Verifique pressupostos: normalidade resíduos, homocedasticidade, independência.",
                                    "Realize validação cruzada ou bootstrap para robustez.",
                                    "Interprete coeficientes restantes no contexto de engenharia.",
                                    "Documente o modelo otimizado com equação final."
                                  ],
                                  "verification": "Relatório final com métricas comparativas e gráficos de diagnósticos aprovados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Funções como plot_model() ou check_residuals()",
                                    "Ferramentas de CV como cross_val_score"
                                  ],
                                  "tips": "Sempre valide out-of-sample para evitar overfitting.",
                                  "learningObjective": "Confirmar otimalidade e aplicabilidade do modelo selecionado.",
                                  "commonMistakes": [
                                    "Aceitar modelo sem checar multicolinearidade residual.",
                                    "Não comparar com forward ou best subset.",
                                    "Superestimar generalização sem CV."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia mecânica para prever eficiência de turbinas (variável resposta: eficiência %), com 10 preditoras como temperatura inlet, pressão, RPM, material densidade, etc. Inicie com modelo completo (R²=0.85, mas 4 vars com p>0.10), remova 'vibração' (p=0.32), reavalie (nova p-max='umidade'=0.18), remova, continue até 6 vars restantes (todas p<0.05, AIC reduzido 25%).",
                              "finalVerifications": [
                                "Todas variáveis restantes têm p-value ≤ 0.05 nos testes t/F.",
                                "AIC/BIC do modelo final é menor que o modelo completo.",
                                "R² ajustado estável ou melhor, sem perda significativa de explanatory power.",
                                "Resíduos atendem pressupostos: normalidade (QQ-plot), homocedasticidade (Breusch-Pagan).",
                                "Nenhuma multicolinearidade alta (VIF < 5).",
                                "Validação cruzada confirma performance out-of-sample."
                              ],
                              "assessmentCriteria": [
                                "Implementação correta do loop backward com remoção baseada em p-value máximo.",
                                "Registro preciso de iterações com métricas (AIC, p-values) em log ou tabela.",
                                "Interpretação adequada de significância e impacto de remoções.",
                                "Diagnósticos completos do modelo final sem violações graves.",
                                "Comparação quantitativa com modelo inicial e critérios de parada respeitados.",
                                "Código reproduzível e comentado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses (t, F) e critérios de informação (AIC/BIC).",
                                "Programação Computacional: Loops e funções em Python/R para automação.",
                                "Machine Learning: Feature selection em regressão e prevenção de overfitting.",
                                "Engenharia de Dados: Modelagem preditiva para otimização de processos industriais.",
                                "Análise de Dados Exploratória: Diagnósticos de regressão e multicolinearidade."
                              ],
                              "realWorldApplication": "Em engenharia, otimiza modelos preditivos para monitoramento de processos industriais, como prever falhas em equipamentos reduzindo variáveis irrelevantes, economizando tempo computacional e melhorando precisão em manufatura preditiva e controle de qualidade."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.3",
                            "name": "Implementar stepwise bidirecional",
                            "description": "Combinar forward e backward em iterações para refinar o modelo, avaliando critérios como AIC em softwares como R para análise econométrica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e os dados em R",
                                  "subSteps": [
                                    "Instalar e carregar pacotes necessários: MASS, lmtest e datasets.",
                                    "Carregar um dataset exemplo, como mtcars ou um conjunto econométrico (ex: dados de salários).",
                                    "Explorar os dados: summary(), cor() e plotar matriz de correlação.",
                                    "Definir a variável dependente e independentes potenciais.",
                                    "Dividir dados em treino e teste se aplicável."
                                  ],
                                  "verification": "Ambiente pronto confirmado por rodar lm() simples sem erros e visualizar dados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R e RStudio",
                                    "Pacotes: MASS, lmtest",
                                    "Dataset exemplo: mtcars ou dados CSV econométricos"
                                  ],
                                  "tips": "Use set.seed() para reprodutibilidade em seleções aleatórias.",
                                  "learningObjective": "Configurar corretamente o ambiente R para seleção de modelos stepwise.",
                                  "commonMistakes": [
                                    "Esquecer de carregar pacotes",
                                    "Não tratar multicolinearidade inicial",
                                    "Usar dataset sem variáveis suficientes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar seleção stepwise forward",
                                  "subSteps": [
                                    "Executar modelo nulo: lm(y ~ 1, data).",
                                    "Usar step() com direction='forward', k=2 para AIC.",
                                    "Analisar saída: variáveis adicionadas e AIC decrescente.",
                                    "Plotar resumo do modelo final e verificar resíduos.",
                                    "Comparar AIC com modelo nulo."
                                  ],
                                  "verification": "Modelo forward completo com AIC reportado e pelo menos 2-3 variáveis selecionadas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R script com dados preparados",
                                    "Função step() do MASS"
                                  ],
                                  "tips": "Monitore o p-value no processo para evitar overfitting.",
                                  "learningObjective": "Dominar forward selection adicionando variáveis uma a uma baseado em AIC.",
                                  "commonMistakes": [
                                    "direction='backward' por engano",
                                    "Ignorar warnings de singularidade",
                                    "Não salvar modelo stepwise"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar seleção stepwise backward",
                                  "subSteps": [
                                    "Construir modelo completo: lm(y ~ ., data).",
                                    "Aplicar step() com direction='backward', k=2.",
                                    "Examinar variáveis removidas e evolução do AIC.",
                                    "Validar modelo final com summary() e teste de Ramsey RESET.",
                                    "Comparar AIC com forward selection."
                                  ],
                                  "verification": "Modelo backward gerado com AIC menor ou similar ao forward, sem variáveis irrelevantes.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R script anterior",
                                    "Função step() com modelo full"
                                  ],
                                  "tips": "Comece com modelo full sem variáveis correlacionadas >0.9.",
                                  "learningObjective": "Executar backward selection removendo variáveis desnecessárias via AIC.",
                                  "commonMistakes": [
                                    "Modelo full com muitas variáveis causando overfitting",
                                    "Não checar VIF para multicolinearidade",
                                    "Confundir k=2 (AIC) com BIC"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e refinar stepwise bidirecional",
                                  "subSteps": [
                                    "Executar step() com direction='both' em modelo nulo ou full.",
                                    "Iterar: adicionar/remover variáveis alternadamente até convergência.",
                                    "Comparar AIC final com forward/backward isolados.",
                                    "Refinar: ajustar k ou usar critério BIC, validar com CV.",
                                    "Documentar processo e exportar modelo final."
                                  ],
                                  "verification": "Modelo bidirecional convergeu com AIC ótimo, relatório comparativo gerado.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Scripts anteriores",
                                    "Funções step(), AIC(), BIC()"
                                  ],
                                  "tips": "Use trace=1 para ver iterações; pare se AIC não melhora.",
                                  "learningObjective": "Combinar forward/backward em iterações bidirecionais para modelo ótimo.",
                                  "commonMistakes": [
                                    "Não convergir por loop infinito",
                                    "Ignorar estabilidade entre métodos",
                                    "Overfitting sem validação externa"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e validar o modelo final",
                                  "subSteps": [
                                    "Calcular métricas: AIC, BIC, R² ajustado, RMSE em teste.",
                                    "Testes diagnósticos: Shapiro-Wilk, Breusch-Pagan, Durbin-Watson.",
                                    "Cross-validation com cv.glm() ou manual.",
                                    "Interpretar coeficientes economicamente.",
                                    "Relatar limitações e sugestões de melhoria."
                                  ],
                                  "verification": "Relatório com todas métricas < thresholds aceitáveis e sem violações graves.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacotes lmtest, car",
                                    "Dados de teste"
                                  ],
                                  "tips": "Priorize AIC para comparação, mas valide com dados out-of-sample.",
                                  "learningObjective": "Avaliar robustez do modelo stepwise bidirecional em contexto econométrico.",
                                  "commonMistakes": [
                                    "Confiar só em AIC sem diagnósticos",
                                    "Não separar treino/teste",
                                    "Interpretar causalidade como correlação"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset mtcars em R: lm(mpg ~ ., data=mtcars) seguido de step(model, direction='both', k=2). Resultado típico seleciona wt, qsec, am com AIC= -77.6, refinando previsão de eficiência de combustível como proxy econométrico de custo-benefício veicular.",
                              "finalVerifications": [
                                "Modelo bidirecional convergeu sem loops infinitos.",
                                "AIC final é menor que modelos forward/backward isolados.",
                                "Resíduos normais e homocedásticos confirmados por plots/Q-Q.",
                                "Variáveis selecionadas têm significância (p<0.05).",
                                "R² ajustado >0.7 e RMSE baixo em dados de teste.",
                                "Comparação com baseline (modelo nulo/full) favorável."
                              ],
                              "assessmentCriteria": [
                                "Correta implementação de step(direction='both') com k=2 (AIC).",
                                "Evolução lógica de AIC em iterações bidirecionais.",
                                "Diagnósticos completos sem violações graves.",
                                "Interpretação contextual em análise econométrica.",
                                "Código limpo, reprodutível e comentado.",
                                "Validação externa com CV ou hold-out."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses em regressão.",
                                "Economia: Modelagem econométrica para previsão de variáveis macro.",
                                "Programação: Scripts R para automação de machine learning.",
                                "Matemática: Otimização via critérios de informação (AIC/BIC)."
                              ],
                              "realWorldApplication": "Em análise econométrica, refinar modelos de regressão para prever PIB com base em indicadores fiscais, removendo variáveis irrelevantes para políticas públicas precisas, como no Banco Central selecionando preditores de inflação."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.4",
                            "name": "Avaliar riscos de overfitting em métodos stepwise",
                            "description": "Discutir limitações como multicolinearidade induzida e preferência por validação cruzada em aplicações práticas de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Overfitting e Mecanismo Stepwise",
                                  "subSteps": [
                                    "Defina overfitting como o fenômeno em que o modelo captura ruído nos dados de treino, perdendo generalização.",
                                    "Explique métodos stepwise (forward, backward, both) e como eles selecionam variáveis sequencialmente baseado em critérios como AIC ou p-valores.",
                                    "Identifique como stepwise pode levar a overfitting ao adicionar variáveis desnecessárias que melhoram fit localmente.",
                                    "Revise métricas de avaliação como R² ajustado e RMSE em treino vs. teste.",
                                    "Simule um exemplo simples com dados sintéticos para observar overfitting."
                                  ],
                                  "verification": "Crie um relatório resumindo definições e um gráfico comparando performance em treino e teste.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python (scikit-learn, statsmodels), Jupyter Notebook, dataset sintético gerado via numpy.",
                                  "tips": "Sempre compare métricas in-sample vs. out-of-sample para detectar overfitting precocemente.",
                                  "learningObjective": "Entender os fundamentos de overfitting e o papel dos métodos stepwise na sua indução.",
                                  "commonMistakes": "Confundir baixa erro em treino com bom modelo; ignorar tamanho da amostra pequeno."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Multicolinearidade Induzida por Stepwise",
                                  "subSteps": [
                                    "Calcule VIF (Variance Inflation Factor) antes e após seleção stepwise para detectar multicolinearidade.",
                                    "Discuta como stepwise pode selecionar variáveis correlacionadas, inflando coeficientes e variância.",
                                    "Examine correlogramas e matriz de correlação para visualizar relações entre variáveis selecionadas.",
                                    "Compare modelos stepwise com ridge regression para mitigar multicolinearidade.",
                                    "Quantifique o impacto com simulações Monte Carlo variando níveis de correlação."
                                  ],
                                  "verification": "Gere tabela de VIF pré e pós-stepwise e interprete valores >5 como indicativo de problema.",
                                  "estimatedTime": "2 horas",
                                  "materials": "R (car package para VIF), Python (statsmodels), dataset com variáveis correlacionadas (ex: Boston Housing).",
                                  "tips": "Use stepwise com cautela em datasets com alta dimensionalidade; prefira penalizações L1/L2.",
                                  "learningObjective": "Identificar e quantificar multicolinearidade induzida como limitação chave dos métodos stepwise.",
                                  "commonMistakes": "Interpretar VIF isoladamente sem contexto de domínio; assumir independência perfeita das variáveis."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Stepwise com Validação Cruzada",
                                  "subSteps": [
                                    "Implemente k-fold cross-validation (k=5 ou 10) para seleção de variáveis em vez de stepwise.",
                                    "Compare AIC/BIC de stepwise com CV error médio e intervalo de confiança.",
                                    "Discuta vantagens da CV: robustez a overfitting e melhor estimativa de erro futuro.",
                                    "Aplique nested CV para hiperparâmetros em métodos regulares como Lasso.",
                                    "Avalie estabilidade da seleção de variáveis entre folds da CV."
                                  ],
                                  "verification": "Produza gráfico de boxplot de erros CV vs. stepwise e relatório de comparação.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Python (sklearn.model_selection), R (caret), mesmo dataset do Step 2.",
                                  "tips": "Escolha k baseado no tamanho da amostra; use stratified k-fold para dados desbalanceados.",
                                  "learningObjective": "Demonstrar preferência por validação cruzada sobre stepwise em cenários práticos.",
                                  "commonMistakes": "Usar CV apenas para tuning sem aninhamento, levando a otimização enviesada."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar Riscos em Aplicação de Engenharia",
                                  "subSteps": [
                                    "Selecione dataset de engenharia (ex: previsão de fadiga em materiais).",
                                    "Aplique stepwise e CV, comparando modelos em termos de overfitting e multicolinearidade.",
                                    "Discuta implicações práticas: custo de falsos positivos em engenharia de confiabilidade.",
                                    "Recomende pipeline híbrido: stepwise inicial + CV refinamento.",
                                    "Documente lições aprendidas para relatórios de engenharia."
                                  ],
                                  "verification": "Elabore relatório final com recomendações específicas para o contexto de engenharia.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": "Dataset UCI (ex: Concrete Compressive Strength), ferramentas dos steps anteriores.",
                                  "tips": "Integre conhecimento de domínio para priorizar variáveis fisicamente relevantes.",
                                  "learningObjective": "Aplicar conceitos para avaliar e mitigar riscos de overfitting em cenários reais de engenharia.",
                                  "commonMistakes": "Ignorar custos computacionais da CV em aplicações de tempo real."
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia mecânica para prever a resistência à compressão de concreto usando dados UCI, aplique stepwise forward: seleciona 7 variáveis, mas VIF>10 indica multicolinearidade. CV-10 revela overfitting (treino RMSE=3.2, CV=5.1). Alternativa Lasso+CV seleciona 5 variáveis estáveis com RMSE CV=4.2, melhor generalização para novos lotes de produção.",
                              "finalVerifications": [
                                "Explicar overfitting em stepwise com exemplo numérico.",
                                "Calcular e interpretar VIF em modelo stepwise.",
                                "Implementar CV e comparar métricas com stepwise.",
                                "Identificar multicolinearidade em dataset real.",
                                "Recomendar CV para engenharia com justificativa.",
                                "Discutir estabilidade da seleção de variáveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de overfitting (80%+ acerto em simulações).",
                                "Correta interpretação de VIF e multicolinearidade (>5 variáveis analisadas).",
                                "Implementação correta de CV com gráficos comparativos.",
                                "Relatório claro com recomendações práticas para engenharia.",
                                "Demonstração de estabilidade via repetições Monte Carlo.",
                                "Integração de limitações em discussão coesa."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses em seleção.",
                                "Machine Learning: Regularização e ensemble methods.",
                                "Engenharia: Modelagem preditiva em confiabilidade e otimização.",
                                "Programação: Implementação em Python/R para análise de dados."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, avaliar riscos de overfitting em stepwise para modelar vibrações em turbinas evita falhas caras; prefira CV para certificar modelos regulatórios (FAA), reduzindo multicolinearidade em sensores correlacionados e garantindo predições confiáveis em voos reais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.2",
                    "name": "Maximização de Verossimilhança",
                    "description": "Método de estimação de parâmetros baseado no princípio da máxima verossimilhança.",
                    "individualConcepts": [
                      {
                        "id": "11.3.2.1",
                        "name": "Função de Verossimilhança",
                        "description": "Definição e construção da função de verossimilhança como a probabilidade conjunta dos dados observados em função dos parâmetros do modelo, no contexto de econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "11.3.2.1.1",
                            "name": "Definir a função de verossimilhança",
                            "description": "Explicar o conceito de verossimilhança como a probabilidade de observar os dados dados os parâmetros θ, diferenciando de probabilidade e escrevendo a fórmula L(θ|x) = ∏ f(xi|θ) para amostras independentes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de Probabilidade",
                                  "subSteps": [
                                    "Defina probabilidade como P(evento), a chance de um evento ocorrer.",
                                    "Explique a função de densidade de probabilidade f(x|θ) para variáveis contínuas ou massa para discretas.",
                                    "Discuta o papel dos parâmetros θ em modelos probabilísticos.",
                                    "Identifique exemplos simples, como distribuição binomial ou normal.",
                                    "Diferencie probabilidade condicional P(X|θ) de P(θ|X)."
                                  ],
                                  "verification": "Resuma em uma frase a diferença entre probabilidade direta e condicional envolvendo parâmetros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Livro de estatística introdutória (capítulo de probabilidade)",
                                    "Notas de aula sobre distribuições probabilísticas"
                                  ],
                                  "tips": "Use diagramas de Venn para visualizar condicionais.",
                                  "learningObjective": "Compreender a base probabilística necessária para verossimilhança.",
                                  "commonMistakes": [
                                    "Confundir P(θ|x) com P(x|θ)",
                                    "Ignorar o condicionamento em θ"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir o Conceito de Verossimilhança",
                                  "subSteps": [
                                    "Defina verossimilhança como a probabilidade dos dados observados dados os parâmetros: L(θ|x) = P(x|θ).",
                                    "Explique intuitivamente: quão 'provável' são os dados sob θ específico.",
                                    "Diferencie de probabilidade bayesiana posterior P(θ|x).",
                                    "Discuta que verossimilhança trata θ como fixo e dados como aleatórios.",
                                    "Crie uma analogia: dados são 'testemunhas', θ é 'suspeito'."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito por que verossimilhança é P(dados|θ) e não o inverso.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Vídeo curto sobre verossimilhança (Khan Academy ou similar)",
                                    "Papel e caneta para anotações"
                                  ],
                                  "tips": "Pense em verossimilhança como 'compatibilidade' dos dados com o modelo.",
                                  "learningObjective": "Dominar a definição conceitual e distinção chave de probabilidade.",
                                  "commonMistakes": [
                                    "Trocar verossimilhança por probabilidade a priori",
                                    "Confundir com evidência bayesiana"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Formular a Função de Verossimilhança para Uma Observação",
                                  "subSteps": [
                                    "Escreva L(θ|x) = f(x|θ) para uma única observação x.",
                                    "Ilustre com exemplo: para x ~ Bernoulli(θ), L(θ|x) = θ^x * (1-θ)^(1-x).",
                                    "Plote graficamente L(θ|x) vs θ para visualizar o pico no valor mais verossímil.",
                                    "Discuta propriedades: não normalizada, foco em maximização relativa.",
                                    "Verifique com cálculo manual para valores específicos de x e θ."
                                  ],
                                  "verification": "Calcule e plote L(θ|x) para um x dado e varie θ de 0 a 1.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Calculadora ou Python/Jupyter para plotagem",
                                    "Software como Desmos ou Matplotlib"
                                  ],
                                  "tips": "Sempre normalize mentalmente dividindo pela constante de normalização ignorada.",
                                  "learningObjective": "Escrever e interpretar a fórmula para casos simples.",
                                  "commonMistakes": [
                                    "Normalizar a verossimilhança como probabilidade",
                                    "Esquecer o condicionamento |θ"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Generalizar para Amostras Independentes e Idênticas",
                                  "subSteps": [
                                    "Para n observações independentes x1,...,xn, escreva L(θ|x) = ∏_{i=1}^n f(xi|θ).",
                                    "Derive introduzindo log-verossimilhança l(θ|x) = ∑ log f(xi|θ) para simplificação.",
                                    "Aplique a uma amostra: ex., n lançamentos de moeda, produto das probabilidades individuais.",
                                    "Discuta independência: multiplicação conjunta segue da independência.",
                                    "Implemente em código simples para validar a fórmula."
                                  ],
                                  "verification": "Escreva a fórmula completa para uma amostra de 3 observações e compute numericamente.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Jupyter Notebook ou R para simulação",
                                    "Dados de exemplo gerados aleatoriamente"
                                  ],
                                  "tips": "Use log para evitar underflow em produtos pequenos.",
                                  "learningObjective": "Formular e derivar a verossimilhança para dados múltiplos.",
                                  "commonMistakes": [
                                    "Adicionar em vez de multiplicar probabilidades",
                                    "Ignorar independência assumida"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere 10 lançamentos de uma moeda: 7 caras, 3 coroas. A verossimilhança é L(θ) = θ^7 * (1-θ)^3, maximizada em θ ≈ 0.7, refletindo a fração observada de caras.",
                              "finalVerifications": [
                                "Explica corretamente verossimilhança como P(x|θ).",
                                "Diferencia de probabilidade bayesiana.",
                                "Escreve L(θ|x) = ∏ f(xi|θ) para independentes.",
                                "Computa exemplo numérico simples.",
                                "Identifica quando usar log-verossimilhança.",
                                "Aplica a um dataset pequeno."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definição e distinção: 30%)",
                                "Correção da fórmula (derivada e escrita: 25%)",
                                "Interpretação intuitiva e exemplos (20%)",
                                "Cálculos numéricos sem erros (15%)",
                                "Uso apropriado de log-verossimilhança (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Programação: Implementar em Python com NumPy/SciPy.",
                                "Machine Learning: Base para MLE em regressão logística.",
                                "Física: Ajuste de parâmetros em modelos experimentais.",
                                "Biologia: Análise de sequências genéticas."
                              ],
                              "realWorldApplication": "Em epidemiologia, maximizar verossimilhança para estimar taxa de transmissão R0 de dados de casos COVID-19, guiando políticas públicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.2.1.2",
                            "name": "Calcular verossimilhança para distribuições comuns",
                            "description": "Construir a função de verossimilhança para distribuições normais, Poisson e binomial, aplicadas a modelos de regressão linear em dados de engenharia como tempos de falha ou custos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos da Função de Verossimilhança",
                                  "subSteps": [
                                    "Definir verossimilhança como a probabilidade dos dados observados dada a hipótese (parâmetros θ).",
                                    "Diferenciar verossimilhança de probabilidade: θ fixo, dados aleatórios.",
                                    "Escrever a fórmula geral L(θ|x) = ∏ f(x_i | θ).",
                                    "Introduzir a log-verossimilhança l(θ|x) = ∑ log f(x_i | θ) para simplificação.",
                                    "Explicar a maximização da verossimilhança como critério de estimação."
                                  ],
                                  "verification": "Explicar em poucas linhas a diferença entre verossimilhança e probabilidade, com exemplo simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de Estatística Inferencial (ex: Casella & Berger)",
                                    "Notebook Jupyter ou papel para fórmulas"
                                  ],
                                  "tips": "Sempre use log-verossimilhança para evitar produtos numéricos pequenos e underflow.",
                                  "learningObjective": "Dominar o conceito teórico e notação da função de verossimilhança.",
                                  "commonMistakes": [
                                    "Confundir verossimilhança com probabilidade posterior bayesiana.",
                                    "Esquecer de considerar independência das observações."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir Verossimilhança para Distribuição Normal",
                                  "subSteps": [
                                    "Recordar a densidade de probabilidade da normal: f(x|μ,σ²) = (1/√(2πσ²)) exp(-(x-μ)²/(2σ²)).",
                                    "Escrever L(μ,σ²|x) = ∏ f(x_i|μ,σ²) para n observações independentes.",
                                    "Derivar a log-verossimilhança: l = -n/2 log(2πσ²) - (1/(2σ²)) ∑(x_i - μ)².",
                                    "Identificar formas fechadas para MLE: μ̂ = x̄, σ̂² = (1/n) ∑(x_i - x̄)².",
                                    "Implementar numericamente em Python com numpy."
                                  ],
                                  "verification": "Calcular manualmente L e l para um conjunto pequeno de dados normais simulados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com numpy e scipy",
                                    "Datasets simulados (gerar com np.random.normal)"
                                  ],
                                  "tips": "Simule dados para testar: np.random.normal(0,1,100).",
                                  "learningObjective": "Construir e simplificar a verossimilhança para normal univariada.",
                                  "commonMistakes": [
                                    "Usar variância amostral viesada (dividir por n-1 em MLE).",
                                    "Esquecer o fator normalizador 1/√(2πσ²)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir Verossimilhança para Distribuição Poisson",
                                  "subSteps": [
                                    "Recordar PMF da Poisson: P(X=k|λ) = (λ^k / k!) exp(-λ).",
                                    "Escrever L(λ|x) = ∏ (λ^{x_i} / x_i!) exp(-λ) para contagens x_i.",
                                    "Derivar log-verossimilhança: l = ∑(x_i log λ - log(x_i!) - λ).",
                                    "Obter MLE: λ̂ = média das x_i.",
                                    "Aplicar a dados de contagens, como falhas por unidade de tempo."
                                  ],
                                  "verification": "Implementar função log-likelihood em Python e maximizar com scipy.optimize.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com scipy.stats e optimize",
                                    "Dados simulados: np.random.poisson(5,100)"
                                  ],
                                  "tips": "Aproximar log(x_i!) com scipy.special.gammaln para precisão numérica.",
                                  "learningObjective": "Derivar verossimilhança para Poisson e interpretá-la em contextos de contagem.",
                                  "commonMistakes": [
                                    "Confundir λ com média amostral em grandes amostras.",
                                    "Ignorar o termo factorial na log-likelihood."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir Verossimilhança para Distribuição Binomial",
                                  "subSteps": [
                                    "Recordar PMF binomial: P(X=k|n,p) = C(n,k) p^k (1-p)^{n-k}.",
                                    "Escrever L(p|x) = ∏ C(n_i, x_i) p^{x_i} (1-p)^{n_i - x_i}.",
                                    "Derivar log-verossimilhança: l = ∑[log C + x_i log p + (n_i - x_i) log(1-p)].",
                                    "Obter MLE: p̂ = (∑ x_i) / (∑ n_i).",
                                    "Testar com dados de sucessos/falhas."
                                  ],
                                  "verification": "Calcular MLE para dados binomiais simulados e comparar com stats.binom.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com scipy.stats.binom",
                                    "Simulação: np.random.binomial(10,0.3,100)"
                                  ],
                                  "tips": "Use logit link para regressão se p variar.",
                                  "learningObjective": "Formular verossimilhança binomial para modelagem de proporções.",
                                  "commonMistakes": [
                                    "Esquecer coeficientes binomiais C(n,k).",
                                    "Tratar n_i como fixo incorretamente."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar em Modelos de Regressão Linear (GLMs) com Dados de Engenharia",
                                  "subSteps": [
                                    "Introduzir GLM: prever parâmetro via link linear, ex: log(μ) = Xβ para Poisson.",
                                    "Construir verossimilhança composta: L(β|x,y) via distribuição assumida.",
                                    "Exemplo: regressão Poisson para contagens de falhas vs. horas de uso.",
                                    "Implementar em statsmodels ou sklearn para dados reais (tempos de falha/custos).",
                                    "Avaliar fit com AIC ou deviance."
                                  ],
                                  "verification": "Ajustar GLM Poisson a dataset de falhas e derivar log-likelihood manualmente.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python statsmodels ou glmnet",
                                    "Dataset exemplo: falhas de máquinas (Kaggle ou simular)"
                                  ],
                                  "tips": "Comece com dados simples; use summary() para checar coeficientes.",
                                  "learningObjective": "Integrar verossimilhança em regressão para dados de engenharia.",
                                  "commonMistakes": [
                                    "Escolher distribuição errada (ex: normal para contagens).",
                                    "Ignorar overdispersion em Poisson."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica, dados de 50 máquinas mostram número de falhas por 100 horas: [2,0,3,1,...]. Assuma Poisson(λ), onde log(λ) = β0 + β1 * idade_máquina. Construa L(β|dados), maximize para estimar β e prever falhas futuras.",
                              "finalVerifications": [
                                "Derivar corretamente log-verossimilhança para normal, Poisson e binomial.",
                                "Implementar funções de likelihood em Python para dados simulados.",
                                "Ajustar GLM com verossimilhança Poisson a dataset de falhas e interpretar.",
                                "Comparar MLEs analíticos vs. numéricos.",
                                "Calcular AIC para dois modelos e selecionar o melhor.",
                                "Explicar impacto de um outlier na verossimilhança."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de fórmulas (100% correta).",
                                "Implementação numérica sem erros de underflow/overflow.",
                                "Interpretação correta de MLEs em contexto de engenharia.",
                                "Uso apropriado de links em GLMs.",
                                "Análise de diagnósticos (residuals, AIC).",
                                "Criatividade em aplicação a dados reais."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: MLE e testes de hipóteses.",
                                "Programação Científica: Python/R para otimização (scipy.optimize).",
                                "Engenharia de Confiabilidade: Modelagem de falhas e manutenção preditiva.",
                                "Machine Learning: Fundamento de loss functions em redes neurais.",
                                "Economia/Finanças: Modelagem de custos com distribuições (normal/binomial)."
                              ],
                              "realWorldApplication": "Na engenharia, calcula parâmetros de modelos para prever tempos de falha (Poisson), otimizar custos de produção (normal) ou taxas de defeitos (binomial), permitindo manutenção preditiva, redução de downtime e alocação eficiente de recursos em indústrias como manufatura e energia."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.1.1"
                            ]
                          },
                          {
                            "id": "11.3.2.1.3",
                            "name": "Usar log-verossimilhança",
                            "description": "Derivar a log-verossimilhança l(θ|x) = log L(θ|x) para simplificar cálculos e maximização, ilustrando com exemplo de regressão linear sob pressupostos normais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Função de Verossimilhança L(θ|x)",
                                  "subSteps": [
                                    "Revise a definição de verossimilhança: L(θ|x) = ∏ f(x_i | θ) para amostras independentes.",
                                    "Entenda que L(θ|x) mede quão provável são os dados observados sob o modelo θ.",
                                    "Discuta desafios computacionais: produtos de probabilidades pequenas levam a underflow.",
                                    "Identifique quando maximizar L(θ|x) é equivalente a maximizar log L(θ|x).",
                                    "Pratique escrevendo L(θ|x) para uma distribuição simples, como Bernoulli."
                                  ],
                                  "verification": "Escreva corretamente a fórmula de L(θ|x) para uma amostra de 5 observações e explique seu propósito.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Livro de Estatística Inferencial (Cap. Verossimilhança)",
                                    "Notebook Jupyter para simulações"
                                  ],
                                  "tips": "Sempre normalize probabilidades para evitar confusão entre densidade e probabilidade.",
                                  "learningObjective": "Entender o conceito e a formulação da função de verossimilhança.",
                                  "commonMistakes": [
                                    "Confundir verossimilhança com probabilidade posterior.",
                                    "Esquecer a independência das observações no produto."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Propriedades do Logaritmo para Simplificação",
                                  "subSteps": [
                                    "Lembre as propriedades: log(∏ a_i) = ∑ log(a_i) e log(ab) = log a + log b.",
                                    "Explique por que log transforma produto em soma, facilitando derivadas e evitando underflow.",
                                    "Verifique que argmax_θ L(θ|x) = argmax_θ log L(θ|x), pois log é monótona crescente.",
                                    "Pratique convertendo um produto simples em soma de logs.",
                                    "Discuta o uso do log natural (ln) por conveniência em derivadas."
                                  ],
                                  "verification": "Converta L(θ|x) = ∏ p_i(θ) em l(θ|x) = ∑ log p_i(θ) e prove a equivalência na maximização.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Calculadora científica",
                                    "Tabela de propriedades logarítmicas"
                                  ],
                                  "tips": "Use ln para alinhar com derivadas em cálculo (d/dx ln x = 1/x).",
                                  "learningObjective": "Dominar as propriedades do logaritmo que justificam sua aplicação na verossimilhança.",
                                  "commonMistakes": [
                                    "Usar log base 10 em vez de natural em contextos analíticos.",
                                    "Esquecer que log de zero é indefinido (tratar probabilidades zero)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar a Log-Verossimilhança Geral l(θ|x) = log L(θ|x)",
                                  "subSteps": [
                                    "Parta de L(θ|x) = ∏_{i=1}^n f(x_i | θ).",
                                    "Aplique log: l(θ|x) = ∑_{i=1}^n log f(x_i | θ).",
                                    "Discuta generalidade para distribuições paramétricas quaisquer.",
                                    "Derive a primeira derivada ∂l/∂θ para preparação de maximização.",
                                    "Implemente numericamente em código para validar."
                                  ],
                                  "verification": "Derive l(θ|x) a partir de L(θ|x) para uma distribuição genérica e compute sua derivada.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Papel e caneta para derivações",
                                    "Python com NumPy/SciPy"
                                  ],
                                  "tips": "Anote cada passo da derivação para rastrear simplificações.",
                                  "learningObjective": "Realizar a derivação formal da log-verossimilhança.",
                                  "commonMistakes": [
                                    "Erros no sinal do log (sempre positivo para L>1, mas geralmente <1).",
                                    "Confundir soma com produto na derivação."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar à Regressão Linear sob Erros Normais",
                                  "subSteps": [
                                    "Assuma y_i = x_i^T β + ε_i, ε_i ~ N(0, σ²).",
                                    "Escreva f(y_i | β, σ²) = (2πσ²)^{-1/2} exp{-(y_i - x_i^T β)^2 / (2σ²)}.",
                                    "Derive l(β,σ²|y) = -n/2 log(2πσ²) - (1/(2σ²)) ∑ (y_i - x_i^T β)^2.",
                                    "Identifique que maximizar l é minimizar soma de quadrados.",
                                    "Implemente em Python e plote l(θ) para visualização."
                                  ],
                                  "verification": "Derive completamente l(β,σ²|y) e mostre que leva aos estimadores MLE conhecidos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dataset simples de regressão (ex: Boston Housing)",
                                    "Python (scikit-learn, matplotlib)"
                                  ],
                                  "tips": "Expanda o expoente para ver a conexão com mínimos quadrados.",
                                  "learningObjective": "Ilustrar a log-verossimilhança em um exemplo concreto de regressão linear.",
                                  "commonMistakes": [
                                    "Esquecer o termo de normalização -n/2 log(2πσ²).",
                                    "Erro no expoente do erro quadrático (dividir por 2σ²)."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Maximizar a Log-Verossimilhança e Verificar",
                                  "subSteps": [
                                    "Compute ∂l/∂β = (1/σ²) X^T (y - Xβ) e resolva para β̂ = (X^T X)^{-1} X^T y.",
                                    "Para σ², derive σ̂² = (1/n) ∑ (y_i - ŷ_i)^2.",
                                    "Use gradiente descendente numérico se analítico não disponível.",
                                    "Compare com mínimos quadrados ordinários.",
                                    "Avalie numericamente a estabilidade."
                                  ],
                                  "verification": "Encontre os MLE analíticos e implemente maximização numérica, comparando resultados.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código Python pronto para regressão",
                                    "Solver como scipy.optimize"
                                  ],
                                  "tips": "Sempre cheque hessiana para convexidade e unicidade.",
                                  "learningObjective": "Aplicar maximização da log-verossimilhança no exemplo.",
                                  "commonMistakes": [
                                    "Inverter o sinal na derivada (l é maximizada, não minimizada).",
                                    "Usar n-1 em vez de n para σ² em MLE."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma regressão linear para prever salários com base em anos de experiência (n=100), derive l(β,σ²|salários) assumindo erros N(0,σ²), maximize para obter β̂ e σ̂², e compare com OLS via código Python.",
                              "finalVerifications": [
                                "Derivação correta de l(θ|x) para distribuição genérica e regressão linear.",
                                "Implementação numérica de l(θ|x) e maximização converge para valores esperados.",
                                "Explicação verbal das simplificações logarítmicas.",
                                "Identificação de MLE como OLS sob normalidade.",
                                "Gráfico de l(θ) mostrando máximo único.",
                                "Tratamento de casos edge (σ²→0)."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (100% dos passos corretos).",
                                "Profundidade dos substeps (mínimo 4 por step com detalhes acionáveis).",
                                "Conexão clara entre log e simplificação computacional.",
                                "Implementação prática funcional em código.",
                                "Explicação de porquês (não só fórmulas).",
                                "Identificação de erros comuns e prevenções."
                              ],
                              "crossCurricularConnections": [
                                "Cálculo Diferencial: Derivadas parciais para maximização.",
                                "Probabilidade: Densidades de distribuições paramétricas.",
                                "Programação: Implementação numérica com NumPy/SciPy.",
                                "Machine Learning: Base para gradiente descendente em redes neurais.",
                                "Econometria: Estimadores em modelos lineares."
                              ],
                              "realWorldApplication": "Em análise de dados para empresas como Google ou bancos, usar log-verossimilhança para estimar parâmetros em modelos de risco financeiro ou recomendação de produtos, evitando underflow em grandes datasets e habilitando MLE eficiente."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "11.3.2.2",
                        "name": "Princípio da Máxima Verossimilhança",
                        "description": "Método de estimação que seleciona os parâmetros que maximizam a verossimilhança dos dados observados, comparado aos mínimos quadrados ordinários.",
                        "specificSkills": [
                          {
                            "id": "11.3.2.2.1",
                            "name": "Explicar o estimador de máxima verossimilhança",
                            "description": "Descrever o estimador θ̂_MLE = argmax_θ L(θ|x), justificando intuitivamente por que maximiza a 'probabilidade' dos dados em modelos econométricos para engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Função de Verossimilhança",
                                  "subSteps": [
                                    "Revise a densidade de probabilidade conjunta p(x|θ) para um conjunto de dados observados x.",
                                    "Defina a função de log-verossimilhança ℓ(θ|x) = log L(θ|x) = ∑ log p(x_i|θ) para simplificar cálculos.",
                                    "Entenda que L(θ|x) mede quão 'provável' os dados x são sob o parâmetro θ.",
                                    "Compare L(θ|x) para diferentes θ, visualizando graficamente para um exemplo simples.",
                                    "Discuta por que usamos log-verossimilhança em vez da verossimilhança direta."
                                  ],
                                  "verification": "Escreva a fórmula da log-verossimilhança para uma distribuição Bernoulli e plote-a para θ variando de 0 a 1.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Caderno, calculadora, Python/Jupyter com matplotlib e numpy para plotar L(θ|x).",
                                  "tips": "Sempre use log para evitar underflow numérico em produtos pequenos.",
                                  "learningObjective": "Dominar a definição e interpretação intuitiva da função de verossimilhança.",
                                  "commonMistakes": "Confundir verossimilhança com probabilidade posterior (Bayes); lembrar que é frequentista."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir o Estimador de Máxima Verossimilhança (MLE)",
                                  "subSteps": [
                                    "Escreva formalmente θ̂_MLE = argmax_θ L(θ|x), ou equivalentemente argmax_θ ℓ(θ|x).",
                                    "Discuta condições para existência e unicidade (ex: convexidade da log-verossimilhança).",
                                    "Implemente numericamente via otimização (gradiente ou métodos de Newton).",
                                    "Calcule MLE analiticamente para distribuições comuns (Normal, Poisson).",
                                    "Explique o papel em modelos econométricos parametrizados."
                                  ],
                                  "verification": "Derive θ̂_MLE para uma amostra de uma Normal(μ,σ²) conhecida σ².",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Livro de estatística (ex: Casella & Berger), Python com scipy.optimize.",
                                  "tips": "Padronize variáveis para melhorar convergência numérica.",
                                  "learningObjective": "Saber definir e calcular o MLE formal e computacionalmente.",
                                  "commonMistakes": "Ignorar restrições no espaço de parâmetros θ; sempre verifique o domínio."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Justificativa Intuitiva do MLE",
                                  "subSteps": [
                                    "Explique intuitivamente: MLE escolhe θ que torna os dados observados mais prováveis.",
                                    "Compare com método dos momentos: MLE é mais eficiente assintoticamente.",
                                    "Discuta propriedades: consistência, asymptoticidade normal (√n(θ̂ - θ) ~ N(0,I^{-1})).",
                                    "Use analogia: como um detetive escolhe hipótese que melhor explica evidências.",
                                    "Aplique em contexto econométrico: maximizar probabilidade de observar PIBs dados."
                                  ],
                                  "verification": "Escreva um parágrafo explicando por que MLE maximiza 'probabilidade dos dados' sem jargões avançados.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Artigos introdutórios sobre MLE em econometria, quadro branco para analogias.",
                                  "tips": "Use gráficos de L(θ|x) com pico no MLE para visual intuitiva.",
                                  "learningObjective": "Articular a intuição por trás do MLE em linguagem acessível.",
                                  "commonMistakes": "Confundir 'maximizar probabilidade dos dados' com maximizar P(θ|x); é P(x|θ)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicação em Modelos Econométricos para Engenharia",
                                  "subSteps": [
                                    "Escolha um modelo simples: regressão linear com erros Normais para previsão de demanda.",
                                    "Escreva L(θ|x) para θ = (β0, β1), derive MLE (que coincide com OLS).",
                                    "Implemente em software para dados reais de engenharia econômica (ex: custos de produção).",
                                    "Avalie robustez: bootstrapping para intervalos de confiança.",
                                    "Discuta extensões: MLE em modelos logit/probit para escolha discreta."
                                  ],
                                  "verification": "Ajuste um modelo MLE em dados sintéticos de regressão e compare com OLS.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Dataset CSV de exemplo (PIB vs investimento), R ou Python (statsmodels/sklearn).",
                                  "tips": "Comece com dados pequenos para depuração rápida.",
                                  "learningObjective": "Aplicar MLE em cenários econométricos relevantes para engenharia.",
                                  "commonMistakes": "Assumir Normalidade sem verificação; teste resíduos."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão linear para prever custo de produção (y) baseado em horas de mão-de-obra (x), assuma erros ~ N(0,σ²). O MLE para β = (β0, β1) maximiza L(β|y,x), resultando em β̂_MLE = argmin SSE, idêntico ao OLS. Com dados: y = [10,15,20], x=[1,2,3], calcule β̂ ≈ (1, 4.5), que torna esses custos 'mais prováveis' sob o modelo.",
                              "finalVerifications": [
                                "Derivar corretamente θ̂_MLE para Bernoulli e Normal.",
                                "Explicar intuitivamente por que MLE escolhe o θ 'melhor'.",
                                "Implementar otimização numérica de ℓ(θ|x) em Python/R.",
                                "Identificar quando MLE coincide com outros estimadores (ex: OLS).",
                                "Discutir limitações: viés em amostras pequenas.",
                                "Aplicar a um dataset econométrico simples."
                              ],
                              "assessmentCriteria": [
                                "Correção matemática na definição e derivação de MLE (40%).",
                                "Clareza e precisão da justificativa intuitiva (25%).",
                                "Profundidade na aplicação prática e código funcional (20%).",
                                "Identificação de erros comuns e propriedades assintóticas (10%).",
                                "Conexão com contexto econométrico/engenharia (5%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Propriedades assintóticas e testes de hipóteses.",
                                "Machine Learning: Paralelo com perda negativa log-likelihood.",
                                "Economia: Modelagem de séries temporais e painéis.",
                                "Computação: Otimização numérica e gradiente descendente.",
                                "Engenharia: Otimização de parâmetros em simulações de sistemas."
                              ],
                              "realWorldApplication": "Em engenharia econômica, MLE é usado para estimar parâmetros em modelos de demanda de energia (ex: logit para escolha de fontes), permitindo previsões precisas para planejamento de infraestrutura sustentável, como otimizar portfólios de energia renovável baseados em dados históricos de consumo."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.1.1"
                            ]
                          },
                          {
                            "id": "11.3.2.2.2",
                            "name": "Maximizar analiticamente",
                            "description": "Resolver ∂l(θ)/∂θ = 0 para encontrar MLE em casos simples como normal univariada e regressão linear clássica, comparando com OLS.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de Verossimilhança e Log-Verossimilhança",
                                  "subSteps": [
                                    "Defina a função de verossimilhança l(θ) para uma amostra de dados independentes.",
                                    "Derive a log-verossimilhança ∂l(θ) a partir de l(θ), explicando por que usamos log.",
                                    "Identifique os parâmetros θ em contextos simples como normal univariada.",
                                    "Escreva a equação geral ∂l(θ)/∂θ = 0 para maximização.",
                                    "Pratique computando log-verossimilhança para uma distribuição normal simples."
                                  ],
                                  "verification": "Escreva corretamente a log-verossimilhança para uma amostra N(μ, σ²) e confirme que ∂l/∂θ leva a zero.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Papel e caneta, calculadora, notebook Jupyter com NumPy para verificação numérica.",
                                  "tips": "Sempre tome log natural para simplificar produtos em somas.",
                                  "learningObjective": "Compreender a base matemática da máxima verossimilhança (MLE) e preparar para derivações analíticas.",
                                  "commonMistakes": "Confundir verossimilhança com probabilidade; esquecer de somar logs para amostras independentes."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar MLE Analiticamente para Distribuição Normal Univariada",
                                  "subSteps": [
                                    "Escreva a densidade da normal univariada para n observações x_i ~ N(μ, σ²).",
                                    "Construa l(μ, σ²) e ∂l(μ, σ²).",
                                    "Compute ∂l/∂μ = 0 e resolva para μ̂.",
                                    "Compute ∂l/∂σ² = 0 e resolva para σ̂².",
                                    "Verifique que μ̂ = média amostral e σ̂² = variância amostral corrigida."
                                  ],
                                  "verification": "Obtenha μ̂ = (1/n)∑x_i e σ̂² = (1/n)∑(x_i - μ̂)², testando com dados simulados.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Papel, calculadora simbólica (SymPy em Python), conjunto de dados simulados (ex: 10 valores normais).",
                                  "tips": "Use propriedades da soma para simplificar derivadas de somatórios.",
                                  "learningObjective": "Resolver analiticamente as equações de pontuação para MLE na normal univariada.",
                                  "commonMistakes": "Usar 1/(n-1) em vez de 1/n para σ̂² na MLE; ignorar o fator -2 na derivada de σ²."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar MLE para Regressão Linear Clássica",
                                  "subSteps": [
                                    "Modele y_i = X_i β + ε_i com ε_i ~ N(0, σ²).",
                                    "Escreva l(β, σ²) assumindo normalidade dos erros.",
                                    "Derive ∂l/∂β = 0, mostrando que leva a (X^T X) β̂ = X^T y.",
                                    "Derive ∂l/∂σ² = 0 para σ̂².",
                                    "Compare com OLS: note que MLE coincide com OLS sob normalidade."
                                  ],
                                  "verification": "Resolva para β̂ = (X^T X)^{-1} X^T y e confirme igualdade com OLS.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Papel, matrizes exemplo (ex: X 3x2), software como Python com NumPy/SciPy para matrizes.",
                                  "tips": "Pense em termos matriciais desde o início para eficiência.",
                                  "learningObjective": "Aplicar derivação MLE ao modelo de regressão linear e reconhecer sua equivalência com OLS.",
                                  "commonMistakes": "Esquecer a independência dos erros; confundir σ² com variância residual corrigida."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar MLE com OLS e Realizar Verificações Finais",
                                  "subSteps": [
                                    "Explique por que MLE = OLS sob normalidade homocedástica.",
                                    "Discuta diferenças sem normalidade (MLE ainda consistente, OLS não necessariamente).",
                                    "Aplique a ambos os casos com dados reais simulados.",
                                    "Avalie propriedades assintóticas (consistência, eficiência).",
                                    "Documente soluções em um relatório curto."
                                  ],
                                  "verification": "Gere relatório comparando estimativas MLE e OLS em um dataset, confirmando igualdade.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Jupyter notebook, dados simulados (normal e não-normal), bibliotecas statsmodels/sklearn.",
                                  "tips": "Simule violações de normalidade para ver diferenças.",
                                  "learningObjective": "Diferenciar contextos onde MLE e OLS coincidem e sintetizar o aprendizado.",
                                  "commonMistakes": "Assumir sempre igualdade sem normalidade; ignorar σ² nas comparações."
                                }
                              ],
                              "practicalExample": "Considere dados y = [2.1, 3.9, 1.8, 4.2] com X = [[1,1], [1,2], [1,3], [1,4]] para regressão linear. Derive MLE: β̂ = (X^T X)^{-1} X^T y ≈ [0.5, 1.0], σ̂² ≈ 0.15. Para normal univariada em x = [1,2,3,2,4]: μ̂=2.4, σ̂²=1.3. Compare com OLS via código.",
                              "finalVerifications": [
                                "Derivações analíticas para normal univariada coincidem com médias/variâncias amostrais.",
                                "Equações normais para regressão linear resolvem corretamente β̂ OLS.",
                                "Cálculos numéricos em exemplos práticos batem com soluções simbólicas.",
                                "Relatório compara MLE vs OLS, destacando condições de equivalência.",
                                "Identifica pelo menos 3 diferenças potenciais sem normalidade.",
                                "Verifica propriedades via simulação em código."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas derivadas ∂l/∂θ = 0 (sem erros algébricos).",
                                "Correta identificação de soluções fechadas para μ, σ², β.",
                                "Explicação clara da equivalência MLE-OLS e limitações.",
                                "Uso apropriado de notação matricial em regressão.",
                                "Aplicação prática em exemplos com verificação numérica.",
                                "Síntese em relatório coeso e acionável."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência bayesiana (MLE como limite de posteriori).",
                                "Machine Learning: Otimização em gradiente descendente (base analítica).",
                                "Programação: Implementação em Python (SymPy para simbólico, SciPy para numérico).",
                                "Econometria: Modelos lineares e suposições de normalidade.",
                                "Física: Estimativa de parâmetros em modelos probabilísticos."
                              ],
                              "realWorldApplication": "Em data science, maximizar analiticamente MLE/OLS é essencial para entender algoritmos de regressão em finanças (previsão de retornos), biologia (modelagem de crescimento populacional) e engenharia (calibração de sensores), permitindo diagnósticos rápidos sem simulações pesadas e otimizações em modelos Gaussianos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.1.3"
                            ]
                          },
                          {
                            "id": "11.3.2.2.3",
                            "name": "Maximizar numericamente",
                            "description": "Aplicar métodos numéricos como Newton-Raphson para maximizar log-verossimilhança em modelos não-lineares, usando exemplos em R de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Log-Verossimilhança e sua Maximização",
                                  "subSteps": [
                                    "Defina verossimilhança e log-verossimilhança para distribuições probabilísticas comuns (ex: normal, Poisson).",
                                    "Derive a função log-likelihood para um modelo não-linear simples, como regressão logística.",
                                    "Explique por que maximizar a log-likelihood equivale a encontrar os melhores parâmetros do modelo.",
                                    "Identifique cenários onde métodos analíticos falham, necessitando de abordagens numéricas.",
                                    "Calcule manualmente a log-likelihood para um dataset pequeno de 10 observações."
                                  ],
                                  "verification": "Resuma em um parágrafo a importância da maximização e forneça a derivada da log-likelihood para um exemplo.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Livro de Estatística Inferencial (ex: Casella & Berger), notebook Jupyter ou RStudio.",
                                  "tips": "Use plotagens para visualizar a função log-likelihood e entender seu formato unimodal.",
                                  "learningObjective": "Entender conceitualmente a log-verossimilhança e sua otimização em modelos não-lineares.",
                                  "commonMistakes": "Confundir verossimilhança com probabilidade; ignorar o logaritmo natural."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Revisar o Algoritmo Newton-Raphson para Otimização",
                                  "subSteps": [
                                    "Revise a fórmula iterativa: θ_{k+1} = θ_k - H^{-1} ∇ℓ(θ_k), onde ∇ℓ é o gradiente e H a Hessiana.",
                                    "Implemente a derivada primeira (score) e segunda (informação de Fisher) para log-likelihood.",
                                    "Discuta condições de convergência: Hessiana positiva definida, ponto inicial próximo.",
                                    "Compare com gradiente descendente simples para destacar vantagens quadráticas.",
                                    "Simule 5 iterações manualmente em papel para uma função quadrática simples."
                                  ],
                                  "verification": "Derive e compute gradiente e Hessiana para um modelo de regressão linear não-linearizado.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Documentação R sobre otimização (optim package), calculadora simbólica como SymPy.",
                                  "tips": "Sempre verifique a inversibilidade da Hessiana antes de cada iteração.",
                                  "learningObjective": "Dominar a matemática por trás do Newton-Raphson aplicada à máxima verossimilhança.",
                                  "commonMistakes": "Esquecer o sinal negativo na atualização; usar aproximações lineares sem validar curvatura."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Newton-Raphson em R para um Modelo Simples",
                                  "subSteps": [
                                    "Carregue dados simulados (ex: normal com média desconhecida) e defina a função log-likelihood.",
                                    "Escreva funções para gradiente e Hessiana usando derivadas analíticas.",
                                    "Implemente o loop iterativo com critérios de parada (tolerância 1e-6, max 100 iterações).",
                                    "Teste com ponto inicial aleatório e plote a convergência (θ vs iteração).",
                                    "Compare resultado com otimização built-in (optim() com método 'BFGS')."
                                  ],
                                  "verification": "Código converge ao valor verdadeiro (conhecido dos dados simulados) em <20 iterações.",
                                  "estimatedTime": "4 horas",
                                  "materials": "RStudio, pacote 'numDeriv' para validação numérica de derivadas, dataset simulado.",
                                  "tips": "Use browser() para debug em loops; vectorize funções para eficiência.",
                                  "learningObjective": "Implementar do zero o Newton-Raphson em R para maximização de log-likelihood.",
                                  "commonMistakes": "Índices off-by-one em vetores; não lidar com singularidade da Hessiana (use solve() com tryCatch)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a Dados Reais de Engenharia",
                                  "subSteps": [
                                    "Carregue dataset de engenharia (ex: tempos de falha de tubos sob pressão, distribuição Weibull).",
                                    "Estime parâmetros (shape, scale) via log-likelihood com Newton-Raphson.",
                                    "Ajuste modelo não-linear e compute intervalos de confiança via Hessiana inversa.",
                                    "Valide com QQ-plot e teste de Kolmogorov-Smirnov.",
                                    "Sensibilidade: teste múltiplos pontos iniciais e compare com nlm() ou optim()."
                                  ],
                                  "verification": "Parâmetros estimados produzem log-likelihood máxima > log-likelihood nula; plots mostram bom fit.",
                                  "estimatedTime": "5 horas",
                                  "materials": "Dataset público (ex: Kaggle 'Failure Times Engineering'), pacotes 'fitdistrplus', 'ggplot2'.",
                                  "tips": "Padronize dados para evitar overflow em exp(); use log-space para estabilidade numérica.",
                                  "learningObjective": "Aplicar Newton-Raphson a problemas reais de engenharia para estimação de parâmetros.",
                                  "commonMistakes": "Escolha errada de distribuição; ignorar censura nos dados de falha."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e Refinar a Otimização",
                                  "subSteps": [
                                    "Calcule métricas: tempo de convergência, precisão (comparado a verdade conhecida).",
                                    "Implemente regularização (ex: penalidade L2) para modelos overparameterizados.",
                                    "Teste robustez com dados ruidosos ou outliers.",
                                    "Documente código em função reutilizável com argumentos flexíveis.",
                                    "Gere relatório com summary: parâmetros, SE, AIC."
                                  ],
                                  "verification": "Função funciona em dataset independente; AIC < baseline.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Pacotes 'knitr' para relatório, dados de teste adicionais.",
                                  "tips": "Salve seeds para reprodutibilidade; profile() para otimizar performance.",
                                  "learningObjective": "Avaliar qualidade da otimização e preparar para uso em produção.",
                                  "commonMistakes": "Sobreajuste sem cross-validation; não reportar múltiplos mínimos locais."
                                }
                              ],
                              "practicalExample": "Em dados de engenharia de falhas de tubos (tempos de vida: 10, 20, 35, 50 dias), modele com Weibull(θ1=shape, θ2=scale). Implemente Newton-Raphson em R para maximizar ℓ(θ) = ∑[ (shape-1)log(t_i/scale) - (t_i/scale)^shape ], convergindo de θ0=(2,30) para θ_hat=(1.8, 25.2), validado por QQ-plot.",
                              "finalVerifications": [
                                "Código R executa sem erros e converge em <50 iterações.",
                                "Parâmetros estimados têm erros padrão <10% via Hessiana.",
                                "Log-likelihood máxima excede valor inicial em >20%.",
                                "Plots de convergência mostram monotonicidade.",
                                "Comparação com optim() difere <1e-4.",
                                "Aplicação a dataset de engenharia produz fit visual aceitável."
                              ],
                              "assessmentCriteria": [
                                "Precisão: erro nos parâmetros <5% do verdadeiro.",
                                "Eficiência: tempo total <10s para 1000 observações.",
                                "Robustez: converge de 80% dos 10 pontos iniciais aleatórios.",
                                "Documentação: código comentado com funções modulares.",
                                "Validação: derivadas numéricas matching analíticas (diff <1e-6).",
                                "Interpretação: relatório explica resultados em contexto de engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência bayesiana via MCMC como alternativa.",
                                "Programação: Otimização em Python (SciPy.optimize).",
                                "Engenharia: Modelagem de confiabilidade e previsão de falhas.",
                                "Matemática: Análise numérica e equações não-lineares."
                              ],
                              "realWorldApplication": "Em engenharia mecânica, maximizar log-verossimilhança em dados de fadiga de materiais para estimar vida útil de componentes, otimizando manutenção preditiva e reduzindo custos em indústrias como óleo & gás."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.2.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "11.3.2.3",
                        "name": "Propriedades e Inferência com MLE",
                        "description": "Propriedades assintóticas dos estimadores MLE e sua aplicação em testes de hipóteses e intervalos de confiança em contextos econométricos.",
                        "specificSkills": [
                          {
                            "id": "11.3.2.3.1",
                            "name": "Descrever propriedades assintóticas",
                            "description": "Explicar consistência, normalidade assintótica N(θ, I(θ)^{-1}) e eficiência sob regularidade, contrastando com OLS em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Consistência Assintótica do MLE",
                                  "subSteps": [
                                    "Defina consistência assintótica: plim θ_hat = θ quando n → ∞.",
                                    "Revise o Teorema de Consistência de MLE sob condições de regularidade (identificabilidade, diferenciabilidade).",
                                    "Estude a prova via Lei dos Grandes Números aplicada ao score function.",
                                    "Discuta implicações: em amostras grandes, θ_hat converge para o verdadeiro θ.",
                                    "Pratique com exemplo simples: MLE para média de normal."
                                  ],
                                  "verification": "Escreva uma definição precisa e esboce a prova em 5 linhas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de aula sobre MLE, Livro 'Statistical Inference' de Casella & Berger (Cap. 10), Jupyter notebook com simulações.",
                                  "tips": "Use notação probabilística: plim para probabilidades limites.",
                                  "learningObjective": "Compreender e explicar por que MLE é consistente em amostras grandes.",
                                  "commonMistakes": "Confundir consistência com unbiasedness; consistência é assintótica, não finita."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Normalidade Assintótica N(θ, I(θ)^{-1})",
                                  "subSteps": [
                                    "Defina a distribuição assintótica: √n (θ_hat - θ) → N(0, I(θ)^{-1}).",
                                    "Explique o papel da Matriz de Informação de Fisher I(θ) = E[-∂²ℓ/∂θ²].",
                                    "Revise Teorema Central do Limite para o score: √n S_n(θ) → N(0, I(θ)).",
                                    "Derive a variância assintótica via Delta method ou expansão Taylor.",
                                    "Simule em software para visualizar convergência."
                                  ],
                                  "verification": "Derive a normalidade assintótica para um modelo binomial e plote histogramas simulados.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Software R ou Python (statsmodels/scipy), exemplos de código para simulação MLE.",
                                  "tips": "Lembre-se: I(θ)^{-1} é a variância mínima assintótica.",
                                  "learningObjective": "Derivar e interpretar a distribuição normal assintótica do MLE.",
                                  "commonMistakes": "Esquecer o fator √n na normalização; confundir com variância de OLS."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Eficiência Assintótica sob Regularidade",
                                  "subSteps": [
                                    "Defina eficiência assintótica: MLE atinge o bound de Cramér-Rao I(θ)^{-1}.",
                                    "Liste condições de regularidade: suporte independente de θ, log-likelihood duas vezes diferenciável, E[|score|] < ∞.",
                                    "Prove eficiência via sandwich variance ou diretamente.",
                                    "Discuta violações: modelos não-regulares como mistura gaussiana.",
                                    "Compare variâncias: MLE vs. outros estimadores."
                                  ],
                                  "verification": "Liste 4 condições de regularidade e explique impacto de uma violação.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Artigo 'Asymptotic Theory of MLE' (pdf online), quadro branco para derivações.",
                                  "tips": "Eficiência significa menor variância assintótica que qualquer estimador não-biasado.",
                                  "learningObjective": "Explicar por que MLE é o 'melhor' estimador assintoticamente.",
                                  "commonMistakes": "Assumir eficiência sem regularidade; ignorar que é assintótica."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Contrastar MLE com OLS em Grandes Amostras",
                                  "subSteps": [
                                    "Revise OLS: consistência e normalidade N(β, σ²(X'X/n)^{-1}).",
                                    "Compare: MLE para modelo linear gaussiano coincide com OLS.",
                                    "Discuta superioridade de MLE em distribuições não-gaussianas (e.g., logística).",
                                    "Analise eficiência: MLE eficiente para modelo verdadeiro; OLS se modelo errado.",
                                    "Simule comparações de variância em n=1000."
                                  ],
                                  "verification": "Crie tabela comparativa de propriedades (consistência, var. assintótica) para MLE vs OLS em regressão logística.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Python (sklearn para OLS/MLE), dados simulados de regressão.",
                                  "tips": "Em grandes n, ambos convergem, mas MLE é mais geral.",
                                  "learningObjective": "Destacar vantagens do MLE sobre OLS em contextos gerais.",
                                  "commonMistakes": "Pensar OLS sempre eficiente; OLS falha sem normalidade/homoscedasticidade."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão logística para prever churn de clientes (n=10.000), use MLE para estimar coeficientes. Simule amostras crescentes e observe √n(θ_hat - θ) ~ N(0, I(θ)^{-1}), contrastando com OLS que seria inconsistente.",
                              "finalVerifications": [
                                "Derive consistência via LLN em um modelo específico.",
                                "Calcule I(θ) e variância assintótica para Bernoulli(p).",
                                "Liste condições de regularidade e uma contraexemplo.",
                                "Compare MSE assintótico MLE vs OLS em simulação.",
                                "Explique intuição de eficiência em 3 frases.",
                                "Plote curvas de convergência para n=10,100,1000."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas derivações (80% correto).",
                                "Clareza na explicação de conceitos assintóticos.",
                                "Uso correto de notação (plim, N(μ,Σ), I(θ)).",
                                "Profundidade na comparação MLE-OLS com evidências.",
                                "Criatividade em exemplos e simulações práticas.",
                                "Identificação precisa de condições/violação."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema Central do Limite e LLN.",
                                "Machine Learning: Otimização em redes neurais (análoga a MLE).",
                                "Econometria: Inferência em grandes dados panel.",
                                "Computação Científica: Simulações Monte Carlo para propriedades assintóticas."
                              ],
                              "realWorldApplication": "Em bioinformática, MLE é usado para estimar parâmetros genéticos em GWAS com milhões de SNPs; propriedades assintóticas garantem inferência confiável em big data, superando OLS em modelos não-lineares como survival analysis."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.2.1"
                            ]
                          },
                          {
                            "id": "11.3.2.3.2",
                            "name": "Calcular matriz de informação de Fisher",
                            "description": "Computar I(θ) = -E[∂²l/∂θ∂θ'] para avaliar variância assintótica em regressão linear e modelos de séries temporais básicas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Derivar o Log-Likelihood para o Modelo Específico",
                                  "subSteps": [
                                    "Identifique o modelo: para regressão linear Y_i = X_i θ + ε_i, ε_i ~ N(0, σ²).",
                                    "Escreva a densidade conjunta: produto de densidades normais para cada observação.",
                                    "Compute o log-likelihood l(θ) = ∑ log f(y_i | θ) = -n/2 log(2πσ²) - 1/(2σ²) ∑ (y_i - X_i θ)^2.",
                                    "Simplifique para foco em θ (assumindo σ conhecido ou perfilado).",
                                    "Verifique dimensionalidade: l(θ) é escalar, θ é vetor p x 1."
                                  ],
                                  "verification": "Derive l(θ) manualmente para um modelo de regressão linear com p=2 e confirme com fórmula padrão.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Caderno e caneta",
                                    "Software Python (NumPy/SciPy)",
                                    "Exemplo de dados sintéticos"
                                  ],
                                  "tips": "Sempre inclua constantes para derivadas precisas, mas note que elas somem em normalizações.",
                                  "learningObjective": "Entender a forma exata do log-likelihood em modelos paramétricos comuns como regressão linear.",
                                  "commonMistakes": [
                                    "Esquecer o fator -1/(2σ²)",
                                    "Confundir log-likelihood com likelihood",
                                    "Ignorar dependência em σ se não fixo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular o Vetor Score (Primeira Derivada ∂l/∂θ)",
                                  "subSteps": [
                                    "Diferencie l(θ) w.r.t. θ: ∂l/∂θ_j = 1/σ² ∑ (y_i - X_i θ) X_{i j}.",
                                    "Escreva em forma matricial: score = (1/σ²) X^T (Y - X θ).",
                                    "Verifique propriedade E[score] = 0 sob modelo verdadeiro.",
                                    "Implemente numericamente em Python para validar derivada analítica.",
                                    "Discuta para séries temporais: adapte para AR(1) com θ = φ."
                                  ],
                                  "verification": "Compute score para θ inicial arbitrário e verifique se é zero no MLE.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com NumPy",
                                    "Dados de regressão linear (sklearn.datasets.make_regression)",
                                    "Calculadora simbólica (SymPy opcional)"
                                  ],
                                  "tips": "Use gradiente descendente mentalmente: score aponta direção de aumento de l(θ).",
                                  "learningObjective": "Dominar o cálculo do vetor score e sua interpretação como gradiente do log-likelihood.",
                                  "commonMistakes": [
                                    "Inverter sinal da derivada",
                                    "Esquecer transposição X^T",
                                    "Não normalizar por σ²"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a Matriz Hessian Observada (Segunda Derivada ∂²l/∂θ∂θ')",
                                  "subSteps": [
                                    "Diferencie score w.r.t. θ: ∂²l/∂θ∂θ' = -1/σ² X^T X (Hessian observada).",
                                    "Confirme que é simétrica e negativa definida para modelos bem especificados.",
                                    "Para uma observação: Hessian_i = -1/σ² X_i^T X_i.",
                                    "Some sobre i: H(θ) = ∑ Hessian_i = -1/σ² X^T X.",
                                    "Avalie numericamente: use finite differences para validar."
                                  ],
                                  "verification": "Hessian no MLE deve ser -1/σ² X^T X; compare com implementação.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Python (NumPy para X^T X)",
                                    "SymPy para derivadas simbólicas",
                                    "Dados com pelo menos 10 observações"
                                  ],
                                  "tips": "Em regressão linear, Hessian é independente de θ e Y, facilitando!",
                                  "learningObjective": "Computar corretamente a matriz de segundas derivadas parciais do log-likelihood.",
                                  "commonMistakes": [
                                    "Esquecer o sinal negativo",
                                    "Confundir Hessian observada com esperada",
                                    "Erro em produto externo X_i^T X_i"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Computar a Matriz de Informação de Fisher I(θ) = -E[H(θ)]",
                                  "subSteps": [
                                    "Tome expectativa: E[H(θ)] = E[-1/σ² X^T X] = -1/σ² X^T X (pois X fixo).",
                                    "Assim I(θ) = 1/σ² X^T X, independente de θ em regressão linear.",
                                    "Para MLE ˆθ, Var(ˆθ) ≈ I(ˆθ)^{-1}.",
                                    "Estenda para séries temporais AR(1): compute E[segundas derivadas condicionais].",
                                    "Implemente em código: calcule I e inverta para variâncias assintóticas."
                                  ],
                                  "verification": "Inverta I(θ) e compare com (X^T X)^{-1} σ², a variância exata OLS.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Python (NumPy.linalg.inv)",
                                    "Dados de séries temporais (statsmodels.datasets)",
                                    "Referência teórica (livro de Casella Berger)"
                                  ],
                                  "tips": "Para modelos não lineares, use Monte Carlo para aproximar E[H].",
                                  "learningObjective": "Finalizar o cálculo de I(θ) e ligar à variância assintótica do MLE.",
                                  "commonMistakes": [
                                    "Confundir I observada com esperada",
                                    "Esquecer inverso para variância",
                                    "Assumir X estocástico sem justificativa"
                                  ]
                                }
                              ],
                              "practicalExample": "Em regressão linear simples Y = β0 + β1 X + ε, n=100, σ=1: I(β) = n/σ² [[1, μ_x], [μ_x, μ_x² + var(x)]], onde μ_x e var(x) de X. Inverta para IC assintóticos de β1.",
                              "finalVerifications": [
                                "Deriva corretamente l(θ), score e Hessian para regressão linear.",
                                "Computa I(θ) = X^T X / σ² e interpreta como precisão.",
                                "Liga I(θ)^{-1} à variância assintótica do MLE.",
                                "Aplica a AR(1): I(φ) ≈ n / (1-φ²) para |φ|<1.",
                                "Valida numericamente com simulações Monte Carlo.",
                                "Discute limitações em amostras pequenas."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas derivadas (sem erros algébricos).",
                                "Correta expectativa negativa para I(θ).",
                                "Interpretação estatística: ligação com eficiência assintótica.",
                                "Implementação computacional funcional e validada.",
                                "Extensão coerente a séries temporais.",
                                "Clareza em verificações e exemplos numéricos."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Propriedades assintóticas MLE.",
                                "Programação Científica: NumPy/SciPy para Hessian numérico.",
                                "Séries Temporais: Avaliação em modelos ARMA.",
                                "Machine Learning: Otimização em GLM e redes neurais.",
                                "Econometria: Testes de hipóteses em regressões."
                              ],
                              "realWorldApplication": "Em previsão de séries temporais financeiras (ex: retornos de ações), calcula variâncias assintóticas de parâmetros MLE para construir intervalos de confiança robustos, auxiliando decisões de investimento e gestão de risco."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.2.2"
                            ]
                          },
                          {
                            "id": "11.3.2.3.3",
                            "name": "Realizar inferência com MLE",
                            "description": "Construir testes de razão de verossimilhança e intervalos de confiança assintóticos, aplicando a dados de engenharia como análise de eficiência de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as propriedades assintóticas do Estimador de Máxima Verossimilhança (MLE)",
                                  "subSteps": [
                                    "Revise a definição de MLE e a função de verossimilhança para distribuições comuns (ex: normal, exponencial).",
                                    "Estude a consistência assintótica: prove que MLE converge em probabilidade para o verdadeiro parâmetro.",
                                    "Analise a normalidade assintótica: derive a distribuição aproximada sqrt(n)(θ̂ - θ) ~ N(0, I(θ)^{-1}).",
                                    "Calcule a matriz de informação de Fisher para exemplos simples.",
                                    "Discuta a eficiência assintótica em comparação com outros estimadores."
                                  ],
                                  "verification": "Derive corretamente a distribuição assintótica do MLE para uma distribuição exponencial e calcule a matriz de informação de Fisher.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Apostila de Estatística Inferencial",
                                    "Software Python (scipy.stats, numpy)",
                                    "Exemplos de distribuições probabilísticas"
                                  ],
                                  "tips": [
                                    "Comece com distribuições univariadas para simplificar os cálculos.",
                                    "Use simulações Monte Carlo para visualizar a convergência assintótica."
                                  ],
                                  "learningObjective": "Entender as bases teóricas que justificam a inferência assintótica com MLE.",
                                  "commonMistakes": [
                                    "Confundir propriedades finitas com assintóticas.",
                                    "Ignorar a dependência da matriz de informação nos dados observados."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir testes de razão de verossimilhança (LRT)",
                                  "subSteps": [
                                    "Defina a estatística LRT: Λ = L(θ0)/L(θ̂), onde θ0 é sob H0.",
                                    "Derive a aproximação assintótica: -2 log Λ ~ χ²(df), com df = dim(θ) - dim(θ0).",
                                    "Implemente o LRT em código para testar H0: θ = θ0 vs H1: θ ≠ θ0.",
                                    "Calcule valores-p e regiões de rejeição para diferentes níveis de significância.",
                                    "Valide com simulações para verificar o tamanho e potência do teste."
                                  ],
                                  "verification": "Construa e execute um LRT para testar a média de uma normal com variância conhecida, obtendo p-valor correto.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python ou R (funções lmtest ou statsmodels)",
                                    "Datasets simulados de processos exponenciais"
                                  ],
                                  "tips": [
                                    "Padronize sempre para a distribuição qui-quadrado.",
                                    "Verifique se as condições de regularidade para a aproximação assintótica são atendidas."
                                  ],
                                  "learningObjective": "Saber formular e computar testes de hipóteses baseados em MLE.",
                                  "commonMistakes": [
                                    "Esquecer de maximizar sob restrições de H0.",
                                    "Usar df incorreto ao calcular a distribuição qui-quadrado."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir intervalos de confiança assintóticos baseados em MLE",
                                  "subSteps": [
                                    "Estime o erro padrão assintótico: se(θ̂) = 1 / sqrt(n * I(θ̂)).",
                                    "Construa ICs de nível (1-α): θ̂ ± z_{α/2} * se(θ̂).",
                                    "Estenda para perfis de verossimilhança para parâmetros multivariados.",
                                    "Implemente em software e compare cobertura via simulações.",
                                    "Ajuste para variância observada vs esperada."
                                  ],
                                  "verification": "Calcule um IC 95% para o parâmetro de uma distribuição de Poisson usando MLE e verifique cobertura em 100 simulações.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Biblioteca statsmodels ou scipy em Python",
                                    "Notas sobre matrizes de informação"
                                  ],
                                  "tips": [
                                    "Use a inversa da matriz de Hessian observada para I(θ̂) em casos numéricos.",
                                    "Sempre reporte o comprimento do IC como medida de precisão."
                                  ],
                                  "learningObjective": "Dominar a construção prática de ICs assintóticos para inferência paramétrica.",
                                  "commonMistakes": [
                                    "Usar distribuição t de Student em vez de normal.",
                                    "Não escalar corretamente pelo sqrt(n)."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar inferência com MLE a dados reais de engenharia",
                                  "subSteps": [
                                    "Selecione um dataset de eficiência de processos (ex: tempos de ciclo em manufatura ~ exponencial).",
                                    "Ajuste modelo via MLE, realize LRT para hipóteses relevantes (ex: taxa média = benchmark).",
                                    "Construa ICs assintóticos e interprete no contexto da engenharia.",
                                    "Verifique suposições (normalidade dos scores, etc.) com diagnósticos.",
                                    "Compare resultados com métodos alternativos (ex: bootstrap) e discuta implicações."
                                  ],
                                  "verification": "Produza relatório com LRT, ICs e interpretação para um dataset fornecido, sem erros computacionais.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dataset real de tempos de processo (ex: de Kaggle)",
                                    "Python (pandas, scipy, matplotlib)"
                                  ],
                                  "tips": [
                                    "Visualize resíduos para checar adequação do modelo.",
                                    "Documente todas as decisões de modelagem."
                                  ],
                                  "learningObjective": "Integrar inferência MLE em análises de dados de engenharia prática.",
                                  "commonMistakes": [
                                    "Não checar outliers ou violações de i.i.d.",
                                    "Ignorar contexto aplicado na interpretação."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma linha de produção, tempos de ciclo seguem exponencial(λ). Use MLE para estimar λ de 100 observações. Teste H0: λ=0.2 (eficiência benchmark) via LRT. Construa IC 95% assintótico para λ e interprete: se IC exclui 0.2 e LRT rejeita, sugira otimização do processo.",
                              "finalVerifications": [
                                "Derivação correta da estatística LRT e sua distribuição assintótica.",
                                "Cálculo preciso de IC assintótico com erro padrão via Fisher information.",
                                "Implementação numérica em software sem erros.",
                                "Interpretação contextualizada para dados de engenharia.",
                                "Verificação de suposições assintóticas via simulações.",
                                "Relatório claro com conclusões acionáveis."
                              ],
                              "assessmentCriteria": [
                                "Correção teórica das fórmulas e derivações (30%).",
                                "Precisão computacional e código reproduzível (25%).",
                                "Qualidade da interpretação e ligação com engenharia (20%).",
                                "Cobertura de verificações e diagnósticos (15%).",
                                "Clareza e organização do relatório (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Computacional: Implementação numérica de otimização.",
                                "Engenharia de Processos: Análise de eficiência e Six Sigma.",
                                "Programação Científica: Uso de Python/R para inferência.",
                                "Machine Learning: MLE como base para modelos probabilísticos."
                              ],
                              "realWorldApplication": "Na indústria manufatureira, inferência com MLE permite testar eficiência de processos (ex: tempo médio de montagem), construir ICs para metas de qualidade e otimizar linhas de produção, reduzindo custos e melhorando controle estatístico de processos (SPC)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "11.3.2.3.1",
                              "11.3.2.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.3",
                    "name": "Métodos Generalizados dos Momentos",
                    "description": "Abordagem para estimação robusta utilizando condições de momentos generalizados.",
                    "individualConcepts": [
                      {
                        "id": "10.1.3.3.1",
                        "name": "Método dos Momentos Clássico",
                        "description": "Fundamentos do método dos momentos como base para estimação de parâmetros, resolvendo equações baseadas em expectativas populacionais igualadas às amostrais.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.3.1.1",
                            "name": "Definir condições de momentos populacionais",
                            "description": "Explicar as condições de momentos E[g(θ)] = 0, onde g são funções de momentos e θ parâmetros do modelo, no contexto de regressão linear.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos fundamentais de expectativa e momentos estatísticos",
                                  "subSteps": [
                                    "Defina expectativa matemática E[Z] para uma variável aleatória Z.",
                                    "Explique o que são momentos de primeira, segunda ordem e momentos centralizados.",
                                    "Diferencie momentos populacionais de momentos amostrais.",
                                    "Calcule exemplos simples de momentos para distribuições conhecidas (ex: normal).",
                                    "Relacione momentos com parâmetros de modelos probabilísticos."
                                  ],
                                  "verification": "Resolva 3 exercícios de cálculo de momentos e explique diferenças entre populacional e amostral.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de Estatística Básica (cap. Expectativas)",
                                    "Calculadora ou Python/Jupyter para simulações"
                                  ],
                                  "tips": "Use notação E[ ] consistentemente para evitar confusões com médias.",
                                  "learningObjective": "Compreender a base teórica de momentos como funções de parâmetros.",
                                  "commonMistakes": "Confundir momentos brutos com centralizados; ignorar normalização."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir o Método dos Momentos Clássico",
                                  "subSteps": [
                                    "Descreva o princípio geral: igualar momentos populacionais a amostrais.",
                                    "Apresente a notação E[g(θ)] = 0, onde g(θ) são funções de momentos.",
                                    "Discuta como resolver o sistema de equações para estimar θ.",
                                    "Compare com máxima verossimilhança em termos de suposições.",
                                    "Implemente um exemplo numérico simples (ex: estimativa de média e variância)."
                                  ],
                                  "verification": "Derive as estimativas de θ para um modelo com 2 momentos e verifique numericamente.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Notas de Econometria (cap. GMM)",
                                    "Software R ou Python (pacotes statsmodels)"
                                  ],
                                  "tips": "Comece com casos univariados antes de multivariados para intuitividade.",
                                  "learningObjective": "Dominar a formulação matemática do método dos momentos.",
                                  "commonMistakes": "Não verificar o número de momentos igual ao de parâmetros; assumir identifiabilidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir formalmente as condições de momentos populacionais",
                                  "subSteps": [
                                    "Escreva E[g(θ)] = 0 explicitamente: g(θ) = funções que igualam momentos teóricos a empíricos.",
                                    "Explique por que essas condições definem os verdadeiros parâmetros populacionais θ*.",
                                    "Analise propriedades: ortogonalidade, consistência e assimptótica.",
                                    "Discuta violações e implicações (ex: modelo mal especificado).",
                                    "Prove que soluções amostrais convergem para populacionais sob regularidade."
                                  ],
                                  "verification": "Formule E[g(θ)]=0 para um modelo bivariado e discuta convergência.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Artigo introdutório sobre GMM (Hansen, 1982)",
                                    "Quadro branco para derivações"
                                  ],
                                  "tips": "Visualize graficamente: interseção de hiperplanos E[g]=0.",
                                  "learningObjective": "Explicar rigorosamente o significado das condições E[g(θ)]=0.",
                                  "commonMistakes": "Confundir condições populacionais com amostrais; omitir suposições de momentos finitos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar no contexto de regressão linear",
                                  "subSteps": [
                                    "Modele regressão linear Y = Xθ + ε, com E[ε]=0 e E[Xε]=0.",
                                    "Defina g(θ) = (Y - Xθ) e g(θ) = X(Y - Xθ) para momentos de 1ª e 2ª ordem.",
                                    "Mostre que E[g(θ*)]=0 implica OLS como estimador de momentos.",
                                    "Simule dados e verifique condições populacionais via Monte Carlo.",
                                    "Compare eficiência com outros estimadores."
                                  ],
                                  "verification": "Implemente em código e confirme que médias amostrais de g(θ) aproximam zero.",
                                  "estimatedTime": "70 minutos",
                                  "materials": [
                                    "Python (numpy, pandas, statsmodels)",
                                    "Dataset simulado de regressão"
                                  ],
                                  "tips": "Use seed para reprodutibilidade em simulações.",
                                  "learningObjective": "Conectar condições de momentos à regressão linear clássica.",
                                  "commonMistakes": "Ignorar heterocedasticidade que viola E[Xε]=0; confundir com IV."
                                }
                              ],
                              "practicalExample": "Em uma regressão linear simples Y_i = β0 + β1 X_i + ε_i, as condições populacionais são E[Y - β0 - β1 X] = 0 e E[X(Y - β0 - β1 X)] = 0. Simule 1000 observações com β0=1, β1=2, X~N(0,1), ε~N(0,1), estime θ via momentos e verifique que E[g(θ*)] ≈ 0.",
                              "finalVerifications": [
                                "Derivar E[g(θ)]=0 para regressão linear sem erros.",
                                "Explicar verbalmente o papel das condições na consistência do estimador.",
                                "Simular e plotar g(θ) amostral convergindo a zero.",
                                "Identificar 2 violações comuns e correções.",
                                "Comparar com verossimilhança gaussiana."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação matemática de E[g(θ)]=0 (90% correto).",
                                "Capacidade de derivar condições para modelos específicos.",
                                "Interpretação correta de propriedades assimptóticas.",
                                "Implementação numérica sem erros de código.",
                                "Análise crítica de limitações do método.",
                                "Clareza na comunicação oral/escrita."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Ligação com teoremas de consistência (LLN, TLC).",
                                "Econometria: Base para GMM e estimadores instrumentais.",
                                "Programação Científica: Implementação em Python/R para análise empírica.",
                                "Probabilidade Avançada: Momentos superiores e identifiabilidade."
                              ],
                              "realWorldApplication": "Em finanças, define condições para estimar betas de CAPM via momentos populacionais E[R - β(R_m - R_f)]=0, permitindo testes de modelos em dados reais de retornos de ações."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.3.1.2",
                            "name": "Calcular estimadores de momentos amostrais",
                            "description": "Derivar e computar estimadores resolvendo a média amostral de g(θ) = 0, comparando com Mínimos Quadrados Ordinários (MQO) em modelos lineares.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos do Método dos Momentos Clássico",
                                  "subSteps": [
                                    "Revise os momentos populacionais e amostrais (primeiro e segundo momentos).",
                                    "Defina a função de momentos g(θ) para um modelo paramétrico simples, como distribuição normal.",
                                    "Explique a equação populacional E[g(X, θ)] = 0 e sua aproximação amostral.",
                                    "Identifique condições para consistência e assimptoticidade dos estimadores.",
                                    "Discuta vantagens sobre máxima verossimilhança em certos casos."
                                  ],
                                  "verification": "Resuma em um parágrafo os conceitos chave e dê um exemplo verbal de g(θ).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge)",
                                    "Notas de aula sobre inferência estatística",
                                    "Calculadora ou Python/Jupyter"
                                  ],
                                  "tips": "Comece com exemplos univariados para fixar ideias antes de multivariados.",
                                  "learningObjective": "Entender a base teórica do Método dos Momentos e a equação g(θ) = 0.",
                                  "commonMistakes": "Confundir momentos populacionais com amostrais; ignorar normalização da função g."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar estimadores de momentos amostrais analiticamente",
                                  "subSteps": [
                                    "Escolha um modelo, ex: regressão linear simples Y = β0 + β1 X + ε.",
                                    "Defina momentos como E[Y|X] e Var(ε) = σ².",
                                    "Escreva g(θ) = [média(Y - β0 - β1 X), média((Y - β0 - β1 X)^2 - σ²)].",
                                    "Resolva o sistema médio amostral ḡ(θ) = 0 para θ = (β0, β1, σ²).",
                                    "Simplifique e compare a solução com a forma fechada do MQO."
                                  ],
                                  "verification": "Derive a fórmula explícita para β1 e verifique se coincide com MQO.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Papel e lápis para derivações",
                                    "Software simbólico como SymPy no Python"
                                  ],
                                  "tips": "Use álgebra matricial para generalizar; teste com n=2 para intuição.",
                                  "learningObjective": "Capacitar derivação manual de estimadores resolvendo ḡ(θ) = 0.",
                                  "commonMistakes": "Esquecer de dividir por n na média amostral; não isolar termos corretamente."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar estimadores numericamente com dados reais",
                                  "subSteps": [
                                    "Gere ou carregue um dataset simulado (ex: 100 observações de regressão linear).",
                                    "Implemente a função ḡ(θ) em código (Python/R).",
                                    "Use otimizador numérico (ex: scipy.optimize) para resolver ḡ(θ) = 0.",
                                    "Calcule os estimadores e compute erros padrão via bootstrap.",
                                    "Valide resultados comparando com função pronta de MQO (ex: statsmodels)."
                                  ],
                                  "verification": "Os estimadores numéricos coincidem com MQO até 1e-6 de precisão.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python com numpy, scipy, pandas",
                                    "Dataset exemplo (CSV com X,Y)"
                                  ],
                                  "tips": "Inicialize θ com MQO para convergência rápida; plote ḡ(θ) para debug.",
                                  "learningObjective": "Aplicar computação prática para estimadores de momentos.",
                                  "commonMistakes": "Má escolha de inicialização levando a mínimo local; overflow em funções g."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar estimadores de momentos com MQO em modelos lineares",
                                  "subSteps": [
                                    "Analise viés e variância em simulações Monte Carlo.",
                                    "Compare eficiência assintótica (MQO é eficiente sob homocedasticidade).",
                                    "Teste em dados com heterocedasticidade onde Momentos Generalizados superam MQO.",
                                    "Discuta quando usar cada método (simples vs. robusto).",
                                    "Gere relatório com tabelas de comparação."
                                  ],
                                  "verification": "Tabela comparativa mostra igualdade em modelo homocedástico e diferenças em violado.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Bibliotecas statsmodels, matplotlib"
                                  ],
                                  "tips": "Use seeds fixas para reprodutibilidade; foque em MSE como métrica.",
                                  "learningObjective": "Discernir forças e limitações relativas a MQO.",
                                  "commonMistakes": "Ignorar pressupostos do MQO; confundir GMM com MOM clássico."
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (Y) vs. anos de estudo (X), derive θ = (β0, β1) resolvendo média(Y - β0 - β1 X) = 0 e média(X*(Y - β0 - β1 X)) = 0, obtendo β1 = cov(X,Y)/var(X), idêntico ao MQO.",
                              "finalVerifications": [
                                "Derivação analítica de estimadores para modelo linear simples está correta.",
                                "Código numérico converge e matches MQO em dados homocedásticos.",
                                "Simulação Monte Carlo mostra propriedades estatísticas esperadas.",
                                "Relatório compara corretamente com MQO, citando condições.",
                                "Identifica cenários onde MOM é preferível (ex: misspecification).",
                                "Verificação de consistência via bootstrap é implementada."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de g(θ) e solução de ḡ(θ) = 0 (30%).",
                                "Correção e eficiência do código numérico (25%).",
                                "Análise comparativa profunda com MQO (20%).",
                                "Uso de simulações e visualizações (15%).",
                                "Clareza no relatório e interpretação (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e propriedades assintóticas.",
                                "Econometria: Estimação em modelos de regressão.",
                                "Programação: Otimização numérica em Python/R.",
                                "Machine Learning: Seleção de modelos e feature engineering.",
                                "Finanças: Estimação de parâmetros em séries temporais."
                              ],
                              "realWorldApplication": "Em econometria, calcular estimadores de momentos para parâmetros de volatilidade em modelos GARCH, onde MQO falha por heterocedasticidade, permitindo previsões robustas em trading algorítmico."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.3.1.3",
                            "name": "Analisar propriedades dos estimadores MM",
                            "description": "Discutir consistência, assimptótica normalidade e eficiência dos estimadores de momentos em comparação aos de máxima verossimilhança.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar definições de estimadores de momentos (MM) e máxima verossimilhança (MLE)",
                                  "subSteps": [
                                    "Defina formalmente o estimador de momentos: iguale momentos amostrais aos teóricos e resolva para os parâmetros.",
                                    "Explique a função de verossimilhança e o princípio de máxima verossimilhança.",
                                    "Compare os princípios matemáticos subjacentes de MM e MLE.",
                                    "Liste vantagens e desvantagens iniciais de cada método.",
                                    "Estude exemplos simples, como estimativa de média e variância em Normal."
                                  ],
                                  "verification": "Escreva resumo de 1 página comparando definições e exemplos.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Livro de Estatística Inferencial (ex: Casella & Berger), notas de aula, Python/R para exemplos numéricos.",
                                  "tips": "Use equações LaTeX para clareza nas definições.",
                                  "learningObjective": "Compreender as bases conceituais para análise posterior de propriedades.",
                                  "commonMistakes": "Confundir momentos teóricos com amostrais; ignorar suposições de regularidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar a consistência dos estimadores MM",
                                  "subSteps": [
                                    "Defina consistência em probabilidade e forte.",
                                    "Prove consistência de MM usando Lei dos Grandes Números (LLN).",
                                    "Discuta condições necessárias (identificabilidade dos momentos).",
                                    "Compare com consistência de MLE (Teorema de consistência de MLE).",
                                    "Simule em software para verificar convergência com n crescente."
                                  ],
                                  "verification": "Execute simulação e plote viés vs. n; explique resultados.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Software Python (numpy, matplotlib), Jupyter Notebook.",
                                  "tips": "Comece com distribuição simples como Exponential para prova analítica.",
                                  "learningObjective": "Dominar prova e intuição de consistência para MM vs. MLE.",
                                  "commonMistakes": "Esquecer condições de Cramér para MLE; não verificar em simulações."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Investigar normalidade assintótica dos estimadores MM",
                                  "subSteps": [
                                    "Enuncie Teorema Central do Limite para momentos amostrais.",
                                    "Derive a distribuição assintótica de MM: √n (θ_hat - θ) ~ N(0, V).",
                                    "Compare com assíntotica de MLE: √n (θ_hat - θ) ~ N(0, I(θ)^{-1}).",
                                    "Calcule matriz de variância assintótica para MM em exemplo específico.",
                                    "Realize simulações para validar normalidade em grandes amostras."
                                  ],
                                  "verification": "Gere QQ-plots das distribuições simuladas e compare com normal.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Python (scipy.stats para QQ-plot), referências teóricas.",
                                  "tips": "Use aproximação delta para funções de momentos.",
                                  "learningObjective": "Entender derivadas assintóticas e suas implicações para inferência.",
                                  "commonMistakes": "Confundir matriz de informação de Fisher com variância de MM."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar eficiência dos estimadores MM e MLE",
                                  "subSteps": [
                                    "Defina eficiência assintótica e variância de Cramér-Rao.",
                                    "Prove que MLE é assintoticamente eficiente sob regularidade.",
                                    "Mostre que MM geralmente tem maior variância assintótica que MLE.",
                                    "Discuta casos onde MM é eficiente (ex: Normal com momentos baixos).",
                                    "Analise trade-offs: simplicidade de MM vs. eficiência de MLE."
                                  ],
                                  "verification": "Calcule razões de variância assintótica em tabela para exemplos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": "Calculadora simbólica (SymPy), artigos sobre GMM.",
                                  "tips": "Foco em exemplos onde MM diverge de MLE, como distribuições assimétricas.",
                                  "learningObjective": "Sintetizar comparação quantitativa de eficiência.",
                                  "commonMistakes": "Assumir eficiência de MM sem condições; ignorar robustez de MM."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar propriedades e discutir aplicações",
                                  "subSteps": [
                                    "Resuma consistência, normalidade e eficiência em tabela comparativa.",
                                    "Discuta cenários onde MM é preferível (ex: misspecification).",
                                    "Explore extensões para GMM.",
                                    "Prepare argumentos para defesa oral ou relatório.",
                                    "Revise com exemplos reais de literatura."
                                  ],
                                  "verification": "Crie tabela comparativa e relatório de 2 páginas.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Literatura (Newey & West sobre GMM), Word/LaTeX.",
                                  "tips": "Use diagramas para visualizar trade-offs.",
                                  "learningObjective": "Integrar conhecimentos para análise crítica.",
                                  "commonMistakes": "Superestimar MLE sem mencionar robustez de MM."
                                }
                              ],
                              "practicalExample": "Para uma amostra de uma distribuição Exponencial(λ), o estimador MM é λ_hat = 1 / X_bar, idêntico ao MLE. Simule n=1000 amostras de tamanho 50, calcule viés, variância e teste normalidade via QQ-plot. Compare variâncias assintóticas: ambas eficientes nesse caso. Para Normal(μ,σ²), MM para σ² é viesado, mas consistente; MLE ajusta para unbiasedness.",
                              "finalVerifications": [
                                "Explicar verbalmente consistência de MM usando LLN.",
                                "Derivar distribuição assintótica para exemplo simples.",
                                "Calcular variância assintótica relativa (MM/MLE >1).",
                                "Identificar cenário onde MM falha em consistência.",
                                "Simular e plotar convergência para n→∞.",
                                "Discutir eficiência em contexto de amostras pequenas."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas provas (80% correto).",
                                "Profundidade na comparação quantitativa (variâncias calculadas).",
                                "Uso correto de simulações para validação.",
                                "Clareza na síntese de trade-offs.",
                                "Aplicação a exemplos concretos sem erros.",
                                "Originalidade na discussão de limitações."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Uso em GMM para modelos estruturais.",
                                "Machine Learning: Robustez de MM em feature engineering.",
                                "Probabilidade: LLN e TCL como fundamentos.",
                                "Computação Científica: Simulações em Python/R para análise empírica."
                              ],
                              "realWorldApplication": "Em finanças, estimadores MM são usados para calibrar modelos de volatilidade em séries temporais onde verossimilhança é difícil (ex: GARCH); em bioestatística, para parâmetros de sobrevivência sob misspecification de modelo, priorizando consistência sobre eficiência em amostras limitadas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.3.2",
                        "name": "Condições de Momentos Generalizados",
                        "description": "Extensão do método dos momentos para casos com mais condições que parâmetros, permitindo estimação robusta sob violações de pressupostos como homocedasticidade.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.3.2.1",
                            "name": "Formular condições de momentos sobre-identificadas",
                            "description": "Construir vetores de momentos E[g(Z, θ)] = 0 com instrumentos Z, aplicável a regressões com endogeneidade em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Condições de Momentos e Identificação",
                                  "subSteps": [
                                    "Defina condições de momentos como E[g(Z, θ)] = 0, onde g é a função de momentos, Z são instrumentos exógenos e θ são parâmetros.",
                                    "Explique a endogeneidade em regressões: covariância entre regressores e erro leva a viés.",
                                    "Discuta identificação: número de instrumentos ≥ número de parâmetros para just-identificado; > para sobre-identificado.",
                                    "Estude propriedades dos estimadores GMM: consistência e eficiência assintótica.",
                                    "Revise matriz de instrumentos Z típica em dados de engenharia (ex: variáveis lagged ou exógenas)."
                                  ],
                                  "verification": "Resuma em um parágrafo os conceitos chave e identifique 3 exemplos de endogeneidade em dados de engenharia.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de aula sobre GMM, slides de 'Métodos Generalizados dos Momentos', calculadora.",
                                  "tips": "Use analogias: instrumentos são 'guardiões' que validam os parâmetros sem contaminação pelo erro.",
                                  "learningObjective": "Compreender os pilares teóricos de GMM para formular momentos válidos.",
                                  "commonMistakes": "Confundir instrumentos endógenos com exógenos; ignorar ortogonalidade E[Z'u] = 0."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular Condições de Momentos Just-Identificadas",
                                  "subSteps": [
                                    "Especifique o modelo de regressão com endogeneidade: Y = Xβ + u, onde X endógeno.",
                                    "Construa g(θ) = Z (Y - Xθ), garantindo E[g(θ)] = 0 se Z válido.",
                                    "Calcule o número de parâmetros (dim(θ)) e instrumentos (dim(Z)); igual para just-identificado.",
                                    "Implemente em software: crie matriz Z e função de momentos em Python/R.",
                                    "Teste ortogonalidade manualmente com dados simulados."
                                  ],
                                  "verification": "Gere um vetor g(θ) para θ verdadeiro e verifique se média próxima de zero.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python/R com pacotes statsmodels ou gmm, dados simulados de regressão endógena.",
                                  "tips": "Comece com poucos instrumentos para visualizar; plote g(θ) vs θ.",
                                  "learningObjective": "Construir e validar condições básicas de momentos.",
                                  "commonMistakes": "Selecionar Z correlacionado com u; não normalizar Z."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Expandir para Condições Sobre-Identificadas",
                                  "subSteps": [
                                    "Adicione instrumentos extras: dim(Z) > dim(θ), criando excesso de momentos.",
                                    "Formule o vetor completo g(Z, θ) = [g1, g2, ..., gK] com K > dim(θ).",
                                    "Discuta eficiência: GMM usa matriz de pesos ótima W para minimizar variância.",
                                    "Implemente GMM de dois passos: primeiro com W=I, segundo com W inversa de Var(g).",
                                    "Prepare para teste J: estatística de Hansen para validade de sobre-identificação."
                                  ],
                                  "verification": "Confirme dim(g) > dim(θ) e rode GMM preliminar sem erros.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Código Python/R expandido, dados de engenharia reais/simulados com múltiplos instrumentos.",
                                  "tips": "Escolha instrumentos relevantes (correlacionados com X) e exógenos (incorrelacionados com u).",
                                  "learningObjective": "Criar vetores de momentos sobre-identificados com eficiência.",
                                  "commonMistakes": "Instrumentos fracos (F-stat <10); ignorar heterocedasticidade em W."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e Aplicar em Contexto de Dados de Engenharia",
                                  "subSteps": [
                                    "Aplique a um dataset: ex. rendimento químico vs temperatura endógena, instrumentos lagged temp e pressão.",
                                    "Estime θ via GMM e compute estatística J: J ~ χ²(K-N), falha H0 indica instrumentos inválidos.",
                                    "Compare com OLS/IV: verifique ganhos de eficiência.",
                                    "Sensitize: altere número de instrumentos e observe impacto.",
                                    "Documente relatório com código, resultados e interpretação."
                                  ],
                                  "verification": "Estatística J não rejeita H0 (p>0.05) e estimativas coerentes com teoria.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Dataset de engenharia (ex: UCI ML repo), Jupyter notebook.",
                                  "tips": "Use robust SE para inferência; valide instrumentos com teste de relevância.",
                                  "learningObjective": "Integrar formulação GMM em análise prática com validação.",
                                  "commonMistakes": "Sobrepor instrumentos; interpretar J como causalidade direta."
                                }
                              ],
                              "practicalExample": "Em um processo químico, preveja rendimento Y com temperatura X (endógena por erro de medição). Use Z1=lag(X), Z2=pressão, Z3=lag(pressão) para g(Z,θ)=Z(Y-Xθ). Estime β_GMM e teste J para validar excesso de instrumentos.",
                              "finalVerifications": [
                                "Vetor g(θ) tem média zero nos dados simulados.",
                                "dim(Z) > dim(θ) confirmado com contagem explícita.",
                                "Estatística J não rejeita H0 de validade instrumental.",
                                "Estimativas GMM mais eficientes que IV (variâncias menores).",
                                "Código roda sem erros e reproduz resultados.",
                                "Relatório explica escolhas de Z e interpretação."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação de g(Z,θ): 25%.",
                                "Correta identificação de sobre-identificação: 20%.",
                                "Implementação GMM funcional com pesos: 20%.",
                                "Validação via teste J e diagnósticos: 20%.",
                                "Exemplo prático coerente com engenharia: 10%.",
                                "Clareza no relatório e código comentado: 5%."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Extensão de IV para GMM.",
                                "Programação: NumPy/SciPy para otimização de momentos.",
                                "Engenharia de Processos: Análise de dados experimentais com endogeneidade.",
                                "Estatística: Testes de hipóteses assintóticos (χ²)."
                              ],
                              "realWorldApplication": "Em engenharia, formula condições sobre-identificadas para estimar parâmetros em modelos de controle de qualidade com variáveis endógenas, como em otimização de reatores químicos ou previsão de falhas em sistemas mecânicos, melhorando precisão além de métodos simples."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.3.3.2.2",
                            "name": "Selecionar matriz de ponderação ótima",
                            "description": "Explicar a escolha da matriz W para minimizar variância assimptótica do estimador, usando estimativas consistentes de segunda momentos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos da variância assintótica no GMM",
                                  "subSteps": [
                                    "Revise as condições de momento generalizadas (GMM): g(θ) = E[m(θ, X)] = 0.",
                                    "Entenda o estimador GMM: θ̂ = argmin g_n(θ)' W g_n(θ), onde g_n é a média amostral.",
                                    "Estude a distribuição assintótica: √n (θ̂ - θ) ~ N(0, V(W)), com V(W) dependendo de W.",
                                    "Identifique os componentes: G = ∂g/∂θ (matriz de derivadas), S = AsyCov(√n g_n)."
                                  ],
                                  "verification": "Escreva a fórmula da distribuição assintótica e identifique G e S corretamente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de Econometria (ex: Wooldridge), notas de aula sobre GMM, calculadora.",
                                  "tips": "Use diagramas para visualizar g(θ) e a minimização quadrática.",
                                  "learningObjective": "Dominar a base teórica da variância assintótica em GMM.",
                                  "commonMistakes": "Confundir S com a covariância amostral simples sem correção de heterocedasticidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a expressão da variância assintótica em função de W",
                                  "subSteps": [
                                    "Parta da expansão linear: √n g_n(θ̂) ≈ G √n (θ̂ - θ).",
                                    "Substitua na função objetivo: g_n(θ̂)' W g_n(θ̂) ≈ [√n (θ̂ - θ)]' (G' W G) [√n (θ̂ - θ)].",
                                    "Aplique o lema de otimização: G' W G (θ̂ - θ) + (1/√n) G' W √n g_n(θ) = 0.",
                                    "Obtenha V(W) = (G' W G)^{-1} (G' W S W G) (G' W G)^{-1}.",
                                    "Verifique que V(W) é positiva definida para W positiva definida."
                                  ],
                                  "verification": "Derive e simplifique V(W) em um caderno, confirmando a simetria.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Papel e caneta para derivações, software simbólico como SymPy (Python).",
                                  "tips": "Use notação matricial consistente e multiplique por n para assintóticas.",
                                  "learningObjective": "Capacitar-se a expressar a eficiência do estimador via V(W).",
                                  "commonMistakes": "Esquecer o termo de sanduíche ou inverter incorretamente as matrizes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar e derivar a matriz de ponderação ótima W*",
                                  "subSteps": [
                                    "Analise V(W): note que minimizar V(W) é equivalente a maximizar eficiência.",
                                    "Mostre que W* = S^{-1} torna V* = (G' S^{-1} G)^{-1}, a variância mínima.",
                                    "Prove usando desigualdade de Cauchy-Schwarz matricial ou otimização.",
                                    "Discuta que W* é assintoticamente ótima (AOP) sob condições regulares.",
                                    "Compare com W = I (2SLS), que é menos eficiente."
                                  ],
                                  "verification": "Demonstre que ∂/∂W tr(V(W)) = 0 implica W* ∝ S^{-1}.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Referências teóricas (Hansen, 1982), quadro branco para provas.",
                                  "tips": "Pense em termos de eficiência: W* aloca peso inverso à variância de g_n.",
                                  "learningObjective": "Compreender por que W* = S^{-1} minimiza a variância.",
                                  "commonMistakes": "Assumir W* = G' G sem contexto ou ignorar S."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar estimativas consistentes de S para obter W*",
                                  "subSteps": [
                                    "Estime Ĝ = média de ∂m/∂θ ou numérica.",
                                    "Estime Ŝ: use covariância amostral se i.i.d., ou Newey-West (HAC) para dependência serial.",
                                    "Calcule Ŵ = Ŝ^{-1} (iterativo: 2-step ou continuous updating).",
                                    "Teste consistência: simule dados e verifique convergência.",
                                    "Avalie em software: implemente em R (gmm package) ou Python (statsmodels)."
                                  ],
                                  "verification": "Execute simulação e confirme que Var(θ̂) diminui com Ŵ vs W=I.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "R/Python com pacotes gmm/statsmodels, dados simulados.",
                                  "tips": "Comece com 2-step GMM para simplicidade antes de iterativo.",
                                  "learningObjective": "Aplicar teoria na prática para estimar W* consistentemente.",
                                  "commonMistakes": "Usar covariância simples em dados com autocorrelação, levando a inconsistência."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão IV com endogeneidade, simule dados X, Z, y com erro AR(1). Estime GMM com W=I (variância alta), então estime Ŝ via Newey-West e Ŵ=Ŝ^{-1}, observando redução de 30% na variância de θ̂ via simulações Monte Carlo (n=1000 reps).",
                              "finalVerifications": [
                                "Deriva corretamente V(W) e identifica W* = S^{-1}.",
                                "Explica consistência de Ŝ em dados dependentes.",
                                "Implementa GMM 2-step em código e compara variâncias.",
                                "Discute condições para optimalidade assintótica (identificação, momentos).",
                                "Responde: 'Por que W* minimiza variância?' com prova.",
                                "Simula exemplo e plota variâncias empíricas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de V(W) (80% pontuação).",
                                "Correta identificação de W* e prova de optimalidade.",
                                "Adequação da estimativa de Ŝ ao contexto de dependência.",
                                "Implementação prática funcional e resultados quantitativos.",
                                "Clareza na explicação de trade-offs (ex: 1-step vs 2-step).",
                                "Uso correto de terminologia e notação matricial."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teoria assintótica e estimadores eficientes.",
                                "Programação: Implementação numérica em R/Python para otimização.",
                                "Economia: Aplicações em modelos estruturais e IV.",
                                "Machine Learning: Paralelos com ponderação em loss functions."
                              ],
                              "realWorldApplication": "Em finanças, selecionar W* em GMM para estimar betas no CAPM com erros de medição, reduzindo variância em previsões de risco e melhorando alocação de portfólios em fundos de investimento."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.3.3",
                        "name": "Estimador GMM e Inferência",
                        "description": "Definição do estimador GMM como minimizador de uma forma quadrática e suas aplicações em econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.3.3.1",
                            "name": "Implementar o estimador GMM",
                            "description": "Minimizar θ̂ = argmin_θ [n̄ g_n(θ)]' W [n̄ g_n(θ)], onde g_n é média amostral de momentos, com exemplos numéricos em R.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e gerar dados simulados",
                                  "subSteps": [
                                    "Instalar e carregar pacotes necessários: optim, numDeriv para otimização e derivadas numéricas.",
                                    "Gerar um dataset simulado para um modelo simples, como AR(1): y_t = 0.5 y_{t-1} + ε_t com ε ~ N(0,1), n=500 observações.",
                                    "Definir os parâmetros verdadeiros θ_true = (μ, φ) e calcular momentos populacionais teóricos para verificação posterior.",
                                    "Explorar os dados: summary, plot de autocorrelação para entender a estrutura.",
                                    "Definir função auxiliar para calcular estatísticas amostrais básicas (média, covariâncias)."
                                  ],
                                  "verification": "Dataset gerado corretamente, momentos amostrais calculados e comparados aos teóricos com erro pequeno (<5%).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R ou RStudio",
                                    "Pacotes: stats, numDeriv, optim"
                                  ],
                                  "tips": "Use set.seed(123) para reprodutibilidade. Comece com n=500 para convergência rápida.",
                                  "learningObjective": "Configurar ambiente R e preparar dados simulados para GMM.",
                                  "commonMistakes": [
                                    "Não definir seed, levando a resultados irreprodutíveis.",
                                    "Gerar dados com parâmetros inconsistentes (ex: φ>1).",
                                    "Ignorar normalização dos dados."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir a função de momentos g_n(θ)",
                                  "subSteps": [
                                    "Especificar os momentos populacionais para o modelo AR(1): g(θ) = [E[y], E[y^2] - μ^2 - σ^2, E[y y_lag] - μ^2 - φ σ^2].",
                                    "Implementar g_n(θ) como média amostral: função que recebe θ e dados, retorna vetor de 3 momentos amostrados.",
                                    "Testar g_n(θ_true) para verificar se está próximo de zero (erro <1e-3).",
                                    "Implementar gradiente numérico de g_n usando grad() do numDeriv para uso futuro na otimização.",
                                    "Validar com plot: g_n(θ) vs θ para um parâmetro fixo."
                                  ],
                                  "verification": "g_n(θ_true) ≈ 0 e gradiente computado sem erros.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R",
                                    "Pacote numDeriv"
                                  ],
                                  "tips": "Vectorize a função g_n para eficiência. Use lags corretos com embed() ou dplyr::lag().",
                                  "learningObjective": "Implementar corretamente a média amostral de momentos g_n(θ).",
                                  "commonMistakes": [
                                    "Erro no cálculo de lags (off-by-one).",
                                    "Não centralizar corretamente os momentos.",
                                    "Ignorar NaNs em lags iniciais."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a função objetivo GMM",
                                  "subSteps": [
                                    "Definir matriz de pesos W inicial: identidade I (2x2 ou 3x3 dependendo de dim(g)).",
                                    "Criar função objetivo Q(θ) = n̄ g_n(θ)' W g_n(θ), onde n̄=1/n.",
                                    "Testar Q(θ_true) ≈ 0.",
                                    "Opcional: Calcular W ótima de duas etapas: W = inv(S), S=cov(g_n(θ_1step)) usando bootstrap ou numérico.",
                                    "Implementar versão eficiente com memoização ou pré-computação."
                                  ],
                                  "verification": "Q(θ_true) < 1e-4 e W positiva definida (eigenvalues >0).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R",
                                    "Pacotes base"
                                  ],
                                  "tips": "Use crossprod(g, W %*% g) para eficiência matricial. Normalize por n corretamente.",
                                  "learningObjective": "Construir a função quadrática de minimização GMM.",
                                  "commonMistakes": [
                                    "Confundir n̄ g_n com g_n (fator 1/n).",
                                    "W não simétrica ou singular.",
                                    "Escala errada nos momentos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar e validar o estimador θ̂",
                                  "subSteps": [
                                    "Usar optim() com método 'BFGS': minimizar Q(θ), θ0 valores iniciais razoáveis (ex: médias amostrais).",
                                    "Extrair θ̂ = optim$result$par, valor objetivo e convergência (convergence==0).",
                                    "Calcular erros padrão via fórmula GMM: V = (G' W G)^{-1} (G' W S W G) (G' W G)^{-1}, G=Jacobiana, S=var(g_n).",
                                    "Comparar θ̂ com θ_true (erro relativo <5%).",
                                    "Repetir com diferentes θ0 e W para robustez."
                                  ],
                                  "verification": "Otimização converge, θ̂ próximo de θ_true, erros padrão finitos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R optim, numDeriv"
                                  ],
                                  "tips": "Bounds em θ se necessário (lower=list(μ=-1,φ=0.9)). Monitore hessian para V.",
                                  "learningObjective": "Executar otimização numérica para obter θ̂ GMM e inferência básica.",
                                  "commonMistakes": [
                                    "θ0 ruim causando não-convergência.",
                                    "Erro na Jacobiana G (sinais errados).",
                                    "S estimado com poucos bootstrap."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e diagnosticar a implementação",
                                  "subSteps": [
                                    "Plotar Q(θ) em grade para um parâmetro, verificando mínimo em θ̂.",
                                    "Testar com dados reais (ex: pacote AER, dados de consumo).",
                                    "Implementar J-test: n Q(θ̂) ~ χ²_{dim(g)-dim(θ)}.",
                                    "Comparar com glm ou outros estimadores para validação.",
                                    "Documentar código em script com comentários."
                                  ],
                                  "verification": "J-stat p-value >0.05, plots mostram mínimo correto.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R",
                                    "Pacote AER opcional"
                                  ],
                                  "tips": "Use contour() ou persp() para visualização 2D. Salve resultados em lista.",
                                  "learningObjective": "Diagnosticar e validar a implementação GMM completa.",
                                  "commonMistakes": [
                                    "Sobre-identificação ignorada no J-test.",
                                    "Dados reais sem pré-processamento.",
                                    "Interpretação errada de p-values."
                                  ]
                                }
                              ],
                              "practicalExample": "Simule dados AR(1) com φ=0.5, μ=0, σ=1 (n=500). Defina 3 momentos: E[y]=μ, E[(y-μ)^2]=σ^2, E[y y_lag]=(μ^2 + φ σ^2). Implemente GMM com W=I, otimize para θ̂ ≈ (0,0.5), Q(θ̂)<1e-3.",
                              "finalVerifications": [
                                "Código completo roda end-to-end sem erros em <5min.",
                                "θ̂ dentro de 5% de θ_true em 10 simulações.",
                                "Matriz de variância V positiva definida.",
                                "J-test rejeita <5% das vezes (simulações Monte Carlo).",
                                "Gradientes e Hessian numéricos consistentes.",
                                "Resultados reproduzíveis com set.seed()."
                              ],
                              "assessmentCriteria": [
                                "Precisão: |θ̂ - θ_true| / |θ_true| < 0.05.",
                                "Eficiência: tempo de otimização <10s por run.",
                                "Robustez: converge para 95% dos θ0 iniciais aleatórios.",
                                "Correção teórica: Q(θ̂) = min e g_n(θ̂)≈0.",
                                "Documentação: código comentado e função modular.",
                                "Inferência: erros padrão <20% do valor de θ̂."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência baseada em momentos e testes de sobre-identificação.",
                                "Programação: Otimização numérica e programação funcional em R.",
                                "Econometria: Estimadores para modelos com endogeneidade (IV-GMM).",
                                "Matemática: Álgebra linear (pesos W, Jacobianas) e cálculo (gradientes).",
                                "Ciência de Dados: Validação de modelos via critérios de momentos."
                              ],
                              "realWorldApplication": "Em econometria, GMM estima parâmetros em modelos dinâmicos com instrumentos (ex: crescimento econômico com endogeneidade); em finanças, para fatores de risco em asset pricing; em epidemiologia, para modelos de contágio com dados agregados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.3.3.3.2",
                            "name": "Realizar testes de hipótese em GMM",
                            "description": "Aplicar teste J de Hansen para validade de sobre-identificação e testes de Wald/LM para restrições, interpretando resultados em contextos de análise de dados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o modelo GMM e realizar estimativa inicial",
                                  "subSteps": [
                                    "Selecionar variáveis endógenas, exógenas e instrumentos válidos.",
                                    "Especificar a matriz de ponderação ótima (ex: duas etapas).",
                                    "Implementar a estimativa GMM usando software como R (pacote gmm) ou Stata.",
                                    "Calcular estatísticas iniciais: parâmetros estimados e matriz de covariância.",
                                    "Verificar suposições básicas como estacionariedade dos dados."
                                  ],
                                  "verification": "Comparar parâmetros estimados com resultados teóricos ou benchmarks conhecidos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Software R com pacote gmm ou Stata",
                                    "Dataset com variáveis instrumentais (ex: dados econômicos simulados)",
                                    "Documentação de Hansen (1996)"
                                  ],
                                  "tips": "Comece com GMM de uma etapa para simplicidade antes de duas etapas.",
                                  "learningObjective": "Dominar a configuração e estimativa inicial de um modelo GMM.",
                                  "commonMistakes": [
                                    "Ignorar o número de instrumentos vs. parâmetros (sobre-identificação insuficiente)",
                                    "Não centralizar variáveis",
                                    "Usar instrumentos fracos sem teste F prévio"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar o teste J de Hansen para validade de sobre-identificação",
                                  "subSteps": [
                                    "Calcular a estatística J = (instrumentos - parâmetros) * (variância)^{-1} * resíduos.",
                                    "Determinar graus de liberdade: número de instrumentos menos parâmetros.",
                                    "Computar p-valor usando distribuição qui-quadrado.",
                                    "Implementar no software: gmm() em R ou ivreg2 em Stata.",
                                    "Registrar o valor J e p-valor."
                                  ],
                                  "verification": "Valor J deve seguir qui-quadrado; p-valor > 0.05 indica instrumentos válidos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Código R/Stata pronto para teste J",
                                    "Dataset do passo 1",
                                    "Tabelas de qui-quadrado"
                                  ],
                                  "tips": "Use matriz de ponderação eficiente para maximizar poder do teste.",
                                  "learningObjective": "Avaliar empiricamente a validade dos instrumentos via teste J.",
                                  "commonMistakes": [
                                    "Confundir graus de liberdade",
                                    "Interpretar J alto como bom (é o oposto)",
                                    "Não testar múltiplos conjuntos de instrumentos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar testes de Wald e LM para restrições nos parâmetros",
                                  "subSteps": [
                                    "Definir restrições lineares (Wald) ou não-lineares (LM).",
                                    "Para Wald: calcular (Rβ - r)' (R Var(β) R')^{-1} (Rβ - r).",
                                    "Para LM: testar score sob restrições vs. irrestrito.",
                                    "Implementar via comandos test() em R/Stata pós-estimativa GMM.",
                                    "Comparar estatísticas com qui-quadrado apropriado."
                                  ],
                                  "verification": "Estatísticas devem coincidir com output do software e p-valores lógicos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Funções test() em gmm (R) ou test após gmm2s (Stata)",
                                    "Exemplos de restrições (ex: β1 = 0)",
                                    "Dataset do passo 1"
                                  ],
                                  "tips": "Wald é robusto a violações; LM bom para restrições não-lineares.",
                                  "learningObjective": "Testar hipóteses específicas sobre parâmetros GMM.",
                                  "commonMistakes": [
                                    "Usar distribuição errada (t vs. qui-quadrado)",
                                    "Não ajustar para GMM duas etapas",
                                    "Ignorar correlação entre testes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados dos testes em contexto analítico",
                                  "subSteps": [
                                    "Analisar p-valor J: rejeitar H0 implica instrumentos inválidos.",
                                    "Interpretar Wald/LM: rejeição indica restrições falsas.",
                                    "Discutir implicações para o modelo (ex: especificação alternativa).",
                                    "Relatar em relatório: valores, p-valores, conclusões.",
                                    "Sensibilizar com diferentes ponderações ou subamostras."
                                  ],
                                  "verification": "Relatório escrito explica corretamente cada teste e recomendações.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Template de relatório LaTeX ou Markdown",
                                    "Gráficos de resíduos",
                                    "Resultados dos passos anteriores"
                                  ],
                                  "tips": "Sempre contextualize com teoria econômica subjacente.",
                                  "learningObjective": "Integrar testes para decisões de modelagem robustas.",
                                  "commonMistakes": [
                                    "Sobrepor confiança em p-valores isolados",
                                    "Ignorar poder estatístico baixo",
                                    "Não discutir limitações como endogeneidade residual"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários e educação (dados CPS), use distância a colleges como IV para escolaridade endógena. Estime GMM, teste J para validar IVs, Wald para H0: coef educação = 0.10, interpretando se IVs são válidos e restrição plausível.",
                              "finalVerifications": [
                                "Calcula corretamente estatística J e interpreta p-valor.",
                                "Executa testes Wald/LM sem erros de sintaxe no software.",
                                "Identifica cenários onde J rejeita (instrumentos inválidos).",
                                "Explica diferenças entre Wald, LM e J.",
                                "Produz relatório com conclusões acionáveis.",
                                "Aplica em dataset real sem orientação."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos de estatísticas de teste (90%+ acurácia).",
                                "Correta interpretação de p-valores e implicações (sem inversões lógicas).",
                                "Uso eficiente de software com código reproduzível.",
                                "Profundidade na discussão de robustez e limitações.",
                                "Integração coerente de todos os testes em análise final.",
                                "Clareza e estrutura no relatório de resultados."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Regressão instrumental e validação de IVs.",
                                "Estatística Inferencial: Distribuições qui-quadrado e testes de hipóteses.",
                                "Programação Computacional: Implementação em R/Python/Stata.",
                                "Análise de Dados: Tratamento de endogeneidade em big data.",
                                "Economia Aplicada: Modelagem de causalidade em políticas públicas."
                              ],
                              "realWorldApplication": "Em análises econométricas para bancos centrais (ex: validar instrumentos em modelos de inflação GMM) ou firmas de consultoria (testar restrições em painéis de empresas para previsões financeiras), garantindo inferências causais confiáveis em políticas públicas e investimentos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.2.2"
                            ]
                          },
                          {
                            "id": "10.1.3.3.3.3",
                            "name": "Aplicar GMM em regressão instrumental",
                            "description": "Usar GMM como 2SLS generalizado em modelos com variáveis instrumentais, simulando cenários de engenharia como análise de painéis de produção.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos Teóricos de GMM e Regressão Instrumental",
                                  "subSteps": [
                                    "Explicar as condições de ordem dos momentos (moment conditions) no GMM.",
                                    "Diferenciar 2SLS de GMM como estimador generalizado.",
                                    "Identificar problemas de endogeneidade em modelos de regressão.",
                                    "Discutir validade de instrumentos: relevância e exogeneidade.",
                                    "Revisar matriz de covariância ótima no GMM."
                                  ],
                                  "verification": "Escrever um resumo de 200 palavras explicando como GMM generaliza 2SLS, com fórmulas chave.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Econometric Analysis' de Greene (cap. GMM)",
                                    "Notas de aula sobre IV",
                                    "Artigo de Hansen (1982) sobre GMM"
                                  ],
                                  "tips": "Use diagramas para visualizar as condições de momentos.",
                                  "learningObjective": "Compreender a base teórica do GMM aplicado a regressão instrumental.",
                                  "commonMistakes": [
                                    "Confundir relevância com exogeneidade dos instrumentos",
                                    "Ignorar a assimetria na matriz de covariância"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar um Modelo GMM-IV com Endogeneidade",
                                  "subSteps": [
                                    "Definir o modelo estrutural com variável endógena (ex: produção ~ investimento).",
                                    "Selecionar instrumentos válidos (ex: lagged variables em painéis).",
                                    "Especificar as condições de momentos E[Z' (y - Xβ)] = 0.",
                                    "Calcular pesos iniciais para iterações GMM (2-step ou continuous).",
                                    "Testar hipóteses de sobre-identificação (J-test)."
                                  ],
                                  "verification": "Montar equação do modelo em papel ou LaTeX e listar 3 instrumentos potenciais.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software R ou Python (statsmodels/linearmodels)",
                                    "Datasets simulados de painéis",
                                    "Tutorial GMM em Wooldridge"
                                  ],
                                  "tips": "Comece com modelo just-identified para simplicidade.",
                                  "learningObjective": "Configurar corretamente condições de momentos para GMM-IV.",
                                  "commonMistakes": [
                                    "Escolher instrumentos correlacionados com erro",
                                    "Esquecer normalização da matriz de pesos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar GMM em Software para Regressão Instrumental",
                                  "subSteps": [
                                    "Carregar biblioteca (ex: linearmodels.IVGMM em Python).",
                                    "Preparar dados: endógena, exógenas, instrumentos.",
                                    "Executar estimativa GMM de 2 passos.",
                                    "Calcular erros-padrão robustos (HCSE).",
                                    "Interpretar coeficientes e estatísticas de teste."
                                  ],
                                  "verification": "Rodar código e obter output com coeficientes convergentes e p-values.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python/Jupyter com pandas, statsmodels, linearmodels",
                                    "Dataset exemplo de produção (simulado ou público)"
                                  ],
                                  "tips": "Use seed para reproducibilidade em simulações.",
                                  "learningObjective": "Implementar GMM-IV computacionalmente de forma eficiente.",
                                  "commonMistakes": [
                                    "Não tratar missing values",
                                    "Usar OLS em vez de IVGMM por engano"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Simular Cenários de Engenharia com Painéis de Produção",
                                  "subSteps": [
                                    "Gerar dados simulados de painel: firmas ao longo do tempo com endogeneidade em investimento.",
                                    "Aplicar GMM em painel (fixed effects + IV).",
                                    "Comparar GMM vs. OLS e 2SLS em termos de bias.",
                                    "Analisar sensibilidade a fraqueza de instrumentos (F-stat >10).",
                                    "Visualizar resultados com plots de coeficientes."
                                  ],
                                  "verification": "Produzir tabela comparativa de estimativas e gráfico de resíduos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Código Python para simulação (numpy.random)",
                                    "Dados reais de produção (ex: Compustat subset)"
                                  ],
                                  "tips": "Simule 1000 repetições para Monte Carlo.",
                                  "learningObjective": "Aplicar GMM em contextos reais de engenharia de produção.",
                                  "commonMistakes": [
                                    "Gerar dados sem endogeneidade realista",
                                    "Ignorar efeitos fixos em painéis"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Realizar Inferência e Validação do Modelo GMM",
                                  "subSteps": [
                                    "Executar testes: Hansen J para sobre-identificação, weak IV (Anderson-Rubin).",
                                    "Calcular intervalos de confiança bootstrap.",
                                    "Avaliar especificação com testes de Hausman.",
                                    "Documentar robustez e limitações.",
                                    "Prever fora da amostra e calcular RMSE."
                                  ],
                                  "verification": "Relatório com todos os testes passando (p>0.05 onde apropriado).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Funções de teste em linearmodels",
                                    "Bootstrap scripts"
                                  ],
                                  "tips": "Sempre reporte F-stat de primeira etapa.",
                                  "learningObjective": "Validar inferências robustas do modelo GMM-IV.",
                                  "commonMistakes": [
                                    "Interpretar J-test baixo como bom sem contexto",
                                    "Usar bootstrap sem convergência"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de automóveis, use GMM-IV para estimar o impacto endógeno do investimento em máquinas na produção diária, instrumentando com políticas fiscais regionais e lags de investimento, analisando painel de 50 plantas ao longo de 10 anos.",
                              "finalVerifications": [
                                "Modelo GMM converge em menos de 10 iterações.",
                                "Teste J de Hansen tem p-value > 0.10.",
                                "F-stat da primeira etapa > 10 para todos instrumentos.",
                                "Comparação Hausman rejeita OLS (p < 0.05).",
                                "Previsões fora da amostra têm RMSE < 10% do mean(y).",
                                "Coeficientes economicamente sensatos (ex: elasticidade produção-capital ~0.3)."
                              ],
                              "assessmentCriteria": [
                                "Precisão teórica: fórmulas de momentos corretas (90% acerto).",
                                "Implementação código: roda sem erros e reproduzível.",
                                "Validação estatística: todos testes passam.",
                                "Interpretação: explicação clara de resultados.",
                                "Simulação realista: dados refletem cenários de engenharia.",
                                "Documentação: relatório completo com plots e tabelas."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Extensão de IV/2SLS para modelos não-lineares.",
                                "Engenharia Industrial: Otimização de produção em painéis.",
                                "Machine Learning: GMM como base para estimadores causais.",
                                "Estatística Computacional: Otimização iterativa e bootstrap.",
                                "Economia: Análise de políticas com endogeneidade."
                              ],
                              "realWorldApplication": "Em engenharia de processos industriais, GMM-IV é usado para estimar retornos ao capital em painéis de produção, auxiliando decisões de investimento em fábricas, como na indústria petrolífera para modelar eficiência de poços com endogeneidade em manutenção."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.3.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.4",
                    "name": "Estimação Robusta em Regressão",
                    "description": "Técnicas de estimação que relaxam pressupostos clássicos para maior robustez em grandes amostras.",
                    "individualConcepts": [
                      {
                        "id": "10.1.3.4.1",
                        "name": "Pressupostos Clássicos da Regressão Linear e Suas Violações",
                        "description": "Revisão dos pressupostos fundamentais do modelo de regressão linear via Mínimos Quadrados Ordinários (MQO) e identificação de violações comuns, como heterocedasticidade, autocorrelação e presença de outliers, especialmente em grandes amostras de dados de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.4.1.1",
                            "name": "Listar e explicar os pressupostos do MQO",
                            "description": "Identificar e descrever os quatro pressupostos principais do modelo linear clássico (linearidade, exogeneidade, homocedasticidade e normalidade dos erros), com exemplos de violações em contextos de análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Explicar o pressuposto de Linearidade nos resíduos",
                                  "subSteps": [
                                    "Defina linearidade como a expectativa condicional E[y|X] = Xβ, onde a relação entre variáveis dependentes e independentes é linear nos parâmetros.",
                                    "Discuta que violações ocorrem em relações não-lineares, como quadráticas ou exponenciais.",
                                    "Forneça um exemplo em engenharia: modelagem de deformação em vigas sob carga, onde deformação = a * carga + b, mas violada se houver fadiga não-linear.",
                                    "Desenhe um gráfico scatter plot para visualizar linearidade.",
                                    "Explique implicações: viés nos coeficientes se violado."
                                  ],
                                  "verification": "Crie um diagrama de resíduos vs. valores preditos que mostra padrão linear aleatório.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Software R ou Python (ggplot ou matplotlib)",
                                    "Dataset de engenharia (ex: dados de testes de materiais)"
                                  ],
                                  "tips": "Sempre plote y vs. X primeiro para checar linearidade visual.",
                                  "learningObjective": "Compreender e identificar o pressuposto de linearidade com exemplos de violações em contextos de engenharia.",
                                  "commonMistakes": [
                                    "Confundir linearidade nos parâmetros com linearidade na forma funcional; assumir sempre linear sem plotar dados."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explicar o pressuposto de Exogeneidade dos erros",
                                  "subSteps": [
                                    "Defina exogeneidade como E[ε|X] = 0, significando que os erros são independentes das variáveis explicativas (sem correlação).",
                                    "Discuta violações como endogeneidade causada por variáveis omitidas ou causalidade reversa.",
                                    "Exemplo em engenharia: regressão de eficiência de motor vs. temperatura, violada se temperatura omitir fator de desgaste endógeno.",
                                    "Teste conceitual: correlação entre resíduos e X deve ser zero.",
                                    "Implicações: estimadores viesados e inconsistentes."
                                  ],
                                  "verification": "Calcule correlação entre resíduos e cada X; deve ser próxima de zero.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Calculadora ou Python (pandas corr())",
                                    "Notas sobre causalidade em engenharia"
                                  ],
                                  "tips": "Pense em causalidade: X causa y, não o inverso, e inclua todas variáveis relevantes.",
                                  "learningObjective": "Identificar exogeneidade e violações comuns em modelos de análise de dados de engenharia.",
                                  "commonMistakes": [
                                    "Ignorar variáveis omitidas que correlacionam com X; confundir com multicolinearidade."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explicar o pressuposto de Homocedasticidade dos erros",
                                  "subSteps": [
                                    "Defina homocedasticidade como Var(ε|X) = σ² constante para todos os níveis de X.",
                                    "Descreva violações como heterocedasticidade, onde variância aumenta com X.",
                                    "Exemplo em engenharia: previsão de consumo de energia em edifícios vs. tamanho; variância maior em edifícios maiores devido a ruídos variáveis.",
                                    "Visualize com plot de resíduos vs. fitted values (funil shape indica violação).",
                                    "Implicações: erros-padrão subestimados, testes inválidos."
                                  ],
                                  "verification": "Plot de scale-location ou Breusch-Pagan test não rejeita H0 de homocedasticidade.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "R (lmtest package) ou Python (statsmodels)",
                                    "Dataset de sensores industriais"
                                  ],
                                  "tips": "Use log-transformações em y para estabilizar variância em dados de engenharia.",
                                  "learningObjective": "Diagnosticar homocedasticidade e reconhecer violações em dados reais de engenharia.",
                                  "commonMistakes": [
                                    "Interpretar heteroscedasticidade como outlier isolado; não plotar resíduos padronizados."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explicar o pressuposto de Normalidade dos erros",
                                  "subSteps": [
                                    "Defina normalidade como ε ~ N(0, σ²), crucial para inferência (t-tests, F-tests).",
                                    "Violação: distribuições assimétricas ou com caudas pesadas em dados ruidosos.",
                                    "Exemplo em engenharia: resíduos em modelo de vibração de máquinas; violado por choques não-gaussianos.",
                                    "Testes: Q-Q plot ou Shapiro-Wilk test.",
                                    "Implicações: intervalos de confiança inválidos, mas OLS ainda não-biasado para grandes amostras."
                                  ],
                                  "verification": "Q-Q plot mostra pontos alinhados na linha reta; p-value > 0.05 em teste de normalidade.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Python (scipy.stats.normaltest) ou R (shapiro.test)",
                                    "Simulador de dados com distribuições não-normais"
                                  ],
                                  "tips": "Normalidade é mais crítica para amostras pequenas; use bootstrap para grandes n.",
                                  "learningObjective": "Avaliar normalidade dos resíduos e mitigar violações em análises de engenharia.",
                                  "commonMistakes": [
                                    "Exigir normalidade perfeita (raro); confundir com normalidade de y em vez de ε."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia mecânica, use um dataset de testes de fadiga em ligas metálicas (carga vs. ciclos até falha). Ajuste regressão linear, diagnostique pressupostos com plots de resíduos, identifique violação de homocedasticidade devido a variância crescente em cargas altas, e proponha transformação log.",
                              "finalVerifications": [
                                "Liste corretamente os quatro pressupostos: linearidade, exogeneidade, homocedasticidade, normalidade.",
                                "Forneça um exemplo de violação para cada em contexto de engenharia.",
                                "Explique implicações de pelo menos duas violações nos estimadores MQO.",
                                "Descreva um teste diagnóstico para cada pressuposto.",
                                "Aplique os conceitos a um dataset simples, identificando todas violações."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições exatas sem erros (30%)",
                                "Exemplos relevantes: violações contextualizadas em engenharia (25%)",
                                "Profundidade diagnóstica: menção a testes/plots corretos (20%)",
                                "Implicações claras: impacto em inferência e estimação (15%)",
                                "Clareza e estrutura: explicação lógica e concisa (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: testes de diagnóstico como Breusch-Pagan e Shapiro-Wilk.",
                                "Programação: implementação em Python/R para plots e testes de resíduos.",
                                "Engenharia de Dados: pré-processamento para corrigir violações (transformações).",
                                "Machine Learning: transição para modelos robustos como regressão robusta."
                              ],
                              "realWorldApplication": "Em engenharia, validar pressupostos MQO garante modelos preditivos confiáveis para otimização de processos industriais, como previsão de manutenção preditiva em turbinas eólicas, evitando decisões baseadas em estimativas viesadas que podem levar a falhas custosas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.4.1.2",
                            "name": "Detectar violações de pressupostos em grandes amostras",
                            "description": "Aplicar diagnósticos gráficos e testes estatísticos (como teste de Breusch-Pagan para heterocedasticidade e Durbin-Watson para autocorrelação) para identificar problemas em datasets grandes, simulando cenários reais de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e Explorar o Dataset Grande",
                                  "subSteps": [
                                    "Carregue um dataset grande (ex: >10k observações) simulando dados de engenharia usando pandas em Python.",
                                    "Execute regressão linear OLS com statsmodels para obter resíduos e valores ajustados.",
                                    "Realize uma análise exploratória inicial: verifique tamanho, missing values e distribuições básicas.",
                                    "Padronize variáveis se necessário para lidar com escalas em grandes amostras.",
                                    "Salve resíduos e fitted values em um DataFrame para análises subsequentes."
                                  ],
                                  "verification": "Confirme que resíduos e fitted values foram gerados sem erros e o dataset tem pelo menos 10k linhas processadas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com pandas, statsmodels, numpy",
                                    "Dataset simulado de engenharia (ex: medições de tensão)"
                                  ],
                                  "tips": "Use chunking com pd.read_csv(chunksize=10000) para datasets muito grandes para evitar memory issues.",
                                  "learningObjective": "Dominar preparação eficiente de grandes datasets para diagnósticos de regressão.",
                                  "commonMistakes": [
                                    "Ignorar missing values levando a NaNs nos resíduos",
                                    "Não escalonar variáveis causando plots distorcidos",
                                    "Usar todo o dataset sem amostragem inicial para testes rápidos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar Diagnósticos Gráficos de Resíduos",
                                  "subSteps": [
                                    "Gere plot de resíduos vs fitted values para detectar heterocedasticidade (padrão de funil).",
                                    "Crie Q-Q plot para verificar normalidade dos resíduos.",
                                    "Plote resíduos ordenados vs ordem de observação para autocorrelação.",
                                    "Use scale-location plot para confirmar heterocedasticidade em grandes amostras.",
                                    "Salve e anote os gráficos com matplotlib ou seaborn."
                                  ],
                                  "verification": "Identifique visualmente padrões como funil ou desvios lineares nos plots gerados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com matplotlib, seaborn, statsmodels",
                                    "Resíduos e fitted values do Step 1"
                                  ],
                                  "tips": "Aumente o tamanho dos pontos nos plots (alpha=0.5) para visualizar grandes amostras sem sobreposição.",
                                  "learningObjective": "Interpretar gráficos de diagnósticos para violações iniciais de pressupostos.",
                                  "commonMistakes": [
                                    "Interpretar ruído aleatório como violação",
                                    "Usar plots inadequados para autocorrelação em dados temporais",
                                    "Ignorar zoom em regiões críticas dos plots"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Testes Estatísticos Formais",
                                  "subSteps": [
                                    "Execute teste de Breusch-Pagan: sm.stats.diagnostic.het_breuschpagan(resid, exog=fitted).",
                                    "Aplique teste de Durbin-Watson: sm.stats.stattools.durbin_watson(model.resid) e interprete (valor ~2 indica ausência de autocorrelação).",
                                    "Para grandes amostras, use versões robustas ou bootstrap se necessário.",
                                    "Registre p-values e estatísticas: rejeite H0 se p<0.05 para heterocedasticidade/autocorrelação.",
                                    "Compare resultados gráficos com testes formais."
                                  ],
                                  "verification": "Obtenha p-values <0.05 confirmando violações onde gráficos indicam problemas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.stats.diagnostic",
                                    "Modelo OLS do Step 1"
                                  ],
                                  "tips": "Para datasets temporais em engenharia, priorize Durbin-Watson após confirmar ordem temporal.",
                                  "learningObjective": "Executar e interpretar testes específicos para violações em grandes amostras.",
                                  "commonMistakes": [
                                    "Confundir H0 dos testes (H0: homocedasticidade, sem autocorrelação)",
                                    "Ignorar tamanho da amostra afetando poder do teste",
                                    "Não reportar estatísticas completas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar Resultados e Propor Correções",
                                  "subSteps": [
                                    "Compile relatório: liste violações detectadas (gráficos + testes).",
                                    "Proponha correções: robust SE para heterocedasticidade, ARIMA para autocorrelação.",
                                    "Re-execute modelo corrigido e verifique melhorias nos diagnósticos.",
                                    "Documente em Jupyter notebook com plots e outputs.",
                                    "Simule cenários reais de engenharia para validação."
                                  ],
                                  "verification": "Relatório mostra violações corrigidas com testes p>0.05 pós-ajuste.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Resultados dos Steps 2-3"
                                  ],
                                  "tips": "Use HC1/HC3 standard errors em statsmodels para robustez rápida.",
                                  "learningObjective": "Integrar diagnósticos em workflow acionável para modelagem robusta.",
                                  "commonMistakes": [
                                    "Não validar correções com re-testes",
                                    "Sobre-corrigir violações menores",
                                    "Omitir contexto de engenharia nos exemplos"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de 50k medições de tensão em vigas de uma ponte (simulado com tendência temporal e variância crescente), detecte heterocedasticidade via Breusch-Pagan (p=0.001) e autocorrelação via Durbin-Watson (1.2), corrigindo com erros robustos e lags.",
                              "finalVerifications": [
                                "Gráficos mostram ausência de padrões sistemáticos nos resíduos corrigidos.",
                                "Teste Breusch-Pagan retorna p>0.05.",
                                "Durbin-Watson próximo de 2.",
                                "Relatório sintetiza violações e correções com evidências.",
                                "Correções melhoram métricas de modelo (AIC/BIC menores)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de violações (90% acerto em cenários simulados).",
                                "Execução correta de testes (p-values e interpretações exatas).",
                                "Qualidade dos plots: legíveis e anotados para grandes amostras.",
                                "Propostas de correção viáveis e testadas.",
                                "Eficiência computacional em datasets >10k linhas.",
                                "Relatório claro e estruturado."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Uso avançado de statsmodels e visualização em Python.",
                                "Engenharia: Aplicação em dados de sensores e monitoramento estrutural.",
                                "Machine Learning: Preparação para modelos robustos e feature engineering.",
                                "Estatística: Inferência em grandes dados e power analysis."
                              ],
                              "realWorldApplication": "Em engenharia civil, detectar violações em dados de sensores IoT de pontes permite modelos preditivos confiáveis para manutenção preditiva, evitando falhas catastróficas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.4.1.3",
                            "name": "Avaliar o impacto de outliers nos estimadores MQO",
                            "description": "Analisar como outliers afetam as propriedades estatísticas dos estimadores MQO (viés e variância) em grandes amostras, utilizando simulações para demonstrar perda de eficiência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de MQO e Outliers",
                                  "subSteps": [
                                    "Defina MQO como o método que minimiza a soma dos quadrados dos resíduos em regressão linear.",
                                    "Explique outliers como observações que desviam significativamente da tendência geral dos dados.",
                                    "Discuta propriedades desejáveis dos estimadores: não-viés, consistência e eficiência em grandes amostras.",
                                    "Identifique como outliers podem violar pressupostos clássicos como homocedasticidade e normalidade.",
                                    "Gere um conjunto de dados sintético simples sem outliers para baseline."
                                  ],
                                  "verification": "Crie um resumo escrito ou diagrama explicando MQO e outliers, e gere dados baseline sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (numpy, pandas, matplotlib), Jupyter Notebook",
                                  "tips": "Use gráficos de dispersão para visualizar dados limpos antes de adicionar outliers.",
                                  "learningObjective": "Compreender os fundamentos teóricos de MQO e identificar outliers conceitualmente.",
                                  "commonMistakes": "Confundir outliers com ruído normal; ignorar propriedades assintóticas em grandes amostras."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Impacto Teórico de Outliers em Viés e Variância",
                                  "subSteps": [
                                    "Derive matematicamente como um outlier aumenta a variância do estimador MQO.",
                                    "Explique o viés introduzido por outliers em cenários de heterocedasticidade ou não-linearidade.",
                                    "Compare variância assintótica de MQO com estimadores robustos como Huber.",
                                    "Calcule analiticamente o efeito em um modelo bivariado simples com um outlier extremo.",
                                    "Discuta perda de eficiência: MQO deixa de ser o estimador de variância mínima."
                                  ],
                                  "verification": "Resolva um exemplo analítico simples e compare viés/variância antes/depois de outlier.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Papel e caneta ou SymPy no Python para derivações simbólicas",
                                  "tips": "Comece com um outlier na direção da regressão para maximizar impacto na variância.",
                                  "learningObjective": "Dominar o impacto matemático de outliers nas propriedades estatísticas do MQO.",
                                  "commonMistakes": "Focar apenas em viés e ignorar variância; assumir impacto uniforme em todos os cenários."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Configurar e Executar Simulações Monte Carlo",
                                  "subSteps": [
                                    "Gere 1000 amostras grandes (n=1000) de um modelo linear verdadeiro sem outliers.",
                                    "Adicione outliers sintéticos (ex: 1-5% das observações com erro multiplicado por 10).",
                                    "Estime MQO para cada simulação e calcule viés, variância e MSE médio.",
                                    "Plote distribuições de coeficientes estimados e boxplots de resíduos.",
                                    "Repita com diferentes proporções de outliers para observar perda de eficiência."
                                  ],
                                  "verification": "Execute simulações e gere gráficos mostrando aumento de variância/MSE com outliers.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (numpy, pandas, statsmodels, matplotlib, seaborn)",
                                  "tips": "Use np.random.seed() para reprodutibilidade; vetorize operações para velocidade.",
                                  "learningObjective": "Implementar simulações para quantificar empiricamente o impacto de outliers.",
                                  "commonMistakes": "Amostras pequenas (use n>500); não controlar semente aleatória."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Demonstrar Perda de Eficiência",
                                  "subSteps": [
                                    "Compare métricas (viés, variância, MSE) entre cenários com/sem outliers.",
                                    "Calcule eficiência relativa: variância MQO contaminado / variância MQO limpo.",
                                    "Identifique thresholds onde MQO perde eficiência significativa (>20%).",
                                    "Teste remoção de outliers vs. estimadores robustos e discuta trade-offs.",
                                    "Escreva relatório resumindo achados com visualizações."
                                  ],
                                  "verification": "Produza relatório com tabelas/gráficos comprovando perda de eficiência em grandes amostras.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Jupyter Notebook, statsmodels para estimadores robustos opcionais",
                                  "tips": "Use log-escala em plots de variância para melhor visualização de mudanças.",
                                  "learningObjective": "Analisar simulações para concluir sobre robustez do MQO a outliers.",
                                  "commonMistakes": "Interpretar causalidade errada; ignorar tamanho da amostra nas conclusões."
                                }
                              ],
                              "practicalExample": "Em um dataset de salários vs. anos de experiência (n=1000), adicione um outlier: um 'estagiário' com salário de R$1M. Simule 1000 vezes: MQO mostra coeficiente de experiência inflado em variância (MSE dobra), demonstrando perda de eficiência para previsões salariais.",
                              "finalVerifications": [
                                "Explicar verbalmente como outlier aumenta variância sem alterar viés assintótico.",
                                "Apresentar gráficos de simulação mostrando dispersão maior nos estimadores MQO.",
                                "Calcular eficiência relativa <80% em cenários com 2% outliers.",
                                "Identificar outlier via resíduos studentizados >3.",
                                "Comparar MSE MQO vs. mediana em simulação contaminada.",
                                "Relatório escrito resume impactos em viés, variância e eficiência."
                              ],
                              "assessmentCriteria": [
                                "Precisão teórica: derivação correta de viés/variância (30%)",
                                "Qualidade da simulação: reprodutível, n grande, métricas completas (25%)",
                                "Análise interpretativa: conclusões alinhadas a resultados (20%)",
                                "Visualizações claras e informativas (15%)",
                                "Relatório estruturado e conciso (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Propriedades assintóticas e teoremas de consistência.",
                                "Programação: Simulações Monte Carlo em Python/R.",
                                "Machine Learning: Robustez em modelos preditivos.",
                                "Econometria: Diagnósticos de regressão em dados econômicos."
                              ],
                              "realWorldApplication": "Em finanças, outliers como crises econômicas (ex: 2008) distorcem modelos de risco MQO, levando a subestimação de variância e decisões erradas em portfólios; simulações ajudam bancos a adotar estimadores robustos para maior precisão."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.4.2",
                        "name": "Técnicas de Estimação Robusta",
                        "description": "Introdução a métodos de estimação que relaxam pressupostos clássicos, como estimadores M (Huber, Tukey) e mínimos quadrados robustos, projetados para maior robustez contra outliers e heterocedasticidade em grandes amostras.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.4.2.1",
                            "name": "Entender o princípio dos estimadores M",
                            "description": "Explicar a minimização de funções de perda robustas (rho-functions) em estimadores M, comparando com a função quadrática do MQO, e derivar o estimador de Huber para regressão linear.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Método dos Mínimos Quadrados Ordinários (MQO)",
                                  "subSteps": [
                                    "Relembre a formulação do problema de regressão linear: minimizar a soma dos erros quadráticos.",
                                    "Escreva a função de perda do MQO: ρ(e) = e²/2, onde e é o resíduo.",
                                    "Discuta as propriedades do MQO: eficiência em dados normais, mas sensibilidade a outliers.",
                                    "Implemente um exemplo simples de MQO em Python usando numpy ou scikit-learn.",
                                    "Visualize o impacto de outliers na estimativa dos coeficientes."
                                  ],
                                  "verification": "Capacidade de derivar os coeficientes β do MQO e plotar curvas de perda com/ sem outliers.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Notebook Jupyter",
                                    "Bibliotecas Python: numpy, matplotlib",
                                    "Dados de exemplo com outliers"
                                  ],
                                  "tips": "Use gráficos para visualizar como outliers distorcem a reta de regressão.",
                                  "learningObjective": "Compreender a função de perda quadrática e suas limitações em cenários com outliers.",
                                  "commonMistakes": [
                                    "Confundir resíduos com predições",
                                    "Ignorar a divisão por 2 na função de perda padrão"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir o Conceito de Estimadores M e Funções Rho Robustas",
                                  "subSteps": [
                                    "Defina estimadores M: soluções de min_θ Σ ρ((y_i - x_i θ)/σ), onde ρ é uma função de perda robusta.",
                                    "Explique o papel da escala σ e funções ρ simétricas e crescentes.",
                                    "Liste exemplos de funções ρ: Huber, Tukey bisquare, Hampel.",
                                    "Compare intuitivamente ρ robusta vs. quadrática: ρ quadrática cresce ilimitadamente, robustas saturam.",
                                    "Derive a condição de estimação: ψ(r) = ρ'(r) = 0 em média."
                                  ],
                                  "verification": "Escrever a equação geral dos estimadores M e listar 3 funções ρ comuns.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Robust Statistics' de Huber (capítulos iniciais)",
                                    "Slides ou vídeo sobre robustez",
                                    "Python para plotar funções ρ"
                                  ],
                                  "tips": "Plote várias ρ-functions no mesmo gráfico para visual comparação.",
                                  "learningObjective": "Dominar a definição formal e intuitiva de estimadores M.",
                                  "commonMistakes": [
                                    "Esquecer a normalização por σ",
                                    "Confundir ρ com ψ (derivada)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Funções de Perda Robustas com a Quadrática do MQO",
                                  "subSteps": [
                                    "Analise o comportamento assintótico: ρ(r) ~ |r| para r grande em robustas vs. r² no MQO.",
                                    "Discuta influência de outliers: downweighting via ρ saturando.",
                                    "Calcule o peso w(r) = ψ(r)/r e mostre como diminui para outliers.",
                                    "Simule regressão com dados contaminados e compare estimativas MQO vs. M.",
                                    "Avalie breakdown point: MQO=0%, M-robustos até 50%."
                                  ],
                                  "verification": "Gerar tabela comparativa de propriedades (eficiência, breakdown point, bias).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dados sintéticos com 20% outliers",
                                    "Python: statsmodels.robust",
                                    "Gráficos de influência functions"
                                  ],
                                  "tips": "Use boxplots para comparar resíduos entre métodos.",
                                  "learningObjective": "Explicar vantagens da robustez em termos de downweighting de outliers.",
                                  "commonMistakes": [
                                    "Achar que todas ρ são lineares para pequenos r",
                                    "Ignorar computacionalmente intensivo de M-estimators"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Derivar o Estimador de Huber para Regressão Linear",
                                  "subSteps": [
                                    "Defina ρ_Huber(r) = { r²/2 se |r|≤k; k|r| - k²/2 caso contrário }.",
                                    "Compute ψ_Huber(r) = derivada: min(|r|, k) * sign(r).",
                                    "Escreva equações de estimação iterativa: usar IRLS (Iteratively Reweighted Least Squares).",
                                    "Implemente algoritmo de Huber em Python (inicializar com MQO, iterar até convergência).",
                                    "Teste com dados reais e compare com MQO."
                                  ],
                                  "verification": "Derivar ψ_Huber manualmente e rodar código que converge para β robusto.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Código base Python para IRLS",
                                    "Dataset Boston Housing ou similar com outliers"
                                  ],
                                  "tips": "Escolha k=1.345 para eficiência 95% em normal; monitore convergência.",
                                  "learningObjective": "Derivar e implementar o estimador de Huber passo a passo.",
                                  "commonMistakes": [
                                    "Erro no ponto de transição k",
                                    "Não inicializar bem (use MQO)",
                                    "Ignorar iterações para σ"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de preços de casas com outliers (ex: uma mansão listada errado), aplique MQO (preços inflados) vs. Huber M-estimador (preços estáveis), plotando retas e resíduos para mostrar robustez.",
                              "finalVerifications": [
                                "Explicar verbalmente minimização de Σ ρ(resíduos).",
                                "Derivar ψ para Huber e plotar.",
                                "Simular dados com 10% outliers e comparar MSE de predições.",
                                "Implementar IRLS para Huber em código funcional.",
                                "Discutir trade-off eficiência vs. robustez.",
                                "Identificar cenários onde MQO falha e M succeeds."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de ρ e ψ (sem erros algébricos).",
                                "Compreensão conceitual de robustez (downweighting qualitativo).",
                                "Implementação correta de algoritmo iterativo (convergência <1e-6).",
                                "Análise comparativa quantitativa (tabelas/gráficos).",
                                "Identificação de limitações (ex: escolha de k, computação).",
                                "Criatividade em exemplos reais."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teoria assintótica e breakdown points.",
                                "Programação: Otimização numérica (IRLS, gradiente descendente).",
                                "Machine Learning: Loss functions em regressão robusta (Huber loss no XGBoost).",
                                "Matemática: Cálculo variacional e funções convexas.",
                                "Ciência de Dados: Tratamento de outliers em pipelines ETL."
                              ],
                              "realWorldApplication": "Em finanças, estimadores M como Huber são usados para modelar retornos de ações com 'fat tails' e outliers (crashs de mercado), evitando distorções em previsões de risco VaR."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.4.2.2",
                            "name": "Implementar regressão robusta com pesos iterativos",
                            "description": "Calcular iterativamente pesos robustos (como bisquare de Tukey) para ajustar o modelo de regressão, aplicando em software como R para dados contaminados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Regressão Linear e Conceitos de Robustez",
                                  "subSteps": [
                                    "Estude a regressão linear ordinária (OLS) e suas suposições (linearidade, homocedasticidade, independência).",
                                    "Entenda o impacto de outliers e dados contaminados na OLS usando exemplos gráficos.",
                                    "Aprenda o conceito de estimação robusta e pesos downweighting para minimizar influência de outliers.",
                                    "Revise a função de influência de Tukey (bisquare): ρ(r) = (1 - (r/6)^2)^2 se |r| < 6, 0 caso contrário.",
                                    "Calcule manualmente pesos bisquare para um resíduo r = 4.5."
                                  ],
                                  "verification": "Responda corretamente a um quiz com 5 perguntas sobre suposições OLS e fórmula bisquare.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação R sobre lm()",
                                    "Artigo introdutório sobre regressão robusta (ex: Tukey 1977)",
                                    "Planilha Excel para cálculos manuais"
                                  ],
                                  "tips": [
                                    "Visualize resíduos com boxplots antes de prosseguir.",
                                    "Use gráficos QQ para detectar desvios."
                                  ],
                                  "learningObjective": "Compreender por que pesos iterativos são necessários em dados contaminados.",
                                  "commonMistakes": [
                                    "Confundir pesos com normalização de features.",
                                    "Ignorar escala dos resíduos (use resíduos padronizados)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Ambiente e Conjunto de Dados em R",
                                  "subSteps": [
                                    "Instale e carregue pacotes necessários: MASS, ggplot2, dplyr.",
                                    "Gere ou carregue um dataset simulado com contaminação: 90% dados normais + 10% outliers (ex: n=100, y = 2x + ε, outliers em y+10).",
                                    "Explore dados com summary(), plot(x,y) e boxplot(y).",
                                    "Ajuste um modelo OLS inicial com lm() e examine coeficientes e resíduos.",
                                    "Identifique outliers nos resíduos usando cutoff |r| > 2.5 * MAD."
                                  ],
                                  "verification": "Execute script R que gera dados contaminados e plota OLS com outliers destacados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R e RStudio",
                                    "Pacotes: MASS, ggplot2, dplyr",
                                    "Script base para geração de dados (disponível online)"
                                  ],
                                  "tips": [
                                    "Use set.seed(123) para reprodutibilidade.",
                                    "Adicione 5-10% de contaminação assimétrica para realismo."
                                  ],
                                  "learningObjective": "Preparar dados realistas para testar robustez.",
                                  "commonMistakes": [
                                    "Não padronizar variáveis preditoras.",
                                    "Usar dataset limpo sem contaminação intencional."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Algoritmo Iterativo de Pesos Bisquare",
                                  "subSteps": [
                                    "Defina função para calcular pesos bisquare: w(r) = [1 - (r/6)^2]^2 se |r|<6, else 0, com r = resid / scale.",
                                    "Inicie com OLS ou modelo inicial, compute resíduos padronizados.",
                                    "Ajuste modelo ponderado com lm(..., weights=w), itere até convergência (Δβ < 0.001 ou max 20 iterações).",
                                    "Implemente loop while em R: while(!converged) { update weights, refit lm, check change }.",
                                    "Salve histórico de coeficientes e pesos por iteração."
                                  ],
                                  "verification": "Código roda sem erros e converge em <15 iterações para dados de teste.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Editor RStudio",
                                    "Função rlm() do MASS como referência (não usar diretamente)"
                                  ],
                                  "tips": [
                                    "Use MAD para scale inicial: median(abs(resid - median(resid))) / 0.6745.",
                                    "Monitore convergência com plot de betas vs iteração."
                                  ],
                                  "learningObjective": "Codificar o algoritmo IRWLS (Iteratively Reweighted Least Squares) manualmente.",
                                  "commonMistakes": [
                                    "Esquecer padronização de resíduos.",
                                    "Loop infinito por pesos zero em todos pontos."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar e Comparar Modelo Robusto com OLS",
                                  "subSteps": [
                                    "Compare coeficientes, R² ajustado e resíduos entre OLS e robusto.",
                                    "Plote resíduos vs fitted para ambos modelos com ggplot2.",
                                    "Calcule métricas: MAE, RMSE para subconjuntos limpo vs contaminado.",
                                    "Teste diagnósticos robustos: Q-Q plot de pesos e leverage.",
                                    "Aplique em dataset real (ex: stackloss do datasets package)."
                                  ],
                                  "verification": "Relatório com tabelas/plots mostrando superioridade robusta em dados contaminados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "ggplot2 para visualizações",
                                    "Dataset stackloss",
                                    "Funções custom para métricas"
                                  ],
                                  "tips": [
                                    "Use weights na plotagem para destacar downweighted points.",
                                    "Compare com rlm() para validar implementação."
                                  ],
                                  "learningObjective": "Validar efetividade da regressão robusta.",
                                  "commonMistakes": [
                                    "Interpretar R² diretamente (use pseudo-R² para robusto).",
                                    "Ignorar instabilidade numérica em iterações iniciais."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Otimizar e Generalizar a Implementação",
                                  "subSteps": [
                                    "Adicione parâmetros customizáveis: k=6 para bisquare, max_iter=50, tol=1e-4.",
                                    "Vectorize cálculos com apply ou vetorização R para eficiência.",
                                    "Crie função robust_lm(x,y) reutilizável com output de betas, weights finais e histórico.",
                                    "Teste sensibilidade variando % contaminação (5%, 15%, 30%).",
                                    "Documente código com roxygen2 ou comentários."
                                  ],
                                  "verification": "Função robust_lm() produz resultados idênticos a rlm(method='bisquare') em 3 datasets.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação roxygen2",
                                    "Pacote MASS para validação"
                                  ],
                                  "tips": [
                                    "Profile código com profvis para otimização.",
                                    "Salve como pacote local para reutilização."
                                  ],
                                  "learningObjective": "Criar ferramenta robusta escalável.",
                                  "commonMistakes": [
                                    "Não tratar multicolinearidade inicial.",
                                    "Hardcode valores em vez de parametrizar."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de previsão de salários (x=anos_experiencia, y=salario) com 10% de entradas erradas (ex: digitação de 'milhões' como 'bilhões'), implemente regressão robusta: OLS superestima inclinação para 50k/ano, robusto corrige para 45k/ano, ignorando 8 outliers via pesos ~0.",
                              "finalVerifications": [
                                "Código converge em <20 iterações para dados com 20% contaminação.",
                                "Coeficientes robustos diferem <5% de rlm(bisquare).",
                                "Resíduos robustos têm MAD <1.5 e sem padrões em plot.",
                                "Função lida com múltiplas preditoras (lm com formula).",
                                "Histórico de iterações mostra estabilização de betas.",
                                "Teste em dataset real (stackloss) reproduz literatura."
                              ],
                              "assessmentCriteria": [
                                "Precisão: Coeficientes dentro de 1% do método padrão robusto.",
                                "Eficiência: Tempo de execução <5s para n=1000.",
                                "Robustez: Lida com 0-50% contaminação sem crash.",
                                "Documentação: Código comentado com explicação de cada componente.",
                                "Visualizações: Plots comparativos claros e informativos.",
                                "Generalidade: Função parametrizável e reutilizável."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Loops, funções e vetorização em R.",
                                "Estatística: Teoria de M-estimadores e funções de perda.",
                                "Visualização de Dados: ggplot2 para diagnósticos.",
                                "Ciência de Dados: Pré-processamento e validação de modelos.",
                                "Matemática Numérica: Métodos iterativos e convergência."
                              ],
                              "realWorldApplication": "Em finanças, modelar retornos de ações com outliers de crashes de mercado (ex: 2008); regressão robusta evita distorções em OLS, melhorando previsões de risco para portfólios de hedge funds."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.4.1.1"
                            ]
                          },
                          {
                            "id": "10.1.3.4.2.3",
                            "name": "Comparar estimadores robustos com MQO",
                            "description": "Realizar comparações empíricas de desempenho (MSE, breakdown point) entre MQO, Huber e LAD em simulações com grandes amostras e contaminação por outliers.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Gerar dados simulados limpos e contaminados",
                                  "subSteps": [
                                    "Defina um modelo linear verdadeiro: Y = β0 + β1 X + ε, com ε ~ N(0, σ²).",
                                    "Gere grandes amostras (n=1000+) de X ~ N(0,1) e Y sem outliers.",
                                    "Crie versões contaminadas adicionando 5-20% de outliers (ex: Y_out = Y + c * sign(ε), c grande).",
                                    "Repita para múltiplos níveis de contaminação (0%, 10%, 20%).",
                                    "Salve datasets em DataFrames para análise."
                                  ],
                                  "verification": "Verifique histogramas e QQ-plots de resíduos para confirmar presença de outliers nas versões contaminadas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python com NumPy, Pandas, Matplotlib, SciPy",
                                  "tips": "Use np.random.seed() para reprodutibilidade.",
                                  "learningObjective": "Entender como simular dados realistas com contaminação para testar robustez.",
                                  "commonMistakes": "Gerar outliers de forma não aleatória, levando a viés; ignorar normalização de X."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar estimadores MQO, Huber e LAD",
                                  "subSteps": [
                                    "Implemente MQO usando statsmodels.OLS.",
                                    "Configure Huber M-estimador com statsmodels.RLM(method='HuberT') ajustando k para tuning.",
                                    "Implemente LAD (Least Absolute Deviations) com statsmodels.RLM(method='MAD') ou quantile regression em mediana.",
                                    "Ajuste cada modelo aos dados limpos e contaminados.",
                                    "Extraia coeficientes estimados (β0_hat, β1_hat) e resíduos."
                                  ],
                                  "verification": "Compare coeficientes verdadeiros com estimados em dados limpos; todos devem ser próximos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python com Statsmodels, Jupyter Notebook",
                                  "tips": "Padronize tuning constants para Huber (ex: 1.345 para 95% eficiência).",
                                  "learningObjective": "Dominar implementação prática de estimadores clássicos e robustos em regressão.",
                                  "commonMistakes": "Não especificar method corretamente em RLM; confundir LAD com quantile regression em 0.5."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar simulações Monte Carlo e calcular métricas",
                                  "subSteps": [
                                    "Repita simulações 1000+ vezes para cada nível de contaminação.",
                                    "Calcule MSE = E[(β_hat - β_true)^2] para cada estimador e parâmetro.",
                                    "Estime breakdown point empírico: % contaminação até MSE explodir (>10x MSE_limpo).",
                                    "Registre variância e bias dos estimadores.",
                                    "Armazene resultados em arrays ou DataFrames para agregação."
                                  ],
                                  "verification": "MSE de MQO deve aumentar drasticamente com outliers, enquanto Huber/LAD permanecem estáveis.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Python com NumPy para loops vetorizados, Pandas para agregação",
                                  "tips": "Use paralelização com joblib para acelerar Monte Carlo.",
                                  "learningObjective": "Avaliar desempenho empírico via simulações para quantificar robustez.",
                                  "commonMistakes": "Poucas repetições levando a variância alta; calcular MSE só em um parâmetro."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar, visualizar e interpretar comparações",
                                  "subSteps": [
                                    "Crie boxplots de MSE por estimador e nível de contaminação.",
                                    "Plote breakdown points empíricos vs. teóricos (MQO=0%, Huber~25%, LAD~50%).",
                                    "Gere tabelas de MSE médio e intervalos de confiança.",
                                    "Interprete: robustos superam MQO em contaminação alta.",
                                    "Documente conclusões em relatório curto."
                                  ],
                                  "verification": "Gráficos mostram curvas de MSE divergentes; breakdown points condizem com teoria.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Matplotlib/Seaborn para plots, Pandas para tabelas",
                                  "tips": "Use log-scale em y para MSE em plots.",
                                  "learningObjective": "Interpretar resultados empíricos e comunicar vantagens da robustez.",
                                  "commonMistakes": "Ignorar ICs nos plots; super-generalizar sem considerar limitações da simulação."
                                }
                              ],
                              "practicalExample": "Em um dataset simulado de salários (Y) vs. experiência (X) com 10% de entradas erradas (outliers como 'salário=1M'), MQO superestima β1 em 30%, Huber erra 5%, LAD 2%; MSE de MQO é 10x maior.",
                              "finalVerifications": [
                                "MSE de Huber/LAD < MQO para contaminação >5%.",
                                "Breakdown point empírico: MQO ~0-1%, Huber ~20-25%, LAD ~45-50%.",
                                "Coeficientes robustos próximos aos verdadeiros em alta contaminação.",
                                "Plots de resíduos mostram redução de outliers influentes em robustos.",
                                "Tabelas de MSE com ICs 95% não sobrepõem para MQO vs. robustos em 20% contaminação.",
                                "Relatório resume pelo menos 3 vantagens quantitativas dos robustos."
                              ],
                              "assessmentCriteria": [
                                "Correção na implementação dos três estimadores (código executável e sem erros).",
                                "Precisão das métricas MSE e breakdown point (erro <5% do teórico).",
                                "Qualidade visual dos gráficos (legendas, escalas adequadas, clareza).",
                                "Interpretação coerente com teoria de robustez.",
                                "Eficiência computacional (simulações <5min com n=1000, reps=1000).",
                                "Relatório cobre limitações (ex: assumes contaminação simétrica)."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Loops Monte Carlo e vetorização em Python.",
                                "Estatística: Teoria assintótica de estimadores M e breakdown point.",
                                "Visualização de Dados: Boxplots e curvas de desempenho.",
                                "Machine Learning: Robust loss functions em regressão."
                              ],
                              "realWorldApplication": "Em finanças, comparar MQO vs. robustos em retornos de ações contaminados por erros de digitação ou crises; robustos previnem superestimação de risco em modelos de regressão para previsão de portfólios."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.4.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.4.3",
                        "name": "Inferência e Aplicações em Grandes Amostras",
                        "description": "Propriedades assintóticas, testes de inferência robustos e critérios de seleção de modelos em contextos de regressão robusta, com ênfase em aplicações econométricas para engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.4.3.1",
                            "name": "Derivar erros-padrão robustos (Huber-White)",
                            "description": "Calcular covariâncias robustas assintóticas para inferência válida sob heterocedasticidade, implementando em grandes amostras para testes de hipóteses.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Heterocedasticidade e Limitações dos Erros-Padrão OLS",
                                  "subSteps": [
                                    "Revise a definição de heterocedasticidade: variância condicional dos erros Var(ε_i | X_i) ≠ σ² constante.",
                                    "Analise a matriz de covariância OLS clássica: σ² (X'X)^{-1}, e por que ela subestima/supera variância sob heterocedasticidade.",
                                    "Visualize com plots de resíduos vs. valores ajustados em um dataset exemplo.",
                                    "Estude consequências para testes t, F e intervalos de confiança.",
                                    "Compare com homocedasticidade assumida."
                                  ],
                                  "verification": "Explique em 3-5 frases por que inferência OLS falha sob heterocedasticidade e desenhe um gráfico ilustrativo.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Introductory Econometrics' de Wooldridge (Cap. 8)",
                                    "Dataset simples de regressão (ex: wage data de statsmodels)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Sempre teste heterocedasticidade com Breusch-Pagan ou White test antes de prosseguir.",
                                  "learningObjective": "Identificar o problema teórico que justifica estimadores robustos como Huber-White.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade com autocorrelação",
                                    "Assumir normalidade dos erros sem testar variância",
                                    "Ignorar que OLS pontual permanece não-viesado"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Fórmula do Estimador de Covariância Huber-White (Sandwich)",
                                  "subSteps": [
                                    "Lembre a representação dos estimadores MLE/OLS: β̂ = β + (1/n) ∑ ψ_i, onde ψ_i = X_i ε_i.",
                                    "Derive a covariância assintótica: plim (1/n X'X)^{-1} [plim (1/n ∑ X_i ε_i² X_i')] plim (1/n X'X)^{-1}.",
                                    "Identifique componentes: 'bread' = (X'X/n)^{-1}, 'meat' = (1/n ∑ X_i ε̂_i² X_i').",
                                    "Escreva a fórmula finita-amostra Huber-White: (X'X)^{-1} (∑ X_i ε̂_i² X_i) (X'X)^{-1}.",
                                    "Discuta consistência assintótica sob condições de grandes amostras (LLN, CLT)."
                                  ],
                                  "verification": "Escreva e justifique a fórmula completa do sandwich estimator em LaTeX ou papel.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Paper 'The Behavior of the Sample Information Criterion' de White (1980)",
                                    "Notas de aula sobre inferência assintótica",
                                    "SymPy ou papel para derivação simbólica"
                                  ],
                                  "tips": "Lembre: meat usa resíduos OLS ε̂_i; para HC1/HC2, ajuste por graus de liberdade.",
                                  "learningObjective": "Dominar a derivação matemática do estimador robusto para inferência válida.",
                                  "commonMistakes": [
                                    "Usar ε_i em vez de ε̂_i no meat",
                                    "Esquecer os dois breads",
                                    "Aplicar em amostras pequenas sem ajustes HC"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Cálculo de Erros-Padrão Robustos em Software",
                                  "subSteps": [
                                    "Carregue dataset com heterocedasticidade conhecida (ex: Mroz wage data).",
                                    "Estime regressão OLS e extraia X, y, resíduos ε̂.",
                                    "Calcule manualmente: bread = inv(X.T @ X), meat = (X.T * (ε̂**2)) @ X / n, cov_robust = bread @ meat @ bread.",
                                    "Extraia erros-padrão: sqrt(diag(cov_robust)).",
                                    "Compare com funções built-in (statsmodels: cov_type='HC0'; R: sandwich::vcovHC)."
                                  ],
                                  "verification": "Execute código, compare erros-padrão OLS vs. robustos (diferença >10% indica heterocedasticidade).",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Python: statsmodels, pandas, numpy",
                                    "R: lmtest, sandwich",
                                    "Dataset: https://www.statsmodels.org/stable/datasets/generated/mroz.html"
                                  ],
                                  "tips": "Use HC3 para amostras menores: meat com (ε̂_i / (1-h_ii))^2 onde h_ii leverage.",
                                  "learningObjective": "Implementar computacionalmente o Huber-White para grandes amostras.",
                                  "commonMistakes": [
                                    "Normalizar incorretamente por n vs. n-k",
                                    "Incluir intercepto sem centering",
                                    "Usar resíduos brutos em vez de studentizados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Testes de Hipóteses e Inferência em Grandes Amostras",
                                  "subSteps": [
                                    "Com erros robustos, calcule estatísticas t = β̂_j / se_robust_j.",
                                    "Construa intervalos de confiança: β̂ ± 1.96 * se_robust.",
                                    "Realize teste F conjunto com covariância robusta completa.",
                                    "Simule grandes amostras (n=10000) para validar tamanho/distorsão.",
                                    "Interprete resultados: rejeição vs. OLS clássico."
                                  ],
                                  "verification": "Conduza teste H0: β_experience = 0 em dataset, reporte p-value robusto vs. clássico.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "Simulador Monte Carlo em Python/R"
                                  ],
                                  "tips": "Em n grande, robusto ≈ normal; valide com QQ-plot de estatísticas t.",
                                  "learningObjective": "Usar erros-padrão Huber-White para inferência confiável em contextos reais.",
                                  "commonMistakes": [
                                    "Interpretar se_robust como σ̂ clássico",
                                    "Ignorar dependência em clusters",
                                    "Usar sem testar heterocedasticidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em regressão de log(salário) sobre anos de educação e experiência usando dados CPS (n=50k), heterocedasticidade surge pois variância erros maior em altos salários. Calcule OLS: se_educ=0.02 (p<0.01); Huber-White: se_educ=0.025 (ainda significativo, mas IC mais largo). Teste H0: experiência afeta salário confirma com p=0.03 robusto vs. 0.01 clássico.",
                              "finalVerifications": [
                                "Deriva corretamente a fórmula sandwich?",
                                "Implementa manualmente em código com match <1% vs. built-in?",
                                "Identifica e corrige heterocedasticidade em dataset real?",
                                "Conduz teste t/F robusto e interpreta diferenças?",
                                "Explica validade assintótica em n>1000?",
                                "Compara Huber-White vs. HC2/HC3 adequadamente?"
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (30%)",
                                "Correção e eficiência da implementação computacional (30%)",
                                "Validação empírica com datasets e simulações (20%)",
                                "Interpretação clara de inferência robusta vs. clássica (10%)",
                                "Uso de testes diagnósticos e tips para pitfalls (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Aplicações em modelos de painel e IV",
                                "Programação Científica: Otimização matricial em NumPy/SciPy",
                                "Probabilidade Avançada: Inferência assintótica e CLT",
                                "Machine Learning: Robustez em gradient boosting e feature importance",
                                "Estatística Bayesiana: Priors para variância heterogênea"
                              ],
                              "realWorldApplication": "Em finanças, modelar retornos de ações com volatilidade heterocedástica (GARCH-like) para testes de fatores de risco; em saúde pública, regressões de outcomes hospitalares por região com variâncias desiguais, garantindo p-values válidos para políticas baseadas em evidência."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.3.4.3.2",
                            "name": "Aplicar testes de hipótese robustos",
                            "description": "Executar testes t e F robustos em modelos de regressão, avaliando significância de coeficientes em dados de engenharia com violações de pressupostos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar violações de pressupostos em dados de regressão",
                                  "subSteps": [
                                    "Carregar o conjunto de dados de engenharia (ex: dados de tensão vs. deformação com outliers).",
                                    "Executar regressão linear OLS padrão e plotar resíduos.",
                                    "Testar pressupostos: normalidade (QQ-plot, Shapiro-Wilk), homocedasticidade (Breusch-Pagan), independência (Durbin-Watson).",
                                    "Identificar violações específicas (ex: heterocedasticidade ou outliers influentes).",
                                    "Documentar evidências gráficas e numéricas das violações."
                                  ],
                                  "verification": "Relatório com gráficos de resíduos e p-valores de testes mostrando violações claras.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (statsmodels, scipy) ou R (lmtest, car); dataset de engenharia (ex: concrete strength).",
                                  "tips": "Sempre visualize resíduos antes de testes numéricos para intuição rápida.",
                                  "learningObjective": "Diagnosticar falhas nos pressupostos da regressão linear clássica.",
                                  "commonMistakes": "Ignorar outliers visuais ou confiar apenas em testes sem gráficos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Selecionar e ajustar modelo de regressão robusta",
                                  "subSteps": [
                                    "Escolher estimador robusto (ex: Huber M-estimator ou least trimmed squares).",
                                    "Ajustar o modelo robusto usando biblioteca apropriada (ex: statsmodels.robust ou robustbase em R).",
                                    "Comparar coeficientes OLS vs. robustos em tabela.",
                                    "Calcular pesos robustos para identificar observações downweighted.",
                                    "Plotar resíduos robustos para confirmação inicial."
                                  ],
                                  "verification": "Modelo ajustado com coeficientes robustos diferentes dos OLS em pelo menos 20%.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (statsmodels.RLM) ou R (rlm); mesmo dataset.",
                                  "tips": "Comece com Huber para simplicidade; ajuste psi para tuning.",
                                  "learningObjective": "Implementar regressão robusta para lidar com violações de pressupostos.",
                                  "commonMistakes": "Usar o modelo errado para o tipo de violação (ex: bootstrap para heterocedasticidade leve)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar testes t robustos para coeficientes individuais",
                                  "subSteps": [
                                    "Calcular estatística t robusta para cada coeficiente usando covariância sandwich (HC).",
                                    "Implementar teste t com p-valores via distribuição t ou bootstrap.",
                                    "Interpretar significância (ex: |t| > 2 ou p < 0.05).",
                                    "Comparar com testes t clássicos.",
                                    "Reportar intervalos de confiança robustos (95%)."
                                  ],
                                  "verification": "Tabela com t-stats, p-valores e ICs para todos coeficientes, mostrando diferenças.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Python (statsmodels.formula.api com cov_type='HC3') ou R (sandwich, lmtest).",
                                  "tips": "Use HC3 para amostras pequenas em engenharia para conservadorismo.",
                                  "learningObjective": "Avaliar significância individual de coeficientes sob violações.",
                                  "commonMistakes": "Esquecer de ajustar covariância para testes válidos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar teste F robusto global e interpretar resultados",
                                  "subSteps": [
                                    "Realizar teste F robusto para significância global do modelo (Wald test com sandwich).",
                                    "Testar subconjuntos de variáveis via F robusto comparativo.",
                                    "Avaliar R² robusto e comparar com OLS.",
                                    "Interpretar no contexto de engenharia (ex: quais variáveis predizem falha estrutural).",
                                    "Gerar relatório final com todas métricas."
                                  ],
                                  "verification": "p-valor F global < 0.05 e pelo menos 70% de coeficientes significativos robustamente.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Mesmas bibliotecas; script integrado.",
                                  "tips": "Combine com stepwise robusto para seleção de modelo.",
                                  "learningObjective": "Testar adequação global do modelo robusto em dados violados.",
                                  "commonMistakes": "Interpretar F sem contexto de violações observadas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e aplicar em cenário de engenharia real",
                                  "subSteps": [
                                    "Simular dados de engenharia com violações conhecidas (ex: adicionar outliers).",
                                    "Aplicar pipeline completo e prever novos dados.",
                                    "Cross-validar previsões robustas vs. OLS.",
                                    "Documentar insights (ex: outlier era falha de sensor).",
                                    "Exportar relatório com código reproduzível."
                                  ],
                                  "verification": "Previsões robustas com erro < 15% em hold-out set violado.",
                                  "estimatedTime": "55 minutos",
                                  "materials": "Dataset simulado ou real (ex: UCI Machine Learning Repo); Jupyter ou RMarkdown.",
                                  "tips": "Use seed para reproducibilidade em simulações.",
                                  "learningObjective": "Integrar testes robustos em workflow de análise de engenharia.",
                                  "commonMistakes": "Não validar em dados novos, levando a overfitting."
                                }
                              ],
                              "practicalExample": "Em dados de resistência à compressão de concreto (com outliers de medições erradas), ajuste regressão robusta de resistência vs. idade/cimento. Testes t robustos mostram significância de 'cimento' apesar de heterocedasticidade, enquanto OLS falha; F global confirma modelo útil para previsão de falhas estruturais.",
                              "finalVerifications": [
                                "Coeficientes robustos diferem >10% dos OLS.",
                                "p-valores t/F robustos <0.05 para variáveis chave.",
                                "Resíduos robustos sem padrões evidentes em plots.",
                                "R² robusto >0.6.",
                                "Previsões em hold-out com MAE <10% do desvio padrão.",
                                "Relatório reproduzível com código e outputs."
                              ],
                              "assessmentCriteria": [
                                "Precisão na detecção de violações (gráficos + testes).",
                                "Correta implementação de estimadores e covariâncias sandwich.",
                                "Interpretação coerente de significância t/F.",
                                "Comparação quantitativa OLS vs. robusto.",
                                "Aplicação contextual em engenharia com insights acionáveis.",
                                "Código limpo, comentado e reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência não-paramétrica e bootstrap.",
                                "Programação: Manipulação de dados em Python/R (pandas/dplyr).",
                                "Engenharia: Análise de dados experimentais e controle de qualidade.",
                                "Matemática: Álgebra linear em matriz de covariância."
                              ],
                              "realWorldApplication": "Em engenharia civil, usar testes robustos para modelar fadiga de materiais com dados ruidosos de sensores, identificando preditores significativos de falha apesar de outliers de vibrações extremas, otimizando designs de pontes ou edifícios."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.4.2.2"
                            ]
                          },
                          {
                            "id": "10.1.3.4.3.3",
                            "name": "Selecionar modelos usando critérios robustos",
                            "description": "Utilizar AIC/BIC adaptados ou validação cruzada robusta para seleção de modelos em grandes amostras, comparando com métodos clássicos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e definir modelos candidatos para grandes amostras",
                                  "subSteps": [
                                    "Carregue um dataset grande com potenciais outliers (ex: >10k observações).",
                                    "Identifique variáveis preditoras e resposta; realize limpeza inicial (remover NAs).",
                                    "Defina 3-5 modelos candidatos (linear, polinomial, ridge, lasso).",
                                    "Divida dados em treino/validação/teste usando splits robustos a outliers.",
                                    "Aplique transformações robustas (ex: winsorizing) para preparar amostra."
                                  ],
                                  "verification": "Confirme dataset carregado, modelos definidos e splits criados sem erros; visualize distribuições.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (pandas, numpy, scikit-learn), dataset exemplo (ex: California Housing).",
                                  "tips": "Use stratified sampling para manter representatividade em grandes amostras.",
                                  "learningObjective": "Preparar dados robustos e listar modelos para comparação.",
                                  "commonMistakes": "Ignorar outliers na preparação, levando a splits enviesados."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular critérios de informação clássicos (AIC/BIC)",
                                  "subSteps": [
                                    "Ajuste cada modelo candidato no conjunto de treino usando OLS padrão.",
                                    "Calcule AIC e BIC para cada modelo com fórmulas padrão.",
                                    "Registre valores e ranqueie modelos pelo menor AIC/BIC.",
                                    "Compare log-likelihood e penalidades por parâmetros.",
                                    "Plote AIC/BIC vs. complexidade do modelo."
                                  ],
                                  "verification": "Tabela com AIC/BIC para todos modelos; gráfico confirma ranking.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (statsmodels para AIC/BIC), matplotlib para plots.",
                                  "tips": "Use summary() em statsmodels para AIC/BIC direto.",
                                  "learningObjective": "Dominar cálculo e interpretação de AIC/BIC clássicos.",
                                  "commonMistakes": "Confundir AIC com BIC; ignorar sobreajuste em amostras grandes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar critérios robustos (AIC/BIC adaptados ou CV robusta)",
                                  "subSteps": [
                                    "Ajuste modelos com estimadores robustos (ex: Huber loss ou MM-estimators).",
                                    "Calcule AIC/BIC robustos adaptando log-likelihood robusta.",
                                    "Implemente validação cruzada robusta (ex: k-fold com trimming de outliers).",
                                    "Compute médias de erro robusto (MAE ou Huber) em folds.",
                                    "Ranqueie modelos pelos critérios robustos."
                                  ],
                                  "verification": "Tabela comparativa de critérios robustos; CV scores consistentes.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (sklearn robusto via RobustScaler, custom Huber; robustbase em R alternativo).",
                                  "tips": "Use sklearn.model_selection.cross_val_score com métrica robusta personalizada.",
                                  "learningObjective": "Aplicar e calcular métricas robustas para seleção.",
                                  "commonMistakes": "Não adaptar penalidades para robustez, subestimando variância."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar métodos e selecionar modelo ótimo",
                                  "subSteps": [
                                    "Compare rankings clássicos vs. robustos em tabela unificada.",
                                    "Avalie sensibilidade a outliers simulados (adicione 5-10% outliers).",
                                    "Selecione modelo com melhor performance robusta em validação.",
                                    "Teste final no conjunto de teste com métricas robustas.",
                                    "Documente justificativa da escolha."
                                  ],
                                  "verification": "Relatório final com tabela comparativa, seleção justificada e teste OK.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Jupyter Notebook para relatórios, datasets com outliers artificiais.",
                                  "tips": "Simule outliers realistas (ex: multiplicar residuals por 10).",
                                  "learningObjective": "Comparar e decidir baseado em critérios robustos vs. clássicos.",
                                  "commonMistakes": "Selecionar por clássico ignorando robustez em grandes amostras."
                                }
                              ],
                              "practicalExample": "Em um dataset de preços de casas (California Housing, 20k amostras), compare modelos lineares vs. polinomiais usando AIC/BIC clássico (seleciona polinomial) vs. robusto com CV 5-fold e Huber loss (seleciona linear robusto, ignorando outliers de luxo).",
                              "finalVerifications": [
                                "Tabela completa compara AIC/BIC clássico e robusto para todos modelos.",
                                "Validação cruzada robusta mostra CV-error < threshold (ex: MAE < 0.1).",
                                "Modelo selecionado performa bem em conjunto de teste com outliers.",
                                "Relatório explica por que robusto difere do clássico.",
                                "Simulação de outliers confirma estabilidade da seleção.",
                                "Código reproduzível gera mesmos resultados."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de AIC/BIC clássico e robusto (erro <1%).",
                                "Implementação correta de CV robusta (média de folds consistente).",
                                "Justificativa lógica para modelo selecionado.",
                                "Análise de sensibilidade a outliers demonstrada.",
                                "Código limpo, comentado e eficiente para grandes amostras.",
                                "Interpretação correta de diferenças entre métodos."
                              ],
                              "crossCurricularConnections": [
                                "Machine Learning: Integra com feature selection e hyperparameter tuning.",
                                "Estatística: Liga estimação robusta (M-estimators) a inferência.",
                                "Programação: Prática em otimização numérica e simulações.",
                                "Ciência de Dados: Aplicação em pipelines de modelagem preditiva."
                              ],
                              "realWorldApplication": "Em finanças, selecionar modelos robustos para previsão de retornos de ações em mercados voláteis com outliers (crashs), evitando sobreajuste clássico e melhorando precisão em portfólios reais."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.3.4.1.3",
                              "10.1.3.4.2.3"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.3.5",
                    "name": "Propriedades Assintóticas de Estimadores",
                    "description": "Análise de convergência e eficiência de estimadores em amostras grandes.",
                    "individualConcepts": [
                      {
                        "id": "10.1.3.5.1",
                        "name": "Consistência de Estimadores",
                        "description": "Conceito de convergência em probabilidade de estimadores para o valor verdadeiro à medida que o tamanho da amostra aumenta, com foco em estimadores de Mínimos Quadrados Ordinários (MQO) em regressão linear.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.5.1.1",
                            "name": "Definir consistência e plim",
                            "description": "Explicar a definição formal de consistência de um estimador, incluindo o operador de limite em probabilidade (plim) e sua relação com viés e variância em amostras grandes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de Estimadores e Convergência",
                                  "subSteps": [
                                    "Defina um estimador como uma função de uma amostra aleatória que estima um parâmetro populacional.",
                                    "Explique a diferença entre convergência em probabilidade e convergência quase certa.",
                                    "Discuta o papel do tamanho da amostra (n → ∞) na análise assintótica.",
                                    "Identifique exemplos simples de estimadores, como a média amostral para a média populacional.",
                                    "Revise notação probabilística básica, como P(|X - μ| < ε) → 1."
                                  ],
                                  "verification": "Escreva definições curtas para estimador e convergência em probabilidade; confira com fontes padrão.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Livro de Estatística Inferencial (ex: Casella & Berger)",
                                    "Notas de aula sobre probabilidade"
                                  ],
                                  "tips": "Use analogias: pense no estimador como um 'chute educado' que melhora com mais dados.",
                                  "learningObjective": "Compreender os fundamentos necessários para consistência.",
                                  "commonMistakes": "Confundir estimador com estatística descritiva simples."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir Formalmente a Consistência de um Estimador",
                                  "subSteps": [
                                    "Estabeleça a definição: Um estimador θ̂_n é consistente para θ se plim θ̂_n = θ.",
                                    "Escreva a definição matemática: Para todo ε > 0, P(|θ̂_n - θ| > ε) → 0 quando n → ∞.",
                                    "Diferencie consistência fraca (em probabilidade) de forte (quase certa).",
                                    "Discuta implicações: consistência garante que o erro diminui com mais dados.",
                                    "Prove consistência para a média amostral usando a Lei dos Grandes Números (LLN)."
                                  ],
                                  "verification": "Escreva e verifique a definição formal; aplique à média amostral.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Quadro branco ou papel para fórmulas",
                                    "Software como R ou Python para simular LLN"
                                  ],
                                  "tips": "Memorize: consistência = 'vai para o valor verdadeiro na maioria dos casos com n grande'.",
                                  "learningObjective": "Dominar a definição precisa de consistência.",
                                  "commonMistakes": "Ignorar o 'em probabilidade'; achar que é apenas média exata."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Entender o Operador plim (Limite em Probabilidade)",
                                  "subSteps": [
                                    "Defina plim_{n→∞} X_n = c como: Para todo ε > 0, P(|X_n - c| > ε) → 0.",
                                    "Compare plim com lim determinístico e com E[·].",
                                    "Ilustre com exemplo: plim da média amostral é μ pela LLN.",
                                    "Discuta notação: plim vs. P-lim, e uso em teoremas assintóticos.",
                                    "Exercite reescrevendo definições de consistência usando plim explicitamente."
                                  ],
                                  "verification": "Traduza 3 expressões probabilísticas para notação plim e valide.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Referência: Hogg & Craig Estatística",
                                    "Calculadora ou sympy para limites"
                                  ],
                                  "tips": "Pense em plim como 'limite onde a probabilidade de erro vai a zero'.",
                                  "learningObjective": "Usar corretamente o operador plim em contextos assintóticos.",
                                  "commonMistakes": "Confundir plim com expectativa: plim ≠ E[lim]."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar Consistência com Viés e Variância em Amostras Grandes",
                                  "subSteps": [
                                    "Lembre: Erro Médio Quadrático (MSE) = Viés² + Variância.",
                                    "Explique: Para consistência, MSE → 0, tipicamente viés → 0 e variância → 0.",
                                    "Discuta estimadores viesados consistentes (ex: retratação de James-Stein).",
                                    "Analise como LLN/CLT implicam variância → 0 e viés fixo pequeno.",
                                    "Simule em software: mostre viés e variância decaindo com n crescente."
                                  ],
                                  "verification": "Calcule MSE para um estimador simples e mostre → 0; plote simulação.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Python/R com numpy/ggplot para simulações",
                                    "Artigo sobre propriedades assintóticas"
                                  ],
                                  "tips": "Simule sempre: visualize como pontos se concentram no verdadeiro θ.",
                                  "learningObjective": "Conectar consistência a decomposição de erro.",
                                  "commonMistakes": "Achar que consistência requer ausência total de viés."
                                }
                              ],
                              "practicalExample": "Considere o estimador da média populacional μ pela média amostral X̄_n. Pelas LLN, plim X̄_n = μ, logo é consistente. Simule: gere amostras de N(0,1) com n=10,100,1000; veja X̄_n aproximar 0, com variância ~1/n decaindo.",
                              "finalVerifications": [
                                "Reescreva a definição de consistência usando plim corretamente.",
                                "Prove consistência da média amostral via LLN.",
                                "Explique por que um estimador com viés fixo pode ser consistente.",
                                "Simule e plote convergência em probabilidade para um estimador.",
                                "Diferencie plim de outros limites em um exemplo numérico.",
                                "Relacione MSE → 0 com consistência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição formal de consistência e plim (sem erros conceituais).",
                                "Correta relação entre consistência, viés e variância.",
                                "Uso apropriado de notação matemática e probabilística.",
                                "Capacidade de provar ou simular exemplos simples.",
                                "Clareza na explicação de implicações assintóticas.",
                                "Identificação de erros comuns em contextos relacionados."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Lei dos Grandes Números e Teorema Central do Limite.",
                                "Machine Learning: Validação de modelos assintóticos em grandes datasets.",
                                "Econometria: Análise de consistência em regressões.",
                                "Computação Científica: Simulações Monte Carlo para verificação."
                              ],
                              "realWorldApplication": "Em análise de dados reais, como prever demanda em e-commerce, usa-se consistência para confiar que estimadores de parâmetros (ex: taxa de conversão) com milhões de cliques convergem ao verdadeiro valor, guiando decisões de estoque sem risco de viés persistente."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.1.2",
                            "name": "Identificar condições para consistência do MQO",
                            "description": "Listar e discutir os pressupostos assintóticos necessários para a consistência dos estimadores de MQO em regressão linear, como exogeneidade estrita e não correlação serial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de consistência assintótica em estimadores",
                                  "subSteps": [
                                    "Defina consistência assintótica: plim β_hat = β verdadeiro quando n → ∞",
                                    "Explique a diferença entre viés e inconsistência usando notação probabilística (plim)",
                                    "Revise a fórmula do estimador MQO: β_hat = (X'X)^{-1} X'y",
                                    "Discuta por que propriedades finitas não garantem consistência",
                                    "Estude a decomposição: β_hat - β = (X'X/n)^{-1} (X'ε/n)"
                                  ],
                                  "verification": "Escreva uma definição precisa de consistência e derive a condição necessária plim(X'ε/n)=0",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de Econometria (Wooldridge, Cap. 3)",
                                    "Notas de aula sobre propriedades assintóticas",
                                    "Calculadora ou software como R/Python para simulações simples"
                                  ],
                                  "tips": "Use analogias como 'média amostral converge para expectativa' para intuitar",
                                  "learningObjective": "Dominar a definição formal e intuitiva de consistência assintótica",
                                  "commonMistakes": [
                                    "Confundir consistência com não-viés finito",
                                    "Ignorar o papel do tamanho da amostra n"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Listar os pressupostos assintóticos fundamentais para consistência do MQO",
                                  "subSteps": [
                                    "Pressuposto 1: Exogeneidade estrita - E[ε_i | X_i] = 0 para todo i",
                                    "Pressuposto 2: (1/n) X'X →^p Q, matriz positiva definida (não multicolinearidade assintótica)",
                                    "Pressuposto 3: (1/n) X'ε →^p 0 (consequência da exogeneidade e LLN)",
                                    "Pressuposto 4: Erros com variância finita e sem correlação serial forte (para processos estacionários)",
                                    "Pressuposto 5: Condições de ergodicidade para processos dependentes"
                                  ],
                                  "verification": "Liste os 5 pressupostos em uma tabela com descrições breves e símbolos matemáticos",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Slides sobre MQO assintótico",
                                    "Artigo de referência: White (1980) sobre robustez assintótica"
                                  ],
                                  "tips": "Memorize usando acrônimo 'E-X-Q-E' (Exogeneidade, X'X, Quase, Erros)",
                                  "learningObjective": "Identificar e enumerar precisamente os pressupostos necessários",
                                  "commonMistakes": [
                                    "Incluir homocedasticidade como obrigatória (é para eficiência, não consistência)",
                                    "Esquecer não-multicolinearidade assintótica"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar profundamente a exogeneidade estrita e não-correlação serial",
                                  "subSteps": [
                                    "Explique exogeneidade estrita: E[ε|X]=0 implica Cov(X,ε)=0 e ausência de endogeneidade",
                                    "Discuta violações: variáveis omitidas, simultaneidade, measurement error",
                                    "Analise não-correlação serial: E[ε_t | X_t, ε_{t-1}, ...] = 0 para dados em painel/série temporal",
                                    "Derive matematicamente por que violação leva a plim β_hat ≠ β",
                                    "Compare com exogeneidade fraca (apenas Cov(X,ε)=0)"
                                  ],
                                  "verification": "Resolva um exercício: prove que sob exogeneidade, plim(X'ε/n)=0 pela LLN condicional",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Software R/Python para simular regressão com endogeneidade",
                                    "Exercícios de Wooldridge"
                                  ],
                                  "tips": "Simule em código: gere X endógeno e mostre β_hat não convergindo",
                                  "learningObjective": "Discutir implicações e violações dos pressupostos chave",
                                  "commonMistakes": [
                                    "Confundir exogeneidade com ortogonalidade nos erros",
                                    "Ignorar dependência serial em dados temporais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar condições em um exemplo prático e discutir robustez",
                                  "subSteps": [
                                    "Selecione um dataset simples (ex: salários vs educação)",
                                    "Teste pressupostos: correlograma para serial correlation, Hausman para endogeneidade",
                                    "Simule cenários de violação e observe convergência com n crescente",
                                    "Discuta testes assintóticos: LM para serial correlation",
                                    "Conclua com condições suficientes para consistência em contextos reais"
                                  ],
                                  "verification": "Gere gráfico de β_hat vs n em simulação violando e não violando pressupostos",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R ou Python (pacotes lmtest, ivreg)",
                                    "Dataset exemplo: wage1.dta de Wooldridge"
                                  ],
                                  "tips": "Use loops em código para variar n de 100 a 10000",
                                  "learningObjective": "Aplicar diagnóstico de pressupostos em dados reais",
                                  "commonMistakes": [
                                    "Usar testes finitos para propriedades assintóticas",
                                    "Não escalar matrizes por n"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma regressão de salário sobre anos de educação, simule endogeneidade (educação correlacionada com habilidade omitida): gere y = β0 + β1*edu + u, edu = γ0 + γ1*habilidade + v. Estime MQO com n=100,1000,10000; observe β1_hat não convergindo para β1 verdadeiro sem IV.",
                              "finalVerifications": [
                                "Liste corretamente os 5 pressupostos assintóticos com fórmulas",
                                "Explique impacto de violação de exogeneidade em plim β_hat",
                                "Simule e plote convergência em código R/Python",
                                "Discuta não-correlação serial em contexto de série temporal",
                                "Identifique violações comuns em datasets reais",
                                "Derive condição plim(X'X/n)^{-1} (X'ε/n) = 0"
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas definições e derivações (30%)",
                                "Profundidade na discussão de violações e implicações (25%)",
                                "Qualidade da simulação prática e interpretação de resultados (20%)",
                                "Clareza na listagem e priorização de pressupostos (15%)",
                                "Uso correto de terminologia assintótica (plim, LLN) (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Leis dos Grandes Números e Teorema Central do Limite",
                                "Econometria: Testes de endogeneidade (Hausman, IV)",
                                "Machine Learning: Viés em regressão linear vs regularização",
                                "Série Temporal: Modelos ARMA e autocorrelação nos resíduos"
                              ],
                              "realWorldApplication": "Em previsões econômicas, como estimar impacto de educação no salário; violação de exogeneidade leva a políticas falhas (ex: subestimar ROI de educação por omitir habilidade inata), exigindo IV para consistência em grandes datasets governamentais."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.1.3",
                            "name": "Demonstrar consistência via Lei dos Grandes Números",
                            "description": "Aplicar a Lei dos Grandes Números para provar a consistência dos coeficientes de MQO sob pressupostos relaxados em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Modelo Linear e o Estimador MQO",
                                  "subSteps": [
                                    "Defina o modelo linear Y = Xβ + ε, onde E[ε|X] = 0 sob pressupostos clássicos.",
                                    "Expresse o estimador MQO: β̂ = (X'X/n)^{-1} (X'Y/n).",
                                    "Identifique os pressupostos relaxados: independência fraca, momentos finitos de X e ε.",
                                    "Discuta por que a consistência requer n → ∞.",
                                    "Calcule o viés em amostras finitas para motivar a convergência."
                                  ],
                                  "verification": "Escreva a fórmula do β̂ e liste 3 pressupostos relaxados corretamente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Notas de aula sobre MQO",
                                    "Livro de Wooldridge 'Introdução à Econometria'",
                                    "Calculadora ou papel para derivações"
                                  ],
                                  "tips": "Comece sempre pela normalização por n para destacar médias amostrais.",
                                  "learningObjective": "Compreender a estrutura do estimador MQO em termos probabilísticos.",
                                  "commonMistakes": [
                                    "Confundir MQO com Mínimos Quadrados Parciais",
                                    "Ignorar a inversa de (X'X/n)",
                                    "Assumir homocedasticidade desnecessária"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir a Lei dos Grandes Números (LLN)",
                                  "subSteps": [
                                    "Enuncie a LLN fraca: plim (1/n Σ Z_i) = E[Z] se E[|Z|] < ∞ e independência.",
                                    "Discuta versões para variáveis dependentes (LLN de ergodicidade).",
                                    "Aplique à matriz Q_n = X'X/n →^p Q = E[xx'], onde x é vetor de regressores.",
                                    "Mostre S_n = X'ε/n →^p 0 sob exogeneidade E[ε|x] = 0.",
                                    "Verifique condições: momentos de segunda ordem finitos."
                                  ],
                                  "verification": "Prove que plim Q_n = Q usando LLN em cada elemento.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Texto de probabilidade (ex: Billingsley)",
                                    "Python com NumPy para simular LLN simples"
                                  ],
                                  "tips": "Use notação plim para convergência em probabilidade.",
                                  "learningObjective": "Dominar a aplicação da LLN a sequências de médias amostrais multivariadas.",
                                  "commonMistakes": [
                                    "Aplicar LLN forte sem necessidade",
                                    "Esquecer momentos finitos",
                                    "Confundir com TLC"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar a Consistência de β̂ via LLN",
                                  "subSteps": [
                                    "Escreva β̂ = Q_n^{-1} S_n, onde S_n = X'Y/n = Q_n β + X'ε/n.",
                                    "Mostre plim β̂ = plim Q_n^{-1} (plim Q_n β + plim (X'ε/n)) = Q^{-1} (Q β + 0) = β.",
                                    "Assuma Q positiva definida (identificação).",
                                    "Discuta pressupostos relaxados: sem esfericidade, apenas exogeneidade ortogonal.",
                                    "Generalize para heterocedasticidade condicional."
                                  ],
                                  "verification": "Derive a igualdade plim β̂ = β em 5 linhas ou menos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Lápis e papel para algebra matricial",
                                    "Software MATLAB/R para verificar algebra simbolicamente"
                                  ],
                                  "tips": "Normalize tudo por n desde o início para facilitar.",
                                  "learningObjective": "Provar formalmente a consistência usando convergência em probabilidade.",
                                  "commonMistakes": [
                                    "Esquecer de multiplicar Q_n^{-1} por plim S_n",
                                    "Assumir Q_n converge quase seguramente",
                                    "Ignorar invertibilidade de Q"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Pressupostos Relaxados e Simulação",
                                  "subSteps": [
                                    "Liste pressupostos mínimos: E[xε]=0, E[xx'] finita e positiva definida.",
                                    "Simule dados com n=100,1000,10000: gere X~N(0,1), ε|X ~ N(0,1), β=[1,2].",
                                    "Calcule β̂ para cada n e plote erro |β̂ - β| vs n.",
                                    "Observe convergência empírica via LLN.",
                                    "Teste violação: adicione correlação em ε e veja falha."
                                  ],
                                  "verification": "Gere gráfico mostrando |β̂ - β| → 0 com n crescente.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python (NumPy, Matplotlib, Statsmodels)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use np.linalg.lstsq para MQO e loops para múltiplos n.",
                                  "learningObjective": "Validar teoricamente via evidência computacional.",
                                  "commonMistakes": [
                                    "Escala errada em X (multicolinearidade artificial)",
                                    "Seeds fixos sem replicatas",
                                    "Ignorar variância em simulações"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificações Finais e Extensões",
                                  "subSteps": [
                                    "Resuma prova: LLN em Q_n e X'ε/n implica consistência.",
                                    "Discuta limitações: endogeneidade quebra LLN em X'ε/n.",
                                    "Conecte a inferência assintótica (TLC para normalidade).",
                                    "Resolva exercício: prove consistência para modelo com intercepto.",
                                    "Prepare apresentação da prova completa."
                                  ],
                                  "verification": "Explique a prova oralmente em <5 min sem notas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Resumo escrito da prova",
                                    "Vídeos de econometria no YouTube (ex: Ben Lambert)"
                                  ],
                                  "tips": "Pratique verbalizando a chain: Q_n → Q, X'ε/n →0, logo β̂ → β.",
                                  "learningObjective": "Sintetizar e comunicar a demonstração de consistência.",
                                  "commonMistakes": [
                                    "Confundir consistência com não-viés",
                                    "Omitir invertibilidade",
                                    "Generalizar além de pressupostos relaxados"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (Y) vs anos de educação e experiência (X), com n=10^6 observações, simule ε correlacionado fracamente com X. Calcule β̂_MQO e observe que converge para β verdadeiro ([0.1, 0.05, 0.02]), ilustrando LLN em Q_n = E[xx'] e X'ε/n →0, mesmo sem homocedasticidade.",
                              "finalVerifications": [
                                "Deriva corretamente plim β̂ = β usando LLN.",
                                "Lista e justifica pressupostos relaxados (exogeneidade, momentos finitos).",
                                "Simula numericamente convergência com n crescente.",
                                "Identifica violações que quebram consistência (endogeneidade).",
                                "Explica intuitivamente por que grandes amostras provam consistência.",
                                "Conecta a aplicações reais como big data em ML."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (80% peso).",
                                "Clareza na explicação de LLN e pressupostos (15%).",
                                "Qualidade da simulação e gráficos (5%).",
                                "Profundidade na discussão de relaxamentos.",
                                "Capacidade de generalizar para outros estimadores."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teoremas de convergência (LLN, TLC).",
                                "Estatística Computacional: Simulações Monte Carlo.",
                                "Econometria: Propriedades assintóticas de IV/GMM.",
                                "Machine Learning: Consistência em regressão linear de alta dimensão."
                              ],
                              "realWorldApplication": "Em análise de dados massivos (ex: Google Analytics com bilhões de cliques), MQO consistente via LLN permite estimar impactos causais confiáveis em modelos lineares relaxados, como previsão de demanda ou A/B testing, onde n grande mitiga viés em pressupostos fracos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.5.2",
                        "name": "Normalidade Assintótica",
                        "description": "Propriedade pela qual a distribuição de estimadores se aproxima de uma normal em amostras grandes, essencial para inferência estatística em econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.3.5.2.1",
                            "name": "Explicar o Teorema do Limite Central para estimadores",
                            "description": "Descrever como o Teorema do Limite Central implica normalidade assintótica para médias amostrais e estimadores de MQO sob condições de momentos finitos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Teorema do Limite Central (TLC) Clássico",
                                  "subSteps": [
                                    "Estude o enunciado básico do TLC: a soma normalizada de variáveis i.i.d. com média μ e variância finita σ² converge em distribuição para N(0,1).",
                                    "Revise conceitos prévios: convergência em distribuição, função geradora de momentos.",
                                    "Analise provas intuitivas baseadas em convolução de densidades.",
                                    "Discuta condições Lindeberg-Feller para generalizações.",
                                    "Resolva exercícios simples com distribuições não normais (ex: Bernoulli)."
                                  ],
                                  "verification": "Enuncie corretamente o TLC e prove intuitivamente para n→∞ usando um diagrama de densidades.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro 'All of Statistics' (Wasserman), Khan Academy vídeos sobre TLC, papel e caneta para diagramas.",
                                  "tips": "Visualize com animações de soma de dados de dados para ver a forma de sino emergir.",
                                  "learningObjective": "Compreender a essência do TLC como base para normalidade assintótica.",
                                  "commonMistakes": "Confundir convergência em probabilidade com convergência em distribuição; ignorar variância finita."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar TLC à Média Amostral",
                                  "subSteps": [
                                    "Mostre que a média amostral Ῡ = (1/n)∑X_i satisfaz √n(Ῡ - μ) → N(0, σ²).",
                                    "Derive a normalidade assintótica explicitamente a partir do TLC.",
                                    "Discuta independência das X_i e momentos finitos E|X_i|^{2+δ} < ∞.",
                                    "Simule em software: gere médias de distribuições assimétricas e plote histogramas.",
                                    "Compare com aproximação normal via Q-Q plots."
                                  ],
                                  "verification": "Calcule a distribuição assintótica de √n(Ῡ - μ) e interprete para n=1000.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (NumPy, Matplotlib), Jupyter Notebook, dados sintéticos gerados.",
                                  "tips": "Use seed para reprodutibilidade nas simulações; aumente n gradualmente para observar convergência.",
                                  "learningObjective": "Explicar como TLC implica normalidade para estatísticos simples como médias.",
                                  "commonMistakes": "Esquecer o fator √n na normalização; assumir normalidade exata em vez de assintótica."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estender TLC a Estimadores de MQO",
                                  "subSteps": [
                                    "Revise o modelo de regressão linear: Y_i = X_i β + ε_i, com E(ε_i|X)=0.",
                                    "Mostre que β̂_MQO = (X'X/n)^{-1}(X'Y/n) é média de termos lineares em ε_i.",
                                    "Aplique TLC multivariado a √n(β̂ - β) = (X'X/n)^{-1}(1/√n ∑ X_i ε_i).",
                                    "Verifique condições: exogeneidade, homocedasticidade condicional, momentos finitos de X_i ε_i.",
                                    "Derive a covariância assintótica: N(0, plim (X'X/n)^{-1} σ²)."
                                  ],
                                  "verification": "Escreva a prova passo a passo da normalidade assintótica de β̂_MQO.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Notas de Econometria (Wooldridge), MATLAB ou R para regressões simuladas.",
                                  "tips": "Centralize as equações matriciais para clareza; use notação assintótica plim.",
                                  "learningObjective": "Conectar TLC diretamente à normalidade de estimadores lineares.",
                                  "commonMistakes": "Ignorar a matriz (X'X/n); confundir MQO com MLE."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Condições e Implicações Práticas",
                                  "subSteps": [
                                    "Liste condições chave: i.i.d. ou débil dependência, E|ε_i|^{2+δ}<∞, E||X_i||^{2+δ}<∞.",
                                    "Discuta violações: heterocedasticidade (use EHC), dependência serial (CLT para misturas).",
                                    "Explore implicações: testes t/Wald assintóticos, intervalos de confiança.",
                                    "Realize uma regressão real com n grande e verifique normalidade dos resíduos padronizados.",
                                    "Compare com bootstrap para validação."
                                  ],
                                  "verification": "Identifique quando o TLC falha e sugira alternativas para dados reais.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Dataset público (ex: Boston Housing), Stata/Python statsmodels.",
                                  "tips": "Sempre cheque diagnósticos de regressão antes de inferir assintoticamente.",
                                  "learningObjective": "Avaliar robustez do TLC em contextos de MQO reais.",
                                  "commonMistakes": "Aplicar TLC sem verificar momentos finitos; superestimar validade para n pequeno."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar e Testar Compreensão",
                                  "subSteps": [
                                    "Resuma o caminho: TLC → média → MQO → normalidade assintótica.",
                                    "Crie um fluxograma conectando teorema, condições e aplicações.",
                                    "Resolva problemas: prove para regressão simples, discuta para IV.",
                                    "Ensine a um par: explique em 5 minutos sem notas.",
                                    "Autoavalie com quiz sobre distribuições assintóticas."
                                  ],
                                  "verification": "Explique o teorema completo para um colega ou grave um vídeo de 3 minutos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Quiz online (ex: custom no Google Forms), gravador de tela.",
                                  "tips": "Use analogias como 'média de lançamentos de moedas se torna normal com muitos lançamentos'.",
                                  "learningObjective": "Integrar conhecimento para explicação fluida e precisa.",
                                  "commonMistakes": "Omitir condições de momentos; confundir assintótico com finito."
                                }
                              ],
                              "practicalExample": "Em uma análise de salários (dataset Wage), ajuste MQO de log(wage) ~ education + experience com n=3000. Plote √n(β̂ - β_true) padronizado: deve se aproximar de N(0,I) por TLC, permitindo ICs 95% precisos mesmo com erros não normais.",
                              "finalVerifications": [
                                "Enuncie precisamente o TLC para médias amostrais e MQO.",
                                "Derive a distribuição assintótica de β̂_MQO em 3 passos.",
                                "Identifique 3 condições de momentos finitos necessárias.",
                                "Simule e plote convergência para uma regressão simples.",
                                "Explique por que testes t são válidos para n grande.",
                                "Discuta uma violação e correção (ex: robust SE)."
                              ],
                              "assessmentCriteria": [
                                "Precisão no enunciado do TLC e derivação (30%)",
                                "Correta identificação de condições e implicações (25%)",
                                "Qualidade de simulações/exemplos práticos (20%)",
                                "Clareza na explicação oral/escrita (15%)",
                                "Conexões com inferência assintótica (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: convergência de medidas e funções geradoras.",
                                "Econometria: inferência em modelos lineares e IV.",
                                "Machine Learning: assintóticas em gradiente descendente.",
                                "Computação Científica: simulações Monte Carlo para validação.",
                                "Estatística Bayesiana: aproximações assintóticas de posteriors."
                              ],
                              "realWorldApplication": "Em finanças, usa-se TLC para ICs de retornos médios em portfólios grandes; em A/B tests de tech, valida significância de diferenças de médias com n>>100 sob erros heterocedásticos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.2.2",
                            "name": "Derivar a distribuição assintótica do MQO",
                            "description": "Derivar a forma √n(β̂ - β) → N(0, σ² (X'X/n)^{-1}) para os estimadores de MQO em regressão linear com grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Estimador MQO e Pressupostos Assintóticos Básicos",
                                  "subSteps": [
                                    "Recordar a definição do estimador β̂ = (X'X)^{-1} X'y em regressão linear simples.",
                                    "Listar os pressupostos padrão para consistência assintótica: exogeneidade condicional estrita (CER), homocedasticidade condicional, e i.i.d. das observações.",
                                    "Introduzir notação assintótica: plim (X'X/n) = Q finita e positiva definida.",
                                    "Verificar que E(ε|X) = 0 e Var(ε|X) = σ² I sob CER.",
                                    "Discutir Lei dos Grandes Números (LLN) para médias amostrais convergirem para expectativas."
                                  ],
                                  "verification": "Escrever os pressupostos CER e confirmar que plim (X'X/n) = Q com prova esboçada usando LLN.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de Econometria (ex: Wooldridge), notas de aula sobre regressão linear, calculadora simbólica (SymPy ou Mathematica).",
                                  "tips": "Use matrizes em notação maiúscula para dados e minúscula para limites populacionais para evitar confusão.",
                                  "learningObjective": "Compreender os fundamentos que garantem consistência de β̂ para derivar normalidade assintótica.",
                                  "commonMistakes": "Confundir homocedasticidade com esfericidade; ignorar que CER é mais fraco que exogeneidade estrita."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estabelecer Consistência Assintótica de β̂",
                                  "subSteps": [
                                    "Derivar β̂ - β = (X'X/n)^{-1} (X'ε / n) multiplicando por n/n.",
                                    "Aplicar LLN: plim (X'X/n) = Q e plim (X'ε / n) = 0 por CER.",
                                    "Concluir plim β̂ = β usando continuidade de inversa de matriz.",
                                    "Verificar que √n(β̂ - β) = [ (X'X/n)^{-1} ] (X'ε / √n ), onde o primeiro termo converge para Q^{-1}.",
                                    "Discutir ordem de magnitude: β̂ - β é O_p(1/√n)."
                                  ],
                                  "verification": "Provar formalmente plim β̂ = β e esboçar a representação √n(β̂ - β).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Papel e lápis para derivações matriciais, software R ou Python para simular consistência com n grande.",
                                  "tips": "Desenhe diagramas de blocos para X'X/n e X'ε/n para visualizar convergência.",
                                  "learningObjective": "Dominar a prova de consistência como pré-requisito para CLT.",
                                  "commonMistakes": "Esquecer de normalizar por n no termo de erro; assumir i.i.d. sem CER."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Teorema do Limite Central (CLT) ao Termo de Erro",
                                  "subSteps": [
                                    "Identificar X'ε / √n como soma de termos independentes: (1/√n) Σ x_i ε_i.",
                                    "Verificar condições Lindeberg ou Lyapounov para CLT matricial: cada x_i ε_i tem covariância finita.",
                                    "Concluir que X'ε / √n →_d N(0, σ² Q) onde Q = plim (X'X/n).",
                                    "Justificar independência condicional sob CER para aplicação de CLT.",
                                    "Esboçar a densidade normal multivariada resultante."
                                  ],
                                  "verification": "Derivar a covariância assintótica de X'ε / √n explicitamente como σ² plim(X'X/n).",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Referência sobre CLT matricial (ex: Davidson's Econometric Theory), simulador Monte Carlo em Python (numpy.random).",
                                  "tips": "Simule em código para visualizar a normalidade emergente com n=1000+.",
                                  "learningObjective": "Aplicar CLT em contexto matricial para capturar variância assintótica.",
                                  "commonMistakes": "Negligenciar normalização √n no CLT; confundir Var(x_i ε_i) com σ² sem E(x_i x_i')."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Derivar a Distribuição Assintótica Final de √n(β̂ - β)",
                                  "subSteps": [
                                    "Substituir no Slutsky's Theorem: √n(β̂ - β) = Q_n^{-1} * Z_n onde Q_n →_p Q^{-1}, Z_n →_d N(0, σ² Q).",
                                    "Concluir √n(β̂ - β) →_d N(0, σ² Q^{-1}).",
                                    "Verificar para caso univariado: regressão simples Y = β0 + β1 X + ε.",
                                    "Discutir implicações para testes t e F assintóticos.",
                                    "Generalizar para heterocedasticidade robusta (sandwich variance)."
                                  ],
                                  "verification": "Escrever a expressão final √n(β̂ - β) → N(0, σ² (X'X/n)^{-1}) e provar usando Slutsky.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Exemplos numéricos em Excel ou Jupyter Notebook, artigo seminal de OLS asymptotics.",
                                  "tips": "Use teorema de Slutsky passo a passo: produto de convergência em probabilidade e distribuição.",
                                  "learningObjective": "Sintetizar todos os passos em uma derivação completa e verificável.",
                                  "commonMistakes": "Esquecer inversa em Q^{-1}; inverter a matriz de variância."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar e Aplicar a Derivação em Contextos Práticos",
                                  "subSteps": [
                                    "Simular dados com n=10000 e plotar histograma de √n(β̂ - β).",
                                    "Calcular variância amostral estimada e comparar com teórica.",
                                    "Testar robustez violando um pressuposto (ex: heterocedasticidade).",
                                    "Derivar para modelo com intercepto e múltiplas variáveis.",
                                    "Documentar a prova completa em LaTeX ou Markdown."
                                  ],
                                  "verification": "Simulação reproduz N(0, σ² (X'X/n)^{-1}) com QQ-plot próximo à reta.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Python (statsmodels, matplotlib), dados sintéticos gerados por seed fixo.",
                                  "tips": "Use n grande para convergência rápida; compare com bootstrap para validação.",
                                  "learningObjective": "Consolidar a teoria através de simulação e extensão.",
                                  "commonMistakes": "Escala errada no plot (esquecer √n); ignorar normalização de X."
                                }
                              ],
                              "practicalExample": "Em uma regressão linear simples Y_i = β X_i + ε_i com X_i ~ N(1,1), ε_i ~ N(0,1) i.i.d., n=10000. Compute β̂, então √n(β̂ - β) deve ser aproximadamente N(0, σ² / Var(X)), verificável por histograma e teste de Shapiro-Wilk.",
                              "finalVerifications": [
                                "Prova completa de plim β̂ = β usando LLN.",
                                "Aplicação correta de CLT matricial a X'ε/√n.",
                                "Uso de Slutsky para multiplicar Q_n^{-1} e Z_n.",
                                "Expressão final exata: √n(β̂ - β) →_d N(0, σ² (plim X'X/n)^{-1}).",
                                "Simulação numérica confirma distribuição normal.",
                                "Generalização para k regressores mantida."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de consistência (20%).",
                                "Correta aplicação de CLT e Slutsky (30%).",
                                "Expressão da matriz de variância assintótica (20%).",
                                "Simulação e visualização convincentes (15%).",
                                "Clareza na prova escrita e tratamento de edge cases (15%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teoremas LLN e CLT em probabilidade avançada.",
                                "Econometria: Inferência assintótica em modelos lineares.",
                                "Machine Learning: Análise de variância em gradiente descendente.",
                                "Matemática Computacional: Simulações Monte Carlo para validação.",
                                "Análise de Dados: Intervalos de confiança assintóticos em pacotes como statsmodels."
                              ],
                              "realWorldApplication": "Em econometria, essa distribuição justifica testes de hipóteses e intervalos de confiança em grandes datasets, como previsão de PIB com dados macroeconômicos (n>1000), permitindo inferências confiáveis sobre coeficientes de regressão em políticas públicas ou finanças."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.2.3",
                            "name": "Aplicar normalidade em testes de inferência",
                            "description": "Utilizar a normalidade assintótica para construir intervalos de confiança e testes de hipóteses t e F em contextos de engenharia com dados observacionais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os fundamentos da normalidade assintótica",
                                  "subSteps": [
                                    "Revise o Teorema Central do Limite (TCL) e sua extensão para estimadores assintóticos.",
                                    "Estude a distribuição assintótica N(0, I^{-1}(θ)) para máxima verossimilhança.",
                                    "Identifique condições para normalidade: amostras grandes (n > 30), independência, identicamente distribuídas (IID).",
                                    "Analise exemplos de estimadores consistentes e assintoticamente normais em dados observacionais.",
                                    "Pratique derivando a variância assintótica de um estimador simples, como a média amostral."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito as condições e derive a normalidade para um estimador dado.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro de Estatística Assintótica (ex: Van der Vaart)",
                                    "Notas de aula sobre TCL",
                                    "Software R ou Python com pacotes statsmodels"
                                  ],
                                  "tips": "Sempre verifique n > 30 e plote histogramas para validar aproximação normal.",
                                  "learningObjective": "Dominar as bases teóricas da normalidade assintótica para estimadores em inferência.",
                                  "commonMistakes": [
                                    "Ignorar violações de IID em dados observacionais",
                                    "Confundir normalidade exata com assintótica",
                                    "Não escalar variâncias corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir intervalos de confiança usando normalidade assintótica",
                                  "subSteps": [
                                    "Calcule o estimador pontual θ̂ e sua variância assintótica Var(θ̂).",
                                    "Padronize para Z = √n (θ̂ - θ) / √Var(θ̂) ~ N(0,1) assintoticamente.",
                                    "Determine o intervalo IC = θ̂ ± z_{α/2} * √(Var(θ̂)/n).",
                                    "Aplique em dados reais: importe dataset, compute IC para média ou proporção.",
                                    "Valide com simulações Monte Carlo para cobertura assintótica.",
                                    "Interprete o IC no contexto de engenharia (ex: tolerâncias de materiais)."
                                  ],
                                  "verification": "Gere um IC correto para um dataset dado e confirme cobertura >95% em simulações.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dataset de engenharia (ex: resistência de materiais CSV)",
                                    "Python (scipy.stats, numpy)",
                                    "R (base stats)"
                                  ],
                                  "tips": "Use bootstrap para comparar com aproximação normal em n moderado.",
                                  "learningObjective": "Construir e interpretar ICs assintóticos precisos para parâmetros em dados observacionais.",
                                  "commonMistakes": [
                                    "Esquecer o fator √n na padronização",
                                    "Usar t-student em vez de normal para n grande",
                                    "Ignorar estimativa de variância via hessiana"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar testes de hipóteses t utilizando normalidade assintótica",
                                  "subSteps": [
                                    "Defina H0: θ = θ0 vs Ha, compute estatística t = √n (θ̂ - θ0) / √Var(θ̂).",
                                    "Determine p-valor ou região crítica sob N(0,1) assintótica.",
                                    "Implemente em software: teste unilateral/bilateral para média em dados de engenharia.",
                                    "Controle erro tipo I com simulações para validar assintótica.",
                                    "Interprete resultados: rejeição e implicações práticas (ex: specs de processo).",
                                    "Ajuste para múltiplos testes se aplicável (Bonferroni)."
                                  ],
                                  "verification": "Execute teste t em dataset, reporte p-valor <0.05 corretamente e justifique decisão.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dataset observacional de engenharia (ex: tempos de falha)",
                                    "Python (statsmodels.stats.weightstats)",
                                    "R (t.test)"
                                  ],
                                  "tips": "Sempre reporte tamanho de efeito (Cohen's d) além de p-valor.",
                                  "learningObjective": "Executar e interpretar testes t assintóticos com rigor estatístico.",
                                  "commonMistakes": [
                                    "Confundir teste z com t para variância desconhecida",
                                    "Não verificar normalidade via QQ-plot",
                                    "Interpretar p-valor como probabilidade de H0"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Executar testes F baseados em normalidade assintótica",
                                  "subSteps": [
                                    "Revise teste F para razão de variâncias: F = s1² / s2² ~ F(df1,df2) assintoticamente.",
                                    "Estenda para testes em regressão/ANOVA com normalidade de resíduos.",
                                    "Compute estatística F = (θ̂ - θ0)' I(θ̂) (θ̂ - θ0) ~ χ²(k) para múltiplos parâmetros.",
                                    "Aplique em contexto de engenharia: teste homocedasticidade em processos.",
                                    "Implemente e valide com dados simulados sob H0/Ha.",
                                    "Discuta poder do teste e tamanho amostral necessário."
                                  ],
                                  "verification": "Realize teste F em dois datasets, rejeite H0 corretamente se F > crítico.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Datasets de variâncias em manufatura",
                                    "Python (scipy.stats.f)",
                                    "R (var.test, anova)"
                                  ],
                                  "tips": "Transforme dados se violação de normalidade (Box-Cox).",
                                  "learningObjective": "Aplicar testes F assintóticos para variâncias e modelos lineares.",
                                  "commonMistakes": [
                                    "Usar F exato sem n grande",
                                    "Inverter num/denom em F-test",
                                    "Ignorar dependência em dados observacionais"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integrar aplicações em contextos de engenharia com dados observacionais",
                                  "subSteps": [
                                    "Selecione dataset real de engenharia (ex: controle de qualidade).",
                                    "Execute pipeline completo: IC, teste t e F sequencialmente.",
                                    "Avalie robustez: sensibilidade a outliers e n.",
                                    "Gere relatório com interpretações e recomendações.",
                                    "Compare com métodos não-paramétricos para validação.",
                                    "Discuta limitações da assintótica em engenharia prática."
                                  ],
                                  "verification": "Produza relatório completo com resultados corretos e insights acionáveis.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Dataset real (ex: UCI ML repo - concrete strength)",
                                    "Jupyter Notebook",
                                    "Relatório template LaTeX/Markdown"
                                  ],
                                  "tips": "Automatize com funções reutilizáveis em Python/R.",
                                  "learningObjective": "Sintetizar normalidade assintótica em análises integradas de engenharia.",
                                  "commonMistakes": [
                                    "Sobre-generalizar resultados sem contexto domínio",
                                    "Não reportar CIs para decisões",
                                    "Esquecer validação cruzada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia mecânica, analise dados observacionais de 100 testes de fadiga em vigas de aço: construa IC para média de ciclos até falha usando normalidade da média amostral; teste H0: μ=10^5 vs Ha: μ>10^5 com t-test; teste homocedasticidade vs outro material com F-test para garantir specs de design.",
                              "finalVerifications": [
                                "Deriva corretamente IC e testes para estimador dado.",
                                "Valida aproximação normal com QQ-plots e simulações.",
                                "Interpreta p-valores e CIs com contexto de engenharia.",
                                "Identifica e corrige violações assintóticas.",
                                "Integra resultados em relatório profissional.",
                                "Compara com alternativas (bootstrap, exato)."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos (erro <1%).",
                                "Correta aplicação de condições assintóticas.",
                                "Interpretação contextualizada e sem erros tipo I/II.",
                                "Uso eficiente de software com código limpo.",
                                "Relatório claro com visualizações (plots, tabelas).",
                                "Criatividade em extensões reais."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: TCL e distribuições limite.",
                                "Programação: Implementação em Python/R para automação.",
                                "Engenharia Mecânica: Análise de confiabilidade e fadiga.",
                                "Machine Learning: Assintóticas em validação de modelos.",
                                "Física: Modelagem de ruído em experimentos."
                              ],
                              "realWorldApplication": "Em manufatura, use para validar processos de produção: IC para média de defeitos garante qualidade; testes t/F detectam desvios em variância, otimizando manutenção preditiva e reduzindo custos em indústrias como automotiva e aeroespacial."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.3.5.3",
                        "name": "Eficiência Assintótica",
                        "description": "Medida de performance ótima de estimadores em termos de variância mínima assintótica, comparando MQO, Maximização de Verossimilhança (ML) e Métodos Generalizados dos Momentos (GMM).",
                        "specificSkills": [
                          {
                            "id": "10.1.3.5.3.1",
                            "name": "Definir eficiência assintótica",
                            "description": "Explicar o conceito de variância assintótica mínima e o estimador eficiente como aquele que atinge o limite de Cramér-Rao assintótico.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Propriedades Assintóticas Básicas de Estimadores",
                                  "subSteps": [
                                    "Defina consistência assintótica: um estimador é consistente se converge em probabilidade para o verdadeiro parâmetro à medida que n → ∞.",
                                    "Explique normalidade assintótica: distribuição assintótica normal do estimador √n(θ̂ - θ) ~ N(0, I(θ)^{-1}).",
                                    "Discuta variância assintótica: Var(√n(θ̂ - θ)) → σ², onde σ² é a variância limite.",
                                    "Identifique a matriz de informação de Fisher I(θ) como base para limites de variância.",
                                    "Compare estimadores com diferentes taxas de convergência assintótica."
                                  ],
                                  "verification": "Resuma em 3 frases os conceitos chave e forneça um exemplo simples de um estimador consistente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro 'Asymptotic Statistics' de van der Vaart (cap. 2); vídeo Khan Academy sobre convergência em probabilidade.",
                                  "tips": "Use notação matemática precisa: destaque √n para normalidade assintótica.",
                                  "learningObjective": "Compreender as bases assintóticas necessárias para eficiência.",
                                  "commonMistakes": "Confundir consistência com normalidade; ignorar a dependência em n."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Entender o Limite de Cramér-Rao Assintótico",
                                  "subSteps": [
                                    "Recapitule o limite de Cramér-Rao finito-amostral: Var(θ̂) ≥ 1/(n I(θ)).",
                                    "Estenda para assintótico: variância assintótica mínima é 1/I(θ) para √n(θ̂ - θ).",
                                    "Derive informalmente o bound usando projeção em espaço de Hilbert de funções de observações.",
                                    "Discuta condições para atinigibilidade: regularidade, diferenciabilidade da densidade.",
                                    "Calcule I(θ) para distribuições comuns como Normal e Poisson."
                                  ],
                                  "verification": "Calcule o limite de Cramér-Rao assintótico para θ em Bernoulli(p=θ).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Notas de aula sobre teoria da informação de Fisher; software R para simular I(θ).",
                                  "tips": "Lembre-se: CRLB assintótico é local em θ, não global.",
                                  "learningObjective": "Dominar o bound inferior para variância assintótica.",
                                  "commonMistakes": "Esquecer o fator √n na normalização; aplicar CRLB finito sem ajustes assintóticos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir Variância Assintótica Mínima e Estimador Eficiente",
                                  "subSteps": [
                                    "Defina variância assintótica mínima: aquela igual ao limite de Cramér-Rao assintótico.",
                                    "Classifique estimador eficiente: atinge Var_as(√n(θ̂ - θ)) = 1/I(θ).",
                                    "Explique super-eficiência e casos raros onde é possível temporariamente.",
                                    "Diferencie eficiência local vs. global; foque em eficiência assintótica local.",
                                    "Forneça teorema: sob regularidade, MLE é assintoticamente eficiente."
                                  ],
                                  "verification": "Escreva a definição formal de eficiência assintótica e identifique um exemplo de MLE eficiente.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Artigo 'Cramér-Rao Lower Bound' no Wikipedia; slides de curso de econometria avançada.",
                                  "tips": "Use diagrama: variância vs. bound para visualizar eficiência.",
                                  "learningObjective": "Definir precisamente eficiência assintótica e seus estimadores.",
                                  "commonMistakes": "Confundir eficiência com menor variância finita; ignorar assintótico."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Conceitos em Exemplos e Verificações",
                                  "subSteps": [
                                    "Analise MLE para Normal(μ,σ²): verifique eficiência para μ.",
                                    "Considere método dos momentos vs. MLE: compare variâncias assintóticas.",
                                    "Simule numericamente: gere dados e plote distribuições normalizadas.",
                                    "Discuta estimadores não-eficientes: razão para ineficiência.",
                                    "Conclua com teorema de eficiência assintótica do MLE."
                                  ],
                                  "verification": "Simule em Python/R e confirme que variância empírica aproxima 1/I(θ).",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Python com NumPy/SciPy; Jupyter notebook template para simulações assintóticas.",
                                  "tips": "Aumente n para 10^5+ para observar comportamento assintótico.",
                                  "learningObjective": "Aplicar definições para validar eficiência em prática.",
                                  "commonMistakes": "Amostras pequenas distorcem resultados; não normalizar por √n."
                                }
                              ],
                              "practicalExample": "Para estimar a média μ de uma Normal(μ,1) com n amostras, o MLE θ̂ = X̄ tem √n(X̄ - μ) ~ N(0,1) assintoticamente, atingindo CRLB 1/I(μ)=1, logo é eficiente. Simule: gere 1000 datasets de n=1000, plote histogramas normalizados – deve convergir para N(0,1).",
                              "finalVerifications": [
                                "Defina eficiência assintótica em termos de variância e CRLB.",
                                "Calcule I(θ) e bound para Exponential(θ).",
                                "Identifique por que MLE é geralmente eficiente.",
                                "Diferencie eficiência assintótica de finita.",
                                "Explique condições de regularidade para teorema de eficiência.",
                                "Forneça contraexemplo de estimador consistente mas ineficiente."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição: menciona variância mínima e CRLB assintótico (peso 25%).",
                                "Compreensão matemática: derivações corretas de bounds (25%).",
                                "Exemplos apropriados: inclui MLE e simulações (20%).",
                                "Distinções claras: assintótico vs. finito, eficiente vs. não (15%).",
                                "Aplicação prática: relaciona a seleção de estimadores (10%).",
                                "Clareza e estrutura: explicação lógica sem erros (5%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: base para testes de hipóteses assintóticos.",
                                "Machine Learning: eficiência em perda de log-verossimilhança para gradiente descendente.",
                                "Econometria: seleção de modelos IV vs. OLS eficientes.",
                                "Probabilidade Avançada: teoremas de grandes desvios e eficiência.",
                                "Computação Científica: otimização numérica de MLE."
                              ],
                              "realWorldApplication": "Em finanças quantitativas, estimadores eficientes como MLE para parâmetros de volatilidade em modelos GARCH minimizam erros em Value-at-Risk, melhorando previsões de risco e alocação de portfólios em bancos como JPMorgan."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.3.2",
                            "name": "Comparar eficiência de MQO e ML",
                            "description": "Analisar quando o MQO é assintoticamente eficiente (homocedasticidade) e quando o ML ou GMM superam em eficiência sob pressupostos relaxados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Propriedades Assintóticas de MQO e ML",
                                  "subSteps": [
                                    "Defina convergência assintótica, consistência e eficiência para estimadores.",
                                    "Revise a matriz de informação de Fisher para ML e sua relação com variância assintótica.",
                                    "Compare as condições assintóticas padrão para MQO (linearidade, exogeneidade, homocedasticidade).",
                                    "Estude fórmulas de variância assintótica: MQO vs. ML sob normalidade.",
                                    "Identifique equivalência MQO-ML em regressão linear gaussiana."
                                  ],
                                  "verification": "Resuma em um quadro comparativo as fórmulas de variância assintótica de MQO e ML.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro 'Econometric Analysis' de Greene (cap. 5); notebook Jupyter com Python (statsmodels).",
                                  "tips": "Use diagramas de Venn para visualizar sobreposições de suposições.",
                                  "learningObjective": "Compreender as bases teóricas de eficiência assintótica para estimadores MQO e ML.",
                                  "commonMistakes": "Confundir consistência com eficiência; ignorar normalidade para equivalência MQO-ML."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Eficiência do MQO sob Homocedasticidade",
                                  "subSteps": [
                                    "Simule dados com erros homocedásticos e normais; estime MQO e calcule variância.",
                                    "Prove que MQO atinge o limite de Cramér-Rao sob homocedasticidade e normalidade.",
                                    "Calcule a matriz de covariância assintótica do MQO: (X'X/n)^{-1} σ².",
                                    "Compare com ML: verifique eficiência BLUE (Best Linear Unbiased Estimator).",
                                    "Teste numericamente com simulações Monte Carlo para variâncias empíricas."
                                  ],
                                  "verification": "Gere gráfico de variâncias simuladas mostrando MQO eficiente (variância próxima ao limite).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (numpy, scipy, matplotlib); código de simulação de regressão linear.",
                                  "tips": "Use n=1000+ para boa aproximação assintótica; replique 1000 vezes.",
                                  "learningObjective": "Demonstrar quando MQO é assintoticamente eficiente.",
                                  "commonMistakes": "Usar amostras pequenas, levando a viés em variâncias; esquecer de normalizar por n."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Superioridade de ML e GMM sob Pressupostos Relaxados",
                                  "subSteps": [
                                    "Introduza heterocedasticidade: simule erros com Var(ε|X) = σ² x_i²; estime MQO e ML.",
                                    "Implemente ML para regressão com erros heteroscedásticos (e.g., GLM).",
                                    "Discuta GMM: momentos populacionais e eficiência em misspecification.",
                                    "Compare variâncias assintóticas: ML/GMM menores que MQO em heterocedasticidade/não-normalidade.",
                                    "Analise casos como erros t-Student ou AR(1) para violações."
                                  ],
                                  "verification": "Tabela comparativa de MSE médio de estimadores em 500 simulações com heterocedasticidade.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "R (sandwich package para erros robustos); Python (sklearn para GLM).",
                                  "tips": "Comece com heterocedasticidade simples multiplicativa; valide com testes de White.",
                                  "learningObjective": "Identificar cenários onde ML/GMM superam MQO em eficiência.",
                                  "commonMistakes": "Assumir normalidade em ML sem especificar distribuição; ignorar identificação em GMM."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Síntese Comparativa e Aplicação Prática",
                                  "subSteps": [
                                    "Crie fluxograma de decisão: MQO se homocedástico/normal; ML/GMM caso contrário.",
                                    "Aplique a dados reais (e.g., Boston Housing) com testes de homocedasticidade (Breusch-Pagan).",
                                    "Estime modelos alternativos e compare variâncias de erros padrão.",
                                    "Discuta trade-offs: robustez vs. eficiência; custo computacional.",
                                    "Documente conclusões em relatório com gráficos de densidades de estimadores."
                                  ],
                                  "verification": "Relatório de 1 página com fluxograma e resultados empíricos comparativos.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Dataset Boston Housing (sklearn); software estatístico (Stata/R/Python).",
                                  "tips": "Sempre reporte erros padrão robustos para MQO como benchmark.",
                                  "learningObjective": "Sintetizar critérios para seleção baseada em eficiência assintótica.",
                                  "commonMistakes": "Overfitting em ML sem validação; negligenciar suposições não testadas."
                                }
                              ],
                              "practicalExample": "Em uma regressão de salários sobre educação e experiência com dados do CPS: sob homocedasticidade (testes ok), MQO é eficiente; com heterocedasticidade detectada, ML com erros gamma reduz variância assintótica em 15-20% em simulações.",
                              "finalVerifications": [
                                "Fluxograma de decisão correto para escolha de estimador.",
                                "Simulações Monte Carlo com MSE de ML/GMM < MQO em heterocedasticidade.",
                                "Quadro comparativo de variâncias assintóticas derivadas.",
                                "Análise de dataset real com testes e comparação de erros padrão.",
                                "Relatório resumindo condições de eficiência para cada método.",
                                "Gráficos de densidades empíricas de estimadores convergindo ao limite."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de variâncias assintóticas (80%+ correto).",
                                "Qualidade das simulações (n>500, visualizações claras).",
                                "Correta identificação de violações de suposições (testes apropriados).",
                                "Profundidade da comparação quantitativa (tabelas/gráficos).",
                                "Clareza do fluxograma de decisão e trade-offs discutidos.",
                                "Aplicação coerente a dados reais sem erros conceituais."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Testes de especificação (White, Hausman).",
                                "Estatística: Teoria de informação de Fisher e limites de Cramér-Rao.",
                                "Programação: Simulações Monte Carlo em Python/R.",
                                "Matemática Aplicada: Álgebra linear para matrizes de covariância."
                              ],
                              "realWorldApplication": "Em finanças quantitativas, escolher ML sobre MQO em modelos de risco com volatilidade condicional (GARCH) para previsões mais eficientes em portfólios, reduzindo variância de estimativas de beta em 10-25% sob heterocedasticidade de retornos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.3.5.3.3",
                            "name": "Calcular matriz de variância assintótica",
                            "description": "Computar a matriz de covariância assintótica para estimadores de MQO e GMM em exemplos de regressão linear aplicados a dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar fórmulas teóricas de variância assintótica para MQO e GMM",
                                  "subSteps": [
                                    "Estude a fórmula assintótica para MQO: Var(β̂) → (plim (X'X/n))^{-1} σ²",
                                    "Revise a fórmula para GMM: Var(θ̂) → (G' W G)^{-1} (G' W V W G) (G' W G)^{-1}, onde G é a derivada dos momentos, V é a covariância dos momentos",
                                    "Identifique diferenças chave: MQO é caso especial de GMM com W=I e momentos lineares",
                                    "Anote condições de regularidade: ergodicidade, identifiabilidade, momentos finitos",
                                    "Derive explicitamente para regressão linear simples Y = Xβ + ε"
                                  ],
                                  "verification": "Resuma as fórmulas em um documento e verifique se derivam corretamente para um modelo linear conhecido",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de texto de Econometria (ex: Wooldridge)",
                                    "Notas de aula sobre propriedades assintóticas",
                                    "Calculadora simbólica como SymPy"
                                  ],
                                  "tips": "Use notação matricial consistente para evitar confusões entre escalares e vetores",
                                  "learningObjective": "Compreender as bases teóricas das matrizes de variância assintótica para estimadores MQO e GMM",
                                  "commonMistakes": "Confundir variância finita-amostral com assintótica; ignorar plim (probabilistic limit)"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar conjunto de dados de engenharia e configurar modelo de regressão",
                                  "subSteps": [
                                    "Carregue dados reais/simulados de engenharia, ex: tensão (Y) vs temperatura (X1) e carga (X2)",
                                    "Verifique e limpe dados: remova missing values, normalize se necessário, confira dimensionalidade",
                                    "Defina o modelo linear: Y = β0 + β1 X1 + β2 X2 + ε",
                                    "Estime parâmetros iniciais via MQO para benchmark",
                                    "Calcule estatísticas descritivas: média, variância de X e resíduos"
                                  ],
                                  "verification": "Confirme que X tem posto completo (det(X'X) ≠ 0) e resíduos têm média zero",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com NumPy, Pandas, StatsModels",
                                    "Dataset de engenharia (ex: de UCI ML Repository)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use seed para reproducibilidade em simulações; armazene X como matriz n x k",
                                  "learningObjective": "Preparar dados adequados para análise assintótica em contexto de engenharia",
                                  "commonMistakes": "Incluir variáveis colineares; não centralizar dados quando necessário"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar matriz de covariância assintótica para estimador MQO",
                                  "subSteps": [
                                    "Calcule Sxx = (1/n) X'X",
                                    "Estime σ² = (1/(n-k)) ê'ê, onde ê são resíduos MQO",
                                    "Inverta Sxx para obter (plim Sxx)^{-1}",
                                    "Multiplique: V_MQO = (Sxx)^{-1} σ²",
                                    "Ajuste para hetero ou autocorrelação se dados de engenharia indicarem (ex: Newey-West)"
                                  ],
                                  "verification": "Verifique se diagonal de V_MQO é positiva e matriz é simétrica positiva definida",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código Python: np.linalg.inv, statsmodels.stats.sandwich_covariance",
                                    "Notebook anterior"
                                  ],
                                  "tips": "Use np.dot para multiplicações matriciais eficientes; teste com n grande (~1000) para aproximação assintótica",
                                  "learningObjective": "Implementar cálculo numérico da variância assintótica MQO em regressão linear",
                                  "commonMistakes": "Usar variância amostral exata em vez de assintótica; dividir por n ao invés de (n-k)"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Computar matriz de covariância assintótica para estimador GMM",
                                  "subSteps": [
                                    "Defina função de momentos: g(θ) = (1/n) ∑ [Z_i (Y_i - X_i θ)], onde Z são instrumentos",
                                    "Calcule G = plim ∂g/∂θ' = - (1/n) Z'X",
                                    "Estime V = covariância assintótica de √n g(θ̂_MQO)",
                                    "Escolha W ótima: W = V^{-1}",
                                    "Calcule V_GMM = (G' W G)^{-1}",
                                    "Compare com V_MQO para eficiência"
                                  ],
                                  "verification": "Confirme que V_GMM ≤ V_MQO elemento a elemento (GMM mais eficiente se instrumentos válidos)",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "StatsModels GMM module ou código custom NumPy/SciPy",
                                    "Instrumentos Z: lags ou exógenos"
                                  ],
                                  "tips": "Comece com MQO como GMM com Z=X e W=I para validar código",
                                  "learningObjective": "Aplicar framework GMM para variância assintótica em dados com possível endogeneidade",
                                  "commonMistakes": "Escolher instrumentos inválidos; não iterar W para two-step GMM"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar, validar e comparar matrizes computadas",
                                  "subSteps": [
                                    "Extraia variâncias e covariâncias marginais das diagonais e off-diagonais",
                                    "Calcule erros-padrão assintóticos: sqrt(diag(V)) / sqrt(n)",
                                    "Teste hipóteses: intervalos de confiança assintóticos",
                                    "Compare MQO vs GMM: ratios de eficiência",
                                    "Valide com bootstrap para checar aproximação assintótica"
                                  ],
                                  "verification": "Intervalos de confiança contêm valores verdadeiros em simulações Monte Carlo",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "SciPy stats para bootstrap",
                                    "Gráficos Matplotlib para visualização de matrizes"
                                  ],
                                  "tips": "Plote heatmap das matrizes para inspeção visual de correlações",
                                  "learningObjective": "Interpretar implicações práticas das matrizes de variância em engenharia",
                                  "commonMistakes": "Ignorar escala de n na variância (divide por sqrt(n)); superestimar precisão com n pequeno"
                                }
                              ],
                              "practicalExample": "Em um dataset de testes de fadiga em vigas de aço (Y: ciclos até falha, X1: tensão máxima, X2: frequência), calcule V_MQO e V_GMM usando Z = [1, X1_lag, X2] como instrumentos para lidar com endogeneidade na frequência. Resultado: GMM mostra β2 mais preciso (var reduzida 20%).",
                              "finalVerifications": [
                                "Matrizes V são simétricas e positivas definidas",
                                "Variâncias diagonais decrescem com 1/n",
                                "GMM eficiente sobre MQO quando instrumentos válidos",
                                "Cálculos coincidem com StatsModels output",
                                "Bootstrap CI sobrepõe estimativas assintóticas",
                                "Resíduos uncorrelacionados com instrumentos"
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica: erro < 1e-6 vs analítico",
                                "Correta implementação de fórmulas MQO/GMM",
                                "Validação com testes estatísticos apropriados",
                                "Interpretação clara de eficiência e implicações",
                                "Código limpo, comentado e reproduzível",
                                "Tratamento de casos edge (ex: singularidade)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência assintótica e teoremas do limite central",
                                "Programação: Otimização numérica e álgebra linear computacional",
                                "Engenharia: Modelagem preditiva em materiais e estruturas",
                                "Economia: Análise de eficiência em métodos de estimação"
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, calcular variância assintótica GMM otimiza estimadores de parâmetros de fadiga sob endogeneidade (ex: carga medida com erro), permitindo previsões mais confiáveis para certificação de segurança de aeronaves."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.4",
                "name": "Regressão em Grandes Amostras e Pressupostos Relaxados",
                "description": "Explora regressão linear em grandes amostras e com pressupostos relaxados para cenários mais realistas.",
                "totalSkills": 47,
                "atomicTopics": [
                  {
                    "id": "10.1.4.1",
                    "name": "Propriedades Assintóticas dos Estimadores OLS",
                    "description": "Consistência, normalidade assintótica e eficiência em grandes amostras para estimadores de mínimos quadrados ordinários.",
                    "individualConcepts": [
                      {
                        "id": "11.3.1.1",
                        "name": "Consistência Assintótica dos Estimadores OLS",
                        "description": "Conceito que define a convergência em probabilidade dos estimadores de mínimos quadrados ordinários (OLS) para os verdadeiros parâmetros à medida que o tamanho da amostra tende ao infinito, sob pressupostos relaxados como heterocedasticidade e ausência de normalidade.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.1.1",
                            "name": "Definir consistência assintótica",
                            "description": "Explicar a definição formal de consistência assintótica para os estimadores β̂_OLS, incluindo plim(β̂_OLS) = β, e identificar os pressupostos mínimos necessários (ex.: exogeneidade estrita e não-correlacionada dos erros).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de convergência em probabilidade",
                                  "subSteps": [
                                    "Definir formalmente convergência em probabilidade: uma sequência de variáveis aleatórias Z_n converge em probabilidade para uma constante c (plim Z_n = c) se, para todo ε > 0, P(|Z_n - c| > ε) → 0 quando n → ∞.",
                                    "Diferenciar convergência em probabilidade de outros tipos de convergência, como quase certa, em média quadrática e em distribuição.",
                                    "Explorar exemplos simples, como a média amostral de variáveis i.i.d. convergindo para a média populacional pela Lei dos Grandes Números (LLN).",
                                    "Discutir a importância da convergência em probabilidade na teoria assintótica de estimadores estatísticos.",
                                    "Visualizar o conceito com gráficos de distribuições aproximando uma constante à medida que n aumenta."
                                  ],
                                  "verification": "Escrever a definição formal de plim e resolver um exercício simples de LLN, confirmando que a probabilidade de desvio excede ε tende a zero.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Notas de probabilidade avançada",
                                    "Livro 'Probabilistic Techniques in Analysis' ou equivalente",
                                    "Software R/Python para simulações básicas"
                                  ],
                                  "tips": "Use simulações Monte Carlo para observar numericamente a convergência, variando n de 10 a 10.000.",
                                  "learningObjective": "Dominar a definição e intuição de convergência em probabilidade como base para propriedades assintóticas.",
                                  "commonMistakes": [
                                    "Confundir plim com E[Z_n] = c (vies nulo, mas não consistência)",
                                    "Ignorar que convergência em probabilidade não implica convergência quase certa"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir consistência assintótica de estimadores",
                                  "subSteps": [
                                    "Estabelecer que um estimador θ̂_n é consistente para o parâmetro verdadeiro θ se plim θ̂_n = θ à medida que n → ∞.",
                                    "Explicar por que o termo 'assintótica': a propriedade emerge apenas em amostras grandes, não necessariamente em amostras finitas.",
                                    "Discutir implicações: consistência garante que o erro de estimação tende a zero em probabilidade.",
                                    "Relacionar com vies e variância: consistência requer que vies + variância → 0, mas foco em plim.",
                                    "Revisar teoremas fundamentais como a LLN fraca que suporta consistência."
                                  ],
                                  "verification": "Reescrever a definição de consistência em termos de plim e aplicar a um estimador simples como a média amostral.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Apostila de econometria (ex: Wooldridge)",
                                    "Caderno para anotações formais"
                                  ],
                                  "tips": "Memorize a notação plim θ̂_n = θ como mantra; pratique com estimadores conhecidos consistentes.",
                                  "learningObjective": "Entender consistência como convergência em probabilidade do estimador para o verdadeiro parâmetro.",
                                  "commonMistakes": [
                                    "Achar que consistência implica eficiência ou normalidade assintótica",
                                    "Confundir com propriedade de amostras pequenas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estabelecer a consistência assintótica do estimador OLS",
                                  "subSteps": [
                                    "Recordar a fórmula do estimador OLS: β̂_OLS = (X'X/n)^{-1} (X'y / n), onde y = Xβ + u.",
                                    "Mostrar que plim (X'X/n) = Q = E[x_t x_t'], assumindo LLN e Q positiva definida.",
                                    "Derivar plim (X'y / n) = Q β, pois plim (X'u / n) = 0 sob exogeneidade.",
                                    "Concluir que plim β̂_OLS = Q^{-1} Q β = β, provando consistência.",
                                    "Esboçar a prova matricial passo a passo, destacando os limites em probabilidade."
                                  ],
                                  "verification": "Derivar algebricamente plim β̂_OLS = β em um modelo com uma regressora, verificando cada plim.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software para álgebra matricial (Mathematica ou Python com SymPy)",
                                    "Livro 'Introdução à Econometria' de Wooldridge, Capítulo 3"
                                  ],
                                  "tips": "Divida a prova em 'sanduíche': plim X'X/n, plim X'y/n, então multiplique; use notação populacional.",
                                  "learningObjective": "Provar formalmente a consistência do OLS usando limites em probabilidade.",
                                  "commonMistakes": [
                                    "Esquecer de dividir por n nas médias amostrais",
                                    "Assumir Q invertível sem justificar"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar os pressupostos mínimos para consistência OLS",
                                  "subSteps": [
                                    "Listar pressuposto chave 1: Exogeneidade estrita E[u_t | X] = 0, implicando E[x_t u_t] = 0.",
                                    "Pressuposto 2: Condições para LLN: variáveis x_t estacionárias/ergodicidade, momentos finitos E[||x_t||^2] < ∞ e E[|u_t|^2] < ∞.",
                                    "Pressuposto 3: plim X'X/n = Q positiva definida (não colinearidade assintótica).",
                                    "Discutir que homocedasticidade e normalidade não são necessárias para consistência (apenas para inferência finita).",
                                    "Exemplificar violações: endogeneidade faz plim X'u/n ≠ 0, quebrando consistência."
                                  ],
                                  "verification": "Listar e justificar os 3-4 pressupostos mínimos, identificando qual falha em um exemplo de endogeneidade.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Tabela de pressupostos OLS de um livro de referência",
                                    "Exemplos numéricos em R (pacote AER)"
                                  ],
                                  "tips": "Foquem em 'mínimos': exog + LLN; teste com simulações onde viola exog.",
                                  "learningObjective": "Reconhecer pressupostos essenciais e distinção de condições para variância assintótica.",
                                  "commonMistakes": [
                                    "Incluir homocedasticidade como necessária para consistência",
                                    "Ignorar ergodicidade para LLN"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere um modelo y_i = β_0 + β_1 x_i + u_i com β = [2, 3]', x_i ~ N(0,1), u_i ~ N(0,1) independente. Simule n=50, 500, 5000 observações em Python/R: compute β̂_OLS e observe |β̂ - β| → 0 em repetições, ilustrando plim β̂_OLS = β.",
                              "finalVerifications": [
                                "Escrever a definição formal de consistência assintótica para β̂_OLS.",
                                "Derivar plim β̂_OLS = β em 3 passos principais.",
                                "Listar e explicar os 3 pressupostos mínimos necessários.",
                                "Identificar por que exogeneidade estrita é crucial.",
                                "Simular um exemplo numérico mostrando convergência.",
                                "Diferenciar consistência de não-vies em amostras finitas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação plim e definição formal (exata).",
                                "Correção na derivação matricial da prova de consistência.",
                                "Identificação precisa dos pressupostos mínimos (sem extras desnecessários).",
                                "Clareza na distinção entre propriedades finitas e assintóticas.",
                                "Capacidade de aplicar em simulação prática.",
                                "Compreensão de violações comuns como endogeneidade."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Lei dos Grandes Números e convergência estocástica.",
                                "Econometria: Extensões para IV e GMM quando OLS inconsistente.",
                                "Machine Learning: Consistência em regressão linear como base para modelos em grandes dados.",
                                "Estatística Computacional: Simulações Monte Carlo para validar assintóticos."
                              ],
                              "realWorldApplication": "Em análise econômica com grandes datasets (ex: painéis de empresas), OLS é usado para estimar retornos ao capital assumindo consistência sob exogeneidade; falhas levam a políticas erradas, como em estudos de causalidade em saúde pública."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.2",
                            "name": "Provar consistência sob pressupostos relaxados",
                            "description": "Derivar a consistência dos estimadores OLS usando a lei dos grandes números, considerando matrizes de covariância não constantes e grandes amostras em contextos de engenharia econômica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Relaxados para Consistência OLS",
                                  "subSteps": [
                                    "Identifique os pressupostos clássicos OLS (linearidade, exogeneidade, sem autocorrelação perfeita, etc.) e destaque os relaxados: permitir heterocedasticidade (covariância não constante) e dependência fraca nas observações.",
                                    "Defina condições para Lei dos Grandes Números (LLN) fraca: ergodicidade, momentos finitos E[||X_i||^2] < ∞ e E[|X_i' ε_i|] < ∞.",
                                    "Escreva o modelo Y_i = X_i' β + ε_i, com E[ε_i | X_i] = 0, mas Var(ε_i | X_i) = σ_i^2 possivelmente variável.",
                                    "Verifique que não se requer homocedasticidade ou independência i.i.d. forte para consistência.",
                                    "Liste matrizes populacionais: Q = plim (1/n ∑ X_i X_i') = E[X_i X_i']"
                                  ],
                                  "verification": "Escreva uma lista dos 4-5 pressupostos relaxados e confirme que suportam LLN fraca.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de econometria (ex: Wooldridge), papel e caneta ou Jupyter Notebook para anotações.",
                                  "tips": "Comece pelos pressupostos mais fracos; memorize que consistência requer apenas convergência em probabilidade dos momentos.",
                                  "learningObjective": "Compreender como pressupostos relaxados permitem LLN em contextos de grandes amostras com covariância não constante.",
                                  "commonMistakes": "Confundir consistência (plim) com não-viés (E[β_hat]=β); assumir i.i.d. desnecessariamente."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Expressar o Estimador OLS e Decompor em Termos Assintóticos",
                                  "subSteps": [
                                    "Escreva β_hat = (X'X / n)^{-1} (X'y / n), onde X é matriz n x k.",
                                    "Decomponha X'y / n = (X'X / n) β + X'ε / n.",
                                    "Assim, β_hat - β = (X'X / n)^{-1} (X'ε / n).",
                                    "Identifique que para plim(β_hat - β) = 0, precisa plim(X'X / n) = Q (invertível) e plim(X'ε / n) = 0.",
                                    "Discuta por que Q é positivo definido sob pressupostos relaxados (ex: E[X_i X_i'] full rank)."
                                  ],
                                  "verification": "Derive algebricamente a decomposição β_hat - β e destaque os dois termos chave para LLN.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Matriz algebra software (ex: SymPy em Python), quadro branco ou LaTeX editor.",
                                  "tips": "Use notação matricial consistente; divida por n cedo para destacar médias amostrais.",
                                  "learningObjective": "Dominar a expressão matricial do OLS e sua decomposição para análise assintótica.",
                                  "commonMistakes": "Esquecer de dividir por n nos termos; inverter a ordem na decomposição."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Lei dos Grandes Números aos Momentos Amostrais",
                                  "subSteps": [
                                    "Aplique LLN fraca: plim(1/n ∑ X_i X_i') = E[X_i X_i'] = Q, assumindo ergodicidade.",
                                    "Para o termo de erro: plim(1/n ∑ X_i ε_i) = E[X_i ε_i] = 0, por exogeneidade E[ε_i | X_i]=0 e momentos finitos.",
                                    "Justifique LLN sob covariância não constante: LLN vale para variáveis martingale difference ou estacionárias ergódicas.",
                                    "Confirme invertibilidade: se Q full rank, então plim((X'X/n)^{-1}) = Q^{-1}.",
                                    "Combine: plim(β_hat) = Q^{-1} * Q β = β."
                                  ],
                                  "verification": "Escreva as 3 aplicações de plim() e prove que levam a plim(β_hat)=β.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Livro de teoria assintótica (ex: Newey & McFadden), simulador Monte Carlo básico em R/Python.",
                                  "tips": "Visualize com simulações pequenas: gere dados com σ_i^2 = |X_i| para testar convergência.",
                                  "learningObjective": "Aplicar LLN corretamente a sequências não-i.i.d. para provar convergência em probabilidade.",
                                  "commonMistakes": "Aplicar LLN forte desnecessariamente; ignorar condições de momentos finitos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e Generalizar a Prova para Contextos de Engenharia Econômica",
                                  "subSteps": [
                                    "Resuma a prova: consistência segue de LLN em X'X/n e X'ε/n sob pressupostos relaxados.",
                                    "Discuta extensões: amostras dependentes (time series), clustering em engenharia econômica.",
                                    "Teste com contraexemplo: se E[X_i ε_i] ≠ 0 (endogeneidade), consistência falha.",
                                    "Implemente verificação numérica: simule n=1000 com heterocedasticidade e compute ||β_hat - β||.",
                                    "Conclua aplicabilidade em grandes datasets econômicos (ex: painéis de firmas)."
                                  ],
                                  "verification": "Escreva a prova completa em 1 página e rode simulação mostrando convergência para n→∞.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (NumPy, StatsModels) ou R para simulação, dados sintéticos.",
                                  "tips": "Use seed para reprodutibilidade; plote bias vs. n para visualização intuitiva.",
                                  "learningObjective": "Generalizar a prova para aplicações reais e validar via simulações.",
                                  "commonMistakes": "Confundir consistência com eficiência assintótica; não testar numericamente."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão de salários em engenharia econômica: Y_i = β0 + β1 Educ_i + β2 Exp_i + ε_i, com Var(ε_i) = σ^2 Exp_i (heterocedasticidade). Simule n=10^6 observações, estime OLS e observe que β_hat converge para verdadeiros valores mesmo com covariância não constante, ilustrando consistência via LLN.",
                              "finalVerifications": [
                                "Derive plim(X'X/n) = Q e plim(X'ε/n) = 0 explicitamente.",
                                "Escreva a prova completa da consistência em notação matricial.",
                                "Simule dados heterocedásticos e confirme ||β_hat - β||_2 → 0 quando n→∞.",
                                "Identifique 3 pressupostos relaxados e justifique LLN sob eles.",
                                "Teste sensibilidade removendo exogeneidade e observe falha na consistência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na aplicação de LLN fraca (pontos por condições corretas).",
                                "Correção algébrica da decomposição β_hat - β (sem erros matriciais).",
                                "Profundidade na discussão de pressupostos relaxados (heterocedasticidade permitida).",
                                "Qualidade da simulação prática (gráficos de convergência, n variando).",
                                "Clareza na generalização para engenharia econômica (exemplos reais)."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Lei dos Grandes Números e convergência em probabilidade.",
                                "Econometria: Propriedades assintóticas em modelos de regressão.",
                                "Programação Computacional: Simulações Monte Carlo em Python/R.",
                                "Estatística Aplicada: Análise de grandes datasets em painéis econômicos."
                              ],
                              "realWorldApplication": "Em engenharia econômica, prova consistência permite usar OLS em grandes bases de dados de firmas ou mercados (ex: CRSP/Compustat), mesmo com volatilidade variável, para prever retornos ou crescimento, suportando decisões de investimento com amostras massivas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.3",
                            "name": "Aplicar em exemplos numéricos",
                            "description": "Calcular e interpretar a consistência em simulações com R ou software similar, comparando estimadores em amostras crescentes para dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar ambiente e gerar dados simulados de engenharia",
                                  "subSteps": [
                                    "Instalar e carregar pacotes necessários no R (ex: ggplot2, dplyr).",
                                    "Definir modelo de regressão linear verdadeiro para dados de engenharia, como tensão (Y) vs. carga (X) em testes de materiais: Y = 2*X + ε, com ε ~ N(0,1).",
                                    "Gerar datasets simulados para tamanhos de amostra crescentes: n = 10, 50, 100, 500, 1000.",
                                    "Salvar datasets em uma lista para reutilização.",
                                    "Verificar estatísticas descritivas básicas (média, variância) para cada dataset."
                                  ],
                                  "verification": "Executar summary() nos dados e confirmar que médias de X e Y aproximam valores teóricos.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "R ou RStudio instalado",
                                    "Pacotes: ggplot2, dplyr, lmtest"
                                  ],
                                  "tips": "Use set.seed(123) para reprodutibilidade das simulações.",
                                  "learningObjective": "Entender geração de dados sintéticos realistas para testar propriedades assintóticas.",
                                  "commonMistakes": [
                                    "Ignorar normalização de variáveis",
                                    "Gerar amostras muito pequenas inicialmente",
                                    "Não definir parâmetros verdadeiros corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar estimador OLS e simulações Monte Carlo",
                                  "subSteps": [
                                    "Escrever função para ajustar modelo OLS: lm(Y ~ X, data).",
                                    "Criar loop Monte Carlo (ex: 1000 replicatas) para cada tamanho de amostra, coletando coeficientes beta estimados.",
                                    "Calcular bias (média(β_hat - β_true)) e MSE para cada n.",
                                    "Armazenar resultados em data.frame com colunas: n, replicata, beta_hat, bias, mse.",
                                    "Executar simulações para todos tamanhos de n."
                                  ],
                                  "verification": "Verificar que o data.frame tem 1000*5 = 5000 linhas e bias próximo de zero para n grande.",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Script R preparado do Step 1",
                                    "Computador com pelo menos 8GB RAM"
                                  ],
                                  "tips": "Use parallel::mclapply() para acelerar simulações em múltiplos cores.",
                                  "learningObjective": "Dominar simulações Monte Carlo para avaliar propriedades de estimadores.",
                                  "commonMistakes": [
                                    "Poucas replicatas (use pelo menos 1000)",
                                    "Confundir bias com variância",
                                    "Não vetorizar loops desnecessariamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Visualizar e analisar convergência dos estimadores",
                                  "subSteps": [
                                    "Criar boxplots de β_hat por n usando ggplot2.",
                                    "Plotar bias e sqrt(MSE) vs. log(n) para observar tendência de convergência.",
                                    "Calcular desvio padrão dos β_hat por n.",
                                    "Comparar com estimador não-consistente (ex: média amostral enviesada artificialmente).",
                                    "Gerar relatório com captions explicando padrões observados."
                                  ],
                                  "verification": "Gráficos mostram β_hat centrado em β_true e variância decrescendo com n.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Resultados do Step 2",
                                    "ggplot2 carregado"
                                  ],
                                  "tips": "Use facet_wrap(~n) para múltiplos painéis; adicione linhas horizontais para β_true.",
                                  "learningObjective": "Interpretar visualmente consistência assintótica via simulações.",
                                  "commonMistakes": [
                                    "Escalas erradas nos eixos",
                                    "Não logar n para melhor visualização",
                                    "Ignorar outliers em boxplots"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e testar pressupostos relaxados",
                                  "subSteps": [
                                    "Quantificar consistência: prob( |β_hat - β_true| < 0.1 ) > 95% para n=1000.",
                                    "Relaxar pressupostos (ex: heterocedasticidade em ε) e reexecutar simulações.",
                                    "Comparar OLS com Ridge para amostras grandes, notando convergência similar.",
                                    "Escrever conclusão: 'OLS é consistente pois bias -> 0 e Var -> 0 com n -> ∞'.",
                                    "Exportar gráficos e tabela de resumo para PDF."
                                  ],
                                  "verification": "Relatório escrito confirma convergência em todos cenários testados.",
                                  "estimatedTime": "1 hour",
                                  "materials": [
                                    "Todos resultados prévios",
                                    "pacote knitr para relatório"
                                  ],
                                  "tips": "Teste com dados reais de engenharia (ex: dataset mtcars adaptado) para validação.",
                                  "learningObjective": "Aplicar e interpretar consistência em contextos relaxados de engenharia.",
                                  "commonMistakes": [
                                    "Não testar múltiplos cenários",
                                    "Concluir sem quantificação probabilística",
                                    "Confundir consistência com eficiência"
                                  ]
                                }
                              ],
                              "practicalExample": "Em testes de fadiga de materiais de engenharia, simule dados de ciclos até falha (Y) vs. amplitude de tensão (X). Use OLS para estimar relação, rodando simulações com n=10 (alta variabilidade) até n=1000 (β_hat ≈ 1.5 verdadeiro), plotando convergência para validar modelo antes de aplicar em dados reais de turbinas.",
                              "finalVerifications": [
                                "Boxplots mostram distribuição de β_hat centrada e estreitando com n crescente.",
                                "Bias médio < 0.05 para n ≥ 500 em todas replicatas.",
                                "MSE decresce monotonicamente com log(n).",
                                "Probabilidade de erro <10% excede 95% para n=1000.",
                                "Relatório PDF exportado com gráficos e interpretações.",
                                "Código R roda sem erros e é reprodutível com set.seed()."
                              ],
                              "assessmentCriteria": [
                                "Precisão das simulações Monte Carlo (≥1000 reps, múltiplos n).",
                                "Qualidade dos visualizações (claras, legendadas, tendências evidentes).",
                                "Correta quantificação de bias, variância e consistência.",
                                "Interpretação teórica alinhada com propriedades assintóticas de OLS.",
                                "Uso apropriado de R (loops eficientes, pacotes corretos).",
                                "Relatório conciso com conclusões acionáveis para engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência assintótica e teoremas limites.",
                                "Programação: Simulações computacionais em R/Python.",
                                "Engenharia: Modelagem preditiva em materiais e estruturas.",
                                "Matemática: Análise de convergência e probabilidades.",
                                "Ciência de Dados: Validação de modelos via Monte Carlo."
                              ],
                              "realWorldApplication": "Engenheiros mecânicos usam simulações de consistência OLS para validar modelos de regressão em grandes datasets de sensores IoT (ex: monitoramento de pontes), garantindo previsões confiáveis à medida que dados acumulam, reduzindo riscos de falhas estruturais."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.2",
                        "name": "Normalidade Assintótica dos Estimadores OLS",
                        "description": "Propriedade pela qual a distribuição dos estimadores OLS, devidamente normalizada, converge para uma normal multivariada à medida que n → ∞, mesmo sem normalidade dos erros.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.2.1",
                            "name": "Enunciar o teorema da normalidade assintótica",
                            "description": "Apresentar o resultado √n (β̂_OLS - β) → N(0, AsyVar), explicando o papel do teorema do limite central e da independência assintótica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos fundamentais de convergência assintótica e consistência do OLS",
                                  "subSteps": [
                                    "Defina consistência assintótica: plim θ̂ = θ quando n → ∞.",
                                    "Liste as condições exogeneidade estrita (E[ε|X] = 0) e homocedasticidade condicional.",
                                    "Explique por que √n (β̂_OLS - β) = O_p(1), mas não converge em probabilidade sem normalização.",
                                    "Discuta a matriz de variância amostral convergindo para AsyVar = plim (X'X/n)^{-1} σ².",
                                    "Verifique com um exemplo simples de regressão linear univariada."
                                  ],
                                  "verification": "Escreva um resumo de 200 palavras confirmando as condições e derive a consistência.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de aula sobre regressão linear, livro 'Introdução à Econometria' de Wooldridge (Cap. 3-5)",
                                  "tips": "Use diagramas para visualizar a convergência de β̂ para β.",
                                  "learningObjective": "Compreender as bases para propriedades assintóticas do OLS.",
                                  "commonMistakes": "Confundir consistência com normalidade; ignorar exogeneidade estrita."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar o Teorema do Limite Central (CLT) em médias amostrais",
                                  "subSteps": [
                                    "Enuncie o CLT clássico: √n (ȳ - μ) → N(0, σ²) sob i.i.d.",
                                    "Estenda para vetores: √n (X̄'ε̄) → N(0, plim Var(X'ε/n)).",
                                    "Mostre que β̂_OLS - β = (X'X/n)^{-1} (X'ε/n), então √n (β̂ - β) ≈ (plim X'X/n)^{-1} √n (X'ε/n).",
                                    "Verifique independência assintótica: Cov(√n (β̂ - β), outros estimadores) → 0.",
                                    "Simule numericamente em Python/R com n=1000 para visualizar a normalidade."
                                  ],
                                  "verification": "Gere um gráfico Q-Q plot mostrando normalidade aproximada.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python/R com bibliotecas numpy/statsmodels, Jupyter Notebook",
                                  "tips": "Aumente n progressivamente (100, 1000, 10000) para observar convergência.",
                                  "learningObjective": "Aplicar CLT à forma assintótica do erro de estimação OLS.",
                                  "commonMistakes": "Esquecer que CLT requer condições de Lindeberg ou Lyapunov para heterogeneidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar a matriz de variância assintótica (AsyVar)",
                                  "subSteps": [
                                    "Defina AsyVar(√n (β̂ - β)) = (E[xx'])^{-1} E[ε² xx'] (E[xx'])^{-1}.",
                                    "Discuta 'sandwich' form sob heteroscedasticidade: usar E[ε_i² x_i x_i'].",
                                    "Prove que sob exogeneidade, Var(X'ε/n) → E[σ_i² x x'].",
                                    "Compare com variância finita amostra sob homocedasticidade.",
                                    "Calcule AsyVar para um modelo simples com x dummy."
                                  ],
                                  "verification": "Derive analiticamente AsyVar para regressão univariada e confira com simulação.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Papel e caneta para derivações, MATLAB ou R para verificação numérica",
                                  "tips": "Use notação matricial consistente para evitar erros algébricos.",
                                  "learningObjective": "Calcular e interpretar a variância assintótica corretamente.",
                                  "commonMistakes": "Assumir homocedasticidade quando não especificado; confundir com variância finita."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Enunciar formalmente o teorema da normalidade assintótica",
                                  "subSteps": [
                                    "Enuncie: Sob exogeneidade estrita e outras condições regulares, √n (β̂_OLS - β) →_d N(0, AsyVar).",
                                    "Explique o papel do CLT na distribuição de √n (X'ε/n).",
                                    "Destaque independência assintótica com outros estimadores (e.g., médias).",
                                    "Liste condições completas: i.i.d. ou estacionariedade fraca, momentos finitos.",
                                    "Teste com bootstrap para aproximar a distribuição em amostras finitas."
                                  ],
                                  "verification": "Escreva o teorema completo em LaTeX e explique verbalmente para um par.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Editor LaTeX (Overleaf), vídeo-aula sobre teoremas assintóticos",
                                  "tips": "Memorize o enunciado exato e pratique recitá-lo.",
                                  "learningObjective": "Enunciar precisamente o teorema com explicações corretas.",
                                  "commonMistakes": "Omitir √n ou usar →_p em vez de →_d; ignorar AsyVar."
                                }
                              ],
                              "practicalExample": "Em uma regressão de salários sobre anos de educação com n=50.000 observações do PUMS dataset: compute β̂_OLS, √n (β̂ - β_simulado), plote histograma vs N(0, AsyVar estimada via HC3), confirmando normalidade aproximada para testes t em grandes amostras.",
                              "finalVerifications": [
                                "Enuncie o teorema sem consultar notas.",
                                "Derive √n (β̂ - β) → N(0, AsyVar) em 5 passos chave.",
                                "Simule e verifique normalidade em código para n>10k.",
                                "Explique papel do CLT e independência assintótica.",
                                "Calcule AsyVar para modelo bivariado simples.",
                                "Discuta quando o teorema falha (e.g., endogeneidade)."
                              ],
                              "assessmentCriteria": [
                                "Precisão no enunciado: inclui √n, →_d N(0, AsyVar)?",
                                "Correta explicação do CLT aplicado a X'ε/n.",
                                "Definição exata de AsyVar com forma 'sandwich'.",
                                "Identificação de condições necessárias (exogeneidade estrita).",
                                "Demonstração via simulação ou derivação.",
                                "Clareza na distinção entre propriedades finitas e assintóticas."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema do Limite Central multivariado.",
                                "Econometria: Inferência em modelos com grandes dados (big data).",
                                "Machine Learning: Análise de variância em regressão linear de alta dimensão.",
                                "Computação Científica: Simulações Monte Carlo para validação assintótica."
                              ],
                              "realWorldApplication": "Em análises de grandes datasets como censos ou logs de usuários (e.g., Google Analytics), usa-se normalidade assintótica para intervalos de confiança e testes de hipóteses em regressões OLS sem assumir homocedasticidade, permitindo inferências confiáveis em marketing, políticas públicas e finanças."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.2",
                            "name": "Derivar a variância assintótica",
                            "description": "Calcular a matriz de variância assintótica σ² (plim X'X/n)^{-1}, sob heterocedasticidade condicional e em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Assintóticos para o Estimador OLS",
                                  "subSteps": [
                                    "Liste os pressupostos padrão para consistência do OLS em grandes amostras: exogeneidade condicional E(u_i | X_i)=0, sem multicolinearidade perfeita, e convergência em probabilidade de (1/n)X'X para uma matriz finita positiva definida.",
                                    "Discuta heterocedasticidade condicional: Var(u_i | X_i) = σ_i² finita, mas não necessariamente constante.",
                                    "Verifique condições para Leis dos Grandes Números (LLN): média amostral de x_i u_i converge para zero, e (1/n)X'X →^p Q positiva definida.",
                                    "Explique o papel da independência ou dependência fraca dos erros para CLT posterior.",
                                    "Escreva as expressões matemáticas para plim (1/n) ∑ x_{it} u_i = 0 e plim (1/n)X'X = Q."
                                  ],
                                  "verification": "Confirme que todos os pressupostos estão corretamente listados e justificadas com fórmulas em um documento ou quadro.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de econometria (ex: Wooldridge, Cap. 10)",
                                    "Caderno de anotações",
                                    "Software simbólico como SymPy ou Mathematica"
                                  ],
                                  "tips": "Comece com regressão simples para visualizar; use notação matricial desde o início para generalidade.",
                                  "learningObjective": "Compreender e enunciar os pressupostos necessários para propriedades assintóticas do OLS sob heterocedasticidade condicional.",
                                  "commonMistakes": [
                                    "Confundir exogeneidade estrita com condicional",
                                    "Ignorar que Q deve ser finita e positiva definida",
                                    "Assumir homocedasticidade prematuramente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Representação do Erro do Estimador OLS",
                                  "subSteps": [
                                    "Escreva o estimador OLS: β̂ = β + (X'X)^{-1} X'u.",
                                    "Multiplique pelo fator de normalização: √n (β̂ - β) = √n (X'X/n)^{-1} (1/√n) X'u.",
                                    "Mostre que, sob LLN, (X'X/n) →^p Q, então (X'X/n)^{-1} →^p Q^{-1}.",
                                    "Analise o termo (1/√n) ∑ x_i u_i: este é a média amostral normalizada que converge em distribuição por CLT.",
                                    "Escreva √n (β̂ - β) →^d N(0, Q^{-1} Ω Q^{-1}), onde Ω = plim (1/n) ∑ σ_i² x_i x_i' sob heterocedasticidade."
                                  ],
                                  "verification": "Derive a equação √n (β̂ - β) = [ (X'X/n)^{-1} ] [ (1/√n) X'u ] e identifique os limites assintóticos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Folha de papel ou tablet para derivações",
                                    "Referência: Newey & McFadden (1994) ou notas de aula",
                                    "Calculadora matricial online"
                                  ],
                                  "tips": "Use a representação de influência linear para intuitividade; verifique dimensões matriciais em cada passo.",
                                  "learningObjective": "Derivar a forma assintótica normal do erro de estimação OLS usando expansão probabilística.",
                                  "commonMistakes": [
                                    "Esquecer o fator √n na normalização",
                                    "Confundir plim (X'X/n) com (X'X/n)",
                                    "Ignorar que Ω ≠ σ² Q sob heterocedasticidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar o Teorema Central do Limite (CLT) ao Termo de Erro",
                                  "subSteps": [
                                    "Defina Z_n = (1/√n) ∑ x_i u_i, e verifique condições para CLT: i.i.d. ou dependência fraca, momentos finitos E||x_i u_i||^2 < ∞.",
                                    "Mostre E(Z_n) → 0 e Var(Z_n) → Ω = E[σ_i² x_i x_i'] (ou plim média).",
                                    "Aplique CLT: Z_n →^d N(0, Ω).",
                                    "Combine com Slutsky: √n (β̂ - β) →^d Q^{-1} Z_n →^d N(0, Q^{-1} Ω Q^{-1}).",
                                    "Discuta simplificação: se homocedástico (σ_i²=σ²), então Ω=σ² Q, V=σ² Q^{-1}."
                                  ],
                                  "verification": "Escreva a prova completa da normalidade assintótica, incluindo condições do CLT.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Texto de teoria assintótica (ex: Davidson, Econometric Theory)",
                                    "Python/R para simular CLT em regressão"
                                  ],
                                  "tips": "Simule numericamente um caso simples para validar; foque em heterocedasticidade condicional.",
                                  "learningObjective": "Aplicar CLT e teorema de Slutsky para obter a distribuição assintótica normal do OLS.",
                                  "commonMistakes": [
                                    "Aplicar CLT sem verificar momentos finitos",
                                    "Confundir variância condicional com incondicional",
                                    "Omitir Q^{-1} nos dois lados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar e Simplificar a Matriz de Variância Assintótica",
                                  "subSteps": [
                                    "Identifique V = plim Var(√n (β̂ - β)) = Q^{-1} Ω Q^{-1}, com Q = plim (X'X/n), Ω = plim (X' D X / n) onde D=diag(σ_i²).",
                                    "Sob a notação do problema, note que se Ω ≈ σ² Q (ex: média σ_i²=σ²), então V ≈ σ² Q^{-1}.",
                                    "Derive explicitamente para regressão simples: var(β̂_1) ≈ σ² / (n s_{xx}), com s_{xx}=plim (1/n)∑(x_i - \bar x)^2.",
                                    "Discuta estimadores consistentes: σ̂² = (1/n) û' û ou White sanduíche para hetero.",
                                    "Verifique com um exemplo numérico simbólico ou simulado."
                                  ],
                                  "verification": "Escreva a fórmula final σ² (plim X'X/n)^{-1} e justifique sob as condições dadas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Software R/Python (pacotes sandwich, lmtest)",
                                    "Dados simulados de regressão"
                                  ],
                                  "tips": "Use a forma sanduíche como extensão; teste com simulação Monte Carlo.",
                                  "learningObjective": "Extrair a matriz de variância assintótica explícita e suas implicações para inferência.",
                                  "commonMistakes": [
                                    "Usar variância finita-amostra exata em vez de assintótica",
                                    "Assumir σ² conhecido",
                                    "Confundir Q com X'X/n exato"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere uma regressão simples Y_i = β_0 + β_1 X_i + u_i, com n=1000, X_i ~ N(0,1), u_i | X_i ~ N(0, σ_i²=0.5 + 0.5 X_i²) (heterocedástico). Simule dados em R/Python, estime OLS, compute √n (β̂ - β), e verifique que segue N(0, σ² (plim X'X/n)^{-1}) aproximando σ² ≈ E(σ_i²)=0.5, Q ≈ [[1,0],[0,1]].",
                              "finalVerifications": [
                                "Derivação completa de √n (β̂ - β) →^d N(0, σ² Q^{-1}) com todos os passos matemáticos corretos.",
                                "Identificação precisa de Q = plim(X'X/n) e justificativa de σ² sob heterocedasticidade condicional.",
                                "Simulação numérica confirma a variância assintótica estimada.",
                                "Discussão de estimador robusto (sanduíche) como extensão.",
                                "Ausência de erros em pressupostos ou aplicação de teoremas."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (100% das fórmulas corretas).",
                                "Compreensão conceitual de assintóticos vs. finitos (explicação clara).",
                                "Uso correto de CLT e Slutsky com condições verificadas.",
                                "Aplicação prática via simulação ou exemplo numérico.",
                                "Tratamento adequado de heterocedasticidade condicional.",
                                "Clareza na escrita e organização lógica."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teorema Central do Limite e inferência assintótica.",
                                "Econometria: Estimadores robustos e testes de hipóteses em grandes amostras.",
                                "Machine Learning: Análise de variância em regressão linear de alta dimensão.",
                                "Computação Científica: Simulações Monte Carlo para validação assintótica."
                              ],
                              "realWorldApplication": "Em finanças, deriva-se variância assintótica de regressões CAPM em painéis de ações (milhares de observações) para construir intervalos de confiança robustos a heterocedasticidade de retornos voláteis, permitindo testes de eficiência de mercado em grandes datasets."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.3",
                            "name": "Verificar empiricamente com simulações",
                            "description": "Usar histogramas e testes QQ em R para validar a normalidade assintótica em dados simulados de regressão linear aplicada a engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente R e simular dados de regressão linear",
                                  "subSteps": [
                                    "Instale e carregue pacotes necessários: ggplot2, dplyr.",
                                    "Defina parâmetros: n = 1000 (grande amostra), beta0 = 1, beta1 = 2, sigma = 1.",
                                    "Gere X ~ Uniform(0,10), erros ~ N(0, sigma^2), Y = beta0 + beta1*X + erro.",
                                    "Salve dados em data.frame para análise."
                                  ],
                                  "verification": "Execute código sem erros e verifique summary(dados) mostrando distribuição esperada.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "R, RStudio, pacotes: ggplot2, dplyr",
                                  "tips": "Use set.seed(123) para reprodutibilidade.",
                                  "learningObjective": "Compreender geração de dados simulados sob pressupostos de regressão linear normal.",
                                  "commonMistakes": "Esquecer de adicionar erro aos Y ou usar n pequeno inicialmente."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar modelo OLS e extrair resíduos",
                                  "subSteps": [
                                    "Ajuste lm(Y ~ X, data = dados).",
                                    "Extraia resíduos: residuals(modelo).",
                                    "Calcule resíduos studentizados se necessário: rstandard(modelo).",
                                    "Verifique dimensões: length(residuals) == nrow(dados)."
                                  ],
                                  "verification": "summary(modelo) mostra coeficientes próximos a verdadeiros betas.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "R com dados simulados do Step 1",
                                  "tips": "Use resid(modelo) para simplicidade.",
                                  "learningObjective": "Extrair resíduos padronizados para análise de normalidade.",
                                  "commonMistakes": "Confundir resíduos raw com studentizados em grandes amostras."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Criar visualizações: Histograma e QQ Plot",
                                  "subSteps": [
                                    "Histograma: ggplot(residuals, aes(x = residuals)) + geom_histogram(bins=50).",
                                    "QQ Plot: qqnorm(residuals); qqline(residuals).",
                                    "Ou ggplot: ggplot(data.frame(res=residuals), aes(sample=res)) + stat_qq() + stat_qq_line().",
                                    "Salve plots como PNG para relatório.",
                                    "Observe curvatura ou desvios da reta."
                                  ],
                                  "verification": "Plots mostram distribuição próxima à normal (simétrica, sem caudas pesadas).",
                                  "estimatedTime": "25 minutos",
                                  "materials": "ggplot2 carregado",
                                  "tips": "Aumente bins no histograma para grandes n.",
                                  "learningObjective": "Visualizar empiricamente normalidade assintótica via gráficos.",
                                  "commonMistakes": "Não padronizar resíduos antes do QQ plot."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Realizar testes formais de normalidade (Shapiro-Wilk, QQ test)",
                                  "subSteps": [
                                    "shapiro.test(residuals) – note limitação para n>5000.",
                                    "Use qqPlot(residuals, test='lillie') do nortest para teste formal QQ.",
                                    "Instale nortest se necessário: install.packages('nortest').",
                                    "Registre p-values >0.05 como evidência de normalidade."
                                  ],
                                  "verification": "p-value >0.05 em pelo menos um teste confirma hipótese nula de normalidade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Pacote nortest",
                                  "tips": "Para n grande, testes são sensíveis; priorize plots.",
                                  "learningObjective": "Aplicar testes estatísticos para validar normalidade assintótica.",
                                  "commonMistakes": "Ignorar que testes rejeitam normalidade perfeita em amostras finitas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar comportamento assintótico variando tamanho da amostra",
                                  "subSteps": [
                                    "Repita simulação para n=100, 1000, 10000.",
                                    "Gere plots e testes para cada n.",
                                    "Compare: QQ plots aproximam-se da reta com n crescente.",
                                    "Documente convergência em relatório.",
                                    "Conclua sobre normalidade assintótica."
                                  ],
                                  "verification": "Plots e p-values melhoram monotonicamente com n.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código dos steps anteriores em loop",
                                  "tips": "Use função para automatizar: simula_analisa(n).",
                                  "learningObjective": "Demonstrar convergência assintótica empiricamente.",
                                  "commonMistakes": "Não variar sigma ou betas, alterando condições."
                                }
                              ],
                              "practicalExample": "Em engenharia civil, simule dados de regressão linear para prever deformação (Y) baseada em carga aplicada (X) em vigas de concreto, com n=5000 simulações. Use histogramas e QQ plots nos resíduos para validar se os estimadores OLS são assintoticamente normais, confirmando confiabilidade de intervalos de confiança em projetos de grandes estruturas.",
                              "finalVerifications": [
                                "Histogramas dos resíduos são simétricos e unimodais para n grande.",
                                "QQ plots mostram pontos alinhados na reta diagonal.",
                                "Testes de normalidade (Shapiro ou QQ) têm p-value >0.05 para n>=1000.",
                                "Coeficientes OLS convergem para valores verdadeiros com n crescente.",
                                "Código R é reprodutível com set.seed().",
                                "Relatório resume evidências visuais e estatísticas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na simulação de dados sob modelo linear normal.",
                                "Correta extração e padronização de resíduos.",
                                "Qualidade e interpretação correta de visualizações (histograma, QQ).",
                                "Execução e interpretação adequada de testes formais.",
                                "Demonstração clara de convergência assintótica variando n.",
                                "Código limpo, comentado e eficiente."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teorema Central do Limite e TLC para resíduos.",
                                "Programação: Manipulação de dados em R com tidyverse.",
                                "Engenharia: Validação de modelos em simulações de sistemas físicos.",
                                "Matemática: Análise assintótica e convergência em probabilidade."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, engenheiros simulam grandes conjuntos de dados de testes de vento em asas (n=10k+), usam regressão OLS para modelar lift vs ângulo, e verificam normalidade assintótica dos resíduos via QQ plots para justificar uso de testes t em hipóteses sobre coeficientes, evitando erros em certificações de segurança."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.3",
                        "name": "Eficiência Assintótica dos Estimadores OLS",
                        "description": "Capacidade dos estimadores OLS de atingirem a menor variância assintótica possível entre estimadores não-viesados em grandes amostras, sob condições específicas como homocedasticidade ou métodos generalizados.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.3.1",
                            "name": "Explicar eficiência assintótica",
                            "description": "Definir eficiência assintótica como a igualdade da variância assintótica ao limite de Cramér-Rao, comparando OLS com MLE em regressões lineares.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais: Limite de Cramér-Rao e Variância Assintótica",
                                  "subSteps": [
                                    "Explique o teorema do limite inferior de Cramér-Rao para variância assintótica de estimadores não viesados.",
                                    "Defina variância assintótica como a variância da distribuição limite normal do estimador √n(θ̂ - θ).",
                                    "Discuta a informação de Fisher e como ela define o limite inferior para a variância assintótica.",
                                    "Diferencie variância finita-amostra de assintótica.",
                                    "Resuma com uma fórmula: Var_as(√n(θ̂)) ≥ 1/I(θ), onde I(θ) é a informação de Fisher."
                                  ],
                                  "verification": "Escreva definições precisas e fórmulas em um papel ou documento, conferindo com referências padrão.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de estatística assintótica, livro 'Asymptotic Statistics' de van der Vaart, calculadora.",
                                  "tips": "Use analogias como 'limite de velocidade' para o bound de Cramér-Rao para fixar o conceito.",
                                  "learningObjective": "Compreender o limite inferior de Cramér-Rao como benchmark para eficiência assintótica.",
                                  "commonMistakes": "Confundir limite de Cramér-Rao com variância exata em amostras finitas; ignorar o requisito de não viés."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir Eficiência Assintótica",
                                  "subSteps": [
                                    "Defina eficiência assintótica: um estimador é assintoticamente eficiente se sua variância assintótica iguala o limite de Cramér-Rao.",
                                    "Explique que isso ocorre quando o estimador é assintoticamente normal e atinge Var_as(√n(θ̂)) = 1/I(θ).",
                                    "Discuta condições necessárias: regularidade, consistência e normalidade assintótica.",
                                    "Compare com super-eficiência (rara e controversa).",
                                    "Ilustre com exemplo simples de estimador de média em distribuição normal."
                                  ],
                                  "verification": "Formule a definição em suas palavras e verifique se menciona igualdade ao bound de Cramér-Rao.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Referências online como Wikipedia 'Cramér–Rao bound', quadro branco para diagramas.",
                                  "tips": "Lembre-se: eficiência assintótica é sobre 'grande n', não amostras pequenas.",
                                  "learningObjective": "Definir precisamente eficiência assintótica em termos matemáticos.",
                                  "commonMistakes": "Equiparar eficiência assintótica a menor variância em todos os casos; esquecer normalidade assintótica."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Propriedades Assintóticas do OLS em Regressão Linear",
                                  "subSteps": [
                                    "Revise o modelo de regressão linear: Y = Xβ + ε, com E(ε)=0, Var(ε)=σ²I.",
                                    "Mostre consistência e normalidade assintótica do OLS: √n(β̂_OLS - β) → N(0, σ²(Q^{-1})), onde Q = plim(X'X/n).",
                                    "Calcule a informação de Fisher para β sob normalidade.",
                                    "Prove que sob ε ~ N(0,σ²I), Var_as(β̂_OLS) = σ²(Q^{-1}) iguala o bound de Cramér-Rao.",
                                    "Discuta relaxamento de normalidade: eficiência persiste sob heteroscedasticidade condicional homoscedástica (martingale difference)."
                                  ],
                                  "verification": "Derive ou recite a variância assintótica do OLS e compare ao bound.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Software R/Python para simular regressão linear, livro 'Econometric Analysis' de Greene.",
                                  "tips": "Simule em código para visualizar convergência assintótica.",
                                  "learningObjective": "Demonstrar que OLS é assintoticamente eficiente em regressão linear clássica.",
                                  "commonMistakes": "Assumir eficiência sem normalidade; confundir com viés em amostras finitas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar OLS com MLE e Concluir sobre Eficiência",
                                  "subSteps": [
                                    "Defina MLE em regressão linear sob normalidade: coincide com OLS.",
                                    "Mostre que sob normalidade, MLE=OLS, logo ambos eficientes.",
                                    "Discuta casos sem normalidade: OLS ainda eficiente se pressupostos assintóticos (LLN, CLT) valem; MLE pode ser mais eficiente se likelihood correta.",
                                    "Exemplo: regressão com erros t-Student – OLS eficiente, mas MLE com likelihood t é super-eficiente.",
                                    "Conclua: OLS é assintoticamente eficiente no modelo linear gaussiano."
                                  ],
                                  "verification": "Escreva tabela comparativa OLS vs MLE e explique igualdade de variâncias assintóticas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código Python para MLE vs OLS (statsmodels), artigos sobre eficiência assintótica.",
                                  "tips": "Foco em 'sob quais pressupostos?'; use matrizes para clareza.",
                                  "learningObjective": "Comparar eficiência assintótica de OLS e MLE em contextos lineares.",
                                  "commonMistakes": "Dizer que OLS sempre perde para MLE; ignorar que coincidem sob normalidade."
                                }
                              ],
                              "practicalExample": "Em uma regressão linear para prever salário por anos de educação (n=1000), simule dados com erros normais. Calcule β̂_OLS e MLE: suas variâncias assintóticas serão σ²(X'X/n)^{-1}, atingindo o bound de Cramér-Rao. Aumente n para 10k e veja convergência.",
                              "finalVerifications": [
                                "Pode definir eficiência assintótica corretamente?",
                                "Consegue derivar variância assintótica do OLS?",
                                "Explica por que OLS= MLE sob normalidade?",
                                "Identifica condições para eficiência do OLS?",
                                "Compara variâncias assintóticas com bound de Cramér-Rao?",
                                "Dá exemplo onde OLS é eficiente sem normalidade?"
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definições e fórmulas corretas): 30%",
                                "Clareza na explicação e uso de notação matemática: 25%",
                                "Profundidade na comparação OLS-MLE: 20%",
                                "Uso de exemplos/simulações para ilustrar: 15%",
                                "Identificação de pressupostos e limitações: 10%"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema do Limite Central e normalidade assintótica.",
                                "Econometria: Inferência em grandes amostras e testes de hipóteses.",
                                "Machine Learning: Otimização de perda quadrática vs likelihood em regressão.",
                                "Computação Científica: Simulações Monte Carlo para propriedades assintóticas."
                              ],
                              "realWorldApplication": "Em big data analytics, como previsão de demanda em e-commerce com milhões de observações, usar OLS garante estimadores eficientes (menor variância assintótica), otimizando decisões com confiança estatística alta sem computação intensiva de MLE não paramétrico."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.2",
                            "name": "Comparar eficiência com outros estimadores",
                            "description": "Analisar quando OLS é assintoticamente eficiente versus GMM ou MLE em pressupostos relaxados, com exemplos de aplicações em análise de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Eficiência Assintótica do OLS sob Pressupostos Clássicos e Relaxados",
                                  "subSteps": [
                                    "Relembre a definição de consistência e eficiência assintótica do OLS: Var(√n (β̂_OLS - β)) → Σ_OLS mínima sob homocedasticidade.",
                                    "Analise impactos de pressupostos relaxados como heterocedasticidade: OLS ainda consistente, mas ineficiente (variância maior).",
                                    "Derive a matriz de variância assintótica do OLS: AsyVar(β̂_OLS) = (Q'Q/n)^{-1} (σ²/n) sob i.i.d., relaxando para E[xε]=0.",
                                    "Compare com eficiência linear: OLS é BLUE sob Gauss-Markov relaxado.",
                                    "Implemente simulação simples em Python para visualizar variância OLS em dados heterocedásticos."
                                  ],
                                  "verification": "Simulação mostra variância OLS maior que o mínimo possível; explique por quê em relatório curto.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (statsmodels, numpy), notebook Jupyter, White (1980) paper on heteroskedasticity.",
                                  "tips": "Use plm ou linearmodels para robust SEs; foque em √n scaling.",
                                  "learningObjective": "Compreender limites da eficiência OLS e quando pressupostos relaxados a tornam subótima.",
                                  "commonMistakes": "Confundir consistência com eficiência; ignorar normalidade assintótica."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir GMM e MLE: Definições e Eficiência Assintótica",
                                  "subSteps": [
                                    "Defina GMM: Minimiza g_n(θ)' W g_n(θ), eficiente quando W ótimo = inv(E[Dg Dg']), sob E[g]=0.",
                                    "Explique MLE: Maximiza log-likelihood, assintoticamente eficiente sob regularidade (Cramer-Rao bound).",
                                    "Derive AsyVar para GMM ótimo: igual à MLE semi-paramétrica em modelos lineares.",
                                    "Compare: GMM flexível para momentos; MLE requer distribuição completa.",
                                    "Simule GMM 2SLS vs OLS em instrumento válido para endogeneidade relaxada."
                                  ],
                                  "verification": "Código GMM mostra variância menor que OLS em simulação com endogeneidade; plote distribuições.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (ivreg, GMM pyblp), Hansen (1982) GMM paper.",
                                  "tips": "Comece com just-identified GMM (W=I); teste overID com J-stat.",
                                  "learningObjective": "Dominar fórmulas assintóticas de GMM/MLE e superioridade sobre OLS relaxado.",
                                  "commonMistakes": "Usar W errado; assumir MLE sempre factível sem dados paramétricos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar OLS vs GMM/MLE sob Pressupostos Relaxados",
                                  "subSteps": [
                                    "Liste cenários: OLS eficiente se homocedástico/ sem endogeneidade; GMM/MLE melhor em hetero/endógeno.",
                                    "Calcule eficiência relativa: ratio de variâncias assintóticas (ex: GMM eficiente se momentos corretos).",
                                    "Analise trade-offs: OLS simples/rápido; GMM/MLE computacionalmente intensos mas precisos.",
                                    "Use teorema de eficiência: GMM ótimo atinge bound semi-paramétrico igual MLE.",
                                    "Crie tabela comparativa com fórmulas e condições para eficiência."
                                  ],
                                  "verification": "Tabela resume quando cada estimador é eficiente; justifique com equações.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "LaTeX ou Markdown para tabela, Newey-West (1987) para robusto.",
                                  "tips": "Foquem em 'local misspecification'; OLS perde eficiência >20% em hetero forte.",
                                  "learningObjective": "Identificar precisamente quando OLS é inferior e qual alternativa usar.",
                                  "commonMistakes": "Ignorar custo computacional de GMM; superestimar robustez OLS."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Comparação em Exemplo de Análise de Dados de Engenharia",
                                  "subSteps": [
                                    "Carregue dataset engenharia (ex: fadiga de materiais com hetero erros).",
                                    "Estime OLS, GMM-IV, MLE (supondo normalidade relaxada).",
                                    "Compare variâncias assintóticas e intervalos de confiança.",
                                    "Avalie fit: AIC/BIC, testes Hausman para endogeneidade.",
                                    "Interprete: Qual melhor para prever vida útil sob incertezas relaxadas?"
                                  ],
                                  "verification": "Relatório com outputs mostra GMM/MLE com IC menores; conclua superioridade.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Dataset simulado (gerar com numpy: y = Xβ + ε hetero), R/python (gmm pkg).",
                                  "tips": "Simule 1000 reps para Monte Carlo var; use bootstrap para SEs.",
                                  "learningObjective": "Aplicar comparação prática, selecionando estimador ótimo.",
                                  "commonMistakes": "Dataset sem violações reais; não reportar múltiplos cenários."
                                }
                              ],
                              "practicalExample": "Em análise de dados de engenharia civil, compare OLS, GMM e MLE para modelar resistência de vigas sob carga variável (heterocedástica devido a materiais). GMM com instrumentos (temperatura medida) supera OLS em eficiência assintótica, reduzindo variância de β̂ em 30%, melhorando previsões de falha.",
                              "finalVerifications": [
                                "Explicar verbalmente 3 cenários onde OLS não é eficiente assintoticamente.",
                                "Derivar AsyVar para GMM ótimo vs OLS em modelo hetero.",
                                "Simulação Monte Carlo mostra variância GMM < OLS em 95% reps.",
                                "Tabela comparativa correta com condições e trade-offs.",
                                "Aplicar Hausman test em exemplo engenharia para validar escolha.",
                                "Discutir limitações computacionais de MLE em amostras grandes."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas fórmulas assintóticas (100% correto).",
                                "Correta identificação de condições de eficiência (sem erros lógicos).",
                                "Simulações reproduzíveis com plots de variâncias comparadas.",
                                "Análise qualitativa profunda de trade-offs (profundidade > superficial).",
                                "Aplicação correta em contexto engenharia com interpretação acionável.",
                                "Clareza na comunicação (tabelas/relatórios legíveis)."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Extensão de IV/2SLS para eficiência.",
                                "Machine Learning: Paralelo com boosting/regularização para variância.",
                                "Engenharia: Otimização de modelos preditivos sob incerteza.",
                                "Estatística Computacional: Simulações Monte Carlo e bootstrap.",
                                "Probabilidade: Teoremas limite centrais relaxados."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, comparar OLS vs GMM/MLE em regressões para prever vibrações de turbinas com endogeneidade (velocidade-rpm). GMM usa instrumentos sensoriais, alcançando eficiência superior para certificação segura, reduzindo margens de erro em testes de fadiga e economizando milhões em redesigns."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.3",
                            "name": "Avaliar em contextos práticos",
                            "description": "Implementar comparações de variâncias assintóticas em software para dados reais, interpretando ganhos de eficiência em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente de software e selecionar dataset real grande",
                                  "subSteps": [
                                    "Instale bibliotecas necessárias: pandas, numpy, statsmodels, matplotlib e scikit-learn.",
                                    "Carregue um dataset real grande, como California Housing (20k+ observações) do sklearn.datasets.",
                                    "Explore o dataset: verifique tamanho (n > 10k), variáveis (preço como y, features como income, rooms), e estatísticas descritivas.",
                                    "Divida em train/test para simular grandes amostras.",
                                    "Salve o dataset processado em um DataFrame limpo."
                                  ],
                                  "verification": "Ambiente configurado e dataset carregado com shape(n>10000, p>5) exibido sem erros.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": "Python 3.8+, Jupyter Notebook, bibliotecas: pip install pandas numpy statsmodels matplotlib scikit-learn; dataset: fetch_california_housing()",
                                  "tips": "Use virtualenv para isolar dependências e comece com n=20000 para capturar efeitos assintóticos.",
                                  "learningObjective": "Preparar infraestrutura computacional para análise assintótica em dados reais grandes.",
                                  "commonMistakes": "Ignorar NaNs ou outliers iniciais; usar datasets pequenos (n<5000) que mascaram propriedades assintóticas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar dados e diagnosticar violações de pressupostos para eficiência assintótica",
                                  "subSteps": [
                                    "Gere plots residuais vs fitted para detectar heteroscedasticidade.",
                                    "Teste formal: Breusch-Pagan ou White test para heteroscedasticidade.",
                                    "Verifique normalidade residual com Q-Q plot e Shapiro-Wilk (opcional para assintóticas).",
                                    "Calcule correlogram para autocorrelação serial.",
                                    "Documente violações esperadas em dados reais (e.g., heteroscedasticidade em housing prices)."
                                  ],
                                  "verification": "Relatório com plots e p-values mostrando violações (e.g., p<0.05 para heteroscedasticidade).",
                                  "estimatedTime": "25-40 minutos",
                                  "materials": "statsmodels.stats.diagnostic het_breuschpagan, het_white; matplotlib seaborn para plots.",
                                  "tips": "Foquem em heteroscedasticidade, chave para comparar variâncias assintóticas relaxadas.",
                                  "learningObjective": "Identificar pressupostos relaxados relevantes para eficiência OLS em grandes amostras.",
                                  "commonMistakes": "Assumir homoscedasticidade sem testes; ignorar plots visuais em favor de apenas p-values."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar OLS e estimar variâncias assintóticas padrão e robustas",
                                  "subSteps": [
                                    "Fit OLS com statsmodels: sm.OLS(y, X).fit().",
                                    "Extraia variâncias padrão: model.summary() para homoscedastic (sandwich=False).",
                                    "Compute covariância robusta: model.get_robustcov_results(cov_type='HC3') para variâncias assintóticas HC.",
                                    "Extraia matriz de variâncias para coeficientes chave (e.g., income).",
                                    "Repita com subamostras crescentes (n=5k,10k,20k) para observar convergência."
                                  ],
                                  "verification": "Tabela com std errors padrão vs HC3 para pelo menos 3 coeficientes e múltiplos n.",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": "statsmodels.api as sm; formula: 'MedHouseVal ~ MedInc + AveRooms + Population'.",
                                  "tips": "Use cov_type='HC3' para finite-sample correction em n grande.",
                                  "learningObjective": "Calcular variâncias assintóticas teóricas e empíricas para OLS sob pressupostos relaxados.",
                                  "commonMistakes": "Confundir std errors com variâncias; não usar robust para dados reais violadores."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar variâncias e quantificar ganhos de eficiência assintótica",
                                  "subSteps": [
                                    "Calcule ratios: var_standard / var_HC3 para cada coeficiente.",
                                    "Plot ratios vs log(n) para mostrar convergência a 1 (eficiência assintótica).",
                                    "Compute métricas: % diferença média e intervalos de confiança empíricos.",
                                    "Simule bootstrap (100 reps) para variâncias empíricas em subamostras.",
                                    "Tabela comparativa: ganhos (redução % em var HC vs standard em n grande)."
                                  ],
                                  "verification": "Gráficos e tabela mostrando ratios próximos de 1 para n>10k, evidenciando eficiência.",
                                  "estimatedTime": "35-50 minutos",
                                  "materials": "scipy.stats.bootstrap; matplotlib para plots de convergência.",
                                  "tips": "Log-scale n para visualizar assintóticas; foque em coeficientes com maior impacto.",
                                  "learningObjective": "Quantificar numericamente superioridade assintótica do OLS em grandes amostras reais.",
                                  "commonMistakes": "Comparar std errors sem quadrados (use variâncias); plots sem escalas adequadas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e relatar ganhos de eficiência no contexto prático",
                                  "subSteps": [
                                    "Escreva relatório: explique por que var_HC → var_standard em n grande (eficiência OLS).",
                                    "Discuta implicações: confiança em inferências mesmo com violações.",
                                    "Visualize: heatmap de matriz cov ou forest plot de CIs.",
                                    "Conclua com limitações (e.g., se n ainda pequeno para full assintótico).",
                                    "Salve notebook com todos outputs e código reproduzível."
                                  ],
                                  "verification": "Relatório de 1-2 páginas com interpretações corretas e código versionado (e.g., GitHub).",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": "Markdown em Jupyter; Git para versionamento.",
                                  "tips": "Ligue resultados à teoria: teorema de eficiência assintótica OLS sob conditional homoscedasticity relaxada.",
                                  "learningObjective": "Traduzir análises computacionais em insights práticos sobre propriedades assintóticas.",
                                  "commonMistakes": "Superestimar ganhos sem evidência numérica; ignorar contexto de dados reais."
                                }
                              ],
                              "practicalExample": "Usando Python e dataset California Housing (20640 obs): fit OLS de MedHouseVal ~ MedInc + HouseAge + AveRooms. Compute var assintótica standard vs HC3 para beta_MedInc. Em n=20k, ratio var_standard/var_HC3 ≈1.02, mostrando eficiência OLS com heteroscedasticidade detectada (BP p<0.01), com plot de convergência vs subamostras.",
                              "finalVerifications": [
                                "Código executa end-to-end sem erros em dataset n>10k.",
                                "Variâncias padrão e HC3 calculadas e tabuladas para ≥3 coefs.",
                                "Plots mostram convergência de ratios a 1 em log(n).",
                                "Relatório interpreta ganhos corretamente (redução <5% em var HC para n grande).",
                                "Notebook reproduzível com seed para simulações.",
                                "Testes diagnósticos confirmam violações relevantes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação de OLS e robust cov (sem erros numéricos).",
                                "Qualidade dos plots e tabelas comparativas (clareza, labels).",
                                "Correção na interpretação assintótica (link a teoria).",
                                "Profundidade quantitativa: ratios, CIs, bootstrap.",
                                "Reprodutibilidade e documentação do código.",
                                "Análise contextualizada a dados reais grandes.",
                                "Identificação precisa de pressupostos relaxados."
                              ],
                              "crossCurricularConnections": [
                                "Programação Científica (Python/statsmodels para modelagem)",
                                "Estatística Inferencial (covariância robusta e testes diagnósticos)",
                                "Ciência de Dados (manipulação pandas, visualização matplotlib)",
                                "Econometria (aplicações em regressão com violações)",
                                "Computação de Alto Desempenho (simulações em large n)"
                              ],
                              "realWorldApplication": "Em epidemiologia, analisar grandes datasets de COVID-19 (milhões de obs) para regressões de mortalidade vs vacinas/fatores, usando OLS HC para variâncias assintóticas precisas apesar de heteroscedasticidade regional, permitindo inferências confiáveis sobre eficiência de políticas em populações massivas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.4",
                            "name": "Discutir limitações",
                            "description": "Identificar cenários onde OLS perde eficiência assintótica (ex.: endogeneidade) e sugestões de correções como IV em econometria aplicada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de eficiência assintótica do OLS",
                                  "subSteps": [
                                    "Definir convergência assintótica e variância assintótica do estimador OLS.",
                                    "Listar os pressupostos clássicos do OLS que garantem eficiência assintótica (ex.: exogeneidade, homocedasticidade).",
                                    "Explicar por que o OLS atinge a menor variância assintótica sob esses pressupostos.",
                                    "Derivar intuitivamente a fórmula da variância assintótica do OLS.",
                                    "Comparar com estimadores não eficientes em termos assintóticos."
                                  ],
                                  "verification": "Escrever um parágrafo explicando eficiência assintótica em palavras próprias e listar 4 pressupostos chave.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro 'Introdução à Econometria' de Wooldridge (cap. 3-5), notas de aula sobre propriedades assintóticas.",
                                  "tips": "Use notação probabilística (plim) para diferenciar de propriedades finitas.",
                                  "learningObjective": "Dominar a definição e condições para eficiência assintótica do OLS.",
                                  "commonMistakes": "Confundir eficiência assintótica com consistência ou propriedades em amostras finitas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar cenários onde o OLS perde eficiência assintótica",
                                  "subSteps": [
                                    "Analisar endogeneidade: explicar como E(u|X) ≠ 0 viola exogeneidade e causa perda de eficiência.",
                                    "Discutir outros cenários como heterocedasticidade e autocorrelação que aumentam variância assintótica.",
                                    "Identificar variáveis omitidas e multicolinearidade perfeita como fontes de ineficiência.",
                                    "Simular numericamente um caso de endogeneidade para observar variância inflada.",
                                    "Mapear cenários reais de dados econômicos onde ocorrem essas violações."
                                  ],
                                  "verification": "Listar 3 cenários específicos com endogeneidade e descrever o impacto na variância assintótica.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Software R ou Python (pacotes wooldridge ou statsmodels), datasets simulados de regressão.",
                                  "tips": "Sempre teste exogeneidade com testes como Hausman antes de concluir.",
                                  "learningObjective": "Reconhecer violações que comprometem a eficiência assintótica do OLS.",
                                  "commonMistakes": "Ignorar que endogeneidade afeta consistência primariamente, mas também eficiência condicional."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar sugestões de correções para limitações do OLS",
                                  "subSteps": [
                                    "Introduzir o estimador de Variáveis Instrumentais (IV) como solução para endogeneidade.",
                                    "Explicar os requisitos para um bom instrumento (relevância e exogeneidade).",
                                    "Comparar eficiência assintótica de OLS vs. IV em cenários violados.",
                                    "Discutir trade-offs: IV tem variância maior, mas recupera consistência e eficiência relativa.",
                                    "Mencionar alternativas como 2SLS e GMM para cenários mais complexos."
                                  ],
                                  "verification": "Desenhar um fluxograma de quando usar IV em vez de OLS e listar 2 instrumentos válidos para um exemplo.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Tutoriais de IV em R (ivreg package) ou Python (linearmodels), paper exemplo sobre IV.",
                                  "tips": "Verifique força do instrumento com teste de F-stat >10.",
                                  "learningObjective": "Entender métodos corretivos como IV e suas propriedades assintóticas.",
                                  "commonMistakes": "Escolher instrumentos endógenos ou irrelevantes, levando a pior performance."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar limitações e correções em uma discussão estruturada",
                                  "subSteps": [
                                    "Estruturar uma discussão: introdução, cenários de falha, impactos, correções.",
                                    "Praticar argumentação com exemplos aplicados em econometria.",
                                    "Avaliar trade-offs entre viés e variância em contextos assintóticos.",
                                    "Preparar respostas para objeções comuns sobre eficiência de IV.",
                                    "Redigir um resumo conciso de 300 palavras."
                                  ],
                                  "verification": "Escrever uma discussão completa de 1 página sobre limitações do OLS com foco em endogeneidade.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Modelos de discussão de papers econométricos, editor de texto.",
                                  "tips": "Use linguagem clara, evitando jargão excessivo; foque em implicações práticas.",
                                  "learningObjective": "Capacitar-se para discutir limitações de forma crítica e propositiva.",
                                  "commonMistakes": "Focar só em teoria sem ligar a aplicações reais."
                                }
                              ],
                              "practicalExample": "Em um estudo sobre o impacto do gasto educacional no salário médio, suspeita-se de endogeneidade por omitir habilidade inata. OLS estima coeficiente enviesado e ineficiente assintoticamente. Correção: usar distância à universidade mais próxima como IV (relevante por afetar gasto educacional, exógena ao erro). Implementar 2SLS em R e comparar variâncias assintóticas.",
                              "finalVerifications": [
                                "Pode listar e explicar 3 cenários onde OLS perde eficiência assintótica?",
                                "Descreve corretamente o papel da endogeneidade na variância assintótica?",
                                "Sugere IV com instrumentos válidos para um exemplo dado?",
                                "Compara eficiência de OLS vs. IV em violações?",
                                "Redige uma discussão coerente e sem erros conceituais?",
                                "Identifica trade-offs práticos das correções?"
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições e pressupostos corretos (30%)",
                                "Profundidade de análise: cenários e impactos detalhados (25%)",
                                "Relevância de correções: sugestões viáveis como IV (20%)",
                                "Clareza e estrutura: discussão lógica e concisa (15%)",
                                "Exemplos práticos: aplicação realista e simulável (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Economia Aplicada: avaliação de políticas causais",
                                "Estatística: inferência causal e testes de hipóteses",
                                "Programação: implementação de IV em Python/R para simulações",
                                "Matemática: limites e propriedades assintóticas",
                                "Ciências Sociais: análise de dados observacionais com viés"
                              ],
                              "realWorldApplication": "Em relatórios do Banco Central ou FMI, econometristas discutem limitações do OLS em modelos de crescimento econômico com endogeneidade (ex.: investimento endógeno), propondo IV para estimativas confiáveis que informam políticas fiscais e monetárias."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.2",
                    "name": "Regressão Linear em Grandes Amostras",
                    "description": "Comportamento e validade da regressão linear quando o tamanho da amostra é grande.",
                    "individualConcepts": [
                      {
                        "id": "11.3.1.1",
                        "name": "Consistência Assintótica dos Estimadores MQO",
                        "description": "Propriedade pela qual os estimadores de mínimos quadrados ordinários (MQO) convergem em probabilidade para os verdadeiros parâmetros populacionais à medida que o tamanho da amostra n tende ao infinito, mesmo sob pressupostos relaxados como heterocedasticidade ou ausência de normalidade.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.1.1",
                            "name": "Definir consistência e notação de convergência em probabilidade",
                            "description": "Explicar o conceito de consistência de um estimador, utilizando notação plim (probabilidade limite) e demonstrar que para MQO, β̂ →p β à medida que n → ∞ sob pressupostos mínimos (exogeneidade e não multicolinearidade perfeita).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Convergência em Probabilidade",
                                  "subSteps": [
                                    "Revise a definição formal de convergência em probabilidade: uma sequência de variáveis aleatórias X_n converge em probabilidade para X se, para todo ε > 0, P(|X_n - X| > ε) → 0 quando n → ∞.",
                                    "Diferencie de convergência quase certa e em distribuição, focando no aspecto probabilístico fraco.",
                                    "Estude exemplos simples, como a média amostral de variáveis i.i.d. convergindo para a média populacional.",
                                    "Pratique com exercícios: prove convergência em probabilidade para a proporção amostral em uma amostra binomial.",
                                    "Visualize graficamente: plote probabilidades para diferentes n."
                                  ],
                                  "verification": "Resuma em suas palavras a definição e dê um exemplo correto sem consultar notas.",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": [
                                    "Livro 'Introdução à Econometria' de Wooldridge (Cap. 3)",
                                    "Vídeo Khan Academy sobre Teorema do Limite Central",
                                    "Papel e caneta para anotações"
                                  ],
                                  "tips": "Use analogias como 'a média amostral se aproxima da verdadeira cada vez mais com mais dados, mas com alguma chance de erro'.",
                                  "learningObjective": "Compreender o conceito fundamental de convergência em probabilidade como base para consistência.",
                                  "commonMistakes": [
                                    "Confundir com convergência em média quadrática (mais forte)",
                                    "Ignorar o papel de ε > 0 arbitrário"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir Consistência de um Estimador",
                                  "subSteps": [
                                    "Defina consistência: um estimador θ̂_n é consistente para θ se θ̂_n →p θ quando n → ∞.",
                                    "Explique por que consistência é desejável: viés e variância vão a zero em grandes amostras.",
                                    "Discuta propriedades assintóticas: consistência é necessária mas não suficiente para eficiência.",
                                    "Resolva exercícios: identifique estimadores consistentes vs. inconsistentes (ex: média amostral vs. mediana em distribuições assimétricas).",
                                    "Compare com viés finito: mostre que estimadores viesados podem ser consistentes."
                                  ],
                                  "verification": "Escreva a definição formal e prove consistência da média amostral por Lei dos Grandes Números.",
                                  "estimatedTime": "25-40 minutos",
                                  "materials": [
                                    "Notas de aula sobre LLN e LTC",
                                    "Software R ou Python para simulações simples",
                                    "Artigo 'Asymptotic Theory' de Newey e McFadden (seção introdutória)"
                                  ],
                                  "tips": "Lembre-se: consistência é sobre n → ∞, não sobre amostras finitas reais.",
                                  "learningObjective": "Dominar a definição precisa de consistência e sua interpretação intuitiva.",
                                  "commonMistakes": [
                                    "Pensar que consistência implica não viés em amostras pequenas",
                                    "Confundir com convergência em distribuição"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir Notação plim e Aplicação Inicial",
                                  "subSteps": [
                                    "Aprenda a notação plim: plim_{n→∞} X_n = X significa X_n →p X.",
                                    "Pratique leitura e escrita: reescreva expressões como 'plim β̂ = β'.",
                                    "Aplique a teoremas básicos: plim da média amostral = μ sob i.i.d.",
                                    "Exercícios: use plim para expressar consistência de estimadores de momento.",
                                    "Crie notações compostas: plim (β̂ - β) = 0."
                                  ],
                                  "verification": "Traduza 3 expressões com plim para definições em probabilidade e vice-versa.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Folha de fórmulas assintóticas",
                                    "Exemplos de slides de aula sobre econometria assintótica"
                                  ],
                                  "tips": "A notação plim economiza espaço e é padrão em literatura avançada; memorize-a.",
                                  "learningObjective": "Usar fluentemente a notação plim para expressar convergência probabilística.",
                                  "commonMistakes": [
                                    "Escrever plim como limite determinístico (lim em vez de →p)",
                                    "Ignorar subscrito n→∞"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Demonstrar Consistência Assintótica do MQO",
                                  "subSteps": [
                                    "Revise modelo de regressão linear: Y = Xβ + ε, β̂ = (X'X)^{-1}X'Y.",
                                    "Prove plim β̂ = β usando decomposição: β̂ - β = (X'X/n)^{-1}(X'ε/n).",
                                    "Mostre plim (X'X/n) = Q (matriz de momentos populacional, sob exogeneidade E(Xε)=0).",
                                    "Conclua plim (X'ε/n) = 0, assim plim β̂ = Q^{-1} Q β = β (sem multicolinearidade perfeita).",
                                    "Simule em software: gere dados com n crescente e plote β̂ vs. β."
                                  ],
                                  "verification": "Derivação escrita completa da prova e simulação numérica confirmando convergência.",
                                  "estimatedTime": "45-60 minutos",
                                  "materials": [
                                    "Código R/Python para simulação MQO (pacote lmtest)",
                                    "Livro Wooldridge Cap. 5",
                                    "Calculadora ou Mathematica para matrizes"
                                  ],
                                  "tips": "Divida a prova em plim de cada termo; foque em normalização por n.",
                                  "learningObjective": "Provar e simular a consistência do MQO sob pressupostos mínimos.",
                                  "commonMistakes": [
                                    "Esquecer normalização /n",
                                    "Assumir homocedasticidade desnecessária"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Discutir Pressupostos Mínimos e Extensões",
                                  "subSteps": [
                                    "Liste pressupostos: (1) Exogeneidade estrita E(ε|X)=0, (2) Não multicolinearidade perfeita (rank(X)=k).",
                                    "Explique por que homocedasticidade e normalidade não são necessários para consistência.",
                                    "Estenda para regressores estocásticos: Lei dos Grandes Números para momentos condicionais.",
                                    "Exercícios: mostre inconsistência se endogeneidade (E(Xε)≠0).",
                                    "Conecte a inferência assintótica futura."
                                  ],
                                  "verification": "Identifique e justifique os 2 pressupostos mínimos; dê contraexemplo para violação.",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": [
                                    "Exemplos de dados endógenos (simulados)",
                                    "Resumo de pressupostos Gauss-Markov"
                                  ],
                                  "tips": "Consistência é robusta; poupe pressupostos para propriedades mais fortes.",
                                  "learningObjective": "Entender condições exatas para consistência MQO e limitações.",
                                  "commonMistakes": [
                                    "Incluir pressupostos desnecessários como esfericidade de erros"
                                  ]
                                }
                              ],
                              "practicalExample": "Em R, gere dados Y_i = 2 + 3 X_i + ε_i com X_i ~ N(0,1), ε_i ~ N(0,1), para n=10,100,1000. Estime β̂ com lm() e plote coeficientes vs. verdadeiros [2,3]; observe β̂ →p β com n crescente.",
                              "finalVerifications": [
                                "Defina corretamente convergência em probabilidade e consistência.",
                                "Escreva e interprete plim β̂ = β.",
                                "Liste e justifique pressupostos mínimos para MQO consistente.",
                                "Prove esboço da consistência MQO.",
                                "Simule e interprete convergência em código.",
                                "Diferencie de propriedades finitas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição formal (80% peso).",
                                "Correta uso de notação plim e prova (15% peso).",
                                "Identificação precisa de pressupostos (5% peso).",
                                "Clareza na explicação intuitiva e exemplos.",
                                "Proficiência em simulação prática.",
                                "Ausência de erros comuns como confusão de convergências."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Lei dos Grandes Números e Teorema do Limite Central.",
                                "Econometria: Base para inferência assintótica e IV.",
                                "Machine Learning: Consistência de OLS em regressão linear.",
                                "Matemática: Teoria da medida e probabilidade avançada.",
                                "Computação: Simulações Monte Carlo em análise de dados."
                              ],
                              "realWorldApplication": "Em previsão econômica, como estimar impacto de políticas públicas com grandes datasets (ex: PNAD no Brasil), onde MQO consistente garante que coeficientes convirjam para efeitos causais verdadeiros sob exogeneidade, permitindo decisões baseadas em grandes amostras."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.2",
                            "name": "Enunciar e provar o teorema de consistência do MQO",
                            "description": "Apresentar o teorema de consistência do estimador MQO, provando que E(β̂) = β e Var(β̂) → 0, utilizando decomposição algebraica e lei dos grandes números.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Enunciar o Teorema de Consistência do MQO e listar os pressupostos necessários",
                                  "subSteps": [
                                    "Relembrar o modelo de regressão linear clássica: Y = Xβ + u, com E(u|X)=0 e pressupostos relaxados para grandes amostras.",
                                    "Enunciar formalmente: Sob pressupostos (A1)-(A4), plim_{n→∞} β̂_{MQO} = β.",
                                    "Listar pressupostos: (A1) E(u_i|X_i)=0; (A2) {X_i u_i} estacionário e ergodico; (A3) E(X_i'X_i) < ∞; (A4) liminf rank(X'X/n) = K.",
                                    "Explicar o significado de consistência assintótica: E(β̂) ≈ β e Var(β̂) → 0 quando n → ∞.",
                                    "Derivar intuitivamente por que MQO é consistente usando heurística de médias amostrais."
                                  ],
                                  "verification": "Escrever o enunciado completo do teorema e os 4 pressupostos em um papel ou documento, conferindo com referência padrão.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge), notas de aula, quadro branco ou editor de texto"
                                  ],
                                  "tips": "Comece com o modelo simples univariado para intuição antes de generalizar para multivariado.",
                                  "learningObjective": "Compreender e reproduzir precisamente o teorema e seus pressupostos fundamentais.",
                                  "commonMistakes": [
                                    "Confundir consistência com não-viés (unbiasedness requer pressupostos mais fortes); omitir ergodicidade em (A2)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar a decomposição algébrica do estimador MQO",
                                  "subSteps": [
                                    "Escrever a fórmula do estimador: β̂ = (X'X)^{-1} X'Y.",
                                    "Substituir Y = Xβ + u: β̂ = β + (X'X)^{-1} X'u.",
                                    "Dividir por n: β̂ = β + (X'X/n)^{-1} (X'u/n).",
                                    "Identificar os termos: A_n = X'X/n e B_n = X'u/n.",
                                    "Verificar algebricamente que a decomposição é exata para qualquer n finito."
                                  ],
                                  "verification": "Derivar a decomposição passo a passo em um caderno, confirmando que β̂ - β = (X'X/n)^{-1} (X'u/n).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Caderno de matemática, calculadora simbólica opcional (ex: Mathematica ou papel)"
                                  ],
                                  "tips": "Use notação matricial consistente e evite expandir para somas até ser necessário.",
                                  "learningObjective": "Dominar a manipulação algébrica matricial essencial para a prova.",
                                  "commonMistakes": [
                                    "Esquecer de dividir por n nos termos; inverter a ordem na multiplicação matricial."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Provar a consistência da matriz de informação X'X/n",
                                  "subSteps": [
                                    "Invocar pressuposto (A3): E(X_i'X_i) = Q finita e positiva definida.",
                                    "Aplicar Lei dos Grandes Números (LLN) para sequências ergodicas: plim (1/n) Σ X_i'X_i = E(X_i'X_i) = Q.",
                                    "Verificar que X'X/n = (1/n) Σ X_i'X_i satisfaz condições de LLN (estacionariedade de {X_i}).",
                                    "Discutir invertibilidade: Pelo (A4), plim (X'X/n)^{-1} = Q^{-1} existe.",
                                    "Confirmar usando teorema de convergência em probabilidade contínua."
                                  ],
                                  "verification": "Escrever a prova formal, mostrando plim A_n = Q e plim A_n^{-1} = Q^{-1}.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Referência de Probabilidade (ex: Billingsley), exemplos matriciais simples"
                                  ],
                                  "tips": "Teste com dados simulados pequenos para visualizar X'X/n convergindo.",
                                  "learningObjective": "Aplicar LLN a matrizes aleatórias e entender invertibilidade assintótica.",
                                  "commonMistakes": [
                                    "Ignorar ergodicidade; assumir Q positiva definida sem prova."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Provar que X'u/n converge em probabilidade para zero",
                                  "subSteps": [
                                    "Usar pressuposto (A1): E(u_i | X_i) = 0 ⇒ E(X_i u_i) = 0.",
                                    "Aplicar LLN a {X_i u_i}: plim (1/n) Σ X_i u_i = E(X_i u_i) = 0.",
                                    "Verificar condições: {X_i u_i} tem momentos finitos por (A3) e ergodicidade por (A2).",
                                    "Discutir ortogonalidade: Cov(X_i, u_i)=0 garante média zero.",
                                    "Concluir plim B_n = 0."
                                  ],
                                  "verification": "Derivar formalmente plim X'u/n = 0, citando LLN explicitamente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas sobre LLN condicional, software R/Python para simulação opcional"
                                  ],
                                  "tips": "Simule em Python: gere X e u ortogonais e plote média de X'u/n vs n.",
                                  "learningObjective": "Compreender como exogeneidade implica convergência de resíduos ponderados.",
                                  "commonMistakes": [
                                    "Confundir E(u|X)=0 com u independente de X; esquecer momentos finitos."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Concluir a prova usando teorema de Slutsky",
                                  "subSteps": [
                                    "Reescrever: β̂ - β = A_n^{-1} B_n.",
                                    "Aplicar teorema de Slutsky: plim (A_n^{-1} B_n) = (plim A_n^{-1}) (plim B_n) = Q^{-1} * 0 = 0.",
                                    "Verificar condições de Slutsky: A_n^{-1} →_p Q^{-1} (degenerescente não), B_n →_p 0.",
                                    "Concluir: plim (β̂ - β) = 0, ou seja, β̂ consistente para β.",
                                    "Discutir extensões: consistência em normas, para subconjuntos de parâmetros."
                                  ],
                                  "verification": "Escrever a conclusão completa da prova, testando com um exemplo numérico simples.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Quadro para diagrama da prova, referência Wooldridge Cap. 5"
                                  ],
                                  "tips": "Desenhe um fluxograma da prova para visualizar dependências.",
                                  "learningObjective": "Integrar todos os passos e aplicar teoremas assintóticos compostos.",
                                  "commonMistakes": [
                                    "Aplicar Slutsky incorretamente se um termo não degenera; omitir continuidade."
                                  ]
                                }
                              ],
                              "practicalExample": "Simule em R ou Python um modelo Y_i = 2 + 3 X_i + u_i com n=1000, X_i ~ N(0,1), u_i ~ N(0,1) independente. Estime β̂_{MQO} e repita 1000 vezes: observe que desvio médio de β̂ de [2,3] →0 e variância →0 à medida que n aumenta para 10k.",
                              "finalVerifications": [
                                "Enunciado do teorema reproduzido corretamente com pressupostos.",
                                "Decomposição algébrica derivada sem erros.",
                                "Provas de plim X'X/n = Q e plim X'u/n = 0 completas.",
                                "Aplicação correta do teorema de Slutsky.",
                                "Exemplo numérico ou simulação confirma intuição.",
                                "Identificação de pelo menos 2 erros comuns evitados."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (sem erros algébricos).",
                                "Correto uso de teoremas assintóticos (LLN, Slutsky).",
                                "Clareza na explicação de pressupostos e condições.",
                                "Profundidade nos subpassos com justificativas lógicas.",
                                "Integração coerente de todos os steps na prova final.",
                                "Criatividade no exemplo prático e verificações."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Lei dos Grandes Números e convergência em probabilidade.",
                                "Álgebra Linear: Manipulação matricial e invertibilidade assintótica.",
                                "Econometria: Aplicações em modelos de regressão com endogeneidade fraca.",
                                "Computação: Simulações Monte Carlo para validar teoremas assintóticos."
                              ],
                              "realWorldApplication": "Em análises econômicas com grandes datasets (ex: painéis de empresas), o teorema justifica usar MQO para previsões assintóticas confiáveis em machine learning e policy evaluation, como estimar impactos de políticas públicas onde n é grande mas pressupostos exatos falham."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.3",
                            "name": "Aplicar consistência em simulação com grandes amostras",
                            "description": "Realizar simulação em R ou Python com n=1000+ observações, comparando β̂ com β verdadeiro e calculando bias e MSE para verificar convergência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente e definir o modelo verdadeiro",
                                  "subSteps": [
                                    "Instalar e importar bibliotecas necessárias (ex: numpy, pandas, statsmodels, matplotlib em Python; ou dplyr, ggplot2 em R)",
                                    "Definir parâmetros do modelo verdadeiro: intercepto β₀, inclinação β₁, variância do erro σ²",
                                    "Escolher tamanho da amostra n ≥ 1000 e definir semente aleatória (seed) para reprodutibilidade",
                                    "Especificar distribuição dos preditores (ex: x ~ N(0,1)) e do erro (ex: ε ~ N(0, σ²))",
                                    "Criar função para gerar dados simulados"
                                  ],
                                  "verification": "Script executa sem erros e parâmetros são impressos corretamente",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "IDE Python/R (Jupyter, RStudio)",
                                    "Bibliotecas: numpy, pandas, statsmodels, matplotlib (Python) ou base R com ggplot2"
                                  ],
                                  "tips": "Sempre use seed (np.random.seed(42)) para resultados reproduzíveis",
                                  "learningObjective": "Compreender a configuração inicial para simulações controladas",
                                  "commonMistakes": [
                                    "Esquecer de importar bibliotecas",
                                    "Não definir seed levando a resultados variáveis",
                                    "Definir n < 1000"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar dados simulados com grandes amostras",
                                  "subSteps": [
                                    "Gerar vetor de preditores x com n observações",
                                    "Gerar erros ε independentes",
                                    "Calcular y = β₀ + β₁ x + ε",
                                    "Repetir geração para múltiplas simulações (ex: 1000 réplicas) para calcular bias e MSE",
                                    "Armazenar dados em DataFrame para análise"
                                  ],
                                  "verification": "Dados gerados têm dimensões corretas (n x 2) e médias aproximam valores teóricos",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Script Python/R iniciado no step 1"
                                  ],
                                  "tips": "Use loops vetorizados ou apply para eficiência em grandes n",
                                  "learningObjective": "Dominar geração de dados sob modelo linear conhecido",
                                  "commonMistakes": [
                                    "Correlação inadvertida entre x e ε",
                                    "n insuficiente",
                                    "Não salvar réplicas para estatísticas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar modelo MQO e estimar β̂",
                                  "subSteps": [
                                    "Ajustar regressão linear ordinária (OLS) nos dados simulados",
                                    "Extrair estimativas β̂₀ e β̂₁ de cada réplica",
                                    "Calcular resíduos e verificar pressupostos básicos (ex: normalidade aproximada)",
                                    "Armazenar todas as estimativas β̂ em array ou lista",
                                    "Computar estatísticas descritivas iniciais das β̂"
                                  ],
                                  "verification": "Modelo ajusta sem warnings e coeficientes são extraídos corretamente",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Bibliotecas statsmodels (Python) ou lm() (R)"
                                  ],
                                  "tips": "Use summary() ou model.summary() para inspeção rápida",
                                  "learningObjective": "Aplicar estimador MQO em dados simulados grandes",
                                  "commonMistakes": [
                                    "Confundir β̂ com valores verdadeiros",
                                    "Ignorar warnings de multicolinearidade",
                                    "Erro na extração de coeficientes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular bias, MSE e visualizar convergência",
                                  "subSteps": [
                                    "Calcular bias = média(β̂ - β verdadeiro) para cada parâmetro",
                                    "Calcular MSE = média((β̂ - β verdadeiro)²)",
                                    "Criar histogramas ou boxplots de β̂ vs β verdadeiro",
                                    "Plotar curvas de bias/MSE vs n (testar n=100, 1000, 10000 para comparação)",
                                    "Interpretar resultados: verificar se bias → 0 e MSE → 0 com n grande"
                                  ],
                                  "verification": "Gráficos mostram convergência e valores de bias/MSE impressos são pequenos (<0.01)",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "matplotlib/ggplot2 para plots"
                                  ],
                                  "tips": "Escala log para MSE em plots vs n melhora visualização",
                                  "learningObjective": "Verificar propriedades assintóticas via simulação",
                                  "commonMistakes": [
                                    "Fórmula errada de bias (não subtrair β verdadeiro)",
                                    "Plots sem labels",
                                    "Ignorar variância em MSE"
                                  ]
                                }
                              ],
                              "practicalExample": "Simule modelo y = 2 + 3x + ε com x ~ N(0,1), ε ~ N(0,1), n=1000 em 500 réplicas. Estime β̂ via MQO, calcule bias ≈0 e MSE ≈0.001, plotando distribuição de β̂₁ centrada em 3.",
                              "finalVerifications": [
                                "Script completo roda end-to-end sem erros",
                                "Bias médio < 0.05 para ambos parâmetros",
                                "MSE diminui com n crescente",
                                "Visualizações mostram β̂ convergindo para β verdadeiro",
                                "Relatório com interpretações escritas",
                                "Resultados reproduzíveis com seed"
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica de bias e MSE (erro <5%)",
                                "Qualidade e clareza das visualizações",
                                "Correta implementação de loops para réplicas",
                                "Interpretação adequada de convergência assintótica",
                                "Eficiência computacional para n=10000+",
                                "Documentação no código (comentários)"
                              ],
                              "crossCurricularConnections": [
                                "Programação Computacional (loops, funções em Python/R)",
                                "Estatística Inferencial (propriedades assintóticas)",
                                "Visualização de Dados (histogramas, boxplots)",
                                "Análise Numérica (simulações Monte Carlo)"
                              ],
                              "realWorldApplication": "Validação de modelos em big data econométrico, como prever salários com milhões de observações no IBGE, confirmando consistência de MQO antes de inferências em políticas públicas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.2",
                        "name": "Distribuição Assintótica Normal dos Estimadores",
                        "description": "Comportamento assintótico dos estimadores MQO, que seguem uma distribuição normal aproximada N(β, σ² (X'X/n)^{-1}) para grandes amostras, permitindo inferência robusta.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.2.1",
                            "name": "Derivar a normalidade assintótica via Teorema Central do Limite",
                            "description": "Demonstrar que √n (β̂ - β) →d N(0, plim (X'X/n)^{-1} σ²), usando TCL multivariado sob pressupostos de momentos finitos e exogeneidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar pressupostos necessários para o TCL multivariado",
                                  "subSteps": [
                                    "Liste os pressupostos padrão da regressão linear: linearidade, exogeneidade estrita (E[u_i | X_i] = 0), momentos finitos até ordem 2+δ para x_i e u_i.",
                                    "Verifique condições do TCL multivariado: i.i.d. ou estacionariedade fraca, E[||x_i u_i||^{2+δ}] < ∞ para δ>0, covariância finita.",
                                    "Defina Q = plim (X'X/n) = E[x_i x_i'], assumindo ergodicidade e E[x_i x_i'] finita e positiva definida.",
                                    "Confirme homocedasticidade opcional: Var(u_i | x_i) = σ², levando a Ω = σ² Q."
                                  ],
                                  "verification": "Escreva uma lista completa dos pressupostos e justifique por que cada um é necessário para o TCL.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Notas de aula sobre regressão linear, livro de Wooldridge 'Econometric Analysis' capítulo 3-4, papel e caneta.",
                                  "tips": "Comece pelos pressupostos clássicos e adicione os específicos do TCL para evitar confusão com consistência.",
                                  "learningObjective": "Identificar e justificar todos os pressupostos requeridos para aplicar o TCL na derivação assintótica.",
                                  "commonMistakes": "Esquecer de momentos de ordem superior (2+δ) ou confundir exogeneidade com independência total."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Expressar o erro de estimação em termos de média amostral",
                                  "subSteps": [
                                    "Escreva β̂ = (X'X)^{-1} X'y e substitua y = Xβ + u para obter β̂ - β = (X'X)^{-1} X'u.",
                                    "Reescreva como β̂ - β = (X'X/n)^{-1} * (1/n ∑_{i=1}^n x_i u_i).",
                                    "Multiplique por √n: √n (β̂ - β) = (X'X/n)^{-1} * √n * (1/n ∑ x_i u_i) = (X'X/n)^{-1} * (1/√n ∑ x_i u_i).",
                                    "Note que √n * (1/n ∑ x_i u_i) = n^{-1/2} ∑ x_i u_i, que é uma média triangular."
                                  ],
                                  "verification": "Derive algebricamente √n (β̂ - β) e destaque o termo da média de x_i u_i.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Lousa ou software simbólico como SymPy (Python), matrizes de exemplo 2x2.",
                                  "tips": "Use notação matricial compacta e normalize por n para destacar os limites de Slutsky.",
                                  "learningObjective": "Manipular expressões algébricas para isolar o termo central que converge pelo TCL.",
                                  "commonMistakes": "Esquecer o fator √n na frente da média ou inverter a ordem das multiplicações matriciais."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar o Teorema Central do Limite multivariado",
                                  "subSteps": [
                                    "Aplique TCL a Z_n = n^{-1/2} ∑_{i=1}^n (x_i u_i - E[x_i u_i]), onde E[x_i u_i]=0 por exogeneidade.",
                                    "Conclua que Z_n →^d N(0, Ω), com Ω = E[x_i x_i' u_i²] (heterocedástico) ou σ² E[x_i x_i'] se homocedástico.",
                                    "Use teorema de Slutsky: como (X'X/n) →^p Q, então (X'X/n)^{-1} →^p Q^{-1}, e produto converge para N(0, Q^{-1} Ω Q^{-1}).",
                                    "Simplifique para homocedástico: Ω = σ² Q, V = σ² Q^{-1}.",
                                    "Escreva a notação final: √n (β̂ - β) →^d N(0, plim(X'X/n)^{-1} σ²)."
                                  ],
                                  "verification": "Esboce a prova do TCL passo a passo e aplique Slutsky explicitamente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Referência ao teorema de Lindeberg-Lévy ou Lyapunov para TCL multivariado, exemplos numéricos simples.",
                                  "tips": "Visualize x_i u_i como vetor aleatório centrado com covariância finita; pratique com dimensão p=1 primeiro.",
                                  "learningObjective": "Demonstrar a aplicação conjunta de TCL e Slutsky para obter a normalidade assintótica.",
                                  "commonMistakes": "Ignorar a convergência em probabilidade de (X'X/n)^{-1} ou assumir independência desnecessária."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e generalizar a derivação",
                                  "subSteps": [
                                    "Confirme que plim(X'X/n)^{-1} = [plim(X'X/n)]^{-1} = Q^{-1} por continuidade.",
                                    "Discuta extensões: heterocedasticidade robusta (Ω = E[x x' u²]), dependência serial (CLT para processos estacionários).",
                                    "Teste com p=1: reg simples, mostre √n (β̂ - β) → N(0, σ² / plim(∑x²/n)).",
                                    "Resuma a demonstração em um quadro final com setas de convergência."
                                  ],
                                  "verification": "Reescreva a derivação completa em uma página e identifique cada teorema usado.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Papel para diagrama de convergência, simulador Monte Carlo em R/Python para validar numericamente.",
                                  "tips": "Use setas →^p e →^d para clareza no fluxograma da prova.",
                                  "learningObjective": "Consolidar a prova e reconhecer limitações/extensões dos pressupostos.",
                                  "commonMistakes": "Confundir plim(A^{-1}) com [plim A]^{-1} sem justificar continuidade."
                                }
                              ],
                              "practicalExample": "Em uma regressão linear simples y_i = β x_i + u_i com n=1000 observações simuladas (x_i ~ N(0,1), u_i ~ N(0,1)), compute β̂ via OLS, calcule √n (β̂ - β) em 1000 simulações e plote o histograma; ele deve aproximar N(0, σ² / Var(x)), validando o TCL.",
                              "finalVerifications": [
                                "Pode derivar √n (β̂ - β) = (X'X/n)^{-1} (1/√n ∑ x_i u_i) corretamente.",
                                "Lista todos os pressupostos do TCL multivariado aplicados.",
                                "Explica o papel do teorema de Slutsky na multiplicação das convergências.",
                                "Identifica a matriz de variância assintótica V = Q^{-1} σ² Q^{-1} (geral) ou σ² Q^{-1}.",
                                "Valida numericamente com simulação Monte Carlo em software.",
                                "Discute o que acontece se um pressuposto falhar (ex: heterocedasticidade)."
                              ],
                              "assessmentCriteria": [
                                "Precisão algébrica na manipulação de √n (β̂ - β) (30%)",
                                "Correta aplicação e justificativa do TCL multivariado (25%)",
                                "Uso apropriado de Slutsky e limites de plim (20%)",
                                "Identificação clara de pressupostos e matriz V (15%)",
                                "Clareza na explicação e exemplo prático (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema Central do Limite e convergência em distribuição.",
                                "Econometria: Inferência assintótica em modelos lineares e testes t/Wald.",
                                "Machine Learning: Análise de variância assintótica em gradiente descendente.",
                                "Estatística Computacional: Simulações Monte Carlo para validar assintóticas."
                              ],
                              "realWorldApplication": "Em análises de grandes datasets econômicos (ex: painéis de empresas), usa-se essa normalidade para intervalos de confiança e testes de hipóteses em regressões OLS, como avaliar impacto de políticas públicas quando n>>p."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.2",
                            "name": "Calcular a matriz de variância assintótica",
                            "description": "Computar a variância assintótica do MQO, incluindo correção para heterocedasticidade (sandwich estimator), e interpretá-la em contexto de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos da Distribuição Assintótica Normal do MQO",
                                  "subSteps": [
                                    "Relembre os pressupostos do Teorema do Limite Central para estimadores MQO em grandes amostras.",
                                    "Entenda a convergência em distribuição: √n (β̂ - β) → N(0, V), onde V é a matriz de variância assintótica.",
                                    "Identifique os componentes de V: V = plim (X'X/n)^{-1} (plim (εε'/n)) (plim (X'X/n)^{-1}).",
                                    "Discuta os pressupostos relaxados: independência condicional, momentos finitos de X e ε.",
                                    "Resuma as condições para validade assintótica em regressão linear."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula de convergência e seus componentes para um colega.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão assintótica",
                                    "Livro 'Econometric Analysis' de Greene (cap. 3)",
                                    "Notebook Jupyter para anotações"
                                  ],
                                  "tips": "Use diagramas para visualizar a sanduíche de V: A^{-1} B A^{-1}.",
                                  "learningObjective": "Compreender a base teórica da variância assintótica do MQO.",
                                  "commonMistakes": "Confundir variância finita com assintótica; ignorar o fator √n."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Matriz de Variância sob Homocedasticidade",
                                  "subSteps": [
                                    "Parta da fórmula geral e assuma homocedasticidade: E(εε'|X) = σ² I.",
                                    "Simplifique para V = σ² plim (X'X/n)^{-1}.",
                                    "Estime σ² com o resíduo médio quadrado: σ̂² = (e'e)/(n-k).",
                                    "Calcule (X'X/n)^{-1} usando dados amostrais.",
                                    "Monte a matriz de variância estimada: V̂ = σ̂² (X'X/n)^{-1}."
                                  ],
                                  "verification": "Implemente em código e verifique se os elementos diagonais são positivos e coerentes com σ̂².",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python com NumPy e StatsModels",
                                    "Dataset simples de regressão linear",
                                    "Calculadora matricial online"
                                  ],
                                  "tips": "Normalizar X para facilitar cálculos iniciais.",
                                  "learningObjective": "Derivar e estimar a variância assintótica clássica.",
                                  "commonMistakes": "Usar X'X ao invés de X'X/n; dividir por n-k em vez de n para plim."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar o Sandwich Estimator para Heterocedasticidade",
                                  "subSteps": [
                                    "Estime resíduos: ê = y - X β̂.",
                                    "Calcule a matriz do meio: B̂ = (1/n) ∑ (x_i ê_i²) x_i' (ou use fórmula HC0).",
                                    "Compute Â = (X'X/n)^{-1}.",
                                    "Monte o sandwich: V̂_sandwich = Â B̂ Â.",
                                    "Implemente em StatsModels: sm.OLS().cov_HC0() ou similar."
                                  ],
                                  "verification": "Compare V̂_hom com V̂_sandwich; diagonais do sandwich devem ser maiores ou iguais.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Python/StatsModels ou R",
                                    "Dataset com heterocedasticidade artificial (e.g., ε ~ N(0, x²))",
                                    "Documentação StatsModels"
                                  ],
                                  "tips": "Use HC1 ou HC3 para amostras finitas: divida por n-k+1 ou ajuste de graus de liberdade.",
                                  "learningObjective": "Corrigir para erros heterocedásticos robustos.",
                                  "commonMistakes": "Esquecer de centralizar ou usar resíduos não-studentizados; inverter ordem do sandwich."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar a Matriz em Contexto de Engenharia",
                                  "subSteps": [
                                    "Extraia variâncias e covariâncias dos elementos diagonais e fora-diagonais.",
                                    "Calcule erros-padrão: se_j = √V̂_jj.",
                                    "Interprete: precisão dos estimadores em cenários de engenharia como previsão de fadiga estrutural.",
                                    "Discuta implicações: intervalos de confiança assintóticos e testes de hipóteses.",
                                    "Valide com bootstrap para comparação."
                                  ],
                                  "verification": "Gere relatório com interpretação de 2-3 coeficientes chave.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Dataset de engenharia (e.g., tensão vs. carga em vigas)",
                                    "Gráficos de resíduos para diagnosticar heterocedasticidade"
                                  ],
                                  "tips": "Visualize com heatmap da matriz V̂ para padrões de correlação.",
                                  "learningObjective": "Aplicar e interpretar variância assintótica em problemas reais.",
                                  "commonMistakes": "Ignorar covariâncias entre coeficientes; superestimar precisão sem sandwich."
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia civil, use dados de 1000 testes de compressão em concreto (variável resposta: resistência, preditoras: idade, proporção cimento/água, carga). Calcule β̂ MQO, estime V̂_hom e V̂_sandwich (heterocedasticidade por idade). Interprete: erro-padrão do coeficiente de cimento é 0.15 (sandwich) vs. 0.10 (hom), indicando subestimação de incerteza em previsões de durabilidade.",
                              "finalVerifications": [
                                "Código reproduz V̂_hom e V̂_sandwich corretamente para dataset padrão.",
                                "Diagonais de V̂_sandwich ≥ V̂_hom elemento a elemento.",
                                "Interpretação escrita explica impacto na engenharia (e.g., dimensionamento seguro).",
                                "Teste de White confirma heterocedasticidade.",
                                "Intervalos de confiança assintóticos incluem valores plausíveis.",
                                "Bootstrap (100 reps) valida V̂_sandwich (variâncias próximas)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação: fórmulas corretas sem erros algébricos (30%).",
                                "Implementação computacional: código funcional e eficiente (25%).",
                                "Correção para robustez: sandwich implementado adequadamente (20%).",
                                "Interpretação contextual: ligada a engenharia com números (15%).",
                                "Verificações e diagnósticos: testes de resíduos e comparações (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência assintótica e testes de hipóteses.",
                                "Programação: Manipulação matricial em Python/R.",
                                "Engenharia: Modelagem preditiva em estruturas/materiais.",
                                "Econometria: Extensões para painel e IV.",
                                "Machine Learning: Variâncias em regressão regularizada."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, calcular variância assintótica de modelo de regressão para prever vibrações em asas de aeronaves sob cargas variáveis (heterocedasticidade por velocidade). O sandwich estimator garante intervalos de confiança robustos, evitando subdimensionamento e falhas catastróficas em certificação FAA."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.3",
                            "name": "Verificar normalidade em grandes amostras via QQ-plot",
                            "description": "Usar gráficos QQ e testes de normalidade (Shapiro-Wilk) em dados simulados com n grande para validar a aproximação normal dos resíduos e estimadores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Simular dados de regressão linear com grande amostra",
                                  "subSteps": [
                                    "Defina parâmetros do modelo: y = β0 + β1*x + ε, com ε ~ N(0, σ²).",
                                    "Gere n=10000 observações para x uniformemente distribuídas entre 0 e 10.",
                                    "Simule erros ε com distribuição normal e adicione ao modelo linear.",
                                    "Crie um DataFrame com pandas contendo x e y.",
                                    "Visualize os dados com scatter plot para confirmar linearidade."
                                  ],
                                  "verification": "Dados simulados gerados corretamente: média de y próxima a β0 + β1*E[x], variância condicional constante.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python 3.x",
                                    "Jupyter Notebook",
                                    "Bibliotecas: numpy, pandas, matplotlib"
                                  ],
                                  "tips": [
                                    "Use np.random.seed(42) para reprodutibilidade.",
                                    "Escolha σ=1 para erros moderados."
                                  ],
                                  "learningObjective": "Compreender a geração de dados sintéticos para testar propriedades assintóticas em regressão.",
                                  "commonMistakes": [
                                    "Gerar n muito pequeno (<1000), invalidando aproximação assintótica.",
                                    "Esquecer de centralizar x, afetando interpretabilidade.",
                                    "Usar distribuição não-normal para ε inicialmente."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar modelo de regressão linear e extrair resíduos padronizados",
                                  "subSteps": [
                                    "Importe statsmodels.api e ajuste OLS: model = sm.OLS(y, sm.add_constant(x)).fit().",
                                    "Extraia resíduos: residuals = model.resid.",
                                    "Padronize resíduos: standardized_residuals = (residuals - residuals.mean()) / residuals.std().",
                                    "Verifique summary do modelo para coeficientes próximos aos verdadeiros β.",
                                    "Plote resíduos vs. fitted values para checar homocedasticidade."
                                  ],
                                  "verification": "Modelo ajustado com R² alto (>0.9), resíduos com média ~0 e variância ~1.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Bibliotecas adicionais: statsmodels"
                                  ],
                                  "tips": [
                                    "Sempre inclua constante com sm.add_constant(x).",
                                    "Padronize para facilitar QQ-plot."
                                  ],
                                  "learningObjective": "Dominar ajuste de OLS e extração de resíduos para análise de normalidade assintótica.",
                                  "commonMistakes": [
                                    "Não padronizar resíduos, distorcendo QQ-plot.",
                                    "Confundir resíduos raw com studentized.",
                                    "Ignorar diagnósticos iniciais do modelo."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar teste de Shapiro-Wilk para normalidade",
                                  "subSteps": [
                                    "Importe from scipy.stats import shapiro.",
                                    "Aplique teste: stat, p_value = shapiro(standardized_residuals[:5000]) (limite devido a restrições do teste).",
                                    "Interprete: se p_value > 0.05, não rejeita H0 de normalidade.",
                                    "Registre estatística W e p-value.",
                                    "Compare com subamostra para validar consistência."
                                  ],
                                  "verification": "Teste executado com p-value reportado corretamente; para dados normais simulados, p>0.05 esperado em n grande.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Biblioteca: scipy.stats"
                                  ],
                                  "tips": [
                                    "Shapiro-Wilk é sensível; use subamostra para n>5000.",
                                    "Não use para n>>5000; prefira visual em assintóticos."
                                  ],
                                  "learningObjective": "Aplicar e interpretar teste formal de normalidade em resíduos de grandes amostras.",
                                  "commonMistakes": [
                                    "Aplicar shapiro em todo dataset (erro se n>5000).",
                                    "Interpretar p baixo como 'não normal' sem contexto assintótico.",
                                    "Confundir H0 com 'dados normais perfeitos'."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Gerar e interpretar QQ-plot dos resíduos",
                                  "subSteps": [
                                    "Importe from scipy.stats import probplot e import matplotlib.pyplot as plt.",
                                    "Gere QQ-plot: probplot(standardized_residuals, dist='norm', plot=plt).",
                                    "Adicione linha de referência teórica e títulos.",
                                    "Analise: verifique alinhamento linear no centro, desvios em caudas.",
                                    "Salve figura e anote observações qualitativas."
                                  ],
                                  "verification": "QQ-plot gerado mostra pontos alinhados com linha diagonal no meio da plotagem.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Bibliotecas: scipy.stats, matplotlib"
                                  ],
                                  "tips": [
                                    "Use plot=plt para customização.",
                                    "Foque em quantis médios para assintóticos."
                                  ],
                                  "learningObjective": "Criar QQ-plots e interpretar evidências visuais de normalidade assintótica.",
                                  "commonMistakes": [
                                    "Não padronizar antes do plot.",
                                    "Ignorar desvios em caudas extremos (comuns em n grande).",
                                    "Confundir QQ com PP-plot."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integrar resultados e validar aproximação normal assintótica",
                                  "subSteps": [
                                    "Combine Shapiro-Wilk e QQ-plot: discuta concordância.",
                                    "Repita simulação com n=100, 1000, 10000 para ver convergência.",
                                    "Conclua: em n grande, resíduos aproximam normal mesmo com violações leves.",
                                    "Documente relatório com plots e métricas.",
                                    "Discuta limitações (e.g., testes conservadores em n grande)."
                                  ],
                                  "verification": "Relatório final afirma normalidade assintótica validada, com evidências visuais e teste.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Todos anteriores"
                                  ],
                                  "tips": [
                                    "Compare múltiplos n para demonstrar CLT.",
                                    "Enfatize 'aproximação' não perfeição."
                                  ],
                                  "learningObjective": "Sintetizar evidências para validar teoremas assintóticos em regressão.",
                                  "commonMistakes": [
                                    "Exigir normalidade perfeita (impossível em finita).",
                                    "Não repetir simulações para robustez.",
                                    "Ignorar contexto de estimadores √n-consistentes."
                                  ]
                                }
                              ],
                              "practicalExample": "Simule regressão y = 2 + 3*x + ε (ε~N(0,1)), n=10000. Ajuste OLS, extraia resíduos padronizados. Shapiro-Wilk em subamostra dá p=0.12 (não rejeita). QQ-plot mostra alinhamento linear central, caudas levemente curvadas – confirma aproximação normal para inferências assintóticas como ICs de β.",
                              "finalVerifications": [
                                "Resíduos padronizados têm média ≈0 e desvio padrão ≈1.",
                                "QQ-plot exibe linearidade no corpo principal dos quantis.",
                                "p-value de Shapiro-Wilk >0.05 em subamostra.",
                                "Repetição com n crescente mostra melhoria na aproximação.",
                                "Relatório identifica limitações do teste em n grande.",
                                "Código reproduzível gera resultados consistentes."
                              ],
                              "assessmentCriteria": [
                                "Correta simulação e ajuste de modelo com diagnósticos.",
                                "Implementação precisa de Shapiro-Wilk e QQ-plot.",
                                "Interpretação integrada: ênfase em assintótico vs. exato.",
                                "Uso de subamostras e repetições para validação.",
                                "Relatório claro com plots anotados e conclusões.",
                                "Reconhecimento de desvios em caudas como normais em n finito."
                              ],
                              "crossCurricularConnections": [
                                "Programação Científica (Python/R para simulações e visualizações).",
                                "Estatística Inferencial (Teorema Central do Limite e assintóticos).",
                                "Visualização de Dados (Interpretação de gráficos diagnósticos).",
                                "Machine Learning (Validação de assunções em modelos lineares grandes)."
                              ],
                              "realWorldApplication": "Em análise de dados financeiros com milhões de transações, verificar normalidade assintótica de resíduos em regressões para construir intervalos de confiança confiáveis em previsões de risco, como em modelos de Value-at-Risk."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.3",
                        "name": "Inferência Estatística em Grandes Amostras",
                        "description": "Uso de propriedades assintóticas para testes de hipóteses e intervalos de confiança na regressão linear, validando a regressão mesmo com violações de pressupostos clássicos.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.3.1",
                            "name": "Construir testes t e F assintóticos",
                            "description": "Formular estatísticas de teste t = (β̂j - βj0) / se(β̂j) →d N(0,1) e F para restrições lineares, comparando com distribuição qui-quadrada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos Assintóticos da Regressão Linear OLS",
                                  "subSteps": [
                                    "Relembre o modelo de regressão linear Y = Xβ + ε, com pressupostos relaxados para grandes amostras (heterocedasticidade permitida).",
                                    "Estude a consistência assintótica: plim β̂ = β, onde β̂ = (X'X/n)^{-1}(X'Y/n).",
                                    "Aplique o Teorema do Limite Central (CLT): √n (β̂ - β) →ᵈ N(0, A), com A = plim (X'X/n)^{-1} plim (εε'/n) plim (X'X/n)^{-1}.",
                                    "Defina o erro padrão assintótico se(β̂ⱼ) = √[Â_{jj}/n], onde Â é estimativa consistente de A (ex: White robust).",
                                    "Verifique condições para validade: ergodicidade estacionária e momentos finitos."
                                  ],
                                  "verification": "Escreva as expressões para plim β̂ e a distribuição limite de √n (β̂ - β), sem erros.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão assintótica",
                                    "Livro 'Introductory Econometrics' de Wooldridge (Cap. 13)",
                                    "Python/R para simulações rápidas"
                                  ],
                                  "tips": "Use notação matricial para clareza; foque em n→∞.",
                                  "learningObjective": "Compreender as propriedades assintóticas de β̂ e seus erros padrão para inferência.",
                                  "commonMistakes": [
                                    "Confundir variância amostral finita com assintótica",
                                    "Ignorar o fator √n na normalização CLT"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a Estatística de Teste t Assintótica",
                                  "subSteps": [
                                    "Defina a hipótese nula H₀: βⱼ = βⱼ⁰.",
                                    "Construa t = (β̂ⱼ - βⱼ⁰) / se(β̂ⱼ).",
                                    "Mostre que sob H₀, t →ᵈ N(0,1) por Slutsky's theorem (pois se(β̂ⱼ) →ᵖ constante >0).",
                                    "Estime se(β̂ⱼ) usando covariância robusta: ĉov(β̂) = (X'X/n)^{-1} (∑ û_i² x_i x_i'/n) (X'X/n)^{-1} /n.",
                                    "Calcule p-value: 2 * (1 - Φ(|t|)), com Φ CDF normal padrão."
                                  ],
                                  "verification": "Derive t e prove sua distribuição limite N(0,1) sob H₀.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Software statsmodels (Python) ou lmtest (R)",
                                    "Artigo sobre standard errors robustos"
                                  ],
                                  "tips": "Sempre use se robusto em grandes amostras para evitar subestimação de variância.",
                                  "learningObjective": "Formular corretamente a estatística t assintótica e sua justificação teórica.",
                                  "commonMistakes": [
                                    "Usar se homocedástico em vez de robusto",
                                    "Esquecer normalização por se(β̂ⱼ) →ᵖ σⱼ"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir a Estatística F para Restrições Lineares",
                                  "subSteps": [
                                    "Defina restrições lineares Rβ = r, com R (q x k), q restrições.",
                                    "Estime resíduos sob H₀: minimize ||Y - Xγ||² s.a. Rγ = r, obtendo γ̂.",
                                    "Calcule F = [ (SSR_r - SSR_u)/q ] / [ SSR_u / (n-k) ], mas versão assintótica: n (r - Rβ̂)' [R ĉov(β̂) R']^{-1} (r - Rβ̂) / q.",
                                    "Mostre F →ᵈ χ²_q sob H₀, por quadratic form em normal.",
                                    "Implemente em software: teste lmtest::waldtest em R ou similar em Python."
                                  ],
                                  "verification": "Escreva a fórmula assintótica de F e identifique sua distribuição limite χ²_q.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Código Python com statsmodels para Wald test",
                                    "Livro 'Econometric Analysis' de Greene"
                                  ],
                                  "tips": "Para q=1, F = t²; use isso para verificação cruzada.",
                                  "learningObjective": "Dominar a formulação do teste F assintótico para múltiplas restrições.",
                                  "commonMistakes": [
                                    "Confundir F finito-amostra com assintótico",
                                    "Errar a matriz de covariância em [R V R']^{-1}"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar Testes t/F com Distribuições Qui-Quadrado e Validar",
                                  "subSteps": [
                                    "Note que para teste t simples (q=1), t² →ᵈ χ²_1.",
                                    "Para restrições gerais, F →ᵈ χ²_q / q, mas use χ²_q para assintótico direto na forma de Wald.",
                                    "Simule dados grandes (n=10000): gere Y = Xβ + ε, teste H₀ falsas/verdadeiras, cheque rejeição ~5%.",
                                    "Compare p-values t vs F vs qui-quadrado em simulação.",
                                    "Discuta quando usar cada: t para univariada, F/Wald para multivariada."
                                  ],
                                  "verification": "Simule e plote distribuições empíricas de t e F vs teóricas N(0,1)/χ².",
                                  "estimatedTime": "90 minutos",
                                  "materials": [
                                    "Python (numpy, statsmodels, matplotlib)",
                                    "Jupyter notebook para simulações"
                                  ],
                                  "tips": "Use seed para reprodutibilidade; n grande acelera convergência.",
                                  "learningObjective": "Validar testes assintóticos via simulação e entender relação com qui-quadrado.",
                                  "commonMistakes": [
                                    "Usar distribuição F finita em grandes n",
                                    "Ignorar tamanho da amostra na convergência"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar e Interpretar Testes em Dados Reais",
                                  "subSteps": [
                                    "Carregue dataset grande (ex: wages data n>1000).",
                                    "Ajuste OLS com se robusto, compute t para β_wage=0.",
                                    "Teste joint F: H₀: β_educ=β_exp=0.",
                                    "Interprete: rejeite se |t|>1.96 ou F>χ²_crit, com significância.",
                                    "Documente relatório: hipótese, stat, p-value, conclusão."
                                  ],
                                  "verification": "Produza output com t/F, p-values corretos e interpretação coerente.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Dataset público (ex: wooldridge package R ou Kaggle)",
                                    "Software de regressão"
                                  ],
                                  "tips": "Sempre reporte se robustos; cheque multicolinearidade.",
                                  "learningObjective": "Aplicar testes t/F assintóticos em prática e interpretar resultados.",
                                  "commonMistakes": [
                                    "Interpretar causalidade sem controles",
                                    "Confundir significância estatística com econômica"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (n=5000), regredir log(wage) ~ educ + exper + female. Teste t: H₀: coef(educ)=0 → t=(0.08-0)/0.01=8 → p<0.001, rejeita. Teste F joint educ+exper=0 → F=45.2 ~ χ²_2 crit=6, rejeita.",
                              "finalVerifications": [
                                "Formulação correta de t = (β̂ⱼ - βⱼ⁰)/se(β̂ⱼ) → N(0,1).",
                                "Estatística Wald F → χ²_q para restrições Rβ=r.",
                                "Simulação valida rejeição nominal 5% sob H₀.",
                                "Cálculo de p-values usando norm.cdf e chi2.cdf.",
                                "Interpretação coerente de resultados em exemplo prático."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação assintótica (CLT, Slutsky).",
                                "Correta implementação de se robustos e F Wald.",
                                "Validação via simulação (QQ-plots ou histograms).",
                                "Clareza na distinção t vs F e relação com χ².",
                                "Aplicação prática sem erros computacionais."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: CLT e convergência em distribuição.",
                                "Cálculo: Álgebra matricial e formas quadráticas.",
                                "Programação: Implementação em Python/R statsmodels/lmtest.",
                                "Econometria: Inferência em modelos lineares relaxados.",
                                "Machine Learning: Feature selection via testes de significância."
                              ],
                              "realWorldApplication": "Em econometria, testar impacto de políticas públicas (ex: coef de 'treinamento' em emprego usando dados administrativos grandes); em bioestatística, validar associações genéticas em GWAS com n=10^6."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.2",
                            "name": "Implementar intervalos de confiança assintóticos",
                            "description": "Calcular ICs de 95% usando distribuição normal padrão para β̂ em grandes amostras, aplicando em dados de engenharia (ex.: análise de sensores).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar fundamentos teóricos dos intervalos de confiança assintóticos",
                                  "subSteps": [
                                    "Estude a propriedade assintótica da estimativa β̂ em regressão linear: √n(β̂ - β) → N(0, σ² (X'X/n)^{-1}) para grandes n.",
                                    "Identifique a variância assintótica de β̂_j como σ² / (n * var(x_j)) ajustada pelo design matrix.",
                                    "Revise a aproximação normal padrão Z = √n (β̂ - β) / se(β̂) ~ N(0,1).",
                                    "Entenda por que usamos distribuição normal padrão para IC de 95%: ±1.96 * se(β̂).",
                                    "Discuta pressupostos relaxados em grandes amostras: independência, homocedasticidade fraca."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula assintótica e justifique o uso da normal padrão.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão assintótica",
                                    "Artigo ou capítulo sobre inferência em grandes amostras"
                                  ],
                                  "tips": "Desenhe o design matrix X para visualizar a variância; foque em intuição antes de fórmulas.",
                                  "learningObjective": "Compreender a base teórica para construção de ICs assintóticos em regressão linear.",
                                  "commonMistakes": [
                                    "Confundir variância assintótica com variância finita-amostral",
                                    "Ignorar o fator √n na normalização"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular β̂ e sua variância assintótica em um modelo de regressão",
                                  "subSteps": [
                                    "Ajuste o modelo de regressão linear usando dados grandes (n > 1000): y = Xβ + ε.",
                                    "Calcule β̂ = (X'X)^{-1} X'y.",
                                    "Estime σ² como resíduo médio quadrado (MSE) dos resíduos e.",
                                    "Compute a matriz de covariância assintótica: ÂVar(β̂) = σ² (X'X/n)^{-1}.",
                                    "Extraia se(β̂_j) = √[ÂVar(β̂)_jj] para o coeficiente de interesse."
                                  ],
                                  "verification": "Verifique se β̂ e se(β̂) coincidem com saída de software (ex.: Python statsmodels).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python/R com bibliotecas statsmodels/ols",
                                    "Dataset simulado de regressão grande (n=5000)"
                                  ],
                                  "tips": "Use funções prontas para (X'X)^{-1} mas entenda o cálculo; normalize X para estabilidade numérica.",
                                  "learningObjective": "Executar computacionalmente estimativas necessárias para IC assintótico.",
                                  "commonMistakes": [
                                    "Usar variância HC sem necessidade em amostras grandes iid",
                                    "Erro numérico em inversão de X'X para n grande: use solve em vez de inv"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir e interpretar o intervalo de confiança de 95%",
                                  "subSteps": [
                                    "Calcule o IC: β̂_j ± 1.96 * se(β̂_j).",
                                    "Verifique se o IC contém zero: implica não significância a 5%.",
                                    "Interprete: 'Com 95% confiança assintótica, β_j está no intervalo'.",
                                    "Compare largura do IC com tamanho da amostra: deve encolher com n maior.",
                                    "Teste sensibilidade variando σ̂ ou subamostras."
                                  ],
                                  "verification": "Implemente função que retorna IC e plote histograma de cobertura em simulações.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código Python para IC",
                                    "Simulador de regressão Monte Carlo"
                                  ],
                                  "tips": "Use z=1.96 exato; para precisão, confira qnorm(0.975) em R.",
                                  "learningObjective": "Construir ICs corretos e interpretá-los no contexto assintótico.",
                                  "commonMistakes": [
                                    "Usar t-student em vez de normal para n grande",
                                    "Esquecer multiplicar por 1.96"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em dados reais de engenharia e validar",
                                  "subSteps": [
                                    "Carregue dataset de sensores (ex.: tensão vs. temperatura, n=2000 observações).",
                                    "Ajuste regressão: tensão ~ temperatura + controles.",
                                    "Compute IC para β_temperatura e interprete (ex.: mudança em tensão por °C).",
                                    "Valide cobertura com bootstrap ou simulação paramétrica.",
                                    "Relate achados: 'IC [a,b] sugere sensibilidade positiva com 95% confiança'."
                                  ],
                                  "verification": "Produza relatório com IC, p-value equivalente e gráfico de resíduos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Dataset real de sensores (ex.: Kaggle IoT sensors)",
                                    "Jupyter notebook"
                                  ],
                                  "tips": "Escolha variável com var(x)>0; cheque multicolinearidade via VIF.",
                                  "learningObjective": "Aplicar IC assintóticos em contexto prático de engenharia.",
                                  "commonMistakes": [
                                    "Ignorar outliers em dados de sensores",
                                    "Sobreinterpretar precisão em amostras não-iid"
                                  ]
                                }
                              ],
                              "practicalExample": "Em análise de sensores IoT de uma fábrica, ajuste regressão linear de leitura de vibração (y) sobre velocidade do motor (x), n=5000. Compute IC 95% para β_x: se [1.2, 1.8], conclua que cada rpm aumenta vibração em 1.5±0.3 unidades com 95% confiança assintótica, guiando manutenção preditiva.",
                              "finalVerifications": [
                                "Calcula corretamente se(β̂) usando (X'X/n)^{-1} σ².",
                                "IC de 95% usa exatamente ±1.96 se(β̂).",
                                "Interpreta IC sem mencionar 'probabilidade' (é confiança).",
                                "Valida cobertura >94% em simulação Monte Carlo (n=1000 reps).",
                                "Aplica em dataset engenharia com relatório coerente.",
                                "Discute limitações assintóticas (ex.: n muito grande ainda requer cuidado)."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: fórmulas e cálculos 100% corretos (30%).",
                                "Implementação computacional: código reproduzível e eficiente (25%).",
                                "Interpretação contextual: liga a engenharia/sensores (20%).",
                                "Validação: simulações/bootstraps mostram cobertura adequada (15%).",
                                "Clareza do relatório: visualizações e escrita profissional (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Uso de NumPy/SciPy para álgebra linear em Python.",
                                "Engenharia: Análise de dados de sensores para monitoramento industrial.",
                                "Estatística Avançada: Transição para regressão robusta e bootstrap.",
                                "Machine Learning: Base para ICs em modelos lineares grandes."
                              ],
                              "realWorldApplication": "Em engenharia de sensores, ICs assintóticos avaliam confiabilidade de coeficientes em previsões de falhas (ex.: vibração em turbinas), permitindo decisões de calibragem sem simulações caras, otimizando manutenção preditiva em indústrias como óleo/gás."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.3",
                            "name": "Avaliar validade da inferência com pressupostos relaxados",
                            "description": "Discutir robustez da inferência MQO em grandes amostras sob heterocedasticidade ou não-normalidade, usando robust standard errors (HCSE).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Pressupostos Clássicos do MQO e Violações em Grandes Amostras",
                                  "subSteps": [
                                    "Listar e descrever os quatro pressupostos principais do modelo linear clássico: linearidade condicional na média, exogeneidade estrita, homocedasticidade e normalidade dos erros.",
                                    "Explicar por que homocedasticidade e normalidade podem ser relaxados em grandes amostras devido ao Teorema do Limite Central (TLC), que garante consistência e normalidade assintótica dos estimadores.",
                                    "Discutir impactos das violações: erros padrão enviesados sob heterocedasticidade (sub ou superestimação de variância), levando a testes de significância inválidos.",
                                    "Analisar exemplos de dados reais onde heterocedasticidade ocorre, como em regressões de renda vs. educação.",
                                    "Revisar propriedades assintóticas do MQO: consistência e normalidade √n(β̂ - β) ~ N(0, Σ)."
                                  ],
                                  "verification": "Escrever um resumo de 200 palavras identificando violações comuns e seus efeitos na inferência, com exemplos.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Notas de aula sobre MQO, vídeo introdutório sobre pressupostos (Khan Academy ou similar), calculadora.",
                                  "tips": "Concentre-se nos erros padrão e testes t/F, não no vies pontual do estimador, que permanece consistente.",
                                  "learningObjective": "Identificar e explicar violações de pressupostos relaxados e seus impactos na validade da inferência.",
                                  "commonMistakes": "Confundir inconsistência do estimador com erros padrão incorretos; ignorar que MQO é consistente mesmo sob violações."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir Conceitos de Robust Standard Errors (HCSE)",
                                  "subSteps": [
                                    "Estudar a fórmula dos HCSE de White: Var(β̂) = (X'X/n)^{-1} (∑ u_i² x_i x_i') (X'X/n)^{-1}, robusta à heterocedasticidade.",
                                    "Comparar variantes HC0, HC1, HC2, HC3 e escolher HC3 para amostras finitas por ser menos enviesado.",
                                    "Explicar robustez à não-normalidade via TLC em grandes amostras.",
                                    "Discutir interpretação: coeficientes iguais, mas erros padrão ajustados para variância condicional.",
                                    "Revisar propriedades: validade assintótica dos testes t e F sob pressupostos relaxados."
                                  ],
                                  "verification": "Derivar ou reescrever a fórmula HCSE em termos simples e comparar com erros padrão clássicos em um quadro.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Artigo de White (1980) 'A Heteroskedasticity-Consistent Covariance Matrix Estimator', slides sobre HCSE.",
                                  "tips": "Visualize com gráficos de resíduos vs. fitted values para detectar heterocedasticidade antes de aplicar HCSE.",
                                  "learningObjective": "Dominar a teoria por trás dos HCSE e sua justificativa assintótica.",
                                  "commonMistakes": "Achar que HCSE corrige vies nos coeficientes (eles só ajustam variância); usar HC0 em amostras pequenas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar HCSE em Software Estatístico",
                                  "subSteps": [
                                    "Carregar um dataset grande (n>1000) com potencial heterocedasticidade, como dados de salários.",
                                    "Estimar MQO padrão e extrair erros padrão clássicos.",
                                    "Aplicar HCSE usando pacotes: em R (sandwich::vcovHC(model, type='HC3')), em Python (statsmodels com cov_type='HC3').",
                                    "Calcular intervalos de confiança e p-values robustos; comparar com clássicos.",
                                    "Realizar teste de significância robusto para coeficientes chave."
                                  ],
                                  "verification": "Produzir output de regressão com HCSE e tabela comparativa de erros padrão clássicos vs. robustos.",
                                  "estimatedTime": "2 horas",
                                  "materials": "R ou Python com pacotes (lmtest, sandwich para R; statsmodels para Python), dataset exemplo (Wage dataset do ISLR).",
                                  "tips": "Sempre especifique type='HC3' para finite-sample correction; plote resíduos para validar necessidade.",
                                  "learningObjective": "Executar inferência robusta computacionalmente de forma precisa.",
                                  "commonMistakes": "Esquecer de ajustar graus de liberdade em HC1/HC2/HC3; interpretar mudanças como 'efeito no coeficiente'."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar Robustez da Inferência e Discutir Limitações",
                                  "subSteps": [
                                    "Comparar inferências: verificar se significância muda com HCSE (ex.: p-values aumentam sob heterocedasticidade).",
                                    "Testar heterocedasticidade com Breusch-Pagan ou White test para justificar uso de HCSE.",
                                    "Discutir limitações: HCSE não lida com autocorrelação, clusters ou endogeneidade; sugerir extensões (cluster-robust).",
                                    "Avaliar validade geral: inferência MQO robusta se n grande e só heterocedasticidade/não-normalidade.",
                                    "Concluir com relatório: robustez confirmada ou necessidade de modelos alternativos."
                                  ],
                                  "verification": "Elaborar relatório de 1 página com comparações, testes e conclusões sobre validade da inferência.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Output do Step 3, pacotes para testes (lmtest::bptest em R).",
                                  "tips": "Se erros padrão robustos dobram p-values, a inferência clássica era inválida – destaque isso.",
                                  "learningObjective": "Criticamente avaliar e comunicar a robustez da inferência em contextos reais.",
                                  "commonMistakes": "Concluir robustez sem testar violações; ignorar que HCSE assume independência dos erros."
                                }
                              ],
                              "practicalExample": "Em um dataset de 5000 observações de salários por hora vs. anos de educação e experiência (do pacote ISLR em R), estime MQO. Detecte heterocedasticidade (resíduos com variância crescente em fitted values). Aplique HC3 SE: o coeficiente de educação permanece significativo, mas p-value de experiência muda de 0.03 para 0.07, alterando conclusões sobre impacto relativo.",
                              "finalVerifications": [
                                "Explica corretamente por que HCSE é robusto à heterocedasticidade e não-normalidade em grandes amostras.",
                                "Implementa HCSE em software e compara erros padrão clássicos vs. robustos.",
                                "Interpreta mudanças em intervalos de confiança e p-values robustos.",
                                "Identifica cenários onde HCSE falha (ex.: clusters, autocorrelação).",
                                "Realiza teste de heterocedasticidade para validar necessidade de robustez.",
                                "Discute vantagens assintóticas do MQO sob pressupostos relaxados."
                              ],
                              "assessmentCriteria": [
                                "Precisão teórica na explicação de pressupostos e HCSE (25%)",
                                "Corretude da implementação computacional e outputs (35%)",
                                "Qualidade da interpretação e comparação de inferências (20%)",
                                "Análise crítica de limitações e testes diagnósticos (10%)",
                                "Clareza na comunicação via relatório ou discussão (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria e Estatística Aplicada",
                                "Programação Estatística (R/Python para análise de dados)",
                                "Matemática Computacional (algoritmos de estimação assintótica)",
                                "Economia Empírica (análise de políticas com dados observacionais)"
                              ],
                              "realWorldApplication": "Em avaliações de políticas públicas, como estimar o impacto de programas de capacitação no emprego usando dados administrativos nacionais (n=10k+), onde variância residual varia por região (heterocedasticidade). HCSE garante testes de significância válidos, suportando decisões governamentais baseadas em evidências robustas, evitando políticas ineficazes devido a inferências frágeis."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.3",
                    "name": "Relaxamento do Pressuposto de Homocedasticidade",
                    "description": "Tratamento de erros heterocedásticos nos resíduos da regressão linear.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.3.1",
                        "name": "Heterocedasticidade nos Resíduos da Regressão Linear",
                        "description": "Compreensão do conceito de heterocedasticidade como violação do pressuposto de homocedasticidade nos erros da regressão linear, com foco em grandes amostras e aplicações em econometria para engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.3.1.1",
                            "name": "Definir e identificar heterocedasticidade",
                            "description": "Explicar a diferença entre homocedasticidade e heterocedasticidade, identificando padrões nos resíduos (ex.: dispersão crescente com variáveis explicativas) em gráficos de resíduos vs. ajustados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Básicos de Homocedasticidade e Heterocedasticidade",
                                  "subSteps": [
                                    "Defina homocedasticidade como a condição em que a variância dos resíduos é constante em todos os níveis das variáveis explicativas.",
                                    "Defina heterocedasticidade como a condição oposta, onde a variância dos resíduos varia sistematicamente com as variáveis explicativas.",
                                    "Compare os dois conceitos usando analogias simples, como dispersão uniforme (homo) versus dispersão em funil (hetero).",
                                    "Explique as implicações para inferência estatística em regressão linear.",
                                    "Revise a fórmula matemática: Var(ε|X) = σ² (homo) vs. Var(ε|X) = σ²(X) (hetero)."
                                  ],
                                  "verification": "Escreva definições em suas próprias palavras e forneça um exemplo de cada, confirmando com uma fonte confiável como um livro de econometria.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre pressupostos de regressão linear",
                                    "Gráficos ilustrativos de homocedasticidade e heterocedasticidade",
                                    "Artigo ou vídeo introdutório (ex: Khan Academy ou StatQuest)"
                                  ],
                                  "tips": "Use analogias visuais como 'chuva uniforme' para homocedasticidade e 'megafone' para heterocedasticidade para fixar o conceito.",
                                  "learningObjective": "Compreender precisamente as definições e diferenças entre homocedasticidade e heterocedasticidade no contexto de regressão.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade com autocorrelação nos resíduos.",
                                    "Achar que homocedasticidade é sempre o ideal sem considerar relaxamentos.",
                                    "Ignorar que heterocedasticidade afeta variâncias de estimadores, mas não viés."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Revisar o Conceito e Cálculo de Resíduos em Regressão Linear",
                                  "subSteps": [
                                    "Recapitule resíduos como e_i = y_i - ŷ_i, onde ŷ_i são valores ajustados.",
                                    "Calcule resíduos manualmente para um modelo simples com 5 observações.",
                                    "Implemente o cálculo em Python usando statsmodels ou R com lm().",
                                    "Entenda por que resíduos são centrais para diagnóstico de pressupostos.",
                                    "Padronize resíduos dividindo por desvio padrão para análise."
                                  ],
                                  "verification": "Execute um código simples para calcular e imprimir resíduos de um dataset de exemplo, verificando soma zero e variância.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python ou R com bibliotecas statsmodels, sklearn ou lmtest",
                                    "Dataset simples (ex: mtcars em R ou auto-mpg.csv)",
                                    "Jupyter Notebook ou RStudio"
                                  ],
                                  "tips": "Sempre verifique se resíduos somam zero (propriedade dos Mínimos Quadrados).",
                                  "learningObjective": "Dominar o cálculo e interpretação de resíduos como base para detecção de violações de pressupostos.",
                                  "commonMistakes": [
                                    "Esquecer de subtrair valores ajustados corretamente.",
                                    "Não tratar outliers que distorcem resíduos.",
                                    "Confundir resíduos com erros populacionais."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir e Interpretar o Gráfico de Resíduos vs. Valores Ajustados",
                                  "subSteps": [
                                    "Ajuste um modelo de regressão linear a um dataset.",
                                    "Extraia resíduos e valores ajustados (fitted values).",
                                    "Crie o scatterplot: resíduos no eixo y, fitted no eixo x.",
                                    "Adicione linha horizontal em zero e smooth de tendência (lowess).",
                                    "Analise visualmente por padrões não aleatórios."
                                  ],
                                  "verification": "Gere o gráfico para um dataset conhecido e descreva se há evidência visual de padrões.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Bibliotecas de plotagem: matplotlib/seaborn (Python) ou ggplot2 (R)",
                                    "Dataset com potencial heterocedasticidade (ex: housing prices vs size)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use escala logarítmica no eixo y se dispersão for assimétrica.",
                                  "learningObjective": "Saber gerar e interpretar o gráfico diagnóstico padrão para variância dos resíduos.",
                                  "commonMistakes": [
                                    "Plotar resíduos vs. variável explicativa errada (deve ser fitted).",
                                    "Ignorar escala inadequada que mascara padrões.",
                                    "Não adicionar linha de referência em zero."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar e Diagnosticar Heterocedasticidade nos Gráficos",
                                  "subSteps": [
                                    "Identifique padrão de 'funil' ou dispersão crescente com fitted values altos.",
                                    "Distinga de homocedasticidade (nuvem aleatória sem padrão).",
                                    "Reconheça formas comuns: crescente, decrescente, em U ou quadrática.",
                                    "Aplique teste estatístico complementar como Breusch-Pagan ou White.",
                                    "Documente evidências e sugira remédios como regressão robusta."
                                  ],
                                  "verification": "Analise 3 gráficos fornecidos (1 homo, 2 hetero) e classifique corretamente cada um com justificativa.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Exemplos de gráficos prontos (homo e hetero)",
                                    "Funções de teste: statsmodels.diagnostic.het_breuschpagan (Python)",
                                    "Datasets variados para prática"
                                  ],
                                  "tips": "Procure por variância que 'abre' como um funil ao longo do x-axis.",
                                  "learningObjective": "Identificar visual e estatisticamente heterocedasticidade em resíduos de regressão.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade com não-linearidade (use QQ-plot para normalidade).",
                                    "Concluir baseado em amostra pequena (<30 obs).",
                                    "Ignorar que testes têm poder baixo em heterocedasticidade leve."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários vs. anos de experiência, ajuste regressão linear e plote resíduos vs. fitted values. Observa-se dispersão crescente para altos salários (funil à direita), indicando heterocedasticidade: variância de erro salarial maior para executivos experientes devido a bônus variáveis.",
                              "finalVerifications": [
                                "Define corretamente heterocedasticidade e diferencia de homocedasticidade.",
                                "Calcula resíduos e gera gráfico vs. fitted values sem erros.",
                                "Identifica padrões de funil em exemplos visuais com >80% acurácia.",
                                "Explica implicações para erros padrão e testes de significância.",
                                "Sugere pelo menos duas abordagens para correção (ex: robust SE, WLS).",
                                "Aplica teste Breusch-Pagan e interpreta p-value."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual nas definições (pontos plenos se sem erros).",
                                "Qualidade do gráfico gerado (legendas, escalas corretas, smooth).",
                                "Acurácia na identificação de padrões em 3+ exemplos (90% mínimo).",
                                "Profundidade na interpretação de implicações e remédios.",
                                "Correta implementação de código e testes estatísticos.",
                                "Clareza na comunicação escrita/visual."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Impacto em intervalos de confiança e testes t/F.",
                                "Programação Computacional: Uso de statsmodels ou lmtest para diagnósticos.",
                                "Econometria: Modelos robustos e estimação eficiente sob hetero.",
                                "Machine Learning: Feature engineering e scaling para reduzir hetero.",
                                "Visualização de Dados: Técnicas de scatterplots e diagnóstico gráfico."
                              ],
                              "realWorldApplication": "Em finanças, ao modelar retornos de ações vs. market cap, heterocedasticidade surge com volatilidade crescente para large caps; identificá-la permite usar erros padrão robustos ou GARCH para previsões de risco mais precisas em portfólios."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.1.2",
                            "name": "Analisar consequências para estimadores MCO",
                            "description": "Descrever como a heterocedasticidade afeta a eficiência e a validade da inferência estatística dos estimadores de mínimos quadrados ordinários (MCO), mantendo consistência em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar pressupostos do modelo MCO e o papel da homocedasticidade",
                                  "subSteps": [
                                    "Relembrar os pressupostos clássicos do MCO: linearidade, exogeneidade, homocedasticidade, não autocorrelação e normalidade dos erros.",
                                    "Focar no pressuposto de homocedasticidade: Var(ε_i | X_i) = σ² para todo i.",
                                    "Derivar a variância condicional do estimador MCO sob homocedasticidade: Var(β̂) = σ² (X'X)^{-1}.",
                                    "Explicar por que a homocedasticidade garante eficiência (BLUE - Best Linear Unbiased Estimator).",
                                    "Discutir violações parciais e impactos iniciais."
                                  ],
                                  "verification": "Escrever um resumo de 200 palavras listando os pressupostos MCO e destacando a fórmula de variância sob homocedasticidade.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge), notas de aula sobre MCO, calculadora ou software R/Python para matrizes."
                                  ],
                                  "tips": "Use diagramas para visualizar pressupostos; memorize a fórmula de variância como base para comparações futuras.",
                                  "learningObjective": "Compreender a base teórica do MCO sob pressupostos clássicos, preparando para análise de violações.",
                                  "commonMistakes": [
                                    "Confundir homocedasticidade com normalidade; ignorar que exogeneidade é pressuposto separado."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir e identificar heterocedasticidade nos resíduos",
                                  "subSteps": [
                                    "Definir heterocedasticidade: Var(ε_i | X_i) = σ_i², variando com covariates.",
                                    "Explorar formas comuns: heterocedasticidade multiplicativa σ_i² = σ² h(X_i), ou dependente de |u_i|.",
                                    "Aprender testes de detecção: Breusch-Pagan, White, Goldfeld-Quandt.",
                                    "Simular dados com e sem heterocedasticidade em R/Python para visualização gráfica (scatter de resíduos vs fitted).",
                                    "Interpretar gráficos de resíduos para padrões em forma de funil."
                                  ],
                                  "verification": "Gerar um gráfico de resíduos de uma simulação heterocedástica e identificar o padrão visualmente.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software R (pacote lmtest), Python (statsmodels), dados simulados via script fornecido."
                                  ],
                                  "tips": "Sempre plote resíduos vs fitted values primeiro; use log-likelihood para testes formais.",
                                  "learningObjective": "Identificar conceitual e empiricamente quando ocorre heterocedasticidade.",
                                  "commonMistakes": [
                                    "Assumir heterocedasticidade só em grandes datasets; confundir com não linearidade."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar impacto na eficiência dos estimadores MCO",
                                  "subSteps": [
                                    "Derivar variância sob heterocedasticidade: Var(β̂) = (X'X)^{-1} X' Ω X (X'X)^{-1}, onde Ω é diagonal com σ_i².",
                                    "Comparar com homocedasticidade: MCO ainda não viesado e consistente, mas não eficiente (variância maior).",
                                    "Calcular numericamente a variância sandwich (White) para estimadores robustos.",
                                    "Comparar eficiência relativa via simulações Monte Carlo (MSE de β̂).",
                                    "Explicar por que GLS seria eficiente, mas requer conhecimento de Ω."
                                  ],
                                  "verification": "Calcular manualmente Var(β̂) para um modelo simples com σ_i² conhecida e comparar com homocedasticidade.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Matriz algebra software (Mathematica ou Python numpy), exemplos numéricos de Wooldridge."
                                  ],
                                  "tips": "Comece com modelo univariado para simplificar matrizes; foque em diagonal de Ω.",
                                  "learningObjective": "Quantificar perda de eficiência devido à heterocedasticidade.",
                                  "commonMistakes": [
                                    "Pensar que MCO é viesado sob heterocedasticidade; ignorar consistência assintótica."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar impactos na inferência estatística e consistência assintótica",
                                  "subSteps": [
                                    "Explicar invalidação de inferência clássica: erros padrão subestimados, testes t/F com tamanho distorcido.",
                                    "Introduzir erros padrão robustos (HC0, HC1, etc.) para inferência válida.",
                                    "Provar consistência de β̂: plim β̂ = β mesmo com heterocedasticidade (SLUTsky e LLN).",
                                    "Simular rejeições de H0 sob heterocedasticidade com e sem robustez.",
                                    "Discutir implicações práticas: confiança intervals inválidos sem correção."
                                  ],
                                  "verification": "Executar simulação mostrando taxa de rejeição >5% para teste t clássico em dados heterocedásticos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R (sandwich package), Python (statsmodels robust cov), scripts de simulação."
                                  ],
                                  "tips": "Use seed para reprodutibilidade em simulações; compare p-values clássicos vs robustos.",
                                  "learningObjective": "Diferenciar impactos em point estimates (consistentes) vs inferência (inválida sem robustez).",
                                  "commonMistakes": [
                                    "Confundir consistência com eficiência; achar que robustez resolve viés (não resolve)."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma regressão de salário (Y) sobre anos de educação (X), resíduos têm variância crescente com X (pessoas mais educadas têm salários mais variáveis). Simule dados: ε_i ~ N(0, (X_i)^2), estime MCO, plote resíduos (funil), calcule Var(β̂) clássica vs sandwich, e teste H0: β_edu=0 – observe rejeição inflada sem robustez.",
                              "finalVerifications": [
                                "Explicar verbalmente por que MCO é consistente mas não eficiente sob heterocedasticidade.",
                                "Derivar fórmula de variância robusta para um modelo simples.",
                                "Interpretar output de regressão com erros padrão HC1 em software.",
                                "Identificar heterocedasticidade em gráfico de resíduos real.",
                                "Simular e reportar taxa de rejeição de teste t sob violação.",
                                "Comparar eficiência MCO vs GLS em Monte Carlo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de Var(β̂) sob heterocedasticidade (fórmula correta).",
                                "Correta distinção entre viés, consistência, eficiência e inferência válida.",
                                "Qualidade de simulações: reprodutíveis, com n grande para assintóticas.",
                                "Interpretação correta de testes e gráficos de resíduos.",
                                "Uso apropriado de erros padrão robustos em exemplos.",
                                "Conexão clara entre teoria e prática em explicações."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Aplicação em modelos de painel e IV com robustez.",
                                "Ciência de Dados: Machine Learning regressão com heteroscedasticity-robust SE.",
                                "Finanças: Modelos CAPM com variância condicional (GARCH).",
                                "Estatística Bayesiana: Priors para variância heterogênea.",
                                "Computação Científica: Otimização numérica de GLS."
                              ],
                              "realWorldApplication": "Em análises econômicas como previsão de salários ou retornos de ações, onde variância de erros aumenta com tamanho da firma ou volatilidade de mercado; usar erros padrão robustos evita conclusões erradas sobre significância de políticas públicas ou investimentos."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.1.3",
                            "name": "Visualizar heterocedasticidade em dados reais",
                            "description": "Construir e interpretar gráficos de resíduos (resíduos vs. ajustados e escala-resíduos) para detectar heterocedasticidade em conjuntos de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o Conjunto de Dados de Engenharia",
                                  "subSteps": [
                                    "Selecione um dataset real de engenharia, como medições de tensão vs. carga em materiais (ex: dados de fadiga em aço).",
                                    "Carregue os dados usando pandas em Python: pd.read_csv('engenharia_dados.csv').",
                                    "Explore os dados com .describe(), .plot() para scatter inicial e verifique outliers ou missing values.",
                                    "Limpe os dados: remova ou imputa valores ausentes com .dropna() ou .fillna().",
                                    "Defina variáveis: X (independente, ex: carga) e y (dependente, ex: tensão)."
                                  ],
                                  "verification": "Dataset carregado e limpo, com shape() e head() mostrando dados prontos sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com pandas, matplotlib, seaborn instalados",
                                    "Dataset CSV de engenharia (ex: fadiga_materiais.csv)"
                                  ],
                                  "tips": "Sempre visualize os dados brutos primeiro para entender a dispersão.",
                                  "learningObjective": "Preparar dados reais de engenharia para análise de regressão.",
                                  "commonMistakes": [
                                    "Ignorar missing values levando a erros no modelo",
                                    "Não escalar variáveis com unidades diferentes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Ajustar o Modelo de Regressão Linear",
                                  "subSteps": [
                                    "Importe statsmodels: from statsmodels.formula.api import ols.",
                                    "Crie o modelo: model = ols('tensao ~ carga', data=df).fit().",
                                    "Obtenha summary com model.summary() para verificar R² e p-values.",
                                    "Extraia valores ajustados: fitted_values = model.fittedvalues.",
                                    "Calcule resíduos iniciais: residuals = model.resid."
                                  ],
                                  "verification": "Modelo ajustado com summary() mostrando coeficientes significativos e R² > 0.7.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Biblioteca statsmodels",
                                    "Jupyter Notebook ou script Python"
                                  ],
                                  "tips": "Use fórmula API para simplicidade em regressões simples.",
                                  "learningObjective": "Construir um modelo de regressão linear robusto em dados de engenharia.",
                                  "commonMistakes": [
                                    "Não verificar multicolinearidade em múltiplas variáveis",
                                    "Interpretar R² alto como garantia de homocedasticidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir Gráficos de Resíduos vs. Ajustados",
                                  "subSteps": [
                                    "Crie o gráfico padrão: plt.scatter(fitted_values, residuals).",
                                    "Adicione linha horizontal em y=0: plt.axhline(y=0, color='r', linestyle='--').",
                                    "Melhore visual: plt.xlabel('Valores Ajustados'), plt.ylabel('Resíduos'), plt.title('Resíduos vs Ajustados').",
                                    "Salve ou mostre: plt.savefig('residuos_vs_ajustados.png') ou plt.show().",
                                    "Analise padrão: procure funil (dispersão crescente) indicando heterocedasticidade."
                                  ],
                                  "verification": "Gráfico gerado sem erros, com eixos rotulados e linha de referência visível.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Matplotlib ou seaborn para plotting"
                                  ],
                                  "tips": "Use escala log nos resíduos se dispersão for muito variada.",
                                  "learningObjective": "Gerar gráfico diagnóstico chave para detecção visual de heterocedasticidade.",
                                  "commonMistakes": [
                                    "Escala inadequada escondendo o padrão de funil",
                                    "Não padronizar resíduos antes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir e Interpretar Gráfico de Escala-Resíduos",
                                  "subSteps": [
                                    "Calcule escala-resíduos: scale_resid = residuals / np.sqrt(model.mse_resid).",
                                    "Plote: plt.scatter(fitted_values, scale_resid).",
                                    "Adicione bandas de confiança aproximadas: ±2 para normalidade.",
                                    "Identifique heterocedasticidade: dispersão não constante em magnitude.",
                                    "Compare com gráfico anterior e anote observações em relatório."
                                  ],
                                  "verification": "Gráfico de escala-resíduos plotado com bandas e interpretação escrita.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "NumPy para cálculos",
                                    "Matplotlib"
                                  ],
                                  "tips": "Escala-resíduos ajuda a normalizar para melhor detecção.",
                                  "learningObjective": "Usar escala-resíduos para confirmação robusta de heterocedasticidade.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade com não-normalidade",
                                    "Ignorar direção do funil (crescente/decrescente)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar e Documentar Detecção de Heterocedasticidade",
                                  "subSteps": [
                                    "Descreva padrões: 'Dispersão crescente com valores ajustados altos indica heterocedasticidade.'",
                                    "Teste qualitativo: meça largura de faixas em quartis dos ajustados.",
                                    "Sugira correções: use regressão ponderada ou transformações (log).",
                                    "Gere relatório: inclua gráficos e conclusões em Markdown ou PDF.",
                                    "Valide com teste formal como Breusch-Pagan para confirmação."
                                  ],
                                  "verification": "Relatório com interpretação clara e sugestões de correção.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Statsmodels para testes adicionais",
                                    "Jupyter para relatório"
                                  ],
                                  "tips": "Combine visual com testes estatísticos para robustez.",
                                  "learningObjective": "Interpretar gráficos para diagnosticar violações de homocedasticidade em contextos reais.",
                                  "commonMistakes": [
                                    "Declarar homocedasticidade sem zoom em regiões críticas",
                                    "Não contextualizar com domínio de engenharia"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de testes de fadiga em vigas de aço (carga aplicada vs. deformação medida), o gráfico de resíduos vs. ajustados mostra dispersão crescente em cargas altas, indicando heterocedasticidade devido a não-linearidades materiais. O gráfico de escala-resíduos confirma funil, levando à recomendação de modelo GLS.",
                              "finalVerifications": [
                                "Gráficos de resíduos vs. ajustados e escala-resíduos gerados corretamente.",
                                "Identificação precisa de padrão de funil ou dispersão constante.",
                                "Interpretação escrita explicando evidência de heterocedasticidade.",
                                "Sugestões de correção como transformações ou modelos robustos.",
                                "Relatório com código reproduzível e visualizações salvas.",
                                "Validação cruzada com teste estatístico (ex: Breusch-Pagan p-value < 0.05)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na construção dos gráficos (rótulos, escalas corretas): 20%",
                                "Detecção correta de heterocedasticidade via padrões visuais: 25%",
                                "Profundidade da interpretação e ligação com dados de engenharia: 20%",
                                "Qualidade do código Python (limpo, comentado): 15%",
                                "Relatório completo com exemplos e correções sugeridas: 10%",
                                "Uso de boas práticas (padronização, verificações): 10%"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes formais de heterocedasticidade (Breusch-Pagan, White).",
                                "Programação: Manipulação de dados com pandas e visualização com matplotlib/seaborn.",
                                "Engenharia: Aplicação em análise de falhas materiais e controle de qualidade.",
                                "Matemática: Propriedades de variância condicional em regressão."
                              ],
                              "realWorldApplication": "Em engenharia civil, detectar heterocedasticidade em dados de sensores de pontes permite modelos de previsão de manutenção mais precisos, evitando falhas catastróficas ao corrigir pressupostos relaxados em regressões de monitoramento estrutural."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.3.2",
                        "name": "Testes de Diagnóstico para Heterocedasticidade",
                        "description": "Aplicação de testes estatísticos formais para detectar heterocedasticidade nos resíduos, relaxando pressupostos clássicos da regressão linear.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.3.2.1",
                            "name": "Realizar teste de Breusch-Pagan",
                            "description": "Executar e interpretar o teste de Breusch-Pagan para verificar se os quadrados dos resíduos são função linear das variáveis independentes, calculando estatística qui-quadrado e p-valor.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Ajustar o modelo de regressão linear ordinária (OLS) e extrair resíduos",
                                  "subSteps": [
                                    "Carregue o dataset usando pandas (ex: dados de regressão com variáveis dependente y e independentes X).",
                                    "Ajuste o modelo OLS usando statsmodels: sm.OLS(y, X).fit().",
                                    "Extraia os resíduos do modelo ajustado: model.resid.",
                                    "Verifique estatísticas básicas dos resíduos (média próxima de zero, plot de resíduos vs fitted).",
                                    "Salve os resíduos em uma variável para uso posterior."
                                  ],
                                  "verification": "Confirme que o modelo OLS foi ajustado com R-quadrado razoável e resíduos extraídos sem erros (len(resid) == len(y)).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com pandas, statsmodels e matplotlib instalados",
                                    "Dataset exemplo (ex: Boston Housing via sklearn.datasets.load_boston)"
                                  ],
                                  "tips": "Sempre centre as variáveis independentes se necessário para estabilidade numérica.",
                                  "learningObjective": "Compreender a obtenção de resíduos como base para testes de diagnóstico.",
                                  "commonMistakes": [
                                    "Esquecer de adicionar constante (sm.add_constant(X))",
                                    "Usar resíduos brutos em vez de padronizados",
                                    "Não verificar multicolinearidade antes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os quadrados dos resíduos e preparar regressão auxiliar",
                                  "subSteps": [
                                    "Calcule os quadrados dos resíduos: resid_squared = resid**2.",
                                    "Prepare a matriz de variáveis independentes para a regressão auxiliar: X_aux = sm.add_constant(X).",
                                    "Normalize os quadrados dos resíduos se o software exigir (opcional, mas comum).",
                                    "Crie um DataFrame com resid_squared como y_aux e X_aux.",
                                    "Visualize correlação entre resid_squared e X para intuição."
                                  ],
                                  "verification": "Verifique que resid_squared tem variância positiva e correlação não nula com pelo menos uma variável em X.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Mesmo ambiente Python do step 1",
                                    "Jupyter Notebook para plots"
                                  ],
                                  "tips": "Use np.log(resid_squared + 1e-8) se houver zeros para evitar log(0).",
                                  "learningObjective": "Entender que heterocedasticidade implica variância dos resíduos dependente de X.",
                                  "commonMistakes": [
                                    "Não adicionar constante na X_aux",
                                    "Usar resíduos em vez de quadrados",
                                    "Ignorar valores negativos nos quadrados (impossível se correto)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar a regressão auxiliar e calcular a estatística qui-quadrado",
                                  "subSteps": [
                                    "Ajuste o modelo auxiliar: aux_model = sm.OLS(resid_squared, X_aux).fit().",
                                    "Calcule a estatística LM de Breusch-Pagan: LM = n * R2_aux, onde n=len(y), R2_aux=aux_model.rsquared.",
                                    "Calcule a estatística qui-quadrado: chisq = LM.",
                                    "Obtenha o p-valor: from scipy.stats import chi2; p_value = 1 - chi2.cdf(chisq, df=len(X[0])).",
                                    "Use função pronta para validação: from statsmodels.stats.diagnostic import breuschpagan; bp_test = breuschpagan(resid, X)."
                                  ],
                                  "verification": "Compare resultado manual com função bp_test; p-valor deve coincidir.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "SciPy instalado",
                                    "Código do step anterior"
                                  ],
                                  "tips": "Graus de liberdade = número de variáveis independentes (excluindo constante).",
                                  "learningObjective": "Dominar o cálculo da estatística de teste sob H0: homocedasticidade.",
                                  "commonMistakes": [
                                    "Usar t-test em vez de qui-quadrado",
                                    "df incorreto (incluir constante)",
                                    "Esquecer multiplicar R2 por n"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e concluir sobre heterocedasticidade",
                                  "subSteps": [
                                    "Compare p-valor com nível de significância (ex: 0.05): se p < alpha, rejeite H0 (heterocedasticidade).",
                                    "Reporte estatística qui-quadrado, df e p-valor.",
                                    "Gere plot de resíduos vs fitted colorido por variável suspeita.",
                                    "Discuta implicações: se hetero, use erros padrão robustos (HC).",
                                    "Documente em relatório: 'Teste BP indica heterocedasticidade (p=0.01).'."
                                  ],
                                  "verification": "Conclusão lógica: hetero se p<0.05; valide com plot de scale-location.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Seaborn ou matplotlib para plots avançados"
                                  ],
                                  "tips": "Sempre reporte tanto estatística quanto p-valor para contexto.",
                                  "learningObjective": "Interpretar teste no contexto de pressupostos de regressão.",
                                  "commonMistakes": [
                                    "Inverter H0/H1 (H0=homocedasticidade)",
                                    "Ignorar poder do teste em amostras pequenas",
                                    "Concluir sem plot de suporte"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários vs experiência e educação (n=1000), após OLS de salário ~ exp + edu, calcule BP: obtém chisq=12.5, df=2, p=0.002 → evidência de heterocedasticidade; use regressão robusta.",
                              "finalVerifications": [
                                "Modelo OLS ajustado com resíduos extraídos corretamente.",
                                "Regressão auxiliar produz R2 >0 e LM calculada.",
                                "Estatística qui-quadrado e p-valor coincidem com função statsmodels.breuschpagan.",
                                "Interpretação correta: rejeição H0 se p<0.05.",
                                "Plot de resíduos confirma visualmente o resultado.",
                                "Relatório inclui todos valores numéricos."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo da estatística LM (erro <1%).",
                                "Correta determinação de graus de liberdade.",
                                "Interpretação inequívoca do p-valor.",
                                "Uso apropriado de função pronta para validação.",
                                "Identificação de implicações para modelo (ex: robust SE).",
                                "Qualidade dos plots de diagnóstico."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipótese qui-quadrado.",
                                "Programação Computacional: Manipulação de dados em Python/statsmodels.",
                                "Econometria: Diagnóstico de regressão.",
                                "Visualização de Dados: Plots de resíduos.",
                                "Matemática Aplicada: Propriedades de variância condicional."
                              ],
                              "realWorldApplication": "Em análises financeiras, como prever retornos de ações com regressão, o teste BP detecta heterocedasticidade (volatilidade variável), permitindo correções com erros padrão robustos para previsões confiáveis em trading algorítmico."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.2.2",
                            "name": "Aplicar teste de White",
                            "description": "Implementar o teste de White para heterocedasticidade geral, incluindo termos cruzados, e discutir sua robustez em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e ajustar modelo de regressão principal",
                                  "subSteps": [
                                    "Carregue o conjunto de dados relevante (ex: salários vs anos de educação).",
                                    "Especifique e ajuste o modelo de regressão linear OLS usando software como R ou Python (statsmodels ou lm).",
                                    "Extraia os resíduos padronizados e calcule os resíduos ao quadrado (e_í²).",
                                    "Verifique suposições básicas como normalidade dos resíduos com testes auxiliares.",
                                    "Salve predições do modelo (y_hat) para uso posterior."
                                  ],
                                  "verification": "Modelo ajustado com resíduos calculados e salvos; verifique sumário do modelo (R², coeficientes).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Conjunto de dados (ex: dataset de salários CSV)",
                                    "Software: R (lm function) ou Python (statsmodels)",
                                    "Documentação de regressão OLS"
                                  ],
                                  "tips": "Use dados com pelo menos 100 observações para robustez; padronize variáveis se necessário.",
                                  "learningObjective": "Compreender e implementar regressão OLS como base para testes diagnósticos.",
                                  "commonMistakes": [
                                    "Esquecer de centralizar variáveis",
                                    "Usar resíduos não-padronizados",
                                    "Ignorar multicolinearidade nos regressores"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir regressores auxiliares para o teste de White",
                                  "subSteps": [
                                    "Crie termos quadráticos: X² para cada regressor X no modelo principal.",
                                    "Gere termos cruzados: produtos entre pares de regressores distintos (X_i * X_j).",
                                    "Inclua termos de interação com constantes se aplicável (ex: X_i * constante).",
                                    "Forme a matriz de regressores auxiliares Z = [1, X, X², XZ] onde Z são subconjuntos.",
                                    "Verifique dimensões da matriz Z para evitar explosão dimensional."
                                  ],
                                  "verification": "Matriz Z construída com dimensões corretas (n x k, onde k <= n/10); visualize com head() ou describe().",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código R/Python para geração de polinômios (poly() em R, PolynomialFeatures em sklearn)",
                                    "Resíduos do Step 1"
                                  ],
                                  "tips": "Limite interações para evitar overfitting; use fórmula automática para White test em pacotes.",
                                  "learningObjective": "Dominar construção de regressores não-lineares para detectar heterocedasticidade geral.",
                                  "commonMistakes": [
                                    "Incluir apenas quadráticos sem cruzados",
                                    "Gerar termos redundantes levando a singularidade",
                                    "Esquecer intercepto"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar modelo auxiliar e calcular estatística do teste",
                                  "subSteps": [
                                    "Ajuste regressão auxiliar: e_í² ~ Z usando OLS.",
                                    "Calcule R² auxiliar e estatística LM = n * R²_aux.",
                                    "Determine graus de liberdade: df = k_aux - 1, onde k_aux é número de regressores em Z.",
                                    "Compute p-valor via distribuição qui-quadrado (χ²(df)).",
                                    "Implemente via função pronta (ex: bptest() em lmtest R) para validação."
                                  ],
                                  "verification": "Estatística LM e p-valor calculados; compare com output de função built-in.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacotes: lmtest (R), statsmodels (Python)",
                                    "Função qui-quadrado (pchisq() R, chi2.sf() Python)"
                                  ],
                                  "tips": "Registre R² para todos os passos; use robust SE se necessário.",
                                  "learningObjective": "Executar regressão auxiliar e derivar teste LM para heterocedasticidade.",
                                  "commonMistakes": [
                                    "Usar R² do modelo principal em vez de auxiliar",
                                    "Erro em df (contar intercepto errado)",
                                    "Confundir com teste Breusch-Pagan"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e discutir robustez",
                                  "subSteps": [
                                    "Interprete: rejeite H0 (homocedasticidade) se p < 0.05.",
                                    "Discuta poder do teste: alto em grandes amostras (n>500) devido a consistência assintótica.",
                                    "Analise limitações: sensível a não-normalidade, poder baixo em amostras pequenas.",
                                    "Sugira correções: HC SE ou modelos GARCH se heterocedasticidade detectada.",
                                    "Documente relatório com gráficos de resíduos vs fitted."
                                  ],
                                  "verification": "Relatório escrito com interpretação, p-valor, e discussão de robustez; gráfico de resíduos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Ferramentas de plot: ggplot2 (R), matplotlib/seaborn (Python)",
                                    "Template de relatório"
                                  ],
                                  "tips": "Sempre plote resíduos para visualização intuitiva.",
                                  "learningObjective": "Avaliar validade do teste e implicações em inferência robusta.",
                                  "commonMistakes": [
                                    "Ignorar tamanho amostral na interpretação",
                                    "Confundir robustez com poder do teste",
                                    "Não sugerir remédios"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (y) vs educação (X1) e experiência (X2), ajuste y ~ X1 + X2. Calcule resíduos², construa Z = [1, X1, X2, X1², X2², X1*X2], teste LM= n*R²_aux ~ χ²(5). Se p<0.05, evidência de heterocedasticidade; use HC1 SE para correção.",
                              "finalVerifications": [
                                "Modelo auxiliar ajustado sem erros de singularidade.",
                                "Estatística LM e p-valor coincidem com função built-in (±0.01).",
                                "Gráfico de resíduos vs fitted mostra padrões não-aleatórios se p<0.05.",
                                "Discussão inclui robustez assintótica para n>1000.",
                                "Sugestões de correção (ex: robust SE) listadas.",
                                "Relatório completo com código reproduzível."
                              ],
                              "assessmentCriteria": [
                                "Precisão na construção de Z (todos termos cruzados incluídos corretamente).",
                                "Cálculo correto de LM e p-valor (erro <1%).",
                                "Interpretação adequada do p-valor e implicações para inferência.",
                                "Análise de robustez com referência a propriedades assintóticas.",
                                "Uso de visualizações para apoiar conclusões.",
                                "Clareza no relatório e código comentado."
                              ],
                              "crossCurricularConnections": [
                                "Programação Estatística: Implementação em R/Python reforça skills de data science.",
                                "Inferência Estatística: Liga a testes qui-quadrado e LM em econometria.",
                                "Matemática Avançada: Polinômios e expansões Taylor para modelagem não-linear.",
                                "Análise de Dados: Diagnósticos em machine learning (ex: validação de resíduos em regressão)."
                              ],
                              "realWorldApplication": "Em finanças, testar heterocedasticidade em retornos de ações para modelos de risco (VaR); em econometria, validar regressões de impacto de políticas públicas em grandes datasets governamentais, garantindo inferência robusta."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.3.3",
                        "name": "Tratamentos e Correções para Erros Heterocedásticos",
                        "description": "Métodos para corrigir a heterocedasticidade, como erros padrão robustos, garantindo inferência válida em regressões com pressupostos relaxados.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.3.3.1",
                            "name": "Calcular erros padrão robustos de White",
                            "description": "Derivar e computar o estimador 'sandwich' (HC0 ou HC1) para variância-covariância robusta a heterocedasticidade, ajustando intervalos de confiança e testes t/F.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos do Estimador Sandwich de White",
                                  "subSteps": [
                                    "Revise o estimador de variância-covariância OLS padrão sob homocedasticidade: Var(β̂) = σ² (X'X)^{-1}.",
                                    "Identifique o problema da heterocedasticidade: Var(ε_i) = σ_i² ≠ σ², invalidando inferências.",
                                    "Introduza o estimador 'sandwich': 'Bread' (X'X/n)^{-1}, 'Meat' (sum u_i² x_i x_i'), 'Bread' novamente.",
                                    "Diferencie HC0 (meat simples) de HC1 (meat ajustado por n/(n-k)).",
                                    "Discuta impacto em erros padrão, intervalos de confiança e testes t/F."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito os componentes do sandwich e por que ele é robusto.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão OLS",
                                    "Artigo original de White (1980)",
                                    "Calculadora ou papel para anotações"
                                  ],
                                  "tips": "Visualize o 'sandwich' como pão (bread) envolvendo carne (meat) para lembrar a estrutura.",
                                  "learningObjective": "Entender conceitualmente o estimador sandwich e sua robustez à heterocedasticidade.",
                                  "commonMistakes": [
                                    "Confundir HC0 com HC1 sem notar o ajuste de graus de liberdade.",
                                    "Ignorar a divisão por n na bread.",
                                    "Achar que sandwich corrige autocorrelação (apenas heterocedasticidade)."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Fórmula Matemática do Estimador HC0 e HC1",
                                  "subSteps": [
                                    "Derive o bread: (X'X/n)^{-1}.",
                                    "Calcule resíduos OLS: û_i = y_i - x_i' β̂ para cada observação.",
                                    "Construa a meat para HC0: (1/n) sum (û_i² x_i x_i').",
                                    "Ajuste para HC1: meat = (n/(n-K)) * HC0 meat, onde K é número de parâmetros.",
                                    "Monte a matriz completa: V = bread * meat * bread.",
                                    "Extraia erros padrão: diag(sqrt(V))."
                                  ],
                                  "verification": "Escreva as fórmulas completas e verifique com um exemplo numérico pequeno (n=3).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Lápis e papel",
                                    "Software simbólico como SymPy (opcional)",
                                    "Matriz de exemplo 3x3"
                                  ],
                                  "tips": "Use notação matricial consistente; teste derivação com dados simulados simples.",
                                  "learningObjective": "Derivar analiticamente o estimador sandwich HC0/HC1 a partir dos resíduos OLS.",
                                  "commonMistakes": [
                                    "Esquecer de elevar resíduos ao quadrado na meat.",
                                    "Não inverter corretamente o bread.",
                                    "Confundir normalização por n vs n-1."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar o Cálculo Manual em Python",
                                  "subSteps": [
                                    "Carregue dados com pandas (ex: dataset com y, X incluindo intercepto).",
                                    "Ajuste OLS manualmente: β̂ = (X'X)^{-1} X'y usando numpy.",
                                    "Compute resíduos û = y - X β̂.",
                                    "Construa bread = np.linalg.inv(X.T @ X / n).",
                                    "Construa meat HC0 = (û**2[:,None] * X.T @ X) / n; ajuste para HC1.",
                                    "V = bread @ meat @ bread; erros = np.sqrt(np.diag(V))."
                                  ],
                                  "verification": "Execute código e compare erros padrão com implementação manual vs pacote.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python 3+",
                                    "numpy",
                                    "pandas",
                                    "statsmodels",
                                    "Dataset exemplo (ex: wages.csv)"
                                  ],
                                  "tips": "Sempre centralize X com intercepto; use broadcasting numpy para eficiência.",
                                  "learningObjective": "Implementar computacionalmente o estimador sandwich do zero em Python.",
                                  "commonMistakes": [
                                    "Esquecer de adicionar coluna de 1s para intercepto em X.",
                                    "Não reshape resíduos para broadcasting.",
                                    "Erro em np.linalg.inv com matrizes singulares."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Erros Padrão Robustos para Inferência Estatística",
                                  "subSteps": [
                                    "Use statsmodels para comparar: sm.OLS(..., cov_type='HC0' ou 'HC1').",
                                    "Ajuste intervalos de confiança: β̂ ± t_{n-k, 0.975} * se_robust.",
                                    "Realize testes t: t = β̂ / se_robust; compare p-values com OLS padrão.",
                                    "Execute teste F robusto para modelo completo.",
                                    "Interprete mudanças: erros maiores sob hetero tipicamente ampliam IC."
                                  ],
                                  "verification": "Gere tabela de resultados com IC e p-values robustos; valide consistência numérica.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels",
                                    "scipy.stats para t-dist",
                                    "Jupyter notebook"
                                  ],
                                  "tips": "Plot resíduos vs fitted para visualizar hetero antes/depois.",
                                  "learningObjective": "Usar erros robustos para ajustar inferências válidas em dados heterocedásticos.",
                                  "commonMistakes": [
                                    "Usar distribuição normal em vez de t para IC em amostras finitas.",
                                    "Ignorar mudança em significância de coeficientes.",
                                    "Confundir cov_type='HC0' com 'HC3' em statsmodels."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (y) vs anos de educação e experiência (X), ajuste regressão OLS. Detecte hetero via Breusch-Pagan. Compute erros HC1: coef educação sobe de se=0.5 (OLS) para 0.7 (robust), alterando p-value de 0.01 para 0.03. Ajuste IC: [2.1, 4.3] vs [1.8, 4.6]; teste F rejeita modelo nulo com stat=15.2 (p<0.01).",
                              "finalVerifications": [
                                "Deriva corretamente bread, meat e V sandwich para HC0/HC1.",
                                "Implementação manual em Python reproduz erros de statsmodels (erro <1e-6).",
                                "IC e p-values robustos diferem logicamente de OLS em dados hetero.",
                                "Teste F robusto é computado e interpretado.",
                                "Resíduos plotados confirmam hetero.",
                                "Código é reproduzível e comentado."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática da derivação (100% fórmulas corretas).",
                                "Funcionalidade e eficiência do código Python (roda sem erros, <5s).",
                                "Interpretação correta de mudanças em se, IC e p-values.",
                                "Validação cruzada com pacotes padrão (statsmodels/sklearn).",
                                "Clareza na documentação e visualizações (plots de resíduos/IC).",
                                "Tratamento edge cases (ex: multicolinearidade leve)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência robusta e testes de hipóteses.",
                                "Programação: Manipulação matricial em NumPy e modelagem em Statsmodels.",
                                "Econometria: Modelos de regressão em painéis e séries temporais.",
                                "Machine Learning: Regularização e validação cruzada para heteroscedasticidade.",
                                "Ciência de Dados: Pré-processamento e diagnóstico de modelos."
                              ],
                              "realWorldApplication": "Em finanças, calcular retornos de ações com erros robustos para prever riscos sob volatilidade (hetero); em políticas públicas, avaliar impacto de programas educacionais em salários regionais, onde variância difere por estado, garantindo inferências confiáveis para decisões baseadas em evidências."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.3.2",
                            "name": "Implementar Mínimos Quadrados Ponderados (MQP)",
                            "description": "Estimar pesos inversos à variância dos erros e aplicar regressão MQP para corrigir heterocedasticidade conhecida ou estimada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Avaliar Heterocedasticidade nos Resíduos do Modelo OLS",
                                  "subSteps": [
                                    "Ajuste um modelo de regressão linear ordinária (OLS) aos dados usando uma biblioteca como statsmodels em Python.",
                                    "Extraia os resíduos do modelo ajustado.",
                                    "Plote os resíduos versus os valores preditos ou uma variável explicativa para visualizar padrões de dispersão crescente/decrescente.",
                                    "Aplique testes formais como Breusch-Pagan ou White para confirmar heterocedasticidade (p-valor < 0.05).",
                                    "Registre o tipo de heterocedasticidade observada (ex.: variância crescente com o nível da variável)."
                                  ],
                                  "verification": "Gráficos de resíduos mostram dispersão não constante e testes rejeitam homocedasticidade.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python (statsmodels, matplotlib, scipy), dataset com heterocedasticidade conhecida (ex.: dados de salários vs. experiência).",
                                  "tips": "Use escala logarítmica no eixo y do plot de resíduos se variâncias forem proporcionais ao quadrado dos preditos.",
                                  "learningObjective": "Identificar e quantificar heterocedasticidade nos resíduos de um modelo OLS.",
                                  "commonMistakes": "Ignorar testes formais e confiar apenas em gráficos visuais; confundir heterocedasticidade com não-linearidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar Variâncias dos Erros para Cada Observação",
                                  "subSteps": [
                                    "Agrupe os dados por níveis discretos de uma variável proxy para variância (ex.: bins de valores preditos).",
                                    "Calcule a variância amostral dos resíduos em cada grupo/bin.",
                                    "Estime a variância para observações fora dos grupos via interpolação ou modelo auxiliar (ex.: regressão dos resíduos quadrados sobre preditos).",
                                    "Ajuste um modelo de variância: Var(ε_i) = σ² * x_i^δ, estime δ via MLE ou OLS nos resíduos quadrados.",
                                    "Valide a estimativa plotando variâncias estimadas vs. observadas."
                                  ],
                                  "verification": "Variâncias estimadas correlacionam fortemente (R² > 0.8) com variâncias amostrais agrupadas.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Python (numpy, pandas, statsmodels), mesmo dataset do Step 1.",
                                  "tips": "Use np.var(ddof=1) para variância amostral não viesada em grupos pequenos.",
                                  "learningObjective": "Estimar variâncias heterocedásticas de forma empírica e robusta.",
                                  "commonMistakes": "Usar variância global única em vez de por observação; grupos muito pequenos levando a estimativas instáveis."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Pesos e Aplicar Regressão Mínimos Quadrados Ponderados (MQP)",
                                  "subSteps": [
                                    "Compute pesos w_i = 1 / Var(ε_i) para cada observação i.",
                                    "Ajuste o modelo MQP usando weights=w no statsmodels (sm.WLS(y, X, weights=w)).",
                                    "Extraia coeficientes, erros-padrão e estatísticas do modelo ponderado.",
                                    "Compare com OLS: verifique se erros-padrão ponderados são menores.",
                                    "Salve o modelo para avaliação posterior."
                                  ],
                                  "verification": "Modelo MQP roda sem erros e coeficientes diferem logicamente do OLS.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python (statsmodels), pesos calculados do Step 2.",
                                  "tips": "Normalize pesos se magnitudes variam muito para evitar overflow numérico (w = w / mean(w)).",
                                  "learningObjective": "Implementar corretamente a regressão ponderada com pesos inversos à variância.",
                                  "commonMistakes": "Esquecer de usar weights no ajuste; inverter pesos (usar variância em vez de inverso)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e Interpretar o Modelo MQP",
                                  "subSteps": [
                                    "Plote resíduos ponderados vs. preditos para checar homocedasticidade corrigida.",
                                    "Aplique testes Breusch-Pagan nos resíduos ponderados (deve falhar em rejeitar H0 agora).",
                                    "Compare métricas: R² ajustado, AIC, erros-padrão de coeficientes entre OLS e MQP.",
                                    "Realize predições out-of-sample em conjunto de teste e avalie RMSE.",
                                    "Interprete impactos: como a correção afeta inferências sobre coeficientes."
                                  ],
                                  "verification": "Resíduos ponderados homocedásticos (teste p-valor > 0.05) e métricas melhores que OLS.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python (statsmodels, matplotlib), conjunto de teste separado.",
                                  "tips": "Use resíduos studentizados para plots mais sensíveis a outliers.",
                                  "learningObjective": "Avaliar a eficácia da correção via MQP e interpretar resultados.",
                                  "commonMistakes": "Não ponderar resíduos na validação; ignorar perda de graus de liberdade em MQP."
                                }
                              ],
                              "practicalExample": "Em um dataset de salários por anos de experiência (n=1000), variância de erros aumenta com salário. Ajuste OLS mostra dispersão crescente nos resíduos. Estime Var(ε) via regressão de res² em preditos, compute w_i=1/Var(ε_i), aplique WLS: erros-padrão dos coefs caem 20-30%, resíduos homocedásticos.",
                              "finalVerifications": [
                                "Teste Breusch-Pagan nos resíduos MQP falha em rejeitar homocedasticidade (p>0.05).",
                                "Erros-padrão dos coeficientes em MQP são menores que em OLS.",
                                "Gráfico de resíduos ponderados vs. preditos mostra dispersão constante.",
                                "R² ajustado ou AIC indica melhor ajuste em MQP.",
                                "Predições out-of-sample têm RMSE menor em MQP.",
                                "Pesos variam monotonicamente com proxy de variância."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimativa de variâncias (correlação >0.85 com amostrais).",
                                "Implementação correta de WLS com pesos inversos (sem erros de sintaxe).",
                                "Validação completa com plots e testes estatísticos.",
                                "Interpretação qualitativa/quantitativa das diferenças OLS vs. MQP.",
                                "Eficiência computacional (tempo de execução razoável para n>1000).",
                                "Robustez a dados com outliers (sensibilidade testada)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses para heterocedasticidade.",
                                "Programação Científica: Uso de statsmodels/sklearn em Python/R.",
                                "Machine Learning: Weighted regression em modelos de ensemble.",
                                "Econometria: Aplicações em dados de painel com erros clustered.",
                                "Visualização de Dados: Plots diagnósticos de resíduos."
                              ],
                              "realWorldApplication": "Em finanças, corrige heterocedasticidade em retornos de ações (variância maior em bull markets) para previsões de risco mais precisas; em bioestatística, analisa ensaios clínicos onde variância de respostas aumenta com dose."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.3.3",
                            "name": "Aplicar correções em software (R)",
                            "description": "Usar funções como lmtest::bptest(), sandwich::vcovHC() e lmtest::coeftest() em R para diagnosticar e corrigir heterocedasticidade em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente R e carregar dados de engenharia",
                                  "subSteps": [
                                    "Instale os pacotes lmtest e sandwich usando install.packages(c('lmtest', 'sandwich')) se necessário.",
                                    "Carregue os pacotes com library(lmtest) e library(sandwich).",
                                    "Importe um conjunto de dados de engenharia, como dados de tensão vs. carga em materiais, usando read.csv() ou similar.",
                                    "Ajuste um modelo de regressão linear inicial com lm(dependente ~ independentes, data = dados).",
                                    "Visualize resíduos com plot(modelo) para suspeita inicial de heterocedasticidade."
                                  ],
                                  "verification": "Confirme que os pacotes estão carregados sem erros e o modelo lm() é ajustado com summary(modelo) mostrando coeficientes.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "R e RStudio instalados, arquivo CSV com dados de engenharia (ex: tensão, carga, temperatura).",
                                  "tips": "Sempre verifique a estrutura dos dados com str(dados) antes de modelar.",
                                  "learningObjective": "Configurar ambiente R pronto para análise de regressão com pacotes específicos.",
                                  "commonMistakes": "Esquecer de instalar pacotes ou usar nomes errados, levando a erros 'package not found'."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diagnosticar heterocedasticidade com o teste de Breusch-Pagan",
                                  "subSteps": [
                                    "Execute bptest(modelo) para testar homocedasticidade nos resíduos.",
                                    "Interprete o p-valor: se p < 0.05, rejeite homocedasticidade (heterocedasticidade presente).",
                                    "Plote resíduos vs. valores ajustados com plot(resid(modelo) ~ fitted(modelo)) para confirmação visual.",
                                    "Registre o estatística BP e p-valor em um relatório ou objeto.",
                                    "Salve o resultado como bp_result <- bptest(modelo)."
                                  ],
                                  "verification": "Resultado de bptest() mostra p-valor < 0.05 confirmando heterocedasticidade.",
                                  "estimatedTime": "10 minutos",
                                  "materials": "Modelo lm() do step 1, pacote lmtest carregado.",
                                  "tips": "Use studentize = FALSE se resíduos não forem normalizados.",
                                  "learningObjective": "Aplicar e interpretar teste BP para detectar violações de homocedasticidade.",
                                  "commonMistakes": "Ignorar o p-valor ou confundir com normalidade; teste BP é específico para heterocedasticidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar correção de erros padrão robustos com vcovHC()",
                                  "subSteps": [
                                    "Calcule matriz de covariância robusta com vcovHC(modelo, type = 'HC1').",
                                    "Salve como vcov_robust <- vcovHC(modelo, type = 'HC1').",
                                    "Compare com vcov original usando print(vcov(modelo)) vs. vcov_robust.",
                                    "Verifique diagonais para erros padrão aumentados em heterocedasticidade.",
                                    "Documente mudanças nos erros padrão."
                                  ],
                                  "verification": "Matriz vcov_robust tem valores diferentes da original, especialmente diagonais maiores.",
                                  "estimatedTime": "12 minutos",
                                  "materials": "Modelo lm() e pacote sandwich.",
                                  "tips": "Use type='HC1' para amostras finitas em engenharia; HC0 para grandes N.",
                                  "learningObjective": "Corrigir matriz de covariância para inferência robusta contra heterocedasticidade.",
                                  "commonMistakes": "Usar type incorreto ou esquecer de especificar, levando a correções inadequadas."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar significância dos coeficientes com coeftest() corrigido",
                                  "subSteps": [
                                    "Execute coeftest(modelo, vcov = vcov_robust) para t-tests robustos.",
                                    "Compare p-valores originais de summary(modelo) com os robustos.",
                                    "Interprete: coeficientes significativos mudam? Relate diferenças.",
                                    "Gere tabela de resultados com stargazer::stargazer(modelo, se = sqrt(diag(vcov_robust))) se disponível.",
                                    "Conclua se modelo é robusto pós-correção."
                                  ],
                                  "verification": "coeftest() produz p-valores corrigidos, com pelo menos uma mudança significativa.",
                                  "estimatedTime": "10 minutos",
                                  "materials": "vcov_robust do step 3, pacote lmtest.",
                                  "tips": "Salve output como resultado_robusto <- coeftest(...) para relatórios.",
                                  "learningObjective": "Avaliar significância de parâmetros com inferência robusta.",
                                  "commonMistakes": "Usar coeftest sem vcov especificado, obtendo resultados não corrigidos."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e validar correções",
                                  "subSteps": [
                                    "Compare diagnósticos pré e pós-correção: BP teste ainda rejeita, mas inferência é confiável.",
                                    "Plote resíduos com weights ou QQ-plot corrigidos.",
                                    "Escreva relatório resumindo: 'Heterocedasticidade detectada (BP p=0.01), corrigida com HC1; coef. X agora insignificante'.",
                                    "Teste sensibilidade com subamostras.",
                                    "Salve script completo como 'analise_hetero.R'."
                                  ],
                                  "verification": "Relatório escrito confirma diagnóstico, correção e interpretações coerentes.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Todos resultados anteriores, editor de texto.",
                                  "tips": "Use knitr::kable() para tabelas bonitas em relatórios R Markdown.",
                                  "learningObjective": "Sintetizar análise completa de heterocedasticidade e correção em contexto de engenharia.",
                                  "commonMistakes": "Não comparar pré/pós, ou ignorar implicações para conclusões do modelo."
                                }
                              ],
                              "practicalExample": "Em dados de engenharia de materiais: regredir resistência à tração (MPa) em temperatura (°C) e carga (kN). BP teste (p=0.003) detecta hetero. vcovHC(HC1) aumenta SE de beta_temp de 0.12 para 0.18; coeftest mostra beta_temp agora p=0.07 (insignificante), ajustando design experimental.",
                              "finalVerifications": [
                                "bptest() rejeita homocedasticidade (p<0.05).",
                                "Erros padrão robustos (diag(sqrt(vcovHC()))) diferem >10% dos originais.",
                                "coeftest() com vcovHC() executa sem erros e altera pelo menos um p-valor.",
                                "Interpretação escrita explica mudanças em significância.",
                                "Script R reproduzível gera mesmos resultados.",
                                "Visualizações confirmam hetero nos resíduos."
                              ],
                              "assessmentCriteria": [
                                "Código R executa corretamente todas funções (lmtest::bptest, sandwich::vcovHC, lmtest::coeftest).",
                                "Diagnóstico BP interpretado corretamente com p-valor.",
                                "vcovHC usa type apropriado (HC0/HC1/HC3) para contexto.",
                                "Comparação pré/pós-correção documentada quantitativamente.",
                                "Interpretação liga resultados a implicações em engenharia.",
                                "Tempo total dentro de 60 minutos, sem erros comuns evitados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência robusta e testes de diagnóstico.",
                                "Programação: Manipulação de objetos em R (matrizes, modelos).",
                                "Engenharia: Modelagem de dados experimentais (ex: mecânica dos materiais).",
                                "Matemática Computacional: Algoritmos numéricos para covariância.",
                                "Ciência de Dados: Validação de pressupostos em ML regressão."
                              ],
                              "realWorldApplication": "Em engenharia civil, corrigir heteroscedasticidade em regressões de fadiga de pontes sob cargas variáveis garante previsões confiáveis de vida útil, evitando superestimação de significância e falhas estruturais custosas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.3.3.4",
                            "name": "Interpretar resultados corrigidos",
                            "description": "Comparar inferência com e sem correções, avaliando significância de coeficientes em contextos de grandes amostras e análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Resultados do Modelo Original sem Correções",
                                  "subSteps": [
                                    "Carregue o dataset de grandes amostras (ex: dados de engenharia com >1000 observações).",
                                    "Execute a regressão linear OLS padrão e extraia coeficientes, erros-padrão, t-stats e p-values.",
                                    "Teste para heterocedasticidade usando Breusch-Pagan ou White test.",
                                    "Registre inferências iniciais: quais coeficientes são significativos (p < 0.05)?",
                                    "Anote o R² e resíduos plotados para visualizar padrões de variância."
                                  ],
                                  "verification": "Confirme que testes indicam heterocedasticidade (p < 0.05) e liste significâncias iniciais em um relatório.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Software R/Python (lm() ou statsmodels), dataset exemplo (ex: dados de custos de projetos de engenharia).",
                                  "tips": "Sempre plote resíduos vs fitted values para inspeção visual rápida.",
                                  "learningObjective": "Identificar evidências de heterocedasticidade e inferências não corrigidas.",
                                  "commonMistakes": "Ignorar testes formais e confiar apenas em gráficos; confundir homocedasticidade com normalidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar Correções para Heterocedasticidade",
                                  "subSteps": [
                                    "Implemente erros-padrão robustos de White (HCSE) usando funções como sandwich::vcovHC() em R ou robust em Python.",
                                    "Reexecute a regressão com covariância corrigida e extraia novos erros-padrão, t-stats e p-values.",
                                    "Compare matrizes de covariância original vs corrigida.",
                                    "Ajuste intervalos de confiança usando a correção.",
                                    "Salve outputs lado a lado em uma tabela comparativa."
                                  ],
                                  "verification": "Verifique se novos erros-padrão são maiores que os originais para coeficientes afetados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Pacotes R: sandwich, lmtest; Python: statsmodels com cov_type='HC3'; mesmo dataset.",
                                  "tips": "Use HC3 para amostras finitas em engenharia para conservadorismo.",
                                  "learningObjective": "Aplicar corretamente correções robustas e extrair métricas atualizadas.",
                                  "commonMistakes": "Aplicar correção errada (ex: confundir HC0 com HC1); não recalcular t-stats."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Inferências com e sem Correções",
                                  "subSteps": [
                                    "Crie tabela comparativa: coeficientes (devem ser iguais), erros-padrão, t-stats, p-values e significância.",
                                    "Identifique mudanças: quais coeficientes perdem/ganham significância?",
                                    "Calcule diferenças percentuais em erros-padrão (ex: +20% indica impacto).",
                                    "Avalie estabilidade em grandes amostras (espera-se pouca mudança).",
                                    "Discuta implicações: inferências originais superconfiantes?"
                                  ],
                                  "verification": "Tabela mostra pelo menos 1 coeficiente com mudança em significância; explique por quê.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Excel/Google Sheets para tabelas; scripts de Step 1-2.",
                                  "tips": "Foco em coeficientes com maiores aumentos em erros-padrão – eles dirigem mudanças.",
                                  "learningObjective": "Detectar e quantificar impactos das correções na inferência.",
                                  "commonMistakes": "Assumir que coeficientes mudam; eles não mudam, só a precisão."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Significância no Contexto de Engenharia",
                                  "subSteps": [
                                    "Relacione coeficientes corrigidos ao domínio (ex: coeficiente de 'tamanho projeto' em custo).",
                                    "Avalie significância prática: efeito size > threshold de engenharia (ex: 5% mudança em custo).",
                                    "Discuta riscos de decisões baseadas em modelo não corrigido.",
                                    "Proponha recomendações: confiar em resultados corrigidos para grandes amostras.",
                                    "Escreva parágrafo de interpretação final."
                                  ],
                                  "verification": "Relatório contextualiza 2+ coeficientes com implicações reais em engenharia.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Relatório template; conhecimento domínio engenharia.",
                                  "tips": "Use linguagem não técnica para stakeholders: 'Correção revela que fator X não afeta custo significativamente'.",
                                  "learningObjective": "Traduzir estatística corrigida para insights acionáveis em análise de dados de engenharia.",
                                  "commonMistakes": "Focar só em p-values; ignorar magnitude e contexto prático."
                                }
                              ],
                              "practicalExample": "Em um dataset de 5000 projetos de engenharia civil, regredir custo total vs tamanho, materiais e localização. Modelo original mostra localização significativa (p=0.03), mas após HCSE, p=0.12 – correção revela insignificância, evitando alocação errada de recursos em planejamento urbano.",
                              "finalVerifications": [
                                "Pode gerar tabela comparativa precisa de métricas antes/depois correção.",
                                "Explica mudança em significância para pelo menos 2 coeficientes.",
                                "Identifica heterocedasticidade corretamente via teste e gráfico.",
                                "Interpreta implicações em contexto de grandes amostras de engenharia.",
                                "Propõe decisão baseada em resultados corrigidos.",
                                "Confirma estabilidade de inferências em amostras grandes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação de HCSE (erros-padrão corretos: 100%).",
                                "Qualidade da comparação tabular (clareza e completude: 4/5).",
                                "Profundidade da interpretação contextual (relevância engenharia: 4/5).",
                                "Identificação correta de mudanças em significância (acertos: 90%).",
                                "Uso adequado de testes e visualizações (completude: 100%).",
                                "Clareza no relatório final (comunicação: 4/5)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Avaliação de pressupostos e robustez.",
                                "Engenharia de Dados: Análise de grandes datasets em projetos reais.",
                                "Programação Computacional: Uso de R/Python para regressão robusta.",
                                "Econometria: Aplicações em modelagem preditiva econômica.",
                                "Visualização de Dados: Plots de resíduos para diagnóstico."
                              ],
                              "realWorldApplication": "Em engenharia, interpretar resultados corrigidos garante decisões confiáveis em análises de grandes datasets, como prever falhas em estruturas (regressão de estresse vs carga), evitando superconfiança em modelos OLS e otimizando alocação de recursos em indústrias como construção e manufatura."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.4",
                    "name": "Erros Padrão Robustos",
                    "description": "Cálculo de erros padrão consistentes sob pressupostos relaxados, como os de White.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.4.1",
                        "name": "Pressupostos Clássicos para Erros Padrão em MQO",
                        "description": "Compreender os pressupostos do modelo de regressão linear via Mínimos Quadrados Ordinários (MQO) que garantem a consistência e validade dos erros padrão convencionais, incluindo homocedasticidade e ausência de autocorrelação.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.4.1.1",
                            "name": "Listar os pressupostos de Gauss-Markov estendidos",
                            "description": "Identificar e descrever os quatro pressupostos principais (linearidade, exogeneidade, homocedasticidade e não correlação serial) necessários para que os erros padrão do MQO sejam válidos para inferência estatística.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Teorema de Gauss-Markov e o Contexto do MQO",
                                  "subSteps": [
                                    "Relembre o modelo de regressão linear: Y = Xβ + ε.",
                                    "Entenda que o Teorema de Gauss-Markov afirma que o estimador MQO é o melhor linear não viesado (BLUE) sob certos pressupostos.",
                                    "Identifique que para inferência (erros padrão válidos), pressupostos estendidos são necessários além dos básicos.",
                                    "Liste os pressupostos básicos: linearidade na forma esperada, exogeneidade estrita (E[ε|X]=0), homocedasticidade (Var(ε|X)=σ²I) e não correlação serial (Cov(ε_i, ε_j|X)=0 para i≠j).",
                                    "Note a distinção: Gauss-Markov clássico para BLUE, estendidos para inferência estatística."
                                  ],
                                  "verification": "Escreva um resumo de 100 palavras explicando o teorema e liste os 4 pressupostos estendidos corretamente.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Notas de aula sobre regressão linear, vídeo introdutório no YouTube sobre Gauss-Markov (ex: canal de econometria).",
                                  "tips": "Use diagramas para visualizar o modelo Y = Xβ + ε.",
                                  "learningObjective": "Compreender o papel dos pressupostos no estimador MQO para inferência.",
                                  "commonMistakes": "Confundir pressupostos de Gauss-Markov (BLUE) com pressupostos para normalidade (t-tests válidos)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar Linearidade e Exogeneidade",
                                  "subSteps": [
                                    "Defina linearidade: E[Y|X] = Xβ (forma linear correta na expectativa condicional).",
                                    "Explique exogeneidade: E[ε|X] = 0, ou Cov(X, ε) = 0, garantindo não viés.",
                                    "Discuta violações: especificação errada do modelo leva a viés nos erros padrão.",
                                    "Exemplo matemático: Mostre como violar exogeneidade infla erros padrão.",
                                    "Pratique: Identifique em um modelo se linearidade/exogeneidade holds."
                                  ],
                                  "verification": "Descreva em bullet points as definições e uma violação comum para cada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro 'Introdução à Econometria' de Wooldridge (cap. 3-4), calculadora ou Python/Jupyter para simulações simples.",
                                  "tips": "Pense em causalidade: exogeneidade é chave para inferência causal.",
                                  "learningObjective": "Dominar os dois primeiros pressupostos e suas implicações para validade dos erros padrão.",
                                  "commonMistakes": "Confundir linearidade paramétrica com funcional (ex: polinômios necessários)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Homocedasticidade e Não Correlação Serial",
                                  "subSteps": [
                                    "Defina homocedasticidade: Var(ε|X) = σ² (variância constante condicional em X).",
                                    "Explique não correlação serial: Cov(ε_t, ε_{t-k}|X) = 0 para k≠0 (erros independentes no tempo).",
                                    "Discuta impactos: Violações levam a erros padrão subestimados, testes inválidos.",
                                    "Testes diagnósticos: Breusch-Pagan para heteroscedasticidade, Durbin-Watson para autocorrelação.",
                                    "Pratique: Simule dados com violação e compare erros padrão."
                                  ],
                                  "verification": "Crie uma tabela comparando os 4 pressupostos com definições, violações e consequências.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Software R ou Python (pacotes statsmodels/sklearn), exemplos de datasets de séries temporais.",
                                  "tips": "Visualize resíduos vs. fitted values para heteroscedasticidade.",
                                  "learningObjective": "Entender os pressupostos de variância e independência para inferência confiável.",
                                  "commonMistakes": "Ignorar heterocedasticidade em dados de painel ou séries temporais."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar Pressupostos e Verificar Aplicação em Inferência",
                                  "subSteps": [
                                    "Liste os 4 pressupostos em ordem: 1. Linearidade, 2. Exogeneidade, 3. Homocedasticidade, 4. Não correlação serial.",
                                    "Explique coletivamente: Necessários para que Var(β_hat) = σ²(X'X)^{-1} seja válido para t-tests e ICs.",
                                    "Compare com erros padrão robustos (relaxam 3 e 4).",
                                    "Pratique explicação oral ou escrita completa.",
                                    "Auto-teste: Responda perguntas como 'Por que esses pressupostos importam?'."
                                  ],
                                  "verification": "Registre um vídeo de 2 minutos listando e descrevendo os pressupostos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Gravador de voz/câmera, cheat sheet dos pressupostos.",
                                  "tips": "Memorize com mnemônico: 'LEHN' (Linearidade, Exogeneidade, Homo, Não-serial).",
                                  "learningObjective": "Listar e descrever fluentemente os pressupostos para inferência em MQO.",
                                  "commonMistakes": "Esquecer que Gauss-Markov estendido inclui normalidade para exatidão em amostras finitas."
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão de salário sobre anos de educação (dados do Wooldridge), verifique linearidade plotando E[salário|educação]; teste exogeneidade assumindo educação exógena; cheque homocedasticidade com plot de resíduos vs. fitted; teste serial com Durbin-Watson. Se violado (ex: heterocedasticidade em altos salários), erros padrão são inválidos, levando a significância espúria.",
                              "finalVerifications": [
                                "Liste corretamente os 4 pressupostos sem consultar notas.",
                                "Descreva cada um em uma frase precisa.",
                                "Explique o impacto de uma violação em inferência estatística.",
                                "Diferencie pressupostos Gauss-Markov clássicos dos estendidos.",
                                "Identifique teste diagnóstico para cada pressuposto (exceto linearidade).",
                                "Aplique a um modelo simples: 'Quais pressupostos assumimos?'"
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições matemáticas (100% correto).",
                                "Compreensão de implicações para erros padrão e inferência (explicação clara).",
                                "Capacidade de identificar violações em exemplos reais.",
                                "Uso correto de terminologia (MQO, BLUE, exogeneidade estrita).",
                                "Fluência na listagem e descrição verbal/escrita.",
                                "Diferenciação de pressupostos relaxados vs. clássicos."
                              ],
                              "crossCurricularConnections": [
                                "Economia: Modelos de causalidade e identificação em econometria.",
                                "Programação: Implementação em Python/R para testes de pressupostos (statsmodels).",
                                "Estatística: Teoria assintótica e inferência em grandes amostras.",
                                "Machine Learning: Pressupostos em regressão linear vs. modelos não paramétricos."
                              ],
                              "realWorldApplication": "Em análise de políticas públicas, como avaliar impacto de treinamento no emprego via regressão: pressupostos garantem que intervalos de confiança para o coeficiente de impacto sejam confiáveis, evitando conclusões erradas sobre eficácia da política."
                            },
                            "estimatedTime": "30 min",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.1.2",
                            "name": "Explicar impactos da violação de homocedasticidade",
                            "description": "Analisar como a heterocedasticidade leva a erros padrão enviesados (sub ou superestimados), afetando testes de significância e intervalos de confiança em regressões aplicadas a dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Conceituar homocedasticidade e identificar heterocedasticidade",
                                  "subSteps": [
                                    "Defina homocedasticidade como variância constante dos erros em torno da reta de regressão.",
                                    "Explique heterocedasticidade como variância não constante dos erros, comum em dados de engenharia.",
                                    "Discuta fontes comuns de heterocedasticidade, como escalas variáveis ou omissão de variáveis.",
                                    "Aprenda a visualizar heterocedasticidade via gráfico de resíduos vs. valores ajustados.",
                                    "Compare homocedasticidade (resíduos uniformes) com heterocedasticidade (padrão de funil)."
                                  ],
                                  "verification": "Plotar um gráfico de resíduos e identificar corretamente se há heterocedasticidade.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software R ou Python (pacotes ggplot2 ou matplotlib/seaborn)",
                                    "Dataset de exemplo com regressão linear"
                                  ],
                                  "tips": "Sempre escale variáveis para facilitar a visualização de padrões nos resíduos.",
                                  "learningObjective": "Compreender e diagnosticar a violação do pressuposto de homocedasticidade.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade com autocorrelação.",
                                    "Ignorar a escala dos eixos no plot de resíduos.",
                                    "Assumir homocedasticidade sem teste visual."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar impacto da heterocedasticidade nos erros padrão",
                                  "subSteps": [
                                    "Explique que sob homocedasticidade, erros padrão são calculados corretamente via MQO.",
                                    "Descreva como heterocedasticidade leva a erros padrão subestimados em regiões de alta variância.",
                                    "Mostre matematicamente: Var(β̂) incorreta quando Var(ε) ≠ σ² constante.",
                                    "Ilustre superestimação em regiões de baixa variância, inflando significância espúria.",
                                    "Calcule erros padrão robustos (White) como correção inicial."
                                  ],
                                  "verification": "Derivar ou simular um exemplo onde erros padrão são enviesados e compará-los com robustos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notebook Jupyter com statsmodels ou lmtest em R",
                                    "Fórmulas de variância de coeficientes"
                                  ],
                                  "tips": "Use simulações Monte Carlo para demonstrar o viés em cenários controlados.",
                                  "learningObjective": "Explicar o viés direcional nos erros padrão devido à heterocedasticidade.",
                                  "commonMistakes": [
                                    "Pensar que o viés é sempre subestimação.",
                                    "Confundir erros padrão com o estimador de β em si (que permanece não viesado)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Examinar efeitos em testes de significância e intervalos de confiança",
                                  "subSteps": [
                                    "Descreva testes t como t = β̂ / SE(β̂); SE enviesado altera rejeição de H0.",
                                    "Explique intervalos de confiança: IC = β̂ ± t * SE; SE subestimado estreita IC indevidamente.",
                                    "Discuta Type I e Type II errors: mais falsos positivos em alta variância.",
                                    "Aplique em regressão: p-valores incorretos levam a conclusões erradas sobre variáveis.",
                                    "Compare testes com erros padrão robustos para validação."
                                  ],
                                  "verification": "Realizar teste t em modelo heterocedástico e mostrar p-valor alterado vs. robusto.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Software com sandwich package (R) ou robustcov em Python",
                                    "Exemplo de regressão com dados simulados"
                                  ],
                                  "tips": "Sempre reporte erros padrão robustos em relatórios de engenharia para robustez.",
                                  "learningObjective": "Analisar como vieses propagam para inferência estatística.",
                                  "commonMistakes": [
                                    "Ignorar que MQO é consistente mesmo com heterocedasticidade.",
                                    "Confundir significância com causalidade."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em dados de engenharia e propor soluções",
                                  "subSteps": [
                                    "Selecione dataset de engenharia (ex: tensão vs. carga em materiais).",
                                    "Ajuste modelo MQO, diagnostique heterocedasticidade e calcule impactos.",
                                    "Quantifique: compare SE clássicos vs. robustos e ajuste testes.",
                                    "Proponha soluções: transformações (log), WLS ou erros robustos.",
                                    "Documente relatório com gráficos e conclusões corrigidas."
                                  ],
                                  "verification": "Gerar relatório mostrando antes/depois da correção, com IC ajustados.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dataset real de engenharia (ex: de Kaggle)",
                                    "Python/R com relatórios (knitr ou papermill)"
                                  ],
                                  "tips": "Priorize erros robustos em aplicações práticas; evite depender de pressupostos frágeis.",
                                  "learningObjective": "Integrar análise de impactos em contexto aplicado de engenharia.",
                                  "commonMistakes": [
                                    "Não testar heterocedasticidade (Breusch-Pagan).",
                                    "Aplicar soluções sem diagnóstico prévio."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma regressão para prever o tempo de falha de um componente eletrônico em função da temperatura de operação (dados de engenharia), os resíduos mostram variância crescente com temperatura alta. Isso subestima SE para coeficientes de baixa temp (superestima significância) e superestima em alta temp (mascara efeitos reais), levando a intervalos de confiança estreitos demais e decisões erradas sobre limites operacionais.",
                              "finalVerifications": [
                                "Definir homocedasticidade e explicar heterocedasticidade com exemplo visual.",
                                "Calcular e comparar erros padrão clássicos vs. robustos em um modelo.",
                                "Demonstrar impacto em p-valores e IC via simulação ou dataset.",
                                "Identificar pelo menos duas soluções práticas para mitigar efeitos.",
                                "Aplicar análise em dataset de engenharia com relatório conciso.",
                                "Explicar riscos de inferência inválida em contextos reais."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: distinção clara entre homocedasticidade e impactos.",
                                "Correção matemática: fórmulas de variância e vieses explicados corretamente.",
                                "Uso de evidências: gráficos, simulações e cálculos suportam argumentos.",
                                "Aplicação contextual: exemplos relevantes a engenharia com soluções viáveis.",
                                "Clareza e estrutura: explicação lógica, sem jargões desnecessários.",
                                "Profundidade: discute Type I/II errors e propagação para decisões."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses e IC.",
                                "Programação Científica: Python/R para modelagem e visualização.",
                                "Engenharia de Materiais: modelagem de falhas e tensões variáveis.",
                                "Econometria: erros padrão robustos em grandes amostras."
                              ],
                              "realWorldApplication": "Na engenharia mecânica, modelar desgaste de engrenagens sob cargas variáveis: heterocedasticidade (maior variância em cargas altas) pode superestimar significância de fatores menores, levando a designs subótimos ou falhas prematuras em sistemas como turbinas eólicas."
                            },
                            "estimatedTime": "45 min",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.4.1.3",
                            "name": "Identificar violações comuns em grandes amostras",
                            "description": "Reconhecer padrões de heterocedasticidade e correlação serial em dados empíricos de grandes amostras, como em séries temporais de engenharia ou painéis de dados industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Clássicos de MQO e Tipos de Violações",
                                  "subSteps": [
                                    "Estude os quatro pressupostos clássicos de erros em MQO: homocedasticidade, ausência de autocorrelação, normalidade e independência.",
                                    "Defina heterocedasticidade: variância dos erros não constante, comum em grandes amostras com escalas variáveis.",
                                    "Defina correlação serial: erros correlacionados temporalmente, típico em séries temporais de engenharia.",
                                    "Examine exemplos em painéis industriais, como dados de produção com volatilidade crescente.",
                                    "Compare com pressupostos relaxados para erros padrão robustos."
                                  ],
                                  "verification": "Resuma em um diagrama os pressupostos violados e forneça um exemplo de cada em dados empíricos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Introdução à Econometria' de Wooldridge (cap. 5)",
                                    "Notas de aula sobre MQO",
                                    "Planilha com definições"
                                  ],
                                  "tips": "Use mnemônicos como 'HANC' (Homo, Ausência autocorr, Normal, Constante) para lembrar pressupostos.",
                                  "learningObjective": "Compreender conceitualmente heterocedasticidade e correlação serial em contextos de grandes amostras.",
                                  "commonMistakes": [
                                    "Confundir heterocedasticidade com não-linearidade",
                                    "Ignorar que violações são assintóticas em grandes amostras"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar Métodos Visuais para Detecção Inicial",
                                  "subSteps": [
                                    "Ajuste um modelo MQO em um dataset grande (ex: série temporal de produção industrial).",
                                    "Gere plots de resíduos vs. valores ajustados para heterocedasticidade (padrão de funil).",
                                    "Crie gráfico ACF (Autocorrelation Function) de resíduos para correlação serial (picos significativos).",
                                    "Plote resíduos padronizados vs. tempo para padrões em painéis industriais.",
                                    "Anote padrões qualitativos em amostras >1000 observações."
                                  ],
                                  "verification": "Produza e interprete 3 plots corretos, destacando violações em um relatório curto.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python/R com bibliotecas statsmodels/seaborn/ggplot2",
                                    "Dataset público de produção industrial (ex: FRED database)"
                                  ],
                                  "tips": "Aumente o tamanho da amostra para >500 para visualizar padrões claros em grandes dados.",
                                  "learningObjective": "Detectar visualmente violações comuns usando gráficos padrão.",
                                  "commonMistakes": [
                                    "Não padronizar resíduos antes de plotar",
                                    "Interpretar ruído aleatório como violação"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Testes Estatísticos Formais",
                                  "subSteps": [
                                    "Implemente teste de Breusch-Pagan ou White para heterocedasticidade.",
                                    "Execute teste de Durbin-Watson ou Ljung-Box para correlação serial.",
                                    "Ajuste em dados empíricos de engenharia (ex: sensores IoT em painéis).",
                                    "Calcule p-valores e compare com níveis de significância (5%).",
                                    "Registre resultados em tabela comparativa para múltiplas amostras grandes."
                                  ],
                                  "verification": "Execute testes em um dataset e rejeite/aceite H0 corretamente com justificativa.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Código Python/R pronto para testes (statsmodels, lmtest)",
                                    "Datasets de séries temporais industriais (ex: UCI ML repo)"
                                  ],
                                  "tips": "Sempre verifique pressupostos dos testes (ex: normalidade para Breusch-Pagan).",
                                  "learningObjective": "Realizar e interpretar testes formais para violações em grandes amostras.",
                                  "commonMistakes": [
                                    "Usar testes inadequados para dados não estacionários",
                                    "Ignorar poder estatístico baixo em amostras muito grandes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar Detecção e Propor Correções Robustas",
                                  "subSteps": [
                                    "Combine evidências visuais e testes em um dataset real de painéis industriais.",
                                    "Identifique padrões mistos (hetero + serial) comuns em engenharia.",
                                    "Calcule erros padrão robustos (HC/SE) para MQO violado.",
                                    "Compare inferências clássicas vs. robustas.",
                                    "Documente relatório com recomendações para grandes amostras."
                                  ],
                                  "verification": "Gere relatório final identificando violações e calculando EPs robustos corretamente.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Jupyter Notebook ou R Markdown",
                                    "Dataset customizado com violações simuladas"
                                  ],
                                  "tips": "Simule violações leves para praticar detecção sensível em grandes N.",
                                  "learningObjective": "Aplicar detecção holística e transitar para estimadores robustos.",
                                  "commonMistakes": [
                                    "Não reportar tamanho da amostra ao interpretar testes",
                                    "Aplicar robustez sem confirmar violações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um painel de dados de produção mensal de 10 fábricas ao longo de 5 anos (600 observações), ajuste MQO de produção vs. horas-trabalho. Plote resíduos mostrando funil (heterocedasticidade) e ACF com lags significativos (serial corr.), confirmados por Breusch-Pagan (p<0.01) e Durbin-Watson=1.2. Use EPs robustos para inferência confiável.",
                              "finalVerifications": [
                                "Identifica corretamente heterocedasticidade em plot de resíduos vs. fitted.",
                                "Detecta serial correlation via ACF e teste Durbin-Watson.",
                                "Executa testes formais com p-valores interpretados em grandes amostras.",
                                "Compara EPs clássicos vs. robustos em relatório.",
                                "Reconoce padrões em séries temporais industriais.",
                                "Propõe correções apropriadas sem overcorreção."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação visual (80% acerto em plots).",
                                "Correta execução e interpretação de testes (p-valores e conclusões).",
                                "Qualidade do relatório integrando evidências múltiplas.",
                                "Compreensão de implicações assintóticas em N grande.",
                                "Aplicação correta de EPs robustos em código.",
                                "Criatividade em exemplos industriais reais."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia: Análise de séries temporais em controle de processos.",
                                "Economia: Modelos de painel em dados industriais.",
                                "Machine Learning: Diagnóstico de resíduos em regressão.",
                                "Estatística Computacional: Simulações de violações.",
                                "Gestão Industrial: Previsão de produção com robustez."
                              ],
                              "realWorldApplication": "Em engenharia industrial, detectar heterocedasticidade e serial corr. em dados de sensores permite erros padrão robustos para prever falhas em linhas de produção, otimizando manutenção preditiva e reduzindo downtime em fábricas."
                            },
                            "estimatedTime": "30 min",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.4.2",
                        "name": "Matriz de Covariância Robusta de White",
                        "description": "Derivação e propriedades da estimativa consistente da matriz de variância-covariância sob heterocedasticidade, conforme proposta por White (1980), relaxando pressupostos clássicos.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.4.2.1",
                            "name": "Derivar a fórmula HC0 de White",
                            "description": "Obter a expressão da matriz robusta como Var(β̂) = (X'X)^(-1) (∑ e_i² x_i x_i') (X'X)^(-1), onde e_i são resíduos, e explicar sua consistência assintótica em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o Modelo de Regressão Linear e o Estimador OLS",
                                  "subSteps": [
                                    "Escreva o modelo y = Xβ + ε, com E(ε|X)=0 e Var(ε|X)=Ω (não necessariamente σ²I).",
                                    "Derive o estimador β̂ = (X'X)^{-1}X'y.",
                                    "Discuta os pressupostos clássicos do OLS e como heteroscedasticidade os viola.",
                                    "Introduza a ideia de variância robusta quando Ω ≠ σ²I.",
                                    "Verifique a consistência de β̂ sob independência condicional: plim (X'X/n)^{-1}(X'ε/n) = 0."
                                  ],
                                  "verification": "Escreva corretamente a expressão de β̂ e liste 3 pressupostos violados pela heteroscedasticidade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Notas de aula sobre OLS",
                                    "Software como R ou Python para simular dados simples"
                                  ],
                                  "tips": "Comece sempre pelo modelo para ancorar a derivação; use notação matricial consistente.",
                                  "learningObjective": "Compreender a base do OLS e identificar quando a variância padrão clássica falha.",
                                  "commonMistakes": "Confundir Var(β̂) clássica σ²(X'X)^{-1} com a robusta; ignorar condicionamento em X."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Variância Assintótica Condicional de β̂",
                                  "subSteps": [
                                    "Mostre que √n (β̂ - β) → N(0, plim (X'X/n)^{-1} (1/n ∑ E(ε_i² x_i x_i'|X)) (X'X/n)^{-1}).",
                                    "Assuma independência condicional: ε_i | X_i ~ iid(0, σ_i²), com σ_i² = Var(ε_i|X_i).",
                                    "Expanda β̂ - β = (X'X)^{-1} X'ε e analise a covariância de X'ε.",
                                    "Identifique a matriz central: E[(X'ε)(X'ε)' | X] = ∑ σ_i² x_i x_i'.",
                                    "Normalize por n para obter a forma assintótica."
                                  ],
                                  "verification": "Escreva a distribuição assintótica de √n (β̂ - β) com a matriz de variância sandwich.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Quadro branco ou papel para álgebra matricial",
                                    "Referência: Wooldridge 'Introductory Econometrics' Capítulo 20"
                                  ],
                                  "tips": "Use a lei dos grandes números condicional (LLNC) para plim; desenhe diagramas matriciais.",
                                  "learningObjective": "Derivar a variância assintótica sob heteroscedasticidade usando teoria assintótica.",
                                  "commonMistakes": "Esquecer o condicionamento em X; usar Var(ε)=σ²I na derivação robusta."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir o Estimador Plug-in HC0",
                                  "subSteps": [
                                    "Estime (X'X)^{-1} como Â.",
                                    "Estime a matriz central B̂ = ∑ e_i² x_i x_i', onde e_i = y_i - x_i' β̂.",
                                    "Forme Var(β̂) ≈ Â B̂ Â.",
                                    "Justifique o uso de resíduos OLS plugged-in pela consistência de e_i² → σ_i².",
                                    "Compare com HC1/HC2 que corrigem graus de liberdade (HC0 não corrige)."
                                  ],
                                  "verification": "Escreva explicitamente Var(β̂) = (X'X)^{-1} (∑ e_i² x_i x_i') (X'X)^{-1} e identifique componentes.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora matricial ou Python (numpy.linalg)",
                                    "Dados simulados com heteroscedasticidade"
                                  ],
                                  "tips": "Implemente em código para verificar numericamente; normalize por n se necessário para amostras grandes.",
                                  "learningObjective": "Construir o estimador HC0 a partir da forma sandwich.",
                                  "commonMistakes": "Usar e_i em vez de e_i²; inverter a ordem do sandwich (não é simétrico assim)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explicar a Consistência Assintótica do HC0",
                                  "subSteps": [
                                    "Mostre plim (X'X/n) = Q finita e positiva definida.",
                                    "Prove plim (1/n ∑ e_i² x_i x_i'/n) = E(σ_i² x_i x_i') pela LLNC e consistência de β̂.",
                                    "Conclua que plim HC0/n = Q^{-1} E(σ_i² x_i x_i') Q^{-1}.",
                                    "Discuta requisitos: n→∞, max ||x_i||² / n →0 (sem dominância).",
                                    "Simule em software para ilustrar convergência."
                                  ],
                                  "verification": "Escreva as condições para consistência e prove plim HC0/n.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software R (sandwich package) ou Python (statsmodels)",
                                    "Script de simulação Monte Carlo"
                                  ],
                                  "tips": "Use teoremas de Slutsky para produtos de consistentes; foque em i.i.d. condicional.",
                                  "learningObjective": "Demonstrar por que HC0 é consistente em grandes amostras mesmo com misspecification.",
                                  "commonMistakes": "Ignorar normalização por n; assumir homoscedasticidade na prova."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar e Aplicar a Derivação",
                                  "subSteps": [
                                    "Compute HC0 manualmente em um dataset pequeno (n=10).",
                                    "Compare com variância clássica e interprete diferenças.",
                                    "Discuta limitações: viés em amostras pequenas, necessidade de HC1/HC2.",
                                    "Explique uso em erros padrão: se(β̂_j) = sqrt( HC0_{jj} ).",
                                    "Teste hipóteses com t-Student robusto."
                                  ],
                                  "verification": "Calcule HC0 para dados simulados e explique uma diferença chave com OLS clássico.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset CSV simples com heteroscedasticidade",
                                    "Excel ou Jupyter Notebook"
                                  ],
                                  "tips": "Sempre centre X (inclua constante); valide com pacote sandwich.",
                                  "learningObjective": "Aplicar HC0 computacionalmente e interpretar resultados.",
                                  "commonMistakes": "Não remover intercepto; dividir por n incorretamente em HC0."
                                }
                              ],
                              "practicalExample": "Simule dados: y_i = β0 + β1 x1_i + ε_i com ε_i ~ N(0, σ_i²) onde σ_i = 1 + |x1_i|. Estime OLS, compute resíduos e_i, então HC0 = (X'X)^{-1} (∑ e_i² x_i x_i') (X'X)^{-1}. Compare intervalos de confiança clássicos vs robustos; robustos são mais largos onde heteroscedasticidade é forte.",
                              "finalVerifications": [
                                "Escreve corretamente a fórmula HC0 com todos os componentes.",
                                "Explica a estrutura sandwich e papel dos resíduos.",
                                "Lista condições para consistência assintótica (LLNC, no dominância).",
                                "Computa HC0 numericamente em exemplo simples.",
                                "Diferencia HC0 de HC1/HC2.",
                                "Interpreta impacto em erros padrão."
                              ],
                              "assessmentCriteria": [
                                "Precisão da derivação assintótica (4/5 passos corretos): 30%",
                                "Correção da fórmula HC0 e componentes: 25%",
                                "Explicação clara de consistência (inclui plim): 20%",
                                "Exemplo prático computado e interpretado: 15%",
                                "Identificação de erros comuns e limitações: 10%"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teoria assintótica e LLNC.",
                                "Econometria: Estimadores robustos em Wooldridge.",
                                "Machine Learning: Variâncias em regressão linear regularizada.",
                                "Computação Científica: Implementação em NumPy/SciPy."
                              ],
                              "realWorldApplication": "Em análises empíricas como regressões salariais (heteroscedasticidade por gênero/ocupação) ou finanças (volatilidade variável), HC0 fornece erros padrão confiáveis para inferência válida em grandes datasets sem assumir homoscedasticidade, essencial para políticas públicas e modelagem preditiva."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.1.1"
                            ]
                          },
                          {
                            "id": "10.1.4.4.2.2",
                            "name": "Comparar variantes HC1, HC2 e HC3",
                            "description": "Diferenciar as correções de graus de liberdade nas estimativas HC1 (n/(n-k) ∑ e_i² x_i x_i'), HC2 e HC3, e indicar quando usar cada uma em amostras finitas de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Erros Padrão Robustos (White's Sandwich Estimator)",
                                  "subSteps": [
                                    "Relembre a regressão linear OLS e a suposição de homocedasticidade.",
                                    "Entenda o estimador de covariância robusto de White: Var(β̂) = (X'X)^(-1) (∑ e_i² x_i x_i') (X'X)^(-1).",
                                    "Identifique limitações em amostras finitas: viés em estimativas de variância.",
                                    "Discuta necessidade de correções HC1, HC2, HC3 para graus de liberdade.",
                                    "Calcule manualmente um exemplo simples com n=10, k=2."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito como o estimador de White corrige heterocedasticidade e liste 3 limitações em amostras pequenas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notas de aula sobre regressão OLS; calculadora ou Python/R com bibliotecas statsmodels ou sandwich.",
                                  "tips": "Use diagramas de 'sandwich' para visualizar a estrutura da matriz de covariância.",
                                  "learningObjective": "Compreender a base teórica dos estimadores HC e motivação para variantes corrigidas.",
                                  "commonMistakes": "Confundir robustez com normalidade dos erros; ignorar que HC assume independência mas não homocedasticidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar e Comparar Fórmulas das Variantes HC1, HC2 e HC3",
                                  "subSteps": [
                                    "Escreva a fórmula HC1: n/(n-k) ∑ e_i² x_i x_i'.",
                                    "Derive HC2: n/(n-k+1) ∑ e_i² (x_i x_i') / (1 - h_ii), onde h_ii é leverage.",
                                    "Detalhe HC3: n/(n-k) ∑ e_i² (x_i x_i') / (1 - h_ii)^2.",
                                    "Compare multiplicadores de correção: HC1 (simples), HC2/HC3 (com leverage).",
                                    "Calcule numericamente para um dataset pequeno (n<30)."
                                  ],
                                  "verification": "Reproduza as três fórmulas de memória e compute diferenças em um exemplo com leverages altos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Planilha Excel ou Jupyter Notebook com dados simulados; fórmula de leverage h_ii = x_i (X'X)^(-1) x_i'.",
                                  "tips": "Implemente funções auxiliares para h_ii antes de covariâncias para evitar erros de indexação.",
                                  "learningObjective": "Dominar as diferenças matemáticas exatas entre HC1, HC2 e HC3.",
                                  "commonMistakes": "Esquecer o denominador (1-h_ii) em HC2/HC3; usar e_i em vez de resíduos studentizados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Impacto das Correções de Graus de Liberdade",
                                  "subSteps": [
                                    "Simule datasets com n=20,40,100 e compare variâncias HC1 vs HC2/HC3.",
                                    "Avalie conservadorismo: HC3 > HC2 > HC1 em erros padrão.",
                                    "Plote intervalos de confiança para coeficientes em cenários de leverage alto.",
                                    "Quantifique viés: HC1 subestima em amostras pequenas; HC3 é mais conservador.",
                                    "Teste com heterocedasticidade real (ex: erros ~ |x|)."
                                  ],
                                  "verification": "Gere gráficos comparativos mostrando inflação de erros padrão em HC3 para n pequeno.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Python (statsmodels, matplotlib) ou R (sandwich package); datasets simulados de engenharia.",
                                  "tips": "Use seed para reproducibilidade; foque em 1-2 preditores para clareza.",
                                  "learningObjective": "Visualizar e quantificar como correções afetam inferência em amostras finitas.",
                                  "commonMistakes": "Ignorar leverage em pontos influentes; confundir cobertura real vs nominal de ICs."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Definir Critérios de Uso para Cada Variante em Contextos de Engenharia",
                                  "subSteps": [
                                    "HC1: Amostras grandes (n>100), baixa influência; padrão em software.",
                                    "HC2: Amostras médias (n=50-100), alguns leverages moderados.",
                                    "HC3: Amostras pequenas (n<50), alta influência ou clusters; recomendado por Long & Ervin.",
                                    "Crie tabela de decisão baseada em n, max(h_ii), aplicação (engenharia: testes de materiais).",
                                    "Aplique a dados reais de engenharia e justifique escolha."
                                  ],
                                  "verification": "Crie e aplique uma heurística de escolha HC para 3 cenários variados, justificando com n e h_ii.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Tabela de referência (Long & Ervin 2000); dataset de falhas em engenharia (ex: fadiga de metais).",
                                  "tips": "Sempre cheque max(h_ii)>0.1 como sinal para HC2/HC3.",
                                  "learningObjective": "Selecionar variante HC apropriada baseado em características da amostra.",
                                  "commonMistakes": "Usar HC1 por default em n pequeno; não reportar qual variante foi usada."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Implementar e Validar Comparação em Software",
                                  "subSteps": [
                                    "Carregue pacote sandwich (R) ou robustcov (Python) e compute EPs HC1/HC2/HC3.",
                                    "Compare outputs em dataset de engenharia com n finito.",
                                    "Teste hipóteses com cada variante e discuta diferenças em p-values.",
                                    "Documente relatório: fórmulas, escolha, impactos em conclusões.",
                                    "Valide com bootstrap para confirmar robustez."
                                  ],
                                  "verification": "Produza relatório com tabelas de EPs e recomendação para o dataset usado.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "RStudio ou Jupyter; dataset público (ex: auto-mpg adaptado para engenharia).",
                                  "tips": "Use vcovHC(model, type='HC1') etc.; compare com coef_test para diferenças.",
                                  "learningObjective": "Aplicar na prática e interpretar resultados comparativos.",
                                  "commonMistakes": "Não escalar corretamente para HC0 vs HC1; ignorar warnings de singularidade."
                                }
                              ],
                              "practicalExample": "Em um estudo de engenharia mecânica com n=35 testes de fadiga em vigas (preditores: carga, ciclos), compute regressão de tempo até falha. Use HC1 para EPs iniciais, mas mude para HC3 ao detectar h_ii>0.15 em 2 pontos, resultando em ICs 20% mais largos e mudança em significância de um coeficiente.",
                              "finalVerifications": [
                                "Reescreva fórmulas HC1/HC2/HC3 corretamente.",
                                "Explique por que HC3 é mais conservador em n pequeno.",
                                "Selecione variante correta para n=25 com max h_ii=0.2.",
                                "Interprete diferença de 15% em EP entre HC1 e HC3.",
                                "Implemente em código e compare saídas.",
                                "Justifique uso em relatório de engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas fórmulas e derivações (30%).",
                                "Correta identificação de critérios de uso por tamanho amostra (25%).",
                                "Implementação prática sem erros de código (20%).",
                                "Análise qualitativa/quantitativa de impactos (15%).",
                                "Clareza em exemplos e conexões reais (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em heterocedasticidade.",
                                "Programação: Manipulação de matrizes em Python/R.",
                                "Engenharia: Análise de dados experimentais finitos.",
                                "Econometria: Testes robustos em painel.",
                                "Machine Learning: Variâncias em regressão regularizada."
                              ],
                              "realWorldApplication": "Em engenharia civil, ao analisar dados limitados de sensores em pontes (n=40), HC3 previne superconfiança em predições de carga crítica, evitando erros em certificações de segurança com amostras finitas de testes destrutivos."
                            },
                            "estimatedTime": "45 min",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.4.4.2.3",
                            "name": "Calcular manualmente erros padrão robustos",
                            "description": "Realizar o cálculo passo a passo da matriz robusta e dos erros padrão para um modelo de regressão linear simples com 5-10 observações, usando ferramentas como Excel ou calculadora matricial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e estimar coeficientes OLS",
                                  "subSteps": [
                                    "Colete um dataset com 5-10 observações, incluindo variável dependente Y e independente X.",
                                    "Adicione uma coluna de intercepto (1s) para formar a matriz X (n x 2).",
                                    "Calcule as médias de X e Y.",
                                    "Compute beta1 = cov(X,Y)/var(X) e beta0 = mean(Y) - beta1 * mean(X).",
                                    "Verifique os valores ajustados Y_hat = beta0 + beta1 * X."
                                  ],
                                  "verification": "Confirme que soma dos resíduos é aproximadamente zero e R² faz sentido.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Papel e caneta para cálculos iniciais",
                                    "Calculadora científica"
                                  ],
                                  "tips": "Use fórmulas de Excel como =SOMA() e =MÉDIA() para agilizar; sempre arredonde para 4 casas decimais.",
                                  "learningObjective": "Dominar a estimação básica de regressão linear simples via OLS.",
                                  "commonMistakes": [
                                    "Esquecer a coluna de 1s na matriz X",
                                    "Confundir covariância com correlação",
                                    "Não centralizar os dados corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular resíduos e valores ajustados",
                                  "subSteps": [
                                    "Para cada observação i, calcule e_i = Y_i - Y_hat_i.",
                                    "Liste todos os resíduos em uma coluna.",
                                    "Calcule resíduos ao quadrado e_i².",
                                    "Verifique se a soma dos e_i é zero (dentro de arredondamento).",
                                    "Calcule a variância dos resíduos para referência futura."
                                  ],
                                  "verification": "Soma dos resíduos = 0 e soma dos e_i² é positiva e finita.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Excel para colunas auxiliares",
                                    "Calculadora para verificações manuais"
                                  ],
                                  "tips": "No Excel, use =Y_i - (beta0 + beta1*X_i) em uma fórmula arrastável.",
                                  "learningObjective": "Entender resíduos como base para diagnósticos e estimadores robustos.",
                                  "commonMistakes": [
                                    "Usar Y em vez de Y_hat",
                                    "Arredondar prematuramente levando a erros cumulativos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir a matriz 'bread' (X'X)^{-1}",
                                  "subSteps": [
                                    "Forme a matriz X (n x 2: coluna 1 de 1s, coluna 2 de X_i).",
                                    "Calcule X'X: soma(1*1), soma(1*X), soma(X*1), soma(X*X).",
                                    "Inverta a matriz 2x2: det = (soma(X²)*n - [soma(X)]²), então aplique fórmula de inversa.",
                                    "Multiplique pelos betas para confirmar que recupera os OLS.",
                                    "Registre a diagonal da inversa para variâncias iniciais."
                                  ],
                                  "verification": "Multiplicando (X'X)^{-1} * X'Y deve dar betas OLS exatos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Excel com função MINVERSE()",
                                    "Calculadora matricial ou app online para verificação"
                                  ],
                                  "tips": "Fórmula para inversa 2x2: [[d,-b],[-c,a]] / det; teste com n=5 para simplicidade.",
                                  "learningObjective": "Aprender cálculo manual de inversas para matrizes pequenas em regressão.",
                                  "commonMistakes": [
                                    "Erro no determinante (sinal errado)",
                                    "Confundir X'X com XX'",
                                    "Não dividir pelo determinante"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular a matriz 'meat' robusta de White",
                                  "subSteps": [
                                    "Para cada i, compute x_i x_i' * e_i² (matriz 2x2: [[1*e_i², X_i*e_i²], [X_i*e_i², X_i²*e_i²]]).",
                                    "Some todas essas matrizes externas para obter 'meat' = sum(u_i² x_i x_i').",
                                    "Verifique se meat é simétrica e diagonal positiva.",
                                    "Registre os elementos: meat11=sum(e_i²), meat12=meat21=sum(X_i e_i²), meat22=sum(X_i² e_i²).",
                                    "Compare com variância homocedástica (dividida por sigma²)."
                                  ],
                                  "verification": "Meat deve ser positiva definida; elementos crescentes com dispersão.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Excel para somas condicionais",
                                    "Papel para matrizes individuais"
                                  ],
                                  "tips": "Crie colunas no Excel para cada elemento da matriz por observação e some.",
                                  "learningObjective": "Compreender o estimador de 'sandwich' como correção para heterocedasticidade.",
                                  "commonMistakes": [
                                    "Esquecer e_i² no multiplicador",
                                    "Não somar corretamente as matrizes externas"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Montar covariância robusta e extrair erros padrão",
                                  "subSteps": [
                                    "Compute covariância robusta = bread * meat * bread.",
                                    "Multiplique as matrizes 2x2 sequencialmente.",
                                    "Extraia erros padrão: sqrt(diag(cov)): se_0 = sqrt(cov_11), se_1 = sqrt(cov_22).",
                                    "Compare com erros padrão clássicos (bread * sigma²).",
                                    "Calcule t-stats: beta/se para inferência."
                                  ],
                                  "verification": "Erros robustos >= erros clássicos; t-stats coerentes.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Excel MMULT() para multiplicação matricial",
                                    "Calculadora para raízes"
                                  ],
                                  "tips": "No Excel: =MMULT(MMULT(bread,meat),bread); use TRANSPOSTO para vetores linha.",
                                  "learningObjective": "Finalizar o estimador HC0 de White e interpretar diferenças.",
                                  "commonMistakes": [
                                    "Ordem errada no sandwich (bread-meat-bread)",
                                    "Raiz quadrada de variância negativa por erro numérico"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dataset: X=[1,2,3,4,5,6], Y=[2.1,3.9,5.2,6.8,8.1,7.9]. Estime OLS: beta0≈0.3, beta1≈1.3. Resíduos calculados levam a meat com off-diagonais não-zero. Cov robusta resulta em se_beta1≈0.45 vs clássico 0.35, corrigindo subestimação.",
                              "finalVerifications": [
                                "Coeficientes OLS recuperados corretamente de X'bread*X'Y.",
                                "Soma resíduos = 0 e meat simétrica.",
                                "Erros padrão robustos maiores ou iguais aos clássicos.",
                                "Matriz covariância positiva semi-definida (diagonal positiva).",
                                "t-stats = beta/se plausíveis (|t|>2 para significância).",
                                "Reproduzível em Excel com fórmulas exatas."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos manuais (erro <0.01).",
                                "Correta implementação do sandwich estimator.",
                                "Identificação de diferenças entre robusto e clássico.",
                                "Uso eficiente de ferramentas como Excel.",
                                "Explicação clara de cada componente (bread/meat).",
                                "Ausência de erros comuns como inversa errada."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em heterocedasticidade.",
                                "Programação: Uso de funções matriciais em Excel/Python.",
                                "Economia: Modelos econométricos em finanças e policy.",
                                "Matemática: Álgebra linear básica (inversas, produtos).",
                                "Ciência de Dados: Diagnósticos de regressão avançados."
                              ],
                              "realWorldApplication": "Em análises econométricas, como avaliar impacto de políticas públicas com dados de renda familiar (heterocedásticos), onde erros robustos previnem inferências erradas sobre significância, usados por bancos centrais e firmas de consultoria."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.4.3",
                        "name": "Implementação e Inferência Robusta",
                        "description": "Aplicação prática de erros padrão robustos em software estatístico para inferência válida sob pressupostos relaxados, com foco em contextos de econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.4.3.1",
                            "name": "Implementar em R com sandwich",
                            "description": "Usar as funções lm() e coeftest() do pacote sandwich para estimar e exibir erros padrão robustos (HC1 ou HC3) em um modelo de regressão linear com dados simulados ou reais de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o ambiente R e instalar o pacote sandwich",
                                  "subSteps": [
                                    "Abra o R ou RStudio.",
                                    "Execute install.packages('sandwich') se não estiver instalado.",
                                    "Execute library(sandwich) para carregar o pacote.",
                                    "Execute library(lmtest) pois coeftest() vem do lmtest.",
                                    "Verifique a versão do R com R.version para compatibilidade."
                                  ],
                                  "verification": "Confirme que library(sandwich) e library(lmtest) executam sem erros e functions()$sandwich lista funções disponíveis.",
                                  "estimatedTime": "10 minutos",
                                  "materials": "R ou RStudio instalado, conexão à internet para instalação.",
                                  "tips": "Use install.packages('sandwich', dependencies=TRUE) para instalar dependências automaticamente.",
                                  "learningObjective": "Preparar o ambiente de programação R com pacotes necessários para análise robusta.",
                                  "commonMistakes": "Esquecer de carregar lmtest, pois coeftest() não está no sandwich; ignorar dependências causando erros de função não encontrada."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar ou simular dados de engenharia para regressão",
                                  "subSteps": [
                                    "Defina uma semente com set.seed(123) para reprodutibilidade.",
                                    "Gere dados simulados: n <- 100; x <- rnorm(n); y <- 2 + 3*x + rnorm(n, sd=abs(x)) para heteroscedasticidade.",
                                    "Crie um data.frame: dados <- data.frame(y=y, x=x).",
                                    "Inspecione com summary(dados) e plot(y~x) para visualizar heteroscedasticidade.",
                                    "Opcionalmente, carregue dados reais de engenharia como de um CSV com read.csv()."
                                  ],
                                  "verification": "Dados gerados/carregados sem NA's (use sum(is.na(dados))), e plot mostra variação heterogênea.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "R base (funções como rnorm, data.frame).",
                                  "tips": "Simule heteroscedasticidade com sd variando com x para testar robustez.",
                                  "learningObjective": "Criar dataset realista de engenharia que viole pressupostos de homoscedasticidade.",
                                  "commonMistakes": "Gerar dados homoscedásticos acidentalmente (sd constante), invalidando necessidade de robustez; não usar set.seed."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar o modelo de regressão linear com lm()",
                                  "subSteps": [
                                    "Execute modelo <- lm(y ~ x, data=dados).",
                                    "Inspecione com summary(modelo) para coeficientes OLS padrão.",
                                    "Verifique resíduos com plot(modelo) para identificar heteroscedasticidade.",
                                    "Extraia coeficientes com coef(modelo).",
                                    "Salve resíduos se necessário: residuos <- residuals(modelo)."
                                  ],
                                  "verification": "summary(modelo) mostra R-squared e p-values OLS; nenhum erro na estimação.",
                                  "estimatedTime": "10 minutos",
                                  "materials": "Dataset do step 2.",
                                  "tips": "Use formula y ~ x para simples; estenda para múltiplos preditores se avançado.",
                                  "learningObjective": "Estimar modelo linear ordinário e diagnosticar violações de pressupostos.",
                                  "commonMistakes": "Incluir intercepto desnecessário ou formula errada (e.g., y ~ x + ); ignorar diagnósticos de resíduos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e exibir erros padrão robustos com coeftest()",
                                  "subSteps": [
                                    "Execute coeftest(modelo, vcov=vcovHC(modelo, type=\"HC1\")) para HC1.",
                                    "Repita com type=\"HC3\" para comparação.",
                                    "Interprete: compare erros padrão robustos vs OLS.",
                                    "Salve resultados: robust_hc1 <- coeftest(modelo, vcov=vcovHC(modelo, type=\"HC1\")).",
                                    "Visualize diferenças com cbind(OLS=summary(modelo)$coefficients[,2], HC1=robust_hc1[,2])."
                                  ],
                                  "verification": "Output de coeftest() mostra 'Std. Error' maiores que OLS devido a robustez; t-values ajustados.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Modelo do step 3, pacotes sandwich e lmtest.",
                                  "tips": "HC1 é conservador para n médio; HC3 para n pequeno; especifique type explicitamente.",
                                  "learningObjective": "Aplicar correção de erros padrão robustos e interpretar inferência corrigida.",
                                  "commonMistakes": "Usar coeftest sem vcovHC, resultando em OLS padrão; erro de sintaxe em vcov=vcovHC()."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e validar inferência robusta",
                                  "subSteps": [
                                    "Compare p-values OLS vs robustos: se mudam, pressupostos violados.",
                                    "Teste formal de heteroscedasticidade com bptest(modelo).",
                                    "Reporte coeficientes robustos e intervalos de confiança.",
                                    "Crie tabela final com stargazer(modelo, type='text', se=NULL, covariate.labels=c('Intercepto','X')).",
                                    "Documente em relatório: 'Erros HC1 indicam significância robusta apesar de heteroscedasticidade.'"
                                  ],
                                  "verification": "Intervalos de confiança robustos incluem zero ou não conforme esperado; bptest rejeita homoscedasticidade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Resultados dos steps anteriores; opcional: stargazer package.",
                                  "tips": "Use confint(modelo, vcov=vcovHC(modelo,type='HC1')) para IC robustos.",
                                  "learningObjective": "Validar e comunicar inferência robusta em contexto de engenharia.",
                                  "commonMistakes": "Interpretar OLS como final sem robustez; ignorar mudança em significância."
                                }
                              ],
                              "practicalExample": "Em um projeto de engenharia civil, simule dados de resistência de concreto (y) vs tempo de cura (x) com heteroscedasticidade crescente. Ajuste lm(resistencia ~ tempo), então coeftest com HC3 revela que o efeito do tempo permanece significativo (p<0.01) apesar de erros OLS subestimados em 20%.",
                              "finalVerifications": [
                                "Pacote sandwich e lmtest carregados sem erros.",
                                "Modelo lm() ajustado com summary() mostrando OLS padrão.",
                                "coeftest() exibe erros HC1/HC3 maiores que OLS.",
                                "Interpretação correta: mudança em p-values devido a robustez.",
                                "Dataset simulado exibe heteroscedasticidade via plot(residuals~fitted).",
                                "Código reproduzível com set.seed()."
                              ],
                              "assessmentCriteria": [
                                "Correta instalação e uso de vcovHC(type='HC1' ou 'HC3').",
                                "Geração de dados com violação realista de homoscedasticidade.",
                                "Comparação explícita de erros padrão OLS vs robustos.",
                                "Interpretação precisa de inferência corrigida.",
                                "Código limpo, comentado e reproduzível.",
                                "Diagnóstico de resíduos e teste bptest aplicado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência robusta e testes de hipóteses.",
                                "Programação: Manipulação de dados e funções em R.",
                                "Engenharia: Modelagem preditiva em experimentos reais.",
                                "Matemática Computacional: Algoritmos numéricos para covariâncias.",
                                "Ciência de Dados: Análise exploratória e validação de modelos."
                              ],
                              "realWorldApplication": "Em engenharia mecânica, analise dados de fadiga de materiais onde variância de falhas aumenta com carga; erros robustos HC3 garantem inferência confiável para design seguro, evitando subestimação de incertezas em relatórios regulatórios."
                            },
                            "estimatedTime": "45 min",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.4.4.3.2",
                            "name": "Comparar erros padrão convencionais e robustos",
                            "description": "Gerar tabelas comparativas de coeficientes, erros padrão clássicos vs. robustos e estatísticas t, interpretando diferenças em termos de significância em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar conceitos teóricos de erros padrão convencionais e robustos",
                                  "subSteps": [
                                    "Defina erro padrão convencional (EP clássico) assumindo homoscedasticidade e independência dos resíduos.",
                                    "Explique erro padrão robusto (HC0, HC1, etc.) que corrige para heteroscedasticidade sem assumir distribuição normal.",
                                    "Discuta a estatística t como coeficiente dividido pelo EP e sua implicação na significância.",
                                    "Estude o impacto em grandes amostras: EP robustos convergem para o verdadeiro, enquanto clássicos superestimam precisão.",
                                    "Revise fórmulas matemáticas básicas: Var(β_hat) = σ² (X'X)^{-1} vs. robusta com sandwich estimator."
                                  ],
                                  "verification": "Resuma em um parágrafo as diferenças principais e cite uma referência como Wooldridge.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'Introductory Econometrics' de Wooldridge (cap. 8)",
                                    "Notebook Jupyter vazio",
                                    "Documentação statsmodels"
                                  ],
                                  "tips": "Use analogias: EP clássico é como medir peso em balança perfeita; robusto considera vibrações irregulares.",
                                  "learningObjective": "Compreender as premissas e fórmulas que diferenciam EP convencionais de robustos.",
                                  "commonMistakes": [
                                    "Confundir EP com desvio padrão dos resíduos",
                                    "Ignorar que robustos não corrigem autocorrelação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar regressão OLS com erros padrão convencionais",
                                  "subSteps": [
                                    "Carregue um dataset com potencial heteroscedasticidade (ex: Boston Housing).",
                                    "Ajuste modelo OLS simples: preço ~ tamanho + quartos.",
                                    "Extraia coeficientes, EP clássicos e estatísticas t usando statsmodels.",
                                    "Calcule p-valores e intervalos de confiança convencionais.",
                                    "Visualize resíduos para confirmar violação de homoscedasticidade (plot residuals vs fitted)."
                                  ],
                                  "verification": "Execute o código e confirme que a tabela de summary mostra 'std err' clássicos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com pandas, statsmodels, matplotlib",
                                    "Dataset Boston Housing via sklearn.datasets"
                                  ],
                                  "tips": "Sempre plote resíduos primeiro para motivar necessidade de robustos.",
                                  "learningObjective": "Executar e interpretar regressão OLS padrão em código.",
                                  "commonMistakes": [
                                    "Esquecer de importar sm.OLS",
                                    "Usar scale=False incorretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar regressão com erros padrão robustos",
                                  "subSteps": [
                                    "No mesmo modelo, aplique covariância robusta: model.fit(cov_type='HC1').",
                                    "Extraia coeficientes (iguais), mas EP robustos e t-stats ajustadas.",
                                    "Compare visualmente as tabelas side-by-side usando print ou pandas DataFrame.",
                                    "Teste diferentes HC (HC0, HC1, HC3) e note diferenças em amostras grandes.",
                                    "Calcule mudança percentual nos EP: (robusto - classico)/classico * 100."
                                  ],
                                  "verification": "Gere output mostrando EP robustos maiores que clássicos em variáveis afetadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Mesmo ambiente Python",
                                    "Código do step anterior"
                                  ],
                                  "tips": "HC1 é bom para n>50; use HC3 para pequenas amostras.",
                                  "learningObjective": "Aplicar e extrair estatísticas robustas em statsmodels.",
                                  "commonMistakes": [
                                    "Confundir cov_type com method",
                                    "Não salvar o modelo fitado"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Gerar tabela comparativa e interpretar diferenças",
                                  "subSteps": [
                                    "Crie DataFrame com colunas: Coef, EP Classico, EP Robusto, t Classico, t Robusto, Mudança %.",
                                    "Formate tabela em LaTeX ou Markdown para relatório.",
                                    "Interprete: Significância muda? Por quê em grandes amostras (EP robusto ~ verdadeiro).",
                                    "Discuta implicações: Evitar rejeitar H0 falsamente com EP subestimados.",
                                    "Salve como CSV e visualize diferenças em gráfico de barras."
                                  ],
                                  "verification": "Produza tabela final com pelo menos 3 variáveis e interpretação escrita.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "pandas para tabela",
                                    "matplotlib/seaborn para gráfico"
                                  ],
                                  "tips": "Use styler.to_latex() para tabelas profissionais.",
                                  "learningObjective": "Sintetizar comparações e inferir sobre significância robusta.",
                                  "commonMistakes": [
                                    "Ignorar sinal dos t-stats",
                                    "Não contextualizar com tamanho da amostra"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset Boston Housing (506 obs.), regredir MEDV ~ RM + LSTAT. Resíduos heteroscedásticos farão EP clássicos de LSTAT subestimarem variância. Tabela mostrará t-robusto menor, possivelmente mudando significância de 5% para 10%, ilustrando risco em amostras grandes como censos nacionais.",
                              "finalVerifications": [
                                "Gera tabela comparativa com coef, EP classico/robusto, t-stats e % diferença.",
                                "Identifica pelo menos uma variável onde significância muda.",
                                "Explica por que EP robustos são maiores em heteroscedasticidade.",
                                "Produz gráfico de resíduos confirmando violação.",
                                "Interpreta implicações para inferência em n>1000."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação: EP robustos corretamente extraídos (80%).",
                                "Qualidade da tabela: Clara, formatada, com todas métricas (20%).",
                                "Interpretação profunda: Liga diferenças a premissas e amostras grandes (30%).",
                                "Código limpo e reproduzível: Sem erros, comentado (20%).",
                                "Visualizações auxiliares: Plots de resíduos e barras de EP (20%).",
                                "Conclusão acionável: Quando usar robustos (30%)."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Manipulação de dados em Python/R (pandas/statsmodels).",
                                "Estatística Inferencial: Testes de hipóteses e intervalos de confiança.",
                                "Ciência de Dados: Modelagem preditiva com pressupostos relaxados.",
                                "Econometria: Aplicações em regressões causais reais.",
                                "Visualização de Dados: Tabelas e gráficos comparativos."
                              ],
                              "realWorldApplication": "Em análises financeiras (retornos de ações com volatilidade volátil), epidemias (regressão de mortalidade ~ vacinas com heteroscedasticidade regional) ou marketing (vendas ~ ads em grandes datasets), onde EP clássicos levam a políticas erradas baseadas em significância falsa."
                            },
                            "estimatedTime": "30 min",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.3.1"
                            ]
                          },
                          {
                            "id": "10.1.4.4.3.3",
                            "name": "Realizar testes de hipótese robustos",
                            "description": "Aplicar testes F e t com estatísticas robustas para validar hipóteses sobre coeficientes em modelos com pressupostos relaxados, usando exemplos de análise de dados industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e modelo de regressão com pressupostos relaxados",
                                  "subSteps": [
                                    "Carregue o conjunto de dados industriais (ex: produção fabril com variáveis como horas trabalhadas, treinamento e produtividade).",
                                    "Verifique violações de pressupostos clássicos como heteroscedasticidade usando testes como Breusch-Pagan.",
                                    "Selecione variáveis relevantes e limpe outliers se necessário, mantendo grandes amostras (n > 1000).",
                                    "Defina o modelo de regressão linear: Y = β0 + β1X1 + ... + ε, com ε possivelmente heteroscedástico.",
                                    "Implemente o modelo em Python usando statsmodels com covariância robusta (HC1 ou HC3)."
                                  ],
                                  "verification": "Modelo ajustado sem erros e resumo mostra coeficientes iniciais e erros padrão HC.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com statsmodels e pandas instalados",
                                    "Dataset industrial CSV (ex: simular com dados de produção fabril)"
                                  ],
                                  "tips": "Use sm.OLS(y, X).fit(cov_type='HC1') para robustez automática.",
                                  "learningObjective": "Configurar corretamente um modelo de regressão robusto a violações de homoscedasticidade.",
                                  "commonMistakes": [
                                    "Ignorar verificação de heteroscedasticidade",
                                    "Usar OLS padrão sem covariância robusta",
                                    "Não limpar dados adequadamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular erros padrão robustos e estatísticas t",
                                  "subSteps": [
                                    "Extraia os erros padrão robustos dos coeficientes do modelo ajustado.",
                                    "Calcule estatísticas t robustas: t = β / SE_robust para cada coeficiente.",
                                    "Defina hipóteses nulas: H0: βj = 0 para coeficientes individuais.",
                                    "Calcule p-valores associados usando distribuição t ou normal para grandes amostras.",
                                    "Compare com níveis de significância (α=0.05, 0.01)."
                                  ],
                                  "verification": "Tabela de summary mostra SE robustos, t-stats e p-values corretos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "statsmodels library"
                                  ],
                                  "tips": "Sempre especifique cov_type='HC3' para amostras finitas em dados industriais.",
                                  "learningObjective": "Computar e interpretar estatísticas t robustas para testes univariados.",
                                  "commonMistakes": [
                                    "Confundir SE padrão com SE robusto",
                                    "Usar distribuição errada para p-values",
                                    "Esquecer de ajustar por graus de liberdade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar testes F robustos para múltiplos coeficientes",
                                  "subSteps": [
                                    "Defina hipóteses conjuntas: H0: βj = βk = 0 (ex: grupo de variáveis de treinamento).",
                                    "Use model.wald_test(R, cov_type='HC1') onde R é a matriz de restrições.",
                                    "Calcule a estatística F robusta e seu p-value.",
                                    "Interprete: rejeitar H0 se p < α.",
                                    "Compare com teste t individual para consistência."
                                  ],
                                  "verification": "Resultado do wald_test mostra F-stat, p-value e rejeição correta de H0.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.formula.api",
                                    "Matriz de restrições numpy array"
                                  ],
                                  "tips": "Para restrições simples, R = [[0,1,0,...]] para β1=0.",
                                  "learningObjective": "Aplicar testes F robustos para validação de subconjuntos de coeficientes.",
                                  "commonMistakes": [
                                    "Definir matriz R incorreta",
                                    "Não usar cov_type robusto no wald_test",
                                    "Ignorar multicolinearidade em grupos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e validar hipóteses",
                                  "subSteps": [
                                    "Resuma achados: quais hipóteses foram rejeitadas e com que confiança.",
                                    "Avalie robustez comparando com OLS padrão.",
                                    "Reporte intervalos de confiança robustos: conf_int(alpha=0.05).",
                                    "Discuta implicações para dados industriais (ex: impacto do treinamento na produtividade).",
                                    "Documente em relatório com tabelas e gráficos de resíduos."
                                  ],
                                  "verification": "Relatório final com tabelas de testes t/F, p-values e conclusões claras.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Matplotlib para plots de resíduos",
                                    "Pandas para tabelas"
                                  ],
                                  "tips": "Sempre plote resíduos vs fitted para visualizar heteroscedasticidade.",
                                  "learningObjective": "Interpretar e comunicar inferências robustas de forma acionável.",
                                  "commonMistakes": [
                                    "Superestimar significância sem robustez",
                                    "Não reportar p-values ajustados",
                                    "Ignorar contexto industrial nos resultados"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica, modelo: produtividade ~ horas_trabalhadas + horas_treinamento + turno_noite. Teste t: H0: β_treinamento = 0 (espera-se rejeição). Teste F: H0: β_treinamento = β_turno_noite = 0. Com dados heteroscedásticos, SE robustos mostram significância real.",
                              "finalVerifications": [
                                "Testes t rejeitam corretamente H0 para coeficientes esperados.",
                                "Teste F conjunto é consistente com testes individuais.",
                                "P-values e IC robustos alinhados com α=0.05.",
                                "Resíduos mostram padrão heteroscedástico resolvido pela robustez.",
                                "Relatório interpreta implicações industriais.",
                                "Código reproduzível sem erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação de covariâncias robustas (HC1/HC3).",
                                "Correção das matrizes de restrições para testes F.",
                                "Interpretação adequada de p-values e rejeições de H0.",
                                "Uso de grandes amostras com verificação de pressupostos relaxados.",
                                "Clareza no relatório com exemplos industriais.",
                                "Ausência de erros comuns como SE não-robustos."
                              ],
                              "crossCurricularConnections": [
                                "Programação em Python/R (statsmodels/lmtest).",
                                "Estatística inferencial básica (distribuições t/F).",
                                "Análise de dados industriais (machine learning pipelines).",
                                "Econometria (modelos com erros padrão clusterizados).",
                                "Visualização de dados (plots de diagnósticos)."
                              ],
                              "realWorldApplication": "Em indústrias manufatureiras, validar se programas de treinamento impactam produtividade apesar de variabilidade nos turnos, guiando alocações de recursos e políticas de RH com confiança estatística robusta."
                            },
                            "estimatedTime": "45 min",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.3.2"
                            ]
                          },
                          {
                            "id": "10.1.4.4.3.4",
                            "name": "Aplicar em dados de grandes amostras",
                            "description": "Analisar um dataset real de engenharia (ex.: eficiência energética) com milhares de observações, computando erros padrão robustos e discutindo robustez da inferência.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Aquisição e Exploração Inicial do Dataset",
                                  "subSteps": [
                                    "Baixe um dataset real de engenharia com milhares de observações, como o 'Individual household electric power consumption' (mais de 2 milhões de linhas) do UCI ML Repository.",
                                    "Carregue o dataset em Python usando pandas (pd.read_csv()).",
                                    "Examine estrutura: df.info(), df.describe(), df.head() e verifique tamanho (len(df)).",
                                    "Identifique variáveis: dependente (ex.: consumo de energia) e independentes (ex.: temperatura, umidade).",
                                    "Visualize distribuições com histograms e scatterplots usando matplotlib/seaborn."
                                  ],
                                  "verification": "Dataset carregado com >1000 observações confirmadas via df.shape; gráficos gerados e salvos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (pandas, matplotlib, seaborn), dataset UCI 'Household Power Consumption' (https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption)",
                                  "tips": "Use chunking (pd.read_csv(chunksize=10000)) para datasets muito grandes para evitar problemas de memória.",
                                  "learningObjective": "Compreender a escala e características de datasets de grandes amostras em contextos de engenharia.",
                                  "commonMistakes": "Ignorar valores ausentes ou outliers iniciais; assumir dataset limpo sem exploração."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparação e Limpeza dos Dados",
                                  "subSteps": [
                                    "Trate valores ausentes: df.fillna(method='ffill') ou remoção (df.dropna()).",
                                    "Remova ou trate outliers usando IQR method (Q1 - 1.5*IQR, Q3 + 1.5*IQR).",
                                    "Crie subconjunto amostral se necessário (df.sample(n=50000)) para testes iniciais.",
                                    "Codifique variáveis categóricas se aplicável (pd.get_dummies()).",
                                    "Divida em treino/teste: train_test_split(X, y, test_size=0.2)."
                                  ],
                                  "verification": "Dataset limpo com shape verificado, sem NaNs (df.isnull().sum().sum() == 0) e divisão confirmada.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (pandas, scikit-learn), notebook Jupyter.",
                                  "tips": "Mantenha um log de transformações em um dict para reprodutibilidade.",
                                  "learningObjective": "Preparar dados massivos para modelagem robusta, lidando com impurezas comuns em dados reais.",
                                  "commonMistakes": "Sobre-limpeza removendo dados válidos; não documentar passos de limpeza."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajuste do Modelo de Regressão e Cálculo de Erros Padrão Robustos",
                                  "subSteps": [
                                    "Ajuste modelo OLS: sm.OLS(y, sm.add_constant(X)).fit().",
                                    "Instale e use statsmodels para erros robustos: model.fit(cov_type='HC3').",
                                    "Extraia coeficientes e erros padrão: results.summary() e results.bse.",
                                    "Compare erros padrão padrão vs. robustos em tabela.",
                                    "Teste pressupostos relaxados: verifique heteroscedasticidade com Breusch-Pagan test."
                                  ],
                                  "verification": "Tabela de summary gerada mostrando erros padrão robustos diferentes dos padrão em pelo menos um coeficiente.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (statsmodels, scikit-learn), notebook Jupyter.",
                                  "tips": "Use cov_type='HC1' ou 'HC3' para amostras grandes; plote residuals vs. fitted para visual inspeção.",
                                  "learningObjective": "Implementar regressão com erros padrão robustos para inferência confiável em grandes datasets.",
                                  "commonMistakes": "Usar erros padrão padrão sem testar violações de homoscedasticidade; ignorar warnings de convergência."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Inferência Estatística e Análise de Robustez",
                                  "subSteps": [
                                    "Calcule intervalos de confiança: results.conf_int(alpha=0.05).",
                                    "Teste hipóteses: results.t_test() para coeficientes específicos.",
                                    "Discuta robustez: compare significância com/s em erros robustos; avalie impacto de outliers.",
                                    "Realize bootstrap para validação (1000 reamostragens).",
                                    "Gere relatório: interprete resultados no contexto de eficiência energética."
                                  ],
                                  "verification": "Intervalos de confiança e p-values robustos documentados; discussão escrita de pelo menos 200 palavras.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (statsmodels, numpy para bootstrap), notebook Jupyter.",
                                  "tips": "Para bootstrap em grandes dados, use frações (0.8 do tamanho) para eficiência computacional.",
                                  "learningObjective": "Avaliar e discutir a robustez da inferência estatística sob pressupostos relaxados.",
                                  "commonMistakes": "Interpretar p-values sem contexto; superestimar robustez sem comparações."
                                }
                              ],
                              "practicalExample": "Analise o dataset 'Household Electric Power Consumption' (2M+ observações): modele consumo global ativo como função de voltage, global intensity e sub metering. Compute erros padrão robustos HC3, note como heteroscedasticidade (devido a picos de uso) infla erros padrão em 20-30% para voltage, alterando significância de coeficientes.",
                              "finalVerifications": [
                                "Dataset processado com >1000 observações efetivas.",
                                "Erros padrão robustos computados e comparados aos padrão.",
                                "Intervalos de confiança e p-values reportados corretamente.",
                                "Discussão de robustez inclui testes de diagnóstico.",
                                "Resultados interpretados no contexto de engenharia energética.",
                                "Código reproduzível e relatório gerado."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de erros padrão robustos (cov_type correto).",
                                "Profundidade da discussão sobre robustez e pressupostos relaxados.",
                                "Qualidade da exploração e limpeza de dados massivos.",
                                "Correta interpretação de inferência (IC, p-values).",
                                "Uso apropriado de visualizações e testes diagnósticos.",
                                "Clareza e estrutura do relatório final."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia Elétrica: Otimização de eficiência energética.",
                                "Ciência de Dados: Manipulação de big data com pandas.",
                                "Estatística: Inferência robusta e bootstrap.",
                                "Programação Computacional: Otimização para grandes datasets."
                              ],
                              "realWorldApplication": "Em empresas de utilities energéticas, analistas usam essa técnica para inferir impactos de variáveis ambientais no consumo de energia em milhões de medições de smart meters, guiando políticas de eficiência e previsão de demanda robusta a violações de pressupostos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.4.4.3.1"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.4.5",
                    "name": "Inferência em Regressão com Pressupostos Relaxados",
                    "description": "Testes de hipóteses e intervalos de confiança válidos em cenários realistas.",
                    "individualConcepts": [
                      {
                        "id": "10.1.4.5.1",
                        "name": "Propriedades Assintóticas dos Estimadores MQO",
                        "description": "Compreender as propriedades de consistência e normalidade assintótica dos estimadores de mínimos quadrados ordinários (MQO) em grandes amostras, sob pressupostos relaxados como ausência de normalidade dos erros e presença de heteroscedasticidade ou dependência serial.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.5.1.1",
                            "name": "Consistência Assintótica do MQO",
                            "description": "Demonstrar que o estimador MQO é consistente em grandes amostras, ou seja, converge em probabilidade para o vetor verdadeiro de parâmetros sob pressupostos mínimos (exogeneidade e momentos finitos).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Mínimos para Consistência Assintótica do MQO",
                                  "subSteps": [
                                    "Identifique os pressupostos essenciais: exogeneidade estrita (E[ε|X] = 0) e momentos finitos (E[XX'] e E[Xε] finitos).",
                                    "Explique por que relevância (rank(X) = K) é necessária para identificação.",
                                    "Discuta homocedasticidade e não-serial correlation não serem requeridas para consistência.",
                                    "Liste pressupostos relaxados em comparação com MQO clássico (sem esfericidade dos erros).",
                                    "Escreva formalmente: plim (1/n X'X) = Qxx e plim (1/n X'y) = Qxy, onde Q são matrizes de probabilidade."
                                  ],
                                  "verification": "Resuma os 3-4 pressupostos chave em um parágrafo coerente e sem erros.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de Wooldridge 'Econometric Analysis' capítulo 3",
                                    "Notas de aula sobre regressão linear",
                                    "Calculadora ou software como R para matrizes simples"
                                  ],
                                  "tips": "Comece pelos pressupostos mais fracos; memorize acrônimo para exogeneidade (E[ε|X]=0).",
                                  "learningObjective": "Compreender os pressupostos mínimos que garantem convergência em probabilidade do estimador MQO.",
                                  "commonMistakes": [
                                    "Confundir consistência com não-viés (não-viés requer E[ε|X]=0, mas consistência é assintótica)",
                                    "Ignorar momentos finitos como condição necessária",
                                    "Achar que homocedasticidade é obrigatória"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Expressão Assintótica do Estimador MQO",
                                  "subSteps": [
                                    "Escreva o estimador MQO: β̂ = (X'X/n)^{-1} (X'y/n).",
                                    "Substitua y = Xβ + ε para obter β̂ = β + (X'X/n)^{-1} (X'ε/n).",
                                    "Mostre que plim(β̂) = β + plim[(X'X/n)^{-1}] plim(X'ε/n), assumindo convergência.",
                                    "Verifique que plim(X'ε/n) = 0 sob exogeneidade (E[Xε]=0).",
                                    "Confirme invertibilidade contínua de plim(X'X/n) = Qxx positiva definida."
                                  ],
                                  "verification": "Derive algebricamente plim(β̂) = β em um quadro, passo a passo.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Lápis e papel para derivação matricial",
                                    "Software MATLAB ou Python (NumPy) para simular matrizes X'X/n",
                                    "Tutorial de álgebra matricial online"
                                  ],
                                  "tips": "Use notação plim consistentemente; divida em termos separáveis para clareza.",
                                  "learningObjective": "Derivar formalmente a convergência em probabilidade do estimador MQO para o verdadeiro β.",
                                  "commonMistakes": [
                                    "Esquecer de dividir por n nos termos",
                                    "Não justificar plim(X'ε/n)=0 via média condicional",
                                    "Assumir Qxx invertível sem rank completo"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Leis Assintóticas (Lei dos Grandes Números) à Prova",
                                  "subSteps": [
                                    "Revise a Lei dos Grandes Números (LLN) para vetores i.i.d.: plim(1/n ∑ Zi) = E[Zi].",
                                    "Aplique LLN a (1/n X'X) →p Qxx e (1/n X'ε) →p E[Xε]=0.",
                                    "Use teorema de Slutsky para plim[(X'X/n)^{-1} (X'ε/n)] = Qxx^{-1} * 0 = 0.",
                                    "Discuta ergodicidade estacionária se dados não forem i.i.d., mas dependentes fracos.",
                                    "Prove informalmente para regressão simples (K=2) para intuição."
                                  ],
                                  "verification": "Explique verbalmente a prova usando LLN e Slutsky, gravando um áudio de 2 minutos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Artigo de Hansen 'Econometrics' seção assintóticos",
                                    "Python com SciPy para LLN simulações",
                                    "Video-aula de Davidson e MacKinnon sobre LLN"
                                  ],
                                  "tips": "Visualize com gráfico de convergência de médias amostrais para X'X/n.",
                                  "learningObjective": "Aplicar ferramentas probabilísticas (LLN, Slutsky) para provar consistência assintótica.",
                                  "commonMistakes": [
                                    "Aplicar TLLN sem verificar i.i.d. ou momentos",
                                    "Confundir LLN com TLC (TCL é para normalidade)",
                                    "Esquecer Slutsky para produto de convergentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e Simular Consistência em Prática",
                                  "subSteps": [
                                    "Gere dados simulados: X ~ N(0,1), ε ~ N(0,1) independente, β verdadeiro = [1,2].",
                                    "Estime MQO para n=10,100,1000 e plote β̂ vs n.",
                                    "Calcule bias(β̂) e MSE, observe redução com n crescente.",
                                    "Teste violação: corrija ε com X (endogeneidade) e veja não-convergência.",
                                    "Compare com estimadores inconsistentes como média amostral em modelo misspecífico."
                                  ],
                                  "verification": "Produza gráfico de convergência e relatório com MSE para n=1000 < 0.01.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "R ou Python (statsmodels/sklearn para OLS)",
                                    "Jupyter Notebook para simulações",
                                    "Dados sintéticos gerados via np.random"
                                  ],
                                  "tips": "Use loop para múltiplas simulações (Monte Carlo) e médias.",
                                  "learningObjective": "Validar teoricamente consistência via simulação numérica e diagnóstico.",
                                  "commonMistakes": [
                                    "n insuficiente para ver convergência",
                                    "Não seed random para reprodutibilidade",
                                    "Ignorar variância em plots (use boxplots)"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários vs anos de educação (n=1000), estime MQO para β_educ. Simule aumentando n para 10k: observe β̂ convergindo de 0.08 para verdadeiro 0.10, com bias caindo de 0.02 para 0.001, demonstrando consistência mesmo sem homocedasticidade.",
                              "finalVerifications": [
                                "Derive corretamente plim(β̂) = β sob pressupostos mínimos.",
                                "Explique papel da LLN e Slutsky na prova.",
                                "Simule e plote convergência para n>500 com MSE<0.005.",
                                "Identifique cenários onde consistência falha (endogeneidade).",
                                "Discuta implicações para inferência em grandes amostras.",
                                "Resolva exercício: prove para regressão simples sem matrizes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação assintótica (sem erros algébricos).",
                                "Compreensão conceitual de pressupostos relaxados vs clássicos.",
                                "Qualidade da simulação (gráficos claros, múltiplos runs).",
                                "Aplicação correta de teoremas probabilísticos.",
                                "Capacidade de diagnosticar violações via exemplo.",
                                "Clareza na explicação verbal/escrita da prova."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Leis dos Grandes Números e convergência em probabilidade.",
                                "Estatística Computacional: Simulações Monte Carlo para propriedades assintóticas.",
                                "Econometria: Extensão para IV e GMM em endogeneidade.",
                                "Machine Learning: Analogia com convergência de gradiente descendente em regressão.",
                                "Análise de Dados: Validação em big data sem pressupostos fortes."
                              ],
                              "realWorldApplication": "Em análises de grandes datasets como dados de saúde pública (n=1M), o MQO consistentemente estima efeitos causais aproximados (ex: impacto de vacinas), permitindo políticas baseadas em β̂ confiáveis mesmo com erros heterocedásticos, comum em bancos de dados reais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.5.1.2",
                            "name": "Normalidade Assintótica dos Estimadores",
                            "description": "Explicar e derivar a distribuição assintótica normal dos estimadores MQO, √n(β̂ - β) ~ N(0, AsyVar), onde AsyVar é a matriz de variância assintótica, válida mesmo sem normalidade dos erros.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Assintóticos para Consistência do Estimador MQO",
                                  "subSteps": [
                                    "Identifique os pressupostos básicos relaxados: exogeneidade condicional estrita (E[u|X]=0), sem multicolinearidade perfeita assintótica e momentos finitos de X e u.",
                                    "Explique convergência em probabilidade: plim (1/n) X'X = Q (matriz não-singular) e plim (1/n) X'u = 0.",
                                    "Derive β̂ →p β usando a representação β̂ = β + (X'X/n)^{-1} (X'u/n).",
                                    "Discuta validade sem normalidade dos erros: foco em momentos finitos E[||X||^k]<∞ e E[u^2|X]<∞.",
                                    "Resuma condições para √n-consistência: Var(√n (X'u/n)) → Σ finita."
                                  ],
                                  "verification": "Escreva os pressupostos e prove β̂ →p β em um quadro ou documento.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Introdução à Econometria' de Wooldridge (Cap. 10)",
                                    "Notas de aula sobre regressão assintótica",
                                    "Lápis e papel para derivações"
                                  ],
                                  "tips": "Comece com os 4 pressupostos assintóticos padrão; memorize Q = plim(X'X/n).",
                                  "learningObjective": "Compreender as condições sob as quais o MQO é consistente assintoticamente sem normalidade dos erros.",
                                  "commonMistakes": [
                                    "Confundir exogeneidade estrita com E[u]=0 incondicional",
                                    "Ignorar requisitos de momentos finitos para X",
                                    "Esquecer que Q deve ser positiva definida"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Matriz de Variância Assintótica (AsyVar)",
                                  "subSteps": [
                                    "Expanda √n(β̂ - β) = (X'X/n)^{-1} (1/√n X'u) ≈ Q^{-1} (1/√n X'u).",
                                    "Mostre que Var_as(1/√n X'u | X) → Σ = E[X X' Var(u|X)] = E[X X' σ^2] se homocedástico.",
                                    "Derive AsyVar(β̂) = lim n→∞ n Var(β̂) = Q^{-1} Σ Q^{-1}.",
                                    "Discuta caso heterocedástico: Σ = E[σ_i^2 X_i X_i'].",
                                    "Calcule exemplos simples: regressão simples com Var(u|X)=σ^2 constante."
                                  ],
                                  "verification": "Derive e escreva a fórmula explícita de AsyVar para modelo com k=1 regressor.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Whiteboard ou software LaTeX para equações",
                                    "Artigo 'Asymptotic Theory for Econometricians' de Hamilton",
                                    "Calculadora simbólica como SymPy (opcional)"
                                  ],
                                  "tips": "Use aproximação Slutsky para justificar Q^{-1} →p Q^{-1}; foque em notação matricial.",
                                  "learningObjective": "Derivar precisamente a variância assintótica do MQO sob pressupostos relaxados.",
                                  "commonMistakes": [
                                    "Usar variância finita-sample em vez de assintótica",
                                    "Confundir Σ com Var(u)",
                                    "Esquecer inversas em ambos os lados: Q^{-1} Σ Q^{-1}"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Provar Normalidade Assintótica via Teorema Central do Limite (CLT)",
                                  "subSteps": [
                                    "Verifique condições do CLT para médias: (1/√n X'u) como média de variáveis i.i.d. ou estacionárias com momentos finitos.",
                                    "Aplique CLT matricial: √n(β̂ - β) →d N(0, Q^{-1} Σ Q^{-1}).",
                                    "Explique independência da normalidade dos erros: CLT requer apenas E[u|X]=0 e Var(u|X)<∞.",
                                    "Discuta CLT para dependência fraca (se aplicável em painéis).",
                                    "Compare com distribuição exata: só normal sob normalidade de u."
                                  ],
                                  "verification": "Esboce a prova usando Lindeberg-Feller CLT e Slutsky; identifique termos o_p(1/√n).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "'Probabilistic Symbiosis in Statistics' de Davidson & MacKinnon",
                                    "Vídeo Khan Academy sobre CLT matricial",
                                    "Papel para diagramas de convergência"
                                  ],
                                  "tips": "Pense em 1/√n X'u como soma de X_i u_i / √n; normalize por √n.",
                                  "learningObjective": "Entender como o CLT garante normalidade assintótica mesmo com erros não-normais.",
                                  "commonMistakes": [
                                    "Aplicar CLT sem verificar momentos de ordem 2+",
                                    "Confundir →d com →p",
                                    "Ignorar condicionamento em X para CLT condicional"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar Numericamente via Simulação Monte Carlo",
                                  "subSteps": [
                                    "Gere dados: Y_i = X_i β + u_i com u_i ~ t(3) (não-normal, caudas pesadas).",
                                    "Estime β̂ para n=100, 1000, 10000; compute √n(β̂ - β).",
                                    "Plote histogramas e Q-Q plots contra N(0, AsyVar).",
                                    "Estime AsyVar empiricamente: sample Q e Σ.",
                                    "Teste formal: Shapiro-Wilk ou Kolmogorov-Smirnov para normalidade."
                                  ],
                                  "verification": "Execute simulação em R/Python e produza gráficos mostrando convergência para n grande.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Python (numpy, statsmodels, matplotlib) ou R (lm, ggplot2)",
                                    "Notebook Jupyter",
                                    "Código template para simulação OLS assintótica"
                                  ],
                                  "tips": "Use n_rep=1000 simulações; compute std dev empírica e compare com sqrt(AsyVar/n).",
                                  "learningObjective": "Validar teoricamente a normalidade assintótica através de experimentos computacionais.",
                                  "commonMistakes": [
                                    "n pequeno (use n>5000)",
                                    "Erros não-mean-zero",
                                    "Não escalar por √n nos plots"
                                  ]
                                }
                              ],
                              "practicalExample": "Simule uma regressão linear simples Y = 1 + 2X + u, com X~N(0,1), u~t(3) (não-normal). Para n=10000, estime β̂ 500 vezes, plote √n(β̂ - β) e observe aproximação à N(0, AsyVar) com AsyVar ≈ (1/Var(X)) * E[Var(u|X)] = 3/1 (pois Var(t(3))=3).",
                              "finalVerifications": [
                                "Deriva corretamente √n(β̂ - β) →d N(0, Q^{-1} Σ Q^{-1}).",
                                "Explica por que normalidade assintótica holds sem normalidade de u.",
                                "Identifica AsyVar em modelo heterocedástico.",
                                "Implementa simulação mostrando convergência visual.",
                                "Discute limitações (e.g., se E[||X u||^{2+δ}]=∞).",
                                "Compara com testes t/Wald finitos vs assintóticos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação de AsyVar (fórmula matricial correta).",
                                "Compreensão conceitual: distinção entre exata e assintótica normalidade.",
                                "Profundidade em CLT: condições e aplicação matricial.",
                                "Qualidade da simulação: plots claros, n adequado, comparação quantitativa.",
                                "Capacidade de generalizar para casos relaxados (heterocedasticidade, clusters).",
                                "Clareza na explicação oral/escrita de toda a cadeia lógica."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade: Teorema Central do Limite matricial e convergência em distribuição.",
                                "Estatística Computacional: Simulações Monte Carlo para validação assintótica.",
                                "Econometria: Inferência robusta em grandes dados (e.g., sandwich estimators).",
                                "Machine Learning: Análise de variância em regressão linear de alta dimensão.",
                                "Matemática Aplicada: Teoria de aproximações em espaços vetoriais."
                              ],
                              "realWorldApplication": "Em big data econométrico (e.g., regressões com milhões de observações em surveys como PNAD), usa-se normalidade assintótica para intervalos de confiança de β̂ sem assumir u~N(0,σ^2), permitindo inferência robusta em erros heterocedásticos ou com caudas pesadas, comum em finanças (retornos de ações) ou saúde (dados de trials clínicos)."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.5.1.3",
                            "name": "Cálculo da Variância Assintótica",
                            "description": "Calcular a matriz de variância assintótica dos estimadores MQO, incorporando heteroscedasticidade condicional e dependência serial fraca em grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Pressupostos Assintóticos do Estimador MQO",
                                  "subSteps": [
                                    "Relembrar os pressupostos clássicos do MQO (linearidade, exogeneidade, homoscedasticidade, não-autocorrelação).",
                                    "Identificar pressupostos relaxados para grandes amostras: consistência plim β_hat = β e normalidade assintótica √n(β_hat - β) ~ N(0, V).",
                                    "Entender o papel da matriz de informação assintótica: V = lim (1/n) E[X' Ω X], onde Ω é a matriz de variância dos erros.",
                                    "Discutir condições para convergência: ergodicidade estacionária e momentos finitos de ordem superior.",
                                    "Derivar intuitivamente a decomposição: variância = (E[X'X/n])^{-1} Var(√n X'u) (E[X'X/n])^{-1}."
                                  ],
                                  "verification": "Escrever os pressupostos relaxados e derivar a forma assintótica básica da variância em um caderno ou software.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de Econometria (ex: Wooldridge), notas de aula sobre regressão assintótica, calculadora simbólica (SymPy ou Mathematica)"
                                  ],
                                  "tips": "Comece com o caso homoscedástico para contrastar com os relaxados; use diagramas de Venn para pressupostos.",
                                  "learningObjective": "Compreender os fundamentos teóricos que sustentam a variância assintótica do MQO sob relaxamentos.",
                                  "commonMistakes": [
                                    "Confundir consistência com normalidade assintótica",
                                    "Ignorar a necessidade de grandes amostras (n→∞)",
                                    "Esquecer ergodicidade para processos dependentes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar Variância Assintótica sob Heteroscedasticidade Condicional",
                                  "subSteps": [
                                    "Definir heteroscedasticidade condicional: Var(u_i | X_i) = σ_i²(X_i), com E(u_i | X_i)=0.",
                                    "Estimar a matriz sandwich: Â = (X'X/n)^{-1} (∑ x_i x_i' û_i² / n) (X'X/n)^{-1}.",
                                    "Provar consistência de Â sob condições de White (1980): uniformidade e momentos finitos.",
                                    "Calcular a variância de cada elemento da matriz Â explicitamente para regressão simples.",
                                    "Implementar correção HC0, HC1, HC2 ou HC3 em código para validação."
                                  ],
                                  "verification": "Derivar a fórmula da matriz sandwich para um modelo y = β0 + β1 x + u e computar para dados simulados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software R ou Python (statsmodels, lmtest), dados simulados com heteroscedasticidade (ex: σ_i = |x_i|)"
                                  ],
                                  "tips": "Use a notação matricial compacta; teste com n=1000 para aproximar assintóticos.",
                                  "learningObjective": "Dominar o cálculo da variância robusta a heteroscedasticidade condicional.",
                                  "commonMistakes": [
                                    "Usar HC sem graus de liberdade ajustados (HC1/HC2)",
                                    "Assumir homoscedasticidade nos resíduos estimados",
                                    "Não normalizar por n"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Incorporar Dependência Serial Fraca na Variância Assintótica",
                                  "subSteps": [
                                    "Introduzir autocorrelação fraca: Cov(u_t, u_{t-j}) ≠ 0 para j pequeno, mas ∑ |ρ_j| < ∞ (mixing).",
                                    "Estender para estimadores HAC (Newey-West, 1987): kernel truncado ou Bartlett para ∑_{j=-T}^T w(j/T) Γ(j).",
                                    "Calcular a matriz de autocovariâncias long-run: Ω = Γ(0) + ∑_{j=1}^∞ [Γ(j) + Γ(j)'].",
                                    "Implementar Newey-West com lag ótimo: floor(4*(T/100)^{2/9}).",
                                    "Comparar variâncias HC vs HAC em séries temporais simuladas."
                                  ],
                                  "verification": "Aplicar Newey-West a uma série AR(1) nos erros e verificar se a variância aumenta corretamente.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Pacotes R: sandwich::NeweyWest(), Python: arch ou statsmodels, dados ARMA simulados"
                                  ],
                                  "tips": "Escolha kernel Bartlett para iniciante; valide com simulações Monte Carlo.",
                                  "learningObjective": "Calcular variância assintótica robusta a dependência serial fraca.",
                                  "commonMistakes": [
                                    "Escolher lag muito pequeno (subestima variância)",
                                    "Ignorar simetria em Γ(j)",
                                    "Confundir serial com cross-sectional dependence"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar e Validar Cálculo Completo da Matriz de Variância",
                                  "subSteps": [
                                    "Gerar dados simulados com heteroscedasticidade e AR(1): u_t = σ_t ε_t, ε_t ~ WN, σ_t = f(x_t), u_t = ρ u_{t-1} + innov.",
                                    "Estimar MQO, calcular variância manualmente (sandwich + HAC).",
                                    "Usar software para replicar: coeficientes SE e intervalos de confiança assintóticos.",
                                    "Realizar teste de robustez: comparar com bootstrap para validação.",
                                    "Documentar a matriz final V e interpretar elementos (ex: Var(β1))."
                                  ],
                                  "verification": "Produzir código que outputa a matriz V exata e compara com software, com erro <1%.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python (numpy, pandas, statsmodels), R, Jupyter notebook para simulações"
                                  ],
                                  "tips": "Seed RNG para reprodutibilidade; plote resíduos para diagnosticar violações.",
                                  "learningObjective": "Aplicar integralmente o cálculo em contexto prático com ambos os relaxamentos.",
                                  "commonMistakes": [
                                    "Não centralizar variáveis para HAC",
                                    "Usar resíduos OLS em vez de centrados",
                                    "Ignorar escala assintótica √n"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de retornos diários de ações (n=2000), regredir log-retorno em lagged volume e volatilidade. Erros exibem heteroscedasticidade (clusters de alta vol) e serial corr (AR(1)=0.3). Calcule V assintótica via Newey-West HC3: Var(β_volume) ≈ 0.00015, SE≈0.012, CI 95% [-0.024, 0.036].",
                              "finalVerifications": [
                                "Deriva corretamente a fórmula sandwich-HAC para MQO.",
                                "Implementa código que replica variâncias de software padrão.",
                                "Interpreta diagonal/off-diagonal de V (variâncias/covariâncias).",
                                "Valida com simulação Monte Carlo (cobertura de IC ~95%).",
                                "Discute limitações em amostras finitas.",
                                "Ajusta lag de HAC baseado em dados."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação teórica (fórmulas corretas, 30%).",
                                "Implementação computacional sem erros (replicação exata, 25%).",
                                "Interpretação econômica dos resultados (20%).",
                                "Tratamento de edge cases (n pequeno, forte serial, 15%).",
                                "Clareza na documentação (10%).",
                                "Validação via bootstrap ou testes (bonus)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Teorema do Limite Central e CLT para dependentes.",
                                "Programação: Otimização numérica e simulações Monte Carlo.",
                                "Econometria: Testes de hipóteses robustos (t-Wald assintótico).",
                                "Ciência de Dados: Previsão em time series com ML (ajuste de variância).",
                                "Matemática: Álgebra linear matricial e séries de covariância."
                              ],
                              "realWorldApplication": "Em finanças, calcular variância assintótica de betas em CAPM com retornos voláteis e autocorrelacionados permite intervalos de confiança robustos para risco sistêmico, auxiliando portfólios e regulação (ex: VAR models no Fed)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.5.2",
                        "name": "Testes de Hipóteses Assintóticos",
                        "description": "Aplicar testes de hipóteses baseados em aproximações assintóticas para inferência em regressão linear com pressupostos relaxados, garantindo validade em cenários realistas com grandes amostras.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.5.2.1",
                            "name": "Teste t Assintótico para Coeficientes Individuais",
                            "description": "Realizar o teste t assintótico H0: βj = βj0 usando estatística z = (β̂j - βj0)/se(β̂j) ~ N(0,1) sob pressupostos relaxados, interpretando p-valores e rejeição.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos Teóricos do Teste t Assintótico",
                                  "subSteps": [
                                    "Revise os pressupostos relaxados para regressão em grandes amostras: independência, momentos finitos e Lei dos Grandes Números (LLN)/Teorema Central do Limite (TCL).",
                                    "Entenda a distribuição assintótica dos estimadores: β̂j ~ N(βj, σ² / (n * Var(xj))) levando a z = (β̂j - βj0)/se(β̂j) ~ N(0,1) sob H0: βj = βj0.",
                                    "Compare com teste t finito: em amostras grandes (n>100), z ≈ t, mas z é exato assintoticamente sem assumir normalidade de erros.",
                                    "Identifique quando usar: heterocedasticidade ou não-linearidades permitidas via TCL.",
                                    "Estude fórmula de se(β̂j) robusta: sqrt( Var(β̂j) ) via sanduíche se necessário."
                                  ],
                                  "verification": "Explique em suas palavras por que o teste usa N(0,1) em vez de t(df=n-k-1) e cite um pressuposto relaxado.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notas de aula sobre regressão assintótica",
                                    "Software R ou Python com pacotes como lmtest ou statsmodels"
                                  ],
                                  "tips": "Visualize com histogramas de β̂j em simulações Monte Carlo para ver convergência a normal.",
                                  "learningObjective": "Dominar a justificativa teórica para o uso da estatística z sob pressupostos relaxados.",
                                  "commonMistakes": [
                                    "Confundir com teste t exato (exigindo normalidade de erros)",
                                    "Ignorar necessidade de grandes n (n<30 falha)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Dados e Estimar o Modelo de Regressão",
                                  "subSteps": [
                                    "Carregue dataset grande (n>500) com variáveis explicativas e dependente.",
                                    "Estime OLS: Y = Xβ + ε, obtenha β̂j e se(β̂j) via summary() em R ou .summary() em Python.",
                                    "Verifique tamanho da amostra e multicolinearidade (VIF<10).",
                                    "Calcule erros padrão robustos se suspeita de heterocedasticidade (HC1 ou HC3).",
                                    "Extraia valores: β̂j, se(β̂j), βj0 (hipótese nula, ex: 0)."
                                  ],
                                  "verification": "Execute regressão e capture β̂j = 0.12, se=0.03 por exemplo; confirme n>100.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Dataset exemplo (Wage dataset do Wooldridge)",
                                    "R: lm(), Python: statsmodels.api.OLS"
                                  ],
                                  "tips": "Use coeficientes robustos com sandwich estimator para realismo.",
                                  "learningObjective": "Obter com precisão as estatísticas necessárias para o teste.",
                                  "commonMistakes": [
                                    "Usar dataset pequeno (n<50)",
                                    "Esquecer erros padrão robustos em dados reais"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a Estatística z e o p-valor",
                                  "subSteps": [
                                    "Formule H0: βj = βj0 vs Ha: βj ≠ βj0 (teste bilateral).",
                                    "Compute z = (β̂j - βj0) / se(β̂j).",
                                    "Calcule p-valor: 2 * (1 - Φ(|z|)) onde Φ é CDF normal padrão.",
                                    "Use funções: pnorm(abs(z), lower.tail=FALSE)*2 em R; norm.sf(abs(z))*2 em Python.",
                                    "Compare |z| com valores críticos: 1.96 (5%), 2.58 (1%)."
                                  ],
                                  "verification": "Para β̂j=0.12, se=0.03, βj0=0, z≈4.0, p<0.001; reproduza manual e via software.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora ou Excel para verificação manual",
                                    "Código R/Python pronto"
                                  ],
                                  "tips": "Sempre cheque sinal de z para interpretação direcional.",
                                  "learningObjective": "Executar cálculo preciso da estatística e p-valor.",
                                  "commonMistakes": [
                                    "Erro no sinal: z positivo se β̂j > βj0",
                                    "Usar distribuição t em vez de normal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Decidir Rejeição",
                                  "subSteps": [
                                    "Se p < α (ex: 0.05), rejeite H0: evidência de βj ≠ βj0.",
                                    "Reporte: 'z=4.0, p<0.001, rejeitamos H0 a 1%'.",
                                    "Considere magnitude: efeito econômico (ex: 0.12% por ano estudo).",
                                    "Discuta limitações: poder do teste, múltiplos testes.",
                                    "Documente em relatório: hipótese, stat, decisão, implicações."
                                  ],
                                  "verification": "Escreva parágrafo de interpretação coerente com exemplo numérico.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Template de relatório LaTeX ou Markdown"
                                  ],
                                  "tips": "Sempre relacione p-valor com nível de significância e contexto prático.",
                                  "learningObjective": "Interpretar corretamente e comunicar achados de inferência.",
                                  "commonMistakes": [
                                    "Confundir p-valor com probabilidade de H0 verdadeira",
                                    "Ignorar tamanho do efeito"
                                  ]
                                }
                              ],
                              "practicalExample": "Em regressão de log(salário) sobre anos de educação (educ), experiência (exp) com n=1000: H0: β_educ = 0.08. Obtido β̂_educ=0.092, se=0.012 → z=(0.092-0.08)/0.012=1.0 → p=0.317 → não rejeita; educação não tem retorno extra de 8% assintoticamente significativo.",
                              "finalVerifications": [
                                "Calcule z e p-valor corretamente para dados fornecidos.",
                                "Explique distribuição assintótica N(0,1) sob H0.",
                                "Interprete rejeição/não rejeição com implicações práticas.",
                                "Ajuste para erros padrão robustos e verifique mudança em z.",
                                "Simule 1000 regressões para validar convergência via histograma.",
                                "Redija relatório de 1 página com teste completo."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de z e p-valor (erro <0.01).",
                                "Correta justificativa teórica dos pressupostos relaxados.",
                                "Interpretação contextualizada, incluindo magnitude do coeficiente.",
                                "Uso apropriado de software com código reproduzível.",
                                "Identificação de erros comuns e limitações do teste.",
                                "Clareza na comunicação escrita/oral dos resultados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Ligação com testes de significância e intervalos de confiança.",
                                "Programação Computacional: Implementação em R/Python para automação de testes.",
                                "Economia/Econometria: Aplicação em avaliação de políticas públicas.",
                                "Matemática: TCL e distribuições assintóticas.",
                                "Ciência de Dados: Inferência em machine learning relaxado."
                              ],
                              "realWorldApplication": "Em análise de impacto de políticas, como testar se um programa de treinamento aumenta produtividade (βj=0?); em finanças, verificar se beta de risco de ativo é 1; ou em marketing, se preço elástico é -2 em grandes datasets de vendas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.5.2.2",
                            "name": "Teste F Assintótico para Restrições Lineares",
                            "description": "Conduzir o teste F assintótico para múltiplas restrições lineares usando a estatística de Wald, que converge para qui-quadrado sob grandes amostras e pressupostos relaxados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Formular Restrições Lineares e Hipóteses",
                                  "subSteps": [
                                    "Identifique as restrições lineares no vetor de parâmetros β, como Rβ = r, onde R é a matriz de restrições.",
                                    "Especifique a hipótese nula H0: Rβ = r contra a alternativa H1: Rβ ≠ r.",
                                    "Verifique a dimensionalidade: número de restrições q = rank(R).",
                                    "Confirme pressupostos relaxados: ergodicidade estacionária, momentos finitos e identificação.",
                                    "Escreva as restrições em termos matriciais explícitas para o modelo de regressão."
                                  ],
                                  "verification": "Escreva corretamente a matriz R e vetor r para um exemplo com 2 restrições lineares.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Notas de aula sobre regressão assintótica",
                                    "Software R ou Python (pacotes como lmtest)"
                                  ],
                                  "tips": "Sempre normalize as restrições para simplificar cálculos; use R com linhas unitárias quando possível.",
                                  "learningObjective": "Compreender e formular hipóteses de restrições lineares em modelos de regressão.",
                                  "commonMistakes": [
                                    "Confundir Rβ = 0 com restrições gerais Rβ = r",
                                    "Ignorar o rank de R, levando a estatísticas inválidas"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar o Modelo e Obter Covariância Assintótica",
                                  "subSteps": [
                                    "Estime o modelo irrestrito por MLE ou OLS assintótico: β̂ →p β.",
                                    "Calcule a matriz de covariância assintótica V = A^{-1} B A^{-1}, onde A é a Hessiana e B o sandwich.",
                                    "Use estimadores consistentes: Â = -H_n / n, B̂ = S_n / n.",
                                    "Implemente em software para obter se(β̂), as erros-padrão assintóticos.",
                                    "Verifique convergência: n^{1/2}(β̂ - β) → N(0, V)."
                                  ],
                                  "verification": "Gere a matriz V̂ para um dataset simulado e confirme simetria positiva definida.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Dataset de regressão simulado",
                                    "R (sandwich package) ou Python (statsmodels)"
                                  ],
                                  "tips": "Use o estimador sandwich robusto para heteroscedasticidade; valide com simulações Monte Carlo.",
                                  "learningObjective": "Calcular variâncias assintóticas robustas para inferência em grandes amostras.",
                                  "commonMistakes": [
                                    "Usar variância clássica OLS em vez de assintótica",
                                    "Esquecer de dividir por n nas estimativas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a Estatística de Wald (F Assintótico)",
                                  "subSteps": [
                                    "Compute o resíduo das restrições: restr = R β̂ - r.",
                                    "Calcule a estatística Wald: W = n * restr' * (R V̂ R')^{-1} * restr.",
                                    "Confirme que sob H0, W →d χ²_q, onde q = dim(restr).",
                                    "Implemente a fórmula em código, evitando inversões numéricas instáveis.",
                                    "Compare com versão F finita: F = (SSR_r - SSR_u)/q / (SSR_u/(n-k)) ≈ W/n para grandes n."
                                  ],
                                  "verification": "Para um exemplo conhecido, obtenha W ≈ valor qui-quadrado crítico.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código template em R/Python",
                                    "Calculadora matricial (Matlab ou similar)"
                                  ],
                                  "tips": "Use decomposição Cholesky para (R V̂ R')^{-1} em casos de alta dimensão.",
                                  "learningObjective": "Derivar e computar a estatística de Wald para testes de restrições lineares.",
                                  "commonMistakes": [
                                    "Multiplicar por n incorretamente",
                                    "Confundir Wald com LM ou LR"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Conduzir o Teste e Interpretar Resultados",
                                  "subSteps": [
                                    "Calcule o p-valor: P(χ²_q > W) usando função de distribuição qui-quadrado.",
                                    "Compare W com quantis χ²_q(1-α) para decisão rejeitar/não rejeitar H0.",
                                    "Avalie tamanho assintótico e poder via simulações.",
                                    "Interprete no contexto: implicações para o modelo econômico ou estatístico.",
                                    "Reporte confiança: intervalos para restrições lineares usando Wald."
                                  ],
                                  "verification": "Execute teste completo em dataset real e justifique rejeição/aceitação com p-valor <0.05.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Dataset real (ex: dados econômicos)",
                                    "R (lmtest::waldtest) ou Python"
                                  ],
                                  "tips": "Sempre reporte graus de liberdade q; ajuste por múltiplos testes se necessário.",
                                  "learningObjective": "Aplicar e interpretar o teste F assintótico em cenários reais.",
                                  "commonMistakes": [
                                    "Usar distribuição F finita em vez de qui-quadrado",
                                    "Ignorar pressupostos relaxados como heterocedasticidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão de salários sobre educação e experiência (n=10000), teste H0: β_educação = β_experiência = 0 usando Wald: formule R = [0 1 0; 0 0 1], compute W=12.5 (χ²_2=5.99 crit 5%), rejeite H0, indicando ambos significativos.",
                              "finalVerifications": [
                                "Formula corretamente Rβ = r para 3 restrições lineares diferentes.",
                                "Deriva W → χ²_q sob H0 com pressupostos relaxados.",
                                "Implementa teste em R/Python para dataset com n>5000.",
                                "Interpreta p-valor e decide corretamente em 3 cenários simulados.",
                                "Compara Wald vs. F finito, notando convergência assintótica.",
                                "Identifica violações de pressupostos e sugere correções."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação matricial de restrições (90% correto).",
                                "Correção na computação de V̂ e W (erro <1e-6).",
                                "Interpretação contextual válida e robusta a pressupostos.",
                                "Eficiência computacional em grandes amostras (n>10k).",
                                "Capacidade de debugar erros comuns em código.",
                                "Poder do teste via simulação >80% em alternativas locais."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuições assintóticas qui-quadrado e CLT.",
                                "Econometria: Testes em modelos lineares gerais (GMM).",
                                "Machine Learning: Feature selection via testes de coeficientes.",
                                "Computação Científica: Álgebra linear numérica e otimização.",
                                "Probabilidade: Convergência em distribuição e Delta Method."
                              ],
                              "realWorldApplication": "Em finanças, testar restrições de eficiência de mercado em regressões de retornos; em políticas públicas, verificar igualdade de impactos de políticas em subgrupos populacionais usando dados censitários grandes."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.5.2.3",
                            "name": "Teste de Wald Generalizado",
                            "description": "Implementar o teste de Wald para hipóteses não-lineares em modelos de regressão, utilizando a distribuição qui-quadrado assintótica em contextos de econometria aplicada à engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Formulação Teórica do Teste de Wald Generalizado",
                                  "subSteps": [
                                    "Revise o teste de Wald para hipóteses lineares em regressão: H0: Rβ = r.",
                                    "Estenda para hipóteses não-lineares: H0: g(β) = 0, onde g é uma função diferenciável.",
                                    "Estude a estatística de Wald: W = [g(β̂)^T] [Var(g(β̂))]^{-1} [g(β̂)] ~ χ²(k) assintoticamente.",
                                    "Analise os pressupostos relaxados: grandes amostras, consistência assintótica de β̂.",
                                    "Discuta aplicações em econometria: testes de restrições em modelos não-lineares."
                                  ],
                                  "verification": "Resuma em um parágrafo a diferença entre Wald linear e generalizado, citando a fórmula exata.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Livro 'Econometric Analysis' de Greene (Cap. 4)",
                                    "Notas de aula sobre inferência assintótica",
                                    "Artigo seminal de Wald (1943)"
                                  ],
                                  "tips": "Use diagramas para visualizar g(β) e sua variância assintótica.",
                                  "learningObjective": "Dominar a formulação matemática do teste para hipóteses não-lineares.",
                                  "commonMistakes": [
                                    "Confundir com teste de Lagrange ou Likelihood Ratio",
                                    "Ignorar a matriz de variância de g(β̂)",
                                    "Esquecer a transformação por Jacobiano"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar a Distribuição Assintótica Qui-Quadrado",
                                  "subSteps": [
                                    "Revise teorema do delta: Var(g(β̂)) ≈ G Var(β̂) G^T, onde G = ∂g/∂β em β̂.",
                                    "Demonstre a convergência em distribuição: √n (β̂ - β) → N(0, Σ), implicando W → χ².",
                                    "Calcule o Jacobiano G para exemplos simples, como g(β) = β1^2 - β2.",
                                    "Simule numericamente em Python para validar a assintótica com n=1000.",
                                    "Discuta robustez sob heterocedasticidade usando covariância sandwich."
                                  ],
                                  "verification": "Derive a prova passo a passo em um documento LaTeX e simule um gráfico QQ-plot.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Software Python com NumPy/SciPy",
                                    "Tutorial 'Asymptotic Theory in Econometrics'",
                                    "Código Jupyter pronto para simulação"
                                  ],
                                  "tips": "Comece com casos univariados para intuitionar antes de multivariados.",
                                  "learningObjective": "Justificar rigorosamente a distribuição qui-quadrado assintótica.",
                                  "commonMistakes": [
                                    "Negligenciar o Jacobiano na variância",
                                    "Usar distribuição normal finita em vez de assintótica",
                                    "Confundir √n com n na normalização"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Computacionalmente a Estatística de Wald",
                                  "subSteps": [
                                    "Defina a função g(β) e seu Jacobiano em código Python/R.",
                                    "Estime β̂ e Var(β̂) via MLE ou OLS robusto.",
                                    "Calcule W = g(β̂)^T (G Var(β̂) G^T)^{-1} g(β̂).",
                                    "Implemente p-valor: 1 - χ².cdf(W, df=k).",
                                    "Teste com dados sintéticos: gere dados sob H0 e H1."
                                  ],
                                  "verification": "Execute o código em um dataset simulado e obtenha p-valor <0.05 sob H1.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Python (statsmodels, NumPy)",
                                    "R (lmtest package)",
                                    "Dataset sintético gerado via código"
                                  ],
                                  "tips": "Use autograd ou sympy para Jacobiano numérico/analítico automático.",
                                  "learningObjective": "Codificar o teste de forma reprodutível e eficiente.",
                                  "commonMistakes": [
                                    "Erro numérico em inversão de matriz singular",
                                    "Jacobiano avaliado em β errado",
                                    "df incorreto para qui-quadrado"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Interpretar em Modelo de Regressão Real",
                                  "subSteps": [
                                    "Carregue dataset de econometria em engenharia (ex: custos de produção).",
                                    "Ajuste modelo de regressão não-linear ou com restrições.",
                                    "Formule H0 não-linear, ex: β1 + exp(β2) = 1.",
                                    "Compute Wald, compare com LR e LM testes.",
                                    "Interprete: rejeição implica reformulação do modelo."
                                  ],
                                  "verification": "Gere relatório com tabela de testes, gráficos de resíduos e conclusão.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dataset 'Production Costs Engineering' (Kaggle)",
                                    "Jupyter Notebook template",
                                    "Documentação statsmodels/R"
                                  ],
                                  "tips": "Sempre reporte ICs de β̂ para contextualizar.",
                                  "learningObjective": "Integrar teoria e prática em análise econométrica aplicada.",
                                  "commonMistakes": [
                                    "Ignorar diagnósticos de modelo antes do teste",
                                    "Má interpretação de p-valor como probabilidade",
                                    "Não checar multicolinearidade afetando Var(β̂)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar Robustez e Extensões Avançadas",
                                  "subSteps": [
                                    "Implemente versão bootstrap para amostras pequenas.",
                                    "Teste sob misspecification: adicione heterocedasticidade.",
                                    "Compare Wald com outros testes em simulações Monte Carlo.",
                                    "Explore em GLM ou modelos de painel.",
                                    "Documente limitações: poder do teste, tamanho finito."
                                  ],
                                  "verification": "Compare p-valores Wald vs bootstrap em relatório com power curve.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Código bootstrap em Python",
                                    "Paper 'Wald Test in Nonlinear Models'",
                                    "Simulador Monte Carlo"
                                  ],
                                  "tips": "Use parallelização para simulações rápidas.",
                                  "learningObjective": "Avaliar limitações e robustez do teste em contextos reais.",
                                  "commonMistakes": [
                                    "Over-reliance em assintóticas sem validação",
                                    "Bootstrap inválido sob dependência serial",
                                    "Confundir tamanho e poder do teste"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para custos de produção em engenharia civil: y = β0 + β1 x1 + β2 x2^2 + ε. Teste H0: β1 + 2β2 = 0 usando Wald generalizado em Python statsmodels, com n=500 observações, obtendo W=7.23 ~ χ²(1), p=0.007, rejeitando H0.",
                              "finalVerifications": [
                                "Deriva corretamente a estatística Wald para g(β)=β1^2 - β2.",
                                "Implementa código que reproduz p-valor exato em dataset padrão.",
                                "Interpreta rejeição em contexto econométrico de engenharia.",
                                "Simula power curve mostrando convergência assintótica.",
                                "Compara Wald com LR test em modelo não-linear.",
                                "Identifica e corrige erro comum em Jacobiano."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na derivação (30%)",
                                "Correção e eficiência do código (25%)",
                                "Interpretação contextualizada (20%)",
                                "Validação via simulação (15%)",
                                "Relatório claro e reprodutível (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Avançada: Inferência assintótica",
                                "Programação Científica: NumPy/SciPy para otimização",
                                "Econometria: Modelos em engenharia de processos",
                                "Matemática Computacional: Cálculo numérico de Jacobianos",
                                "Engenharia Aplicada: Análise de dados em projetos reais"
                              ],
                              "realWorldApplication": "Em engenharia, o teste valida restrições teóricas em modelos econométricos para otimizar custos de produção, prever falhas estruturais ou alocar recursos em projetos de infraestrutura, garantindo decisões baseadas em evidências estatísticas robustas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.4.5.3",
                        "name": "Intervalos de Confiança e Correções Robustas",
                        "description": "Construir intervalos de confiança válidos e calcular erros padrão robustos para inferência confiável em regressões com violações de pressupostos clássicos, como heteroscedasticidade e autocorrelação.",
                        "specificSkills": [
                          {
                            "id": "10.1.4.5.3.1",
                            "name": "Erros Padrão Robustos de White",
                            "description": "Calcular e interpretar erros padrão robustos a heteroscedasticidade (sandwich estimator de White) para regressão linear em grandes amostras, ajustando a inferência para variância condicional.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Heteroscedasticidade e Limitações dos Erros Padrão OLS",
                                  "subSteps": [
                                    "Defina heteroscedasticidade como variância não constante dos erros condicional aos regressores.",
                                    "Explique como os erros padrão OLS superestimam ou subestimam a variância sob heteroscedasticidade.",
                                    "Realize testes diagnósticos: Breusch-Pagan ou White test para detectar heteroscedasticidade.",
                                    "Gere e plote resíduos de uma regressão simulada com heteroscedasticidade.",
                                    "Compare inferência inválida (IC OLS) com realidade simulada."
                                  ],
                                  "verification": "Produza um gráfico de resíduos vs fitted values mostrando heteroscedasticidade e interprete o teste White com p-valor < 0.05.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R ou Python (pacotes: lmtest, sandwich para R; statsmodels para Python)",
                                    "Dados simulados ou conjunto mtcars com log(wage) como DV"
                                  ],
                                  "tips": [
                                    "Sempre plote resíduos antes de qualquer correção.",
                                    "Use simulações para visualizar o problema.",
                                    "Interprete p-valores com cautela em grandes amostras."
                                  ],
                                  "learningObjective": "Identificar violações de homoscedasticidade e suas consequências para inferência estatística.",
                                  "commonMistakes": [
                                    "Confundir heteroscedasticidade com não-normalidade.",
                                    "Ignorar o impacto em testes t e F.",
                                    "Usar testes sem plotar dados."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar e Entender a Fórmula do Sandwich Estimator de White",
                                  "subSteps": [
                                    "Relembre a variância assintótica dos estimadores OLS: Var(β) = (X'X/n)^{-1} (σ²) (X'X/n)^{-1}.",
                                    "Introduza o sandwich: 'pão' (X'X/n)^{-1}, 'recheio' (plim média de x_i u_i² x_i).",
                                    "Escreva a fórmula HC0: Var(β) = (X'X/n)^{-1} (1/n Σ x_i u_i² x_i) (X'X/n)^{-1}.",
                                    "Discuta variantes HC1-HC3 para correções de graus de liberdade em amostras finitas.",
                                    "Prove intuitivamente por que é robusto: não assume homoscedasticidade."
                                  ],
                                  "verification": "Escreva a fórmula do HC1 estimator e explique cada componente em palavras.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Notas de aula ou Wooldridge 'Introductory Econometrics' Cap. 8",
                                    "Lápis e papel para derivação",
                                    "Jupyter notebook para simulação"
                                  ],
                                  "tips": [
                                    "Pense no 'sandwich' como pão-modelo + recheio-empírico + pão-modelo.",
                                    "Use n em vez de n-k para HC0 em grandes amostras.",
                                    "Memorize que é consistente sob misspecification."
                                  ],
                                  "learningObjective": "Dominar a estrutura matricial do estimador robusto e sua robustez assintótica.",
                                  "commonMistakes": [
                                    "Esquecer a divisão por n no meio.",
                                    "Confundir com cluster-robust.",
                                    "Aplicar em amostras pequenas sem HC2/HC3."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Cálculo de Erros Padrão Robustos em Software",
                                  "subSteps": [
                                    "Ajuste um modelo lm() em R ou OLS em statsmodels Python.",
                                    "Aplique sandwich::vcovHC(model, type='HC1') em R ou get_robustcov_results() em Python.",
                                    "Extraia coeficientes, erros padrão robustos e compare com OLS padrão.",
                                    "Calcule estatísticas t robustas: coef / se_robust.",
                                    "Gere intervalos de confiança robustos: coef ± 1.96 * se_robust."
                                  ],
                                  "verification": "Execute código em um dataset real, output tabela com se_OLS vs se_White, mostrando diferenças.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "R: pacotes lmtest, sandwich, AER",
                                    "Python: statsmodels, pandas",
                                    "Dataset: wage data de AER ou similar"
                                  ],
                                  "tips": [
                                    "Use type='HC1' para finite-sample correction.",
                                    "Salve modelo primeiro: vcovHC(fit).",
                                    "Verifique se n > 100 para validade assintótica."
                                  ],
                                  "learningObjective": "Implementar computacionalmente o sandwich estimator em fluxos de análise de dados.",
                                  "commonMistakes": [
                                    "Não carregar pacotes corretos.",
                                    "Usar coef() sem summary().",
                                    "Interpretar se_robust como se_OLS."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Construir Inferência Robusta",
                                  "subSteps": [
                                    "Compare mudanças em significância: testes t mudam com se_robust?",
                                    "Construa e interprete IC 95% robustos.",
                                    "Avalie robustez: se resultados mudam drasticamente?",
                                    "Relate em relatório: 'Usando erros padrão HC1 robustos a heteroscedasticidade'.",
                                    "Teste sensibilidade com HC0 vs HC3."
                                  ],
                                  "verification": "Escreva um parágrafo interpretando uma tabela com se_OLS e se_robust, destacando diferenças.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Tabela de resultados gerada no step 3",
                                    "Template de relatório LaTeX ou Markdown"
                                  ],
                                  "tips": [
                                    "Sempre reporte ambos para transparência.",
                                    "IC robustos são mais largos, mas confiáveis.",
                                    "Discuta implicações para conclusões."
                                  ],
                                  "learningObjective": "Aplicar inferência robusta para decisões baseadas em evidência confiável.",
                                  "commonMistakes": [
                                    "Ignorar alargamento de IC.",
                                    "Não mencionar a correção usada.",
                                    "Sobreconfiar em p-valores sem contexto."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários por educação e experiência (n=1000), ajuste log(wage) ~ educ + exper. Resíduos mostram heteroscedasticidade (White test p<0.01). OLS dá se(educ)=0.015 (t=5.2), mas White HC1 dá se=0.022 (t=2.8), alterando significância de exper. IC robusto: educ [0.03, 0.09] vs OLS [0.04, 0.08].",
                              "finalVerifications": [
                                "Implementa corretamente vcovHC em R/Python para um modelo dado.",
                                "Explica a estrutura 'sandwich' sem olhar notas.",
                                "Detecta heteroscedasticidade via plot e teste em dados novos.",
                                "Calcula e interpreta IC robustos corretamente.",
                                "Compara mudanças em significância pré/pós-robusto.",
                                "Relata resultados com notação padrão (e.g., *** p<0.01 robust)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação: erros padrão coincidem com output esperado (±1e-4).",
                                "Compreensão conceitual: explica robustez assintótica corretamente.",
                                "Diagnóstico correto: identifica heteroscedasticidade em 90% dos casos.",
                                "Interpretação qualitativa: discute implicações para inferência.",
                                "Eficiência computacional: código limpo e reproduzível.",
                                "Relato claro: tabela com ambos se, IC e notas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses robustos.",
                                "Programação Científica: manipulação matricial em R/Python.",
                                "Econometria: pressupostos relaxados em modelos lineares.",
                                "Machine Learning: standard errors em validação de modelos.",
                                "Visualização de Dados: plots de resíduos para diagnóstico."
                              ],
                              "realWorldApplication": "Em análises econômicas para políticas salariais, onde variâncias de erros aumentam com nível educacional (heteroscedasticidade); ou em estudos médicos com variabilidade crescente por dose de tratamento, garantindo inferência válida para decisões baseadas em grandes datasets observacionais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.5.3.2",
                            "name": "Erros Padrão HAC (Newey-West)",
                            "description": "Aplicar o estimador HAC de Newey-West para corrigir erros padrão em presença de heteroscedasticidade e autocorrelação serial, selecionando largura de banda adequada em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender Heteroscedasticidade, Autocorrelação e Necessidade do Estimador HAC",
                                  "subSteps": [
                                    "Revisar os pressupostos clássicos de regressão linear (homoscedasticidade e ausência de autocorrelação serial).",
                                    "Identificar sinais de heteroscedasticidade (gráficos de resíduos vs. fitted values) e autocorrelação (ACF plot dos resíduos).",
                                    "Explicar matematicamente por que erros padrão OLS são enviesados nessas condições.",
                                    "Comparar visualmente erros padrão OLS vs. robustos em um dataset simulado.",
                                    "Discutir o estimador HAC como solução consistente para covariância de longo prazo."
                                  ],
                                  "verification": "Gerar gráficos de resíduos mostrando heteroscedasticidade e autocorrelação, e explicar em um parágrafo por que HAC é necessário.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python/R com bibliotecas statsmodels/sklearn",
                                    "Dataset simulado com autocorrelação (ex: AR(1) erros)"
                                  ],
                                  "tips": "Sempre plote resíduos primeiro; use Breusch-Pagan para heteroscedasticidade e Ljung-Box para autocorrelação.",
                                  "learningObjective": "Compreender as violações de pressupostos que justificam o uso de Newey-West.",
                                  "commonMistakes": [
                                    "Ignorar testes formais de resíduos",
                                    "Confundir heteroscedasticidade com autocorrelação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender a Fórmula e o Algoritmo Newey-West",
                                  "subSteps": [
                                    "Estudar a matriz de covariância HAC: Σ = Γ(0) + ∑ [Γ(k) + Γ(k)^T] * kernel(k/bandwidth).",
                                    "Implementar o kernel Bartlett (padrão Newey-West): w(k) = 1 - |k|/M.",
                                    "Derivar intuitivamente por que o kernel trunca autocorrelações em lags altos.",
                                    "Codificar uma função simples para estimar a matriz HAC manualmente em Python.",
                                    "Validar contra implementação built-in (statsmodels)."
                                  ],
                                  "verification": "Implementar e comparar matriz HAC manual vs. library; diferença < 1%.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação statsmodels NeweyWest",
                                    "Notebook Jupyter",
                                    "Fórmulas de econometria (Wooldridge cap. 12)"
                                  ],
                                  "tips": "Comece com bandwidth=1 para entender, depois aumente; kernel Bartlett é o default.",
                                  "learningObjective": "Dominar a construção matemática do estimador Newey-West.",
                                  "commonMistakes": [
                                    "Usar kernel errado (ex: Parzen em vez de Bartlett)",
                                    "Esquecer termos Γ(k)^T"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Selecionar Largura de Banda Adequada",
                                  "subSteps": [
                                    "Explorar regras de ouro: M = floor(4*(T/100)^{2/9}) (Newey-West original).",
                                    "Testar métodos automáticos: plug-in de Andrews ou cross-validation de erros padrão.",
                                    "Avaliar trade-off: bandwidth pequeno (viés baixo, variância alta) vs. grande (over-smoothing).",
                                    "Plotar erros padrão vs. bandwidth para um dataset e escolher ótimo.",
                                    "Aplicar em dados de engenharia com T~100-500 observações."
                                  ],
                                  "verification": "Gerar plot de erros padrão vs. bandwidth e justificar escolha com mínimo MSE.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Função bwselect em statsmodels",
                                    "Dados de engenharia (ex: séries temporais de sensores)"
                                  ],
                                  "tips": "Para T pequeno, prefira regras fixas; valide com múltiplos critérios.",
                                  "learningObjective": "Selecionar bandwidth otimizada para inferência confiável.",
                                  "commonMistakes": [
                                    "Bandwidth fixo=0 (volta a OLS)",
                                    "Bandwidth muito grande levando a singularidade"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar HAC em Regressão e Construir Inferência",
                                  "subSteps": [
                                    "Ajustar modelo OLS e extrair resíduos.",
                                    "Computar erros padrão HAC com bandwidth escolhida usando library.",
                                    "Calcular t-stats, p-values e intervalos de confiança corrigidos.",
                                    "Comparar inferência OLS vs. HAC em relatório.",
                                    "Testar robustez com bootstrap HAC para validação."
                                  ],
                                  "verification": "Relatório mostrando coeficientes significativos mudando com HAC; IC não contém zero onde OLS errava.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "statsmodels.formula.api OLS + cov_type='HAC'",
                                    "Dataset real de engenharia"
                                  ],
                                  "tips": "Use maxlags='auto' inicialmente; sempre reporte bandwidth usada.",
                                  "learningObjective": "Aplicar Newey-West para inferência corrigida em dados reais.",
                                  "commonMistakes": [
                                    "Não recentralizar resíduos",
                                    "Ignorar warnings de bandwidth"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar e Validar Resultados em Contexto de Engenharia",
                                  "subSteps": [
                                    "Interpretar mudanças em significância de coeficientes pós-HAC.",
                                    "Verificar se IC são mais largos (esperado).",
                                    "Simular cenários de engenharia: prever fadiga material com dados seriais.",
                                    "Documentar pipeline completo em notebook reproduzível.",
                                    "Discutir limitações (ex: T pequeno)."
                                  ],
                                  "verification": "Notebook com análise completa, conclusões acionáveis e código rodando sem erros.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Dados públicos de engenharia (ex: UCI ML repo séries temporais)",
                                    "Relatório template"
                                  ],
                                  "tips": "Sempre inclua seed para reprodutibilidade em simulações.",
                                  "learningObjective": "Integrar HAC em workflow de análise de dados de engenharia.",
                                  "commonMistakes": [
                                    "Over-interpretar p-values sem contexto",
                                    "Não reportar bandwidth"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de sensores de vibração de uma turbina (T=200 observações), modele tensão vs. tempo e carga. Resíduos mostram autocorrelação AR(1). Aplique Newey-West com bandwidth=4: erros padrão do coef. de carga aumentam 30%, tornando-o significativo (p=0.03 vs. 0.12 OLS), permitindo decisão segura de manutenção.",
                              "finalVerifications": [
                                "Erros padrão HAC > OLS em pelo menos 20% dos coeficientes.",
                                "Intervalos de confiança válidos não rejeitam H0 onde OLS falsamente rejeitava.",
                                "Código reproduz matriz HAC com diff <0.01 vs. library.",
                                "Bandwidth escolhida justificada por plot ou regra.",
                                "Análise completa em notebook com plots de resíduos pré/pós.",
                                "Inferência muda significância em pelo menos um preditor chave."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação HAC (match com library >99%).",
                                "Escolha adequada de bandwidth com justificativa quantitativa.",
                                "Interpretação correta de mudanças em inferência.",
                                "Qualidade dos plots e testes de diagnóstico.",
                                "Clareza no relatório de aplicação em engenharia.",
                                "Tratamento de edge cases (T pequeno, multicolinearidade)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência robusta e testes de hipóteses.",
                                "Programação: NumPy/pandas para manipulação de dados seriais.",
                                "Engenharia: Análise de séries temporais em monitoramento estrutural.",
                                "Econometria: Aplicações em finanças de engenharia (riscos).",
                                "Machine Learning: Robustez em regressão para previsão."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, usar Newey-West em dados de telemetria de voo para corrigir erros padrão em modelos de fadiga, garantindo intervalos de confiança confiáveis para certificação de segurança, evitando recalls caros por inferência enviesada."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.4.5.3.3",
                            "name": "Construção de Intervalos de Confiança Robustos",
                            "description": "Construir intervalos de confiança assintóticos de 95% usando erros padrão robustos, verificando cobertura em simulações e aplicando em exemplos reais de análise de dados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos de Erros Padrão Robustos",
                                  "subSteps": [
                                    "Revise os pressupostos da regressão linear clássica (OLS) e identifique violações comuns como heterocedasticidade.",
                                    "Estude a definição de erros padrão robustos (ex: HC0, HC1, HC2, HC3) e sua fórmula assintótica.",
                                    "Compare erros padrão OLS padrão vs. robustos em cenários com pressupostos relaxados.",
                                    "Entenda a propriedade assintótica: √n (θ_hat - θ) → N(0, V) onde V é a matriz de variância robusta.",
                                    "Leia documentação de pacotes como 'sandwich' em R ou 'statsmodels' em Python."
                                  ],
                                  "verification": "Resuma em um parágrafo as diferenças entre SE OLS e SE robustos, com exemplos de violações.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de 'sandwich' (R) ou 'statsmodels' (Python)",
                                    "Notebook Jupyter ou RMarkdown"
                                  ],
                                  "tips": "Use diagramas para visualizar heterocedasticidade vs. homocedasticidade.",
                                  "learningObjective": "Compreender conceitualmente erros padrão robustos e suas vantagens em dados reais.",
                                  "commonMistakes": [
                                    "Confundir HC0 com HC3",
                                    "Ignorar a necessidade de amostras grandes para validade assintótica"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Erros Padrão Robustos em Software",
                                  "subSteps": [
                                    "Carregue um dataset com regressão linear (ex: dados de salários vs. experiência).",
                                    "Ajuste modelo OLS e extraia SE padrão.",
                                    "Implemente SE robustos: em R use vcovHC(modelo, type='HC1'); em Python use HC1 se.",
                                    "Compare matrizes de covariância e isole SE para coeficientes de interesse.",
                                    "Teste sensibilidade variando type (HC0 a HC3)."
                                  ],
                                  "verification": "Gere tabela comparativa de SE OLS vs. robustos e confira diferenças >10%.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R com pacotes lmtest, sandwich",
                                    "Python com statsmodels, pandas",
                                    "Dataset exemplo (mtcars ou wages)"
                                  ],
                                  "tips": "Sempre use n > 100 para robustez; plote resíduos para diagnosticar.",
                                  "learningObjective": "Calcular e interpretar SE robustos computacionalmente.",
                                  "commonMistakes": [
                                    "Esquecer de recarregar modelo após vcovHC",
                                    "Usar type incorreto para amostras pequenas"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir Intervalos de Confiança Assintóticos de 95%",
                                  "subSteps": [
                                    "Para coeficiente β_j: IC = β_hat ± 1.96 * SE_robust(β_j).",
                                    "Implemente função personalizada para múltiplos coeficientes.",
                                    "Interprete: 'Com 95% confiança, β_j está entre [low, up]' assintoticamente.",
                                    "Ajuste para múltiplas comparações se necessário (ex: Bonferroni).",
                                    "Visualize ICs em gráfico de coeficientes com barras de erro."
                                  ],
                                  "verification": "Calcule IC para pelo menos 3 coeficientes e plote; confira que não inclui zero se significativo.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Código dos steps anteriores",
                                    "ggplot2 (R) ou matplotlib/seaborn (Python)"
                                  ],
                                  "tips": "Use qnorm(0.975) para precisão em vez de 1.96 hardcoded.",
                                  "learningObjective": "Construir e visualizar ICs robustos de 95%.",
                                  "commonMistakes": [
                                    "Usar t-student em vez de normal para grandes n",
                                    "Inverter low/up no relatório"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar Cobertura em Simulações e Aplicar em Dados Reais",
                                  "subSteps": [
                                    "Gere 1000 simulações: dados com heterocedasticidade conhecida, ajuste modelo e conte % ICs cobrindo verdadeiros β.",
                                    "Implemente loop de Monte Carlo para cobertura empírica ~95%.",
                                    "Aplique em dataset real (ex: housing prices com features não-lineares).",
                                    "Reporte cobertura, viés e compare OLS vs. robusto.",
                                    "Discuta limitações (ex: dependência serial não tratada)."
                                  ],
                                  "verification": "Simulação mostra cobertura entre 93-97%; aplique em dataset real com relatório.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Funções de simulação em R/Python",
                                    "Dataset real (ex: Boston Housing)"
                                  ],
                                  "tips": "Paralelize simulações com foreach (R) ou joblib (Python) para velocidade.",
                                  "learningObjective": "Validar ICs robustos via simulação e aplicar em contexto real.",
                                  "commonMistakes": [
                                    "Poucas simulações (<500)",
                                    "Não seedar RNG para reprodutibilidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de salários (n=1000), regredir log(salário) ~ experiência + educação. Heterocedasticidade detectada nos resíduos. Calcule SE robusto HC1 para β_experiência=0.05 (SE=0.01), IC=[0.03, 0.07]. Simule 1000 reps: cobertura=94.2%.",
                              "finalVerifications": [
                                "Cálculo de SE robustos coincide com software padrão (±0.001).",
                                "ICs de 95% construídos corretamente com 1.96*SE.",
                                "Simulação Monte Carlo mostra cobertura empírica próxima de 95% (93-97%).",
                                "Aplicação em dados reais inclui plot de resíduos e interpretação.",
                                "Relatório final discute limitações assintóticas.",
                                "Código é reprodutível com seed fixo."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: explica robustez corretamente (80%).",
                                "Implementação computacional sem erros (90%).",
                                "Cobertura simulada dentro de ±2% do nominal.",
                                "Interpretação clara e sem ambiguidades.",
                                "Visualizações profissionais e informativas.",
                                "Relatório integra teoria e prática."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses e p-values robustos.",
                                "Programação Computacional: simulações Monte Carlo em R/Python.",
                                "Análise de Dados: diagnóstico de resíduos e modelagem preditiva.",
                                "Econometria: aplicações em regressões com endogeneidade leve.",
                                "Machine Learning: feature engineering com ICs para interpretabilidade."
                              ],
                              "realWorldApplication": "Em análises econômicas para políticas públicas (ex: impacto de treinamento no emprego), relatórios de risco financeiro (ex: ICs para betas em CAPM), ou ciência de dados em empresas (ex: A/B tests com violações de pressupostos), garantindo inferências confiáveis apesar de dados 'sujos'."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.5",
                "name": "Séries Temporais",
                "description": "Introduz conceitos de séries temporais, modelos ARIMA, cointegração, vetor corretor de erros e modelos vetoriais autoregressivos.",
                "totalSkills": 48,
                "atomicTopics": [
                  {
                    "id": "10.1.5.1",
                    "name": "Conceitos Básicos de Séries Temporais",
                    "description": "Introdução aos fundamentos de séries temporais, incluindo estacionariedade, autocorrelação e componentes trend, sazonalidade e irregular.",
                    "individualConcepts": [
                      {
                        "id": "11.1.1.1",
                        "name": "Estacionariedade em Séries Temporais",
                        "description": "Conceito fundamental que verifica se as propriedades estatísticas de uma série temporal, como média e variância, permanecem constantes ao longo do tempo, essencial para a validade de modelos econométricos aplicados à engenharia, evitando violações nos pressupostos de regressão linear.",
                        "specificSkills": [
                          {
                            "id": "11.1.1.1.1",
                            "name": "Definir tipos de estacionariedade",
                            "description": "Diferenciar estacionariedade fraca (média e variância constantes) e forte (distribuição conjunta invariante), relacionando com pressupostos de regressão linear em séries temporais de dados econômicos ou de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de Estacionariedade em Processos Estocásticos",
                                  "subSteps": [
                                    "Revise a definição de um processo estocástico como uma sequência de variáveis aleatórias indexadas pelo tempo.",
                                    "Entenda que estacionariedade implica invariância estatística ao longo do tempo.",
                                    "Diferencie processos estacionários de não-estacionários usando exemplos simples como ruído branco vs. tendência linear.",
                                    "Estude as propriedades estatísticas básicas: média, variância e covariância.",
                                    "Analise gráficos de séries temporais para identificar padrões de não-estacionariedade visualmente."
                                  ],
                                  "verification": "Crie um diagrama conceitual distinguindo processos estacionários e não-estacionários, com exemplos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro de texto de séries temporais (ex: Hamilton 'Time Series Analysis'), Notebook Jupyter com dados de exemplo (ex: airpassengers dataset)."
                                  ],
                                  "tips": "Comece com visualizações gráficas para intuitivamente captar o conceito antes de mergulhar em definições formais.",
                                  "learningObjective": "Identificar as propriedades estatísticas chave que definem estacionariedade em processos estocásticos.",
                                  "commonMistakes": "Confundir estacionariedade com ausência de tendência, ignorando variância ou covariância."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Definir e Diferenciar Estacionariedade Fraca (Covariância Estacionária)",
                                  "subSteps": [
                                    "Defina estacionariedade fraca como constante média (E[X_t] = μ ∀ t) e variância (Var(X_t) = σ² ∀ t), com covariância dependendo apenas do lag (Cov(X_t, X_{t+k}) = γ(k)).",
                                    "Calcule média e variância em uma série temporal simulada usando Python (pacote statsmodels).",
                                    "Teste estacionariedade fraca com o teste de Dickey-Fuller Aumentado (ADF) em dados econômicos.",
                                    "Compare séries estacionárias fracas com não-estacionárias, plotando autocorrelações.",
                                    "Discuta limitações: não captura mudanças na distribuição além dos momentos de 1ª e 2ª ordem."
                                  ],
                                  "verification": "Implemente e interprete um teste ADF em um dataset, confirmando hipótese nula de não-estacionariedade.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python com statsmodels e matplotlib, Dataset de taxa de juros (ex: FRED database)."
                                  ],
                                  "tips": "Use funções prontas como adfuller() para prática rápida, mas entenda a fórmula subjacente.",
                                  "learningObjective": "Formalizar e testar estacionariedade fraca usando momentos estatísticos.",
                                  "commonMistakes": "Interpretar erroneamente p-valor do ADF, confundindo rejeição da nula com estacionariedade forte."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar Estacionariedade Forte (Estritamente Estacionária)",
                                  "subSteps": [
                                    "Defina estacionariedade forte como invariância da distribuição conjunta: Lei de probabilidade de (X_t, ..., X_{t+k}) idêntica para todo t.",
                                    "Relacione com estacionariedade fraca: forte implica fraca, mas não vice-versa.",
                                    "Simule processos estritamente estacionários (ex: i.i.d.) vs. fracos apenas (ex: AR(1) com φ<1).",
                                    "Analise impacto em previsão: distribuições invariantes permitem modelagem consistente.",
                                    "Compare com exemplos em engenharia, como sinais estacionários em controle de sistemas."
                                  ],
                                  "verification": "Gere amostras de processos e verifique se as distribuições empíricas são invariantes ao shift temporal.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Python com numpy e scipy para simulações, Gráficos de histogramas sobrepostos por janelas temporais."
                                  ],
                                  "tips": "Visualize distribuições por janelas deslizantes para 'ver' a invariância.",
                                  "learningObjective": "Distinguir estacionariedade forte pela invariância distributiva total.",
                                  "commonMistakes": "Assumir que estacionariedade fraca basta para todos os contextos analíticos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar Tipos de Estacionariedade com Pressupostos de Regressão Linear em Séries Temporais",
                                  "subSteps": [
                                    "Revise pressupostos OLS: homocedasticidade (variância constante), ausência de autocorrelação serial.",
                                    "Explique como não-estacionariedade viola exogeneidade e causa regressões espúrias em dados econômicos.",
                                    "Aplique em exemplos: regressão de PIB vs. inflação sem/diferenças para induzir estacionariedade.",
                                    "Discuta soluções: diferenciação, cointegração para séries integradas.",
                                    "Teste resíduos de regressão para estacionariedade usando Ljung-Box ou ADF."
                                  ],
                                  "verification": "Execute uma regressão linear em dados não-estacionários, diferencie e re-teste, documentando mudanças nos resíduos.",
                                  "estimatedTime": "70 minutos",
                                  "materials": [
                                    "Python com pandas, statsmodels para OLS e testes, Dataset econômico (ex: PIB e desemprego do World Bank)."
                                  ],
                                  "tips": "Sempre plote resíduos ACF/PACF para diagnosticar violações.",
                                  "learningObjective": "Conectar estacionariedade aos pressupostos de regressão e identificar regressões espúrias.",
                                  "commonMistakes": "Ignorar autocorrelação nos resíduos, levando a inferências inválidas."
                                }
                              ],
                              "practicalExample": "Em dados econômicos de taxa de juros diários (ex: Fed Funds Rate), teste estacionariedade fraca com ADF: se p>0.05, diferencie até estacionária. Para forte, verifique se histogramas de retornos em janelas de 1 ano são idênticos. Em regressão de juros vs. PIB, não-estacionariedade causa coeficientes espúrios; diferenciação resolve.",
                              "finalVerifications": [
                                "Explique verbalmente a diferença entre estacionariedade fraca e forte com fórmulas.",
                                "Identifique corretamente uma série como fracamente estacionária em um gráfico ACF.",
                                "Simule e confirme invariância distributiva em um processo estritamente estacionário.",
                                "Detecte e corrija uma regressão espúria em dados econômicos simulados.",
                                "Liste 3 violações de pressupostos OLS causadas por não-estacionariedade.",
                                "Aplique teste ADF e interprete em contexto de engenharia de sinais."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas definições matemáticas de ambos os tipos de estacionariedade (100% match com referências padrão).",
                                "Correta implementação e interpretação de testes como ADF e Ljung-Box.",
                                "Qualidade das visualizações e simulações, mostrando distinções claras.",
                                "Capacidade de relacionar conceitos a regressão linear sem erros conceituais.",
                                "Profundidade nas discussões de limitações e implicações práticas.",
                                "Criatividade e relevância nos exemplos econômicos/engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e momentos de processos estocásticos.",
                                "Econometria: Modelos ARIMA e cointegração para séries não-estacionárias.",
                                "Engenharia de Controle: Análise de sinais estacionários em sistemas dinâmicos.",
                                "Machine Learning: Pré-processamento de séries temporais para LSTM/RNN."
                              ],
                              "realWorldApplication": "Em finanças, detectar não-estacionariedade em retornos de ações evita modelos de risco falhos; em engenharia, garante controle PID robusto em sinais de sensores; economistas usam para validar forecasts de PIB, prevenindo políticas baseadas em correlações espúrias."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.1.2",
                            "name": "Identificar não-estacionariedade",
                            "description": "Reconhecer padrões como tendência ou variância crescente em séries temporais, com exemplos de dados de produção industrial ou sensores de engenharia, e discutir impactos na inferência estatística.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de Estacionariedade",
                                  "subSteps": [
                                    "Defina estacionariedade fraca: média constante, variância constante e autocovariância dependente apenas do lag.",
                                    "Identifique os três componentes principais de não-estacionariedade: tendência, sazonalidade e variância heterogênea.",
                                    "Estude definições formais com fórmulas simples, como E[X_t] = μ para todos t em processos estacionários.",
                                    "Revise exemplos iniciais: série com tendência linear vs. ruído branco.",
                                    "Compare estacionariedade forte vs. fraca."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito os três tipos de não-estacionariedade com um exemplo cada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro ou PDF sobre séries temporais (cap. estacionariedade)",
                                    "Notebook com Python/Jupyter para anotações"
                                  ],
                                  "tips": "Use analogias como 'um rio calmo (estacionário) vs. um rio com correnteza crescente (tendência)'.",
                                  "learningObjective": "Dominar definições teóricas para basear identificação prática.",
                                  "commonMistakes": [
                                    "Confundir sazonalidade com tendência; ignorar variância heterogênea."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar Não-Estacionariedade Visualmente em Gráficos",
                                  "subSteps": [
                                    "Carregue um dataset de exemplo (ex: produção industrial mensal).",
                                    "Plote a série temporal bruta e observe padrões visuais: linhas ascendentes/descendentes para tendência.",
                                    "Analise variância: plot de resíduos ou log-retornos para detectar heteroscedasticidade.",
                                    "Identifique sazonalidade com múltiplos anos de dados.",
                                    "Anote observações em um relatório simples."
                                  ],
                                  "verification": "Produza um gráfico anotado destacando pelo menos dois padrões de não-estacionariedade.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python com pandas, matplotlib/seaborn",
                                    "Dataset exemplo: produção industrial (ex: de FRED database)"
                                  ],
                                  "tips": "Aumente o zoom em subperíodos para detectar variância crescente; use scales logarítmicos.",
                                  "learningObjective": "Desenvolver intuição visual para detecção rápida de não-estacionariedade.",
                                  "commonMistakes": [
                                    "Ignorar escalas nos eixos; confundir ruído com tendência em amostras curtas."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Testes Estatísticos Básicos para Confirmação",
                                  "subSteps": [
                                    "Implemente o teste de Dickey-Fuller Aumentado (ADF) em Python.",
                                    "Interprete p-value: p > 0.05 indica não-estacionariedade.",
                                    "Teste resíduos após diferenciação para confirmar.",
                                    "Compare com teste KPSS para estacionariedade em torno de tendência.",
                                    "Registre resultados em tabela."
                                  ],
                                  "verification": "Execute teste ADF em dataset fornecido e interprete corretamente o resultado (estacionário ou não).",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Biblioteca statsmodels em Python",
                                    "Jupyter Notebook",
                                    "Dataset de sensores de engenharia (ex: temperatura com drift)"
                                  ],
                                  "tips": "Sempre verifique suposições do teste (ex: lags adequados via AIC).",
                                  "learningObjective": "Usar ferramentas quantitativas para validar observações visuais.",
                                  "commonMistakes": [
                                    "Não selecionar lags corretos; ignorar hipóteses nula/alternativa do teste."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Impactos na Inferência Estatística e Exemplos Reais",
                                  "subSteps": [
                                    "Discuta como não-estacionariedade invalida ARIMA ou regressões padrão (ex: autocorrelação espúria).",
                                    "Aplique a dados reais: produção industrial (tendência) ou sensores (variância crescente).",
                                    "Proponha transformações: diferenciação, log ou de-trending.",
                                    "Escreva um parágrafo sobre impactos em previsões.",
                                    "Debata soluções em grupo ou auto-reflexão."
                                  ],
                                  "verification": "Escreva relatório de 200 palavras ligando identificação a impactos e soluções.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Datasets reais: produção industrial (IBGE/FRED), sensores IoT",
                                    "Artigos curtos sobre estacionariedade em inferência"
                                  ],
                                  "tips": "Ligue a exemplos pessoais: 'previsão de vendas com tendência sazonal'.",
                                  "learningObjective": "Conectar teoria prática a consequências analíticas.",
                                  "commonMistakes": [
                                    "Subestimar impactos em modelos ML; propor soluções sem testar."
                                  ]
                                }
                              ],
                              "practicalExample": "Analise dados mensais de produção industrial de uma fábrica (ex: toneladas de aço de 2010-2023). Plote a série, identifique tendência crescente e variância expandindo pós-2020 devido a automação. Aplique ADF test (p=0.85, não-estacionário), diferencie e confirme estacionariedade nos retornos. Discuta: inferências erradas levariam a sobreestimar eficiência sem de-trending.",
                              "finalVerifications": [
                                "Identifica corretamente tendência em gráfico de produção industrial.",
                                "Detecta variância heterogênea em dados de sensores e propõe log-transform.",
                                "Executa e interpreta ADF test com p-value correto.",
                                "Explica impacto: 'não-estacionariedade causa testes t inválidos'.",
                                "Sugere diferenciação como solução para dois exemplos.",
                                "Liga visual + teste em relatório coeso."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições corretas de não-estacionariedade (80%).",
                                "Habilidade visual: anotações claras em plots (90%).",
                                "Proficiência técnica: testes implementados sem erros (85%).",
                                "Análise de impacto: ligação lógica a inferência estatística (75%).",
                                "Criatividade em exemplos: uso de dados reais relevantes (80%).",
                                "Relatório estruturado e acionável (90%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e validação de suposições.",
                                "Engenharia: Monitoramento de sensores e controle de processos.",
                                "Economia: Análise de séries macroeconômicas como PIB.",
                                "Ciência de Dados: Pré-processamento para ML em time series.",
                                "Física: Modelagem de sinais não-estacionários em experimentos."
                              ],
                              "realWorldApplication": "Em fábricas, identificar tendência em dados de produção evita previsões erradas de estoque; engenheiros usam para calibrar sensores com drift, prevenindo falhas; bancos detectam não-estacionariedade em retornos para modelos de risco robustos, evitando perdas financeiras."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.1.3",
                            "name": "Aplicar teste de Dickey-Fuller",
                            "description": "Executar e interpretar o teste de raiz unitária de Dickey-Fuller para verificar estacionariedade, utilizando software como R, no contexto de análise econométrica para previsão em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar a série temporal para análise",
                                  "subSteps": [
                                    "Carregue os dados da série temporal em R usando read.csv() ou read.table()",
                                    "Converta os dados em objeto ts() com frequência apropriada (ex: monthly = 12)",
                                    "Plote a série com plot() para inspeção visual de tendências e sazonalidade",
                                    "Verifique valores ausentes com is.na() e trate-os com na.omit() ou interpolação",
                                    "Realize teste de autocorrelação inicial com acf() para suspeita de não-estacionariedade"
                                  ],
                                  "verification": "Série temporal plotada corretamente sem erros de carregamento e valores ausentes tratados",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R instalado",
                                    "Dados de série temporal em CSV (ex: PIB trimestral)",
                                    "Pacote base do R"
                                  ],
                                  "tips": "Sempre especifique start e end no ts() para alinhar datas corretamente",
                                  "learningObjective": "Preparar dados limpos e visualmente analisados para teste de estacionariedade",
                                  "commonMistakes": [
                                    "Ignorar frequência da série",
                                    "Não tratar NAs",
                                    "Plot incorreto sem labels"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar e instalar pacotes necessários no R",
                                  "subSteps": [
                                    "Instale o pacote tseries com install.packages('tseries')",
                                    "Carregue o pacote com library(tseries)",
                                    "Opcionalmente, instale urca com install.packages('urca') para testes avançados",
                                    "Verifique a instalação executando adf.test() em uma série de teste simples",
                                    "Prepare a sintaxe básica: adf.test(serie, alternative='stationary')"
                                  ],
                                  "verification": "Pacotes instalados e carregados sem erros; teste em série dummy funciona",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "R e RStudio",
                                    "Conexão à internet para instalação"
                                  ],
                                  "tips": "Use devtools::install_github() para versões atualizadas se necessário",
                                  "learningObjective": "Configurar ambiente R pronto para execução de testes econométricos",
                                  "commonMistakes": [
                                    "Esquecer library()",
                                    "Conflitos de pacotes",
                                    "Instalação sem privilégios"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste de Dickey-Fuller Aumentado (ADF)",
                                  "subSteps": [
                                    "Execute adf.test(serie_ts) para teste padrão com lag automático",
                                    "Especifique lags manualmente: adf.test(serie_ts, k=4) baseado em AIC",
                                    "Registre estatística do teste, p-value e lags selecionados",
                                    "Compare com valores críticos de MacKinnon para rejeição de H0 (raiz unitária)",
                                    "Salve resultados em objeto: resultado <- adf.test(serie_ts)"
                                  ],
                                  "verification": "Resultado do teste gerado com estatística, p-value e conclusão impressa",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Série temporal preparada",
                                    "Pacote tseries carregado"
                                  ],
                                  "tips": "Use type='trend' se houver tendência linear na série",
                                  "learningObjective": "Executar o teste ADF corretamente com parâmetros adequados",
                                  "commonMistakes": [
                                    "Poucos lags causando super-rejeição",
                                    "Ignorar tipo de teste (none, drift, trend)",
                                    "Não salvar output"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e verificar estacionariedade",
                                  "subSteps": [
                                    "Analise p-value: <0.05 rejeita H0 (estacionária); >0.05 não estacionária",
                                    "Verifique estatística ADF vs. críticos: mais negativa = mais evidência contra raiz unitária",
                                    "Se não estacionária, diferencie: diff_serie <- diff(serie_ts) e re-teste",
                                    "Gere relatório: 'A série é estacionária ao nível X de significância'",
                                    "Plote resíduos ou ACF pós-teste para validação"
                                  ],
                                  "verification": "Relatório escrito com interpretação correta e sugestão de diferenciação se aplicável",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Resultados do ADF",
                                    "Funções plot() e acf()"
                                  ],
                                  "tips": "Sempre teste em níveis de 1%, 5%, 10% para robustez",
                                  "learningObjective": "Interpretar outputs ADF para decisões em modelagem de séries temporais",
                                  "commonMistakes": [
                                    "Confundir H0 (não estacionária) com H1",
                                    "Não diferenciar quando necessário",
                                    "Ignorar lags ótimos"
                                  ]
                                }
                              ],
                              "practicalExample": "Carregue dados de preços de ações da Petrobras (PETR4.SA) de 2010-2023 via getSymbols('PETR4.SA', src='yahoo') no pacote quantmod. Plote, execute adf.test(precos), interprete p-value >0.05 indicando não-estacionariedade, diferencie e re-teste confirmando estacionariedade em diff(log(precos)).",
                              "finalVerifications": [
                                "Executa ADF em nova série sem erros de sintaxe",
                                "Interpreta corretamente p-value e estatística crítica",
                                "Identifica necessidade de diferenciação e aplica",
                                "Gera plot e relatório completo",
                                "Compara resultados com literatura econométrica",
                                "Valida com teste KPSS complementar"
                              ],
                              "assessmentCriteria": [
                                "Precisão na execução do código R (sem erros)",
                                "Correta interpretação estatística (p-value e críticos)",
                                "Tratamento adequado de dados não estacionários",
                                "Relatório claro e estruturado",
                                "Uso de parâmetros apropriados (lags, tipo)",
                                "Validação visual e complementar"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Modelos ARIMA e previsão econômica",
                                "Estatística: Testes de hipóteses e inferência",
                                "Engenharia: Análise de sinais e controle de processos",
                                "Programação: Manipulação de dados em R/Python",
                                "Finanças: Análise de risco em séries financeiras"
                              ],
                              "realWorldApplication": "Em engenharia de produção, aplica-se para verificar estacionariedade em séries de demanda energética ou falhas de equipamentos antes de modelar ARIMA, evitando previsões enviesadas e otimizando planejamento de manutenção preditiva."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.1.1.2",
                        "name": "Autocorrelação em Séries Temporais",
                        "description": "Medida da correlação entre valores de uma série temporal em diferentes lags, crítica para detectar dependência serial que viola pressupostos de independência nos resíduos de modelos de mínimos quadrados ordinários.",
                        "specificSkills": [
                          {
                            "id": "11.1.1.2.1",
                            "name": "Calcular função de autocorrelação (ACF)",
                            "description": "Computar e plotar a ACF para uma série temporal, identificando lags significativos, com aplicação em dados econômicos como PIB ou séries de controle de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparação do ambiente e carregamento dos dados da série temporal",
                                  "subSteps": [
                                    "Instale as bibliotecas necessárias: pandas, matplotlib, statsmodels via pip.",
                                    "Carregue um dataset de série temporal, como dados trimestrais de PIB (ex: CSV com datas e valores).",
                                    "Converta o índice para datetime e defina a frequência (ex: 'Q' para trimestral).",
                                    "Realize uma inspeção inicial: verifique valores ausentes, plote a série e teste estacionariedade básica com ADF test.",
                                    "Limpe os dados se necessário (remova outliers ou interpoles missing values)."
                                  ],
                                  "verification": "Execute df.head(), df.plot() e adfuller_test; confirme que a série está pronta sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python/Jupyter Notebook, bibliotecas: pandas, matplotlib, statsmodels, dataset CSV de PIB ou série industrial.",
                                  "tips": "Sempre defina a frequência correta para evitar erros no cálculo de ACF.",
                                  "learningObjective": "Preparar uma série temporal limpa e formatada para análise de autocorrelação.",
                                  "commonMistakes": "Ignorar missing values ou não converter índice para datetime, causando NaNs na ACF."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Cálculo da Função de Autocorrelação (ACF)",
                                  "subSteps": [
                                    "Importe as funções: from statsmodels.tsa.stattools import acf; from statsmodels.graphics.tsaplots import plot_acf.",
                                    "Compute a ACF com acf(series, nlags=40, alpha=0.05) para obter coeficientes e intervalos de confiança.",
                                    "Armazene os resultados em variáveis: acf_values, conf_int = acf(...).",
                                    "Verifique os primeiros lags manualmente para entender os valores.",
                                    "Ajuste nlags baseado no tamanho da série (ex: min(40, len(series)//5))."
                                  ],
                                  "verification": "Imprima acf_values e conf_int; confirme que os valores estão entre -1 e 1 e conf_int tem shape correto.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Jupyter Notebook com statsmodels instalado.",
                                  "tips": "Use alpha=0.05 para bandas de 95% de confiança padrão.",
                                  "learningObjective": "Calcular numericamente a ACF e seus intervalos de confiança para uma série temporal.",
                                  "commonMistakes": "Definir nlags muito alto para séries curtas, gerando warnings ou instabilidade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Plotagem da ACF e identificação de lags significativos",
                                  "subSteps": [
                                    "Gere o plot com plot_acf(series, lags=40, alpha=0.05); plt.show().",
                                    "Analise visualmente: identifique barras que saem das bandas azuis (regiões de confiança).",
                                    "Registre lags significativos (ex: lag 4 > limite superior de conf_int).",
                                    "Adicione título e labels: plt.title('ACF do PIB Trimestral'); plt.xlabel('Lags').",
                                    "Salve o plot como PNG para relatório."
                                  ],
                                  "verification": "O gráfico mostra decay gradual ou picos claros; lags significativos listados corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Matplotlib integrado ao statsmodels.",
                                  "tips": "Aumente lags se suspeitar de sazonalidade longa (ex: 12 para anual).",
                                  "learningObjective": "Visualizar e interpretar a ACF para detectar dependências temporais.",
                                  "commonMistakes": "Confundir barras dentro das bandas como significativas; sempre cheque conf_int."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretação e aplicação contextual",
                                  "subSteps": [
                                    "Interprete lags: ex: lag 4 significativo indica ciclo trimestral no PIB.",
                                    "Compare com teoria econômica: sazonalidade em dados industriais ou ciclos econômicos.",
                                    "Documente insights em um relatório Markdown no notebook.",
                                    "Teste em outra série (ex: controle industrial) para validar.",
                                    "Sugira próximos passos: ARIMA se ACF decay lento."
                                  ],
                                  "verification": "Relatório lista 2-3 lags chave com explicação coerente ao contexto.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Notebook Jupyter para documentação.",
                                  "tips": "Relacione lags com domínio: 4 lags = 1 ano em trimestral.",
                                  "learningObjective": "Aplicar ACF em contextos reais como economia ou processos industriais.",
                                  "commonMistakes": "Ignorar não-estacionariedade, que distorce ACF; teste ADF primeiro."
                                }
                              ],
                              "practicalExample": "Carregue dados trimestrais de PIB brasileiro (2000-2023) de um CSV. Compute ACF com 20 lags, plote e identifique lag 4 significativo (ciclo anual), útil para modelar crescimento econômico sazonal.",
                              "finalVerifications": [
                                "Gráfico ACF gerado sem erros, com bandas de confiança visíveis.",
                                "Lista de lags significativos (ex: lag 1,4) com valores > limite superior.",
                                "Interpretação alinhada ao contexto econômico ou industrial.",
                                "Código reproduzível em novo notebook.",
                                "Série original plotada para comparação.",
                                "Teste de sensibilidade alterando nlags."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo da ACF (valores coincidem com statsmodels).",
                                "Correta identificação visual e numérica de lags significativos.",
                                "Qualidade do plot: labels, título e legibilidade.",
                                "Interpretação contextual relevante (econômica/industrial).",
                                "Código limpo, comentado e eficiente.",
                                "Tratamento adequado de dados (estacionariedade, missing values)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de significância e intervalos de confiança.",
                                "Programação: Manipulação de dados com Pandas e visualização em Matplotlib.",
                                "Economia: Análise de ciclos econômicos em séries como PIB.",
                                "Engenharia: Controle de processos industriais via detecção de autocorrelações."
                              ],
                              "realWorldApplication": "Em economia, ACF identifica sazonalidades no PIB para previsões de crescimento; em indústrias, detecta ciclos em séries de temperatura ou produção, otimizando controle de qualidade e manutenção preditiva."
                            },
                            "estimatedTime": "0.75 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.2.2",
                            "name": "Interpretar autocorrelação significativa",
                            "description": "Analisar gráficos de ACF para diagnosticar dependência serial, relacionando com propriedades dos estimadores em regressão linear e necessidade de modelos como ARIMA.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de Autocorrelação e Gráfico ACF",
                                  "subSteps": [
                                    "Defina autocorrelação como a correlação de uma série temporal consigo mesma em diferentes lags.",
                                    "Explique a função ACF como uma medida normalizada da autocorrelação em cada lag k.",
                                    "Descreva o gráfico ACF: eixo x (lags), eixo y (coeficientes de correlação), e bandas de confiança (geralmente 95%).",
                                    "Diferencie autocorrelação de correlação cruzada.",
                                    "Identifique que valores dentro das bandas são insignificantes (ruído branco)."
                                  ],
                                  "verification": "Resuma em 3 frases o que o gráfico ACF representa e o significado das bandas de confiança.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Documentação de ACF em R (stats::acf) ou Python (statsmodels.tsa.stattools.acf)",
                                    "Exemplos de gráficos ACF de séries ruído branco vs. AR(1)"
                                  ],
                                  "tips": [
                                    "Sempre verifique estacionariedade primeiro; use diff() se necessário.",
                                    "Compare múltiplos lags visualmente."
                                  ],
                                  "learningObjective": "Compreender os componentes visuais e teóricos do gráfico ACF para interpretação precisa.",
                                  "commonMistakes": [
                                    "Confundir ACF com PACF.",
                                    "Ignorar as bandas de confiança ao julgar significância.",
                                    "Assumir estacionariedade sem teste."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Picos Significativos no Gráfico ACF",
                                  "subSteps": [
                                    "Examine lags de 1 a 20 (ou mais) e identifique barras que excedem as bandas de confiança.",
                                    "Classifique picos: decay exponencial (AR), sinusoidal (SARIMA), lento (não-estacionário).",
                                    "Conte o número de lags significativos consecutivos.",
                                    "Registre lags específicos (ex: lag 1 e 2 significativos).",
                                    "Compare com hipótese nula de autocorrelação zero."
                                  ],
                                  "verification": "Anote 3 lags significativos de um gráfico ACF fornecido e justifique com base nas bandas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráficos ACF de séries reais (ex: AirPassengers dataset)",
                                    "Ferramentas: RStudio ou Jupyter Notebook"
                                  ],
                                  "tips": [
                                    "Use zoom no gráfico para lags iniciais.",
                                    "Ignore lags muito altos sem padrão claro."
                                  ],
                                  "learningObjective": "Desenvolver habilidade para detectar visualmente autocorrelação significativa.",
                                  "commonMistakes": [
                                    "Considerar picos pequenos como significativos.",
                                    "Focar apenas no lag 1.",
                                    "Não diferenciar decay de oscilação."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diagnosticar Dependência Serial e Implicações para Regressão Linear",
                                  "subSteps": [
                                    "Explique dependência serial como violação da independência dos erros em OLS.",
                                    "Relacione picos ACF significativos a heterocedasticidade e ineficiência dos estimadores OLS.",
                                    "Discuta consequências: vieses em testes t/F, intervalos de confiança inválidos.",
                                    "Compare resíduos de modelo OLS: plote ACF dos resíduos para detectar problemas.",
                                    "Conclua se a série exibe ruído branco (sem picos) ou dependência."
                                  ],
                                  "verification": "Dado um gráfico ACF de resíduos OLS, diagnostique presença de dependência serial e explique impactos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Exemplo de regressão linear em série temporal (lm() em R)",
                                    "Gráficos ACF de resíduos"
                                  ],
                                  "tips": [
                                    "Sempre teste Ljung-Box para confirmação estatística.",
                                    "Visualize múltiplos gráficos lado a lado."
                                  ],
                                  "learningObjective": "Conectar interpretação ACF a propriedades assuntivas da regressão linear.",
                                  "commonMistakes": [
                                    "Ignorar que autocorrelação afeta apenas erros, não X.",
                                    "Confundir com multicolinearidade.",
                                    "Subestimar impacto em previsões."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com Modelos Avançados como ARIMA e Planejar Próximos Passos",
                                  "subSteps": [
                                    "Identifique padrões ACF para ordem ARIMA: picos cortando para AR(p), decay lento para I(1).",
                                    "Sugira auto.arima() ou manual box-jenkins baseado em ACF/PACF.",
                                    "Planeje diagnóstico pós-modelo: ACF de resíduos deve ser ruído branco.",
                                    "Discuta alternativas: GARCH para variância, SARIMA para sazonalidade.",
                                    "Documente decisão: 'Usar ARIMA devido a lag 1 significativo'."
                                  ],
                                  "verification": "Proponha um modelo ARIMA(p,d,q) baseado em um gráfico ACF e justifique.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tutoriais ARIMA em statsmodels (Python) ou forecast (R)",
                                    "Datasets como sunspots ou气温"
                                  ],
                                  "tips": [
                                    "Combine ACF com PACF para identificação precisa.",
                                    "Valide com AIC/BIC."
                                  ],
                                  "learningObjective": "Aplicar interpretação ACF para seleção e justificativa de modelos de séries temporais.",
                                  "commonMistakes": [
                                    "Escolher ARIMA sem evidência de não-estacionariedade.",
                                    "Ignorar sazonalidade em ACF.",
                                    "Não verificar resíduos finais."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de temperaturas diárias mensais (ex: mauna.loa dataset), plote o ACF mostrando picos significativos nos lags 1-7 (decay exponencial), indicando AR(7) ou necessidade de diferenciação. Isso diagnostica dependência serial, invalidando OLS simples para previsão, levando à modelagem ARIMA(1,1,1).",
                              "finalVerifications": [
                                "Identifica corretamente todos os lags significativos em um gráfico ACF fornecido.",
                                "Explica o impacto da autocorrelação em estimadores OLS com exemplos numéricos.",
                                "Propõe modelo ARIMA apropriado baseado no padrão ACF.",
                                "Verifica ruído branco nos resíduos simulados.",
                                "Documenta interpretação em relatório curto.",
                                "Diferencia padrões ACF de AR, MA e não-estacionariedade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de picos vs. bandas de confiança (90% acurácia).",
                                "Profundidade na explicação de implicações para regressão linear (cobertura de vieses e testes).",
                                "Relevância da sugestão de modelo ARIMA ao padrão observado.",
                                "Clareza e estrutura na documentação da análise.",
                                "Correção conceitual (sem confusões ACF/PACF ou estacionariedade).",
                                "Criatividade em conexões com dados reais."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de significância (Ljung-Box).",
                                "Econometria: Modelos de regressão com erros autocorrelacionados (Newey-West).",
                                "Machine Learning: Feature engineering para séries temporais em LSTM/Prophet.",
                                "Programação: Manipulação de dados em Python/R (pandas, dplyr)."
                              ],
                              "realWorldApplication": "Em análise financeira, interpretar ACF de retornos de ações diários revela dependência serial (ex: momentum), guiando traders a usar ARIMA para previsões em vez de regressão simples, melhorando estratégias de portfolio e risco em bancos como Itaú ou JPMorgan."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.2.3",
                            "name": "Testar autocorrelação nos resíduos",
                            "description": "Aplicar teste de Ljung-Box para verificar ausência de autocorrelação em resíduos de regressão, essencial para inferência válida em contextos econométricos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os resíduos do modelo de regressão",
                                  "subSteps": [
                                    "Ajuste um modelo de regressão linear ou ARIMA aos dados de série temporal usando Python (statsmodels).",
                                    "Extraia os resíduos do modelo ajustado com o atributo .resid.",
                                    "Visualize os resíduos com plot de autocorrelação (ACF) para inspeção inicial.",
                                    "Verifique estacionariedade dos resíduos usando teste ADF se necessário.",
                                    "Salve os resíduos em um array ou Series para o teste subsequente."
                                  ],
                                  "verification": "Resíduos extraídos e plot ACF gerado sem erros, mostrando possível autocorrelação.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com statsmodels e matplotlib instalados",
                                    "Dataset de série temporal (ex: dados econômicos como PIB)"
                                  ],
                                  "tips": "Sempre padronize os resíduos (subtraia média e divida pelo desvio padrão) para melhor interpretação.",
                                  "learningObjective": "Compreender como obter resíduos válidos de um modelo de regressão para testes de diagnóstico.",
                                  "commonMistakes": [
                                    "Usar resíduos não padronizados",
                                    "Esquecer de importar bibliotecas",
                                    "Não verificar o ajuste inicial do modelo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar o teste de Ljung-Box nos resíduos",
                                  "subSteps": [
                                    "Importe a função acorr_ljungbox do statsmodels.stats.diagnostic.",
                                    "Aplique a função aos resíduos: acorr_ljungbox(residuos, lags=10, return_df=True).",
                                    "Especifique lags apropriados (ex: 10-20 para séries mensais).",
                                    "Armazene os resultados em um DataFrame para análise.",
                                    "Repita para diferentes lags se necessário para robustez."
                                  ],
                                  "verification": "DataFrame com estatísticas LB e p-valores gerado corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Biblioteca statsmodels",
                                    "Jupyter Notebook ou script Python"
                                  ],
                                  "tips": "Use return_df=True para facilitar a leitura dos resultados em tabela.",
                                  "learningObjective": "Executar o teste Ljung-Box de forma programática e entender seus parâmetros.",
                                  "commonMistakes": [
                                    "Definir lags muito baixos",
                                    "Confundir com teste Box-Pierce",
                                    "Ignorar o parâmetro boxpierce=False"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar os resultados do teste",
                                  "subSteps": [
                                    "Examine o p-valor para cada lag: rejeite H0 (ausência de autocorrelação) se p < 0.05.",
                                    "Analise a estatística Q de Ljung-Box cumulativa.",
                                    "Compare com gráfico ACF para confirmação visual.",
                                    "Registre lags significativos e padrões observados.",
                                    "Documente conclusões em um relatório curto."
                                  ],
                                  "verification": "Relatório escrito com interpretação clara de p-valores e decisão sobre autocorrelação.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resultados do teste",
                                    "Ferramenta de escrita (Markdown ou Word)"
                                  ],
                                  "tips": "p-valor alto em todos lags indica resíduos brancos (bons para inferência).",
                                  "learningObjective": "Interpretar corretamente p-valores e estatísticas para validar suposições de resíduos.",
                                  "commonMistakes": [
                                    "Interpretar estatística Q como p-valor",
                                    "Ignorar múltiplos lags",
                                    "Confundir H0 com presença de autocorrelação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e reportar a ausência de autocorrelação",
                                  "subSteps": [
                                    "Confirme ausência se p > 0.05 em lags relevantes.",
                                    "Se presente, sugira correções como lags adicionais no modelo.",
                                    "Gere um resumo gráfico (ACF + tabela de teste).",
                                    "Compare com outros testes (Durbin-Watson para lag 1).",
                                    "Salve relatório final com código e outputs."
                                  ],
                                  "verification": "Relatório completo com gráficos, tabela e recomendação para o modelo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código completo",
                                    "Gráficos gerados"
                                  ],
                                  "tips": "Automatize com função personalizada para testes repetidos em múltiplos modelos.",
                                  "learningObjective": "Integrar o teste em um workflow de diagnóstico de modelos econométricos.",
                                  "commonMistakes": [
                                    "Não testar múltiplos lags",
                                    "Aceitar p-valor marginal sem investigação",
                                    "Omitir visualizações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de preços de ações diárias, ajuste um modelo ARIMA(1,1,1), extraia resíduos, aplique Ljung-Box com 20 lags e conclua que p-valores > 0.05 indicam ausência de autocorrelação, validando o modelo para previsões de risco financeiro.",
                              "finalVerifications": [
                                "Teste Ljung-Box executado com lags adequados e p-valores reportados.",
                                "Interpretação correta: ausência de autocorrelação se p > 0.05.",
                                "Gráficos ACF dos resíduos incluídos e analisados.",
                                "Recomendação clara para validade do modelo de regressão.",
                                "Código reproduzível sem erros.",
                                "Relatório documenta suposições e limitações do teste."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e padronização de resíduos (90%+ correção).",
                                "Implementação correta do teste com parâmetros apropriados.",
                                "Interpretação estatística precisa de p-valores e Q-stat.",
                                "Uso de visualizações complementares (ACF plots).",
                                "Relatório claro e acionável para contextos econométricos.",
                                "Identificação de erros comuns e correções propostas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses e significância.",
                                "Programação Computacional: Manipulação de dados em Python/R.",
                                "Econometria: Diagnóstico de modelos de séries temporais.",
                                "Engenharia de Dados: Validação de pipelines de ML.",
                                "Análise Financeira: Previsão e risco em séries temporais."
                              ],
                              "realWorldApplication": "Em engenharia econômica, engenheiros usam o teste Ljung-Box para validar modelos de previsão de demanda energética ou inflação, garantindo inferências confiáveis para decisões de investimento e políticas públicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.1.1.3",
                        "name": "Componentes de Séries Temporais",
                        "description": "Decomposição de uma série temporal em tendência (trend), sazonalidade e componente irregular (ruído), permitindo modelagem separada e previsão em aplicações econométricas e de engenharia de controle.",
                        "specificSkills": [
                          {
                            "id": "11.1.1.3.1",
                            "name": "Identificar componente de tendência",
                            "description": "Detectar e descrever a tendência de longo prazo em séries temporais, utilizando métodos como médias móveis, com exemplos de crescimento econômico ou degradação de equipamentos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Componente de Tendência",
                                  "subSteps": [
                                    "Defina tendência como a componente de longo prazo em uma série temporal, representando a direção geral dos dados ao longo do tempo.",
                                    "Diferencie tendência de outros componentes como sazonalidade e ruído aleatório.",
                                    "Estude exemplos: crescimento exponencial em PIB ou declínio linear em vida útil de equipamentos.",
                                    "Analise características: pode ser linear, exponencial, logística ou estacionária.",
                                    "Discuta como tendências são causadas por fatores subjacentes como crescimento populacional ou obsolescência tecnológica."
                                  ],
                                  "verification": "Explique em suas palavras o que é tendência e dê dois exemplos distintos, confirmando com uma fonte confiável.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Livro-texto de séries temporais ou artigo online sobre componentes (ex: Wikipedia 'Trend-stationary process')",
                                    "Caderno para anotações"
                                  ],
                                  "tips": "Use analogias como 'a direção geral de um rio apesar das ondas' para fixar o conceito.",
                                  "learningObjective": "Entender a definição, tipos e causas do componente de tendência em séries temporais.",
                                  "commonMistakes": [
                                    "Confundir tendência com sazonalidade curta-prazo",
                                    "Ignorar que tendência pode ser não-linear"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Visualizar e Identificar Tendência em Dados Brutos",
                                  "subSteps": [
                                    "Colete ou baixe um conjunto de dados de série temporal (ex: PIB anual ou horas de uso até falha de máquina).",
                                    "Plote os dados em um gráfico de linha com tempo no eixo x.",
                                    "Observe padrões visuais: procure linhas gerais ascendentes, descendentes ou estáveis, ignorando flutuações curtas.",
                                    "Marque manualmente uma linha suavizada sobre os dados para destacar a tendência.",
                                    "Registre observações iniciais sobre direção e força da tendência."
                                  ],
                                  "verification": "Crie um gráfico anotado mostrando a tendência visual e descreva-a em 1-2 frases.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Ferramenta de plotagem como Python (Matplotlib) ou papel milimetrado",
                                    "Dataset exemplo: dados de PIB do World Bank"
                                  ],
                                  "tips": "Aumente o tamanho da janela de visualização para focar em longo prazo; use zoom out no gráfico.",
                                  "learningObjective": "Desenvolver habilidade em identificar tendências por inspeção visual em séries temporais.",
                                  "commonMistakes": [
                                    "Focar em flutuações de curto prazo como tendência",
                                    "Não escalar eixos corretamente, distorcendo a percepção"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Médias Móveis para Extrair a Tendência",
                                  "subSteps": [
                                    "Escolha uma janela de média móvel (ex: 3-5 períodos para dados anuais).",
                                    "Calcule a média móvel simples (SMA): para cada ponto, some os valores da janela e divida pelo tamanho.",
                                    "Plote a SMA sobre os dados originais para visualizar a tendência suavizada.",
                                    "Ajuste a janela: menor para capturar curvas, maior para suavizar mais.",
                                    "Compare SMA com visualização manual para validar."
                                  ],
                                  "verification": "Calcule e plote SMA para um dataset de 20 pontos; verifique se valores batem com cálculo manual de 3 pontos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Excel (função AVERÁGUA.MÓVEL) ou Python (pandas rolling().mean())",
                                    "Dataset com pelo menos 20 observações"
                                  ],
                                  "tips": "Comece com janela ímpar para centralizar; teste múltiplas janelas para ver sensibilidade.",
                                  "learningObjective": "Dominar o cálculo e aplicação de médias móveis para isolar a componente de tendência.",
                                  "commonMistakes": [
                                    "Usar janela muito pequena (amplifica ruído)",
                                    "Não alinhar corretamente os pontos da média móvel no plot"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Descrever e Interpretar a Tendência Identificada",
                                  "subSteps": [
                                    "Descreva a direção (crescente/decrescente), forma (linear/exponencial) e magnitude (ex: +2% ao ano).",
                                    "Relacione com contexto: para PIB, discuta implicações econômicas; para equipamentos, planejamento de manutenção.",
                                    "Projete a tendência futura por 2-3 períodos usando a SMA.",
                                    "Discuta limitações: mudanças abruptas podem quebrar a tendência.",
                                    "Escreva um relatório curto resumindo achados."
                                  ],
                                  "verification": "Produza um parágrafo descritivo da tendência com evidências do gráfico e cálculos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráficos gerados nos steps anteriores",
                                    "Template de relatório simples"
                                  ],
                                  "tips": "Use termos quantitativos como 'inclinação média de 1.5 unidades/ano' para precisão.",
                                  "learningObjective": "Capacitar interpretação qualitativa e quantitativa da tendência no contexto real.",
                                  "commonMistakes": [
                                    "Descrições vagas sem números",
                                    "Ignorar contexto do domínio (ex: economia vs. engenharia)"
                                  ]
                                }
                              ],
                              "practicalExample": "Baixe dados anuais do PIB do Brasil (2000-2020) do World Bank. Plote a série, aplique SMA de 5 anos, identifique tendência crescente de ~3% ao ano devido a expansão econômica, e discuta implicações para políticas fiscais.",
                              "finalVerifications": [
                                "Definição correta de tendência sem confundir com outros componentes.",
                                "Gráfico visual com tendência destacada.",
                                "Cálculo preciso de SMA para dataset fornecido.",
                                "Descrição quantitativa e contextual da tendência.",
                                "Projeção simples futura baseada na tendência.",
                                "Identificação de pelo menos uma limitação do método."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual (definição e diferenciação: 20%)",
                                "Qualidade da visualização e cálculo de SMA (30%)",
                                "Profundidade da descrição e interpretação (25%)",
                                "Uso correto de ferramentas e materiais (15%)",
                                "Clareza e completude do relatório final (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Economia: Análise de crescimento GDP e forecasting macroeconômico.",
                                "Engenharia: Previsão de degradação e manutenção preditiva de ativos.",
                                "Estatística: Modelagem de regressão linear para tendências.",
                                "Ciência de Dados: Preparação para decomposição STL avançada."
                              ],
                              "realWorldApplication": "Em finanças, identificar tendências em ações para estratégias de investimento; em manufatura, detectar desgaste em máquinas para agendar reparos preventivos, reduzindo downtime em 20-30%."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.3.2",
                            "name": "Reconhecer sazonalidade",
                            "description": "Identificar padrões cíclicos repetitivos em intervalos fixos, como vendas trimestrais ou variações diárias em sistemas de controle, e discutir remoção via diferenciação sazonal.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Conceito de Sazonalidade em Séries Temporais",
                                  "subSteps": [
                                    "Defina sazonalidade como padrões cíclicos repetitivos em intervalos fixos, como diário, semanal, mensal ou anual.",
                                    "Distinga sazonalidade de tendência (mudança gradual) e ruído (variações aleatórias).",
                                    "Estude exemplos: vendas trimestrais de varejo ou temperatura diária.",
                                    "Revise a decomposição clássica de séries temporais: nível + tendência + sazonalidade + irregular.",
                                    "Anote características chave: periodicidade fixa e repetição previsível."
                                  ],
                                  "verification": "Explique em suas palavras o que é sazonalidade e dê 2 exemplos corretos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Vídeo introdutório sobre séries temporais (ex: Khan Academy)",
                                    "Notas em papel ou digital"
                                  ],
                                  "tips": "Use analogias cotidianas, como tráfego de fim de semana, para fixar o conceito.",
                                  "learningObjective": "Compreender a definição e componentes da sazonalidade em séries temporais.",
                                  "commonMistakes": [
                                    "Confundir sazonalidade com tendência de longo prazo",
                                    "Ignorar a periodicidade fixa"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Visualizar e Identificar Padrões Sazonais em Gráficos",
                                  "subSteps": [
                                    "Colete um conjunto de dados de série temporal simples (ex: vendas mensais).",
                                    "Plote o gráfico de linha temporal usando ferramentas como Excel ou Python (matplotlib).",
                                    "Observe repetições visuais: picos e vales em intervalos regulares.",
                                    "Marque os ciclos sazonais no gráfico com linhas ou anotações.",
                                    "Compare com dados sem sazonalidade para contrastar."
                                  ],
                                  "verification": "Crie um gráfico anotado mostrando pelo menos 3 ciclos sazonais identificados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Dataset de exemplo (vendas de varejo)",
                                    "Software de plotagem opcional (Python/Jupyter)"
                                  ],
                                  "tips": "Aumente a escala do eixo Y para realçar padrões sutis; use zoom em períodos específicos.",
                                  "learningObjective": "Desenvolver habilidade visual para detectar sazonalidade em dados plotados.",
                                  "commonMistakes": [
                                    "Sobrepor ruído como sazonalidade",
                                    "Ignorar mudanças de escala no gráfico"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Dados Reais com Sazonalidade Evidente",
                                  "subSteps": [
                                    "Selecione datasets reais: consumo de energia diário ou tráfego de site semanal.",
                                    "Calcule médias móveis por período sazonal (ex: média semanal).",
                                    "Identifique amplitude e fase da sazonalidade (pico em qual mês?).",
                                    "Discuta impactos: como sazonalidade afeta previsões.",
                                    "Registre observações em uma tabela: período, amplitude, fase."
                                  ],
                                  "verification": "Preencha uma tabela de análise com 4 observações corretas de sazonalidade em dados reais.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Datasets públicos (Kaggle: air passengers ou electricity consumption)",
                                    "Excel ou Python (pandas)"
                                  ],
                                  "tips": "Comece com dados clássicos como 'AirPassengers' para prática guiada.",
                                  "learningObjective": "Aplicar identificação de sazonalidade em conjuntos de dados reais.",
                                  "commonMistakes": [
                                    "Confundir correlação com causalidade sazonal",
                                    "Não considerar múltiplos componentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Discutir Remoção de Sazonalidade via Diferenciação Sazonal",
                                  "subSteps": [
                                    "Explique diferenciação sazonal: subtrair valor de mesmo período no ciclo anterior (ex: Y_t - Y_{t-s}).",
                                    "Aplique em um dataset: calcule diferenças sazonais para um lag s=12 (mensal).",
                                    "Plote série original vs. diferenciada sazonalmente.",
                                    "Avalie redução de padrões cíclicos e compare com diferenciação regular.",
                                    "Discuta limitações: perda de dados iniciais e possível sobrediferenciação."
                                  ],
                                  "verification": "Gere gráfico comparativo mostrando remoção efetiva da sazonalidade.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Mesmos datasets do Step 3",
                                    "Python (pandas para diff) ou Excel fórmulas"
                                  ],
                                  "tips": "Use lag apropriado ao período (12 para mensal, 7 para diário semanal).",
                                  "learningObjective": "Compreender e aplicar técnicas básicas para remover sazonalidade.",
                                  "commonMistakes": [
                                    "Escolher lag errado",
                                    "Não validar remoção com ACF plots"
                                  ]
                                }
                              ],
                              "practicalExample": "Analise dados mensais de vendas de sorvetes: picos consistentes em dezembro-fevereiro (verão no hemisfério sul). Identifique ciclo anual (s=12), plote e aplique diferenciação sazonal para remover o padrão, resultando em resíduos mais estacionários.",
                              "finalVerifications": [
                                "Identifica corretamente sazonalidade em 3 gráficos diferentes.",
                                "Explica decomposição de série temporal com sazonalidade.",
                                "Aplica diferenciação sazonal em dataset simples sem erros.",
                                "Discute limitações da remoção sazonal.",
                                "Compara sazonalidade vs. outros componentes em exemplos reais.",
                                "Cria tabela de análise com período, fase e amplitude."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação visual de padrões cíclicos (80%+ acurácia).",
                                "Correta aplicação de diferenciação sazonal com lag apropriado.",
                                "Qualidade de gráficos e anotações (clareza e legibilidade).",
                                "Profundidade na discussão de exemplos reais e impactos.",
                                "Compreensão conceitual demonstrada em explicações escritas.",
                                "Eficiência no uso de ferramentas (tempo e erros mínimos)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Decomposição aditiva/multiplicativa de séries.",
                                "Economia: Previsão de demanda sazonal em varejo.",
                                "Ciência Ambiental: Padrões climáticos em dados meteorológicos.",
                                "Negócios: Otimização de estoque baseado em ciclos sazonais."
                              ],
                              "realWorldApplication": "Em empresas de varejo, reconhecer sazonalidade em vendas permite ajustar estoques para Black Friday ou Natal, evitando excessos ou faltas; em energia, prevê picos de consumo no verão para planejamento de rede."
                            },
                            "estimatedTime": "0.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.3.3",
                            "name": "Decompor série temporal",
                            "description": "Realizar decomposição aditiva ou multiplicativa de uma série em trend, sazonal e irregular usando R ou ferramentas similares, aplicando a análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o ambiente e os dados da série temporal",
                                  "subSteps": [
                                    "Instalar e carregar os pacotes necessários no R (forecast, ggplot2).",
                                    "Carregar o conjunto de dados de série temporal (ex: AirPassengers ou dados próprios).",
                                    "Converter os dados para objeto ts() com frequência apropriada (mensal=12, trimestral=4).",
                                    "Visualizar a série original com plot() para identificar padrões iniciais.",
                                    "Verificar estacionariedade e tratar missing values se necessário."
                                  ],
                                  "verification": "Série temporal plotada corretamente sem erros e com frequência definida.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R/RStudio",
                                    "Pacotes: forecast, ggplot2",
                                    "Dataset de série temporal (ex: AirPassengers)"
                                  ],
                                  "tips": "Sempre defina start e frequency corretamente para evitar erros na decomposição.",
                                  "learningObjective": "Configurar ambiente R e preparar dados para análise de séries temporais.",
                                  "commonMistakes": [
                                    "Esquecer de converter para ts()",
                                    "Frequência errada levando a sazonalidade incorreta",
                                    "Ignorar missing values"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar decomposição aditiva",
                                  "subSteps": [
                                    "Aplicar a função decompose() com type='additive'.",
                                    "Extrair componentes: trend, seasonal e irregular.",
                                    "Plotar os componentes individuais usando plot(decomposição).",
                                    "Calcular resíduos e analisar variância.",
                                    "Salvar os componentes em variáveis separadas para análise posterior."
                                  ],
                                  "verification": "Gráficos dos componentes trend, seasonal e irregular gerados e salvos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R com pacotes carregados",
                                    "Objeto ts() preparado"
                                  ],
                                  "tips": "Use additive para séries com variância constante; verifique se seasonal soma zero.",
                                  "learningObjective": "Executar e visualizar decomposição aditiva de uma série temporal.",
                                  "commonMistakes": [
                                    "Aplicar additive em séries com variância crescente",
                                    "Não inspecionar se trend é suave",
                                    "Ignorar warnings sobre não-estacionariedade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar decomposição multiplicativa",
                                  "subSteps": [
                                    "Aplicar decompose() com type='multiplicative'.",
                                    "Extrair e plotar componentes: trend, seasonal e irregular.",
                                    "Comparar com a decomposição aditiva via side-by-side plots.",
                                    "Ajustar Box-Cox se necessário para estabilizar variância.",
                                    "Calcular e plotar resíduos para ambos os modelos."
                                  ],
                                  "verification": "Comparação visual entre aditiva e multiplicativa com resíduos analisados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R",
                                    "Decomposição aditiva anterior",
                                    "Função BoxCoxTransform do forecast"
                                  ],
                                  "tips": "Multiplicativa é ideal para séries com variância proporcional ao nível; teste log-transform.",
                                  "learningObjective": "Diferenciar e aplicar decomposição multiplicativa adequadamente.",
                                  "commonMistakes": [
                                    "Usar multiplicative com zeros ou negativos nos dados",
                                    "Não comparar modelos",
                                    "Esquecer transformação log"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar, validar e documentar resultados",
                                  "subSteps": [
                                    "Analisar trend para direção e suavidade.",
                                    "Verificar sazonalidade: amplitude e periodicidade.",
                                    "Examinar irregular para ruído e outliers.",
                                    "Escolher melhor modelo baseado em AIC ou resíduos.",
                                    "Gerar relatório com ggplots e exportar componentes."
                                  ],
                                  "verification": "Relatório com interpretação escrita e escolha de modelo justificada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R com ggplot2",
                                    "Componentes extraídos"
                                  ],
                                  "tips": "Use STL() para decomposições mais robustas se decompose() falhar.",
                                  "learningObjective": "Interpretar componentes e validar decomposição em contexto de engenharia.",
                                  "commonMistakes": [
                                    "Interpretar irregular como sinal útil",
                                    "Não validar com dados out-of-sample",
                                    "Escolha subjetiva sem métricas"
                                  ]
                                }
                              ],
                              "practicalExample": "Decompor a série clássica AirPassengers (passageiros aéreos mensais 1949-1960) no R: aplicar decompose additive/multiplicative, identificar trend crescente, sazonalidade anual e irregular, plotando para análise de demanda em aviação.",
                              "finalVerifications": [
                                "Trend é suave e captura direção de longo prazo.",
                                "Componente sazonal tem média zero (aditiva) ou 1 (multiplicativa) e periodicidade correta.",
                                "Irregular representa ruído sem padrões restantes.",
                                "Resíduos são estacionários (teste ADF).",
                                "Visualizações claras de todos componentes.",
                                "Modelo escolhido justificado por métricas (ex: menor MSE)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação de dados ts() (sem erros).",
                                "Correta aplicação e distinção aditiva/multiplicativa.",
                                "Qualidade das visualizações e extração de componentes.",
                                "Interpretação precisa dos componentes em contexto.",
                                "Validação com métricas quantitativas.",
                                "Documentação completa e acionável."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Modelos lineares e resíduos.",
                                "Programação: Manipulação de dados em R.",
                                "Engenharia: Análise preditiva de processos.",
                                "Machine Learning: Pré-processamento para forecasting.",
                                "Visualização de Dados: ggplot2 e plots temporais."
                              ],
                              "realWorldApplication": "Em engenharia, decompor séries de vibrações de máquinas para detectar trend de desgaste, sazonalidade operacional e irregular (falhas), permitindo manutenção preditiva e otimização de produção."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.1.1.3.4",
                            "name": "Analisar componente irregular",
                            "description": "Interpretar o ruído residual após remoção de trend e sazonalidade, verificando se é estacionário e autocorrelacionado, preparando para modelagem ARIMA.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Extrair o componente irregular da série temporal",
                                  "subSteps": [
                                    "Realize a decomposição da série temporal usando método clássico ou STL para separar trend e sazonalidade.",
                                    "Subtraia o trend e a sazonalidade dos dados originais para obter o resíduo.",
                                    "Plote o resíduo resultante para inspeção visual inicial.",
                                    "Calcule estatísticas descritivas (média, variância, skewness) do resíduo.",
                                    "Salve o resíduo em uma nova série para análises subsequentes."
                                  ],
                                  "verification": "O gráfico do resíduo não apresenta padrões de trend ou sazonalidade evidentes, e estatísticas indicam ausência de viés.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com bibliotecas pandas e statsmodels",
                                    "Jupyter Notebook",
                                    "Dataset de série temporal exemplo (ex: AirPassengers)"
                                  ],
                                  "tips": [
                                    "Prefira decomposição multiplicativa para séries com variância crescente.",
                                    "Verifique o tipo de sazonalidade antes de prosseguir.",
                                    "Use log-transformação se houver heterocedasticidade."
                                  ],
                                  "learningObjective": "Extrair com precisão o componente irregular após remoção de trend e sazonalidade.",
                                  "commonMistakes": [
                                    "Falhar em remover completamente o trend, deixando resíduos não estacionários.",
                                    "Usar decomposição aditiva em séries multiplicativas.",
                                    "Ignorar outliers que distorcem o resíduo."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Verificar estacionariedade do componente irregular",
                                  "subSteps": [
                                    "Aplique o teste Augmented Dickey-Fuller (ADF) no resíduo.",
                                    "Gere plots de série temporal, boxplot e histograma para inspeção visual de média e variância constantes.",
                                    "Se não estacionário (p-value > 0.05), aplique diferenciação de primeira ordem e re-teste.",
                                    "Compare estatísticas antes e após diferenciação.",
                                    "Documente os resultados do teste com p-value e estatística crítica."
                                  ],
                                  "verification": "p-value do ADF < 0.05 confirma estacionariedade; plots mostram ausência de drift.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python statsmodels.tsa.stattools.adfuller",
                                    "Matplotlib/Seaborn para plots",
                                    "Dataset do resíduo gerado no step 1"
                                  ],
                                  "tips": [
                                    "Inclua lags automáticos no ADF para robustez.",
                                    "Visualize sempre antes de testes formais.",
                                    "Considere KPSS como teste complementar."
                                  ],
                                  "learningObjective": "Aplicar e interpretar testes de estacionariedade no resíduo.",
                                  "commonMistakes": [
                                    "Interpretar erroneamente p-value alto como estacionariedade.",
                                    "Não diferenciar adequadamente séries com unit root.",
                                    "Ignorar visualizações em favor apenas de testes."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar autocorrelação no componente irregular",
                                  "subSteps": [
                                    "Gere gráficos de Função de Autocorrelação (ACF) e Função de Autocorrelação Parcial (PACF) do resíduo.",
                                    "Identifique lags significativos (fora das bandas de confiança).",
                                    "Aplique teste Ljung-Box para verificar independência residual.",
                                    "Interprete padrões: decaimento exponencial sugere AR, oscilações sugerem MA.",
                                    "Registre lags relevantes para sugestão de ordens ARIMA."
                                  ],
                                  "verification": "ACF/PACF mostram ausência de autocorrelação significativa em lags altos; Ljung-Box p-value > 0.05.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "statsmodels.tsa.stattools.acf e pacf",
                                    "Matplotlib",
                                    "Resíduo estacionário do step 2"
                                  ],
                                  "tips": [
                                    "Use 20-30 lags para visualização inicial.",
                                    "Confie mais em PACF para ordens AR.",
                                    "White noise ideal tem todas autocorrelações insignificantes."
                                  ],
                                  "learningObjective": "Detectar e interpretar dependências autocorrelacionadas no resíduo.",
                                  "commonMistakes": [
                                    "Confundir bandas de confiança com significância.",
                                    "Ignorar PACF ao focar só em ACF.",
                                    "Não testar independência com Ljung-Box."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e preparar para modelagem ARIMA",
                                  "subSteps": [
                                    "Sintetize achados: confirme se resíduo é white noise ou requer ARIMA.",
                                    "Sugira ordens p, d, q baseadas em ACF/PACF e testes.",
                                    "Prepare dataset limpo (resíduo estacionário) para estimação ARIMA.",
                                    "Elabore relatório com plots, testes e conclusões.",
                                    "Planeje validação cruzada para modelo final."
                                  ],
                                  "verification": "Relatório inclui interpretação coerente, ordens sugeridas e preparação de dados confirmada.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Notebook para relatório",
                                    "Resíduos e resultados dos steps anteriores"
                                  ],
                                  "tips": [
                                    "Se white noise, pare; senão, prossiga para ARIMA.",
                                    "Documente suposições explicitamente.",
                                    "Use AIC para refinar ordens."
                                  ],
                                  "learningObjective": "Integrar análises para preparar modelagem preditiva.",
                                  "commonMistakes": [
                                    "Assumir white noise sem testes rigorosos.",
                                    "Sugestões de ordens sem base em ACF/PACF.",
                                    "Omitir documentação de decisões."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de vendas mensais de varejo (ex: dataset 'sunspots' ou AirPassengers), decomponha a série, extraia o resíduo, teste ADF (confirma estacionariedade após d=1), analise ACF/PACF (detecta MA(1)) e prepare para ARIMA(0,1,1).",
                              "finalVerifications": [
                                "Resíduo extraído sem trend/sazonalidade visíveis.",
                                "Estacionariedade confirmada por ADF (p<0.05).",
                                "Autocorrelações interpretadas corretamente via ACF/PACF.",
                                "Teste Ljung-Box indica resíduos independentes.",
                                "Ordens ARIMA sugeridas com justificativa.",
                                "Relatório completo com plots e conclusões."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e visualização do resíduo (90%+ correção).",
                                "Correta aplicação e interpretação de testes ADF e Ljung-Box.",
                                "Análise integrada de ACF/PACF com sugestões de modelo válidas.",
                                "Relatório claro, com evidências visuais e quantitativas.",
                                "Identificação precisa de erros comuns evitados.",
                                "Preparação adequada de dados para ARIMA."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses e processos estocásticos.",
                                "Programação Computacional: Manipulação de séries em Python/R.",
                                "Matemática Aplicada: Modelos lineares e diferenciais.",
                                "Ciência de Dados: Pré-processamento para machine learning.",
                                "Econometria: Análise de séries financeiras."
                              ],
                              "realWorldApplication": "Na previsão de demanda em supply chain, análise de resíduos em séries de vendas permite detectar padrões residuais, melhorando modelos ARIMA para estoque otimizado e redução de custos."
                            },
                            "estimatedTime": "0.75 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.2",
                    "name": "Modelos ARIMA",
                    "description": "Modelos autoregressivos integrados de média móvel (ARIMA) para modelagem e previsão de séries temporais univariadas.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.2.1",
                        "name": "Modelos Autoregressivos AR(p)",
                        "description": "Modelos em que o valor atual de uma série temporal univariada é uma combinação linear de seus valores passados mais um termo de erro, utilizados para capturar dependências autoregressivas em séries estacionárias.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.1.1",
                            "name": "Definir a equação e notação do modelo AR(p)",
                            "description": "Escrever a equação geral do modelo AR(p), identificar os parâmetros φ_i e σ², e explicar o significado de cada termo no contexto de séries temporais univariadas em econometria aplicada à engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Séries Temporais Univariadas",
                                  "subSteps": [
                                    "Defina o que é uma série temporal univariada: uma sequência de observações {Y_t} de uma única variável ao longo do tempo.",
                                    "Explique a estacionariedade: média, variância e covariância constantes no tempo, essencial para modelos AR(p).",
                                    "Introduza o ruído branco ε_t: processo com E(ε_t)=0, Var(ε_t)=σ², e independência serial.",
                                    "Discuta a dependência autoregressiva: Y_t depende de valores passados Y_{t-1}, Y_{t-2}, etc.",
                                    "Diferencie séries temporais de regressão estática em econometria."
                                  ],
                                  "verification": "Escreva um resumo de 100 palavras definindo série temporal univariada e ruído branco, confirmando estacionariedade básica.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre séries temporais",
                                    "Livro 'Introdução à Econometria' (capítulo de séries temporais)",
                                    "Vídeo introdutório no YouTube sobre estacionariedade"
                                  ],
                                  "tips": "Use gráficos de séries temporais reais (ex: PIB) para visualizar dependência temporal.",
                                  "learningObjective": "Compreender o contexto univariado e estacionário onde o AR(p) se aplica em econometria de engenharia.",
                                  "commonMistakes": [
                                    "Confundir univariada com multivariada",
                                    "Ignorar a necessidade de estacionariedade",
                                    "Achar que ruído branco tem variância variável"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Dominar o Modelo AR(1) como Base",
                                  "subSteps": [
                                    "Escreva a equação do AR(1): Y_t = φ_1 Y_{t-1} + ε_t.",
                                    "Identifique os parâmetros: φ_1 (coeficiente autoregressivo, |φ_1| < 1 para estacionariedade), σ² (variância do erro).",
                                    "Explique o significado: Y_t é uma média ponderada do passado mais ruído aleatório.",
                                    "Discuta condições de estacionariedade: raízes da equação característica fora do círculo unitário.",
                                    "Simule um AR(1) simples manualmente com φ_1 = 0.5."
                                  ],
                                  "verification": "Escreva a equação AR(1), liste parâmetros e simule 5 observações iniciais com Y_0=0, ε_t ~ N(0,1).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora ou Excel para simulação",
                                    "Software R/Python (opcional para plotar)",
                                    "Folha de papel para cálculos manuais"
                                  ],
                                  "tips": "Verifique |φ_1| < 1 plotando a série para ver se converge.",
                                  "learningObjective": "Construir intuição para autoregressão de primeira ordem antes da generalização.",
                                  "commonMistakes": [
                                    "Esquecer o intercepto (ausente em AR puro)",
                                    "Permitir |φ_1| >=1 levando a explosão",
                                    "Confundir φ_1 com variância"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir a Equação Geral do Modelo AR(p)",
                                  "subSteps": [
                                    "Escreva a equação geral: Y_t = φ_1 Y_{t-1} + φ_2 Y_{t-2} + ... + φ_p Y_{t-p} + ε_t.",
                                    "Identifique a notação: φ_i (i=1 a p) são coeficientes autoregressivos, σ² variância do ruído.",
                                    "Explique cada termo: lags passados capturam dependência serial de ordem p.",
                                    "Discuta a forma matricial ou polinomial característica: 1 - φ_1 z - ... - φ_p z^p = 0.",
                                    "Compare com AR(1): extensão para múltiplos lags em séries com memória longa."
                                  ],
                                  "verification": "Escreva a equação AR(2) explicitamente e rotule todos os φ_i e σ².",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Quadro branco ou papel para equações",
                                    "Referência: Hamilton 'Time Series Analysis' (seção AR)",
                                    "Simulador online de ARIMA"
                                  ],
                                  "tips": "Use subscritos consistentes: Y_{t-k} para lag k.",
                                  "learningObjective": "Escrever e notate corretamente a forma geral AR(p).",
                                  "commonMistakes": [
                                    "Errar índices de lags (ex: Y_{t+1})",
                                    "Omitir ε_t",
                                    "Confundir ordem p com número de parâmetros"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explicar Parâmetros e Significado no Contexto",
                                  "subSteps": [
                                    "Descreva φ_i: peso do lag i na previsão de Y_t; sinal indica direção da dependência.",
                                    "Explique σ²: mede incerteza não explicada pelo passado.",
                                    "Discuta interpretação em econometria de engenharia: φ_i mostram persistência em séries como consumo de energia.",
                                    "Verifique estacionariedade: raízes do polinômio AR fora do círculo unitário.",
                                    "Relacione com ACF/PACF: PACF corta após lag p em AR(p)."
                                  ],
                                  "verification": "Explique em parágrafo o papel de φ_2 em um AR(2) para previsão de demanda.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Gráficos ACF/PACF de exemplos reais",
                                    "Artigo sobre ARIMA em engenharia",
                                    "Software para estimar φ_i (opcional)"
                                  ],
                                  "tips": "Pense em φ_i como 'herança' do passado na série.",
                                  "learningObjective": "Interpretar parâmetros no contexto de séries temporais univariadas aplicadas.",
                                  "commonMistakes": [
                                    "Interpretar φ_i como causalidade",
                                    "Ignorar variância σ² na incerteza",
                                    "Confundir com parâmetros de MA"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia civil, para modelar a série temporal de deformações diárias em uma ponte (Y_t), use AR(2): Y_t = 0.6 Y_{t-1} + 0.3 Y_{t-2} + ε_t, onde φ_1=0.6 indica forte influência do dia anterior, φ_2=0.3 do anterior a ele, e σ²=0.1 mede ruído de vento/vibrações. Estacione os dados primeiro via diferenças.",
                              "finalVerifications": [
                                "Escrever corretamente a equação geral AR(p) com notação padrão.",
                                "Identificar e listar φ_1 a φ_p e σ² como parâmetros.",
                                "Explicar o papel de cada termo em 2-3 frases.",
                                "Verificar condições de estacionariedade verbalmente.",
                                "Diferenciar AR(p) de outros modelos como MA(q).",
                                "Aplicar notação a um exemplo numérico simples."
                              ],
                              "assessmentCriteria": [
                                "Precisão na equação e notação (sem erros de índices).",
                                "Correta identificação e descrição de todos os parâmetros.",
                                "Explicação clara do significado contextual em séries univariadas.",
                                "Demonstração de entendimento de estacionariedade.",
                                "Uso consistente de termos técnicos (lags, ruído branco).",
                                "Capacidade de generalizar de AR(1) para AR(p)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em processos estocásticos e testes de estacionariedade (Dickey-Fuller).",
                                "Programação: Implementação em Python (statsmodels) ou R (arima) para estimação.",
                                "Economia/Finanças: Modelagem de retornos de ativos ou PIB em econometria.",
                                "Engenharia: Previsão de séries sensoriais (IoT) em sistemas de controle.",
                                "Matemática: Equações diferenciais lineares e polinômios características."
                              ],
                              "realWorldApplication": "Na engenharia elétrica, o modelo AR(p) é usado para prever carga de energia em redes baseadas em histórico de consumo, permitindo otimização de geração e redução de falhas; em econometria aplicada, estima persistência em séries de produção industrial para planejamento de infraestrutura."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.2",
                            "name": "Determinar condições de estacionariedade para AR(p)",
                            "description": "Derivar as condições para que o processo AR(p) seja estacionário, incluindo a análise das raízes do polinômio característico e interpretação das funções de autocorrelação (ACF) e autocorrelação parcial (PACF).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o Modelo AR(p) e o Polinômio Característico",
                                  "subSteps": [
                                    "Defina o processo AR(p): X_t = φ_1 X_{t-1} + ... + φ_p X_{t-p} + ε_t, onde ε_t é ruído branco.",
                                    "Escreva a equação em forma de atraso (lag operator): φ(L) X_t = ε_t, onde φ(L) = 1 - φ_1 L - ... - φ_p L^p.",
                                    "Identifique o polinômio característico: φ(z) = 1 - φ_1 z - ... - φ_p z^p.",
                                    "Explique que as raízes de φ(z) = 0 determinam o comportamento do processo.",
                                    "Discuta a representação em série infinita para processos causais."
                                  ],
                                  "verification": "Escreva corretamente o polinômio característico para um AR(2) dado e liste suas raízes.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de Séries Temporais (ex: Brockwell & Davis)",
                                    "Notebook Jupyter com Python/R",
                                    "Documentação de statsmodels"
                                  ],
                                  "tips": "Use o operador de atraso para simplificar notações; pratique com p=1 e p=2 primeiro.",
                                  "learningObjective": "Compreender a estrutura matemática do modelo AR(p) e seu polinômio associado.",
                                  "commonMistakes": [
                                    "Confundir φ(L) com o polinômio em z",
                                    "Esquecer o termo 1 no polinômio característico",
                                    "Ignorar a invertibilidade vs. causalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar Condições de Estacionariedade",
                                  "subSteps": [
                                    "Estude a condição de causalidade: todas as raízes de φ(z)=0 devem ter |z| > 1 (fora do círculo unitário).",
                                    "Derive a representação MA(∞): X_t = ∑ ψ_j ε_{t-j}, com ∑ |ψ_j| < ∞ para estacionariedade.",
                                    "Verifique para AR(1): |φ_1| < 1 implica raiz z=1/φ_1 com |z|>1.",
                                    "Para AR(p), use o triângulo de estacionariedade ou critérios de Jury para verificar raízes.",
                                    "Implemente uma função para calcular raízes em Python/R e checar magnitudes."
                                  ],
                                  "verification": "Para φ(z)=1-0.5z+0.3z^2, calcule raízes e confirme se |raízes| >1.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software Python (numpy.polyroots)",
                                    "Tabela de condições para AR(2)",
                                    "Exercícios de Shumway & Stoffer"
                                  ],
                                  "tips": "Plote o polinômio no plano complexo para visualizar raízes; use numpy.roots para automação.",
                                  "learningObjective": "Derivar e aplicar condições matemáticas para estacionariedade em AR(p).",
                                  "commonMistakes": [
                                    "Permitir raízes na unidade circular",
                                    "Confundir magnitude com fase da raiz",
                                    "Não normalizar o polinômio corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar ACF e PACF para AR(p) Estacionário",
                                  "subSteps": [
                                    "Lembre que para AR(p) estacionário, ACF ρ_k satisfaz a equação de Yule-Walker: ρ_k = φ_1 ρ_{k-1} + ... + φ_p ρ_{k-p}.",
                                    "Descreva o decaimento da ACF: exponencial ou senoidal, tail off após lag p.",
                                    "Explique PACF: corta abruptamente após lag p (impulso em lag p+1=0).",
                                    "Gere simulações de AR(p) estacionário e não-estacionário; plote ACF/PACF.",
                                    "Interprete: se ACF não decai ou PACF não corta, suspeite de não-estacionariedade."
                                  ],
                                  "verification": "Simule AR(2) estacionário, gere ACF/PACF e identifique padrões corretos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python: statsmodels.tsa.arima.model",
                                    "R: arima.sim e acf/pacf",
                                    "Gráficos interativos com plotly"
                                  ],
                                  "tips": "Compare ACF/PACF de AR estacionário vs. ARIMA com d>0; use bandas de confiança.",
                                  "learningObjective": "Interpretar gráficos de ACF e PACF como indicadores de estacionariedade em AR(p).",
                                  "commonMistakes": [
                                    "Confundir tail-off de ACF com corte de PACF",
                                    "Ignorar amostras pequenas em simulações",
                                    "Não diferenciar AR de MA"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar e Aplicar Condições em Exemplos Práticos",
                                  "subSteps": [
                                    "Escolha coeficientes φ para AR(p) e verifique estacionariedade via raízes.",
                                    "Simule série temporal e teste estacionariedade com ADF ou KPSS.",
                                    "Ajuste modelo AR(p) a dados reais e diagnostique resíduos.",
                                    "Compare cenários: estacionário vs. unit root (ex: φ_1=1 em AR(1)).",
                                    "Documente relatório com raízes, ACF/PACF e testes."
                                  ],
                                  "verification": "Produza relatório para um dataset de série temporal confirmando estacionariedade.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Datasets: AirPassengers (não-estacionário)",
                                    "Python: adfuller de statsmodels",
                                    "Excel para cálculos manuais"
                                  ],
                                  "tips": "Sempre teste hipóteses nulas de não-estacionariedade; combine múltiplos diagnósticos.",
                                  "learningObjective": "Aplicar integralmente as condições de estacionariedade em análises reais.",
                                  "commonMistakes": [
                                    "Confiar só em visual ACF sem testes formais",
                                    "Não checar resíduos pós-ajuste",
                                    "Escolher p inadequado sem evidência"
                                  ]
                                }
                              ],
                              "practicalExample": "Para um AR(2) com φ_1=0.6, φ_2=-0.3: polinômio φ(z)=1-0.6z+0.3z^2. Raízes z≈1.67 e z≈-1.0 (ambas |z|>1, estacionário). Simule 200 observações, plote ACF (decaimento senoidal) e PACF (corte após lag 2).",
                              "finalVerifications": [
                                "Calcule raízes de φ(z) para AR(3) dado e confirme todas |z|>1.",
                                "Gere ACF teórica para AR(1) e compare com simulada.",
                                "Interprete PACF de uma simulação AR(2): deve cortar em lag 2.",
                                "Aplique teste ADF a série AR estacionário vs. random walk.",
                                "Explique por que raiz unitária implica não-estacionariedade.",
                                "Ajuste AR(p) a dados e verifique diagnósticos de estacionariedade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação do polinômio característico e raízes.",
                                "Correta aplicação da condição |raízes|>1 para causalidade/estacionariedade.",
                                "Interpretação precisa de padrões ACF/PACF para AR(p).",
                                "Uso correto de testes estatísticos (ADF, KPSS).",
                                "Capacidade de simular e diagnosticar em software.",
                                "Relatório claro com evidências matemáticas e empíricas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Equações de Yule-Walker e estimação de parâmetros.",
                                "Programação: Implementação em Python/R para análise de séries.",
                                "Economia: Modelagem de séries financeiras estacionárias.",
                                "Física: Modelos autoregressivos em sinais dinâmicos.",
                                "Machine Learning: Preprocessamento de features temporais estacionárias."
                              ],
                              "realWorldApplication": "Em finanças, verificar estacionariedade de retornos de ações antes de modelar com AR(p) para previsão de volatilidade; em meteorologia, analisar séries de temperatura para forecasts confiáveis."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.3",
                            "name": "Estimar parâmetros de um modelo AR(p) usando Mínimos Quadrados Ordinários",
                            "description": "Aplicar o método dos mínimos quadrados ordinários (MQO) para estimar os coeficientes φ_i em um modelo AR(p), discutir propriedades dos estimadores em grandes amostras e realizar inferência estatística.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o modelo AR(p) e preparar os dados",
                                  "subSteps": [
                                    "Revise a definição de um processo autoregressivo de ordem p: y_t = ∑_{i=1}^p φ_i y_{t-i} + ε_t, onde ε_t ~ WN(0, σ²).",
                                    "Colete uma série temporal estacionária e verifique stationariedade usando testes como ADF.",
                                    "Transforme a série em uma matriz de regressores lagged: crie Y = [y_{p+1}, ..., y_T]^T e X com colunas y_t-1 até y_t-p.",
                                    "Calcule a média amostral e centralize a série se necessário para evitar intercepto.",
                                    "Divida os dados em amostra de estimação e validação."
                                  ],
                                  "verification": "Construa manualmente a matriz X e Y para uma série pequena (T=10, p=1) e verifique dimensões.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Série temporal de exemplo (ex: dados de PIB ou temperaturas)",
                                    "Software: Python (statsmodels, pandas) ou R",
                                    "Notebook Jupyter"
                                  ],
                                  "tips": "Sempre verifique stationariedade antes; use diff() se não estacionária.",
                                  "learningObjective": "Preparar dados adequadamente para estimação AR(p).",
                                  "commonMistakes": [
                                    "Ignorar stationariedade levando a estimadores inconsistentes",
                                    "Incluir lags incorretos na matriz X",
                                    "Não tratar missing values"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular o problema de estimação via Mínimos Quadrados Ordinários (MQO)",
                                  "subSteps": [
                                    "Escreva o modelo em forma matricial: Y = X φ + ε, onde φ = [φ1, ..., φp]^T.",
                                    "Derive o estimador MQO: φ̂ = (X^T X)^{-1} X^T Y.",
                                    "Discuta pressupostos do MQO: erros iid, sem autocorrelação (válido para AR condicional).",
                                    "Calcule manualmente φ̂ para p=1 com dados sintéticos.",
                                    "Interprete os coeficientes φ_i como pesos de persistência."
                                  ],
                                  "verification": "Derive φ̂ para AR(1) e compare com regressão simples y_t ~ y_{t-1}.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Papel e lápis para derivações",
                                    "Calculadora matricial ou Python (numpy.linalg)",
                                    "Livro: Brockwell & Davis 'Time Series' capítulo AR"
                                  ],
                                  "tips": "Lembre-se: MQO é regressão linear sem intercepto para AR puro.",
                                  "learningObjective": "Formular e derivar o estimador OLS para AR(p).",
                                  "commonMistakes": [
                                    "Incluir intercepto desnecessariamente",
                                    "Confundir com Yule-Walker (que usa autocovariâncias)",
                                    "Esquecer inversão de X^T X"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar a estimação computacionalmente",
                                  "subSteps": [
                                    "Carregue dados em Python/R e crie lags com pandas.shift() ou lag() no R.",
                                    "Ajuste o modelo usando statsmodels.tsa.ar_model.AR ou lm() no R.",
                                    "Extraia coeficientes φ̂, variâncias e intervalos de confiança.",
                                    "Plote resíduos e verifique normalidade/autocorrelação com Ljung-Box.",
                                    "Compare com estimação Yule-Walker para validar."
                                  ],
                                  "verification": "Execute código em dataset real e obtenha φ̂ com p-value <0.05 para pelo menos um coeficiente.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python: statsmodels, pandas, matplotlib",
                                    "R: forecast, tseries",
                                    "Dataset: AirPassengers ou sunspots"
                                  ],
                                  "tips": "Use n_lags=p explícito; evite overfitting com AIC/BIC para escolher p.",
                                  "learningObjective": "Aplicar MQO numericamente em software para AR(p).",
                                  "commonMistakes": [
                                    "Não dropar primeiros p observações",
                                    "Ignorar warnings de multicolinearidade em p alto",
                                    "Confundir ordem do modelo com lags"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Discutir propriedades assintóticas e inferência estatística",
                                  "subSteps": [
                                    "Explique consistência: φ̂ → φ quando T→∞ sob stationariedade e momentos finitos.",
                                    "Derive variância assintótica: Var(φ̂) ≈ σ² (Γ)^{-1}, onde Γ é matriz autocovariância.",
                                    "Construa testes t: t = φ̂ / se(φ̂) ~ N(0,1) assintoticamente.",
                                    "Discuta inferência para raízes unitárias (teste Dickey-Fuller).",
                                    "Avalie validade com Q-Q plot de resíduos e teste de normalidade."
                                  ],
                                  "verification": "Interprete saída de summary() e conclua se modelo é adequado (resíduos brancos).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Notas de aula sobre asymptóticos",
                                    "Software para testes: adfuller() em statsmodels",
                                    "Referência: Hamilton 'Time Series Analysis'"
                                  ],
                                  "tips": "Foco em grandes amostras; para pequenas T, use bootstrap.",
                                  "learningObjective": "Compreender e aplicar propriedades/inferência de estimadores AR(p).",
                                  "commonMistakes": [
                                    "Assumir normalidade finita em vez de assintótica",
                                    "Ignorar não-estacionariedade",
                                    "Mal interpretar p-values sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Estime um AR(2) para a série de passageiros aéreos (AirPassengers). Após log-diff para stationariedade, use MQO para obter φ1 ≈ 0.6, φ2 ≈ 0.3, verifique resíduos brancos e preveja próximos 12 meses, comparando com valores reais.",
                              "finalVerifications": [
                                "Deriva corretamente φ̂ = (X^T X)^{-1} X^T Y para AR(p).",
                                "Implementa estimação em Python/R com lags corretos e diagnósticos.",
                                "Interpreta coeficientes, se(φ̂) e testes de significância.",
                                "Verifica pressupostos: stationariedade e resíduos iid.",
                                "Discute consistência assintótica e limitações.",
                                "Aplica em dataset real com previsão básica."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação matricial (100% correta).",
                                "Código funcional sem erros, com plots de resíduos.",
                                "Interpretação correta de propriedades assintóticas.",
                                "Identificação de pelo menos 3 erros comuns evitados.",
                                "Exemplo prático com validação quantitativa (MAE <10%).",
                                "Conexões claras com inferência estatística."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Regressão linear e testes de hipóteses.",
                                "Programação: Manipulação de dados em Python/R (pandas, numpy).",
                                "Economia: Modelagem de séries financeiras (ex: retornos de ações).",
                                "Matemática: Álgebra linear (matrizes, inversas).",
                                "Machine Learning: Base para modelos mais avançados como LSTM."
                              ],
                              "realWorldApplication": "Em finanças, estima AR(1) para retornos diários de ações para risco (VaR); em meteorologia, AR(p) para temperaturas para previsões curtas; em controle de estoque, para demanda sazonal."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.2.1.2",
                        "name": "Modelos de Média Móvel MA(q)",
                        "description": "Modelos em que o valor atual da série é uma combinação linear dos erros passados, ideais para capturar dependências de curto prazo em resíduos de séries temporais estacionárias.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.1.2.1",
                            "name": "Definir a equação do modelo MA(q)",
                            "description": "Escrever a equação geral do modelo MA(q), explicar os parâmetros θ_j e sua invertibilidade, relacionando com aplicações em previsão de séries univariadas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Séries Temporais e Ruído Branco",
                                  "subSteps": [
                                    "Defina o que é uma série temporal univariada e dê exemplos como temperaturas diárias ou preços de ações.",
                                    "Explique o conceito de processo estocástico estacionário e seus requisitos (média constante, variância finita, autocovariância dependente apenas do lag).",
                                    "Descreva o ruído branco (white noise): ε_t ~ WN(0, σ²), com E(ε_t)=0, Var(ε_t)=σ², Cov(ε_t, ε_{t-k})=0 para k≠0.",
                                    "Calcule manualmente a autocorrelação (ACF) de um ruído branco para lags 1 e 2.",
                                    "Discuta por que o ruído branco é a base para modelos MA(q)."
                                  ],
                                  "verification": "Escreva as propriedades matemáticas do ruído branco e compute ACF(1)=0 manualmente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Folha de papel e caneta",
                                    "Notebook com Python/R (opcional para plotar ACF)"
                                  ],
                                  "tips": "Lembre-se: ruído branco é idempotente na autocorrelação; use fórmulas para fixar conceitos.",
                                  "learningObjective": "Compreender a base estocástica necessária para modelos MA(q).",
                                  "commonMistakes": [
                                    "Confundir estacionariedade com invertibilidade",
                                    "Achar que ruído branco tem variância variável"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir a Equação do Modelo MA(1) e Generalizar para MA(q)",
                                  "subSteps": [
                                    "Escreva a equação do MA(1): X_t = μ + ε_t + θ_1 ε_{t-1}.",
                                    "Calcule a média E(X_t) = μ e a variância Var(X_t) = σ² (1 + θ_1²).",
                                    "Generalize para MA(q): X_t = μ + ∑_{j=1}^q θ_j ε_{t-j} + ε_t.",
                                    "Escreva a forma em operador de atraso: X_t - μ = (1 + θ_1 B + ... + θ_q B^q) ε_t, onde B é o operador backward shift.",
                                    "Verifique a notação padrão: θ_0 = 1 implícito."
                                  ],
                                  "verification": "Escreva a equação geral MA(q) e compute Var(X_t) para q=1.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora",
                                    "Livro de referência como 'Time Series Analysis' de Hamilton (capítulo MA)"
                                  ],
                                  "tips": "Comece com MA(1) para visualizar; use operadores B para economizar notação.",
                                  "learningObjective": "Derivar e escrever corretamente a equação geral do MA(q).",
                                  "commonMistakes": [
                                    "Esquecer o termo ε_t atual",
                                    "Confundir θ_j com φ_j de AR"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explicar Parâmetros θ_j e Condição de Invertibilidade",
                                  "subSteps": [
                                    "Descreva θ_j como coeficientes que ponderam choques passados ε_{t-j}.",
                                    "Explique invertibilidade: o modelo é invertível se as raízes do polinômio θ(z) = 1 + θ_1 z + ... + θ_q z^q estão fora do círculo unitário (|z| > 1).",
                                    "Para MA(1): invertível se |θ_1| < 1; relacione com representação AR(∞).",
                                    "Calcule o polinômio característico para MA(1) e encontre raízes.",
                                    "Discuta implicações: modelos não-invertíveis são raros na prática, mas equivalentes a outros parametrizados."
                                  ],
                                  "verification": "Para θ_1 = 0.5, verifique se |θ_1| < 1 e escreva a condição geral.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software como Python (statsmodels) para roots",
                                    "Gráfico de polinômio θ(z)"
                                  ],
                                  "tips": "Pense em invertibilidade como 'expressar ε_t em termos de X_t passados'; teste raízes numericamente.",
                                  "learningObjective": "Dominar o papel dos θ_j e critérios de invertibilidade.",
                                  "commonMistakes": [
                                    "Confundir invertibilidade com estacionariedade (MA sempre estacionário)",
                                    "Raízes dentro do círculo unitário como invertível"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar com Aplicações em Previsão de Séries Univariadas",
                                  "subSteps": [
                                    "Explique funções de autocorrelação (ACF) para MA(q): cortam após lag q.",
                                    "Discuta previsão ótima: E(X_{t+h} | X_t, ..., X_1) = μ para h > q.",
                                    "Gere dados simulados MA(1) e plote ACF para validar.",
                                    "Compare com ARIMA: MA(q) como caso especial (p=0,d=0).",
                                    "Aplique em exemplo: prever resíduos em modelo de regressão."
                                  ],
                                  "verification": "Simule MA(1) e confirme ACF cai a zero após lag 1.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Python com libraries: numpy, matplotlib, statsmodels.tsa.arima.model"
                                  ],
                                  "tips": "Use simulações para intuição; foque em previsões de curto prazo fortes de MA.",
                                  "learningObjective": "Conectar teoria MA(q) a práticas de previsão.",
                                  "commonMistakes": [
                                    "Achar que MA prevê bem longo prazo (não, só até q lags)",
                                    "Ignorar normalização dos dados"
                                  ]
                                }
                              ],
                              "practicalExample": "Em Python, simule um processo MA(1) com θ_1=0.6: import numpy as np; import matplotlib.pyplot as plt; np.random.seed(42); n=200; e=np.random.normal(0,1,n); theta1=0.6; X=np.zeros(n); for t in range(1,n): X[t]=e[t]+theta1*e[t-1]; plt.acf(X, lags=10); plt.show(). Observe ACF cortando após lag 1 e use para previsão de próximos 2 passos.",
                              "finalVerifications": [
                                "Escreva corretamente a equação MA(q): X_t = μ + ε_t + ∑_{j=1}^q θ_j ε_{t-j}.",
                                "Explique θ_j como pesos de choques passados e liste condições de invertibilidade.",
                                "Compute ACF para MA(1) e confirme corte após lag 1.",
                                "Simule dados MA(q) e valide propriedades.",
                                "Descreva uma aplicação em previsão univariada.",
                                "Diferencie MA de AR pela estrutura de dependência."
                              ],
                              "assessmentCriteria": [
                                "Precisão na equação geral e notação (100% correto).",
                                "Compreensão clara de θ_j e distinção de estacionariedade/invertibilidade.",
                                "Cálculos corretos de momentos (média, variância, ACF).",
                                "Exemplo prático funcional com simulação.",
                                "Conexão lógica com previsão e ARIMA.",
                                "Ausência de erros comuns como confusão de parâmetros."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em processos estocásticos e estimação de parâmetros via máxima verossimilhança.",
                                "Programação: Implementação em Python/R com statsmodels ou forecast.",
                                "Economia: Modelagem de séries financeiras como retornos de ações.",
                                "Engenharia: Previsão de sinais em controle de sistemas.",
                                "Machine Learning: Resíduos em modelos de regressão temporal."
                              ],
                              "realWorldApplication": "Em finanças, modelos MA(q) são usados para prever volatilidade de retornos diários de ações (ex: resíduos de GARCH), permitindo traders ajustarem posições com previsões de curto prazo baseadas em choques recentes, como impactos de notícias econômicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.2.2",
                            "name": "Analisar propriedades ACF e PACF para MA(q)",
                            "description": "Interpretar o comportamento da função ACF (corta após q lags) e PACF (decai gradualmente) para identificação de ordem q em processos MA estacionários e invertíveis.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Fundamentais de ACF e PACF",
                                  "subSteps": [
                                    "Defina ACF como a correlação serial em diferentes lags para uma série temporal estacionária.",
                                    "Explique PACF como a correlação parcial, removendo efeitos de lags intermediários.",
                                    "Discuta a importância da estacionariedade para validade das funções ACF e PACF.",
                                    "Revise fórmulas básicas: ACF(ρ_k) = Cov(Y_t, Y_{t-k}) / Var(Y_t).",
                                    "Identifique diferenças chave: ACF mede correlação direta, PACF mede contribuição única de um lag."
                                  ],
                                  "verification": "Resuma em 3 frases as diferenças entre ACF e PACF e liste 2 exemplos de uso.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas de aula sobre séries temporais",
                                    "Gráficos de exemplo ACF/PACF de AR(1)"
                                  ],
                                  "tips": "Use diagramas visuais para diferenciar ACF (picos decaindo) vs PACF (corte abrupto em AR).",
                                  "learningObjective": "Compreender definições e papéis de ACF e PACF em identificação de modelos.",
                                  "commonMistakes": [
                                    "Confundir ACF com PACF",
                                    "Ignorar necessidade de estacionariedade",
                                    "Interpretar lags sem contexto de modelo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar Propriedades ACF para Modelos MA(q)",
                                  "subSteps": [
                                    "Aprenda que em MA(q), ACF corta abruptamente para zero após lag q (devido a dependência finita).",
                                    "Simule MA(1): Y_t = ε_t + θ ε_{t-1}, ACF(1) ≠ 0, ACF(k>1) = 0.",
                                    "Gere fórmulas: Para MA(q), ρ_k = 0 para k > q.",
                                    "Plote ACF para MA(1), MA(2) usando software para visualizar o 'corte'.",
                                    "Discuta invertibilidade: Polo dentro do círculo unitário garante representações AR infinitas."
                                  ],
                                  "verification": "Desenhe manualmente ACF para MA(2) e identifique o lag de corte.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python/R com bibliotecas statsmodels ou forecast",
                                    "Simulador online de séries temporais"
                                  ],
                                  "tips": "Sempre normalize ACF para barras de confiança ±1.96/√n.",
                                  "learningObjective": "Identificar assinatura ACF única de MA(q): corte após q lags.",
                                  "commonMistakes": [
                                    "Assumir decaimento gradual como em AR",
                                    "Não verificar significância estatística",
                                    "Confundir com MA não estacionário"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Propriedades PACF para Modelos MA(q)",
                                  "subSteps": [
                                    "Entenda que PACF em MA(q) decai gradualmente ou oscila sem corte abrupto.",
                                    "Para MA(1), φ_{11} = ρ_1, φ_{kk} decai para zero em lags subsequentes.",
                                    "Use equação Yule-Walker para calcular PACF teórico em MA(q).",
                                    "Compare com AR(p): PACF corta em p, ACF decai.",
                                    "Plote PACF de simulações MA(1)/MA(2) para observar padrão de decaimento."
                                  ],
                                  "verification": "Compare PACF plotado de MA(1) com expectativa teórica e descreva o padrão.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código Jupyter para plot_acf e plot_pacf",
                                    "Tabela de propriedades ARIMA"
                                  ],
                                  "tips": "Foque em barras de confiança: PACF pode parecer 'cortar' por acaso se n pequeno.",
                                  "learningObjective": "Reconhecer decaimento gradual na PACF como indício de componente MA.",
                                  "commonMistakes": [
                                    "Esperar corte na PACF para MA",
                                    "Ignorar oscilações em MA de ordem superior",
                                    "Não diferenciar de ruído branco"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar Identificação de Ordem q via ACF/PACF",
                                  "subSteps": [
                                    "Gere séries simuladas MA(1), MA(2), misture com AR para prática.",
                                    "Plote ACF/PACF e identifique q pelo primeiro lag insignificante na ACF.",
                                    "Confirme com critérios: ACF corta em q, PACF não corta abruptamente.",
                                    "Teste estacionariedade com ADF e invertibilidade via raízes do polinômio MA.",
                                    "Aplique a dados reais: Identifique MA(q) em série de residuals de modelo AR."
                                  ],
                                  "verification": "Analise 3 plots fornecidos e especifique ordem q com justificativa.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Datasets de séries temporais (ex: AirPassengers residuals)",
                                    "Software R/Python"
                                  ],
                                  "tips": "Use log-scale para variâncias altas; valide com Ljung-Box para autocorrelação residual.",
                                  "learningObjective": "Aplicar padrões ACF/PACF para identificar corretamente ordem q em MA.",
                                  "commonMistakes": [
                                    "Sobreajuste q baseado em ruído",
                                    "Não diferenciar MA de ARIMA misto",
                                    "Ignorar sazonalidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de vendas diárias de varejo, plote ACF/PACF dos residuals após remoção de tendência. ACF corta após lag 2 (q=2), PACF decai gradualmente, confirmando MA(2) para modelar choques de demanda curta.",
                              "finalVerifications": [
                                "ACF mostra corte significativo após lag q com barras de confiança.",
                                "PACF exibe decaimento gradual sem corte abrupto.",
                                "Modelo simulado MA(q) reproduz padrões observados.",
                                "Teste de invertibilidade confirma raízes dentro do círculo unitário.",
                                "Residuals do modelo ajustado passam em Ljung-Box (sem autocorrelação).",
                                "Previsão de 1-step ahead tem erro baixo comparado a benchmark."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação do lag q via ACF (100% em 4/5 casos).",
                                "Explicação correta de por quê PACF decai em MA(q).",
                                "Uso apropriado de testes de significância em plots.",
                                "Integração de estacionariedade/invertibilidade na análise.",
                                "Aplicação prática em dataset real com relatório conciso.",
                                "Evita erros comuns como confusão AR/MA."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em processos estocásticos.",
                                "Programação: Uso de bibliotecas como statsmodels em Python.",
                                "Econometria: Modelagem de séries financeiras.",
                                "Machine Learning: Feature engineering com lags em forecasting.",
                                "Física: Análise de sinais ruidosos em experimentos."
                              ],
                              "realWorldApplication": "Em finanças, analisa ACF/PACF de retornos de ações para modelar volatilidade com MA(q), melhorando previsões de risco e alocação de portfólio em trading algorítmico."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.2.3",
                            "name": "Estimar MA(q) por maximização de verossimilhança",
                            "description": "Implementar estimação de parâmetros θ_j via máxima verossimilhança condicional ou incondicional, comparando com métodos generalizados dos momentos em contextos econométricos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos do Modelo MA(q)",
                                  "subSteps": [
                                    "Defina o modelo MA(q): y_t = ε_t + θ_1 ε_{t-1} + ... + θ_q ε_{t-q}, onde ε_t ~ N(0, σ²).",
                                    "Entenda as propriedades: invertibilidade, estacionariedade e autocorrelações teóricas.",
                                    "Revise a representação em função de atrasos infinitos (MA(∞)).",
                                    "Implemente simulação de uma série MA(q) usando Python (numpy.random.normal).",
                                    "Calcule ACF empírica e compare com teórica."
                                  ],
                                  "verification": "Simular uma série MA(1) e plotar ACF que decai após lag 1.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python (numpy, matplotlib, statsmodels)",
                                    "Documentação de modelos MA em statsmodels"
                                  ],
                                  "tips": "Use seed para reprodutibilidade nas simulações.",
                                  "learningObjective": "Compreender a estrutura e propriedades do modelo MA(q).",
                                  "commonMistakes": [
                                    "Confundir MA com AR",
                                    "Ignorar condições de invertibilidade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a Função de Verossimilhança Condicional e Incondicional",
                                  "subSteps": [
                                    "Escreva a densidade condicional: L(θ| y_1, ..., y_t) baseada em ε_t | passado.",
                                    "Derive a log-verossimilhança incondicional: log L(θ) = - (T/2) log(2πσ²) - (1/(2σ²)) Σ ε_t²(θ).",
                                    "Implemente ε_t(θ) recursivamente usando filtro de previsão.",
                                    "Compare verossimilhança condicional (ignora primeiros q lags) vs. exata.",
                                    "Teste em simulação MA(1) com θ conhecido."
                                  ],
                                  "verification": "Calcular log-likelihood para θ verdadeiro e verificar valor próximo ao ótimo teórico.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Caderno para derivações",
                                    "Jupyter Notebook",
                                    "Livro 'Time Series Analysis' de Hamilton (cap. 5)"
                                  ],
                                  "tips": "Use log-verossimilhança para evitar underflow numérico.",
                                  "learningObjective": "Dominar a formulação matemática da verossimilhança para MA(q).",
                                  "commonMistakes": [
                                    "Usar verossimilhança incondicional sem filtro",
                                    "Esquecer normalização por σ²"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Maximização Numérica da Verossimilhança",
                                  "subSteps": [
                                    "Defina função de log-likelihood em Python usando scipy.optimize.",
                                    "Inicialize θ com estimativas iniciais (ex: de Yule-Walker).",
                                    "Use minimize_scalar ou minimize para q=1, e differential_evolution para q>1.",
                                    "Calcule erros padrão via hessiana inversa (-1/Hessian).",
                                    "Ajuste modelo em dados simulados e verifique recuperação de θ verdadeiro."
                                  ],
                                  "verification": "Estimativa de θ converge para valor verdadeiro em 100 simulações (erro < 0.05).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python (scipy.optimize, statsmodels.tsa.arima.model)",
                                    "Exemplos de código statsmodels ARIMA fit"
                                  ],
                                  "tips": "Forneça bounds razoáveis para θ (-0.99 a 0.99) para invertibilidade.",
                                  "learningObjective": "Implementar estimação MLE prática para MA(q).",
                                  "commonMistakes": [
                                    "Má inicialização levando a mínimo local",
                                    "Não checar convergência"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com Método Generalizado dos Momentos (GMM)",
                                  "subSteps": [
                                    "Revise GMM para MA: momentos baseados em autocovariâncias sample vs. teóricas.",
                                    "Implemente estimador GMM de dois passos: primeiro OLS em autocovariâncias.",
                                    "Segundo passo: minimizar quadratic form com matriz ótima.",
                                    "Compare estimativas MLE vs. GMM em simulação e dados reais (AIC, std errors).",
                                    "Avalie eficiência: MLE assintoticamente eficiente vs. GMM robusto a misspecification."
                                  ],
                                  "verification": "Tabela comparativa de θ_hat, std err e log-likelihood para MLE e GMM.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python (statsmodels.tsa.arima_model para GMM-like)",
                                    "Paper 'GMM for Time Series' de Hansen"
                                  ],
                                  "tips": "Use kernel para covariância robusta em GMM.",
                                  "learningObjective": "Entender e comparar MLE com GMM em contextos econométricos.",
                                  "commonMistakes": [
                                    "Não ponderar momentos corretamente",
                                    "Ignorar robustez de GMM"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar e Diagnosticar em Dados Econométricos Reais",
                                  "subSteps": [
                                    "Carregue dados reais (ex: retornos diários de ações ou PIB trimestral).",
                                    "Teste estacionariedade (ADF) e identifique ordem q via ACF/PACF.",
                                    "Ajuste MA(q) via MLE e GMM, selecione melhor por BIC.",
                                    "Diagnostique resíduos: Ljung-Box, QQ-plot, histograma.",
                                    "Compare previsões out-of-sample."
                                  ],
                                  "verification": "Resíduos sem autocorrelação (p-value Ljung-Box > 0.05) e normalidade razoável.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Dados: Yahoo Finance API ou FRED",
                                    "Python (pandas, statsmodels)"
                                  ],
                                  "tips": "Diferençe séries não-estacionárias antes de ajustar MA.",
                                  "learningObjective": "Aplicar estimação MA(q) em cenários econométricos reais.",
                                  "commonMistakes": [
                                    "Ajustar MA em dados não-estacionários",
                                    "Sobreajuste de q alto"
                                  ]
                                }
                              ],
                              "practicalExample": "Estime um modelo MA(1) para retornos diários do índice S&P500 (2000-2020). Use MLE para obter θ ≈ -0.15, σ² ≈ 0.0004, e compare com GMM que dá θ ≈ -0.14 com std err similar. Verifique que resíduos são white noise.",
                              "finalVerifications": [
                                "Função de log-verossimilhança implementada corretamente e maximizada numericamente.",
                                "Parâmetros θ estimados dentro de bounds de invertibilidade (|θ| < 1).",
                                "Comparação quantitativa MLE vs. GMM (tabelas de coefs, std errs, AIC).",
                                "Diagnósticos de resíduos passam em testes padrão.",
                                "Recuperação consistente de θ verdadeiro em simulações Monte Carlo.",
                                "Previsões out-of-sample razoáveis vs. benchmark naive."
                              ],
                              "assessmentCriteria": [
                                "Precisão da implementação da verossimilhança (erro < 1% em simulação).",
                                "Correta convergência da otimização (critério de parada < 1e-6).",
                                "Análise comparativa MLE-GMM com métricas estatísticas.",
                                "Qualidade dos diagnósticos residuais (plots e testes).",
                                "Interpretação econômica dos resultados.",
                                "Código limpo, reprodutível e comentado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência assintótica e testes de hipóteses.",
                                "Programação: Otimização numérica e manipulação de séries temporais.",
                                "Economia: Modelagem de volatilidade e previsão macroeconômica.",
                                "Matemática: Cálculo multivariável e álgebra linear (hessianas)."
                              ],
                              "realWorldApplication": "Em finanças, estimar MA(q) para modelar dependências de curto prazo em retornos de ativos, auxiliando em Value-at-Risk (VaR) e estratégias de trading de alta frequência; em macroeconomia, para residuals de modelos maiores como ARIMA em previsão de inflação ou desemprego."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.2.1.3",
                        "name": "Componente Integrado e Diferenciação (I(d))",
                        "description": "Processo para tornar séries não estacionárias em estacionárias por diferenciação, essencial para lidar com tendências e não-estacionariedade em dados de engenharia e econometria.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.1.3.1",
                            "name": "Identificar não-estacionariedade e aplicar diferenciação",
                            "description": "Usar testes como Dickey-Fuller para detectar unidade raiz, aplicar operador de diferença Δ e determinar ordem d necessária para estacionariedade em séries temporais univariadas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender conceitos de estacionariedade e não-estacionariedade",
                                  "subSteps": [
                                    "Defina estacionariedade: média, variância e covariância constantes ao longo do tempo.",
                                    "Identifique características de séries não-estacionárias: tendência, sazonalidade ou unidade raiz.",
                                    "Estude o impacto da não-estacionariedade em modelos como ARIMA.",
                                    "Revise exemplos gráficos de séries estacionárias vs. não-estacionárias.",
                                    "Discuta a necessidade de diferenciação para induzir estacionariedade."
                                  ],
                                  "verification": "Resuma em suas palavras os conceitos e identifique corretamente exemplos gráficos fornecidos.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Livro 'Forecasting: Principles and Practice' (Hyndman), gráficos de séries temporais exemplo, notebook Jupyter.",
                                  "tips": "Use plots ACF/PACF para visualizar dependências.",
                                  "learningObjective": "Entender os fundamentos teóricos da estacionariedade em séries temporais.",
                                  "commonMistakes": "Confundir variância crescente com tendência linear."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar teste de Dickey-Fuller Aumentado (ADF)",
                                  "subSteps": [
                                    "Carregue dados de uma série temporal univariada (ex: preços de ações).",
                                    "Instale e importe statsmodels em Python: from statsmodels.tsa.stattools import adfuller.",
                                    "Execute o teste ADF: result = adfuller(série).",
                                    "Interprete resultados: p-value, estatística do teste e valores críticos.",
                                    "Compare p-value com nível de significância (ex: 0.05)."
                                  ],
                                  "verification": "Gere relatório do teste ADF mostrando p-value >0.05 indicando não-estacionariedade.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python com statsmodels, pandas; dataset exemplo (ex: AirPassengers do R ou dados de PIB).",
                                  "tips": "Inclua lags automáticos com 'auto_lag=True' para melhor precisão.",
                                  "learningObjective": "Aplicar e interpretar teste estatístico para detectar unidade raiz.",
                                  "commonMistakes": "Ignorar lags ou não verificar resíduos do teste."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar operador de diferença Δ",
                                  "subSteps": [
                                    "Calcule a primeira diferença: diff_serie = série.diff().dropna().",
                                    "Plote a série original e diferenciada para inspeção visual.",
                                    "Reaplique o teste ADF na série diferenciada.",
                                    "Registre mudanças na estatística e p-value.",
                                    "Documente o processo em um notebook com comentários."
                                  ],
                                  "verification": "A série diferenciada apresenta p-value <0.05 no teste ADF.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python com pandas e matplotlib; mesmo dataset do passo anterior.",
                                  "tips": "Use diff(1) para primeira ordem; verifique over-differencing por variância negativa em ACF.",
                                  "learningObjective": "Implementar diferenciação prática para remover não-estacionariedade.",
                                  "commonMistakes": "Não remover NaN após diff() ou diferenciar excessivamente."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Determinar ordem de integração d e validar estacionariedade",
                                  "subSteps": [
                                    "Aplique diferenças sucessivas (2ª, 3ª ordem se necessário) até p-value <0.05.",
                                    "Use critério de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) como teste complementar.",
                                    "Identifique ordem d mínima onde ambos testes confirmam estacionariedade.",
                                    "Plote ACF/PACF da série final para confirmar ausência de unidade raiz.",
                                    "Salve relatório com ordem d recomendada."
                                  ],
                                  "verification": "Relatório final com ordem d, plots e resultados de testes confirmando estacionariedade.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python com statsmodels (kpss); datasets variados para prática.",
                                  "tips": "Pare na menor d possível para evitar perda de informação.",
                                  "learningObjective": "Estabelecer ordem d ótima para componente I(d) em ARIMA.",
                                  "commonMistakes": "Usar apenas ADF sem KPSS, levando a under/over-differencing."
                                }
                              ],
                              "practicalExample": "Analise a série temporal mensal de passageiros aéreos (AirPassengers dataset). Aplique ADF (p>0.05), diferencie uma vez (p<0.05), confirme d=1 com plots ACF e prepare para ARIMA(p,1,q).",
                              "finalVerifications": [
                                "Teste ADF na série final tem p-value <0.05.",
                                "KPSS confirma estacionariedade (p>0.05).",
                                "ACF/PACF não mostram decay lento típico de não-estacionariedade.",
                                "Ordem d documentada com justificativa.",
                                "Notebook reproduzível com código e plots.",
                                "Relatório resume processo e conclusões."
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de testes estatísticos (p-values e críticas).",
                                "Correta aplicação e iteração de diferenciações.",
                                "Qualidade visual dos plots (clareza e labels).",
                                "Identificação correta de ordem d mínima.",
                                "Documentação completa e reproduzível.",
                                "Uso de testes complementares (ADF + KPSS).",
                                "Ausência de erros comuns como over-differencing."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial (testes de hipóteses).",
                                "Programação em Python/R (statsmodels, forecast).",
                                "Econometria (modelos de séries temporais).",
                                "Machine Learning (pré-processamento de features temporais).",
                                "Economia (análise de ciclos econômicos)."
                              ],
                              "realWorldApplication": "Em finanças para modelar retornos de ações estacionários antes de ARIMA; em meteorologia para prever temperaturas removendo tendências; em controle de qualidade industrial para detectar padrões em sensores não-estacionários."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.3.2",
                            "name": "Explicar propriedades de processos integrados I(d)",
                            "description": "Descrever o comportamento de ACF e PACF em séries I(1), efeitos da diferenciação na variância e autocorrelações, com exemplos em análise de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de processos integrados I(d)",
                                  "subSteps": [
                                    "Defina processo estacionário (média e variância constantes) versus não estacionário.",
                                    "Explique I(0) como processo estacionário, I(1) como random walk com drift ou sem.",
                                    "Descreva a generalização para I(d), onde d é a ordem de integração.",
                                    "Discuta a implicação de raiz unitária no polinômio característico.",
                                    "Compare com processos ARMA estacionários."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre I(0) e I(1), com um exemplo simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro 'Análise de Séries Temporais' (Hamilton ou Brockwell), notebook Jupyter com Python/R.",
                                  "tips": "Visualize graficamente um random walk para intuitar a não-estacionariedade.",
                                  "learningObjective": "Dominar definições e propriedades básicas de I(d).",
                                  "commonMistakes": "Confundir I(1) com tendência determinística (linear) em vez de estocástica."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar o comportamento de ACF e PACF em séries I(1)",
                                  "subSteps": [
                                    "Gere ou carregue uma série I(1) simulada (ex: random walk).",
                                    "Plote a série temporal e observe a tendência não estacionária.",
                                    "Calcule e plote ACF: observe decaimento muito lento (aprox. linear).",
                                    "Calcule e plote PACF: observe persistência ou decaimento lento similar.",
                                    "Interprete: ACF alta por muitos lags indica integração."
                                  ],
                                  "verification": "Gere plots de ACF/PACF e identifique corretamente o padrão de I(1).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (statsmodels, matplotlib) ou R (forecast package), dados simulados.",
                                  "tips": "Use lags até 50 para ver o decaimento lento claramente.",
                                  "learningObjective": "Identificar visualmente não-estacionariedade via ACF/PACF.",
                                  "commonMistakes": "Interpretar ACF lenta como AR de alta ordem em vez de integração."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Examinar efeitos da diferenciação na variância e autocorrelações",
                                  "subSteps": [
                                    "Aplique diferenciação de primeira ordem (Δy_t = y_t - y_{t-1}) à série I(1).",
                                    "Plote a série diferenciada e verifique estacionariedade (ADF test).",
                                    "Compare variâncias: variância da diff é constante (ruído branco se RW puro).",
                                    "Plote ACF/PACF da diferenciada: ACF corta após lag 0 se white noise.",
                                    "Discuta como d=1 remove a integração, estabilizando variância e correlações."
                                  ],
                                  "verification": "Mostre plots antes/depois e explique mudanças quantitativamente (ex: var(diff) << var(original)).",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Mesmo ambiente de programação, função adfuller() do statsmodels.",
                                  "tips": "Sempre teste estacionariedade com KPSS ou ADF após diff.",
                                  "learningObjective": "Entender transformação para estacionariedade via diferenciação.",
                                  "commonMistakes": "Sobrediferenciar (d>1 desnecessário), criando variância invertível."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar conceitos em dados reais de engenharia",
                                  "subSteps": [
                                    "Carregue dados de engenharia (ex: consumo de energia horária).",
                                    "Analise ACF/PACF original para suspeita de I(1).",
                                    "Aplique diferenciação e reanalise ACF/PACF/variância.",
                                    "Documente mudanças e interprete no contexto de ARIMA(p,1,q).",
                                    "Simule cenários com drift para engenharia (ex: carga crescente)."
                                  ],
                                  "verification": "Produza relatório com plots e conclusões sobre ordem d.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Dataset público (ex: UCI Energy Consumption), Python/R.",
                                  "tips": "Use log-transform antes se variância crescente.",
                                  "learningObjective": "Integrar teoria em análise prática de dados reais.",
                                  "commonMistakes": "Ignorar sazonalidade, confundindo com integração."
                                }
                              ],
                              "practicalExample": "Em dados de consumo de energia elétrica de uma usina (série horária), a ACF original decai lentamente indicando I(1); após diferenciação, ACF corta em lag 0, variância estabiliza, permitindo modelagem ARMA na diff para previsão de picos de demanda.",
                              "finalVerifications": [
                                "Identifica corretamente ACF lenta em I(1) vs corte rápido em estacionário.",
                                "Explica efeito da diff na variância (estabiliza) e autocorrelações (remove persistência).",
                                "Aplica ADF test para confirmar d=1.",
                                "Gera plots comparativos antes/depois diff.",
                                "Interpreta resultados em contexto ARIMA.",
                                "Distingue I(1) de tendência determinística."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição de ACF/PACF para I(1) (decaimento lento).",
                                "Correta análise de efeitos da diferenciação (estacionariedade alcançada).",
                                "Uso apropriado de testes e plots em exemplos.",
                                "Explicações claras com fórmulas (ex: y_t = y_{t-1} + ε_t).",
                                "Aplicação coerente em dados de engenharia.",
                                "Ausência de confusões comuns (ex: AR alta ordem)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de raiz unitária (Dickey-Fuller).",
                                "Programação: Manipulação de séries em Python/R (pandas, statsmodels).",
                                "Engenharia: Análise de sinais em controle de processos industriais.",
                                "Econometria: Modelos de previsão econômica semelhantes."
                              ],
                              "realWorldApplication": "Em engenharia, analisar séries de sensores IoT (ex: vibração de turbinas) para detectar não-estacionariedade I(1), diferenciar e modelar ARIMA para prever falhas ou otimizar manutenção preditiva, reduzindo downtime em plantas industriais."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.2.1.4",
                        "name": "Modelo ARIMA(p,d,q): Identificação, Estimação, Diagnóstico e Previsão",
                        "description": "Modelo completo ARIMA combinando AR(p), I(d) e MA(q), seguindo a metodologia Box-Jenkins para modelagem e previsão de séries temporais univariadas em contextos econométricos.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.2.1.4.1",
                            "name": "Identificar ordens p, d, q usando ACF e PACF",
                            "description": "Aplicar critérios de identificação Box-Jenkins: analisar gráficos ACF/PACF da série diferenciada para selecionar p, q, e validar com critérios como AIC/BIC.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Avaliar estacionariedade da série temporal e determinar a ordem de diferenciação d",
                                  "subSteps": [
                                    "Colete e carregue os dados da série temporal em um ambiente computacional (ex: Python com pandas).",
                                    "Plote a série original e verifique visualmente por tendências ou sazonalidade.",
                                    "Aplique teste de estacionariedade como Augmented Dickey-Fuller (ADF) na série original.",
                                    "Se não estacionária (p-value > 0.05), aplique diferenciação de primeira ordem (diff(1)) e re-teste ADF.",
                                    "Repita diferenciações até que a série seja estacionária (geralmente d=0,1 ou 2)."
                                  ],
                                  "verification": "Teste ADF na série diferenciada resulta em p-value < 0.05 e gráficos mostram ausência de tendência.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python: pandas, statsmodels.tsa.stattools.adfuller, matplotlib",
                                    "Ou R: tseries::adf.test"
                                  ],
                                  "tips": "Comece sempre com d=1 para séries com tendência; evite overdifferencing que cria não-estacionariedade invertível.",
                                  "learningObjective": "Compreender e aplicar critérios de estacionariedade para determinar d no modelo ARIMA.",
                                  "commonMistakes": [
                                    "Ignorar testes formais e confiar só em plots visuais.",
                                    "Aplicar diferenciação excessiva levando a séries com raízes unitárias invertíveis."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar e visualizar gráficos ACF e PACF da série diferenciada",
                                  "subSteps": [
                                    "Ajuste a série para a ordem d determinada (ex: dados.diff(d).dropna()).",
                                    "Gere o gráfico de autocorrelação (ACF) usando função apropriada (ex: plot_acf em statsmodels).",
                                    "Gere o gráfico de autocorrelação parcial (PACF) da mesma forma.",
                                    "Configure lags significativos (ex: até 20 lags) e inclua bandas de confiança de 95%.",
                                    "Salve ou exiba os gráficos lado a lado para comparação fácil."
                                  ],
                                  "verification": "Gráficos ACF e PACF são plotados corretamente sem erros e mostram decays claros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python: statsmodels.graphics.tsaplots.plot_acf, plot_pacf",
                                    "Ou R: acf(), pacf()"
                                  ],
                                  "tips": "Use lags = min(10*len(dados)^{1/4}, 20) para número adequado de lags.",
                                  "learningObjective": "Produzir visualizações padrão ACF/PACF para análise de dependências temporais.",
                                  "commonMistakes": [
                                    "Não remover NaNs após diferenciação, causando erros nos plots.",
                                    "Escolher poucos lags, perdendo padrões em maiores delays."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar ACF para identificar ordem q (MA) e PACF para p (AR)",
                                  "subSteps": [
                                    "No ACF: Conte spikes significativos além das bandas até o primeiro lag insignificante (isso sugere q).",
                                    "No PACF: Conte spikes significativos até o primeiro insignificante (sugere p).",
                                    "Identifique padrões: ACF decay exponencial/sinusoidal sugere AR(p); PACF cortado sugere MA(q).",
                                    "Registre candidatos: ex: se ACF significativo em lag 1-2, q=2; PACF em lag 3, p=3.",
                                    "Anote observações qualitativas como 'decay lento' ou 'oscilações'."
                                  ],
                                  "verification": "Ordens p e q provisórias anotadas com justificativa baseada em lags significativos.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Gráficos ACF/PACF gerados no step anterior",
                                    "Papel/caneta ou notebook para anotações"
                                  ],
                                  "tips": "Spikes que tocam as bandas são marginais; priorize os que as excedem claramente.",
                                  "learningObjective": "Aplicar regras Box-Jenkins para leitura direta de p e q a partir de ACF/PACF.",
                                  "commonMistakes": [
                                    "Confundir ACF com PACF (ACF para MA, PACF para AR).",
                                    "Contar todos os spikes sem considerar o 'corte' após o primeiro insignificante."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar ordens candidatas com critérios AIC/BIC",
                                  "subSteps": [
                                    "Ajuste modelos ARIMA(p,d,q) candidatos usando função fit() (ex: statsmodels SARIMAX).",
                                    "Calcule AIC e BIC para cada modelo (menor valor indica melhor ajuste).",
                                    "Compare 3-5 modelos próximos (ex: ARIMA(1,1,1), (2,1,1), etc.).",
                                    "Selecione o modelo com menor AIC/BIC, garantindo resíduos brancos (Ljung-Box test).",
                                    "Documente a tabela de comparação com p,d,q, AIC e BIC."
                                  ],
                                  "verification": "Modelo final selecionado com menor AIC/BIC e resíduos não-autocorrelacionados (p>0.05 em Ljung-Box).",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Python: statsmodels.tsa.arima.model.ARIMA",
                                    "Ou R: arima() com auto.arima para referência"
                                  ],
                                  "tips": "Use grid search simples para candidatos próximos; evite overfitting com BIC mais penalizador.",
                                  "learningObjective": "Integrar análise gráfica com critérios de informação para identificação robusta.",
                                  "commonMistakes": [
                                    "Ajustar só um modelo sem comparação.",
                                    "Ignorar validação de resíduos, aceitando modelo com autocorrelação residual."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Documentar e verificar o modelo ARIMA(p,d,q) identificado",
                                  "subSteps": [
                                    "Resuma: 'Modelo ARIMA(p=X,d=Y,q=Z) identificado por ACF lag q, PACF lag p, AIC=valor'.",
                                    "Plote resíduos e faça teste Ljung-Box para independência.",
                                    "Gere previsões de 1-5 passos à frente e compare com hold-out se disponível.",
                                    "Salve relatório com gráficos, tabela AIC e conclusões.",
                                    "Autoavalie se p+q <=5 para parsimônia."
                                  ],
                                  "verification": "Relatório completo com evidências gráficas e numéricas confirma identificação correta.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Funções de plot de resíduos e forecast do statsmodels/R"
                                  ],
                                  "tips": "Sempre valide com dados out-of-sample se possível para robustez.",
                                  "learningObjective": "Consolidar processo Box-Jenkins completo com documentação profissional.",
                                  "commonMistakes": [
                                    "Pular verificação de resíduos.",
                                    "Selecionar modelo não-parsimonioso sem justificativa."
                                  ]
                                }
                              ],
                              "practicalExample": "Analise a série temporal mensal de passageiros aéreos (airpassengers dataset no R ou statsmodels). Determine d=1 por tendência, observe ACF decay sinusoidal (q=1?), PACF spike lag1 (p=1), valide ARIMA(1,1,1) com AIC baixo e resíduos brancos.",
                              "finalVerifications": [
                                "Série diferenciada é estacionária (ADF p<0.05).",
                                "ACF/PACF mostram padrões claros com lags significativos corretamente contados.",
                                "Modelo ARIMA(p,d,q) tem menor AIC/BIC entre candidatos.",
                                "Resíduos passam Ljung-Box (p>0.05).",
                                "Previsões iniciais plausíveis e sem bias.",
                                "Documentação inclui gráficos e tabela de comparação.",
                                "p+q <=5 para modelo parsimonioso."
                              ],
                              "assessmentCriteria": [
                                "Precisão na determinação de d via testes e plots (30%).",
                                "Interpretação correta de ACF para q e PACF para p (25%).",
                                "Seleção baseada em AIC/BIC com pelo menos 3 modelos comparados (20%).",
                                "Validação de resíduos e estacionariedade (15%).",
                                "Relatório claro e completo com evidências (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses (ADF, Ljung-Box).",
                                "Programação: Manipulação de dados em Python/R (pandas, dplyr).",
                                "Econometria: Modelagem de séries financeiras.",
                                "Machine Learning: Feature engineering temporal e validação de modelos."
                              ],
                              "realWorldApplication": "Em finanças, identificar ARIMA(1,1,0) em retornos diários de ações para previsões de risco; em supply chain, modelar demanda sazonal de produtos para otimizar estoque e reduzir custos em 10-20%."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.4.2",
                            "name": "Estimar e diagnosticar modelo ARIMA",
                            "description": "Estimar parâmetros via máxima verossimilhança, verificar resíduos com testes Ljung-Box para autocorrelação e normalidade, ajustando modelo se necessário.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar e Estimar Parâmetros do Modelo ARIMA via Máxima Verossimilhança",
                                  "subSteps": [
                                    "Selecionar ordens p, d, q baseadas em ACF/PACF ou critérios como AIC/BIC.",
                                    "Carregar biblioteca (ex: statsmodels em Python) e preparar série temporal estacionária.",
                                    "Ajustar o modelo ARIMA usando método de máxima verossimilhança (MLE).",
                                    "Verificar convergência do otimizador e extrair coeficientes estimados.",
                                    "Calcular log-likelihood e critérios de informação (AIC, BIC)."
                                  ],
                                  "verification": "Coeficientes estimados são finitos e o modelo reporta convergência bem-sucedida.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com statsmodels",
                                    "Dados de série temporal (ex: AirPassengers dataset)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use método='css-mle' para inicialização robusta; monitore warnings de não-convergência.",
                                  "learningObjective": "Compreender e aplicar estimação MLE para modelos ARIMA.",
                                  "commonMistakes": [
                                    "Escolha errada de p,d,q levando a não-estacionariedade",
                                    "Ignorar differencing insuficiente",
                                    "Não checar warnings de otimização"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Extrair e Inspecionar Resíduos do Modelo",
                                  "subSteps": [
                                    "Obter resíduos padronizados do modelo ajustado (model.resid).",
                                    "Plotar resíduos no tempo, histograma e Q-Q plot para inspeção visual.",
                                    "Calcular estatísticas descritivas: média, variância, skewness e kurtosis.",
                                    "Verificar se resíduos têm média zero e variância constante.",
                                    "Identificar outliers ou padrões visuais suspeitos."
                                  ],
                                  "verification": "Resíduos plotados mostram ausência de padrões sistemáticos e média próxima de zero.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels ou equivalente em R (forecast)",
                                    "Gráficos via matplotlib/seaborn"
                                  ],
                                  "tips": "Padronize resíduos dividindo por desvio padrão para melhor visualização.",
                                  "learningObjective": "Extrair e realizar inspeção inicial de resíduos para diagnóstico.",
                                  "commonMistakes": [
                                    "Confundir resíduos com fitted values",
                                    "Não padronizar resíduos",
                                    "Ignorar heteroscedasticidade visual"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Testar Autocorrelação dos Resíduos com Ljung-Box",
                                  "subSteps": [
                                    "Aplicar teste Ljung-Box em múltiplos lags (ex: lags=10,20).",
                                    "Interpretar p-value: >0.05 indica ausência de autocorrelação serial.",
                                    "Plotar ACF dos resíduos para lags até 20 e checar bandas de confiança.",
                                    "Comparar com resultados do teste estatístico.",
                                    "Documentar lags significativos se p-value <0.05."
                                  ],
                                  "verification": "P-value do Ljung-Box >0.05 para lags relevantes.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Função statsmodels.stats.diagnostic.acorr_ljungbox",
                                    "Dados de resíduos"
                                  ],
                                  "tips": "Teste múltiplos lags; foque em lags > ordem do modelo.",
                                  "learningObjective": "Aplicar e interpretar teste Ljung-Box para resíduos brancos.",
                                  "commonMistakes": [
                                    "Usar lags muito baixos",
                                    "Confundir com teste de normalidade",
                                    "Ignorar múltiplos lags"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar Normalidade dos Resíduos",
                                  "subSteps": [
                                    "Aplicar teste Jarque-Bera para normalidade (JB test).",
                                    "Usar Q-Q plot e histograma para validação visual.",
                                    "Calcular skewness e kurtosis; ideal: skewness~0, kurtosis~3.",
                                    "Interpretar p-value JB: >0.05 suporta normalidade.",
                                    "Se falhar, considerar transformações ou modelos alternativos."
                                  ],
                                  "verification": "P-value Jarque-Bera >0.05 e Q-Q plot linear.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "statsmodels.stats.stattools.jarque_bera",
                                    "scipy.stats.probplot"
                                  ],
                                  "tips": "Normalidade é assunção aproximada; foque em resíduos brancos primeiro.",
                                  "learningObjective": "Avaliar normalidade dos resíduos e suas implicações.",
                                  "commonMistakes": [
                                    "Exigir normalidade perfeita (não essencial para grandes amostras)",
                                    "Confundir com estacionariedade",
                                    "Não plotar Q-Q"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Diagnosticar Problemas e Ajustar o Modelo ARIMA",
                                  "subSteps": [
                                    "Resumir resultados de testes: listar falhas (autocorr, normalidade).",
                                    "Se autocorr presente: aumentar p/q ou revisar d.",
                                    "Se não-normal: aplicar Box-Cox ou modelo ARIMA com erros não-normais (GARCH).",
                                    "Reestimar modelo ajustado e repetir diagnósticos.",
                                    "Comparar AIC/BIC entre modelos originais e ajustados."
                                  ],
                                  "verification": "Todos testes passam ou melhorias documentadas com AIC reduzido.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Iterações no código de estimação",
                                    "Critérios AIC/BIC"
                                  ],
                                  "tips": "Mantenha parsimônia: evite overfitting com ordens altas.",
                                  "learningObjective": "Iterativamente diagnosticar e refinar modelo ARIMA.",
                                  "commonMistakes": [
                                    "Ajustes excessivos sem validação out-of-sample",
                                    "Ignorar custo computacional",
                                    "Não documentar iterações"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados de passageiros aéreos (AirPassengers), estime ARIMA(2,1,2), verifique resíduos com Ljung-Box (p>0.05) e Jarque-Bera, ajuste para ARIMA(1,1,1) se necessário, confirmando resíduos brancos.",
                              "finalVerifications": [
                                "Modelo convergeu sem warnings.",
                                "Ljung-Box p-value >0.05 para lags 10-20.",
                                "Jarque-Bera p-value >0.05.",
                                "Resíduos sem padrões em plots ACF/Q-Q.",
                                "AIC/BIC melhor ou similar ao modelo baseline.",
                                "Previsões iniciais estáveis."
                              ],
                              "assessmentCriteria": [
                                "Parâmetros estimados via MLE com SE razoáveis.",
                                "Interpretação correta de p-values em testes.",
                                "Ajustes lógicos baseados em diagnósticos.",
                                "Código reproduzível e comentado.",
                                "Documentação de iterações e decisões.",
                                "Uso apropriado de visualizações."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e testes de hipóteses.",
                                "Programação: Manipulação de dados em Python/R.",
                                "Economia/Finanças: Previsão de séries temporais econômicas.",
                                "Machine Learning: Modelos lineares vs. não-lineares.",
                                "Matemática: Otimização e máxima verossimilhança."
                              ],
                              "realWorldApplication": "Em finanças, diagnosticar ARIMA para prever retornos de ações, garantindo resíduos brancos para previsões confiáveis de risco; em supply chain, ajustar modelos para demanda sazonal de produtos."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.2.1.4.3",
                            "name": "Realizar previsões com ARIMA",
                            "description": "Gerar previsões pontuais e intervalos de confiança para h passos à frente, interpretando resultados em aplicações de engenharia como previsão de demandas ou falhas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o modelo ARIMA ajustado e definir horizonte de previsão",
                                  "subSteps": [
                                    "Carregue a série temporal usando pandas.read_csv ou similar",
                                    "Confirme que o modelo ARIMA(p,d,q) foi ajustado previamente com fit()",
                                    "Defina o horizonte h (ex: h=12 para 12 meses à frente)",
                                    "Verifique resíduos e diagnósticos do modelo com plot_diagnostics()",
                                    "Salve o modelo fitted em uma variável para uso"
                                  ],
                                  "verification": "Modelo ARIMA ajustado está pronto e h definido; execute model.summary() sem erros",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python 3.x",
                                    "Bibliotecas: pandas, statsmodels, matplotlib",
                                    "Dataset de série temporal (ex: dados_mensais.csv)"
                                  ],
                                  "tips": [
                                    "Use o melhor (p,d,q) de análises ACF/PACF anteriores",
                                    "Garanta que a série está estacionária pós-diferenciação"
                                  ],
                                  "learningObjective": "Configurar corretamente um modelo ARIMA pronto para gerar previsões",
                                  "commonMistakes": [
                                    "Esquecer de chamar fit()",
                                    "Definir h muito grande sem suporte computacional",
                                    "Ignorar verificação de estacionariedade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar previsões pontuais para h steps à frente",
                                  "subSteps": [
                                    "Use o método forecast(steps=h) no modelo fitted",
                                    "Armazene as previsões em um array ou Series do pandas",
                                    "Crie um índice de tempo para as previsões (ex: pd.date_range)",
                                    "Plote a série original + previsões pontuais com matplotlib",
                                    "Salve as previsões em um DataFrame para análise"
                                  ],
                                  "verification": "Previsões pontuais geradas e plotadas corretamente; valores numéricos coerentes com tendência histórica",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com statsmodels e matplotlib",
                                    "Modelo ARIMA do step 1"
                                  ],
                                  "tips": [
                                    "forecast() assume condições atuais persistem",
                                    "Combine com plot da série original para visual inspeção"
                                  ],
                                  "learningObjective": "Produzir previsões pontuais precisas usando ARIMA",
                                  "commonMistakes": [
                                    "Usar predict() em vez de forecast()",
                                    "Índice de tempo desalinhado",
                                    "Não plotar para validação visual"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e visualizar intervalos de confiança",
                                  "subSteps": [
                                    "Use get_forecast(steps=h) para obter objeto com intervalos",
                                    "Extraia conf_int com alpha=0.05 para 95% IC",
                                    "Plote a série + previsões pontuais + bandas de confiança",
                                    "Calcule largura média dos intervalos para avaliar incerteza",
                                    "Compare com previsões pontuais para identificar regiões de alta variância"
                                  ],
                                  "verification": "Intervalos de confiança plotados; largura aumenta com h, como esperado",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "statsmodels (get_forecast)",
                                    "matplotlib para plotting"
                                  ],
                                  "tips": [
                                    "IC mais largos no horizonte distante refletem maior incerteza",
                                    "Ajuste alpha para diferentes níveis de confiança"
                                  ],
                                  "learningObjective": "Incorporar incerteza nas previsões via intervalos de confiança ARIMA",
                                  "commonMistakes": [
                                    "Confundir forecast() com get_forecast()",
                                    "Plot incorreto das bandas",
                                    "Ignorar expansão dos ICs"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados no contexto de engenharia",
                                  "subSteps": [
                                    "Analise tendência, sazonalidade e incerteza nas previsões",
                                    "Compare com benchmarks ou dados reais se disponíveis",
                                    "Discuta implicações (ex: demanda excederá capacidade em mês X?)",
                                    "Gere relatório com previsões, ICs e recomendações",
                                    "Valide com métricas como MAE em hold-out set"
                                  ],
                                  "verification": "Relatório escrito com interpretação coerente e acionável",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Previsões e ICs dos steps anteriores",
                                    "Ferramenta de relatório (Jupyter Notebook ou Word)"
                                  ],
                                  "tips": [
                                    "Foque em decisões: 'Com 95% confiança, falhas aumentarão 20%'",
                                    "Considere cenários otimista/pessimista dos ICs"
                                  ],
                                  "learningObjective": "Traduzir previsões ARIMA em insights práticos para engenharia",
                                  "commonMistakes": [
                                    "Interpretação literal sem contexto",
                                    "Ignorar ICs na tomada de decisão",
                                    "Falta de métricas de validação"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados históricos de demanda mensal de energia elétrica (em MWh) de uma usina, ajuste um ARIMA(1,1,1), gere previsões para 12 meses à frente e intervalos de 95% IC. Interprete: 'Demanda média prevista de 1500 MWh/mês, com risco de pico acima de 1800 MWh em julho devido a sazonalidade.'",
                              "finalVerifications": [
                                "Previsões pontuais e ICs gerados sem erros computacionais",
                                "Plots mostram coerência com histórico e expansão de incerteza",
                                "Interpretação inclui implicações práticas para engenharia",
                                "Métricas de validação (ex: RMSE em teste) abaixo de threshold",
                                "Relatório completo com código reproduzível",
                                "Horizonte h variado testado (ex: 6 e 12 steps)"
                              ],
                              "assessmentCriteria": [
                                "Precisão das previsões pontuais (MAE < 10% do histórico)",
                                "Correta implementação de ICs com expansão progressiva",
                                "Qualidade visual dos plots (legendas, escalas adequadas)",
                                "Profundidade da interpretação contextualizada",
                                "Eficiência computacional e código limpo",
                                "Capacidade de lidar com diferentes horizontes h"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência e intervalos de confiança",
                                "Programação: Manipulação de dados em Python/R com statsmodels",
                                "Engenharia Industrial: Previsão de demanda e planejamento",
                                "Machine Learning: Modelos univariados vs. multivariados",
                                "Gestão de Riscos: Uso de ICs para cenários probabilísticos"
                              ],
                              "realWorldApplication": "Em engenharia, previsões ARIMA com ICs são usadas para antecipar demandas de produção (ex: estoque em fábricas), prever falhas em turbinas eólicas (manutenção preditiva) ou fluxos de tráfego em sistemas de transporte, permitindo alocação otimizada de recursos e redução de custos operacionais em até 20%."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.3",
                    "name": "Cointegração",
                    "description": "Conceito de cointegração entre séries temporais não estacionárias e testes para sua detecção.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.3.1",
                        "name": "Conceito de Cointegração",
                        "description": "Definição de cointegração como uma relação de longo prazo entre séries temporais não estacionárias integradas de mesma ordem, onde uma combinação linear delas resulta em uma série estacionária.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.3.1.1",
                            "name": "Identificar séries temporais integradas de ordem 1 (I(1))",
                            "description": "Diferenciar séries estacionárias de não estacionárias e aplicar testes de raiz unitária (como Dickey-Fuller) para confirmar integração de ordem 1, essencial para cointegração.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Estacionariedade e Integração",
                                  "subSteps": [
                                    "Defina estacionariedade: média, variância e covariância constantes ao longo do tempo.",
                                    "Identifique características de séries não estacionárias: tendência, sazonalidade ou raiz unitária.",
                                    "Explique integração de ordem d (I(d)): série que requer d diferenças para se tornar estacionária.",
                                    "Diferencie I(0) (estacionária) de I(1) (não estacionária, mas primeira diferença é I(0)).",
                                    "Estude exemplos gráficos de séries I(1), como caminhada aleatória."
                                  ],
                                  "verification": "Crie um diagrama comparando gráficos de série I(0) e I(1), explicando diferenças.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Livro 'Time Series Analysis' de Hamilton (cap. 2)",
                                    "Vídeos Khan Academy sobre estacionariedade",
                                    "Notebook Jupyter para plots"
                                  ],
                                  "tips": "Use plots ACF/PACF para visualizar não-estacionariedade rapidamente.",
                                  "learningObjective": "Distinguir conceitualmente séries estacionárias de integradas de ordem 1.",
                                  "commonMistakes": [
                                    "Confundir tendência determinística com estocástica",
                                    "Ignorar testes formais e confiar só em gráficos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender Testes de Raiz Unitária, Foco em Dickey-Fuller",
                                  "subSteps": [
                                    "Entenda a hipótese nula do teste ADF: presença de raiz unitária (não estacionária).",
                                    "Estude a estatística do teste ADF e valores críticos (1%, 5%, 10%).",
                                    "Aprenda variações: ADF com drift e tendência.",
                                    "Compare ADF com Phillips-Perron (PP) test para robustez.",
                                    "Pratique interpretação: p-value > 0.05 rejeita estacionariedade."
                                  ],
                                  "verification": "Resuma em tabela: Hipóteses, estatística e decisão para ADF em I(1).",
                                  "estimatedTime": "2 hours",
                                  "materials": [
                                    "Documentação statsmodels Python (ADF)",
                                    "Paper original Dickey-Fuller (1981)",
                                    "Simulador online de séries temporais"
                                  ],
                                  "tips": "Sempre inclua lags ótimos via AIC/BIC para evitar autocorrelação.",
                                  "learningObjective": "Dominar o teste Augmented Dickey-Fuller (ADF) para detectar I(1).",
                                  "commonMistakes": [
                                    "Não selecionar lags corretos levando a tamanho distorcido",
                                    "Confundir rejeição da nula com confirmação de I(1) sem diferenciar"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Teste ADF em Dados Reais",
                                  "subSteps": [
                                    "Carregue dados de série temporal (ex: preços diários de ações via yfinance).",
                                    "Aplique adfuller() do statsmodels em Python.",
                                    "Teste a série original e sua primeira diferença.",
                                    "Registre p-values, estatísticas e gráficos de resíduos.",
                                    "Repita com R usando ur.df() para validação."
                                  ],
                                  "verification": "Execute código e produza relatório com outputs ADF para nível e diferenças.",
                                  "estimatedTime": "2.5 hours",
                                  "materials": [
                                    "Python: pandas, statsmodels, yfinance",
                                    "R: urca package",
                                    "Dataset: GSPC (S&P500) de 2000-2023"
                                  ],
                                  "tips": "Use log-retornos para volatilidade; teste tamanho amostral >100.",
                                  "learningObjective": "Aplicar computacionalmente testes para identificar I(1).",
                                  "commonMistakes": [
                                    "Usar dados com breaks estruturais sem pré-teste",
                                    "Ignorar não-estacionariedade sazonal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Confirmar I(1)",
                                  "subSteps": [
                                    "Confirme I(1): ADF rejeita nula no nível, mas não nas primeiras diferenças.",
                                    "Avalie robustez com múltiplos testes (KPSS complementar).",
                                    "Discuta implicações para modelagem: evitar espúrios regressões.",
                                    "Crie fluxograma de decisão: I(0), I(1) ou I(2).",
                                    "Documente conclusão com evidências quantitativas."
                                  ],
                                  "verification": "Analise dataset exemplo e classifique como I(1) com justificativa escrita.",
                                  "estimatedTime": "1.5 hours",
                                  "materials": [
                                    "Planilha Excel para tabela de resultados",
                                    "Artigo sobre cointegração (Engle-Granger)"
                                  ],
                                  "tips": "Combine ADF com KPSS: ADF para raiz unitária, KPSS para estacionariedade.",
                                  "learningObjective": "Interpretar testes para validar séries I(1) preparadas para cointegração.",
                                  "commonMistakes": [
                                    "Parar em um teste só",
                                    "Concluir I(1) sem testar diferenças"
                                  ]
                                }
                              ],
                              "practicalExample": "Baixe dados diários do S&P500 (GSPC) de 2010-2023 via yfinance. Aplique ADF: p-value ~0.8 no nível (não estacionária), p-value <0.01 na primeira diferença (estacionária) → confirme I(1). Plote série e diferenças para visualização.",
                              "finalVerifications": [
                                "Explica diferença entre I(0), I(1) e I(2) com exemplo.",
                                "Executa ADF corretamente em novo dataset e interpreta p-value.",
                                "Identifica erro em output ADF falso (ex: lags errados).",
                                "Cria fluxograma para testar ordem de integração.",
                                "Discute por que I(1) é pré-requisito para cointegração.",
                                "Aplica teste em 2 séries diferentes com conclusões corretas."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: 90% acerto em definições chave.",
                                "Implementação código: Sem erros, lags ótimos selecionados.",
                                "Interpretação: Correta distinção I(1) vs outros, com p-values.",
                                "Robustez: Uso de múltiplos testes e visualizações.",
                                "Documentação: Relatório claro com tabelas/gráficos.",
                                "Aplicação: Classifica corretamente 3 datasets reais."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Pré-requisito para modelos VAR/VECM.",
                                "Programação: Manipulação de dados em Python/R (pandas, dplyr).",
                                "Finanças: Análise de preços de ativos para trading algorítmico.",
                                "Estatística: Inferência em processos estocásticos.",
                                "Machine Learning: Feature engineering para séries temporais em forecasting."
                              ],
                              "realWorldApplication": "Em finanças, identificar I(1) em preços de ações permite testar cointegração para pairs trading (ex: comprar Coca-Cola e vender Pepsi se cointegrados), evitando regressões espúrias e melhorando previsões econômicas como PIB ou inflação."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.3.1.2",
                            "name": "Explicar a relação de cointegração entre múltiplas séries",
                            "description": "Descrever como duas ou mais séries I(1) são cointegradas se existe um vetor de cointegração β tal que y_t - β x_t é estacionário, representando equilíbrio de longo prazo.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Conceitos Básicos de Estacionariedade e Processos I(1)",
                                  "subSteps": [
                                    "Defina estacionariedade: média, variância e covariância constantes ao longo do tempo.",
                                    "Explique processos I(0) (estacionários) versus I(1) (integrados de ordem 1, com raiz unitária).",
                                    "Discuta testes de estacionariedade como Dickey-Fuller.",
                                    "Ilustre com gráficos de séries aleatórias caminhadas versus ruído branco.",
                                    "Diferencie divergência de séries I(1) sem relação de longo prazo."
                                  ],
                                  "verification": "Crie gráficos de uma série I(0) e I(1); aplique teste ADF e interprete p-valor >0.05 para I(1).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Software R ou Python (pacotes forecast ou statsmodels)",
                                    "Dados de exemplo: série randômica caminhada gerada via código"
                                  ],
                                  "tips": "Sempre plote as séries primeiro para visualização intuitiva da tendência.",
                                  "learningObjective": "Compreender por que séries I(1) não estacionárias precisam de modelagem especial para relações de longo prazo.",
                                  "commonMistakes": [
                                    "Confundir não-estacionariedade com tendência determinística; ignorar testes formais de unidade raiz."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir Cointegração para Duas Séries Temporais",
                                  "subSteps": [
                                    "Defina cointegração: duas séries y_t e x_t I(1) são cointegradas se existe β ≠ 0 tal que z_t = y_t - β x_t ~ I(0).",
                                    "Explique que β é o vetor de cointegração, capturando a relação de equilíbrio.",
                                    "Derive intuitivamente: desvios z_t revertem à média, apesar de tendências comuns.",
                                    "Teste conceitual: regredir Δy_t em Δx_t e resíduo deve ser estacionário.",
                                    "Implemente teste Engle-Granger em código."
                                  ],
                                  "verification": "Aplique Engle-Granger a duas séries simuladas cointegradas; confirme resíduo ADF estacionário.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python (statsmodels.tsa.stattools.coint)",
                                    "Dados simulados: y_t = x_t + erro estacionário, com x_t ~ RW"
                                  ],
                                  "tips": "Escolha β próximo de 1 para simulações iniciais para clareza visual.",
                                  "learningObjective": "Identificar quando duas séries não estacionárias compartilham equilíbrio de longo prazo.",
                                  "commonMistakes": [
                                    "Assumir cointegração sem testar resíduo; confundir com correlação espúria."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Generalizar para Múltiplas Séries e Vetor de Cointegração",
                                  "subSteps": [
                                    "Estenda para vetor Y_t = [y1_t, ..., yn_t] I(1): cointegradas rank r se existe matriz β (n x r, rank r) tal que β' Y_t ~ I(0).",
                                    "Explique espaço de cointegração: combinações lineares estacionárias.",
                                    "Discuta Johansen test para rank r e estimação de β.",
                                    "Interprete: r < n implica r relações de equilíbrio entre n séries.",
                                    "Simule exemplo com 3 séries: duas cointegradas e uma independente."
                                  ],
                                  "verification": "Execute Johansen test em dados simulados multivariados; identifique rank r=1 corretamente.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "R (urca package) ou Python (statsmodels.tsa.vector_ar.vecm)",
                                    "Dados VECM simulados"
                                  ],
                                  "tips": "Comece com n=3 e r=1 para evitar complexidade matricial excessiva.",
                                  "learningObjective": "Generalizar o conceito bivariado para sistemas multivariados de séries temporais.",
                                  "commonMistakes": [
                                    "Confundir rank de cointegração com número de séries; ignorar pressupostos de VECM."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Cointegração como Equilíbrio de Longo Prazo",
                                  "subSteps": [
                                    "Descreva z_t = β' Y_t como erro de equilíbrio que mean-reverte.",
                                    "Relacione com Error Correction Model (ECM): ajusta velocidades de correção.",
                                    "Discuta implicações econômicas: forças de arbitragem restauram equilíbrio.",
                                    "Compare com VAR sem restrições: cointegração impõe estrutura de longo prazo.",
                                    "Crie narrativa: 'preços divergem curto prazo, mas convergem longo prazo'."
                                  ],
                                  "verification": "Escreva equação ECM para exemplo bivariado e interprete coeficiente de correção (-0.1 significa 10% correção por período).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Notas teóricas de Johansen (1995)",
                                    "Exemplo de dados econômicos: PIB e consumo"
                                  ],
                                  "tips": "Use analogia de 'cão e coleira': séries I(1) como cães, z_t como folga da coleira.",
                                  "learningObjective": "Articular o significado econômico da cointegração além da definição matemática.",
                                  "commonMistakes": [
                                    "Interpretar β como elasticidade de curto prazo; negligenciar mean-reversão em z_t."
                                  ]
                                }
                              ],
                              "practicalExample": "Considere preços de ações da Pepsi (y_t) e Coca-Cola (x_t), ambos I(1). Estime β ≈1 via Engle-Granger; resíduo z_t = y_t - β x_t é estacionário, indicando que spreads de preços revertem, permitindo estratégias de pairs trading.",
                              "finalVerifications": [
                                "Explique corretamente definição para 2 e >2 séries.",
                                "Simule e teste cointegração bivariada/multivariada com código.",
                                "Interprete β como parâmetro de equilíbrio de longo prazo.",
                                "Distinga cointegração de correlação espúria.",
                                "Aplique Johansen test e identifique rank r.",
                                "Descreva ECM e papel do termo de correção de erro."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição matemática de vetor β e estacionariedade de β' Y_t (70%).",
                                "Capacidade de simular/testar exemplos computacionais (20%).",
                                "Clareza na interpretação econômica de equilíbrio (10%).",
                                "Uso correto de testes (ADF, Engle-Granger, Johansen).",
                                "Identificação de erros comuns como confusão com estacionariedade.",
                                "Conexão com aplicações reais como finanças."
                              ],
                              "crossCurricularConnections": [
                                "Economia: Modelagem de equilíbrio macroeconômico (ex: paridade de poder de compra).",
                                "Finanças: Estratégias de trading cointegrado e risco de mercado.",
                                "Estatística: Análise multivariada e testes de hipótese em VECM.",
                                "Machine Learning: Feature engineering com resíduos cointegrados para previsão."
                              ],
                              "realWorldApplication": "Em finanças quantitativas, detectar cointegração entre ativos permite pairs trading: comprar o subvalorizado e vender o supervalorizado, lucrando com convergência ao equilíbrio de longo prazo, como em fundos de hedge que gerenciam bilhões em estratégias mean-reverting."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.3.1.3",
                            "name": "Interpretar implicações econômicas da cointegração em engenharia",
                            "description": "Aplicar o conceito para analisar relações de longo prazo em dados de engenharia, como consumo de energia e produção industrial, evitando espúrios regressões.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Cointegração e Regressões Espúrias",
                                  "subSteps": [
                                    "Defina cointegração como uma relação de equilíbrio de longo prazo entre séries não estacionárias.",
                                    "Explique regressões espúrias: correlações falsas devido a tendências comuns sem relação real.",
                                    "Compare séries I(1) individuais vs. co-integradas, usando gráficos de caminhadas aleatórias.",
                                    "Estude o teorema de Granger Representation para implicações dinâmicas.",
                                    "Identifique exemplos em engenharia: consumo de energia e produção industrial."
                                  ],
                                  "verification": "Crie um diagrama explicando cointegração vs. espúria e compartilhe com um par para feedback.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Análise de Séries Temporais' de Hamilton (cap. 19)",
                                    "Software R ou Python com pacotes urca ou statsmodels",
                                    "Datasets de exemplo do FRED (energia e produção)"
                                  ],
                                  "tips": "Use animações de séries temporais para visualizar divergências e convergências.",
                                  "learningObjective": "Compreender a distinção conceitual entre cointegração real e regressões espúrias em contextos econômicos de engenharia.",
                                  "commonMistakes": [
                                    "Confundir estacionariedade com cointegração",
                                    "Ignorar testes de raiz unitária prévios",
                                    "Assumir causalidade sem evidência"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aprender Testes de Cointegração Aplicados a Dados de Engenharia",
                                  "subSteps": [
                                    "Realize teste ADF/KPSS em séries individuais (ex: log(energia) e log(produção)).",
                                    "Aplique teste Engle-Granger de dois passos: regressão residual e ADF nos resíduos.",
                                    "Implemente teste Johansen para múltiplas séries, interpretando autovalores e estatísticas traço.",
                                    "Use software para replicar: carregue dados, execute testes e interprete p-valores.",
                                    "Discuta robustez: lags, determinísticos e tamanho amostral em dados de engenharia."
                                  ],
                                  "verification": "Execute testes em um dataset real e documente resultados em um relatório curto (evidência de cointegração ou não).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python: statsmodels.tsa.stattools.coint",
                                    "R: urca::ca.jo",
                                    "Dataset FRED: Industrial Production Index e Energy Consumption"
                                  ],
                                  "tips": "Sempre teste estacionariedade primeiro; ajuste lags com AIC/BIC para precisão.",
                                  "learningObjective": "Dominar testes empíricos para detectar cointegração em pares de séries temporais de engenharia.",
                                  "commonMistakes": [
                                    "Pular testes unit root",
                                    "Ignorar termos determinísticos",
                                    "Interpretar rejeição como ausência de relação econômica"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar Resultados no Contexto Econômico de Engenharia",
                                  "subSteps": [
                                    "Analise resíduos estacionários como desvios do equilíbrio de longo prazo.",
                                    "Estime vetor de cointegração (β) e interprete: elasticidade entre energia e produção.",
                                    "Discuta implicações: previsibilidade de longo prazo, modelagem ECM para correções de erro.",
                                    "Avalie impactos econômicos: eficiência energética, políticas industriais baseadas em relações estáveis.",
                                    "Compare com cenários sem cointegração: risco de políticas baseadas em espúrias."
                                  ],
                                  "verification": "Escreva uma interpretação de 200 palavras de resultados de teste, ligando a implicações econômicas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Artigos: 'Cointegration and Error Correction' de Engle-Granger",
                                    "Gráficos de resíduos e ECM",
                                    "Ferramentas Jupyter Notebook"
                                  ],
                                  "tips": "Foque em β econômico: '1% aumento produção implica X% em energia'.",
                                  "learningObjective": "Traduzir resultados estatísticos de cointegração em insights econômicos acionáveis para engenharia.",
                                  "commonMistakes": [
                                    "Sobrepor causalidade a cointegração",
                                    "Ignorar direção do equilíbrio",
                                    "Generalizar resultados sem contexto setorial"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Avaliar Implicações em um Caso de Estudo",
                                  "subSteps": [
                                    "Selecione dataset engenharia: consumo energia vs. produção industrial (1980-2020).",
                                    "Execute análise completa: testes, estimação, ECM e forecast.",
                                    "Interprete: relação estável implica planejamento energético sustentável?",
                                    "Simule cenários: choque em produção e retorno ao equilíbrio.",
                                    "Documente limitações: breaks estruturais em dados de engenharia."
                                  ],
                                  "verification": "Produza um dashboard ou relatório com gráficos, testes e conclusões econômicas.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Datasets: EIA.gov energia, BLS produção",
                                    "Tableau/Public ou Plotly para visualização",
                                    "Código replicável no GitHub"
                                  ],
                                  "tips": "Use forecasts de ECM para demonstrar utilidade preditiva econômica.",
                                  "learningObjective": "Integrar análise de cointegração a decisões econômicas reais em projetos de engenharia.",
                                  "commonMistakes": [
                                    "Usar amostras pequenas",
                                    "Não validar out-of-sample",
                                    "Desconsiderar multicolinearidade em múltiplas séries"
                                  ]
                                }
                              ],
                              "practicalExample": "Analise dados mensais de consumo de eletricidade industrial (kWh) e índice de produção manufatureira (1985-2023). Teste cointegração revela β=0.75: 1% aumento produção eleva energia em 0.75%. Implicação: planejar expansão energética alinhada à produção para evitar déficits, evitando políticas baseadas em correlações espúrias.",
                              "finalVerifications": [
                                "Explicar verbalmente cointegração vs. espúria com exemplo engenharia.",
                                "Executar teste Engle-Granger em novo dataset e interpretar p-valor.",
                                "Estimar ECM e prever desvio de equilíbrio após choque.",
                                "Identificar 3 implicações econômicas de resultados co-integrados.",
                                "Criticar uma regressão espúria hipotética em contexto energia-produção.",
                                "Discutir limitações em dados reais de engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: distinção clara cointegração/espúria (30%)",
                                "Proficiência técnica: testes corretos e interpretação estatística (25%)",
                                "Relevância econômica: ligações acionáveis a engenharia (20%)",
                                "Qualidade análise: uso de dados reais, visualizações e robustez (15%)",
                                "Clareza comunicação: relatório/diagramaas concisos e profissionais (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Economia: Modelos de equilíbrio de longo prazo e políticas energéticas.",
                                "Engenharia Industrial: Otimização de sistemas energia-produção.",
                                "Estatística: Análise multivariada e testes de hipótese avançados.",
                                "Finanças: Pares trading e risco sistêmico em commodities.",
                                "Ciência de Dados: Previsão em séries não estacionárias."
                              ],
                              "realWorldApplication": "Em empresas de engenharia como Siemens ou GE, usar cointegração para modelar demanda energética ligada à produção fabril, otimizando investimentos em infraestrutura sustentável e evitando super/sub-capacidade baseados em tendências falsas, impactando bilhões em eficiência operacional."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.3.2",
                        "name": "Teste de Engle-Granger para Cointegração",
                        "description": "Procedimento em dois passos para testar cointegração bivariada: regressão OLS residual e teste de estacionariedade nos resíduos.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.3.2.1",
                            "name": "Executar o primeiro passo: regressão OLS entre séries",
                            "description": "Realizar regressão linear por mínimos quadrados ordinários entre duas séries I(1) para obter resíduos, considerando pressupostos relaxados para grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e carregar as séries temporais I(1)",
                                  "subSteps": [
                                    "Selecionar duas séries temporais não estacionárias I(1), como log-preços de ações ou PIB e consumo.",
                                    "Carregar os dados em um ambiente computacional (ex: Python com pandas).",
                                    "Verificar dimensões, remover valores ausentes e alinhar índices temporais.",
                                    "Plotar as séries para visual inspeção de tendência comum.",
                                    "Confirmar que ambas são I(1) via teste ADF (opcional, mas recomendado)."
                                  ],
                                  "verification": "Série carregada sem NaNs, plots mostram tendências semelhantes e ADF rejeita estacionariedade em níveis.",
                                  "estimatedTime": "15-20 minutos",
                                  "materials": "Python (pandas, matplotlib, statsmodels), dataset exemplo (ex: dados de ações AAPL e MSFT).",
                                  "tips": "Use pd.read_csv() com parse_dates para índices temporais precisos.",
                                  "learningObjective": "Dominar carregamento e pré-processamento de séries temporais para análise de cointegração.",
                                  "commonMistakes": "Ignorar desalinhamento de datas ou não tratar NaNs, levando a erros na regressão."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar o modelo de regressão linear OLS",
                                  "subSteps": [
                                    "Definir o modelo: y_t = α + β x_t + ε_t, onde y e x são as séries I(1).",
                                    "Separar variáveis endógena (y) e exógena (x).",
                                    "Configurar fórmula ou matriz de design (X com intercepto).",
                                    "Importar biblioteca OLS (statsmodels.api.OLS).",
                                    "Preparar arrays endog (y) e exog (X com sm.add_constant(x))."
                                  ],
                                  "verification": "Modelo especificado com intercepto incluído e arrays sem erros de shape.",
                                  "estimatedTime": "10-15 minutos",
                                  "materials": "Biblioteca statsmodels, Jupyter Notebook.",
                                  "tips": "Sempre inclua constante com sm.add_constant para evitar omitted variable bias.",
                                  "learningObjective": "Entender a formulação matemática do modelo OLS para cointegração de Engle-Granger.",
                                  "commonMistakes": "Esquecer o intercepto α, invalidando o teste posterior."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar o modelo OLS e obter resíduos",
                                  "subSteps": [
                                    "Instanciar e ajustar o modelo: model = sm.OLS(endog, exog).fit().",
                                    "Extrair coeficientes β e α via model.params.",
                                    "Calcular resíduos: resid = model.resid.",
                                    "Plotar resíduos e fitted values para inspeção visual.",
                                    "Salvar resíduos em uma série para o próximo passo do teste."
                                  ],
                                  "verification": "Modelo ajustado com R-squared > 0.5 típico, resíduos salvos como série pandas.",
                                  "estimatedTime": "10 minutos",
                                  "materials": "statsmodels instalado, dados preparados do step 1.",
                                  "tips": "Use model.summary() para relatório completo de diagnósticos iniciais.",
                                  "learningObjective": "Executar estimação OLS computacionalmente e isolar resíduos estacionários potenciais.",
                                  "commonMistakes": "Confundir endog/exog, resultando em regressão invertida."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar suposições relaxadas para grandes amostras",
                                  "subSteps": [
                                    "Verificar ausência de autocorrelação serial nos resíduos (Durbin-Watson via model).",
                                    "Testar normalidade aproximada (Jarque-Bera ou QQ-plot).",
                                    "Confirmar heteroscedasticidade leve (plot resid vs fitted).",
                                    "Notar que para T grande (>100), suposições clássicas são relaxadas no contexto de cointegração.",
                                    "Documentar métricas para relatório."
                                  ],
                                  "verification": "Diagnósticos mostram violações mínimas; resíduos plausíveis para teste ADF no step 2 do Engle-Granger.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "statsmodels (diagnósticos integrados), scipy para testes adicionais.",
                                  "tips": "Foco em superconsistência de OLS para cointegração, não em suposições estritas.",
                                  "learningObjective": "Aplicar critérios relaxados de validade OLS em séries não estacionárias.",
                                  "commonMistakes": "Aplicar testes rigorosos como em regressões estacionárias, desnecessário aqui."
                                }
                              ],
                              "practicalExample": "Usando dados mensais de log-retornos cumulativos de ações AAPL (y) e MSFT (x) de 2010-2023 em Python: carregar via yfinance, ajustar OLS(y ~ x), obter resid = model.resid, plotar para ver resíduos estacionários.",
                              "finalVerifications": [
                                "Resíduos extraídos corretamente sem NaNs.",
                                "Coeficientes β e α estimados e interpretáveis.",
                                "Plots de séries, fitted e resíduos gerados.",
                                "Diagnósticos básicos (DW, JB) documentados.",
                                "Resíduos prontos para teste ADF de estacionariedade.",
                                "Código reproduzível em notebook."
                              ],
                              "assessmentCriteria": [
                                "Correção na especificação e estimação OLS (80% peso).",
                                "Qualidade dos resíduos e diagnósticos (15%).",
                                "Clareza em plots e documentação (5%).",
                                "Eficiência computacional e tratamento de dados.",
                                "Compreensão verbal dos pressupostos relaxados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em regressão linear.",
                                "Econometria: Modelos de séries temporais não estacionárias.",
                                "Programação: Manipulação de dados em Python/pandas.",
                                "Finanças: Análise de pares cointegrados para trading."
                              ],
                              "realWorldApplication": "Em finanças, executar OLS entre preços de ações cointegradas (ex: pares trading) para detectar desvios mean-reverting nos resíduos, sinalizando oportunidades de arbitragem; em macroeconomia, testar cointegração entre PIB e consumo para modelagem de equilíbrio de longo prazo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.2.2",
                            "name": "Aplicar teste de raiz unitária nos resíduos",
                            "description": "Usar teste ADF (Dickey-Fuller Aumentado) com constante nos resíduos da regressão para rejeitar ou não a hipótese nula de não cointegração.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os resíduos da regressão para o teste ADF",
                                  "subSteps": [
                                    "Extraia os resíduos (ê) da regressão OLS entre as séries Y e X: Y_t = α + β X_t + ê_t",
                                    "Verifique se os resíduos formam uma série temporal estacionária em nível",
                                    "Garanta que não haja valores ausentes (NaN) nos resíduos",
                                    "Defina a série de resíduos como um objeto de série temporal no software utilizado",
                                    "Plote os resíduos para inspeção visual inicial"
                                  ],
                                  "verification": "Resíduos extraídos corretamente e plotados sem erros; comprimento da série igual ao das originais",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Biblioteca statsmodels (Python) ou urca (R)",
                                    "Dados de séries temporais Y e X",
                                    "Jupyter Notebook ou RStudio"
                                  ],
                                  "tips": "Use np residuals do OLSResults em Python para eficiência",
                                  "learningObjective": "Compreender a origem dos resíduos como proxy para relação de longo prazo",
                                  "commonMistakes": [
                                    "Incluir constante na regressão de resíduos",
                                    "Ignorar lags nas séries originais",
                                    "Não tratar missing values"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Configurar e executar o teste ADF com constante nos resíduos",
                                  "subSteps": [
                                    "Especifique o teste ADF com opção de constante (c ou 'c' em statsmodels)",
                                    "Defina o número máximo de lags (ex: 'auto' ou AIC-based)",
                                    "Execute a função adfuller(resíduos, regression='c', autolag='AIC')",
                                    "Capture saídas: estatística ADF, p-value, valores críticos",
                                    "Registre o número de observações usadas no teste"
                                  ],
                                  "verification": "Função ADF executada sem erros; p-value e estatística ADF obtidos",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "statsmodels.tsa.stattools.adfuller (Python)",
                                    "Dados de resíduos preparados"
                                  ],
                                  "tips": "Sempre use regression='c' para incluir intercepto, simulando drift",
                                  "learningObjective": "Executar teste de raiz unitária com especificação correta para resíduos",
                                  "commonMistakes": [
                                    "Omitir constante (usar 'n' em vez de 'c')",
                                    "Escolher lags fixos sem critério",
                                    "Confundir com teste sem constante"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar os resultados do teste ADF",
                                  "subSteps": [
                                    "Compare a estatística ADF com valores críticos (1%, 5%, 10%)",
                                    "Verifique se p-value < 0.05 para rejeitar H0 (raiz unitária)",
                                    "Calcule e interprete o número de lags selecionados",
                                    "Gere resumo dos resultados em tabela ou print",
                                    "Plote os resíduos e ACF/PACF para suporte visual"
                                  ],
                                  "verification": "Tabela de resultados gerada com comparações claras; interpretação inicial documentada",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "statsmodels output",
                                    "Matplotlib ou ggplot para plots"
                                  ],
                                  "tips": "p-value é o mais intuitivo; rejeição se estatística < crítico",
                                  "learningObjective": "Interpretar evidências estatísticas de estacionariedade nos resíduos",
                                  "commonMistakes": [
                                    "Rejeitar H0 se p>0.05",
                                    "Ignorar valores críticos específicos",
                                    "Confundir H0 com estacionariedade"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Concluir sobre cointegração e validar o teste",
                                  "subSteps": [
                                    "Se rejeitar H0 nos resíduos, conclua cointegração (relação de equilíbrio)",
                                    "Caso contrário, não há evidência de cointegração pelo Engle-Granger",
                                    "Teste robustez variando lags ou tamanho de amostra",
                                    "Documente conclusão com justificativa estatística",
                                    "Compare com teste Johansen se aplicável para validação"
                                  ],
                                  "verification": "Conclusão explícita sobre H0 de não-cointegração; relatório escrito",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Resultados ADF",
                                    "Notebook para documentação"
                                  ],
                                  "tips": "Cointegração só se resíduos estacionários; Engle-Granger é de dois passos",
                                  "learningObjective": "Ligar resultados do ADF à hipótese de cointegração",
                                  "commonMistakes": [
                                    "Concluir cointegração sem rejeição",
                                    "Ignorar power baixo em amostras pequenas",
                                    "Não mencionar limitações do teste"
                                  ]
                                }
                              ],
                              "practicalExample": "Em Python com statsmodels: Regressão OLS entre log(PIB) e log(Consumo) trimestrais (1980-2020). Resíduos ê_t = log(PIB_t) - (α + β log(Consumo_t)). ADF(ê, regression='c'): se p-value=0.01 <0.05 e estatística=-4.2 < -3.45 (5%), rejeite H0 → cointegração confirmada.",
                              "finalVerifications": [
                                "Resíduos extraídos corretamente da regressão estática",
                                "Teste ADF executado com constante e lags automáticos",
                                "p-value e estatística comparados adequadamente aos críticos",
                                "Conclusão sobre cointegração alinhada aos resultados",
                                "Código reproduzível e plots incluídos",
                                "Limitações do teste (ex: univariado) mencionadas"
                              ],
                              "assessmentCriteria": [
                                "Correção na especificação do ADF (constante incluída)",
                                "Interpretação precisa de p-value e valores críticos",
                                "Uso apropriado de lags e critérios de seleção",
                                "Conclusão lógica sobre hipótese de não-cointegração",
                                "Clareza no relatório com evidências numéricas",
                                "Tratamento de dados sem erros (NaN, alinhamento)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e estacionariedade",
                                "Econometria: Modelos de cointegração e ECM",
                                "Programação: Manipulação de séries temporais em Python/R",
                                "Finanças: Análise de pares cointegrados para trading",
                                "Matemática: Processos estocásticos e integração"
                              ],
                              "realWorldApplication": "Em finanças, testar cointegração entre preços de ações (ex: Coca-Cola e Pepsi) para estratégias de pairs trading mean-reverting; em macroeconomia, verificar equilíbrio de longo prazo entre PIB e inflação para previsões políticas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.2.3",
                            "name": "Interpretar resultados e limitações do teste",
                            "description": "Analisar estatísticas do teste, valores críticos e discutir problemas como assimetria em regressões cointegrantes e normalização.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Examinar a Estatística do Teste ADF nos Resíduos",
                                  "subSteps": [
                                    "Execute o teste ADF (Augmented Dickey-Fuller) nos resíduos da regressão de longo prazo entre as séries temporais.",
                                    "Identifique a estatística do teste (t-statistic) gerada pelo teste.",
                                    "Registre o valor p-value associado à estatística.",
                                    "Anote o número de lags utilizados no teste ADF.",
                                    "Compare a estatística com os valores críticos fornecidos para diferentes níveis de significância (1%, 5%, 10%)."
                                  ],
                                  "verification": "Confirme que a saída do teste ADF mostra estatística, p-value e valores críticos claramente anotados em um relatório ou notebook.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Software de análise (Python com statsmodels, R com urca)",
                                    "Dados de séries temporais cointegradas (ex: preços de ações)",
                                    "Documentação do teste Engle-Granger"
                                  ],
                                  "tips": "Sempre inclua lags suficientes para tornar os resíduos estacionários; use critério AIC/BIC para seleção automática.",
                                  "learningObjective": "Compreender e extrair componentes chave da saída do teste ADF nos resíduos.",
                                  "commonMistakes": [
                                    "Ignorar a seleção de lags, levando a estatísticas enviesadas",
                                    "Confundir estatística ADF com p-value sem contexto de significância"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar a Hipótese Nula e Decidir sobre Cointegração",
                                  "subSteps": [
                                    "Lembre-se da H0: resíduos não estacionários (não há cointegração).",
                                    "Compare a estatística ADF com valores críticos: se mais negativa que o crítico, rejeite H0 (evidência de cointegração).",
                                    "Avalie o p-value: <0.05 indica rejeição de H0 em 5% de significância.",
                                    "Considere o tamanho da amostra: testes são assimétricos em amostras pequenas.",
                                    "Documente a decisão: 'Cointegração confirmada' ou 'Não há evidência'."
                                  ],
                                  "verification": "Escreva uma declaração clara de aceitação/rejeição da H0 com justificativa baseada em estatística vs. críticos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Tabelas de valores críticos MacKinnon",
                                    "Notebook Jupyter ou R script com output do teste"
                                  ],
                                  "tips": "Use tabelas MacKinnon para valores críticos exatos em vez de aproximados.",
                                  "learningObjective": "Aplicar regras de decisão para inferir presença de cointegração dos resultados.",
                                  "commonMistakes": [
                                    "Rejeitar H0 baseado apenas em p-value sem comparar com críticos",
                                    "Ignorar direção da estatística (deve ser mais negativa)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Limitações e Problemas Comuns",
                                  "subSteps": [
                                    "Discuta assimetria na regressão cointegrante: OLS pode super-rejeitar H0 devido a endogeneidade.",
                                    "Aborde normalização: escolha arbitrária da variável dependente afeta inferência.",
                                    "Avalie poder do teste: fraco em amostras finitas ou com desvios de tendência.",
                                    "Considere alternativas: teste Johansen para múltiplas séries.",
                                    "Liste impactos: falsos positivos em regressões assimétricas ou normalização inadequada."
                                  ],
                                  "verification": "Crie uma lista de 3-5 limitações específicas identificadas no contexto do teste realizado.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Artigos originais Engle-Granger (1987)",
                                    "Livro 'Analysis of Integrated and Cointegrated Time Series' de Johansen"
                                  ],
                                  "tips": "Sempre normalize com a primeira série como dependente para consistência.",
                                  "learningObjective": "Identificar e explicar limitações teóricas e práticas do teste Engle-Granger.",
                                  "commonMistakes": [
                                    "Subestimar assimetria, tratando regressão como simétrica",
                                    "Ignorar necessidade de normalização padronizada"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar Interpretação Completa e Implicações",
                                  "subSteps": [
                                    "Resuma resultados: presença/ausência de cointegração e força da evidência.",
                                    "Integre limitações na interpretação final (ex: 'Cointegração sugerida, mas cautela com assimetria').",
                                    "Discuta implicações para modelagem: use VECM se cointegrado.",
                                    "Valide com gráficos: plote resíduos e teste estacionariedade visualmente.",
                                    "Prepare relatório com todas as evidências e ressalvas."
                                  ],
                                  "verification": "Gere um relatório de 1 página resumindo interpretação, decisão e limitações.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Ferramentas de visualização (Matplotlib, ggplot2)",
                                    "Templates de relatório em LaTeX ou Markdown"
                                  ],
                                  "tips": "Inclua gráficos de resíduos para suporte visual à interpretação.",
                                  "learningObjective": "Produzir uma interpretação holística que equilibre resultados e limitações.",
                                  "commonMistakes": [
                                    "Focar só em resultados positivos, ignorando limitações",
                                    "Não conectar a decisões de modelagem subsequentes"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados de preços diários de Coca-Cola e Pepsi (1980-2000): Regressão y = Pepsi ~ Coca-Cola gera resíduos; teste ADF nos resíduos dá t-stat = -4.2 (crítico 5% = -3.37), rejeitando H0. Limitação: assimetria detectada por teste de Phillips-Ouliaris leva a super-rejeição; normalize invertendo variáveis para confirmação.",
                              "finalVerifications": [
                                "Pode extrair e explicar estatística ADF, p-value e valores críticos corretamente.",
                                "Decide corretamente sobre cointegração em 3 exemplos variados.",
                                "Lista pelo menos 4 limitações específicas do teste Engle-Granger.",
                                "Interpreta resultados considerando assimetria e normalização.",
                                "Produz relatório sintetizado com gráficos e implicações.",
                                "Distingue Engle-Granger de Johansen em contextos apropriados."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e comparação de estatísticas (30%)",
                                "Profundidade na discussão de limitações como assimetria e normalização (25%)",
                                "Clareza na decisão de cointegração com justificativa (20%)",
                                "Uso de exemplos práticos e visualizações (15%)",
                                "Síntese holística em relatório (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Aplicação em modelagem VAR/VECM",
                                "Estatística: Testes de estacionariedade e unit root",
                                "Finanças: Pares trading e hedging com cointegration",
                                "Programação: Implementação em Python/R para análise de dados",
                                "Economia: Análise de equilíbrio de longo prazo em séries macroeconômicas"
                              ],
                              "realWorldApplication": "Em finanças quantitativas, traders usam interpretação de testes Engle-Granger para identificar pares cointegrados de ações (ex: Coke vs Pepsi), criando estratégias de mean-reversion que lucram com desvios temporários do equilíbrio de longo prazo, evitando riscos de não-estacionariedade."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.2.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.3.3",
                        "name": "Teste de Johansen e Modelos Vetor Corretor de Erros (VEC)",
                        "description": "Testes multivariados para cointegração e modelagem de ajuste de curto prazo via VEC, baseados em VAR.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.3.3.1",
                            "name": "Construir modelo VAR para séries multivariadas",
                            "description": "Estimar um modelo autoregressivo vetorial (VAR) em níveis para séries I(1) e testar ordem de defasagem via critérios AIC ou BIC.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e validar os dados multivariados como séries I(1)",
                                  "subSteps": [
                                    "Carregar os dados multivariados em um DataFrame usando pandas.",
                                    "Verificar estacionariedade individual das séries com teste ADF para confirmar I(1).",
                                    "Diferenciar as séries uma vez se necessário e confirmar I(0) nos diferenciais.",
                                    "Alinhar datas e remover valores ausentes.",
                                    "Visualizar séries com plots para detectar tendências e correlações."
                                  ],
                                  "verification": "Todas as séries passam no teste ADF em níveis (não estacionárias) e nos diferenciais (estacionárias); gráficos mostram comportamento I(1).",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python (pandas, statsmodels.tsa.stattools), dados de exemplo (ex: PIB e inflação trimestrais).",
                                  "tips": "Use freq='Q' para trimestrais ao criar DateTimeIndex para melhor indexação.",
                                  "learningObjective": "Entender e validar propriedades I(1) em séries multivariadas para VAR.",
                                  "commonMistakes": "Ignorar missing values ou não diferenciar corretamente, levando a pseudorregressão."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Selecionar a ordem ótima de defasagem usando AIC e BIC",
                                  "subSteps": [
                                    "Instalar e importar statsmodels.tsa.vector_ar.var_model.VAR.",
                                    "Definir modelo VAR provisional com maxlags=10 ou 12.",
                                    "Calcular critérios de informação: VAR.select_order(maxlags=12).summary().",
                                    "Comparar AIC e BIC para escolher lag order mínima com menor critério.",
                                    "Documentar valores de AIC/BIC para diferentes lags em tabela."
                                  ],
                                  "verification": "Tabela com AIC/BIC mostra lag order selecionada (ex: p=2 com menor AIC).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (statsmodels.tsa.vector_ar), Jupyter Notebook.",
                                  "tips": "Prefira BIC para parcimônia em amostras pequenas; AIC para previsão.",
                                  "learningObjective": "Aplicar critérios de informação para evitar sobreparametrização no VAR.",
                                  "commonMistakes": "Escolher lag muito alto sem critérios, causando perda de graus de liberdade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimar o modelo VAR em níveis com a ordem selecionada",
                                  "subSteps": [
                                    "Instanciar VAR(data).fit(lag_order_selecionada).",
                                    "Exibir summary() para coeficientes, t-stats e matriz de covariância de resíduos.",
                                    "Verificar raízes características com model.roots para estabilidade.",
                                    "Plotar resíduos com model.plot_forecast ou acf/pacf manual.",
                                    "Salvar modelo em variável para próximos passos."
                                  ],
                                  "verification": "Modelo estimado sem erros; raízes dentro do círculo unitário (estável).",
                                  "estimatedTime": "1 hora",
                                  "materials": "statsmodels.tsa.vector_ar.var_model.VAR, dados preparados.",
                                  "tips": "Use trend='c' para constante se séries têm drift.",
                                  "learningObjective": "Estimar e interpretar coeficientes de um VAR multivariado em níveis.",
                                  "commonMistakes": "Especificar lags errados ou ignorar estabilidade (raízes >1)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Diagnosticar o modelo e validar pressupostos",
                                  "subSteps": [
                                    "Testar autocorrelação de resíduos com model.test_normality() e Ljung-Box.",
                                    "Verificar normalidade com Jarque-Bera via model.test_normality().",
                                    "Testar heteroscedasticidade e estabilidade com testes adicionais.",
                                    "Analisar Impulse Response Functions (IRF) com model.irf().plot().",
                                    "Ajustar se necessário (ex: aumentar lags) e reestimar."
                                  ],
                                  "verification": "Resíduos sem autocorrelação (p>0.05 em Ljung-Box); normalidade aceitável.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "statsmodels, matplotlib para plots de IRF e resíduos.",
                                  "tips": "IRF ajudam a ver respostas dinâmicas; plote com orth=False para não ortogonalizar.",
                                  "learningObjective": "Diagnosticar violações em VAR para garantir inferência válida.",
                                  "commonMistakes": "Aceitar modelo sem checar resíduos, levando a conclusões enviesadas."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e preparar para cointegration",
                                  "subSteps": [
                                    "Interpretar coeficientes de lags como dinâmicas de curto prazo.",
                                    "Analisar Variance Decomposition via model.fevd().",
                                    "Gerar previsões com model.forecast(steps=8).",
                                    "Documentar Granger causality tests com model.test_causality().",
                                    "Preparar output para teste de Johansen no próximo módulo."
                                  ],
                                  "verification": "Relatório com interpretações, plots de IRF/FEVD e previsões plausíveis.",
                                  "estimatedTime": "1 hora",
                                  "materials": "statsmodels para fevd, forecast, causality.",
                                  "tips": "Granger testa se uma variável 'causa' outra; use para hipóteses econômicas.",
                                  "learningObjective": "Extrair insights econômicos de um VAR e conectar a VEC.",
                                  "commonMistakes": "Interpretar coeficientes como causais sem Granger ou controles."
                                }
                              ],
                              "practicalExample": "Usando dados trimestrais de PIB real e taxa de juros do Brasil (2000-2023): confirme I(1), selecione p=2 via AIC, estime VAR(2), diagnostique resíduos brancos e plote IRF mostrando como choque em juros afeta PIB em 4 trimestres.",
                              "finalVerifications": [
                                "Modelo VAR estável com raízes características dentro do círculo unitário.",
                                "Ordem de lag selecionada minimiza AIC/BIC com tabela comparativa.",
                                "Resíduos sem autocorrelação e aproximadamente normais (testes passados).",
                                "IRF e FEVD plotados e interpretados corretamente.",
                                "Previsões de 8 períodos geradas e visualizadas.",
                                "Testes de Granger executados para pelo menos uma causalidade."
                              ],
                              "assessmentCriteria": [
                                "Precisão na validação I(1) com testes ADF (p-valores corretos).",
                                "Seleção correta de lags baseada em AIC/BIC com justificativa.",
                                "Código VAR sem erros e summary interpretado.",
                                "Diagnóstico completo com pelo menos 3 testes de resíduos.",
                                "Interpretação econômica coerente dos resultados.",
                                "Relatório final com plots e conclusões acionáveis."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Base para testes de cointegration Johansen e VEC.",
                                "Economia: Modelagem de ciclos econômicos multivariados.",
                                "Estatística: Inferência em modelos dinâmicos lineares.",
                                "Programação: Manipulação avançada de dados temporais em Python."
                              ],
                              "realWorldApplication": "Em bancos centrais, para simular impactos de política monetária (ex: elevar juros reduz PIB temporariamente) ou prever crescimento econômico com múltiplas variáveis como emprego, inflação e exportações."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.1.2"
                            ]
                          },
                          {
                            "id": "10.1.5.3.3.2",
                            "name": "Aplicar teste de Johansen para rank de cointegração",
                            "description": "Executar teste de traço e máximo autovalor para determinar o número de relações de cointegração r em sistemas multivariados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e verificar pré-requisitos",
                                  "subSteps": [
                                    "Coletar dados de séries temporais multivariadas (ex: Y1, Y2, ..., Yk) em formato de painel ou vetorial.",
                                    "Testar estacionariedade das séries individuais usando testes ADF ou KPSS para confirmar não-estacionariedade (I(1)).",
                                    "Verificar ausência de quebras estruturais e selecionar lag order usando critérios AIC/BIC.",
                                    "Transformar dados em diferenças se necessário e preparar matriz de dados para VAR.",
                                    "Padronizar ou log-transformar variáveis para estabilidade numérica."
                                  ],
                                  "verification": "Todas as séries são confirmadas como I(1) e lag order selecionado com evidência estatística (p-valores < 0.05).",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Software R (pacotes urca, vars) ou Python (statsmodels, arch)",
                                    "Dados de séries temporais (ex: FRED database)"
                                  ],
                                  "tips": "Sempre plotar séries e ACF/PACF para visual inspeção antes de testes formais.",
                                  "learningObjective": "Entender e aplicar testes de pré-condições para validade do teste de Johansen.",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade levando a testes inválidos",
                                    "Selecionar lags inadequados sem critérios informativos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar e estimar o modelo VAR",
                                  "subSteps": [
                                    "Definir ordem de lag p baseada em critérios de informação (AIC, BIC, HQ).",
                                    "Estimar o VAR em níveis para as variáveis não-estacionárias.",
                                    "Testar restrições de lag usando teste LR para otimização.",
                                    "Verificar resíduos do VAR para autocorrelação (teste LM) e normalidade.",
                                    "Salvar coeficientes e resíduos para uso no teste de Johansen."
                                  ],
                                  "verification": "Resíduos do VAR sem autocorrelação significativa (p > 0.05 no teste LM) e modelo estável (raízes dentro do círculo unitário).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R: funções VAR() do pacote vars",
                                    "Python: VAR() do statsmodels.tsa.vector_ar"
                                  ],
                                  "tips": "Comece com lag máximo de 12 e reduza iterativamente; use BIC para parcimônia.",
                                  "learningObjective": "Construir uma representação VAR adequada como base para testes de cointegração.",
                                  "commonMistakes": [
                                    "Sobreparametrização levando a perda de graus de liberdade",
                                    "Não testar estabilidade do VAR"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste de Johansen",
                                  "subSteps": [
                                    "Especificar tipo de modelo (ex: intercepto restrito, tendência linear).",
                                    "Executar teste de traço (trace test) para H0: rank <= r vs HA: rank > r, para r=0 até k-1.",
                                    "Executar teste do máximo autovalor (max eigenvalue) para H0: rank = r vs HA: rank = r+1.",
                                    "Comparar estatísticas com valores críticos (tabelas Johansen ou bootstrap).",
                                    "Registrar autovalores e p-valores para cada teste."
                                  ],
                                  "verification": "Estatísticas de teste calculadas e p-valores reportados corretamente para trace e max eigenvalue.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R: johansen() do pacote urca",
                                    "Python: coint_johansen() do statsmodels.tsa.vector_ar.vecm"
                                  ],
                                  "tips": "Use simulação bootstrap para valores críticos se amostra pequena (<100 obs).",
                                  "learningObjective": "Implementar os dois testes principais do Johansen com configurações corretas.",
                                  "commonMistakes": [
                                    "Confundir testes trace vs max eigenvalue",
                                    "Usar tabelas de valores críticos erradas para o caso (com/sem tendência)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e determinar o rank r",
                                  "subSteps": [
                                    "Identificar o menor r onde trace test rejeita H0 pela primeira vez (top-down).",
                                    "Confirmar com max eigenvalue test para consistência.",
                                    "Analisar autovalores: os maiores indicam força da cointegração.",
                                    "Reportar rank estimado r e discutir implicações (ex: r=1 implica 1 relação de cointegração).",
                                    "Preparar para modelo VEC se r>0."
                                  ],
                                  "verification": "Rank r determinado de forma consistente entre testes, com justificativa baseada em p-valores.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Tabelas de valores críticos Johansen (Osterwald-Lenum)",
                                    "Gráficos de autovalores"
                                  ],
                                  "tips": "Se testes discordam, priorize trace test; considere poder sequencial se amostra grande.",
                                  "learningObjective": "Interpretar outputs estatísticos para inferir número de relações de cointegração.",
                                  "commonMistakes": [
                                    "Parar no primeiro teste sem verificar consistência",
                                    "Ignorar tamanho da amostra afetando poder do teste"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados mensais de PIB real e taxa de juros de EUA e Canadá (1990-2020): após confirmar I(1), estimar VAR(2), executar Johansen com intercepto restrito, encontrar r=1 indicando uma relação de equilíbrio de longo prazo (ex: PIB_CA ~ PIB_US).",
                              "finalVerifications": [
                                "Séries confirmadas I(1) com testes unit root.",
                                "VAR estável e sem autocorrelação nos resíduos.",
                                "Testes trace e max eigenvalue executados com p-valores corretos.",
                                "Rank r determinado consistentemente e justificado.",
                                "Autovalores plotados e interpretados.",
                                "Preparação para VEC se r>0 confirmada."
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação de dados e testes pré-requisitos (90%+ correção).",
                                "Correta especificação e estimação do VAR (resíduos válidos).",
                                "Implementação exata dos testes Johansen (estatísticas coincidem com software).",
                                "Interpretação coerente do rank r com evidência estatística.",
                                "Relatório claro com gráficos e conclusões acionáveis.",
                                "Eficiência temporal e uso apropriado de recursos."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Integra com modelos VAR/VECM e causalidade de Granger.",
                                "Programação: Uso avançado de R/Python para análise estatística.",
                                "Finanças: Aplicação em pares trading e modelagem de risco sistêmico.",
                                "Estatística: Testes de hipóteses sequenciais e valores críticos assintóticos.",
                                "Machine Learning: Paralelos com análise de componentes principais em séries temporais."
                              ],
                              "realWorldApplication": "Em finanças quantitativas, determinar r para cointegração entre ações (ex: ETF SPY e QQQ) permite estratégias de mean-reversion; em macroeconomia, modelar paridades de poder de compra entre moedas para previsão de câmbio de longo prazo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.3.1"
                            ]
                          },
                          {
                            "id": "10.1.5.3.3.3",
                            "name": "Estimar e interpretar modelo VEC",
                            "description": "Reespecificar VAR em forma VEC com termos de correção de erro, interpretando coeficientes de longo e curto prazo em contextos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Verificar pré-condições e preparar dados para modelo VEC",
                                  "subSteps": [
                                    "Confirmar resultado do teste de Johansen indicando presença de cointegration (r > 0 vetores cointegrantes).",
                                    "Selecionar ordem de lag (p) baseada em critérios como AIC ou BIC do modelo VAR equivalente.",
                                    "Preparar séries temporais em diferenças primeiras (ΔY_t) e resíduo de cointegration (ECT_{t-1}).",
                                    "Padronizar dados: remover missing values e verificar estacionariedade das diferenças.",
                                    "Definir matriz de cointegration inicial a partir do teste Johansen."
                                  ],
                                  "verification": "Teste de Johansen reproduzível com r vetores cointegrantes identificados e lag order escolhido.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Software R (pacote 'urca' ou 'vars') ou Python (statsmodels.tsa.vector_ar.vec)",
                                    "Dados de séries temporais multivariadas cointegradas (ex: consumo energia e produção industrial)"
                                  ],
                                  "tips": "Comece com dados reais de engenharia para motivação; use lag máxima de 4-6 para séries trimestrais.",
                                  "learningObjective": "Identificar e preparar dados adequados para estimação de VEC.",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade das diferenças primeiras",
                                    "Escolher lag order sem critérios informativos",
                                    "Confundir r com ordem total de lags"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Reespecificar modelo VAR na forma VEC",
                                  "subSteps": [
                                    "Escrever a forma VAR(k): Y_t = c + A1 Y_{t-1} + ... + Ak Y_{t-k} + ε_t.",
                                    "Decompor Π = α β' onde β' Y_{t-1} é o termo de correção de erro (ECT_{t-1}).",
                                    "Reescrever como VEC: ΔY_t = c + α ECT_{t-1} + Γ1 ΔY_{t-1} + ... + Γ_{k-1} ΔY_{t-k+1} + ε_t.",
                                    "Identificar matrizes: α (ajuste), Γ_i (curto prazo), β (longo prazo).",
                                    "Verificar restrições de cointegration de Johansen."
                                  ],
                                  "verification": "Equação VEC derivada corretamente do VAR equivalente com decomposição Π = α β'.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Documentação de modelos VEC (Livro Hamilton 'Time Series Analysis')",
                                    "Notebook Jupyter para derivação simbólica (SymPy)"
                                  ],
                                  "tips": "Use representação matricial para visualizar; teste igualdade entre VAR e VEC por FIML.",
                                  "learningObjective": "Dominar reespecificação algébrica de VAR para VEC.",
                                  "commonMistakes": [
                                    "Confundir Γ_i com A_i do VAR",
                                    "Esquecer normalização em β",
                                    "Não decompor Π corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimar parâmetros do modelo VEC",
                                  "subSteps": [
                                    "Implementar estimação por MCO restrito ou MLE (Johansen ML).",
                                    "Estimar α, β, Γ_i usando função vecm() em R ou VECM em Python.",
                                    "Testar diagnósticos: autocorrelação residual (Ljung-Box), normalidade (Jarque-Bera), heteroscedasticidade.",
                                    "Validar estabilidade: raízes características dentro do círculo unitário.",
                                    "Ajustar hiperparâmetros se necessário (ex: determininsticos: intercepto ou tendência)."
                                  ],
                                  "verification": "Modelo estimado converge sem erros, com resíduos brancos e raízes estáveis.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "R: pacotes 'tsDyn', 'vars'; Python: 'statsmodels' ou 'arch'",
                                    "Dados sintéticos cointegrados para teste (função coint_sim)"
                                  ],
                                  "tips": "Use estimação Johansen para β normalizado; inclua intercepto restrito se apropriado.",
                                  "learningObjective": "Executar estimação numérica precisa de VEC.",
                                  "commonMistakes": [
                                    "Não testar resíduos",
                                    "Ignorar determininsticos errados",
                                    "Overfitting com lags excessivos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar coeficientes de curto e longo prazo",
                                  "subSteps": [
                                    "Analisar α: velocidade de ajuste (speed of adjustment); sinal negativo indica convergência.",
                                    "Interpretar β: relações de longo prazo (equilíbrio cointegrante).",
                                    "Examinar Γ_i: impactos de curto prazo (diferenças passadas).",
                                    "Calcular multiplicadores de impulso-resposta (IRF) e variância decomposição (FEVD).",
                                    "Contextualizar em engenharia: ex. ajuste de erro em sistemas de controle."
                                  ],
                                  "verification": "Relatório com interpretações econômicas/engenheirísticas de α, β e Γ_i.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Funções plot de IRF/FEVD em R/Python",
                                    "Exemplos de engenharia (energia, controle de processos)"
                                  ],
                                  "tips": "Expresse longo prazo como Y1 = γ Y2 + const; foque em significância estatística.",
                                  "learningObjective": "Extrair insights práticos de coeficientes VEC.",
                                  "commonMistakes": [
                                    "Interpretar α como impacto imediato",
                                    "Ignorar significância t-test",
                                    "Confundir curto com longo prazo"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e aplicar o modelo em contexto prático",
                                  "subSteps": [
                                    "Realizar previsões out-of-sample e comparar com VAR.",
                                    "Testar estabilidade de parâmetros (Chow test).",
                                    "Simular cenários de desvio do equilíbrio e ajuste.",
                                    "Documentar relatório com gráficos de ECT e ajustes.",
                                    "Discutir limitações (ex: não-linearidades)."
                                  ],
                                  "verification": "Previsões precisas e relatório completo com validações.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Dados reais de engenharia (ex: Kaggle séries temporais industriais)",
                                    "Ferramentas de plotting (ggplot2/matplotlib)"
                                  ],
                                  "tips": "Use walk-forward validation; compare RMSE com benchmark.",
                                  "learningObjective": "Aplicar VEC em problemas reais de engenharia.",
                                  "commonMistakes": [
                                    "Não validar out-of-sample",
                                    "Generalizar sem contexto",
                                    "Omitir limitações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia elétrica, estime VEC para séries de consumo de energia (Y1) e produção renovável (Y2). α indica quão rápido o consumo ajusta desequilíbrios (ex: -0.3 significa 30% correção por período); β mostra relação de longo prazo (1MW produção suporta 2MW consumo estabilizado).",
                              "finalVerifications": [
                                "Reespecifica corretamente VAR(k) para VEC(k-1) com ECT.",
                                "Estima modelo com diagnósticos residuais aprovados.",
                                "Interpreta α como velocidade de ajuste e β como equilíbrio longo prazo.",
                                "Calcula e interpreta IRF/FEVD.",
                                "Aplica em exemplo de engenharia com previsões válidas.",
                                "Identifica erros comuns como não-estacionariedade."
                              ],
                              "assessmentCriteria": [
                                "Precisão algébrica na reespecificação (100% correta).",
                                "Convergência e diagnósticos do modelo (todos testes passados).",
                                "Interpretação correta de coeficientes (curto/longo prazo com contexto).",
                                "Qualidade de gráficos e relatório (claro, profissional).",
                                "Criatividade na aplicação engenheirística.",
                                "Tratamento de erros e limitações."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Controle: Analogia com feedback em sistemas dinâmicos.",
                                "Econometria: Aplicações em previsão macroeconômica.",
                                "Estatística Computacional: Otimização MLE em grandes dados.",
                                "Engenharia Industrial: Modelagem de processos cointegrados (estoque-fluxo)."
                              ],
                              "realWorldApplication": "Em engenharia de processos, VEC modela cointegration entre variáveis como temperatura e pressão em reatores, permitindo prever desvios de equilíbrio, otimizar controle PID e prevenir falhas, como em plantas petroquímicas onde ajuste lento (α pequeno) sinaliza risco de overflow."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.3.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.4",
                    "name": "Vetor Corretor de Erros (VECM)",
                    "description": "Modelos de vetor corretor de erros para análise de relações de longo prazo em sistemas cointegrados.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.4.1",
                        "name": "Cointegração em Séries Temporais",
                        "description": "Conceito fundamental para VECM, que descreve relações de longo prazo entre séries temporais não estacionárias integradas de ordem 1 (I(1)), onde combinações lineares delas são estacionárias.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.4.1.1",
                            "name": "Identificar séries I(1) e relações cointegradas",
                            "description": "Diferenciar séries temporais estacionárias de não estacionárias e reconhecer vetores de cointegração que eliminam tendências estocásticas em sistemas multivariados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos de Estacionariedade e Séries I(1)",
                                  "subSteps": [
                                    "Estude a definição de processos estacionários vs. não estacionários, focando em walk random com drift e tendência.",
                                    "Aprenda sobre integração de ordem 1 (I(1)): séries cujas primeiras diferenças são estacionárias.",
                                    "Revise testes de hipótese para raízes unitárias (Dickey-Fuller).",
                                    "Pratique diferenciando visualmente séries I(0), I(1) e I(2) em gráficos ACF/PACF.",
                                    "Explore implicações de regressões espúrias em séries não estacionárias."
                                  ],
                                  "verification": "Explique em suas palavras a diferença entre I(0) e I(1), e identifique corretamente 3 exemplos gráficos fornecidos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Livro 'Time Series Analysis' de Hamilton (cap. 17)",
                                    "Notebook Jupyter com dados sample de séries temporais (ex: airpassengers dataset)",
                                    "Biblioteca Python: pandas, matplotlib, statsmodels"
                                  ],
                                  "tips": "Sempre plote as séries e suas diferenças antes de qualquer teste para intuição visual.",
                                  "learningObjective": "Diferenciar conceitualmente séries estacionárias de I(1) e entender riscos de não estacionariedade.",
                                  "commonMistakes": [
                                    "Confundir tendência determinística com estocástica",
                                    "Ignorar a necessidade de detrending antes de testes",
                                    "Interpretar p-valores sem considerar tamanho da amostra"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar Testes de Raiz Unitária para Identificar Séries I(1)",
                                  "subSteps": [
                                    "Implemente o teste Augmented Dickey-Fuller (ADF) em Python com statsmodels.",
                                    "Aplique o teste em níveis e primeiras diferenças das séries.",
                                    "Interprete estatísticas: rejeitar H0 (raiz unitária) indica estacionariedade.",
                                    "Compare com teste KPSS para confirmação (H0 estacionária).",
                                    "Teste múltiplas séries de um dataset multivariado."
                                  ],
                                  "verification": "Execute ADF em 3 séries sample e classifique corretamente como I(1) se não estacionárias no nível mas no primeiro diff.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "statsmodels.tsa.stattools.adfuller",
                                    "Dataset exemplo: PIB e inflação trimestral (FRED API)",
                                    "Jupyter Notebook template para testes unit root"
                                  ],
                                  "tips": "Use lag selection automático (AIC) e inclua constante/tendência conforme suspeita.",
                                  "learningObjective": "Aplicar e interpretar testes para confirmar ordem de integração I(1).",
                                  "commonMistakes": [
                                    "Não testar diferenças após falha no nível",
                                    "Ignorar autocorrelação nos resíduos",
                                    "Confundir ADF com DF simples em séries com serial correlation"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir e Testar Cointegração Bivariada (Engle-Granger)",
                                  "subSteps": [
                                    "Defina cointegration: combinação linear estacionária de não estacionárias.",
                                    "Execute regressão OLS entre duas séries I(1) para resíduo.",
                                    "Aplique ADF nos resíduos: se estacionário, cointegradas.",
                                    "Calcule vetor de cointegration normalizado.",
                                    "Valide com teste de significância dos coeficientes."
                                  ],
                                  "verification": "Identifique cointegration em par de séries (ex: PIB e consumo) e extraia vetor corretamente.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "statsmodels.tsa.stattools.coint",
                                    "Dataset bivariado: stock prices AAPL e MSFT",
                                    "Documentação Engle-Granger procedure"
                                  ],
                                  "tips": "Padronize séries se escalas diferem; teste superconsistência dos estimadores.",
                                  "learningObjective": "Detectar e quantificar relações cointegradas em pares de séries I(1).",
                                  "commonMistakes": [
                                    "Usar OLS diretamente sem testar I(1) prévio",
                                    "Não normalizar vetor (sum=1)",
                                    "Ignorar endogeneidade em regressão de cointegration"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar Relações Cointegradas em Sistemas Multivariados (Johansen)",
                                  "subSteps": [
                                    "Estude teste Johansen: trace e max-eigen para rank de cointegration.",
                                    "Estime VAR em níveis, selecione lags (AIC/HQ).",
                                    "Implemente Johansen em Python para múltiplas séries.",
                                    "Identifique número de relações r e vetores cointegrantes.",
                                    "Interprete loadings e ajuste para VECM."
                                  ],
                                  "verification": "Aplique Johansen em sistema de 3 séries I(1) e especifique corretamente rank r e vetores.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "statsmodels.tsa.vector_ar.vecm.JohansenTest",
                                    "Dataset: taxas câmbio EUR/USD, GBP/USD, JPY/USD",
                                    "Tutorial VECM em statsmodels"
                                  ],
                                  "tips": "Comece com modelo sem restrições; teste hipóteses lineares nos vetores pós-estimação.",
                                  "learningObjective": "Identificar múltiplas relações cointegradas em contextos VECM.",
                                  "commonMistakes": [
                                    "Lag selection inadequada levando a overspecification",
                                    "Confundir rank com número de séries",
                                    "Não verificar estacionariedade das combinações lineares"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados mensais de PIB real e índice de preços ao consumidor (CPI) de 1980-2020: (1) Teste ADF confirma ambas I(1). (2) Regressão Engle-Granger nos resíduos é estacionária (p<0.05). (3) Johansen bivariado confirma r=1. Vetor: PIB - 1.2*CPI ≈ estacionário, indicando relação de longo prazo.",
                              "finalVerifications": [
                                "Classifica corretamente 4 séries sample como I(1) via ADF/KPSS.",
                                "Detecta cointegration bivariada em 2 pares teste com Engle-Granger.",
                                "Estima rank Johansen=1 em sistema trivariate conhecido cointegrado.",
                                "Extrai e interpreta vetor cointegrante normalizado.",
                                "Explica eliminação de tendências estocásticas via combinação linear.",
                                "Identifica ausência de cointegration em pares spurious."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de I(1) (>90% acurácia em testes simulados).",
                                "Correta interpretação de p-valores em testes ADF/Johansen.",
                                "Implementação sem erros de código em Python statsmodels.",
                                "Explicação conceitual clara de cointegration vs. correlação espúria.",
                                "Aplicação correta a dados reais com visualizações.",
                                "Identificação de pelo menos 1 relação cointegrada em dataset multivariado."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Modelagem VECM para previsão macroeconômica.",
                                "Finanças Quant: Pairs trading baseado em desvios de equilíbrio cointegrado.",
                                "Machine Learning: Feature engineering com resíduos cointegrados em TS forecasting.",
                                "Estatística: Testes de hipótese multivariados e análise VAR.",
                                "Economia: Análise de equilíbrio de longo prazo em políticas monetárias."
                              ],
                              "realWorldApplication": "Em finanças, traders usam cointegration para estratégias mean-reversion em pares de ações cointegradas (ex: Coke e Pepsi), comprando o subvalorizado e vendendo o supervalorizado até convergência; em macroeconomia, Bancos Centrais monitoram relações cointegradas entre PIB, inflação e juros para políticas estáveis."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.4.1.2",
                            "name": "Aplicar teste de Engle-Granger para cointegração bivariada",
                            "description": "Realizar regressão residual para testar cointegração em duas séries, verificando estacionariedade dos resíduos via teste Dickey-Fuller aumentado.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e verificar pré-condições de estacionariedade",
                                  "subSteps": [
                                    "Colete duas séries temporais bivariadas relevantes, como preços de ações diários.",
                                    "Carregue os dados em Python usando pandas e realize transformações logarítmicas se necessário (log-prices).",
                                    "Plote as séries temporais para visual inspeção de tendências e não-estacionariedade.",
                                    "Aplique o teste Dickey-Fuller Aumentado (ADF) em cada série individual para confirmar que são I(1).",
                                    "Selecione lags apropriados usando critérios AIC/BIC para o teste ADF."
                                  ],
                                  "verification": "Ambas séries rejeitam H0 de não-estacionariedade no nível, mas aceitam em primeiras diferenças (p-value >0.05 no nível, <0.05 em diferenças).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com pandas, matplotlib, statsmodels",
                                    "Dataset exemplo: preços AAPL e MSFT de Yahoo Finance"
                                  ],
                                  "tips": [
                                    "Sempre use log-retornos para séries de preços financeiras; plote ACF/PACF para auxiliar lag selection."
                                  ],
                                  "learningObjective": "Identificar séries não-estacionárias integradas de ordem 1, pré-requisito para cointegração.",
                                  "commonMistakes": [
                                    "Não transformar em logs",
                                    "Ignorar seleção de lags",
                                    "Confundir I(0) com I(1)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar a regressão de equilíbrio de longo prazo (OLS)",
                                  "subSteps": [
                                    "Defina a regressão: y_t = α + β x_t + ε_t, onde y e x são as séries.",
                                    "Use statsmodels OLS para estimar α, β e obter resíduos ε_t.",
                                    "Inclua lags de y se necessário para correção de autocorrelação (teste Breusch-Godfrey).",
                                    "Salve os coeficientes estimados e resíduos em variáveis separadas.",
                                    "Interprete β como a relação de cointegração de longo prazo."
                                  ],
                                  "verification": "Resíduos extraídos com sucesso e regressão converge (R² alto, t-stats significativos para β).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python statsmodels.api.OLS",
                                    "Resíduos da regressão anterior"
                                  ],
                                  "tips": [
                                    "Teste regressão x em y e y em x para direção; use robust standard errors se heteroscedasticidade."
                                  ],
                                  "learningObjective": "Estimar vetor de cointegração via OLS univariada.",
                                  "commonMistakes": [
                                    "Não testar autocorrelação nos resíduos",
                                    "Omitir constante α",
                                    "Usar níveis errados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Extrair e preparar resíduos para teste de estacionariedade",
                                  "subSteps": [
                                    "Extraia os resíduos ε_t da regressão OLS ajustada.",
                                    "Plote os resíduos para verificar ausência de tendência.",
                                    "Compute estatísticas descritivas dos resíduos (média ~0, variância estável).",
                                    "Transforme resíduos em série temporal se necessário (índice temporal).",
                                    "Verifique estacionariedade preliminar via plot de ACF dos resíduos."
                                  ],
                                  "verification": "Resíduos plotados sem tendência linear e ACF decaindo rapidamente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "pandas Series para resíduos",
                                    "matplotlib para plots"
                                  ],
                                  "tips": [
                                    "Padronize resíduos se escalas diferem; salve como df.resid."
                                  ],
                                  "learningObjective": "Preparar resíduos como proxy para erros de previsão de equilíbrio.",
                                  "commonMistakes": [
                                    "Usar resíduos brutos sem plot",
                                    "Índice temporal desalinhado"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar teste Dickey-Fuller Aumentado nos resíduos",
                                  "subSteps": [
                                    "Aplique statsmodels.tsa.stattools.adfuller nos resíduos, especificando lags via AIC.",
                                    "Registre estatística de teste, p-value e valores críticos.",
                                    "Compare p-value com nível de significância (ex: 5%).",
                                    "Se necessário, teste com diferentes lags ou trend.",
                                    "Documente hipótese nula: resíduos têm raiz unitária (não cointegrados)."
                                  ],
                                  "verification": "P-value <0.05 rejeita H0, indicando resíduos estacionários e cointegração.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "statsmodels.tsa.stattools.adfuller",
                                    "Série de resíduos"
                                  ],
                                  "tips": [
                                    "Use maxlags='AIC'; inclua trend se resíduos trendem."
                                  ],
                                  "learningObjective": "Testar hipótese de cointegração via estacionariedade residual.",
                                  "commonMistakes": [
                                    "Lags insuficientes levando a teste inválido",
                                    "Ignorar valores críticos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e concluir sobre cointegração",
                                  "subSteps": [
                                    "Resuma: se resíduos estacionários, séries cointegradas com vetor (1, -β).",
                                    "Reporte estatística ADF, p-value e conclusão.",
                                    "Discuta implicações para VECM (existe erro de correção).",
                                    "Valide com teste Johansen bivariado para robustez.",
                                    "Documente relatório com plots e tabelas."
                                  ],
                                  "verification": "Conclusão correta: cointegradas se ADF resíduos significativo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resultados ADF",
                                    "Jupyter notebook para relatório"
                                  ],
                                  "tips": [
                                    "Compare com Engle-Granger 2-step vs Johansen; cite fontes acadêmicas."
                                  ],
                                  "learningObjective": "Interpretar teste para modelagem de séries cointegradas.",
                                  "commonMistakes": [
                                    "Concluir cointegração sem rejeitar H0",
                                    "Não discutir direção da regressão"
                                  ]
                                }
                              ],
                              "practicalExample": "Baixe dados diários de preços de fechamento da AAPL e MSFT (2010-2020) via yfinance. Teste log-preços: regressão log(AAPL) ~ log(MSFT), ADF nos resíduos. Espere p-value baixo confirmando cointegração devido a setor tech similar.",
                              "finalVerifications": [
                                "Séries individuais I(1) confirmadas por ADF.",
                                "Resíduos da OLS estacionários (ADF p-value <0.05).",
                                "Vetor de cointegração β estimado corretamente.",
                                "Relatório com plots, tabelas e interpretação.",
                                "Validação cruzada com Johansen test.",
                                "Código Python reproduzível sem erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação ADF e OLS (resultados numéricos corretos).",
                                "Seleção adequada de lags e testes diagnósticos.",
                                "Interpretação teórica correta de cointegração.",
                                "Qualidade de visualizações e relatório.",
                                "Tratamento de edge cases (ex: não-estacionariedade).",
                                "Eficiência computacional do código."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Extensão para VECM e modelagem multivariada.",
                                "Finanças Quantitativas: Trading de pares e hedge ratios.",
                                "Programação Científica: Uso avançado de statsmodels e pandas.",
                                "Estatística: Testes de hipóteses unit root e cointegration.",
                                "Machine Learning: Feature engineering com resíduos cointegrados."
                              ],
                              "realWorldApplication": "Em finanças, detectar cointegração entre ativos para estratégias de trading de pares (ex: vender spread mean-reverting AAPL-MSFT); em economia, modelar relações de longo prazo entre PIB e inflação para políticas monetárias."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.1.1"
                            ]
                          },
                          {
                            "id": "10.1.5.4.1.3",
                            "name": "Executar teste de Johansen para cointegração multivariada",
                            "description": "Implementar teste de autovalores trace e máximo para determinar o rank de cointegração em sistemas VAR, usando software como R.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e verificar pré-requisitos para o teste",
                                  "subSteps": [
                                    "Carregar os dados de séries temporais multivariadas em R usando read.csv ou ts()",
                                    "Testar estacionariedade com testes ADF ou KPSS para confirmar não-estacionariedade (I(1))",
                                    "Verificar lag order ótimo usando critérios AIC/BIC com função VARselect() do pacote vars",
                                    "Determinar ordem de integração e possíveis quebras estruturais nos dados"
                                  ],
                                  "verification": "Confirme que todas as séries são I(1) e lag order selecionado via plot de critérios de informação",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R e RStudio",
                                    "Pacotes: vars, urca, tseries",
                                    "Dados de exemplo: PIB e taxa de juros (disponíveis em datasets como Canada do pacote urca)"
                                  ],
                                  "tips": "Sempre plot os dados primeiro com plot.ts() para visualizar tendências e sazonalidades",
                                  "learningObjective": "Entender e aplicar testes de pré-condições para validade do teste de Johansen",
                                  "commonMistakes": [
                                    "Ignorar testes de estacionariedade",
                                    "Usar lags inadequados sem critérios de informação",
                                    "Não tratar valores ausentes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar e estimar o modelo VAR",
                                  "subSteps": [
                                    "Instalar e carregar pacotes necessários: library(vars), library(urca)",
                                    "Criar objeto VAR com função VAR() usando lag order selecionado e tipo='const' ou 'trend'",
                                    "Realizar testes de estabilidade do VAR com roots() ou stability() para garantir invertibilidade",
                                    "Serial correlation LM test com serial.test() para validar resíduos"
                                  ],
                                  "verification": "Verifique raízes do polinômio característico dentro do círculo unitário e p-value > 0.05 no teste LM",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R scripts com dados carregados",
                                    "Documentação de vars e urca"
                                  ],
                                  "tips": "Comece com modelo simples (const) e adicione trend se justificado pelos dados",
                                  "learningObjective": "Construir um modelo VAR estável como base para o teste de cointegração",
                                  "commonMistakes": [
                                    "Selecionar lags excessivos levando a sobreparametrização",
                                    "Ignorar testes de diagnóstico do VAR"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste de Johansen",
                                  "subSteps": [
                                    "Aplicar ca.jo() do pacote urca com tipo de determinístico correto (intercept, trend etc.)",
                                    "Especificar K=2 para intercepto no cointegrating eq e none na VAR, ajustando conforme contexto",
                                    "Extrair estatísticas trace e max-eigenvalue com cajorc() ou diretamente de ca.jo()",
                                    "Comparar estatísticas com valores críticos tabulados ou p-values bootstrap"
                                  ],
                                  "verification": "Obtenha output com traceStat, eigenStat e p-values; rejeite H0 se p-value < 0.05",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacote urca",
                                    "Tabelas de valores críticos de Johansen (disponíveis online ou em doc)"
                                  ],
                                  "tips": "Use spec='transitory' para intercepto se tendência linear nos dados",
                                  "learningObjective": "Implementar corretamente o procedimento de Johansen para testes trace e eigenvalue",
                                  "commonMistakes": [
                                    "Configuração errada do determinístico levando a testes inválidos",
                                    "Confundir trace (r=0 vs r<=k) com max-eigen"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e determinar rank de cointegração",
                                  "subSteps": [
                                    "Identificar o menor r onde trace/max-eigen não rejeita H0 (rank r)",
                                    "Plotar gráficos de carga de autovalores e vetores de cointegração com plot(ca.jo())",
                                    "Testar normalidade e heterocedasticidade dos resíduos com diagnostics",
                                    "Documentar rank e preparar para estimação VECM se r>0"
                                  ],
                                  "verification": "Relatório escrito com rank estimado, estatísticas chave e interpretação econômica",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R plots e summary(ca.jo())",
                                    "Papel para relatório"
                                  ],
                                  "tips": "Use sequencial teste de MacKinnon-Haug-Michelis p-values para robustez",
                                  "learningObjective": "Interpretar estatísticas e inferir presença/ausência de cointegração",
                                  "commonMistakes": [
                                    "Parar no primeiro não-rejeição sem teste sequencial",
                                    "Ignorar diagnósticos de resíduos"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados Canada do pacote urca (PIB real, emprego, etc.), execute ca.jo(cbind(rgnp, rw, ...), K=2, spec='const', type='trace') e determine rank=1, interpretando que variáveis compartilham uma relação de longo prazo.",
                              "finalVerifications": [
                                "Teste de Johansen executado sem erros no R com dados multivariados I(1)",
                                "Rank de cointegração corretamente identificado via trace e eigenvalue",
                                "Diagnósticos do VAR (estabilidade, serial corr) aprovados",
                                "Relatório inclui plots, p-values e interpretação",
                                "Reprodutibilidade confirmada rodando script em novo R session",
                                "Aplicação em VECM possível com rank estimado"
                              ],
                              "assessmentCriteria": [
                                "Precisão na especificação do modelo (lags, determinísticos): 25%",
                                "Correta execução e output do ca.jo(): 30%",
                                "Interpretação válida do rank e estatísticas: 25%",
                                "Qualidade de diagnósticos e plots: 10%",
                                "Relatório claro e completo: 10%"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Modelos VAR/VECM em análise macroeconômica",
                                "Programação: Manipulação de dados em R (tidyverse, tsibble)",
                                "Estatística: Testes de hipótese sequenciais e autovalores",
                                "Finanças: Cointegração em pares de trading e risco sistêmico"
                              ],
                              "realWorldApplication": "Em finanças, detectar cointegração entre ações para estratégias de pairs trading; em economia, analisar relações de longo prazo entre PIB, inflação e juros para políticas monetárias."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.4.2",
                        "name": "Modelos Autoregressivos Vetoriais (VAR)",
                        "description": "Base para VECM, modela interdependências dinâmicas entre múltiplas séries temporais como processos lineares autoregressivos em forma vetorial.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.4.2.1",
                            "name": "Especificar e estimar modelo VAR",
                            "description": "Determinar ordem lag via critérios AIC/BIC, estimar coeficientes por Mínimos Quadrados Ordinários em cada equação e validar pressupostos de resíduos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e testar pré-condições para modelo VAR",
                                  "subSteps": [
                                    "Carregar e inspecionar os dados multivariados de séries temporais (ex: PIB e taxa de juros).",
                                    "Testar estacionariedade com testes ADF ou KPSS para cada série; diferenciar se necessário.",
                                    "Verificar cointegration com teste Johansen para justificar VAR vs VECM.",
                                    "Definir o período de amostra e remover outliers.",
                                    "Padronizar ou transformar variáveis se aplicável (log, etc.)."
                                  ],
                                  "verification": "Dados limpos e estacionários confirmados por sumários de testes e gráficos ACF/PACF.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (statsmodels, pandas), dados de exemplo (ex: dados macroeconômicos do FRED); ou R (vars package).",
                                  "tips": "Sempre plotar séries para visualização intuitiva antes de testes formais.",
                                  "learningObjective": "Garantir dados adequados para evitar viés em estimações VAR.",
                                  "commonMistakes": "Ignorar não-estacionariedade, levando a resultados espúrios."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Determinar ordem de lag ótima usando critérios AIC e BIC",
                                  "subSteps": [
                                    "Especificar modelo VAR provisional com lags máximos (ex: p_max = 12).",
                                    "Calcular AIC e BIC para cada possível p de 1 a p_max via função VARselect.",
                                    "Selecionar p que minimiza AIC (mais parcimonioso) ou BIC (mais penalizador).",
                                    "Comparar com HQIC se disponível e plotar evolução dos critérios.",
                                    "Documentar escolha final e justificar com valores numéricos."
                                  ],
                                  "verification": "Tabela com AIC/BIC valores mostrando mínimo claro no lag selecionado.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python: statsmodels.tsa.vector_ar.var_model.VARSelect; R: VARselect().",
                                  "tips": "Use BIC para amostras pequenas para evitar overfitting.",
                                  "learningObjective": "Selecionar lag ótimo para capturar dinâmica sem excesso de parâmetros.",
                                  "commonMistakes": "Escolher lag alto sem penalização, causando perda de graus de liberdade."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimar coeficientes do modelo VAR por Mínimos Quadrados Ordinários",
                                  "subSteps": [
                                    "Ajustar modelo VAR(p) com lags selecionados usando OLS em cada equação.",
                                    "Extrair coeficientes, matriz de covariância e estatísticas de significância (t-stats).",
                                    "Calcular Impulse Response Functions (IRF) e Forecast Error Variance Decomposition (FEVD) iniciais.",
                                    "Verificar estabilidade do modelo (raízes de autovalores dentro do círculo unitário).",
                                    "Interpretar coeficientes: efeitos contemporâneos e laggeados entre variáveis."
                                  ],
                                  "verification": "Modelo ajustado com sumário de coeficientes significativos e raízes estáveis.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Python: statsmodels.tsa.vector_ar.VAR; R: VAR() function.",
                                  "tips": "Salve o modelo fitted para reutilização em diagnósticos.",
                                  "learningObjective": "Entender estimação OLS em sistemas multivariados e interpretação.",
                                  "commonMistakes": "Não checar estabilidade, levando a explosões em previsões."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar pressupostos dos resíduos e diagnosticar o modelo",
                                  "subSteps": [
                                    "Testar resíduos para autocorrelação (Ljung-Box ou Portmanteau).",
                                    "Verificar normalidade dos resíduos (Jarque-Bera test).",
                                    "Testar homocedasticidade e ausência de ARCH effects.",
                                    "Analisar IRF e FEVD para plausibilidade econômica.",
                                    "Realizar previsões out-of-sample e comparar com dados reais."
                                  ],
                                  "verification": "Resíduos brancos confirmados por p-values > 0.05 em todos testes.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Funções de diagnóstico em statsmodels/R: serial_correlation, normality tests.",
                                  "tips": "Se resíduos ruins, considere lags sazonais ou variáveis exógenas.",
                                  "learningObjective": "Garantir validade estatística do modelo para inferências confiáveis.",
                                  "commonMistakes": "Aceitar modelo sem diagnósticos, ignorando violações."
                                }
                              ],
                              "practicalExample": "Usando dados mensais de PIB real e taxa de juros dos EUA (1970-2020) do FRED: teste estacionariedade (diferencie PIB), selecione p=4 por BIC mínimo, estime VAR, valide resíduos sem autocorrelação e interprete como choque de juros afeta PIB em 2 lags.",
                              "finalVerifications": [
                                "Lag selecionado minimiza AIC/BIC com tabela comparativa.",
                                "Coeficientes estimados por OLS com t-stats significativos (>2).",
                                "Raízes características dentro do círculo unitário (|raízes| <1).",
                                "Resíduos sem autocorrelação (Portmanteau p>0.05).",
                                "Normalidade e homocedasticidade dos resíduos aprovadas.",
                                "IRF plausíveis e estáveis ao longo de 10 períodos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na seleção de lag (coerente com critérios informacionais).",
                                "Correta implementação de OLS multivariado.",
                                "Validação completa de pressupostos com testes apropriados.",
                                "Interpretação econômica coerente dos coeficientes/IRF.",
                                "Código reproduzível e documentado.",
                                "Diagnóstico de estabilidade e previsões out-of-sample."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e critérios de informação.",
                                "Econometria: Modelos dinâmicos e cointegration.",
                                "Programação: Manipulação de dados em Python/R.",
                                "Economia: Aplicações macroeconômicas em séries temporais."
                              ],
                              "realWorldApplication": "Previsão de variáveis macroeconômicas como impacto de política monetária no crescimento (usado por bancos centrais como FED para cenários de stress testing)."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.1.3"
                            ]
                          },
                          {
                            "id": "10.1.5.4.2.2",
                            "name": "Realizar testes de causalidade de Granger",
                            "description": "Testar se uma série prevê outra em um VAR, usando estatística F e interpretando implicações para relações dinâmicas em contextos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e determinar ordem de lag para o modelo VAR",
                                  "subSteps": [
                                    "Verificar estacionariedade das séries temporais usando testes ADF ou KPSS",
                                    "Coletar e alinhar dados de pelo menos duas séries temporais relevantes",
                                    "Aplicar critérios de informação como AIC, BIC e HQIC para testar diferentes ordens de lag",
                                    "Selecionar a ordem de lag ótima que minimiza o critério escolhido",
                                    "Confirmar ausência de autocorrelação serial nos resíduos preliminares"
                                  ],
                                  "verification": "Relatório com resultados dos testes de estacionariedade e tabela de critérios de lag mostrando a ordem selecionada",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software Python (statsmodels, pandas) ou R (vars package)",
                                    "Dados de séries temporais em CSV",
                                    "Documentação de testes unitários"
                                  ],
                                  "tips": "Comece com lags baixos (1-4) e priorize BIC para modelos parcimoniosos em amostras pequenas",
                                  "learningObjective": "Preparar dados adequados e selecionar ordem de lag ótima para modelagem VAR",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade levando a resultados espúrios",
                                    "Escolher lags muito altos causando perda de graus de liberdade",
                                    "Não testar múltiplos critérios de informação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar o modelo VAR com a ordem de lag selecionada",
                                  "subSteps": [
                                    "Especificar o modelo VAR incluindo todas as variáveis endógenas",
                                    "Estimar coeficientes via Mínimos Quadrados Ordinários (MQO) para cada equação",
                                    "Verificar diagnósticos residuais: normalidade, heterocedasticidade e autocorrelação",
                                    "Gerar impulsos-resposta e decomposição de variância se aplicável",
                                    "Salvar o modelo estimado para uso no teste"
                                  ],
                                  "verification": "Modelo VAR estimado com sumário de coeficientes e testes de resíduos aprovados (p-valores > 0.05)",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Biblioteca statsmodels.tsa.vector_ar.var_model em Python ou VAR() em R",
                                    "Dados preparados do Step 1"
                                  ],
                                  "tips": "Inclua constantes ou tendências se justificado pelos testes de cointegration prévios",
                                  "learningObjective": "Construir e validar um modelo VAR estável para análise de causalidade",
                                  "commonMistakes": [
                                    "Omitir variáveis relevantes causando viés de especificação",
                                    "Não diagnosticar resíduos levando a inferências inválidas",
                                    "Confundir ordem de lag com número de variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste de causalidade de Granger",
                                  "subSteps": [
                                    "Definir a hipótese nula: variável X não causa Y (não melhora previsão)",
                                    "Executar teste F restrito vs. irrestrito usando função grangertest() ou equivalente",
                                    "Realizar teste em ambas as direções (X causa Y e Y causa X)",
                                    "Reportar estatística F, graus de liberdade e p-valor",
                                    "Ajustar por múltiplos testes se mais de duas variáveis (Bonferroni)"
                                  ],
                                  "verification": "Output do teste com p-valores para cada direção e rejeição/aceitação da H0 em alpha=0.05",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Função grangercausalitytests() em statsmodels ou causality() em R",
                                    "Modelo VAR do Step 2"
                                  ],
                                  "tips": "Use lags consistentes com o modelo VAR; teste unilateral se teoria suporta direção específica",
                                  "learningObjective": "Aplicar e interpretar o teste estatístico de Granger corretamente",
                                  "commonMistakes": [
                                    "Testar apenas uma direção ignorando bidirecionalidade",
                                    "Interpretar causalidade como 'causa real' em vez de 'previsibilidade'",
                                    "Usar alpha inadequado sem justificativa"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e discutir implicações",
                                  "subSteps": [
                                    "Analisar p-valores: rejeitar H0 se p < 0.05 indicando causalidade de Granger",
                                    "Discutir magnitude da estatística F e robustez com diferentes lags",
                                    "Relacionar achados a relações dinâmicas no contexto de engenharia",
                                    "Verificar sensibilidade com subamostras ou modelos alternativos",
                                    "Documentar limitações como não-causalidade verdadeira ou omissões"
                                  ],
                                  "verification": "Relatório escrito com interpretação, tabela de resultados e conclusões contextualizadas",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Modelos e testes dos steps anteriores",
                                    "Ferramentas de visualização como matplotlib ou ggplot"
                                  ],
                                  "tips": "Sempre qualifique: 'Granger-causalidade, não causalidade ontológica'",
                                  "learningObjective": "Extrair insights acionáveis de testes de causalidade em sistemas dinâmicos",
                                  "commonMistakes": [
                                    "Sobre-generalizar resultados sem contexto",
                                    "Ignorar poder estatístico em amostras pequenas",
                                    "Confundir com testes de cointegration"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia de processos, use dados de sensores de uma planta química para testar se variações na vazão de fluido (X) Granger-causam flutuações na temperatura do reator (Y). Estime VAR(2), teste revela p=0.01 para X→Y, implicando que vazão prevê temperatura para otimização de controle PID.",
                              "finalVerifications": [
                                "Ordem de lag selecionada com critérios AIC/BIC reportados",
                                "Modelo VAR estimado com resíduos sem autocorrelação (Ljung-Box p>0.05)",
                                "Testes de Granger executados bidirecionalmente com p-valores corretos",
                                "Interpretação consistente com nível de significância",
                                "Relatório inclui diagnósticos e limitações",
                                "Resultados reproduzíveis com seed ou dados fornecidos"
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação de dados e seleção de lags (30%)",
                                "Correção na estimação VAR e diagnósticos (25%)",
                                "Execução e relatório do teste F de Granger (20%)",
                                "Qualidade da interpretação e discussão de implicações (15%)",
                                "Clareza do relatório e uso de visualizações (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial (testes de hipóteses F)",
                                "Engenharia de Controle (modelos dinâmicos VAR/VECM)",
                                "Análise de Sinais e Sistemas (impulsos-resposta)",
                                "Econometria (causalidade em séries temporais)",
                                "Machine Learning (previsão multivariada)"
                              ],
                              "realWorldApplication": "Na engenharia, testes de Granger identificam precedências em sistemas como previsão de falhas em turbinas eólicas (vibração causa desgaste) ou otimização de redes elétricas (demanda causa geração), guiando designs de controladores e políticas de manutenção preditiva."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.4.2.3",
                            "name": "Analisar funções de impulso-resposta e decomposição de variância",
                            "description": "Interpretar respostas dinâmicas a choques e contribuições de variáveis para variância de previsões em sistemas VAR cointegrados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Modelos VAR e Cointegração",
                                  "subSteps": [
                                    "Relembrar a estrutura de um modelo VAR(p): Y_t = A_1 Y_{t-1} + ... + A_p Y_{t-p} + ε_t.",
                                    "Explicar testes de cointegration (Johansen) e por que VAR cointegrados requerem VECM, mas IRF/FEVD são derivados de VAR reduzido.",
                                    "Discutir ortogonalização de choques (Cholesky) para IRF.",
                                    "Identificar variáveis endógenas em um sistema bivariado ou multivariado.",
                                    "Preparar dados estacionários ou com tendência para análise."
                                  ],
                                  "verification": "Resumir em um parágrafo as diferenças entre VAR e VECM e listar pré-requisitos para IRF/FEVD.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Documentação statsmodels Python, dados de exemplo (ex: PIB e taxa de juros do FRED).",
                                  "tips": "Use gráficos de séries temporais para visualizar cointegration antes de modelar.",
                                  "learningObjective": "Compreender a base teórica para geração de IRF e FEVD em contextos cointegrados.",
                                  "commonMistakes": "Ignorar testes de estacionariedade, levando a IRF espúrias."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar Modelo VAR e Gerar Funções de Impulso-Resposta (IRF)",
                                  "subSteps": [
                                    "Selecionar ordem lag ótima com critérios AIC/BIC.",
                                    "Estimar VAR usando statsmodels.tsa.VAR.",
                                    "Gerar IRF com método 'cholesky' e horizonte de 10-20 períodos.",
                                    "Plotar IRF com intervalos de confiança bootstrap.",
                                    "Exportar matriz de IRF para análise numérica."
                                  ],
                                  "verification": "Gerar e plotar IRF para um choque em uma variável e confirmar que respostas somem a zero em sistemas cointegrados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Python (statsmodels, pandas, matplotlib), Jupyter Notebook, conjunto de dados macroeconômicos.",
                                  "tips": "Sempre inclua intervalos de confiança para validar significância.",
                                  "learningObjective": "Dominar a computação prática de IRF em Python.",
                                  "commonMistakes": "Escolher ordem lag inadequada, distorcendo respostas dinâmicas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar Funções de Impulso-Resposta",
                                  "subSteps": [
                                    "Analisar pico, persistência e sinal da resposta a um choque unitário.",
                                    "Comparar respostas cruzadas vs. próprias (ex: choque em PIB afeta inflação?).",
                                    "Discutir assimetrias e reversão à média em sistemas cointegrados.",
                                    "Quantificar magnitude: % de desvio após n períodos.",
                                    "Relacionar com teoria econômica (ex: overshooting em câmbio)."
                                  ],
                                  "verification": "Escrever relatório de 200 palavras interpretando 3 IRF chave de um modelo estimado.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Gráficos IRF gerados, notas teóricas de Lütkepohl.",
                                  "tips": "Foque em horizontes econômicos relevantes (1-8 trimestres).",
                                  "learningObjective": "Desenvolver habilidade de interpretação econômica de dinâmicas.",
                                  "commonMistakes": "Interpretar respostas sem confiança estatística."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e Interpretar Decomposição de Variância (FEVD)",
                                  "subSteps": [
                                    "Gerar FEVD do modelo VAR com mesmo horizonte de IRF.",
                                    "Calcular % de variância explicada por cada choque em cada horizonte.",
                                    "Plotar FEVD como heatmaps ou linhas empilhadas.",
                                    "Analisar convergência para longo prazo em cointegrados.",
                                    "Comparar FEVD com IRF para validação."
                                  ],
                                  "verification": "Identificar qual variável explica mais variância de outra em h=8.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Código Python estendido, software de visualização (seaborn).",
                                  "tips": "Normalize FEVD para somar 100% por horizonte.",
                                  "learningObjective": "Entender contribuições relativas de choques à incerteza de previsões.",
                                  "commonMistakes": "Confundir FEVD com causalidade Granger."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integrar Análise em Relatório e Sensibilidade",
                                  "subSteps": [
                                    "Combinar IRF e FEVD em narrativa coesa.",
                                    "Testar robustez: diferentes ortogonalizações ou subamostras.",
                                    "Discutir limitações em cointegrados (usar VECM.IRF se necessário).",
                                    "Simular cenários de política com choques.",
                                    "Documentar código e resultados reproduzíveis."
                                  ],
                                  "verification": "Produzir relatório final com plots, tabelas e conclusões acionáveis.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Notebook completo, LaTeX ou Markdown para relatório.",
                                  "tips": "Use versionamento Git para rastrear mudanças em parâmetros.",
                                  "learningObjective": "Sintetizar análise para insights práticos.",
                                  "commonMistakes": "Sobre-generalizar resultados sem testes de sensibilidade."
                                }
                              ],
                              "practicalExample": "Em dados trimestrais de PIB real e inflação dos EUA (1980-2020), analisar IRF de um choque de 1% na inflação sobre o PIB: resposta negativa inicial (custo de recessão), pico em -0.5% no trimestre 4, revertendo em 12 trimestres. FEVD mostra inflação explicando 25% da variância do PIB em h=8.",
                              "finalVerifications": [
                                "IRF mostram reversão à equilíbrio em sistemas cointegrados.",
                                "FEVD somam 100% por horizonte e variável.",
                                "Intervalos de confiança excluem zero em respostas significativas.",
                                "Interpretação alinhada com teoria econômica.",
                                "Código reproduz resultados exatos.",
                                "Relatório identifica principais dinâmicas de choque."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação de VAR e geração de IRF/FEVD (80%+ match com benchmarks).",
                                "Profundidade de interpretação econômica (uso de termos como persistência, overshooting).",
                                "Qualidade visual de plots (legendas, escalas, confiança).",
                                "Robustez: testes de sensibilidade documentados.",
                                "Clareza do relatório (estrutura lógica, quantificação).",
                                "Correção teórica (distinção VAR vs. VECM)."
                              ],
                              "crossCurricularConnections": [
                                "Economia: Modelagem de ciclos econômicos e política monetária.",
                                "Estatística: Inferência bootstrap e testes de hipóteses multivariadas.",
                                "Finanças: Análise de risco em portfólios de ativos cointegrados.",
                                "Machine Learning: Previsão em séries multivariadas vs. redes neurais recorrentes."
                              ],
                              "realWorldApplication": "Bancos centrais usam IRF/FEVD para simular impactos de choques de política (ex: FED analisa elevação de juros sobre emprego); empresas de energia preveem preços de óleo e demanda com VAR para hedging."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.4.3",
                        "name": "Modelo Vetor Corretor de Erros (VECM)",
                        "description": "Representação equivalente ao VAR para sistemas cointegrados, incorporando termos de correção de erro para capturar ajustes de curto prazo rumo ao equilíbrio de longo prazo.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.4.3.1",
                            "name": "Especificar a forma do VECM",
                            "description": "Converter VAR em VECM usando relações cointegradas, definindo matrizes α (ajuste) e β (cointegrantes) com base no rank de Johansen.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Realizar o Teste de Johansen para Determinar o Rank de Cointegração",
                                  "subSteps": [
                                    "Colete dados multivariados de séries temporais não estacionárias (ex: Y_t com k variáveis).",
                                    "Selecione a ordem de lag p do VAR subjacente usando critérios como AIC ou BIC.",
                                    "Aplique o teste de Johansen (trace ou max-eigenvalue) para testar hipóteses H0: rank r = 0,1,...,k-1.",
                                    "Interprete os valores-p e determine o rank r estimado (número de relações cointegradas).",
                                    "Registre o rank r e os autovalores para justificar a escolha."
                                  ],
                                  "verification": "Valores-p do teste de Johansen mostram rejeição até r, mas não além; rank r documentado.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Software R (pacote 'urca'), Python (statsmodels.tsa.vector_ar.vecm), dados sample como PIB e consumo.",
                                  "tips": "Use teste trace para robustez; considere determinísticos (constante, tendência) no teste.",
                                  "learningObjective": "Identificar o número de relações cointegradas r usando estatísticas de Johansen.",
                                  "commonMistakes": "Ignorar a ordem de lag p ou não ajustar por determinísticos, levando a rank superestimado."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar e Estimar a Matriz β de Cointegração",
                                  "subSteps": [
                                    "Defina o espaço de cointegração: β é matriz k x r com rank r.",
                                    "Estime β via máxima verossimilhança restrita (Johansen ML) ou redução de eigenvalues.",
                                    "Normalize β (ex: primeira variável =1) e teste restrições lineares se necessário.",
                                    "Interprete os vetores cointegrantes: verifique estacionariedade de β' Y_{t-1}.",
                                    "Documente β e seus intervalos de confiança."
                                  ],
                                  "verification": "Matriz β estimada tem rank r; β' Y_{t-1} é estacionária (teste ADF unitário).",
                                  "estimatedTime": "2 horas",
                                  "materials": "R ('urca::cajorls'), Python (statsmodels), dados do passo 1.",
                                  "tips": "Comece com normalização simples; use 'cajorls' no R para just-identified case.",
                                  "learningObjective": "Construir a matriz β que define as combinações lineares estacionárias.",
                                  "commonMistakes": "Não normalizar β, causando interpretações ambíguas; superparametrização."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Definir e Estimar a Matriz α de Velocidades de Ajuste",
                                  "subSteps": [
                                    "α é matriz k x r; interprete como velocidades de ajuste às disequilíbrios cointegrados.",
                                    "Estime α via Johansen ML, separadamente ou conjuntamente com β.",
                                    "Teste hipóteses: α = 0 (ausência de ajuste) ou restrições de exclusão.",
                                    "Analise sinais e significância: α <0 para variáveis de equilíbrio.",
                                    "Combine α e β para formar Π = α β'."
                                  ],
                                  "verification": "α tem rank r; elementos significativos (t-test); Π = α β' correta.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": "Mesmo software do passo 2; output de Johansen.",
                                  "tips": "Verifique se α_i ≠0 para variáveis endógenas; use testes LR para restrições.",
                                  "learningObjective": "Determinar como as variáveis ajustam aos erros de cointegração via α.",
                                  "commonMistakes": "Confundir α com β; ignorar testes de significância de α."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Especificar a Forma Final do VECM a partir do VAR",
                                  "subSteps": [
                                    "Comece com VAR(p): Y_t = μ + ∑ A_i Y_{t-i} + ε_t.",
                                    "Converta para VECM: ΔY_t = μ + ∑_{i=1}^{p-1} Γ_i ΔY_{t-i} + α β' Y_{t-1} + ε_t.",
                                    "Compute Γ_i = -Π + ∑_{j=1}^i A_j para i=1,...,p-1.",
                                    "Inclua determinísticos e lags conforme teste.",
                                    "Implemente e estime o VECM completo no software."
                                  ],
                                  "verification": "Equação VECM estima corretamente; resíduos brancos e sem autocorrelação (teste LM).",
                                  "estimatedTime": "2 horas",
                                  "materials": "R ('urca::vecm'), Python (statsmodels.tsa.vector_ar.VECM); VAR residuals.",
                                  "tips": "Use função VECM built-in após Johansen; valide Γ_i manualmente para p pequeno.",
                                  "learningObjective": "Transformar VAR em VECM usando Π = α β' e especificar todos os termos.",
                                  "commonMistakes": "Erro na reparametrização de Γ_i; omitir lags de diferenças."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Documentar a Especificação do VECM",
                                  "subSteps": [
                                    "Teste diagnósticos: normalidade, heterocedasticidade, estabilidade (raízes <1).",
                                    "Compare com VAR irrestrito via teste LR.",
                                    "Interprete economicamente: ajuste α, relações β.",
                                    "Gere previsões curtas e compare com dados.",
                                    "Documente modelo completo com equações e outputs."
                                  ],
                                  "verification": "Todos diagnósticos passam; LR test não rejeita restrições cointegradas.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Funções de diagnóstico no software; plots de resíduos.",
                                  "tips": "Use 'stability' no R; foque em previsões in-sample primeiro.",
                                  "learningObjective": "Garantir que o VECM especificado é válido e bem-ajustado.",
                                  "commonMistakes": "Ignorar diagnósticos, levando a modelo inválido; overfit com r alto."
                                }
                              ],
                              "practicalExample": "Usando dados mensais de PIB real (y1) e taxa de juros (y2) de 1980-2020 no Brasil. Teste Johansen dá r=1. β' = [1, -0.5] (PIB ajusta a juros). α = [-0.02, 0.01]', VECM: Δy1 = ... -0.02*(y1_{t-1} -0.5 y2_{t-1}) + ...",
                              "finalVerifications": [
                                "Rank r determinado corretamente pelo Johansen (valores-p consistentes).",
                                "Matrizes α e β estimadas com rank r e significância.",
                                "Forma VECM derivada corretamente do VAR com Γ_i precisos.",
                                "Diagnósticos residuais: sem autocorrelação, normalidade aproximada.",
                                "Interpretação econômica coerente (ex: sinais de α esperados).",
                                "Previsões in-sample validam o modelo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação de r via Johansen (erro <10% em simulações).",
                                "Correta decomposição Π = α β' com testes de restrição passados.",
                                "Implementação computacional sem erros (reprodutível).",
                                "Interpretação qualitativa de α e β (econômica/financeira).",
                                "Diagnósticos completos e interpretação.",
                                "Documentação clara da especificação final."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Extensão de VAR/ARIMA para não-estacionárias.",
                                "Economia: Modelagem de equilíbrio de longo prazo (ex: IS-LM cointegrado).",
                                "Finanças: Preços de ativos cointegrados (pares trading).",
                                "Estatística: Inferência em modelos de alta dimensão.",
                                "Programação: Otimização numérica em ML (MLE Johansen)."
                              ],
                              "realWorldApplication": "Em bancos centrais, especificar VECM para prever inflação e PIB cointegrados, auxiliando política monetária; em finanças, modelar spreads de yields para arbitragem estatística."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.2.1"
                            ]
                          },
                          {
                            "id": "10.1.5.4.3.2",
                            "name": "Estimar e interpretar VECM",
                            "description": "Estimar parâmetros por máxima verossimilhança, analisar velocidade de ajuste via coeficientes α e relações de longo prazo via β, aplicando em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparação dos dados e testes de cointegração",
                                  "subSteps": [
                                    "Coletar dados multivariados de séries temporais estacionárias em diferenças, como produção industrial e consumo de energia.",
                                    "Realizar testes de raiz unitária (ADF, KPSS) em níveis e diferenças para confirmar não-estacionariedade e estacionariedade em diferenças.",
                                    "Aplicar teste de Johansen para cointegração, determinando o rank r do vetor de cointegração.",
                                    "Selecionar o lag ótimo usando critérios AIC/BIC.",
                                    "Transformar dados em formato adequado para VECM (matriz de diferenças e níveis)."
                                  ],
                                  "verification": "Testes confirmam cointegração (p-valor < 0.05) e lag selecionado; gráficos mostram relações de longo prazo.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Software R (pacotes urca, vars, tseries)",
                                    "Dados de exemplo de engenharia (ex: IBGE ou EPE)"
                                  ],
                                  "tips": "Sempre normalize os dados e verifique multicolinearidade antes dos testes.",
                                  "learningObjective": "Preparar dados adequadamente para modelagem VECM, identificando cointegração.",
                                  "commonMistakes": [
                                    "Ignorar testes de estacionariedade levando a especificação errada",
                                    "Escolher lag inadequado sem critérios informativos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificação do modelo VECM",
                                  "subSteps": [
                                    "Definir a ordem do modelo VAR em níveis para derivar VECM.",
                                    "Especificar a forma restrita do VECM: ΔYt = α β' Yt-1 + Γ ΔYt-1 + ... + εt.",
                                    "Determinar restrições em α e β baseadas no rank r (ex: identificação just-identificada).",
                                    "Incluir determinísticos (constante, tendência) conforme teste.",
                                    "Configurar equação para máxima verossimilhança condicional ou irrestrita."
                                  ],
                                  "verification": "Modelo especificado com rank r correto e lag, sem erros de sintaxe no código.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Documentação de urca::cajorls()",
                                    "Notas teóricas de Johansen (1988)"
                                  ],
                                  "tips": "Use ca.jo() no R para automação inicial da especificação.",
                                  "learningObjective": "Especificar corretamente a estrutura VECM com base em testes prévios.",
                                  "commonMistakes": [
                                    "Confundir rank r com número de variáveis",
                                    "Omitir termos de determinísticos levando a viés"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimação dos parâmetros por máxima verossimilhança",
                                  "subSteps": [
                                    "Executar estimação com cajorls() ou VECM() no R para obter α, β, Γ.",
                                    "Calcular matriz de covariância de resíduos para inferência.",
                                    "Verificar convergência do otimizador de ML.",
                                    "Extrair coeficientes α (ajuste de erro) e β (cointegração de longo prazo).",
                                    "Armazenar resultados em objeto para análise posterior."
                                  ],
                                  "verification": "Parâmetros estimados com valores finitos, p-valores computados e sem warnings de convergência.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R com pacotes urca, tsDyn",
                                    "Dados preparados do Step 1"
                                  ],
                                  "tips": "Use método 'ML' explícito para máxima verossimilhança; teste sensibilidade a lags.",
                                  "learningObjective": "Estimar VECM usando máxima verossimilhança e extrair parâmetros chave.",
                                  "commonMistakes": [
                                    "Usar OLS em vez de ML, invalidando inferência",
                                    "Ignorar restrições de identificação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretação e análise dos resultados",
                                  "subSteps": [
                                    "Interpretar α: sinais negativos indicam velocidade de ajuste à equilíbrio (ex: |α| > 0.1 sugere ajuste rápido).",
                                    "Analisar β: relações de longo prazo (ex: β1/β2 = -elasticidade entre variáveis).",
                                    "Calcular half-life de ajuste: ln(0.5)/ln(1+α).",
                                    "Plotar impulsos-resposta e variância decomposição para dinâmica.",
                                    "Testar hipóteses em α e β (LR test)."
                                  ],
                                  "verification": "Relatório com interpretações claras de α, β e half-life; gráficos gerados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Funções plot() e irf() no urca",
                                    "Planilha para half-life"
                                  ],
                                  "tips": "Normalize β para interpretação econômica intuitiva.",
                                  "learningObjective": "Interpretar economicamente α (ajuste curto prazo) e β (equilíbrio longo prazo).",
                                  "commonMistakes": [
                                    "Interpretar α como positiva sem checar sinal",
                                    "Confundir β normalizado com não-normalizado"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validação e diagnósticos do modelo",
                                  "subSteps": [
                                    "Testar resíduos para autocorrelação (Ljung-Box), normalidade (JB) e heteroscedasticidade.",
                                    "Verificar estabilidade com raízes do polinômio característico dentro do círculo unitário.",
                                    "Realizar testes de especificação (ex: LR para restrições em α/β).",
                                    "Comparar com VAR irrestrito via teste de cointegração.",
                                    "Documentar relatório final com conclusões."
                                  ],
                                  "verification": "Todos testes diagnósticos aprovados (p > 0.05 onde aplicável); modelo estável.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Funções stability() e serial.test() no urca"
                                  ],
                                  "tips": "Se falhar diagnósticos, ajuste lags ou adicione variáveis exógenas.",
                                  "learningObjective": "Validar VECM para garantir robustez e confiabilidade.",
                                  "commonMistakes": [
                                    "Ignorar resíduos correlacionados invalidando modelo",
                                    "Não testar estabilidade levando a previsões erradas"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de engenharia brasileira (produção industrial Y1 e consumo de energia Y2, 2000-2020), teste Johansen confirma r=1. VECM estima α1=-0.15 (ajuste rápido de produção a excesso de energia), β=[1, -0.8] indicando que 1% a mais de energia correlaciona com 0.8% menos produção no longo prazo. Half-life: 4.6 trimestres.",
                              "finalVerifications": [
                                "Testes de cointegração e estacionariedade corretos.",
                                "Parâmetros α e β estimados e interpretados com sinais e magnitudes adequadas.",
                                "Half-life de ajuste calculado e plausível.",
                                "Diagnósticos de resíduos aprovados.",
                                "Gráficos de impulsos-resposta gerados e analisados.",
                                "Relatório com aplicação em contexto de engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação ML (coerente com urca standard output).",
                                "Interpretação correta de α (velocidade de ajuste) e β (longo prazo).",
                                "Uso apropriado de testes diagnósticos e correções.",
                                "Qualidade dos gráficos e exemplos práticos.",
                                "Clareza no relatório final com half-life e implicações.",
                                "Eficiência temporal (dentro de 8-10 horas totais)."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Modelos VAR/VECM em previsões econômicas.",
                                "Engenharia Elétrica: Análise de séries em monitoramento de redes.",
                                "Estatística Computacional: Otimização ML em grandes dados.",
                                "Economia de Energia: Relações cointegradas em políticas sustentáveis.",
                                "Análise de Sistemas: Dinâmicas de ajuste em controle de processos."
                              ],
                              "realWorldApplication": "Em engenharia, VECM é usado para modelar relações cointegradas em sistemas como previsão de demanda de energia vs. produção industrial, otimizando alocação de recursos e detectando desvios de equilíbrio em tempo real para manutenção preditiva em redes elétricas."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.3.1",
                              "10.1.5.4.1.3"
                            ]
                          },
                          {
                            "id": "10.1.5.4.3.3",
                            "name": "Diagnosticar e validar modelo VECM",
                            "description": "Verificar resíduos estacionários, normalidade, autocorrelação e homocedasticidade; testar restrições em α e β para identificação econômica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o modelo VECM ajustado e extrair resíduos",
                                  "subSteps": [
                                    "Confirmar que o modelo VECM foi estimado corretamente com teste de Johansen para cointegration rank.",
                                    "Extrair os resíduos do modelo VECM usando a função apropriada no software (ex: residuals() no R).",
                                    "Verificar dimensões e ausência de valores ausentes nos resíduos.",
                                    "Plotar séries de resíduos para inspeção visual inicial.",
                                    "Salvar resíduos em formato adequado para testes subsequentes."
                                  ],
                                  "verification": "Resíduos extraídos sem erros e plots mostram ausência óbvia de tendências ou não-estacionariedade.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Software R (pacotes urca, tsDyn) ou Python (statsmodels)",
                                    "Dados de séries temporais cointegradas (ex: PIB e inflação)"
                                  ],
                                  "tips": "Sempre use o número de lags otimizado pelo critério AIC/BIC para evitar resíduos enviesados.",
                                  "learningObjective": "Preparar resíduos confiáveis para diagnósticos subsequentes.",
                                  "commonMistakes": [
                                    "Usar resíduos brutos em vez de padronizados",
                                    "Ignorar verificação de missing values",
                                    "Não plotar resíduos inicialmente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Verificar estacionariedade dos resíduos",
                                  "subSteps": [
                                    "Aplicar teste Augmented Dickey-Fuller (ADF) univariado em cada resíduo.",
                                    "Realizar teste Johansen de trace ou max-eigen para resíduos multivariados.",
                                    "Selecionar lags apropriados no teste ADF (ex: via AIC).",
                                    "Calcular e interpretar p-valores.",
                                    "Rejeitar H0 se p < 0.05 para todos os resíduos."
                                  ],
                                  "verification": "Todos os testes ADF/Johansen rejeitam H0 de não-estacionariedade (p < 0.05).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Funções adf.test() no R ou adfuller() no Python statsmodels"
                                  ],
                                  "tips": "Inclua constante e tendência se apropriado; teste múltiplos lags para robustez.",
                                  "learningObjective": "Aplicar testes de raiz unitária em resíduos de VECM para validar especificação.",
                                  "commonMistakes": [
                                    "Não testar todos os resíduos individualmente",
                                    "Ignorar tamanho da amostra pequeno",
                                    "Confundir H0 do teste ADF"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Testar normalidade e autocorrelação dos resíduos",
                                  "subSteps": [
                                    "Aplicar teste Jarque-Bera para normalidade multivariada.",
                                    "Realizar teste Ljung-Box ou Breusch-Godfrey para autocorrelação serial.",
                                    "Verificar resíduos cruzados com teste de Portmanteau.",
                                    "Interpretar estatísticas e p-valores.",
                                    "Documentar resultados em tabela."
                                  ],
                                  "verification": "Jarque-Bera não rejeita normalidade (p > 0.05) e testes de autocorrelação rejeitam presença (p > 0.05).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacotes strucchange ou vars no R; statsmodels no Python"
                                  ],
                                  "tips": "Normalidade é fraca em amostras pequenas; foque em rejeitar autocorrelação.",
                                  "learningObjective": "Diagnosticar violações de pressupostos iid nos resíduos.",
                                  "commonMistakes": [
                                    "Usar testes univariados para normalidade multivariada",
                                    "Poucos lags no Ljung-Box",
                                    "Interpretar p-valores ao contrário"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar homocedasticidade e restrições em α e β",
                                  "subSteps": [
                                    "Aplicar teste ARCH-LM para heteroscedasticidade condicional.",
                                    "Testar restrições lineares em α (matriz de ajuste) via Wald test.",
                                    "Testar restrições em β (vetores de cointegration) para identificação econômica.",
                                    "Usar teste LR para restrições conjuntas.",
                                    "Interpretar significância econômica das restrições."
                                  ],
                                  "verification": "ARCH-LM não rejeita homocedasticidade (p > 0.05) e restrições em α/β são válidas (p > 0.05 ou teoricamente justificadas).",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "Funções arch.test() no R (FinTS); linearHypothesis() no car package"
                                  ],
                                  "tips": "Justifique restrições econômicas antes de testar; use bootstrap para robustez.",
                                  "learningObjective": "Validar identificação econômica via testes de restrições.",
                                  "commonMistakes": [
                                    "Não especificar H0 corretas para restrições",
                                    "Ignorar multicolinearidade em β",
                                    "Testar sem teoria econômica"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e validar modelo globalmente",
                                  "subSteps": [
                                    "Compilar todos os resultados em relatório.",
                                    "Verificar estabilidade do modelo com raízes características.",
                                    "Realizar previsões out-of-sample para validação.",
                                    "Comparar com modelo VAR para superioridade.",
                                    "Documentar conclusões e sugestões de reespecificação."
                                  ],
                                  "verification": "Modelo passa em todos os testes e raízes estão dentro do círculo unitário.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Plots de raízes (roots() no R)",
                                    "Dados de hold-out para previsão"
                                  ],
                                  "tips": "Sempre valide com previsão; VECM deve outperform VAR se cointegrado.",
                                  "learningObjective": "Sintetizar diagnósticos para decisão final sobre validade do modelo.",
                                  "commonMistakes": [
                                    "Ignorar instabilidade de raízes",
                                    "Não testar previsões",
                                    "Aceitar modelo sem interpretação econômica"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados trimestrais de PIB real e índice de preços ao consumidor (IPCA) do Brasil (2000-2023). Estime um VECM(1) com rank de cointegration 1. Extraia resíduos, aplique ADF (p=0.01), Jarque-Bera (p=0.12), Ljung-Box (p=0.45), ARCH-LM (p=0.23), e teste restrição β=[1,-1] para paridade de longo prazo (Wald p=0.08). Modelo validado para análise de política monetária.",
                              "finalVerifications": [
                                "Resíduos estacionários por ADF/Johansen (p < 0.05)",
                                "Ausência de autocorrelação (Ljung-Box p > 0.05)",
                                "Normalidade aceitável (Jarque-Bera p > 0.05)",
                                "Homocedasticidade (ARCH-LM p > 0.05)",
                                "Restrições em α e β economicamente identificáveis (testes p > 0.05 ou justificadas)",
                                "Raízes características dentro do círculo unitário"
                              ],
                              "assessmentCriteria": [
                                "Aplicação correta de todos os testes estatísticos com lags apropriados",
                                "Interpretação precisa de p-valores e hipóteses nulas",
                                "Documentação completa de resultados com tabelas/plots",
                                "Justificativa econômica para restrições testadas",
                                "Validação global incluindo estabilidade e previsões",
                                "Identificação de potenciais reespecificações se falhas"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e distribuições assintóticas",
                                "Econometria: Modelos VAR/VECM e cointegration",
                                "Programação: Manipulação de ts objects em R/Python",
                                "Economia: Identificação de equilíbrio de longo prazo",
                                "Matemática Computacional: Otimização numérica em estimação ML"
                              ],
                              "realWorldApplication": "Bancos centrais e instituições financeiras usam diagnósticos de VECM para validar modelos de previsão macroeconômica, como impactos de choques monetários na inflação e crescimento, auxiliando decisões de política fiscal e monetária em cenários de divergência de longo prazo."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.3.2"
                            ]
                          },
                          {
                            "id": "10.1.5.4.3.4",
                            "name": "Aplicar VECM em análise de engenharia",
                            "description": "Usar VECM para modelar sistemas dinâmicos cointegrados, como relações entre variáveis de controle e sensores, integrando com ferramentas R.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar Dados e Testar Cointegração",
                                  "subSteps": [
                                    "Coletar dados multivariados de séries temporais relevantes, como variáveis de sensores e controles em um sistema de engenharia.",
                                    "Verificar estacionariedade usando testes ADF ou KPSS para cada série.",
                                    "Realizar teste de cointegration Johansen para determinar o rank de cointegration.",
                                    "Identificar lag order usando critérios AIC/BIC.",
                                    "Preparar a matriz de dados no formato adequado para VECM."
                                  ],
                                  "verification": "Testes de estacionariedade e cointegration produzem resultados significativos (p-value < 0.05) e lag order selecionado.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Dados de sensores (CSV), R com pacotes urca, vars, tseries",
                                  "tips": "Sempre diferencie séries não estacionárias antes de testar cointegration para evitar falsos positivos.",
                                  "learningObjective": "Compreender pré-requisitos de dados para VECM e validar cointegration.",
                                  "commonMistakes": "Ignorar testes de estacionariedade, levando a modelos inválidos; usar lags inadequados."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar e Estimar o Modelo VECM",
                                  "subSteps": [
                                    "Definir a ordem de lag e rank de cointegration com base no Step 1.",
                                    "Especificar o modelo VECM usando função cajorls() ou vec2var() no pacote urca.",
                                    "Estimar parâmetros do modelo, incluindo matriz de cointegration alpha e beta.",
                                    "Incorporar determinísticos como tendência linear se aplicável ao contexto de engenharia.",
                                    "Converter VECM para VAR em diferenças para análise adicional."
                                  ],
                                  "verification": "Modelo estimado sem erros de convergência; matrizes alpha e beta geradas com valores coerentes.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": "R script com dados preparados, pacotes urca e vars",
                                  "tips": "Use restrições just-identified na matriz beta se houver teoria econômica/engenheira guiando relações de longo prazo.",
                                  "learningObjective": "Dominar estimação de parâmetros VECM para sistemas cointegrados.",
                                  "commonMistakes": "Selecionar rank de cointegration errado, superparametrizando o modelo."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diagnosticar e Interpretar o Modelo",
                                  "subSteps": [
                                    "Testar resíduos para autocorrelação (Ljung-Box), normalidade (Jarque-Bera) e heteroscedasticidade.",
                                    "Analisar impulso-resposta (IRF) e decomposição de variância de erro previsional (FEVD).",
                                    "Interpretar coeficientes de correção de erro (alpha) e relações de longo prazo (beta).",
                                    "Verificar estabilidade do modelo com raízes características dentro do círculo unitário.",
                                    "Ajustar modelo se diagnósticos falharem (e.g., adicionar lags)."
                                  ],
                                  "verification": "Todos testes de diagnóstico passam (p-values > 0.05 para resíduos brancos); gráficos IRF estáveis.",
                                  "estimatedTime": "2 horas",
                                  "materials": "R com pacotes urca, vars; funções como stability() e serial.test()",
                                  "tips": "Plote IRF com intervalos de confiança para visualização intuitiva em contextos de engenharia.",
                                  "learningObjective": "Avaliar validade e interpretar dinâmicas de curto e longo prazo no VECM.",
                                  "commonMistakes": "Não testar resíduos, assumindo modelo bom; ignorar instabilidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Análise de Engenharia e Prever",
                                  "subSteps": [
                                    "Integrar VECM com dados reais de engenharia, como controle de temperatura e pressão em um reator.",
                                    "Gerar previsões de curto prazo usando predict() no modelo VAR equivalente.",
                                    "Simular cenários de choque (e.g., falha de sensor) via IRF.",
                                    "Validar previsões com dados out-of-sample.",
                                    "Documentar insights para otimização de sistemas de controle."
                                  ],
                                  "verification": "Previsões alinhadas com dados reais (MAPE < 10%); simulações mostram correções de desvio de equilíbrio.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Dados de engenharia reais/simulados, R para previsão e simulação",
                                  "tips": "Use VECM para feedback em loops de controle, prevendo desvios de equilíbrio cointegrado.",
                                  "learningObjective": "Aplicar VECM na resolução de problemas de engenharia dinâmica.",
                                  "commonMistakes": "Extrapolação excessiva sem validação out-of-sample."
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de HVAC (aquecimento, ventilação e ar condicionado), use VECM para modelar a cointegration entre temperatura ambiente (sensor T1) e umidade relativa (sensor T2), prevendo ajustes de ventilador para manter equilíbrio termodinâmico. Colete dados horários por 1 ano, teste cointegration, estime VECM e simule resposta a um pico de temperatura.",
                              "finalVerifications": [
                                "Teste Johansen confirma cointegration (trace statistic significativo).",
                                "Resíduos do modelo são brancos e normais (todos diagnósticos passam).",
                                "Raízes características dentro do círculo unitário (estabilidade).",
                                "Previsões out-of-sample com erro baixo (RMSE < threshold de engenharia).",
                                "Interpretação coerente com teoria de controle (correção de erro negativa).",
                                "IRF mostram convergência para equilíbrio de longo prazo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação de cointegration e parâmetros VECM.",
                                "Qualidade dos diagnósticos de modelo (todos testes aprovados).",
                                "Interpretação correta de alpha, beta e dinâmicas de curto/longo prazo.",
                                "Relevância da aplicação ao contexto de engenharia (integração com sensores/controle).",
                                "Efetividade das previsões e simulações (métricas quantitativas).",
                                "Clareza na documentação e código R reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e inferência em séries temporais.",
                                "Programação: Manipulação de dados e modelagem em R (pacotes urca/vars).",
                                "Engenharia de Controle: Modelos dinâmicos e feedback loops.",
                                "Econometria: Extensão de modelos VAR/VECM para não-financeiros.",
                                "Análise de Dados: Pré-processamento e validação multivariada."
                              ],
                              "realWorldApplication": "Na engenharia estrutural, VECM modela cointegration entre vibrações de sensores em pontes e vento/força sísmica, permitindo detecção precoce de fadiga e otimização de manutenção preditiva; em processos industriais, integra com PLCs para controle cointegrado de variáveis como pressão e fluxo em refinarias."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.5.4.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.5.5",
                    "name": "Modelos Vetoriais Autoregressivos (VAR)",
                    "description": "Modelos VAR para análise multivariada de séries temporais e impulsos-resposta.",
                    "individualConcepts": [
                      {
                        "id": "10.1.5.5.1",
                        "name": "Estrutura do Modelo VAR",
                        "description": "Definição e representação matricial do modelo Vetorial Autoregressivo (VAR), que modela múltiplas séries temporais endógenas como funções lineares de seus próprios valores passados, capturando interdependências dinâmicas em contextos multivariados de econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.5.1.1",
                            "name": "Definir a forma geral do modelo VAR(p)",
                            "description": "Explicar a equação matricial Y_t = A_1 Y_{t-1} + ... + A_p Y_{t-p} + ε_t, identificando variáveis endógenas, coeficientes de lag e termo de erro, com exemplos em dados econômicos ou de engenharia como PIB e produção industrial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de Modelos VAR",
                                  "subSteps": [
                                    "Revise séries temporais univariadas AR(p) e estenda para multivariadas.",
                                    "Defina variáveis endógenas como um vetor Y_t de dimensão kx1 representando múltiplas séries interdependentes.",
                                    "Explique o conceito de lags p, onde o modelo usa os últimos p períodos para previsão.",
                                    "Descreva o termo de erro ε_t como um vetor de ruído branco multivariado com covariância Σ.",
                                    "Discuta a ausência de exógenas na forma pura VAR(p)."
                                  ],
                                  "verification": "Liste e defina as quatro componentes principais (Y_t, A_i Y_{t-i}, p, ε_t) com dimensões corretas.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notas sobre séries temporais",
                                    "Capítulo de econometria sobre VAR (ex: Stock & Watson)"
                                  ],
                                  "tips": [
                                    "Pense em Y_t como um 'time-step' em um videogame com múltiplos personagens interligados."
                                  ],
                                  "learningObjective": "Identificar e explicar os blocos conceituais básicos do modelo VAR(p).",
                                  "commonMistakes": [
                                    "Confundir endógenas com exógenas.",
                                    "Ignorar que ε_t é vetorial e correlacionado."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Construir a Equação Matricial Geral do VAR(p)",
                                  "subSteps": [
                                    "Escreva Y_t = soma de i=1 a p de A_i Y_{t-i} + ε_t.",
                                    "Especifique que cada A_i é uma matriz kxk de coeficientes de lag i.",
                                    "Confirme dimensionalidade: lado esquerdo kx1, cada termo A_i Y_{t-i} kx1, ε_t kx1.",
                                    "Inclua a suposição de estacionariedade para os processos Y_t.",
                                    "Reescreva em forma compacta matricial para múltiplas equações simultâneas."
                                  ],
                                  "verification": "Escreva a equação completa em LaTeX ou notação e verifique se soma dimensionalmente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Papel e caneta para equações",
                                    "Software como R ou Python para visualizar notação"
                                  ],
                                  "tips": [
                                    "Construa do univariado para multivariado passo a passo para evitar confusão."
                                  ],
                                  "learningObjective": "Formular matematicamente a estrutura geral do modelo VAR(p).",
                                  "commonMistakes": [
                                    "Escrever escalares em vez de vetores/matrizes.",
                                    "Errar o índice de lag (t-i)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar os Componentes e Parâmetros do Modelo",
                                  "subSteps": [
                                    "Explique Y_t como variáveis endógenas tratadas simetricamente (ex: PIB e inflação interagem).",
                                    "Descreva A_i(j,l) como o impacto da l-ésima variável no lag i sobre a j-ésima variável atual.",
                                    "Discuta ε_t: média zero, não-autocorrelacionado, mas possivelmente correlacionado entre equações.",
                                    "Identifique p como ordem do modelo, escolhida por critérios como AIC/BIC.",
                                    "Aborde intercepto opcional: Y_t = c + soma A_i Y_{t-i} + ε_t."
                                  ],
                                  "verification": "Para um A_1(2,1), explique seu significado econômico em contexto bivariado.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Exemplos de dados econômicos (FRED database)",
                                    "Tabela de símbolos VAR"
                                  ],
                                  "tips": [
                                    "Use Impulse Response Functions (IRF) intuitivamente para entender A_i."
                                  ],
                                  "learningObjective": "Interpretar economicamente ou engenheiristicamente cada parâmetro.",
                                  "commonMistakes": [
                                    "Assumir independência entre ε_t componentes.",
                                    "Confundir ordem p com número de variáveis k."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar a Forma Geral a Dados Reais Simples",
                                  "subSteps": [
                                    "Selecione dados bivariados: PIB_t e Produção Industrial_t de uma base como FRED.",
                                    "Defina Y_t = [PIB_t, ProdInd_t]^T e especifique VAR(2).",
                                    "Escreva explicitamente as duas equações: PIB_t = a11 PIB_{t-1} + a12 ProdInd_{t-1} + ... + ε1_t.",
                                    "Simule ou plote dados para visualizar lags e erros.",
                                    "Verifique estacionariedade com teste ADF em cada componente."
                                  ],
                                  "verification": "Construa e escreva o modelo VAR(2) para os dados escolhidos.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Dados FRED (PIB, IP)",
                                    "R com pacote vars ou Python statsmodels"
                                  ],
                                  "tips": [
                                    "Comece com p=1 para simplicidade antes de expandir."
                                  ],
                                  "learningObjective": "Aplicar a definição geral a um caso concreto econômico/engenharia.",
                                  "commonMistakes": [
                                    "Usar dados não-estacionários sem diferenciar.",
                                    "Ignorar normalização de séries (log ou %)."
                                  ]
                                }
                              ],
                              "practicalExample": "Para dados de PIB (y1_t) e Produção Industrial (y2_t), o VAR(1) é: [y1_t; y2_t] = [a11, a12; a21, a22] [y1_{t-1}; y2_{t-1}] + [ε1_t; ε2_t]. Aqui, a12 mede quanto a produção lagged afeta PIB atual, útil para prever recessões.",
                              "finalVerifications": [
                                "Escreve corretamente Y_t = ∑_{i=1}^p A_i Y_{t-i} + ε_t?",
                                "Identifica dimensões: Y kx1, A_i kxk?",
                                "Explica papel de endógenas, lags e erro?",
                                "Aplica a um exemplo bivariado econômico?",
                                "Discute suposições como ruído branco?",
                                "Menciona como escolher p?"
                              ],
                              "assessmentCriteria": [
                                "Precisão na equação matricial (100% correta).",
                                "Correta identificação e interpretação de componentes.",
                                "Uso apropriado de notação vetorial/matrizzial.",
                                "Exemplo prático relevante com dados reais.",
                                "Compreensão de dimensões e suposições.",
                                "Capacidade de estender para p>1 e k>2."
                              ],
                              "crossCurricularConnections": [
                                "Economia: Modelagem macroeconômica e previsão de ciclos.",
                                "Engenharia: Análise de sistemas dinâmicos multivariados.",
                                "Finanças: Previsão de yields e retornos de portfólio.",
                                "Estatística: Estimação por MCO e testes de causalidade Granger.",
                                "Ciência de Dados: Feature engineering em séries temporais."
                              ],
                              "realWorldApplication": "Bancos centrais como o FED usam VAR para simular impactos de choques monetários no PIB e inflação; em engenharia, modela interações entre sensores em redes IoT para detecção de falhas preditiva."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.1.2",
                            "name": "Determinar a ordem de lag p",
                            "description": "Aplicar critérios de informação como AIC, BIC ou HQIC para selecionar o número ótimo de lags em um modelo VAR, considerando estacionariedade prévia das séries via testes ADF ou KPSS.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Verificar Estacionariedade das Séries Temporais",
                                  "subSteps": [
                                    "Carregar os dados das séries temporais usando pandas.",
                                    "Executar teste ADF (Augmented Dickey-Fuller) para cada série com statsmodels.tsa.stattools.adfuller.",
                                    "Executar teste KPSS para confirmar estacionariedade com statsmodels.tsa.stattools.kpss.",
                                    "Diferenciar as séries se necessário até que ambos os testes indiquem estacionariedade (p-valor ADF < 0.05 e p-valor KPSS > 0.05)."
                                  ],
                                  "verification": "Ambos os testes ADF e KPSS confirmam estacionariedade para todas as séries (relatar p-valores).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com pandas, statsmodels",
                                    "Dados de séries temporais (ex: CSV de PIB e inflação)"
                                  ],
                                  "tips": "Sempre teste em níveis primeiro; use gráficos de ACF/PACF para suporte visual.",
                                  "learningObjective": "Garantir que as séries atendam aos pré-requisitos de estacionariedade para modelagem VAR.",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade levando a resultados espúrios",
                                    "Não diferenciar adequadamente",
                                    "Confundir p-valores dos testes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Determinar o Número Máximo de Lags Possíveis",
                                  "subSteps": [
                                    "Calcular o comprimento da amostra efetiva (T = len(dados) após remoção de lags).",
                                    "Usar regra de thumb: p_max = min(12, floor(T / (k * 3))) onde k é número de variáveis.",
                                    "Considerar critérios como Schwarz para limite superior ou testar até convergência.",
                                    "Definir p_max baseado em disponibilidade de dados para evitar overfitting."
                                  ],
                                  "verification": "p_max definido e justificado com base no tamanho da amostra e número de variáveis.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com numpy para cálculos",
                                    "Documentação statsmodels VAR"
                                  ],
                                  "tips": "Comece com p_max baixo (ex: 8-12) para séries trimestrais; ajuste para mensais.",
                                  "learningObjective": "Estabelecer limites práticos para busca de lags evitando perda excessiva de observações.",
                                  "commonMistakes": [
                                    "Escolher p_max muito alto causando perda de graus de liberdade",
                                    "Ignorar tamanho da amostra"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar Modelos VAR para Diferentes Ordens de Lag",
                                  "subSteps": [
                                    "Importar VAR de statsmodels.tsa.vector_ar.var_model.VAR.",
                                    "Loop sobre lags de 1 a p_max: fit_model = VAR(dados).fit(lag_order).",
                                    "Armazenar modelos em uma lista ou dicionário para comparação posterior.",
                                    "Verificar diagnósticos básicos como resíduos para cada modelo (sem correlação serial)."
                                  ],
                                  "verification": "Modelos VAR ajustados com sucesso para todos lags de 1 a p_max sem erros de convergência.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "statsmodels.tsa.vector_ar.var_model.VAR",
                                    "Jupyter Notebook para iteração"
                                  ],
                                  "tips": "Use select_order() do statsmodels para automação inicial, mas entenda o processo manual.",
                                  "learningObjective": "Construir múltiplos modelos VAR para permitir comparação de critérios de informação.",
                                  "commonMistakes": [
                                    "Não padronizar dados antes",
                                    "Esquecer de especificar exog se aplicável"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular Critérios de Informação (AIC, BIC, HQIC)",
                                  "subSteps": [
                                    "Para cada modelo ajustado, extrair aic = model.aic, bic = model.bic, hqic = model.hqic.",
                                    "Criar DataFrame comparativo com lags, AIC, BIC, HQIC e Delta (diferença do mínimo).",
                                    "Plotar os critérios vs. lags para visualização (matplotlib).",
                                    "Identificar o lag com menor valor para cada critério (AIC mais parcimonioso, BIC penaliza mais)."
                                  ],
                                  "verification": "Tabela com valores de AIC, BIC, HQIC para cada lag gerada e plotada.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "pandas para DataFrame",
                                    "matplotlib para plots"
                                  ],
                                  "tips": "BIC penaliza lags altos mais que AIC; use HQIC como compromisso.",
                                  "learningObjective": "Aplicar critérios de informação para quantificar trade-off entre fit e complexidade.",
                                  "commonMistakes": [
                                    "Confundir fórmulas (ex: log-likelihood incorreto)",
                                    "Não normalizar critérios"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Selecionar e Validar a Ordem Ótima de Lag p",
                                  "subSteps": [
                                    "Escolher p ótimo como argmin de BIC (padrão conservador) ou consenso AIC/BIC/HQIC.",
                                    "Reajustar modelo final com p selecionado e checar resíduos (Ljung-Box teste).",
                                    "Comparar previsões out-of-sample se dados disponíveis para validação.",
                                    "Documentar escolha com tabela e justificativa (ex: 'p=2 por menor BIC')."
                                  ],
                                  "verification": "Ordem p selecionada, modelo final ajustado e diagnósticos de resíduos aprovados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "statsmodels para Ljung-Box: acorr_ljungbox",
                                    "Relatório em Markdown"
                                  ],
                                  "tips": "Se critérios discordarem, priorize BIC para amostras pequenas; valide com CV.",
                                  "learningObjective": "Finalizar seleção de p com validação robusta para modelagem VAR confiável.",
                                  "commonMistakes": [
                                    "Selecionar p por AIC sem considerar BIC (overfitting)",
                                    "Ignorar diagnósticos de resíduos"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados trimestrais de PIB e taxa de desemprego dos EUA (1959-2020) do FRED: Verifique estacionariedade em 1ª diferença, defina p_max=8, ajuste VAR(1) a VAR(8), calcule critérios (ex: BIC mínimo em p=2), selecione p=2 para modelagem de choques econômicos.",
                              "finalVerifications": [
                                "Estacionariedade confirmada por ADF e KPSS em todas séries.",
                                "Tabela de critérios AIC/BIC/HQIC gerada com p ótimo identificado.",
                                "Modelo VAR(p) final ajustado sem autocorrelação em resíduos (Ljung-Box p>0.05).",
                                "Gráficos de critérios vs lags mostram mínimo claro.",
                                "Justificativa escrita para escolha de p.",
                                "Previsão de 4 períodos ahead plausível."
                              ],
                              "assessmentCriteria": [
                                "Correta aplicação de testes de estacionariedade com interpretação de p-valores.",
                                "Cálculo preciso de AIC, BIC, HQIC sem erros numéricos.",
                                "Seleção de p baseada em mínimo de critério apropriado (ex: BIC).",
                                "Validação adequada com diagnósticos de resíduos.",
                                "Documentação clara com tabelas, plots e justificativas.",
                                "Eficiência computacional no loop de lags."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses (ADF, KPSS, Ljung-Box).",
                                "Econometria: Modelos multivariados e previsão econômica.",
                                "Programação: Loops, DataFrames e visualização em Python.",
                                "Matemática: Otimização e penalização de complexidade (critérios de informação).",
                                "Ciência de Dados: Pré-processamento e validação de modelos."
                              ],
                              "realWorldApplication": "Em bancos centrais, selecionar p ótimo em VAR para simular impactos de política monetária (ex: choque de juros no PIB e inflação), ou em finanças para modelar retornos de ativos correlacionados evitando overfitting em previsões de risco."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.1.3",
                            "name": "Interpretar coeficientes em VAR",
                            "description": "Analisar os coeficientes das matrizes A_i para entender como um lag de uma variável afeta as outras, com foco em relações causais Granger em aplicações multivariadas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a Estrutura e Notação do Modelo VAR",
                                  "subSteps": [
                                    "Escreva a equação geral do modelo VAR(p): Y_t = A_1 Y_{t-1} + A_2 Y_{t-2} + ... + A_p Y_{t-p} + e_t, onde Y_t é um vetor de k variáveis.",
                                    "Identifique as matrizes A_i como k x k, onde cada entrada α_{ij}(l) representa o coeficiente do lag l da variável j na equação da variável i.",
                                    "Diferencie coeficientes próprios (i=j) de cruzados (i≠j) e explique seu papel em dinâmicas univariadas vs. multivariadas.",
                                    "Liste as variáveis no vetor Y_t para um exemplo bivariado (ex: PIB e Inflação).",
                                    "Desenhe um diagrama esquemático das matrizes A_i mostrando dependências."
                                  ],
                                  "verification": "Construa manualmente uma matriz A_1 fictícia 2x2 e explique cada entrada em termos de impacto de lag 1.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Papel e caneta ou software de desenho (ex: Draw.io)",
                                    "Documentação de modelo VAR (ex: PDF de referência)"
                                  ],
                                  "tips": [
                                    "Use notação consistente: subscrito para lag e supescrito para direção.",
                                    "Visualize matrizes como 'mapas de influência' entre variáveis."
                                  ],
                                  "learningObjective": "Compreender a notação matricial das matrizes A_i e seu significado em termos de lags e variáveis.",
                                  "commonMistakes": [
                                    "Confundir α_{ij} com α_{ji} (direção da causalidade)",
                                    "Ignorar que A_i captura apenas efeitos lineares diretos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Extrair e Analisar Magnitude e Significância dos Coeficientes",
                                  "subSteps": [
                                    "Carregue coeficientes estimados de um modelo VAR ajustado (ex: via função VAR() no R ou statsmodels no Python).",
                                    "Calcule intervalos de confiança ou valores-p para cada α_{ij}(l) usando erros padrão.",
                                    "Classifique coeficientes como significativos (p < 0.05) e interprete magnitude: 'um aumento de 1% em j_{t-l} leva a α_{ij}(l)% em i_t'.",
                                    "Compare magnitudes entre lags e variáveis para identificar padrões de persistência.",
                                    "Registre coeficientes em uma tabela organizada por equação e lag."
                                  ],
                                  "verification": "Produza uma tabela com 5 coeficientes selecionados, incluindo valor, p-valor e interpretação verbal.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Software R/Python com pacotes vars/statsmodels",
                                    "Dataset de séries temporais (ex: dados macroeconômicos do FRED)"
                                  ],
                                  "tips": [
                                    "Padronize variáveis se necessário para interpretar magnitudes diretamente.",
                                    "Sempre reporte com CIs para robustez."
                                  ],
                                  "learningObjective": "Extrair coeficientes de outputs de software e avaliar sua significância estatística e tamanho econômico.",
                                  "commonMistakes": [
                                    "Interpretar coeficientes brutos sem considerar unidades das variáveis",
                                    "Ignorar testes de significância e focar só em magnitude"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar Relações Causais e Granger Causality",
                                  "subSteps": [
                                    "Explique causalidade Granger: j Granger-causa i se coeficientes de lags de j na equação de i são conjuntamente significativos.",
                                    "Realize teste de Granger usando função grangertest() no R ou similar no Python.",
                                    "Trace Impulse Response Functions (IRFs) para visualizar efeitos dinâmicos de um choque em j sobre i.",
                                    "Identifique direções de causalidade (unidirecional, bidirecional) baseadas em testes e coeficientes.",
                                    "Discuta limitações: Granger não implica causalidade verdadeira, apenas preditiva."
                                  ],
                                  "verification": "Execute teste de Granger em um modelo bivariado e resuma resultados com interpretação causal.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Código R/Python pronto para VAR e Granger test",
                                    "Dataset bivariado exemplo (ex: PIB e Juros)"
                                  ],
                                  "tips": [
                                    "Teste múltiplos lags no VAR antes de Granger.",
                                    "Combine com IRFs para validação visual."
                                  ],
                                  "learningObjective": "Aplicar testes de Granger para inferir direções causais multivariadas a partir de coeficientes.",
                                  "commonMistakes": [
                                    "Confundir significância individual de α_{ij}(l) com causalidade conjunta",
                                    "Aplicar Granger sem stationariedade pré-teste"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Sintetizar Interpretações e Visualizar Impactos",
                                  "subSteps": [
                                    "Crie um relatório resumindo principais coeficientes: 'Lag 1 de Inflação afeta PIB com α=0.3 (p=0.01)'.",
                                    "Gere gráficos de coeficientes por lag (heatmap ou barplot das matrizes A_i).",
                                    "Discuta implicações multivariadas: ciclos de feedback entre variáveis.",
                                    "Valide com previsão out-of-sample usando os coeficientes.",
                                    "Documente insights em um dashboard ou relatório final."
                                  ],
                                  "verification": "Produza um gráfico de heatmap das matrizes A_i com legendas interpretativas e um parágrafo de síntese.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Bibliotecas de plotagem (ggplot2, matplotlib)",
                                    "Jupyter Notebook ou RMarkdown"
                                  ],
                                  "tips": [
                                    "Use heatmaps coloridos para significância (vermelho=positivo significativo).",
                                    "Mantenha síntese concisa: foque em 3-5 achados chave."
                                  ],
                                  "learningObjective": "Sintetizar análises de coeficientes em visualizações e narrativas acionáveis para aplicações multivariadas.",
                                  "commonMistakes": [
                                    "Sobrecarregar com todos coeficientes sem priorizar significativos",
                                    "Ignorar normalização em visualizações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um VAR(2) bivariado com PIB (y1) e Inflação (y2), o coeficiente α_{12}(1) = 0.25 (p<0.01) na equação de PIB significa: um choque de 1% na Inflação no t-1 aumenta o PIB em 0.25% no t, sugerindo Inflação Granger-causa PIB no curto prazo. Teste confirma F=4.2 (p=0.02).",
                              "finalVerifications": [
                                "Explicar verbalmente o significado de α_{ij}(l) em contexto multivariado.",
                                "Identificar corretamente direções de Granger causality em um output de teste.",
                                "Produzir tabela de coeficientes com interpretações precisas.",
                                "Gerar e interpretar um heatmap das matrizes A_i.",
                                "Discutir uma limitação da interpretação (ex: não causalidade exógena)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na notação e extração de coeficientes (30%)",
                                "Correta aplicação e interpretação de testes de significância/Granger (25%)",
                                "Qualidade de visualizações e síntese narrativa (20%)",
                                "Profundidade em relações multivariadas e lags (15%)",
                                "Clareza e ausência de erros comuns (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Aplicação em modelos macroeconômicos.",
                                "Estatística: Testes de hipótese conjunta e funções de resposta a impulso.",
                                "Finanças: Análise de spillovers em mercados de ativos.",
                                "Machine Learning: Extensão a VARs não-lineares ou com redes neurais."
                              ],
                              "realWorldApplication": "Em bancos centrais, interpretar coeficientes VAR auxilia na análise de transmissão de política monetária: como choques de juros afetam PIB e inflação, guiando decisões de taxa de juros para estabilizar economias."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.5.2",
                        "name": "Estimação e Inferência em Modelos VAR",
                        "description": "Métodos de estimação por Mínimos Quadrados Ordinários (MQO) para cada equação do VAR, propriedades dos estimadores e testes de inferência, assumindo erros esféricos e estacionariedade.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.5.2.1",
                            "name": "Estimar modelo VAR via MQO",
                            "description": "Implementar estimação equação por equação usando MQO em software como R, verificando pressupostos de regressão linear como ausência de autocorrelação nos resíduos via teste de Ljung-Box.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os Dados e Selecionar a Ordem de Lags",
                                  "subSteps": [
                                    "Instalar e carregar os pacotes necessários no R (ex: vars, urca)",
                                    "Importar e inspecionar os dados multivariados estacionários (ex: teste ADF prévio)",
                                    "Aplicar função VARselect() para calcular critérios de informação (AIC, BIC, HQ)",
                                    "Selecionar o número ótimo de lags com base nos critérios",
                                    "Verificar dimensões e ausência de valores ausentes"
                                  ],
                                  "verification": "Lags selecionados confirmados via output de VARselect() e dados prontos para estimação.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R e RStudio",
                                    "Pacotes: vars, urca",
                                    "Dataset multivariado estacionário (ex: Canada do pacote vars)"
                                  ],
                                  "tips": "Priorize BIC para modelos parsimoniosos em amostras pequenas.",
                                  "learningObjective": "Preparar dados multivariados adequados e determinar a lag length ótima para modelo VAR.",
                                  "commonMistakes": [
                                    "Usar dados não estacionários sem diferenciação",
                                    "Ignorar múltiplos critérios de seleção de lags",
                                    "Selecionar lags excessivos levando a sobreajuste"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estimar o Modelo VAR via MQO Equação por Equação",
                                  "subSteps": [
                                    "Definir o objeto VAR com lags selecionados e tipo='const' ou 'trend'",
                                    "Executar estimação com função VAR() que aplica OLS internamente",
                                    "Extrair coeficientes das equações individuais usando coef() e summary()",
                                    "Calcular resíduos serialmente não correlacionados",
                                    "Armazenar o modelo para diagnósticos subsequentes"
                                  ],
                                  "verification": "Coeficientes estimados via OLS exibidos corretamente sem mensagens de erro.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R com pacotes vars carregados",
                                    "Dados preparados do Step 1"
                                  ],
                                  "tips": "Use type='const' inicialmente; adicione trends se justificado pelos dados.",
                                  "learningObjective": "Implementar estimação OLS equação-por-equação para modelo VAR em R.",
                                  "commonMistakes": [
                                    "Confundir VAR com VECM sem cointegration",
                                    "Especificar lags incorretos",
                                    "Não inspecionar matriz de covariância de resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificar Pressupostos de Regressão Linear nos Resíduos",
                                  "subSteps": [
                                    "Executar teste de Ljung-Box nos resíduos com serial.test()",
                                    "Aplicar teste de normalidade Jarque-Bera com normality.test()",
                                    "Verificar estabilidade do modelo com roots() ou stability()",
                                    "Inspecionar gráficos de resíduos (ACF/PACF) para autocorrelação",
                                    "Testar heterocedasticidade se aplicável (ex: ARCH test)"
                                  ],
                                  "verification": "p-valores dos testes > 0.05 indicando pressupostos satisfeitos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Modelo VAR estimado",
                                    "Pacotes vars"
                                  ],
                                  "tips": "Teste múltiplos lags no Ljung-Box até ordem máxima razoável.",
                                  "learningObjective": "Diagnosticar violações de pressupostos como autocorrelação e normalidade nos resíduos VAR.",
                                  "commonMistakes": [
                                    "Interpretar testes univariados em resíduos multivariados",
                                    "Ignorar testes de estabilidade",
                                    "Não plotar resíduos para inspeção visual"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Realizar Inferência",
                                  "subSteps": [
                                    "Analisar significância de coeficientes via summary() e intervalos de confiança",
                                    "Interpretar impulsos-resposta com irf() (opcional para validação)",
                                    "Calcular variância de previsão decomposições (FEVD)",
                                    "Documentar achados em relatório com tabelas e gráficos",
                                    "Comparar com modelo alternativo se necessário"
                                  ],
                                  "verification": "Interpretação coerente dos coeficientes e inferência estatística correta.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Modelo diagnosticado",
                                    "Pacotes vars para irf e fevd"
                                  ],
                                  "tips": "Foco em coeficientes próprios e cross-equation para spillovers.",
                                  "learningObjective": "Extrair insights econômicos e estatísticos da estimação VAR.",
                                  "commonMistakes": [
                                    "Ignorar significância estatística",
                                    "Confundir causalidade com correlação",
                                    "Não reportar erros-padrão robustos"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando o dataset 'Canada' do pacote vars (PIB real, emprego, inflação, taxa de juros), selecione lags=2 via BIC, estime VAR via MQO, verifique ausência de autocorrelação nos resíduos com Ljung-Box (p>0.05) e interprete spillover de choques de juros no PIB.",
                              "finalVerifications": [
                                "Modelo VAR estimado sem erros de convergência",
                                "Teste Ljung-Box passa para todos resíduos (p>0.05)",
                                "Raízes características dentro do círculo unitário (estabilidade)",
                                "Coeficientes significativos identificados corretamente",
                                "Relatório com summary(), resíduos e gráficos gerado",
                                "Pressupostos de OLS validados para todas equações"
                              ],
                              "assessmentCriteria": [
                                "Precisão na seleção de lags (coerente com critérios info)",
                                "Correta implementação de VAR() e extração de outputs",
                                "Aplicação e interpretação adequada de testes diagnósticos",
                                "Ausência de erros comuns em código R",
                                "Interpretação econômica clara dos resultados",
                                "Qualidade dos gráficos e documentação"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Modelos dinâmicos multivariados",
                                "Estatística: Testes de hipóteses e regressão linear",
                                "Programação: Manipulação de dados em R/tidyverse",
                                "Análise de Séries Temporais: Estacionariedade e cointegration",
                                "Economia: Modelagem macroeconômica"
                              ],
                              "realWorldApplication": "Em bancos centrais para forecasting de variáveis macroeconômicas, análise de transmissão de política monetária e identificação de choques em mercados financeiros, como prever impactos de taxas de juros no PIB e inflação."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.2.2",
                            "name": "Realizar testes de causalidade de Granger",
                            "description": "Testar se uma série Granger-causa outra no contexto VAR, usando teste F sobre coeficientes de lags relevantes, com interpretação em termos de previsibilidade em séries de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e estimar o modelo VAR",
                                  "subSteps": [
                                    "Coletar e pré-processar séries temporais multivariadas, garantindo estacionariedade via testes ADF",
                                    "Determinar ordem ótima de lags (p) usando critérios AIC/BIC",
                                    "Estimar o modelo VAR usando MCO (OLS) com biblioteca statsmodels em Python",
                                    "Verificar resíduos do modelo para ausência de autocorrelação (teste Ljung-Box)",
                                    "Armazenar coeficientes e resíduos para uso no teste"
                                  ],
                                  "verification": "Modelo VAR estimado com resíduos brancos (p-value > 0.05 no teste Ljung-Box) e ordem de lags confirmada",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python 3.x",
                                    "Biblioteca statsmodels",
                                    "Dados de séries temporais em CSV (ex: temperatura e vibrações)"
                                  ],
                                  "tips": "Sempre teste estacionariedade primeiro; use diff() se necessário para evitar resultados spurious",
                                  "learningObjective": "Dominar a estimação prévia de VAR como base para testes de causalidade",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade das séries",
                                    "Escolher lags arbitrários sem AIC/BIC",
                                    "Não verificar diagnóstico de resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular hipóteses e configurar o teste de Granger",
                                  "subSteps": [
                                    "Definir H0: coeficientes de lags da variável X em equação de Y são todos zero (X não Granger-causa Y)",
                                    "Especificar lags relevantes (máximo p do VAR) para o teste restrito vs irrestrito",
                                    "Preparar matriz de restrições para os coeficientes específicos no teste F",
                                    "Configurar função grangercausalitytests() do statsmodels com maxlag=p",
                                    "Documentar direção do teste (unidirecional ou bilateral)"
                                  ],
                                  "verification": "Hipóteses H0/H1 claramente definidas e função de teste configurada com lags corretos",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Código Python do Step 1",
                                    "Documentação statsmodels Granger test"
                                  ],
                                  "tips": "Comece com lags baixos se dados curtos; teste múltiplas direções para causalidade bilateral",
                                  "learningObjective": "Compreender a base estatística do teste F como comparação de modelos aninhados",
                                  "commonMistakes": [
                                    "Confundir causalidade Granger com causalidade real",
                                    "Usar lags maiores que p do VAR",
                                    "Ignorar direção da causalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar o teste F de causalidade de Granger",
                                  "subSteps": [
                                    "Executar grangercausalitytests(modelo_VAR, maxlag=p, verbose=True)",
                                    "Extrair estatística F, graus de liberdade e p-value para cada lag",
                                    "Realizar teste conjunto F para todos lags (H0 global)",
                                    "Registrar resultados em tabela (F-stat, p-value, lags)",
                                    "Ajustar por múltiplos testes se bilateral (Bonferroni)"
                                  ],
                                  "verification": "Tabela de resultados gerada com p-values para lags 1 a p, e decisão rejeitar/aceitar H0",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Modelo VAR estimado"
                                  ],
                                  "tips": "Use verbose=False para output limpo; salve resultados em DataFrame para análise",
                                  "learningObjective": "Executar teste computacionalmente e interpretar saída estatística",
                                  "commonMistakes": [
                                    "Interpretar p-value isolado sem contexto de lags",
                                    "Não reportar graus de liberdade",
                                    "Confundir F com t-test"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e validar no contexto de engenharia",
                                  "subSteps": [
                                    "Se p-value < 0.05, concluir que X Granger-causa Y (melhora previsibilidade)",
                                    "Analisar lags significativos para delay de causalidade",
                                    "Verificar robustez com subamostras ou lags alternativos",
                                    "Discutir limitações: não implica causalidade exógena, sensível a omissões",
                                    "Relacionar à previsibilidade em séries de engenharia (ex: sensor A prevê falha B)"
                                  ],
                                  "verification": "Relatório escrito com conclusão, lags chave e implicações práticas",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Resultados dos steps anteriores",
                                    "Ferramentas de plotagem (matplotlib)"
                                  ],
                                  "tips": "Plote impulse responses para complementar Granger; sempre contextualize com domínio",
                                  "learningObjective": "Interpretar causalidade em termos de previsibilidade melhorada",
                                  "commonMistakes": [
                                    "Confundir Granger com causalidade física",
                                    "Ignorar power do teste em amostras pequenas",
                                    "Sobre-generalizar sem validação"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma planta industrial, teste se a série temporal de temperatura ambiente (X) Granger-causa a série de vibrações de uma turbina (Y) usando dados horários de sensores por 1 ano. Estime VAR(2), execute teste com maxlag=2; se p<0.05, conclua que temperatura melhora previsão de vibrações, sugerindo monitoramento preditivo.",
                              "finalVerifications": [
                                "Executa teste completo em novo dataset com código reproduzível",
                                "Formula H0/H1 corretamente para qualquer par de séries",
                                "Interpreta p-value e F-stat em termos de previsibilidade",
                                "Identifica lags causais e discute limitações",
                                "Valida robustez com diagnósticos VAR",
                                "Aplica interpretação a contexto de engenharia real"
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação VAR e escolha de lags (AIC/BIC)",
                                "Correção na formulação e execução do teste F",
                                "Interpretação adequada de resultados (p-value, lags)",
                                "Verificação de pressupostos (estacionariedade, resíduos)",
                                "Relatório claro com conclusões práticas",
                                "Tratamento de limitações e robustez"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Testes em modelos macroeconômicos",
                                "Engenharia de Controle: Identificação de dependências dinâmicas",
                                "Machine Learning: Feature selection em previsão de séries temporais",
                                "Análise de Sinais: Detecção de leads/lags em sinais",
                                "Estatística: Testes de hipóteses em regressões restritas"
                              ],
                              "realWorldApplication": "Em engenharia, testes de Granger identificam se variáveis de sensores (ex: pressão, temperatura) preveem falhas em equipamentos, otimizando manutenção preditiva, reduzindo downtime em indústrias como óleo/gás ou manufatura, melhorando eficiência operacional."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.2.3",
                            "name": "Diagnosticar resíduos do modelo VAR",
                            "description": "Verificar normalidade, homocedasticidade e ausência de autocorrelação nos resíduos multivariados, aplicando testes como Jarque-Bera e LM para autocorrelação serial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Obter e Visualizar Resíduos do Modelo VAR",
                                  "subSteps": [
                                    "Ajuste o modelo VAR aos dados multivariados usando statsmodels em Python.",
                                    "Extraia os resíduos padronizados do modelo ajustado.",
                                    "Crie gráficos de resíduos: séries temporais, histograma, Q-Q plot e correlograma.",
                                    "Analise visualmente padrões como heterocedasticidade ou autocorrelação.",
                                    "Salve os resíduos em um DataFrame para testes subsequentes."
                                  ],
                                  "verification": "Gráficos gerados mostram resíduos sem padrões óbvios; resíduos salvos em variável acessível.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com statsmodels, pandas, matplotlib, seaborn"
                                  ],
                                  "tips": "Padronize os resíduos dividindo pelo desvio padrão para melhor visualização.",
                                  "learningObjective": "Compreender como extrair e inspecionar visualmente resíduos multivariados de um VAR.",
                                  "commonMistakes": [
                                    "Esquecer de padronizar resíduos",
                                    "Usar escala errada nos gráficos",
                                    "Ignorar resíduos de todas as equações"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Testar Normalidade dos Resíduos com Jarque-Bera",
                                  "subSteps": [
                                    "Implemente o teste Jarque-Bera para cada equação do VAR usando statsmodels.stats.diagnostic.jarque_bera.",
                                    "Colete estatísticas JB e p-values para todos os resíduos multivariados.",
                                    "Interprete: p-value > 0.05 indica normalidade.",
                                    "Visualize distribuições residuais com boxplots multivariados.",
                                    "Registre resultados em uma tabela de diagnóstico."
                                  ],
                                  "verification": "Tabela com JB stats e p-values gerada; conclusão sobre normalidade documentada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels.stats.diagnostic",
                                    "pandas para tabela"
                                  ],
                                  "tips": "Teste univariadamente por equação se multivariado não estiver disponível.",
                                  "learningObjective": "Aplicar e interpretar teste de normalidade em resíduos de VAR.",
                                  "commonMistakes": [
                                    "Confundir JB com teste univariado simples",
                                    "Ignorar múltiplas equações",
                                    "Interpretar estatística ao invés de p-value"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificar Homocedasticidade dos Resíduos",
                                  "subSteps": [
                                    "Aplique teste de White para heterocedasticidade em resíduos de cada equação.",
                                    "Use teste ARCH-LM para variância condicional em resíduos.",
                                    "Crie plot de resíduos quadrados vs tempo para inspeção visual.",
                                    "Compare variâncias condicionais ao longo do tempo.",
                                    "Documente p-values e conclusões em tabela."
                                  ],
                                  "verification": "Testes executados com resultados tabulados; plots sem padrões de variância crescente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.stats.diagnostic.het_white, het_arch"
                                  ],
                                  "tips": "Para VAR, teste por equação; considere resíduos veiculados se aplicável.",
                                  "learningObjective": "Diagnosticar violações de homocedasticidade em contextos multivariados.",
                                  "commonMistakes": [
                                    "Aplicar teste univariado sem ajuste multivariado",
                                    "Não testar variância condicional",
                                    "Ignorar resíduos cruzados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Testar Ausência de Autocorrelação Serial com Teste LM",
                                  "subSteps": [
                                    "Implemente teste LM de Lagrange Multiplier para autocorrelação serial nos resíduos usando vars::serial.test em R ou equivalente em Python.",
                                    "Teste lags de 1 a 12 e colete p-values.",
                                    "Gere correlogramas de resíduos e resíduos quadrados.",
                                    "Interprete: ausência se p-values > 0.05 para lags relevantes.",
                                    "Compile relatório final de diagnóstico."
                                  ],
                                  "verification": "Tabela LM com p-values; correlogramas sem picos significativos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels.tsa.stattools.acf ou R vars package"
                                  ],
                                  "tips": "Teste joint LM para todas equações simultaneamente.",
                                  "learningObjective": "Detectar e quantificar autocorrelação em resíduos multivariados.",
                                  "commonMistakes": [
                                    "Testar apenas lag 1",
                                    "Confundir com autocorrelação nos dados originais",
                                    "Não ajustar por múltiplos testes"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados de PIB e taxa de juros do Brasil (1980-2020), ajuste VAR(2), extraia resíduos, aplique JB (p=0.12, normal), White (p=0.08, homocedástico), LM lag1-4 (todos p>0.05, sem autocorr). Conclusão: resíduos adequados para inferência.",
                              "finalVerifications": [
                                "Todos testes (JB, White/ARCH, LM) têm p-values >0.05.",
                                "Gráficos residuais sem padrões visuais evidentes.",
                                "Tabela de diagnóstico completa e interpretada.",
                                "Sugestões de correção se violações detectadas.",
                                "Resíduos salvos e prontos para forecasting.",
                                "Relatório escrito confirmando adequação do modelo."
                              ],
                              "assessmentCriteria": [
                                "Correta extração e padronização de resíduos multivariados.",
                                "Implementação precisa de testes JB, homocedasticidade e LM.",
                                "Interpretação correta de p-values e implicações.",
                                "Uso de visualizações apropriadas para suporte.",
                                "Identificação de erros comuns e como evitá-los.",
                                "Relatório claro com conclusões acionáveis."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e diagnósticos residuais.",
                                "Econometria: Validação de modelos dinâmicos.",
                                "Machine Learning: Diagnóstico em modelos de séries temporais.",
                                "Programação: Manipulação de dados multivariados em Python/R.",
                                "Análise de Dados: Visualização e testes em contextos reais."
                              ],
                              "realWorldApplication": "Em bancos centrais para validar modelos VAR em previsões macroeconômicas, evitando inferências enviesadas em políticas monetárias; em finanças para testar modelos de risco sistêmico em portfólios multivariados."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.5.5.3",
                        "name": "Funções de Impulso-Resposta (IRF)",
                        "description": "Análise das funções de resposta a impulso e decomposição de variância em modelos VAR, para quantificar efeitos dinâmicos de choques em sistemas multivariados de séries temporais.",
                        "specificSkills": [
                          {
                            "id": "10.1.5.5.3.1",
                            "name": "Construir funções de impulso-resposta",
                            "description": "Calcular e interpretar IRF ortogonalizadas (Cholesky) para medir o impacto de um choque unitário em uma variável sobre as demais ao longo do tempo, com intervalos de confiança via bootstrap.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e estimar o modelo VAR",
                                  "subSteps": [
                                    "Carregue um conjunto de dados de séries temporais multivariadas (ex: PIB, inflação, taxa de juros).",
                                    "Teste estacionariedade com testes ADF e diferencie se necessário.",
                                    "Selecione o número ótimo de lags usando critérios AIC/BIC.",
                                    "Estime o modelo VAR usando biblioteca statsmodels em Python.",
                                    "Verifique resíduos para ausência de autocorrelação com teste Ljung-Box."
                                  ],
                                  "verification": "Execute model.summary() e confirme coeficientes significativos e resíduos brancos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python 3.x",
                                    "statsmodels",
                                    "pandas",
                                    " Conjunto de dados macroeconômicos (ex: FRED API)"
                                  ],
                                  "tips": "Comece com lags baixos (1-4) para evitar overfitting em amostras pequenas.",
                                  "learningObjective": "Dominar a estimação de modelos VAR estáveis para análise de séries temporais.",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade levando a resultados espúrios.",
                                    "Escolher lags excessivos causando perda de graus de liberdade."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar decomposição Cholesky para IRF ortogonalizadas",
                                  "subSteps": [
                                    "Defina a ordem recursiva das variáveis (ex: exógenas primeiro).",
                                    "Extraia matriz de covariância dos resíduos do VAR estimado.",
                                    "Calcule a decomposição Cholesky inferior (L) onde Sigma = L @ L.T.",
                                    "Gere funções de impulso-resposta usando recursão MA(∞) com L.",
                                    "Compute respostas cumulativas para horizontes de 1 a 10 períodos."
                                  ],
                                  "verification": "Verifique se a matriz L satisfaz Sigma ≈ L @ L.T com tolerância 1e-6.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python com numpy e statsmodels",
                                    "Código fonte de VAR do step 1"
                                  ],
                                  "tips": "Use np.linalg.cholesky para decomposição; teste identidade para ordem unitária.",
                                  "learningObjective": "Entender e aplicar ortogonalização Cholesky para identificar choques estruturais.",
                                  "commonMistakes": [
                                    "Ordem errada de variáveis alterando identificação.",
                                    "Confundir IRF ponto com cumulativa."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Gerar intervalos de confiança via bootstrap residual",
                                  "subSteps": [
                                    "Implemente bootstrap residual: resample resíduos com reposição (500-1000 reps).",
                                    "Para cada replicata, reconstroe séries com mean + resample e reestime VAR.",
                                    "Calcule IRF para cada bootstrap e armazene matriz de IRFs.",
                                    "Compute intervalos de 95% via percentis (2.5% e 97.5%) para cada horizonte.",
                                    "Valide convergência checando variância das estimativas bootstrap."
                                  ],
                                  "verification": "Intervalos devem ser simétricos em torno da IRF central e não incluir zero em impactos significativos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Python com numpy.random",
                                    "Funções VAR e Cholesky dos steps anteriores"
                                  ],
                                  "tips": "Use parallelização (joblib) para acelerar >500 reps; monitore tempo de computação.",
                                  "learningObjective": "Aplicar bootstrap paramétrico para quantificar incerteza em funções dinâmicas.",
                                  "commonMistakes": [
                                    "Bootstrap não-residual permitindo correlação serial.",
                                    "Poucas replicatas levando a IC instáveis."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Visualizar, interpretar e validar as IRFs",
                                  "subSteps": [
                                    "Plote IRFs com bandas de confiança usando matplotlib (um plot por resposta).",
                                    "Analise pico, persistência e significância econômica (ex: % de mudança no PIB).",
                                    "Compare com teoria econômica (ex: choque monetário contracionista).",
                                    "Teste robustez variando ordem Cholesky ou lags.",
                                    "Gere relatório com insights chave e limitações."
                                  ],
                                  "verification": "Plots mostram trajetórias plausíveis com IC não sobrepondo zero onde esperado.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "matplotlib/seaborn",
                                    "IRFs e ICs dos steps anteriores"
                                  ],
                                  "tips": "Use fill_between para bandas; adicione grid e legendas claras.",
                                  "learningObjective": "Interpretar IRFs economicamente e comunicar resultados visualmente.",
                                  "commonMistakes": [
                                    "Sobreporpretação de efeitos não-significativos.",
                                    "Ignorar assunções Cholesky (recursividade)."
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados mensais de PIB real, inflação CPI e taxa Fed Funds dos EUA (1990-2020 via FRED), estime VAR(2), aplique Cholesky com ordem [inflação, Fed Funds, PIB], e plote IRF de choque unitário em Fed Funds sobre PIB: espere queda inicial no PIB com pico em -1.5% no período 4, IC 95% não incluindo zero nos períodos 2-6.",
                              "finalVerifications": [
                                "IRF central converge a zero para horizontes longos (estacionariedade).",
                                "Matriz Cholesky reproduz covariância residual com erro <1e-5.",
                                "Bootstrap IC são contínuas e cobrem 95% das replicatas simuladas.",
                                "Plots mostram pelo menos um impacto significativo alinhado à teoria.",
                                "Código roda sem erros e reproduz resultados em <10 min.",
                                "Interpretação inclui magnitude, duração e significância."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação VAR e decomposição Cholesky (90%+ match com statsmodels.irf).",
                                "Implementação correta de bootstrap com ≥500 reps e percentis adequados.",
                                "Visualizações claras com eixos rotulados, bandas de IC e múltiplos horizontes.",
                                "Interpretação econômica coerente com contexto macroeconômico.",
                                "Tratamento robusto de erros comuns (estacionariedade, lags).",
                                "Código modular, comentado e reproduzível."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Bootstrap e testes de hipóteses para incerteza.",
                                "Econometria: Identificação estrutural em modelos dinâmicos.",
                                "Programação: NumPy para álgebra linear e paralelização em Python.",
                                "Economia: Análise de política monetária e ciclos econômicos."
                              ],
                              "realWorldApplication": "Bancos centrais como o FED usam IRFs Cholesky para simular impactos de choques de política monetária (ex: alta de juros) no crescimento e inflação, auxiliando decisões em reuniões de comitê e relatórios de estabilidade financeira."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.5.5.3.2",
                            "name": "Realizar decomposição de variância de previsão",
                            "description": "Decompor a variância da previsão de erro de uma variável atribuída a choques em cada série do VAR, ilustrando contribuições relativas em horizontes de previsão variados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos Teóricos da Decomposição de Variância em VAR",
                                  "subSteps": [
                                    "Estudar a definição de variância de erro de previsão em modelos VAR.",
                                    "Aprender sobre choques estruturais e ortogonalização (ex: Cholesky decomposition).",
                                    "Entender a fórmula matemática da VD: proporção da variância de y_i,h atribuída a ε_j.",
                                    "Revisar a representação em forma companheira do VAR.",
                                    "Explorar como a VD evolui com horizontes de previsão h=1,4,8,..."
                                  ],
                                  "verification": "Escrever um resumo de 200 palavras explicando VD e sua relação com IRF, com fórmulas chave.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Livro 'New Introduction to Multiple Time Series Analysis' de Lütkepohl (cap. 4)",
                                    "Notebook Jupyter com exemplos teóricos",
                                    "Documentação statsmodels.tsa.vector_ar.var_model.VAR"
                                  ],
                                  "tips": "Visualize matematicamente: Φ(h) da MA(∞) representa respostas acumuladas.",
                                  "learningObjective": "Dominar a teoria por trás da alocação de variância de erros de previsão a choques.",
                                  "commonMistakes": [
                                    "Confundir VD com funções de impulso-resposta (IRF)",
                                    "Ignorar que somas das contribuições devem ser 100% em cada horizonte"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Dados e Estimar o Modelo VAR",
                                  "subSteps": [
                                    "Coletar e pré-processar séries temporais estacionárias (teste ADF/KPSS).",
                                    "Verificar ordem do VAR com critérios AIC/BIC/HQIC.",
                                    "Estimar o modelo VAR usando máxima verossimilhança.",
                                    "Realizar testes de diagnóstico: autocorrelação residual (Ljung-Box), normalidade (Jarque-Bera).",
                                    "Confirmar estabilidade do modelo (raízes características dentro do círculo unitário)."
                                  ],
                                  "verification": "Executar código que estima VAR e imprime sumário com p-valores de testes >0.05.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python: statsmodels, pandas, matplotlib",
                                    "Dataset exemplo: dados macroeconômicos (PIB, inflação) do FRED/BCB",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use lag_order=1-4 inicialmente; sempre teste estacionariedade primeiro.",
                                  "learningObjective": "Preparar e validar um modelo VAR robusto para análise de VD.",
                                  "commonMistakes": [
                                    "Usar dados não estacionários levando a resultados espúrios",
                                    "Escolher lag_order inadequado inflando variâncias"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a Decomposição de Variância de Previsão",
                                  "subSteps": [
                                    "Invocar método fevd() ou variance_decomposition() no objeto VAR.",
                                    "Especificar horizontes de previsão: h=[1,4,8,12].",
                                    "Computar matrizes de covariância de erros e respostas acumuladas.",
                                    "Normalizar contribuições para somar 100% por variável e horizonte.",
                                    "Exportar resultados em array ou DataFrame para análise."
                                  ],
                                  "verification": "Gerar tabela numérica mostrando % de variância de cada variável atribuída a choques próprios/cruzados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.tsa.vector_ar.var_model.VARResults.fevd()",
                                    "Código template: var_results.fevd(12).to_pandas()"
                                  ],
                                  "tips": "Use to_pandas() para facilitar visualização; confira se diagonal soma próximo a 100%.",
                                  "learningObjective": "Implementar computacionalmente a VD para múltiplos horizontes.",
                                  "commonMistakes": [
                                    "Esquecer normalização levando a somas !=100%",
                                    "Usar ordem de Cholesky errada alterando atribuições"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Visualizar, Interpretar e Analisar Contribuições Relativas",
                                  "subSteps": [
                                    "Plotar heatmaps ou barplots de contribuições por horizonte.",
                                    "Comparar contribuições relativas: própria vs. cruzadas ao longo de h.",
                                    "Analisar persistência: como choques decayem em horizontes longos.",
                                    "Discutir implicações econômicas (ex: dominância de choques monetários).",
                                    "Sensibilizar variando ordem de variáveis ou identificações alternativas."
                                  ],
                                  "verification": "Produzir gráfico com legendas explicando 'Choque de PIB explica 60% da variância de inflação em h=4'.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Seaborn/Matplotlib para heatmaps",
                                    "Exemplo dataset: PIB e juros reais Brasil 2000-2023"
                                  ],
                                  "tips": "Use plt.stackplot() para visualizações empilhadas mostrando evolução.",
                                  "learningObjective": "Interpretar VD ilustrando transmissão de choques em VAR.",
                                  "commonMistakes": [
                                    "Interpretar causalidade absoluta (VD é só variância condicional)",
                                    "Ignorar incertezas (bootstrap para intervalos de confiança)"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados mensais de PIB real e taxa Selic (Banco Central do Brasil, 2010-2023), estime VAR(2), compute VD para h=1,6,12. Resultado: Choque de Selic explica 25% da variância do PIB em h=6, ilustrando transmissão monetária.",
                              "finalVerifications": [
                                "Pode derivar fórmula de VD a partir da representação MA(∞).",
                                "Implementa código que produz tabela/heatmaps corretos somando 100%.",
                                "Explica diferenças entre VD em h=1 vs. h=12 para um exemplo real.",
                                "Valida estabilidade e diagnósticos do VAR antes de VD.",
                                "Discute limitações como identificação de choques."
                              ],
                              "assessmentCriteria": [
                                "Precisão teórica: explica corretamente alocação de variância (90%).",
                                "Implementação: código roda sem erros e normaliza (100%).",
                                "Interpretação: identifica contribuições dominantes com justificativa (80%).",
                                "Visualização: gráficos claros e informativos (85%).",
                                "Análise crítica: menciona suposições Cholesky e alternativas (75%)."
                              ],
                              "crossCurricularConnections": [
                                "Econometria (identificação estrutural)",
                                "Estatística (análise de variância multivariada)",
                                "Programação (Python/R para modelagem TS)",
                                "Economia (política monetária e ciclos)",
                                "Machine Learning (previsão multivariada)"
                              ],
                              "realWorldApplication": "Em bancos centrais (ex: BCB/FED) para quantificar impacto de choques monetários na inflação/PIB; em finanças para decompor risco de portfólios de ativos correlacionados; em previsão de vendas empresariais com múltiplas séries dependentes."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.6",
                "name": "Análise Multivariada",
                "description": "Cobre análise de componentes principais e análise fatorial para redução de dimensionalidade e extração de fatores.",
                "totalSkills": 51,
                "atomicTopics": [
                  {
                    "id": "10.1.6.1",
                    "name": "Análise de Componentes Principais (PCA)",
                    "description": "Método para redução de dimensionalidade baseado na decomposição da matriz de covariância em autovalores e autovetores.",
                    "individualConcepts": [
                      {
                        "id": "11.3.1.1",
                        "name": "Matriz de Covariância e Correlação",
                        "description": "Conceito fundamental para PCA, representando as relações lineares entre variáveis multivariadas, calculada a partir dos dados centrados.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.1.1",
                            "name": "Calcular a matriz de covariância",
                            "description": "Dado um conjunto de dados multivariados, centralizar as variáveis (subtrair a média) e computar a matriz de covariância como (1/n) * X^T * X, onde X é a matriz de dados centrados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e carregar o conjunto de dados multivariado",
                                  "subSteps": [
                                    "Selecione um conjunto de dados com pelo menos 2 variáveis numéricas (ex: altura e peso de 10 indivíduos).",
                                    "Carregue os dados em uma matriz X de dimensão (n x p), onde n é o número de observações e p o número de variáveis.",
                                    "Verifique se os dados estão limpos: sem valores ausentes e em formato numérico.",
                                    "Visualize os dados com estatísticas descritivas básicas (média, desvio padrão por variável).",
                                    "Armazene os dados em uma biblioteca como NumPy para manipulação eficiente."
                                  ],
                                  "verification": "Confirme que X tem shape (n, p) e que todas as entradas são numéricas sem NaNs usando np.shape(X) e np.isnan(X).any().",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Python com NumPy instalado",
                                    "Conjunto de dados exemplo (CSV ou array manual)"
                                  ],
                                  "tips": "Use np.array() para criar a matriz e np.info() para inspecionar.",
                                  "learningObjective": "Compreender a estrutura de dados multivariados e prepará-los para análise.",
                                  "commonMistakes": [
                                    "Confundir linhas com observações vs. colunas com variáveis",
                                    "Ignorar valores ausentes",
                                    "Usar dados categóricos sem codificação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Centralizar as variáveis subtraindo as médias",
                                  "subSteps": [
                                    "Calcule o vetor de médias μ para cada coluna de X usando np.mean(X, axis=0).",
                                    "Crie a matriz centrada X_centered = X - μ (broadcasting automático no NumPy).",
                                    "Verifique as médias da matriz centrada: devem ser próximas de zero (np.mean(X_centered, axis=0)).",
                                    "Salve X_centered para o próximo passo.",
                                    "Opcionalmente, plote histogramas antes/depois para visualizar centralização."
                                  ],
                                  "verification": "Médias de X_centered devem ser ≈0 para cada variável (tolerância 1e-10).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "NumPy",
                                    "Matplotlib para plots opcionais"
                                  ],
                                  "tips": "Use broadcasting: X - mu.reshape(1, -1) se necessário para clareza.",
                                  "learningObjective": "Dominar a centralização como pré-requisito para covariância.",
                                  "commonMistakes": [
                                    "Subtrair média errada (axis incorreto)",
                                    "Não usar broadcasting levando a erros de shape",
                                    "Esquecer de centralizar todas as variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar a matriz de covariância",
                                  "subSteps": [
                                    "Calcule o produto matricial X_centered.T @ X_centered.",
                                    "Divida o resultado por n (número de observações): cov_matrix = (X_centered.T @ X_centered) / n.",
                                    "Arredonde para precisão numérica se necessário (np.round(cov_matrix, decimals=4)).",
                                    "Verifique propriedades: simétrica (cov_matrix == cov_matrix.T) e diagonal com variâncias.",
                                    "Salve ou exiba a matriz final."
                                  ],
                                  "verification": "Matriz é simétrica e trace(cov_matrix) ≈ soma das variâncias das variáveis centradas.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "NumPy para operações matriciais"
                                  ],
                                  "tips": "Use @ para multiplicação matricial em Python 3.5+; evite loops para eficiência.",
                                  "learningObjective": "Implementar a fórmula (1/n) * X^T * X corretamente.",
                                  "commonMistakes": [
                                    "Dividir por (n-1) em vez de n (amostra vs. população)",
                                    "Erro de transpose (X @ X_centered.T)",
                                    "Problemas de shape em multiplicação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e interpretar a matriz de covariância",
                                  "subSteps": [
                                    "Confirme simetria: np.allclose(cov_matrix, cov_matrix.T).",
                                    "Extraia variâncias da diagonal: np.diag(cov_matrix).",
                                    "Compare com np.cov(X.T) para validação (deve coincidir).",
                                    "Interprete: covariâncias positivas indicam relação direta, negativas inversa.",
                                    "Documente insights, como variáveis mais correlacionadas."
                                  ],
                                  "verification": "np.allclose(cov_matrix, np.cov(X.T)) e propriedades básicas atendidas.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "NumPy"
                                  ],
                                  "tips": "Use np.cov(X.T, bias=True) para covariância populacional exata.",
                                  "learningObjective": "Garantir correção e extrair significado da matriz.",
                                  "commonMistakes": [
                                    "Confundir covariância com correlação",
                                    "Ignorar escala das variáveis",
                                    "Não validar com função built-in"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados de 5 pessoas: X = [[170, 70], [165, 65], [180, 80], [160, 60], [175, 75]]. Centralize subtraindo médias (μ_altura=170, μ_peso=70), obtenha X_centered, compute cov_matrix = (X_centered.T @ X_centered)/5 ≈ [[72.5, 62.5], [62.5, 62.5]].",
                              "finalVerifications": [
                                "Matriz resultante é simétrica (cov == cov.T).",
                                "Elementos da diagonal são as variâncias das variáveis centradas.",
                                "Valores off-diagonal representam covariâncias entre pares de variáveis.",
                                "Resultado coincide com np.cov(X.T, bias=True).",
                                "Médias das colunas originais foram corretamente subtraídas (médias centradas ≈0).",
                                "Shape da matriz é (p, p), onde p é número de variáveis."
                              ],
                              "assessmentCriteria": [
                                "Correção na centralização: médias zero confirmadas.",
                                "Implementação precisa da fórmula matricial sem erros de shape.",
                                "Validação completa com propriedades esperadas.",
                                "Interpretação coerente dos elementos da matriz.",
                                "Eficiência: uso de operações vetoriais, não loops.",
                                "Documentação clara do processo e resultados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Base para testes de hipótese e regressão linear.",
                                "Machine Learning: Pré-processamento essencial para PCA e SVD.",
                                "Física: Modelagem de correlações em sistemas multivariados (ex: forças em partículas).",
                                "Economia/Finanças: Análise de risco em portfólios via covariâncias de ativos.",
                                "Bioinformática: Análise de dados genéticos multivariados."
                              ],
                              "realWorldApplication": "Em finanças, calcular covariâncias entre retornos de ações para otimizar portfólios (minimizar risco via diversificação); em PCA para compressão de imagens ou redução de dimensionalidade em big data, permitindo análise eficiente de conjuntos com milhares de features."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.2",
                            "name": "Padronizar dados para matriz de correlação",
                            "description": "Transformar a matriz de covariância em matriz de correlação dividindo cada elemento pela raiz do produto dos desvios-padrão das variáveis correspondentes, facilitando a comparação entre escalas diferentes.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Fundamentais de Covariância e Correlação",
                                  "subSteps": [
                                    "Revise a definição de matriz de covariância: mede a covariância entre pares de variáveis.",
                                    "Diferencie covariância de correlação: correlação é covariância padronizada, variando de -1 a 1.",
                                    "Identifique o problema de escala: covariância depende das unidades das variáveis.",
                                    "Estude a fórmula básica: ρ_xy = Cov(X,Y) / (σ_x * σ_y), onde σ é o desvio-padrão.",
                                    "Examine um exemplo numérico simples com duas variáveis."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a diferença entre covariância e correlação, incluindo a fórmula de padronização.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Notas de aula sobre estatística descritiva, calculadora ou planilha (Excel/Google Sheets).",
                                  "tips": "Use diagramas Venn para visualizar as diferenças entre os conceitos.",
                                  "learningObjective": "Compreender por que a padronização é necessária para comparar forças de relações entre variáveis em escalas diferentes.",
                                  "commonMistakes": "Confundir desvio-padrão com variância (lembre-se: σ = sqrt(variância))."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Desvios-Padrão das Variáveis",
                                  "subSteps": [
                                    "Extraia os dados das variáveis do dataset.",
                                    "Calcule a média de cada variável.",
                                    "Compute os desvios em relação à média para cada observação.",
                                    "Calcule a variância (média dos quadrados dos desvios).",
                                    "Tire a raiz quadrada da variância para obter o desvio-padrão (σ) de cada variável."
                                  ],
                                  "verification": "Liste os desvios-padrão calculados para todas as variáveis e confirme com uma ferramenta de cálculo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Dataset exemplo com 5-10 observações e 3-4 variáveis (ex: alturas, pesos, idades), Python (NumPy) ou R.",
                                  "tips": "Use funções prontas como np.std() no Python para validar cálculos manuais.",
                                  "learningObjective": "Dominar o cálculo preciso de desvios-padrão univariados como pré-requisito para padronização.",
                                  "commonMistakes": "Esquecer de dividir pela n-1 para amostra (não população); use ddof=1 no NumPy."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar a Transformação da Matriz de Covariância para Correlação",
                                  "subSteps": [
                                    "Obtenha ou calcule a matriz de covariância Σ.",
                                    "Crie uma matriz diagonal D com os desvios-padrão na diagonal principal.",
                                    "Calcule a raiz quadrada da diagonal de D para formar o vetor de σ.",
                                    "Para cada elemento Σ_ij, divida por (σ_i * σ_j).",
                                    "Construa a matriz de correlação completa R."
                                  ],
                                  "verification": "Compare a matriz resultante com uma função built-in (ex: np.corrcoef() no Python) para igualdade.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código Python/R com NumPy ou base R, matriz de covariância exemplo.",
                                  "tips": "Implemente em loop ou vetorizado para eficiência; vetorizado é mais rápido.",
                                  "learningObjective": "Executar a fórmula de padronização matematicamente e computacionalmente.",
                                  "commonMistakes": "Dividir incorretamente pela raiz do produto (use produto das raízes, não raiz do produto das variâncias)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e Interpretar a Matriz de Correlação Padronizada",
                                  "subSteps": [
                                    "Verifique se a diagonal da matriz R é identidade (1s).",
                                    "Confira se os valores estão entre -1 e 1.",
                                    "Identifique correlações fortes (>0.7 ou <-0.7) e interprete seu significado.",
                                    "Compare com a matriz de covariância original para notar diferenças de escala.",
                                    "Teste com um dataset real para prática adicional."
                                  ],
                                  "verification": "Gere um relatório curto descrevendo 2-3 insights da matriz de correlação.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Software de visualização (Matplotlib/Seaborn para heatmap), dataset real (ex: Iris do sklearn).",
                                  "tips": "Visualize como heatmap para inspeção rápida de padrões.",
                                  "learningObjective": "Interpretar corretamente a matriz de correlação em contextos multivariados.",
                                  "commonMistakes": "Interpretar correlação como causalidade; lembre-se: correlação ≠ causação."
                                }
                              ],
                              "practicalExample": "Dado um dataset de 10 pessoas com variáveis 'Altura (cm)', 'Peso (kg)' e 'Idade (anos)': 1) Calcule covariâncias (ex: Cov(Altura,Peso)=150). 2) Desvios-padrão: σ_Altura=10, σ_Peso=15, σ_Idade=5. 3) Correlação Altura-Peso = 150 / (10*15) = 1.0 (perfeita positiva após padronização). Use Python: import numpy as np; data = np.array([...]); cov = np.cov(data.T); std = np.std(data, axis=0); corr = cov / np.outer(std, std).",
                              "finalVerifications": [
                                "A diagonal da matriz de correlação contém apenas 1s.",
                                "Todos os elementos estão no intervalo [-1, 1].",
                                "Cálculos manuais coincidem com funções computacionais (erro < 0.001).",
                                "Interpretação correta de pelo menos duas correlações identificadas.",
                                "Matriz é simétrica e consistente com propriedades esperadas.",
                                "Aplicação bem-sucedida em um dataset não visto anteriormente."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de desvio-padrão (erro < 1%).",
                                "Correta aplicação da fórmula de padronização em todos os elementos.",
                                "Validação computacional e manual alinhadas.",
                                "Interpretação qualitativa precisa das correlações.",
                                "Eficiência no uso de ferramentas computacionais.",
                                "Relatório claro com insights acionáveis.",
                                "Tratamento correto de edge cases (ex: variáveis constantes)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Fundamentos de medidas de dispersão e dependência.",
                                "Programação: Manipulação de arrays e operações matriciais em Python/R.",
                                "Análise de Dados: Pré-processamento para PCA e modelagem multivariada.",
                                "Finanças: Análise de portfólios e risco via correlações de ativos."
                              ],
                              "realWorldApplication": "Em finanças, padronizar covariâncias de retornos de ações para matriz de correlação permite diversificação de portfólio, identificando ativos com baixa correlação para reduzir risco sistêmico, como em modelos Black-Litterman ou otimização Markowitz."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.1.3",
                            "name": "Interpretar a matriz de covariância",
                            "description": "Analisar os elementos da matriz para identificar covariâncias positivas/negativas fortes, indicando redundâncias lineares entre variáveis em contextos de econometria e engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar a estrutura e definição da matriz de covariância",
                                  "subSteps": [
                                    "Lembre-se da fórmula da covariância: Cov(X,Y) = E[(X - μ_X)(Y - μ_Y)]",
                                    "Identifique elementos diagonais como variâncias das variáveis individuais",
                                    "Note que a matriz é simétrica: Cov(X,Y) = Cov(Y,X)",
                                    "Entenda que off-diagonais representam covariâncias entre pares de variáveis",
                                    "Carregue um exemplo de matriz de 3x3 para visualização"
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o significado de cada tipo de elemento (diagonal vs off-diagonal) com precisão",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Notebook Jupyter ou Python com NumPy/Pandas",
                                    "Exemplo de matriz de covariância de um dataset simples (ex: Iris)"
                                  ],
                                  "tips": "Sempre visualize a matriz como uma tabela para intuitividade; use heatmaps para padrões visuais",
                                  "learningObjective": "Compreender a composição matemática e simétrica da matriz de covariância",
                                  "commonMistakes": [
                                    "Confundir covariância com correlação (unidade vs padronizada)",
                                    "Ignorar simetria e ler apenas triângulo superior"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar sinais de covariância (positiva, negativa ou nula)",
                                  "subSteps": [
                                    "Examine off-diagonais: positivo indica movimento conjunto na mesma direção",
                                    "Negativo indica movimento oposto; próximo de zero indica independência linear",
                                    "Classifique cada par: forte positivo (> threshold, ex: 0.5*sd), fraco, etc.",
                                    "Marque padrões: clusters de positivos sugerem grupos correlacionados",
                                    "Registre em uma tabela anotada"
                                  ],
                                  "verification": "Crie uma tabela resumindo sinais para todos os pares de variáveis em uma matriz exemplo",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Matriz de covariância calculada de dataset real (ex: preços de ações)",
                                    "Ferramenta de visualização como Seaborn heatmap"
                                  ],
                                  "tips": "Defina thresholds baseados no desvio padrão das variâncias para normalizar julgamento",
                                  "learningObjective": "Classificar corretamente a direção da relação linear entre variáveis",
                                  "commonMistakes": [
                                    "Interpretar magnitude sem sinal (foco apenas em absoluto)",
                                    "Assumir causalidade de covariância"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Avaliar a magnitude da covariância para força da relação",
                                  "subSteps": [
                                    "Compare off-diagonais com diagonais (variâncias) para relativizar força",
                                    "Use regra: |Cov| > 0.5 * sqrt(Var_X * Var_Y) como 'forte'",
                                    "Identifique as maiores covariâncias em valor absoluto",
                                    "Calcule correlações opcionais para confirmação (Cov / (sd_X * sd_Y))",
                                    "Anote as 3 covariâncias mais fortes e suas implicações"
                                  ],
                                  "verification": "Liste as covariâncias mais fortes com justificativa quantitativa de 'forte'",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código Python para calcular matriz e thresholds",
                                    "Dataset multivariado (ex: dados econômicos com PIB, inflação, desemprego)"
                                  ],
                                  "tips": "Sempre contextualize com unidades das variáveis para evitar viés de escala",
                                  "learningObjective": "Determinar a intensidade quantitativa das dependências lineares",
                                  "commonMistakes": [
                                    "Comparar covariâncias absolutas sem normalizar por variâncias",
                                    "Ignorar escalas diferentes das variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar redundâncias lineares e implicações práticas",
                                  "subSteps": [
                                    "Covariâncias fortes positivas/negativas indicam redundância: uma variável explica outra",
                                    "Em PCA: sugere componentes principais para redução dimensional",
                                    "Contextualize: em econometria, multicolinearidade afeta regressões; em engenharia, falhas correlacionadas",
                                    "Proponha ações: remover variáveis redundantes ou rotacionar",
                                    "Resuma insights em relatório curto"
                                  ],
                                  "verification": "Escreva um parágrafo interpretando redundâncias e recomendando próximos passos em PCA",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Dataset de engenharia (ex: sensores IoT) ou econometria",
                                    "Template de relatório de interpretação"
                                  ],
                                  "tips": "Ligue sempre à meta maior (PCA): alta covariância = bom candidato para combinação em PC",
                                  "learningObjective": "Traduzir análise em insights acionáveis sobre redundâncias",
                                  "commonMistakes": [
                                    "Sobreinterpretar como causalidade",
                                    "Não ligar à aplicação específica do contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de econometria com variáveis PIB, Inflação e Desemprego: Cov(PIB, Inflação) = 1500 (forte positivo, redundância econômica); Cov(PIB, Desemprego) = -2000 (forte negativo, trade-off); interprete como PIB alto reduz desemprego mas aumenta inflação, sinalizando multicolinearidade para PCA.",
                              "finalVerifications": [
                                "Explicar corretamente 3 off-diagonais de uma matriz exemplo",
                                "Identificar todas covariâncias fortes em uma matriz 4x4",
                                "Discutir implicações de redundância em contexto real",
                                "Criar heatmap anotado com interpretações",
                                "Propor redução dimensional baseada na análise",
                                "Diferenciar de matriz de correlação"
                              ],
                              "assessmentCriteria": [
                                "Precisão na classificação de sinais e magnitudes (90% acerto)",
                                "Uso correto de thresholds relativos às variâncias",
                                "Conexão clara com redundâncias lineares",
                                "Insights contextuais relevantes (econometria/engenharia)",
                                "Visualizações claras e anotadas",
                                "Ausência de confusão com causalidade"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Ligação com testes de hipótese para significância",
                                "Machine Learning: Pré-processamento para PCA/SVD",
                                "Econometria: Detecção de multicolinearidade em regressões",
                                "Engenharia: Análise de sinais correlacionados em sistemas",
                                "Finanças: Modelagem de risco em portfólios"
                              ],
                              "realWorldApplication": "Em finanças, interpretar covariâncias altas entre ações para diversificação de portfólio; em engenharia de manufatura, detectar sensores redundantes em linhas de produção para otimizar monitoramento e reduzir custos."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.2",
                        "name": "Decomposição em Autovalores e Autovetores",
                        "description": "Processo matemático que diagonaliza a matriz de covariância, identificando direções de máxima variância (autovetores) e suas magnitudes (autovalores).",
                        "specificSkills": [
                          {
                            "id": "11.3.1.2.1",
                            "name": "Calcular autovalores e autovetores",
                            "description": "Resolver a equação característica det(Σ - λI) = 0 para autovalores λ e encontrar autovetores associados, ordenando-os em ordem decrescente de λ.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Formular a equação característica det(Σ - λI) = 0",
                                  "subSteps": [
                                    "Obtenha a matriz de covariância Σ do contexto (ex: de dados centrados).",
                                    "Construa a matriz Σ - λI subtraindo λ da diagonal de Σ.",
                                    "Calcule o determinante det(Σ - λI) expandindo por cofatores ou fórmula para dimensões baixas (2x2 ou 3x3).",
                                    "Simplifique o polinômio resultante em λ, obtendo p(λ) = 0.",
                                    "Verifique se o polinômio é de grau igual à dimensão de Σ."
                                  ],
                                  "verification": "O polinômio característico está corretamente expandido e igualado a zero.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Matriz Σ",
                                    "Papel e lápis",
                                    "Calculadora ou software simbólico como SymPy"
                                  ],
                                  "tips": "Para 2x2: det = (a-λ)(d-λ) - bc. Sempre verifique traço e determinante como coeficientes.",
                                  "learningObjective": "Formular e computar o polinômio característico de Σ.",
                                  "commonMistakes": [
                                    "Erro no sinal de λ ao formar Σ - λI",
                                    "Expansão incorreta do determinante",
                                    "Esquecer termo constante"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Resolver o polinômio para encontrar os autovalores λ",
                                  "subSteps": [
                                    "Escreva o polinômio p(λ) = 0 em forma padrão (ex: λ² - tr(Σ)λ + det(Σ) = 0 para 2x2).",
                                    "Use fórmula quadrática para 2x2: λ = [tr ± sqrt(tr² - 4det)] / 2.",
                                    "Para 3x3, use Cardano ou fatoração; numéricamente, métodos como Newton-Raphson.",
                                    "Liste todos os autovalores reais (Σ simétrica garante reais e ortogonais).",
                                    "Verifique somando λ_i = tr(Σ) e produto λ_i = det(Σ)."
                                  ],
                                  "verification": "Autovalores satisfazem p(λ_i) ≈ 0 e somam ao traço de Σ.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Polinômio calculado",
                                    "Calculadora gráfica ou Python/NumPy para raízes"
                                  ],
                                  "tips": "Ordene λ decrescente desde o início para PCA; use np.linalg.eig para verificação.",
                                  "learningObjective": "Resolver numericamente ou analiticamente para autovalores.",
                                  "commonMistakes": [
                                    "Raízes complexas ignoradas (não ocorre em PCA)",
                                    "Erro aritmético em fórmula quadrática",
                                    "Não verificar soma dos λ"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular autovetores associados a cada autovalor λ",
                                  "subSteps": [
                                    "Para cada λ_i, forme a matriz A_i = Σ - λ_i I.",
                                    "Resolva o sistema A_i v = 0 (sistema homogêneo).",
                                    "Use eliminação gaussiana ou substituição para encontrar v não nulo.",
                                    "Escolha uma solução básica e normalize ||v|| = 1 (opcional para PCA).",
                                    "Verifique A_i v ≈ 0 (tolerância numérica)."
                                  ],
                                  "verification": "A_i v = 0 e v ≠ 0 para cada i.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Autovalores λ_i",
                                    "Matriz A_i",
                                    "Software como MATLAB ou Jupyter para resolução linear"
                                  ],
                                  "tips": "Para autovalor simples, null space tem dim 1; pivoteie corretamente no sistema.",
                                  "learningObjective": "Encontrar o espaço nulo para autovetores.",
                                  "commonMistakes": [
                                    "Escolher v=0",
                                    "Erro na substituição back",
                                    "Não normalizar consistentemente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar ortogonalidade e ordenar por λ decrescente",
                                  "subSteps": [
                                    "Verifique Σ v_i = λ_i v_i para cada par.",
                                    "Confirme ortogonalidade: v_i · v_j = 0 para i ≠ j (Σ simétrica).",
                                    "Ordene os pares (λ_i, v_i) com λ_1 ≥ λ_2 ≥ ... ≥ λ_n.",
                                    "Opcionalmente, ortonormalize via Gram-Schmidt se necessário.",
                                    "Salve como lista ou matriz de autovetores V."
                                  ],
                                  "verification": "Σ V = V Λ (forma diagonal) e V^T V = I.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Pares (λ, v)",
                                    "Calculadora matricial ou NumPy"
                                  ],
                                  "tips": "Use multiplicação matricial para verificação global; tolerância 1e-10 para floats.",
                                  "learningObjective": "Validar decomposição e ordenar para PCA.",
                                  "commonMistakes": [
                                    "Ordenação crescente em vez de decrescente",
                                    "Ignorar verificação Σv=λv",
                                    "Vetores não unitários"
                                  ]
                                }
                              ],
                              "practicalExample": "Para Σ = [[5, 2], [2, 2]] (2x2): det(Σ - λI) = (5-λ)(2-λ) - 4 = λ² - 7λ + 6 = 0 → λ1=6, λ2=1. Para λ=6: [[-1,2],[2,-4]]v=0 → v1=[2,1]/sqrt(5). Para λ=1: v2=[-1,2]/sqrt(5). Ordenado: λ1=6 > λ2=1. Verifique Σv1=6v1.",
                              "finalVerifications": [
                                "Todos autovalores λ satisfazem det(Σ - λI)=0.",
                                "Para cada v_i, Σ v_i = λ_i v_i com erro <1e-10.",
                                "Autovetores ordenados em λ decrescente.",
                                "Soma dos λ_i equals traço de Σ.",
                                "Vetores ortogonais: v_i^T v_j = 0 (i≠j).",
                                "Decomposição Σ = V Λ V^T (para simétrica)."
                              ],
                              "assessmentCriteria": [
                                "Precisão dos autovalores (erro relativo <0.01).",
                                "Correção dos autovetores (erro no sistema homogêneo <1e-8).",
                                "Ordenação correta por magnitude decrescente de λ.",
                                "Verificações matemáticas completas e documentadas.",
                                "Eficiência computacional para dimensões baixas.",
                                "Explicação clara de passos manuais vs. numéricos."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Interpretação de variância em PCA.",
                                "Física: Modos normais de vibração (matrizes de rigidez).",
                                "Ciência da Computação: Bibliotecas NumPy/SciPy para eigendecomposição.",
                                "Machine Learning: Redução de dimensionalidade em datasets.",
                                "Engenharia: Análise de estabilidade em sistemas dinâmicos."
                              ],
                              "realWorldApplication": "Em PCA para análise de imagens, autovalores indicam variância retida por componentes principais; ordenar decrescente permite compressão de dados mantendo 95% variância, usado em reconhecimento facial (ex: Eigenfaces) ou bioinformática para análise de genes."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.2",
                            "name": "Interpretar autovalores",
                            "description": "Associar autovalores à variância explicada por cada componente principal, calculando a proporção cumulativa para decidir o número de componentes a reter.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o significado dos autovalores em PCA",
                                  "subSteps": [
                                    "Revise a decomposição espectral da matriz de covariância: S = V Λ V^T, onde Λ é a diagonal com autovalores λ_i.",
                                    "Associe cada λ_i à variância explicada pelo i-ésimo componente principal.",
                                    "Normalize pela variância total: trace(S) = soma(λ_i).",
                                    "Identifique que autovalores maiores indicam componentes que capturam mais variância.",
                                    "Visualize com um scree plot conceitual."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o que um autovalor representa e dê um exemplo numérico simples.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Matriz de covariância de exemplo",
                                    "Calculadora ou Python (numpy.linalg.eig)"
                                  ],
                                  "tips": [
                                    "Lembre-se: autovalores são variâncias ao longo dos autovetores.",
                                    "Comece com datasets 2D para intuição visual."
                                  ],
                                  "learningObjective": "Compreender que autovalores quantificam a variância explicada por cada PC.",
                                  "commonMistakes": [
                                    "Confundir autovalores com autovetores.",
                                    "Ignorar que eles devem somar a variância total."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a proporção de variância explicada individual",
                                  "subSteps": [
                                    "Calcule a variância total: total_var = soma(λ_i para todos i).",
                                    "Para cada PC i, compute prop_i = λ_i / total_var * 100%.",
                                    "Ordene os autovalores em ordem decrescente (λ1 ≥ λ2 ≥ ...).",
                                    "Crie uma tabela com λ_i, prop_i e ranking.",
                                    "Interprete: o primeiro PC explica prop_1% da variância."
                                  ],
                                  "verification": "Produza uma tabela com proporções para um conjunto de 3 autovalores exemplo e interprete a maior.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Autovalores de um dataset (ex: Iris PCA)",
                                    "Planilha Excel ou Jupyter Notebook"
                                  ],
                                  "tips": [
                                    "Use funções prontas como sklearn.decomposition.PCA para validar cálculos.",
                                    "Arredonde para 2 casas decimais para clareza."
                                  ],
                                  "learningObjective": "Calcular e interpretar proporções individuais de variância.",
                                  "commonMistakes": [
                                    "Esquecer de dividir pela soma total.",
                                    "Não ordenar os autovalores."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e interpretar a variância cumulativa",
                                  "subSteps": [
                                    "Compute cumul_i = soma(prop_1 a prop_i) para i=1 a k.",
                                    "Plote cumul_i vs. número de componentes (scree plot cumulativo).",
                                    "Identifique o 'joelho' onde cumulativa estabiliza.",
                                    "Defina thresholds comuns: 80%, 90% ou 95%.",
                                    "Registre o menor k tal que cumul_k ≥ threshold."
                                  ],
                                  "verification": "Para autovalores exemplo, calcule cumulativa e sugira k para 85% variância.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python: matplotlib para plot",
                                    "Dataset pequeno como Iris ou synthético"
                                  ],
                                  "tips": [
                                    "Threshold 80-90% é comum para trade-off dimensionalidade vs. informação.",
                                    "Automatize com loop em código."
                                  ],
                                  "learningObjective": "Dominar cálculo e visualização da variância cumulativa.",
                                  "commonMistakes": [
                                    "Confundir cumulativa com individual.",
                                    "Escolher k muito pequeno ignorando o plot."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Decidir o número de componentes a reter",
                                  "subSteps": [
                                    "Aplique critério cumulativo: retém k onde cumul_k ≥ 90%.",
                                    "Considere scree plot: corte no joelho de queda dos λ_i.",
                                    "Avalie trade-offs: mais PCs = melhor fit, mas risco de overfitting.",
                                    "Valide com Kaiser criterion (λ_i > 1) ou parallel analysis.",
                                    "Documente a decisão com justificativa numérica."
                                  ],
                                  "verification": "Justifique escolha de k para um exemplo real, citando % cumulativa e visual.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código Python completo de PCA",
                                    "Scree plot gerado"
                                  ],
                                  "tips": [
                                    "Combine múltiplos critérios para robustez.",
                                    "Em ML, valide com cross-validation downstream."
                                  ],
                                  "learningObjective": "Aplicar critérios heurísticos para seleção de componentes em PCA.",
                                  "commonMistakes": [
                                    "Retenção automática sem interpretação.",
                                    "Ignorar contexto do dataset (ex: alta dimensionalidade)."
                                  ]
                                }
                              ],
                              "practicalExample": "No dataset Iris (4 features), autovalores da covariância: [0.619, 0.233, 0.070, 0.058]. Total var=0.98. Proporções: 63.2%, 23.8%, 7.1%, 5.9%. Cumulativa: 63.2%, 87%, 94.1%, 100%. Decida reter 2 PCs (87% > 80%), reduzindo de 4D para 2D sem perda significativa de info.",
                              "finalVerifications": [
                                "Explica corretamente autovalores como variância por PC.",
                                "Calcula proporções e cumulativa sem erros aritméticos.",
                                "Identifica k ótimo para threshold dado.",
                                "Interpreta scree plot para decisão.",
                                "Justifica trade-offs dimensionais.",
                                "Aplica a um dataset real."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos (proporções e cumulativa >95% acuradas).",
                                "Interpretação qualitativa correta (80%+ alinhada com conceitos).",
                                "Uso apropriado de critérios (cumulativo, scree, Kaiser).",
                                "Visualizações claras e rotuladas.",
                                "Justificativa contextualizada ao dataset.",
                                "Eficiência: escolhe k que equilibra info vs. simplicidade."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: ligação com variância e testes de hipóteses.",
                                "Machine Learning: pré-processamento para modelos supervisionados.",
                                "Física: modos normais de vibração (autovalores em matrizes massa-rigidez).",
                                "Economia: análise de fatores em séries financeiras.",
                                "Bioinformática: redução em genômica."
                              ],
                              "realWorldApplication": "Em visão computacional, PCA com interpretação de autovalores reduz imagens de 1000+ pixels para 50 PCs (95% variância), acelerando reconhecimento facial em apps como segurança aeroportuária ou filtros de Instagram."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.2.3",
                            "name": "Normalizar autovetores",
                            "description": "Garantir que os autovetores sejam unitários (norma euclidiana igual a 1) para formar uma base ortonormal, essencial para a projeção ortogonal nos componentes principais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Norma Euclidiana",
                                  "subSteps": [
                                    "Defina a norma euclidiana (L2) de um vetor v = [v1, v2, ..., vn] como ||v|| = sqrt(v1² + v2² + ... + vn²).",
                                    "Explique por que autovetores unitários (||v|| = 1) são necessários para formar uma base ortonormal em PCA.",
                                    "Discuta a importância da normalização para projeções ortogonais e preservação de distâncias.",
                                    "Calcule manualmente a norma de um vetor simples, como [3, 4].",
                                    "Relacione com propriedades de autovetores: Av = λv implica que normalização preserva direção."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a fórmula da norma e calcule ||[3,4]|| = 5.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Papel e caneta",
                                    "Calculadora científica"
                                  ],
                                  "tips": [
                                    "Sempre use a raiz quadrada no final; pratique com vetores 2D e 3D."
                                  ],
                                  "learningObjective": "Dominar a definição e cálculo da norma euclidiana para vetores.",
                                  "commonMistakes": [
                                    "Esquecer a raiz quadrada",
                                    "Confundir com norma L1 (soma absoluta)",
                                    "Usar norma errada para PCA"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a Norma de um Autovetor Dado",
                                  "subSteps": [
                                    "Obtenha um autovetor v de uma matriz de covariância (ex: v = [1, 1, 1] para dados centrados).",
                                    "Eleve cada componente ao quadrado: vi² para i=1 a n.",
                                    "Some os quadrados: sum_vi².",
                                    "Aplique a raiz quadrada para obter ||v||.",
                                    "Registre o valor exato ou numérico com precisão de 4 casas decimais."
                                  ],
                                  "verification": "Confirme que ||v|| > 0 (não-zero) e compare com cálculo em software como Python.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Matriz exemplo com autovetores conhecidos",
                                    "Python com NumPy (opcional)",
                                    "Planilha Excel"
                                  ],
                                  "tips": [
                                    "Use sqrt() em calculadora; para vetores grandes, considere aproximações numéricas."
                                  ],
                                  "learningObjective": "Calcular precisamente a norma de autovetores extraídos de decomposição.",
                                  "commonMistakes": [
                                    "Arredondamentos prematuros",
                                    "Inverter sinal em componentes",
                                    "Ignorar autovetores nulos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Normalizar o Autovetor",
                                  "subSteps": [
                                    "Divida cada componente do autovetor v pela norma calculada: v_normalized[i] = v[i] / ||v||.",
                                    "Calcule todos os componentes normalizados.",
                                    "Arredonde para 4-6 casas decimais para precisão numérica.",
                                    "Repita para todos os autovetores relevantes (top-k para PCA).",
                                    "Forme a matriz P com colunas como autovetores normalizados."
                                  ],
                                  "verification": "Verifique que cada componente foi dividido corretamente comparando v_normalized * ||v|| ≈ v original.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Autovetor do passo anterior",
                                    "Calculadora ou Python (numpy.divide)",
                                    "Papel quadriculado"
                                  ],
                                  "tips": [
                                    "Mantenha sinal original; use broadcasting em arrays para eficiência."
                                  ],
                                  "learningObjective": "Executar a normalização escalar para obter autovetores unitários.",
                                  "commonMistakes": [
                                    "Dividir pela norma ao invés de multiplicar",
                                    "Normalizar apenas magnitude ignorando direção",
                                    "Perder precisão em divisões"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar Ortonormalidade da Base",
                                  "subSteps": [
                                    "Recalcule a norma do v_normalized: deve ser ≈1 (tolerância 1e-10).",
                                    "Para múltiplos autovetores, calcule produto interno vi·vj = 0 para i≠j.",
                                    "Verifique P^T P = I (identidade) para matriz P de autovetores.",
                                    "Teste em contexto PCA: projeção X P deve preservar variância.",
                                    "Documente discrepâncias e ajuste numéricamente se necessário."
                                  ],
                                  "verification": "Norma == 1 e produtos internos == 0 para pares ortogonais.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Matriz P formada",
                                    "Python (numpy.dot, numpy.linalg.norm)",
                                    "Software MATLAB ou similar"
                                  ],
                                  "tips": [
                                    "Use tolerância numérica devido a erros de floating-point; ortogonalize com Gram-Schmidt se preciso."
                                  ],
                                  "learningObjective": "Validar que autovetores normalizados formam base ortonormal.",
                                  "commonMistakes": [
                                    "Ignorar tolerâncias numéricas",
                                    "Confundir ortogonalidade com normalização",
                                    "Não verificar múltiplos vetores"
                                  ]
                                }
                              ],
                              "practicalExample": "Para matriz de covariância 2x2: [[2,1],[1,2]], autovalores λ1=3, λ2=1; autovetores v1=[1,1], v2=[1,-1]. Norma v1=√2≈1.414, v1_norm=[0.707,0.707]; v2_norm=[0.707,-0.707]. Verifique: v1_norm · v2_norm ≈0, normas=1. Use em PCA para projetar dados [[1,0],[0,1]] em componentes principais.",
                              "finalVerifications": [
                                "Norma euclidiana de cada autovetor normalizado é exatamente 1 (ou <1e-10 erro).",
                                "Produtos internos entre autovetores distintos são zero.",
                                "Matriz P de autovetores satisfaz P^T P = I.",
                                "Projeção de dados em P preserva variância total.",
                                "Sem perda de direção original dos autovetores.",
                                "Cálculos numéricos consistentes em software."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo da norma inicial (>99% exatidão).",
                                "Correta aplicação da divisão escalar em todos componentes.",
                                "Verificação completa de ortonormalidade com tolerâncias adequadas.",
                                "Uso eficiente de ferramentas computacionais.",
                                "Explicação clara da relevância para PCA.",
                                "Identificação e correção de erros comuns."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Bases ortonormais e decomposição espectral.",
                                "Programação Numérica: Uso de numpy.linalg.norm e dot para vetores.",
                                "Física: Vetores unitários em mecânica quântica e eletromagnetismo.",
                                "Estatística: Padronização em análise multivariada além de PCA.",
                                "Machine Learning: Pré-processamento para algoritmos de redução dimensional."
                              ],
                              "realWorldApplication": "Em PCA para compressão de imagens (ex: faces em reconhecimento facial), autovetores normalizados definem direções de máxima variância unitárias, permitindo reconstrução eficiente sem distorções de escala, usado em ferramentas como scikit-learn para grandes datasets."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "11.3.1.3",
                        "name": "Redução de Dimensionalidade via PCA",
                        "description": "Aplicação prática do PCA para projetar dados em um espaço de menor dimensão, preservando a maior variância possível, útil em regressão e análise de séries em engenharia.",
                        "specificSkills": [
                          {
                            "id": "11.3.1.3.1",
                            "name": "Executar o algoritmo PCA completo",
                            "description": "Padronizar dados, decompor a matriz de covariância, selecionar k principais componentes baseados no critério de variância explicada (>80%) e projetar X_new = X * V_k.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Padronizar os dados de entrada",
                                  "subSteps": [
                                    "Carregue o dataset numérico X com shape (n_samples, n_features).",
                                    "Calcule a média μ e o desvio padrão σ para cada feature.",
                                    "Aplique a fórmula de padronização: X_std = (X - μ) / σ.",
                                    "Verifique se a média de X_std é aproximadamente 0 e o desvio padrão é 1 para cada feature.",
                                    "Salve X_std para uso posterior."
                                  ],
                                  "verification": "Execute np.mean(X_std, axis=0) ≈ 0 e np.std(X_std, axis=0) ≈ 1.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com NumPy e Pandas",
                                    "Dataset de exemplo (ex: Iris)"
                                  ],
                                  "tips": "Use sklearn.preprocessing.StandardScaler para automação, mas implemente manualmente primeiro para compreensão.",
                                  "learningObjective": "Entender a importância da padronização para PCA evitar dominância de features com maior escala.",
                                  "commonMistakes": [
                                    "Esquecer de padronizar, levando a componentes enviesados",
                                    "Padronizar incorretamente com mediana em vez de média"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a matriz de covariância",
                                  "subSteps": [
                                    "Compute a matriz de covariância Σ = (1/n) * (X_std.T @ X_std).",
                                    "Confirme que Σ é simétrica e seus valores diagonais são variâncias unitárias.",
                                    "Visualize a matriz com heatmap para identificar correlações.",
                                    "Armazene Σ para a próxima etapa.",
                                    "Teste com um dataset pequeno para validar manualmente."
                                  ],
                                  "verification": "Verifique se Σ é simétrica (Σ == Σ.T) e trace(Σ) ≈ n_features.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "NumPy",
                                    "Matplotlib/Seaborn para visualização"
                                  ],
                                  "tips": "Para datasets grandes, use np.cov(X_std.T) para eficiência.",
                                  "learningObjective": "Compreender como a covariância captura relações lineares entre features.",
                                  "commonMistakes": [
                                    "Usar X não padronizado",
                                    "Dividir por n-1 em vez de n para população"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Decompor a matriz de covariância",
                                  "subSteps": [
                                    "Calcule autovalores λ e autovetores V usando np.linalg.eigh(Σ).",
                                    "Ordene λ decrescentemente e V correspondente.",
                                    "Normalize os autovetores para unit length (||V||=1).",
                                    "Crie uma matriz V com colunas como autovetores ordenados.",
                                    "Plote scree plot de λ para inspeção visual."
                                  ],
                                  "verification": "Confirme ∑λ = trace(Σ) e V.T @ V ≈ I (ortogonalidade).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "NumPy.linalg",
                                    "Matplotlib"
                                  ],
                                  "tips": "Use eigh para matrizes simétricas positivas definidas como Σ.",
                                  "learningObjective": "Dominar decomposição espectral e interpretação de autovalores como variância.",
                                  "commonMistakes": [
                                    "Não ordenar autovalores",
                                    "Usar eig em vez de eigh"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Selecionar k principais componentes",
                                  "subSteps": [
                                    "Calcule variância explicada cumulativa: cumsum(λ / sum(λ)) * 100.",
                                    "Encontre o menor k tal que variância cumulativa > 80%.",
                                    "Selecione V_k = V[:, :k] os k primeiros autovetores.",
                                    "Registre k e % variância explicada.",
                                    "Valide com plot de variância cumulativa."
                                  ],
                                  "verification": "cumsum_explicada[k-1] >= 80% e k é mínimo possível.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "NumPy",
                                    "Matplotlib"
                                  ],
                                  "tips": "Ajuste threshold se necessário, mas siga >80%.",
                                  "learningObjective": "Aprender critério de seleção baseado em variância retida.",
                                  "commonMistakes": [
                                    "Selecionar k fixo sem critério",
                                    "Calcular % errado (não normalizar por sum(λ))"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Projetar dados no espaço reduzido",
                                  "subSteps": [
                                    "Compute X_new = X_std @ V_k.",
                                    "Verifique shape(X_new) = (n_samples, k).",
                                    "Compare variância em X_new com λ[:k].",
                                    "Visualize X_new em 2D se k>=2.",
                                    "Salve ou retorne X_new como resultado final."
                                  ],
                                  "verification": "np.var(X_new, axis=0) ≈ λ[:k] e shape correto.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "NumPy",
                                    "Matplotlib/Seaborn"
                                  ],
                                  "tips": "Use dados padronizados originais para projeção.",
                                  "learningObjective": "Executar transformação linear para redução dimensional.",
                                  "commonMistakes": [
                                    "Projetar X original em vez de X_std",
                                    "Usar V_k.T incorretamente"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset Iris (150 amostras, 4 features): padronize, compute Σ, decompõe (k=2 para >80% var), projete para X_new (150x2), plote scatter plot mostrando separação de classes.",
                              "finalVerifications": [
                                "Variância explicada cumulativa >=80%.",
                                "X_new tem shape (n_samples, k) com k mínimo.",
                                "Autovetores em V_k são ortonormais.",
                                "Projeção preserva variância esperada (np.var(X_new.T) ≈ λ[:k]).",
                                "Visualização confirma redução sem perda crítica de informação.",
                                "Reproduzibilidade: execute múltiplas vezes com seed."
                              ],
                              "assessmentCriteria": [
                                "Correta padronização (médias=0, desvios=1).",
                                "Matriz de covariância simétrica e válida.",
                                "Decomposição espectral precisa (autovalores somam trace(Σ)).",
                                "Seleção de k segue critério >80% variância.",
                                "Projeção resulta em X_new correto e verificável.",
                                "Código limpo, comentado e eficiente."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência multivariada e testes de correlação.",
                                "Machine Learning: Pré-processamento para modelos como KNN/SVM.",
                                "Visualização de Dados: Redução para plots 2D/3D.",
                                "Álgebra Linear: Autovalores e decomposições matriciais.",
                                "Computação Científica: Otimização numérica com SciPy."
                              ],
                              "realWorldApplication": "Em análise de imagens, PCA reduz pixels correlacionados para compressão (ex: faces em reconhecimento facial); em finanças, reduz features de ações para previsão de portfólio; em bioinformática, diminui dimensionalidade de dados genômicos para clustering de genes."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.2",
                            "name": "Selecionar número de componentes",
                            "description": "Usar scree plot, proporção de variância ou critério de Kaiser (λ > 1) para determinar o número ótimo de componentes principais em dados de econometria aplicada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e computar eigenvalues via PCA",
                                  "subSteps": [
                                    "Carregar dataset multivariado padronizado (ex: indicadores econômicos regionais)",
                                    "Aplicar StandardScaler para normalizar variáveis",
                                    "Ajustar modelo PCA usando scikit-learn e extrair eigenvalues (PCA.components_ e explained_variance_)",
                                    "Calcular variância explicada por componente (explained_variance_ratio_)"
                                  ],
                                  "verification": "Verificar se eigenvalues são positivos e decrescentes; imprimir array de eigenvalues e variâncias",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com scikit-learn, pandas, numpy",
                                    "Dataset exemplo: dados econômicos (CSV com 50 regiões x 10 variáveis)"
                                  ],
                                  "tips": "Sempre padronize dados antes de PCA para evitar viés de escala",
                                  "learningObjective": "Compreender como PCA decompõe dados em componentes principais e extrai métricas chave",
                                  "commonMistakes": [
                                    "Esquecer padronização levando a componentes enviesados",
                                    "Confundir eigenvalues com eigenvectors"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar critério de Kaiser (λ > 1)",
                                  "subSteps": [
                                    "Listar eigenvalues ordenados em ordem decrescente",
                                    "Identificar o número de componentes onde λ > 1",
                                    "Contar quantos atendem o critério (rejeitar componentes com λ ≤ 1 como ruído)",
                                    "Documentar o valor k sugerido pelo Kaiser"
                                  ],
                                  "verification": "Número de componentes com λ > 1 é registrado e justificado",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Jupyter Notebook ou script Python",
                                    "Output do Step 1"
                                  ],
                                  "tips": "O critério Kaiser é conservador; combine com outros para evitar super-retention",
                                  "learningObjective": "Dominar o critério heurístico de Kaiser para retenção de componentes",
                                  "commonMistakes": [
                                    "Incluir λ próximos a 1 sem contexto",
                                    "Ignorar que critério é para dados correlacionados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir e interpretar scree plot",
                                  "subSteps": [
                                    "Plotar eigenvalues vs. número de componente usando matplotlib",
                                    "Identificar o 'elbow' (ponto de inflexão onde declínio estabiliza)",
                                    "Marcar visualmente o elbow e testar diferentes k",
                                    "Salvar plot com anotações"
                                  ],
                                  "verification": "Scree plot gerado mostra elbow claro e interpretação escrita",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "matplotlib ou seaborn",
                                    "Eigenvalues do Step 1"
                                  ],
                                  "tips": "Use escala log para eigenvalues pequenos; procure queda acentuada inicial",
                                  "learningObjective": "Aprender a visualizar trade-off variância vs. dimensionalidade",
                                  "commonMistakes": [
                                    "Escolha subjetiva sem múltiplas visualizações",
                                    "Plot sem ordenação decrescente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar proporção de variância cumulativa e selecionar k ótimo",
                                  "subSteps": [
                                    "Calcular variância cumulativa (np.cumsum(explained_variance_ratio_))",
                                    "Plotar scree cumulativo e mirar >70-90% variância retida",
                                    "Comparar k de Kaiser, elbow e variância para decisão final",
                                    "Justificar k ótimo com tabela comparativa"
                                  ],
                                  "verification": "Tabela resume critérios e k selecionado com justificativa",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python numpy/pandas",
                                    "Plots anteriores"
                                  ],
                                  "tips": "Prefira k que equilibre variância (>80%) e parcimônia (<50% originais)",
                                  "learningObjective": "Integrar múltiplos critérios para decisão robusta de dimensionalidade",
                                  "commonMistakes": [
                                    "Retenção excessiva por >99% variância",
                                    "Ignorar contexto do dataset"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de econometria de 50 regiões brasileiras (variáveis: PIB per capita, desemprego, inflação, dívida pública, etc.), PCA revela 3 componentes capturando 85% variância: Kaiser sugere 4, elbow em 3, cumulativa confirma 3 como ótimo para regressão posterior.",
                              "finalVerifications": [
                                "Eigenvalues corretamente ordenados e >0",
                                "Scree plot exibe elbow identificável",
                                "Variância cumulativa para k ótimo >80%",
                                "Tabela comparativa de critérios coerente",
                                "k selecionado reduz dimensionalidade sem perda significativa",
                                "Código reproduzível gera mesmos resultados"
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração de eigenvalues e variâncias",
                                "Interpretação correta de Kaiser (λ>1)",
                                "Identificação visual precisa do elbow no scree plot",
                                "Cálculo exato de variância cumulativa",
                                "Justificativa integrada de múltiplos critérios",
                                "Redução efetiva com >75% variância retida"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência sobre autovalores",
                                "Visualização de Dados: Gráficos interpretativos",
                                "Econometria: Preparação para modelos de painel",
                                "Machine Learning: Feature engineering e redução dimensional"
                              ],
                              "realWorldApplication": "Em análise de risco financeiro, selecionar 5 componentes de 20 indicadores macroeconômicos para prever recessões, evitando multicolinearidade em modelos VAR ou regressões econômicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.3",
                            "name": "Aplicar PCA em dados de engenharia",
                            "description": "Implementar PCA em conjuntos de dados reais de sistemas de controle ou séries temporais, interpretando componentes para redução de ruído e multicolinearidade em regressões.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Selecionar e Explorar Dados de Engenharia",
                                  "subSteps": [
                                    "Identifique um conjunto de dados reais de sistemas de controle ou séries temporais (ex: sensores de temperatura, pressão e fluxo).",
                                    "Carregue os dados usando pandas em Python e inspecione estrutura com info() e describe().",
                                    "Visualize correlações com heatmap e distribuições com histograms para detectar multicolinearidade inicial.",
                                    "Identifique e documente valores ausentes, outliers e padrões de ruído.",
                                    "Calcule a matriz de correlação para confirmar alta dimensionalidade."
                                  ],
                                  "verification": "Relatório de exploração gerado com gráficos e estatísticas resumidas, confirmando presença de multicolinearidade (correlações > 0.8).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python 3.x",
                                    "Bibliotecas: pandas, numpy, matplotlib, seaborn",
                                    "Dataset exemplo: dados de sensores industriais (ex: UCI ML Repository)"
                                  ],
                                  "tips": [
                                    "Comece sempre com visualizações para ganhar intuição; use pairplots para relações multivariadas."
                                  ],
                                  "learningObjective": "Compreender a estrutura e problemas iniciais em dados multivariados de engenharia.",
                                  "commonMistakes": [
                                    "Ignorar valores ausentes sem tratamento",
                                    "Não visualizar correlações antes de PCA",
                                    "Selecionar datasets sem ruído realista"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Pré-processar e Padronizar os Dados",
                                  "subSteps": [
                                    "Trate valores ausentes com imputação média ou mediana, justificando a escolha.",
                                    "Remova ou transforme outliers usando IQR ou z-score.",
                                    "Aplique escalonamento (StandardScaler do sklearn) para normalizar features.",
                                    "Divida os dados em treino e teste (80/20).",
                                    "Verifique multicolinearidade pós-pré-processamento com VIF (Variance Inflation Factor)."
                                  ],
                                  "verification": "Dados padronizados com VIF < 5 para todas as features e sem missing values.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python",
                                    "sklearn.preprocessing",
                                    "statsmodels para VIF"
                                  ],
                                  "tips": [
                                    "Padronização é crucial para PCA, pois assume variância unitária; sempre fit no treino apenas."
                                  ],
                                  "learningObjective": "Preparar dados para PCA, eliminando vieses de escala e multicolinearidade.",
                                  "commonMistakes": [
                                    "Escalonar sem separar treino/teste",
                                    "Usar escalas diferentes para features",
                                    "Ignorar outliers que distorcem variância"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar e Executar PCA",
                                  "subSteps": [
                                    "Importe PCA do sklearn.decomposition e ajuste no conjunto de treino.",
                                    "Determine o número de componentes usando scree plot e cumulativa de variância explicada (alvo: 95%).",
                                    "Transforme dados de treino e teste nos componentes principais.",
                                    "Plote scree plot e loadings para visualizar contribuição de features.",
                                    "Salve o modelo PCA treinado."
                                  ],
                                  "verification": "Scree plot gerado com pelo menos 95% de variância explicada por k componentes selecionados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "sklearn.decomposition.PCA",
                                    "matplotlib para plots"
                                  ],
                                  "tips": [
                                    "Escolha k onde elbow ocorre ou variância cumulativa atinge 95%; evite over-reduction.",
                                    "Use explained_variance_ratio_ para priorizar componentes."
                                  ],
                                  "learningObjective": "Executar PCA computacionalmente e selecionar componentes ótimos.",
                                  "commonMistakes": [
                                    "Ajustar PCA em todo dataset (leakage)",
                                    "Selecionar k arbitrário sem análise de variância",
                                    "Não plotar loadings"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Componentes e Aplicar em Regressão",
                                  "subSteps": [
                                    "Analise loadings para interpretar componentes (ex: PC1 = ruído comum em sensores).",
                                    "Substitua features originais pelos PCs selecionados em um modelo de regressão linear.",
                                    "Treine regressão nos PCs e compare métricas (R², MSE) com baseline (features originais).",
                                    "Valide redução de ruído/multicolinearidade comparando VIF e resíduos.",
                                    "Gere relatório de interpretação e ganhos."
                                  ],
                                  "verification": "Modelo de regressão com PCs mostra R² > baseline e VIF < 5 nos PCs.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "sklearn.linear_model.LinearRegression",
                                    "sklearn.metrics"
                                  ],
                                  "tips": [
                                    "PCs são ortogonais, eliminando multicolinearidade automaticamente; foque em top loadings para interpretação."
                                  ],
                                  "learningObjective": "Interpretar resultados de PCA e usá-los para melhorar modelos preditivos.",
                                  "commonMistakes": [
                                    "Interpretar PCs como features originais",
                                    "Não comparar com baseline",
                                    "Usar todos PCs sem seleção"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Documentar Resultados",
                                  "subSteps": [
                                    "Aplique cross-validation nos PCs para robustez.",
                                    "Teste em dados não vistos e analise resíduos para ruído residual.",
                                    "Documente pipeline completo em notebook Jupyter.",
                                    "Discuta limitações (ex: perda de interpretabilidade).",
                                    "Exporte modelo e visualizações."
                                  ],
                                  "verification": "Notebook completo com validação (CV score > baseline) e documentação.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "sklearn.model_selection.cross_val_score"
                                  ],
                                  "tips": [
                                    "Use Pipeline do sklearn para automatizar; sempre valide em hold-out set."
                                  ],
                                  "learningObjective": "Garantir reprodutibilidade e validade prática da aplicação de PCA.",
                                  "commonMistakes": [
                                    "Pular validação cross",
                                    "Não documentar pipeline",
                                    "Sobre-generalizar sem testes"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de sensores de um sistema de controle de reator químico (temperatura, pressão, pH, fluxo), aplique PCA para reduzir 10 features para 4 PCs, interpretando PC1 como 'modo de operação principal' (alta correlação positiva em temp/fluxo), e use em regressão para prever eficiência energética, melhorando R² de 0.72 para 0.89 e eliminando multicolinearidade.",
                              "finalVerifications": [
                                "PCA captura >95% variância com redução dimensional >50%.",
                                "Interpretação clara de pelo menos 2 PCs principais via loadings.",
                                "Regressão com PCs supera baseline em R² e MSE.",
                                "VIF pós-PCA <5, confirmando eliminação de multicolinearidade.",
                                "Resíduos da regressão mostram redução de ruído (normalidade via QQ-plot).",
                                "Pipeline documentado e reproduzível em notebook."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação PCA (variância explicada correta).",
                                "Qualidade da interpretação de componentes (loadings e significado físico).",
                                "Melhoria mensurável em modelo de regressão (métricas comparadas).",
                                "Tratamento adequado de pré-processamento e validação.",
                                "Documentação clara com visualizações e justificativas.",
                                "Identificação correta de ruído/multicolinearidade pré/pós-PCA."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência multivariada e análise de variância.",
                                "Machine Learning: Pré-processamento para modelos supervisionados.",
                                "Engenharia de Controle: Análise de séries temporais e sistemas dinâmicos.",
                                "Processamento de Sinais: Redução de ruído em dados sensoriais.",
                                "Ciência de Dados: Pipelines end-to-end para dados reais."
                              ],
                              "realWorldApplication": "Em indústrias como óleo & gás ou manufatura, PCA é usado para reduzir ruído em dados de vibração de turbinas ou sensores IoT, permitindo regressões precisas para manutenção preditiva, otimizando downtime e custos em milhões de dólares anuais."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "11.3.1.3.4",
                            "name": "Avaliar qualidade da redução",
                            "description": "Calcular métricas como variância explicada cumulativa e erro de reconstrução ||X - X_hat||^2 para validar a eficácia da redução dimensional em contextos multivariados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Calcular a variância explicada por componente e cumulativa",
                                  "subSteps": [
                                    "Carregue o dataset multivariado e ajuste o modelo PCA com o número de componentes desejado.",
                                    "Extraia os valores de explained_variance_ratio_ do modelo PCA.",
                                    "Calcule a variância explicada cumulativa somando os ratios de forma cumulativa.",
                                    "Plote um scree plot para visualizar a variância explicada por componente."
                                  ],
                                  "verification": "Verifique se a soma da variância cumulativa para todos os componentes é aproximadamente 1.0 e gere um gráfico do scree plot.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python com scikit-learn, NumPy, Matplotlib; dataset de exemplo (ex: Iris ou Boston Housing).",
                                  "tips": "Use np.cumsum() para calcular a cumulativa de forma eficiente.",
                                  "learningObjective": "Compreender e computar quanto da variância total dos dados é capturada pelos componentes principais.",
                                  "commonMistakes": "Confundir explained_variance_ (variância absoluta) com explained_variance_ratio_ (proporcional); não normalizar os dados antes do PCA."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Computar o erro de reconstrução ||X - X_hat||^2",
                                  "subSteps": [
                                    "Transforme os dados originais X para o espaço reduzido usando fit_transform().",
                                    "Reconstrua os dados X_hat invertendo a transformação com inverse_transform().",
                                    "Calcule a diferença X - X_hat e compute a norma Frobenius ou MSE (média do quadrado da norma euclidiana).",
                                    "Compare o erro com baselines como variância total dos dados."
                                  ],
                                  "verification": "Confirme que o erro de reconstrução diminui monotonicamente com mais componentes e é próximo de zero para k = dimensionalidade original.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python com scikit-learn, NumPy; mesmo dataset do Step 1.",
                                  "tips": "Use np.linalg.norm((X - X_hat), 'fro')^2 para norma Frobenius eficiente em matrizes.",
                                  "learningObjective": "Avaliar a fidelidade da aproximação dos dados originais após redução dimensional.",
                                  "commonMistakes": "Esquecer de centralizar os dados antes do PCA, levando a erros inflados; usar norma L1 em vez de L2 para reconstrução."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar as métricas de qualidade",
                                  "subSteps": [
                                    "Defina thresholds: ex., variância cumulativa > 90% para boa redução.",
                                    "Analise o trade-off entre número de componentes, variância explicada e erro de reconstrução.",
                                    "Identifique o 'elbow' no scree plot ou cumulativa para escolher k ótimo.",
                                    "Documente as implicações para perda de informação."
                                  ],
                                  "verification": "Escreva um relatório curto justificando o k escolhido baseado nas métricas.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Gráficos gerados anteriormente; ferramenta de relatório (Jupyter Notebook).",
                                  "tips": "Use critérios como Kaiser (eigenvalue >1) ou scree test para guiar a interpretação.",
                                  "learningObjective": "Interpretar métricas para decidir a eficácia da redução dimensional.",
                                  "commonMistakes": "Escolher k baseado apenas em variância máxima sem considerar custo computacional; ignorar multicolinearidade nos dados originais."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e visualizar os resultados",
                                  "subSteps": [
                                    "Compare métricas com diferentes k (ex.: 2, 5, 10 componentes).",
                                    "Gere plots de variância cumulativa vs. k e erro vs. k.",
                                    "Realize validação cruzada se aplicável para robustez.",
                                    "Exporte resultados em tabela e gráficos para apresentação."
                                  ],
                                  "verification": "Crie uma tabela comparativa mostrando variância cumulativa e erro para vários k, com k ótimo destacado.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Pandas para tabelas, Seaborn/Matplotlib para plots avançados.",
                                  "tips": "Use loop para variar k e coletar métricas em um DataFrame para eficiência.",
                                  "learningObjective": "Validar a escolha de redução através de comparações e visualizações.",
                                  "commonMistakes": "Sobreajuste visualizando apenas um k; não escalar dados corretamente em comparações."
                                }
                              ],
                              "practicalExample": "Usando o dataset Iris (150 amostras, 4 features), aplique PCA com k=2: variância cumulativa ≈95%, erro de reconstrução baixo (~0.1), confirmando boa redução para visualização 2D sem perda significativa de info.",
                              "finalVerifications": [
                                "Variância explicada cumulativa atinge ≥90% com k mínimo.",
                                "Erro de reconstrução <5% da variância total dos dados.",
                                "Scree plot mostra elbow claro.",
                                "Reconstrução visual de scatter plots originais vs. reduzidos é fiel.",
                                "Relatório interpreta corretamente trade-offs."
                              ],
                              "assessmentCriteria": [
                                "Cálculos precisos de métricas (100% match com sklearn outputs).",
                                "Interpretação correta de thresholds e elbow (rubrica 1-5).",
                                "Visualizações claras e rotuladas adequadamente.",
                                "Escolha de k justificada com evidências quantitativas.",
                                "Relatório conciso e profissional (sem erros conceituais)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses para significância de componentes.",
                                "Machine Learning: Integração com clustering/supervised models pós-PCA.",
                                "Visualização de Dados: Scree plots e biplots.",
                                "Computação Científica: Otimização numérica em eigen-decomposição."
                              ],
                              "realWorldApplication": "Em genômica, avaliar PCA para reduzir milhares de genes a 10-50 componentes principais, mantendo >95% variância para downstream analysis como clustering de tumores, reduzindo tempo computacional de horas para minutos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.2",
                    "name": "Matriz de Covariância e Correlação",
                    "description": "Construção e interpretação das matrizes fundamentais para análise multivariada.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.2.1",
                        "name": "Matriz de Covariância",
                        "description": "Definição, fórmula e construção da matriz de covariância, que mede a dispersão conjunta entre múltiplas variáveis em contextos de econometria e análise de dados em engenharia, essencial para pressupostos de regressão linear e métodos como análise de componentes principais.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.2.1.1",
                            "name": "Definir covariância e matriz de covariância",
                            "description": "Explicar a covariância populacional e amostral, derivar a fórmula para múltiplas variáveis e identificar sua relação com a variância diagonal na matriz.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o conceito básico de covariância para duas variáveis",
                                  "subSteps": [
                                    "Defina covariância como uma medida da direção da relação linear entre duas variáveis aleatórias X e Y.",
                                    "Explique que covariância positiva indica movimento conjunto na mesma direção, negativa na direção oposta, e zero sugere ausência de relação linear.",
                                    "Diferencie covariância populacional (E[(X-μ_X)(Y-μ_Y)]) de amostral (1/(n-1) Σ (x_i - x̄)(y_i - ȳ)).",
                                    "Discuta unidades: produto das unidades de X e Y, o que limita interpretação direta.",
                                    "Ilustre com gráfico de dispersão: pontos alinhados positivamente, negativamente ou aleatoriamente."
                                  ],
                                  "verification": "Crie um gráfico de dispersão manual para dois conjuntos de dados e identifique o sinal da covariância esperada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e lápis para gráficos",
                                    "Calculadora",
                                    "Exemplos de dados: alturas e pesos de 10 pessoas"
                                  ],
                                  "tips": "Sempre pense em termos de desvios da média para visualizar o produto.",
                                  "learningObjective": "Compreender intuitivamente o que a covariância mede e suas implicações directionais.",
                                  "commonMistakes": [
                                    "Confundir covariância com correlação (normalizada)",
                                    "Usar n em vez de n-1 na amostra",
                                    "Ignorar que zero não implica independência"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar as fórmulas de covariância populacional e amostral",
                                  "subSteps": [
                                    "Derive a fórmula populacional: Cov(X,Y) = E[XY] - E[X]E[Y], expandindo E[(X-μ_X)(Y-μ_Y)].",
                                    "Mostre a equivalência algébrica entre as duas formas da fórmula populacional.",
                                    "Para amostral, derive a partir da populacional assumindo amostra representativa, justificando o divisor n-1 (correção de Bessel).",
                                    "Calcule numericamente Cov para um pequeno dataset: liste desvios, produtos e média.",
                                    "Compare resultados com software como Python (numpy.cov) para validação."
                                  ],
                                  "verification": "Derive e calcule Cov para dataset fornecido, comparando com resultado computacional (erro < 1%).",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Folha de cálculo ou Excel",
                                    "Python com NumPy (opcional)",
                                    "Dataset exemplo: notas em duas disciplinas"
                                  ],
                                  "tips": "Expanda sempre (X-μ)(Y-μ) para E[XY] - μ_X μ_Y para facilitar memória.",
                                  "learningObjective": "Derivar e aplicar corretamente as fórmulas de covariância em contextos populacional e amostral.",
                                  "commonMistakes": [
                                    "Divisor n ao invés de n-1",
                                    "Esquecer de centralizar os dados",
                                    "Confundir E[XY] com média de produtos sem centralização"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estender covariância para múltiplas variáveis: Construir a matriz de covariância",
                                  "subSteps": [
                                    "Defina matriz de covariância Σ como k x k, onde Σ_{ij} = Cov(X_i, X_j).",
                                    "Explique que é simétrica (Cov(X,Y)=Cov(Y,X)) e diagonal Σ_{ii} = Var(X_i).",
                                    "Construa manualmente para 3 variáveis: calcule todos os pares Cov.",
                                    "Discuta propriedades: definida semi positiva, traço = soma de variâncias.",
                                    "Use notação matricial: Σ = E[(X-μ)(X-μ)^T] para população; amostral similar com 1/(n-1)."
                                  ],
                                  "verification": "Construa matriz 3x3 para dataset multivariado e verifique simetria e diagonal.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Matriz em papel ou Excel",
                                    "Dataset 3D: ex. temperatura, umidade, pressão para 20 observações"
                                  ],
                                  "tips": "Lembre: off-diagonal são covariâncias cruzadas; diagonal puramente variâncias.",
                                  "learningObjective": "Construir e interpretar matriz de covariância para vetores multivariados.",
                                  "commonMistakes": [
                                    "Não garantir simetria por erro de cálculo",
                                    "Confundir covariância com correlação na matriz",
                                    "Diagonal não igual à variância"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar relações e propriedades da matriz de covariância",
                                  "subSteps": [
                                    "Verifique que elementos diagonais são variâncias: prove Σ_{ii} = E[(X_i - μ_i)^2] = Var(X_i).",
                                    "Discuta interpretação: magnitude indica força da relação linear entre pares.",
                                    "Explore independência: Cov=0 para i≠j implica não-correlacionadas (mas não necessariamente independentes).",
                                    "Visualize com heatmap da matriz usando ferramenta simples.",
                                    "Conclua com ligação para PCA ou análise de risco: matriz captura dependências."
                                  ],
                                  "verification": "Explique por que diagonal = variância e crie heatmap confirmando propriedades.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Ferramenta de plot: Python matplotlib ou Excel heatmap",
                                    "Matriz do step anterior"
                                  ],
                                  "tips": "Use heatmaps para visualizar padrões; foque em sinal e magnitude.",
                                  "learningObjective": "Reconhecer propriedades chave da matriz e sua relação com variância.",
                                  "commonMistakes": [
                                    "Achar que Cov=0 implica independência total",
                                    "Ignorar que matriz não é de correlação",
                                    "Diagonal interpretada como covariância cruzada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de ações (preços de AAPL, GOOG, MSFT), calcule a matriz de covariância para medir como os retornos diários co-movem: diagonal mostra volatilidade individual, off-diagonal risco compartilhado para otimização de portfólio.",
                              "finalVerifications": [
                                "Deriva corretamente fórmulas de Cov populacional e amostral.",
                                "Constrói matriz de covariância simétrica para 3+ variáveis.",
                                "Identifica diagonal como variâncias e interpreta off-diagonais.",
                                "Calcula Cov numericamente com erro <1% vs software.",
                                "Explica limitações (unidades, não-causalidade).",
                                "Visualiza matriz via heatmap e discute insights."
                              ],
                              "assessmentCriteria": [
                                "Precisão nas derivações matemáticas (100% correta).",
                                "Correta distinção população vs amostra (divisor n-1).",
                                "Matriz simétrica com diagonal = Var comprovada.",
                                "Interpretação qualitativa e quantitativa precisa.",
                                "Exemplo prático aplicado corretamente.",
                                "Identificação de erros comuns evitados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Base para testes de hipótese e regressão.",
                                "Machine Learning: Pré-processamento em PCA e modelagem.",
                                "Finanças: Análise de risco em portfólios (Markowitz).",
                                "Física: Modelagem de variáveis correlacionadas em sistemas.",
                                "Economia: Análise de co-movimentos em séries temporais."
                              ],
                              "realWorldApplication": "Na gestão de portfólios financeiros, a matriz de covariância quantifica riscos compartilhados entre ativos, permitindo diversificação ótima para minimizar volatilidade sem sacrificar retornos esperados."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.2.1.2",
                            "name": "Calcular covariância amostral",
                            "description": "Aplicar a fórmula (1/n) * Σ (xi - x̄)(yj - ȳ) para pares de variáveis e computar manualmente ou via software (R ou Python) para um conjunto de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o conjunto de dados e calcular as médias amostrais",
                                  "subSteps": [
                                    "Selecione ou crie um conjunto de dados bivariado relevante para engenharia, com pelo menos 5-10 observações (ex: temperatura e eficiência de um motor).",
                                    "Identifique as variáveis X e Y, garantindo que sejam numéricas e sem valores ausentes.",
                                    "Calcule a média amostral de X (x̄ = Σ xi / n) e de Y (ȳ = Σ yi / n) manualmente.",
                                    "Registre os valores em uma tabela organizada (planilha ou papel).",
                                    "Verifique os cálculos de média com uma calculadora para precisão inicial."
                                  ],
                                  "verification": "Confirme que as médias calculadas batem com uma verificação cruzada em software como Excel ou calculadora.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Conjunto de dados de exemplo (papel ou Excel)",
                                    "Calculadora",
                                    "Planilha (Excel ou Google Sheets)"
                                  ],
                                  "tips": "Use n como o número de observações, não n-1 para covariância amostral não viesada conforme fórmula dada.",
                                  "learningObjective": "Dominar o cálculo preciso de médias amostrais como base para desvios.",
                                  "commonMistakes": [
                                    "Confundir n com n-1",
                                    "Arredondar prematuramente",
                                    "Ignorar outliers nos dados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular desvios individuais e produtos cruzados",
                                  "subSteps": [
                                    "Para cada par (xi, yi), compute o desvio de X: (xi - x̄).",
                                    "Compute o desvio de Y: (yi - ȳ).",
                                    "Multiplique os desvios: (xi - x̄)(yi - ȳ) para cada i.",
                                    "Liste todos os produtos em uma tabela ao lado dos dados originais.",
                                    "Some todos os produtos cruzados: Σ (xi - x̄)(yi - ȳ)."
                                  ],
                                  "verification": "Verifique que a soma dos desvios de X e de Y seja zero (propriedade das médias).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Tabela do Step 1",
                                    "Calculadora",
                                    "Papel quadriculado ou Excel para tabela"
                                  ],
                                  "tips": "Mantenha pelo menos 4 casas decimais nos desvios para evitar erros de propagação.",
                                  "learningObjective": "Entender como os desvios capturam a variabilidade conjunta das variáveis.",
                                  "commonMistakes": [
                                    "Esquecer o sinal negativo nos desvios",
                                    "Multiplicar errado os desvios",
                                    "Somar produtos incorretos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar a fórmula da covariância amostral manualmente",
                                  "subSteps": [
                                    "Divida a soma dos produtos pela quantidade de observações: cov(X,Y) = (1/n) * Σ (xi - x̄)(yi - ȳ).",
                                    "Registre o resultado com precisão decimal.",
                                    "Repita para todos os pares necessários em uma matriz (se multivariado).",
                                    "Interprete o sinal: positivo (movem juntos), negativo (oposto), zero (independente).",
                                    "Documente o processo em um relatório curto."
                                  ],
                                  "verification": "Compare o resultado manual com um cálculo rápido em Python ou R para um par simples.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Resultados dos Steps 1-2",
                                    "Calculadora científica"
                                  ],
                                  "tips": "A fórmula usa 1/n para amostral populacional; confirme o contexto do problema.",
                                  "learningObjective": "Executar o cálculo final da covariância com exatidão.",
                                  "commonMistakes": [
                                    "Usar 1/(n-1) em vez de 1/n",
                                    "Dividir pela soma errada",
                                    "Ignorar interpretação do sinal"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Implementar o cálculo via software (R ou Python)",
                                  "subSteps": [
                                    "Carregue os dados em um DataFrame (Python: pandas) ou data.frame (R).",
                                    "Use função built-in: Python (df.cov()), R (cov(data)).",
                                    "Calcule manualmente no código para comparar: np.mean((x - x_mean)*(y - y_mean)).",
                                    "Gere uma matriz de covariância para múltiplas variáveis.",
                                    "Visualize com heatmap (seaborn ou corrplot)."
                                  ],
                                  "verification": "Assert que resultado manual == software (tolerância 1e-6).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python (pandas, numpy) ou R instalado",
                                    "Jupyter Notebook ou RStudio",
                                    "Dataset em CSV"
                                  ],
                                  "tips": "Sempre padronize dados se scales diferirem muito.",
                                  "learningObjective": "Automatizar cálculos para datasets grandes e validar manual vs. computacional.",
                                  "commonMistakes": [
                                    "Índices errados no array",
                                    "Confundir cov() com cor()",
                                    "Dados não numéricos"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e interpretar em contexto de engenharia",
                                  "subSteps": [
                                    "Aplique a um dataset real de engenharia (ex: tensão vs. deformação).",
                                    "Compare covariâncias entre pares e discuta implicações.",
                                    "Teste sensibilidade removendo outliers.",
                                    "Escreva um parágrafo de interpretação.",
                                    "Salve código e resultados em repositório."
                                  ],
                                  "verification": "Cálculos consistentes em manual, Python e R; interpretação coerente.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset de engenharia (ex: de Kaggle)",
                                    "Código dos steps anteriores"
                                  ],
                                  "tips": "Covariância não é causal; use para pré-análise.",
                                  "learningObjective": "Conectar cálculo à análise multivariada prática.",
                                  "commonMistakes": [
                                    "Sobreinterpretar magnitude sem normalizar",
                                    "Ignorar unidades das variáveis"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um motor de combustão, dados de 10 testes: Temperatura do escapamento (X: 450, 480, ..., 520°C) e Eficiência térmica (Y: 32%, 34%, ..., 31%). Calcule cov(X,Y) manualmente e via Python para prever se alta temperatura reduz eficiência.",
                              "finalVerifications": [
                                "Cálculo manual coincide com software (erro < 0.001).",
                                "Soma de desvios é zero para cada variável.",
                                "Interpretação correta do sinal e magnitude.",
                                "Matriz de covariância simétrica e diagonal com variâncias.",
                                "Código reproduzível sem erros.",
                                "Relatório documenta todos os passos."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica nos cálculos (100% match com software).",
                                "Completude da tabela de desvios e produtos.",
                                "Correta implementação em pelo menos um software.",
                                "Interpretação contextualizada para engenharia.",
                                "Identificação e correção de erros comuns.",
                                "Eficiência temporal (dentro de 2h total)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Base para correlação e PCA.",
                                "Programação: Manipulação de dados em Python/R.",
                                "Engenharia: Análise de sensibilidade em sistemas multivariados.",
                                "Física: Modelagem de variáveis dependentes em experimentos."
                              ],
                              "realWorldApplication": "Em engenharia mecânica, calcular covariância entre variáveis como pressão e vazão em tubulações para otimizar designs e detectar falhas precoces em monitoramento preditivo."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.2.1.3",
                            "name": "Construir matriz de covariância completa",
                            "description": "Montar a matriz simétrica n x n a partir de dados multivariados, verificando propriedades como simetria e não-negatividade definida semi-definida.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o conjunto de dados multivariados",
                                  "subSteps": [
                                    "Colete um dataset com pelo menos 3 variáveis numéricas e n observações (n > 30 recomendado).",
                                    "Verifique a ausência de valores ausentes e outliers extremos.",
                                    "Organize os dados em uma matriz X de dimensão n x p, onde p é o número de variáveis.",
                                    "Salve em formato acessível (CSV, Excel ou array NumPy).",
                                    "Documente as variáveis e unidades de medida."
                                  ],
                                  "verification": "Dataset carregado corretamente sem erros, dimensões confirmadas (shape(n, p)).",
                                  "estimatedTime": "15-20 minutos",
                                  "materials": [
                                    "Dataset de exemplo (ex: CSV com variáveis como altura, peso, idade)",
                                    "Python com pandas/NumPy ou Excel"
                                  ],
                                  "tips": "Use funções como pd.read_csv() para carregar e df.shape para verificar dimensões.",
                                  "learningObjective": "Entender a estrutura de dados multivariados necessários para análise de covariância.",
                                  "commonMistakes": [
                                    "Ignorar valores ausentes levando a cálculos enviesados",
                                    "Confundir linhas (observações) com colunas (variáveis)",
                                    "Usar datasets com poucas observações"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular as médias de cada variável",
                                  "subSteps": [
                                    "Compute a média μ_j para cada variável j = 1 a p.",
                                    "Crie um vetor de médias μ de dimensão 1 x p.",
                                    "Verifique os cálculos manualmente para um subconjunto pequeno.",
                                    "Armazene as médias para uso posterior.",
                                    "Confirme que as médias são escalares finitos."
                                  ],
                                  "verification": "Vetor de médias calculado e comparado com função built-in (ex: np.mean(axis=0)).",
                                  "estimatedTime": "10-15 minutos",
                                  "materials": [
                                    "Código Python/NumPy: np.mean(X, axis=0)",
                                    "Calculadora ou Excel para validação manual"
                                  ],
                                  "tips": "Centralize mentalmente: subtraia médias para mean-zero antes de covariâncias.",
                                  "learningObjective": "Dominar o cálculo de estatísticas univariadas como pré-requisito para multivariadas.",
                                  "commonMistakes": [
                                    "Calcular média ao longo de eixos errados",
                                    "Usar mediana em vez de média aritmética",
                                    "Arredondar prematuramente causando erros de precisão"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Centralizar os dados e calcular covariâncias elementares",
                                  "subSteps": [
                                    "Crie a matriz centralizada Z = X - μ (broadcasting para subtrair vetor de médias).",
                                    "Para cada par (i,j), calcule cov_ij = (1/(n-1)) * sum_{k=1}^n (Z_{k,i} * Z_{k,j}).",
                                    "Use fórmula não-bias (divisor n-1) para amostra.",
                                    "Calcule todos os p(p+1)/2 elementos únicos.",
                                    "Armazene em estrutura temporária (dicionário ou matriz superior)."
                                  ],
                                  "verification": "Verifique se colunas de Z têm média zero: np.mean(Z, axis=0) ≈ 0.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "NumPy: X_centered = X - np.mean(X, axis=0)",
                                    "np.dot(Z.T, Z) / (n-1) para matriz completa"
                                  ],
                                  "tips": "Implemente loop duplo para pares i<=j para eficiência.",
                                  "learningObjective": "Aplicar centralização e fórmula de covariância amostral corretamente.",
                                  "commonMistakes": [
                                    "Usar n em vez de n-1 (viés)",
                                    "Esquecer centralização levando a covariâncias incorretas",
                                    "Confundir covariância com correlação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Montar a matriz completa e verificar propriedades",
                                  "subSteps": [
                                    "Construa matriz Σ n x n simétrica preenchendo Σ_ij = cov_ij e Σ_ji = cov_ij.",
                                    "Preencha diagonal com variâncias (cov_ii).",
                                    "Verifique simetria: Σ == Σ.T.",
                                    "Confirme semi-definida positiva: todos autovalores ≥ 0.",
                                    "Salve/exporte a matriz final."
                                  ],
                                  "verification": "Testes passados: simetria exata, autovalores não-negativos (np.linalg.eigvals(Σ) >= 0).",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "NumPy: np.cov(X.T) para validação",
                                    "Funções eigvals para verificação"
                                  ],
                                  "tips": "Use np.cov(X.T) como benchmark para comparar sua implementação.",
                                  "learningObjective": "Construir e validar matriz de covariância com propriedades teóricas.",
                                  "commonMistakes": [
                                    "Matriz não simétrica por erro de cálculo",
                                    "Autovalores negativos devido a divisor errado",
                                    "Diagonal com covariâncias off-diagonal"
                                  ]
                                }
                              ],
                              "practicalExample": "Dado um dataset de 50 observações com 3 variáveis (temperatura, umidade, pressão em uma cidade), centralize os dados, calcule cov(temperatura-umidade) ≈ 2.5, cov(temperatura-pressão) ≈ -1.2, etc., montando Σ = [[4.2, 2.5, -1.2], [2.5, 3.8, 0.9], [-1.2, 0.9, 2.1]].",
                              "finalVerifications": [
                                "Matriz resultante é simétrica (Σ[i,j] == Σ[j,i] para todo i,j).",
                                "Elementos da diagonal são variâncias positivas ou zero.",
                                "Todos autovalores são não-negativos (semi-definida positiva).",
                                "Cálculos coincidem com função padrão (ex: np.cov(X.T)).",
                                "Centralização confirmada (médias das colunas = 0).",
                                "Uso correto do divisor n-1 para amostra."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de médias e centralização (erro < 1e-6).",
                                "Correta implementação da fórmula de covariância sem viés.",
                                "Simetria e propriedades da matriz verificadas programaticamente.",
                                "Eficiência computacional (evitar loops desnecessários em grandes p).",
                                "Documentação clara dos passos e resultados.",
                                "Validação cruzada com ferramentas built-in."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Descritiva (médias, variâncias univariadas).",
                                "Programação Computacional (NumPy, loops vetoriais).",
                                "Álgebra Linear (propriedades de matrizes simétricas, autovalores).",
                                "Machine Learning (pré-processamento para PCA ou regressão).",
                                "Finanças (modelagem de risco em portfólios)."
                              ],
                              "realWorldApplication": "Em finanças, constrói-se a matriz de covariância de retornos de ações para otimizar portfólios via Markowitz; em ML, é essencial para PCA reduzindo dimensionalidade em datasets de imagens ou genômica."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.2.1.4",
                            "name": "Interpretar matriz de covariância",
                            "description": "Analisar sinais (positivo/negativo para direção da relação), magnitudes para força da dependência linear e implicações em regressão linear (ex.: multicolinearidade).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Estrutura da Matriz de Covariância",
                                  "subSteps": [
                                    "Revise a fórmula da covariância: Cov(X,Y) = Σ[(Xi - μX)(Yi - μY)] / (n-1)",
                                    "Identifique elementos diagonais como variâncias das variáveis",
                                    "Observe que a matriz é simétrica: Cov(X,Y) = Cov(Y,X)",
                                    "Pratique construindo uma matriz simples com 3 variáveis usando dados fictícios",
                                    "Visualize a matriz em formato tabular para entender posições off-diagonal"
                                  ],
                                  "verification": "Construa manualmente uma matriz de covariância para um dataset pequeno (3 variáveis, 5 observações) e confirme simetria e diagonais como variâncias.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Dataset exemplo com 3 variáveis (ex: altura, peso, idade)",
                                    "Calculadora ou Python com NumPy"
                                  ],
                                  "tips": "Sempre normalize os dados subtraindo as médias antes de calcular para evitar erros de escala.",
                                  "learningObjective": "Dominar a estrutura simétrica da matriz e diferenciar variâncias (diagonal) de covariâncias (off-diagonal).",
                                  "commonMistakes": [
                                    "Confundir covariância com correlação (correlação é normalizada)",
                                    "Usar n em vez de n-1 (amostra vs população)",
                                    "Ignorar a simetria e interpretar unilateralmente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar Sinais Positivos e Negativos das Covariâncias",
                                  "subSteps": [
                                    "Analise Cov(X,Y) > 0: variáveis tendem a aumentar juntas (relação positiva)",
                                    "Analise Cov(X,Y) < 0: uma aumenta enquanto a outra diminui (relação negativa)",
                                    "Cov(X,Y) ≈ 0: pouca ou nenhuma dependência linear detectada",
                                    "Compare múltiplos pares de variáveis na matriz",
                                    "Desenhe setas em um diagrama para visualizar direções das relações"
                                  ],
                                  "verification": "Para uma matriz exemplo, liste todas as relações positivas, negativas e neutras corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Matriz de covariância exemplo impressa ou digital",
                                    "Papel e caneta para diagramas",
                                    "Software como R ou Python para gerar matrizes"
                                  ],
                                  "tips": "Lembre-se: sinal indica direção, não causalidade – evite inferir causa.",
                                  "learningObjective": "Identificar corretamente a direção da dependência linear entre pares de variáveis.",
                                  "commonMistakes": [
                                    "Interpretar sinal como causalidade",
                                    "Ignorar covariâncias próximas a zero como 'fracas' sem verificar magnitude",
                                    "Confundir com correlação de Pearson"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Avaliar Magnitudes para Força da Dependência Linear",
                                  "subSteps": [
                                    "Compare magnitudes absolutas: |Cov| grande indica forte dependência linear",
                                    "Relacione com escalas das variáveis: normalize comparando com variâncias diagonais",
                                    "Calcule coeficiente de correlação simples: Corr = Cov / (σX * σY) para contexto",
                                    "Classifique: fraca (<0.1*σ média), moderada (0.1-0.5*σ), forte (>0.5*σ)",
                                    "Pratique ranqueando covariâncias por força em uma matriz real"
                                  ],
                                  "verification": "Classifique as forças de 5 covariâncias em uma matriz e justifique com comparações às variâncias.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Dataset multivariado (ex: Boston Housing)",
                                    "Python/Jupyter com pandas e numpy",
                                    "Tabela de referência de escalas de força"
                                  ],
                                  "tips": "Sempre verifique unidades/escalas das variáveis para interpretar magnitudes corretamente.",
                                  "learningObjective": "Quantificar a força da dependência linear usando magnitudes relativas às variâncias.",
                                  "commonMistakes": [
                                    "Interpretar magnitude absoluta sem considerar escalas diferentes",
                                    "Confundir força com significância estatística",
                                    "Ignorar variâncias diagonais para normalização"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar Implicações em Regressão Linear (Multicolinearidade)",
                                  "subSteps": [
                                    "Identifique covariâncias altas off-diagonal: indica multicolinearidade entre preditores",
                                    "Calcule VIF aproximado: VIFj = 1 / (1 - R²j) onde R² de regressão de Xj em outras Xs",
                                    "Discuta impactos: coeficientes instáveis, inflação de variância de erros",
                                    "Sugira soluções: remoção de variáveis, PCA ou ridge regression",
                                    "Aplique a uma matriz de preditores de regressão exemplo"
                                  ],
                                  "verification": "Detecte multicolinearidade em uma matriz e proponha 2 soluções com justificativa.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dataset para regressão (ex: mtcars)",
                                    "Python com statsmodels para VIF",
                                    "Documentação de multicolinearidade"
                                  ],
                                  "tips": "Foquem em |Cov| > 0.5 * min(σi,σj) como threshold inicial para suspeita.",
                                  "learningObjective": "Reconhecer e mitigar multicolinearidade usando insights da matriz de covariância.",
                                  "commonMistakes": [
                                    "Assumir multicolinearidade só por covariâncias positivas",
                                    "Ignorar que multicolinearidade afeta inferência, não predição",
                                    "Não diferenciar multicolinearidade perfeita (singular) de alta"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere um dataset de vendas: variáveis PreçoProduto, PublicidadeTV, Vendas. Matriz de Cov: [[10.2, 2.1, 8.5], [2.1, 4.3, 3.2], [8.5, 3.2, 15.1]]. Cov(Preço,Vendas)=8.5>0 forte (preços altos com vendas altas?); Cov(PublicidadeTV,Vendas)=3.2>0 moderado; alta Cov(Preço,Vendas) sugere multicolinearidade em regressão de Vendas ~ Preço + PublicidadeTV.",
                              "finalVerifications": [
                                "Explique corretamente o significado de um elemento off-diagonal positivo, negativo e zero.",
                                "Classifique magnitudes de covariâncias como fracas/moderadas/fortes com justificativa relativa às variâncias.",
                                "Identifique potenciais multicolinearidades em uma matriz 4x4 fornecida.",
                                "Proponha pelo menos uma implicação prática para regressão linear.",
                                "Construa e interprete uma matriz simples de 3 variáveis.",
                                "Diferencie covariância de correlação em um exemplo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de sinais (100% correto).",
                                "Correta quantificação de forças com normalização por variâncias (erro <10%).",
                                "Detecção completa de implicações como multicolinearidade (cobre todos pares relevantes).",
                                "Uso de exemplos concretos e linguagem clara sem jargões desnecessários.",
                                "Completude: todos aspectos (direção, força, implicações) abordados.",
                                "Criatividade em conexões reais ou soluções propostas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Ligação com testes de hipótese para significância de covariâncias.",
                                "Programação: Uso de NumPy (np.cov()) ou R (cov()) para computação prática.",
                                "Machine Learning: Pré-processamento de features para evitar multicolinearidade em modelos.",
                                "Economia/Finanças: Análise de correlações em retornos de ativos para diversificação de portfólio.",
                                "Biologia: Estudo de dependências entre genes em análise genômica multivariada."
                              ],
                              "realWorldApplication": "Em finanças, interpretar matriz de covariância de retornos de ações ajuda a construir portfólios diversificados (baixas covariâncias reduzem risco); em ML, detecta multicolinearidade em features de modelos de regressão, melhorando estabilidade de predições em previsões de vendas ou saúde."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.2.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.2.2",
                        "name": "Matriz de Correlação",
                        "description": "Construção e interpretação da matriz de correlação, obtida a partir da padronização da matriz de covariância, fundamental para análise multivariada padronizada em econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.2.2.1",
                            "name": "Definir coeficiente de correlação de Pearson",
                            "description": "Explicar correlação como covariância padronizada, fórmula r = cov(X,Y)/(σx σy), e propriedades (intervalo [-1,1], invariância à escala).",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Covariância",
                                  "subSteps": [
                                    "Defina covariância como a medida da direção da relação linear entre duas variáveis X e Y.",
                                    "Explique que covariância positiva indica movimento conjunto na mesma direção, negativa na direção oposta, e zero indica ausência de relação linear.",
                                    "Discuta a fórmula básica: cov(X,Y) = Σ[(Xi - μx)(Yi - μy)] / (n-1), onde μ é a média.",
                                    "Compare com variância, que é cov(X,X).",
                                    "Identifique limitações: dependente de unidades e escala."
                                  ],
                                  "verification": "Escreva a definição e fórmula da covariância em suas próprias palavras e calcule cov para um conjunto de dados pequeno (ex: X=[1,2,3], Y=[2,4,6]).",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta ou calculadora",
                                    "Planilha Excel ou Google Sheets para prática"
                                  ],
                                  "tips": "Visualize graficamente com scatter plot para intuitivamente entender a direção da covariância.",
                                  "learningObjective": "Entender covariância como base para correlação, reconhecendo sua dependência de escala.",
                                  "commonMistakes": [
                                    "Confundir covariância com correlação.",
                                    "Usar n em vez de n-1 na fórmula amostral.",
                                    "Ignorar que covariância pode ser ilimitada em magnitude."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Revisar Desvio Padrão e Padronização",
                                  "subSteps": [
                                    "Recapitule variância: σ² = cov(X,X) = Σ(Xi - μ)² / (n-1).",
                                    "Defina desvio padrão σ como raiz quadrada da variância, medindo dispersão em unidades originais.",
                                    "Explique padronização: dividir por σx e σy normaliza as variáveis para escala unitária.",
                                    "Calcule σ para conjuntos de dados simples.",
                                    "Discuta por que padronização resolve o problema de escala da covariância."
                                  ],
                                  "verification": "Calcule σx e σy para os dados do Step 1 e explique como eles padronizam a covariância.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Calculadora",
                                    "Tutorial online sobre desvio padrão (Khan Academy)"
                                  ],
                                  "tips": "Lembre-se: σ é sempre positivo e reflete variabilidade; pratique com dados reais para fixar.",
                                  "learningObjective": "Dominar desvio padrão como normalizador essencial para correlação.",
                                  "commonMistakes": [
                                    "Confundir desvio padrão com variância.",
                                    "Esquecer raiz quadrada na definição de σ.",
                                    "Usar população vs. amostra incorretamente (n vs. n-1)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar e Memorizar a Fórmula da Correlação de Pearson",
                                  "subSteps": [
                                    "Apresente a fórmula: r = cov(X,Y) / (σx * σy).",
                                    "Derive intuitivamente: correlação é covariância 'dividida' pelas dispersões individuais.",
                                    "Escreva a forma expandida: r = Σ[(Xi - μx)(Yi - μy)] / [(n-1) σx σy].",
                                    "Calcule r manualmente para um exemplo: X=[1,2,3], Y=[1,4,5] → r ≈ 0.98.",
                                    "Implemente em uma ferramenta como Excel (=CORREL(X,Y)) para validar."
                                  ],
                                  "verification": "Derive a fórmula do zero e calcule r para um novo par de dados, comparando com software.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Excel ou Python (pandas.corr())",
                                    "Papel para derivação"
                                  ],
                                  "tips": "Pense em r como 'covariância padronizada' – sempre entre -1 e 1 após normalização.",
                                  "learningObjective": "Aplicar e derivar a fórmula r, entendendo-a como medida padronizada.",
                                  "commonMistakes": [
                                    "Esquecer o denominador σx σy.",
                                    "Usar médias erradas nos cálculos.",
                                    "Confundir com coeficiente de determinação (r²)."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Propriedades e Interpretação",
                                  "subSteps": [
                                    "Liste propriedades: r ∈ [-1,1]; r=1 (correlação perfeita positiva), r=-1 (perfeita negativa), r=0 (sem correlação linear).",
                                    "Explique invariância à escala: mudar unidades de X ou Y não altera r.",
                                    "Discuta simetria: r(X,Y) = r(Y,X).",
                                    "Interprete magnitudes: |r|>0.7 forte, 0.3-0.7 moderada, <0.3 fraca.",
                                    "Avisos: r mede só linearidade; não implica causalidade."
                                  ],
                                  "verification": "Para cenários dados (ex: r=0.9, r=-0.5), interprete corretamente e cite propriedades violadas se aplicável.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Scatter plots de exemplos (online generator)",
                                    "Tabela de interpretação de r"
                                  ],
                                  "tips": "Sempre plote dados: alta |r| sem linearidade indica falha (ex: quadrático).",
                                  "learningObjective": "Interpretar r corretamente, conhecendo limites e propriedades chave.",
                                  "commonMistakes": [
                                    "Interpretar r=0 como independência total.",
                                    "Confundir correlação com causalidade.",
                                    "Ignorar que r é insensível a relações não-lineares."
                                  ]
                                }
                              ],
                              "practicalExample": "Calcule o coeficiente de correlação de Pearson entre altura (cm: [160, 170, 180, 190]) e peso (kg: [50, 60, 70, 90]). Passos: médias (μh=175, μp=67.5), covariância ≈166.67, σh≈12.99, σp≈16.58, r≈0.98 (correlação forte positiva, como esperado).",
                              "finalVerifications": [
                                "Recite a fórmula r = cov(X,Y)/(σx σy) sem olhar.",
                                "Explique por que r é invariante à escala com um exemplo.",
                                "Calcule r corretamente para um dataset de 5 pares de dados.",
                                "Interprete r=0.4, r=-0.8 e r=0 em termos de força e direção.",
                                "Identifique 3 limitações do coeficiente de Pearson.",
                                "Compare r com cov em uma frase."
                              ],
                              "assessmentCriteria": [
                                "Precisão na derivação e memorização da fórmula (100% correto).",
                                "Compreensão conceitual: explica padronização corretamente.",
                                "Habilidade de cálculo: erros <5% em exemplos numéricos.",
                                "Interpretação qualitativa: distingue força/direção e limitações.",
                                "Aplicação: usa propriedades em contextos variados.",
                                "Clareza na explicação verbal/escrita de propriedades."
                              ],
                              "crossCurricularConnections": [
                                "Programação: Implementar em Python (pandas.corr()) para análise de dados reais.",
                                "Economia: Analisar correlação entre PIB e desemprego.",
                                "Biologia: Correlação entre tamanho de asas e velocidade em aves.",
                                "Física: Correlação entre força aplicada e aceleração (lei de Newton).",
                                "Psicologia: Correlação entre horas de estudo e notas em testes."
                              ],
                              "realWorldApplication": "Em finanças, mede correlação entre retornos de ações para diversificação de portfólio (ex: r baixo entre tech e energia reduz risco); em machine learning, seleciona features com alta correlação com target; em saúde, correlaciona IMC com pressão arterial para estudos epidemiológicos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.2.2.2",
                            "name": "Construir matriz de correlação",
                            "description": "Calcular a partir da matriz de covariância dividindo por desvios-padrão ou diretamente via fórmula amostral, usando dados de regressão em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o dataset multivariado e calcular estatísticas descritivas básicas",
                                  "subSteps": [
                                    "Colete um dataset com pelo menos 3 variáveis numéricas relevantes, como temperatura, pressão e eficiência em testes de motor de engenharia (mínimo 10 observações).",
                                    "Calcule a média de cada variável usando a fórmula μ = Σx_i / n.",
                                    "Calcule o desvio-padrão amostral de cada variável: s = sqrt( Σ(x_i - μ)^2 / (n-1) ).",
                                    "Organize os resultados em uma tabela com colunas para média e desvio-padrão de cada variável.",
                                    "Verifique a ausência de valores ausentes ou outliers extremos que possam distorcer os cálculos."
                                  ],
                                  "verification": "Confirme que médias e desvios-padrão foram calculados corretamente comparando com uma ferramenta como Excel ou Python (numpy.std(ddof=1)).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dataset em CSV ou Excel",
                                    "Calculadora científica ou Python (NumPy/Pandas)",
                                    "Papel e caneta para cálculos manuais"
                                  ],
                                  "tips": "Padronize unidades das variáveis para consistência (ex: °C para temperatura). Use n-1 para desvio-padrão amostral.",
                                  "learningObjective": "Dominar o preparo de dados e estatísticas univariadas necessárias para correlação.",
                                  "commonMistakes": [
                                    "Usar desvio-padrão populacional (dividir por n em vez de n-1)",
                                    "Ignorar outliers que afetam médias"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a matriz de covariância amostral",
                                  "subSteps": [
                                    "Para cada par de variáveis (i,j), calcule a covariância: cov(X_i, X_j) = Σ( (x_{k,i} - μ_i)(x_{k,j} - μ_j) ) / (n-1).",
                                    "Preencha a matriz simétrica: diagonal com variâncias (cov(X_i,X_i) = s_i^2), off-diagonal com covariâncias.",
                                    "Use uma planilha ou código para automatizar: em Python, np.cov(data, rowvar=False, bias=False).",
                                    "Registre todos os elementos da matriz em formato tabular.",
                                    "Confirme simetria: cov(i,j) == cov(j,i)."
                                  ],
                                  "verification": "A matriz deve ser simétrica e a diagonal deve igualar os quadrados dos desvios-padrão calculados no Step 1.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Mesmos do Step 1",
                                    "Planilha Excel ou Google Sheets",
                                    "Código Python pronto: import numpy as np"
                                  ],
                                  "tips": "Comece com pares simples antes de matriz completa. Automatize para datasets maiores.",
                                  "learningObjective": "Entender e computar covariâncias como base para correlações.",
                                  "commonMistakes": [
                                    "Dividir por n em vez de n-1",
                                    "Confundir covariância com correlação (unidades preservadas na cov)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir a matriz de correlação normalizando a covariância",
                                  "subSteps": [
                                    "Para cada elemento (i,j), aplique r_{i,j} = cov(i,j) / (s_i * s_j).",
                                    "Preencha a nova matriz: diagonal sempre 1 (r_{i,i} = 1), off-diagonal entre -1 e 1.",
                                    "Alternativa direta: r_{i,j} = [Σ( (x_{k,i}-μ_i)(x_{k,j}-μ_j) ) / (n-1) ] / (s_i * s_j).",
                                    "Implemente em código: np.corrcoef(data, rowvar=False).",
                                    "Compare resultados da normalização vs. fórmula direta para validação cruzada."
                                  ],
                                  "verification": "Todos elementos off-diagonal em [-1,1], diagonal = 1, simetria preservada.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Matriz de covariância do Step 2",
                                    "Desvios-padrão do Step 1",
                                    "Python ou Excel para divisão elemento a elemento"
                                  ],
                                  "tips": "Use broadcasting em NumPy para eficiência: corr = cov / (std[:, None] * std).",
                                  "learningObjective": "Aplicar normalização para obter correlações padronizadas e adimensionais.",
                                  "commonMistakes": [
                                    "Esquecer de normalizar diagonal (deve ser 1)",
                                    "Dividir por s_i^2 incorretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar, interpretar e documentar a matriz de correlação",
                                  "subSteps": [
                                    "Verifique propriedades: simetria, diagonal 1, range [-1,1].",
                                    "Identifique correlações fortes (>0.7 ou <-0.7) e interprete (ex: correlação positiva indica relação direta).",
                                    "Crie um heatmap visual usando seaborn.heatmap(corr).",
                                    "Discuta limitações: correlação ≠ causalidade, sensível a outliers.",
                                    "Salve a matriz em JSON/CSV e gere relatório com insights para regressão em engenharia."
                                  ],
                                  "verification": "Heatmap gerado sem erros e interpretações coerentes com dados.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Matriz final",
                                    "Python (Matplotlib/Seaborn)",
                                    "Ferramenta de visualização"
                                  ],
                                  "tips": "Use cores divergentes no heatmap (azul-negativo, vermelho-positivo).",
                                  "learningObjective": "Interpretar matrizes de correlação no contexto de análise multivariada.",
                                  "commonMistakes": [
                                    "Interpretar magnitude como causalidade",
                                    "Ignorar significância estatística"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados de engenharia de um motor: 10 testes com variáveis Temperatura (°C): [100,105,110,115,120,125,130,135,140,145]; Pressão (bar): [1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9]; Eficiência (%): [85,87,88,89,90,91,92,93,94,95]. Médias: T=122.5, P=1.5, E=91.4. Desvios-padrão: s_T≈15.81, s_P≈0.316, s_E≈3.03. Covariância inclui cov(T,P)≈5.0. Correlação r(T,P)=5.0/(15.81*0.316)≈1.0 (forte positiva). Matriz final: [[1,1,0.99],[1,1,0.99],[0.99,0.99,1]].",
                              "finalVerifications": [
                                "Matriz é simétrica com diagonal igual a 1.",
                                "Todos elementos off-diagonal estão no intervalo [-1, 1].",
                                "Correlações calculadas coincidem com np.corrcoef() (±0.001 de precisão).",
                                "Visualização (heatmap) reflete valores corretamente.",
                                "Interpretação identifica pelo menos uma correlação forte.",
                                "Documentação inclui fórmulas usadas e dataset fonte."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática: erros <0.01 nos coeficientes.",
                                "Completude: todos pares de variáveis processados.",
                                "Correta normalização: uso de desvios-padrão amostrais.",
                                "Validação: propriedades da matriz confirmadas.",
                                "Interpretação contextual: ligada a regressão em engenharia.",
                                "Eficiência: código ou cálculos otimizados sem erros."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de significância de Pearson.",
                                "Engenharia: Análise de falhas multivariadas em sistemas.",
                                "Machine Learning: Pré-processamento para modelos de regressão.",
                                "Economia: Análise de risco em portfólios via correlações."
                              ],
                              "realWorldApplication": "Em engenharia, construir matriz de correlação identifica relações entre variáveis como temperatura, pressão e eficiência em turbinas, otimizando regressões lineares para previsão de falhas e design preditivo, reduzindo custos em manutenção preventiva."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.2.1.2"
                            ]
                          },
                          {
                            "id": "10.1.6.2.2.3",
                            "name": "Interpretar matriz de correlação",
                            "description": "Avaliar força e direção das correlações lineares bivariadas, identificar padrões multivariados e discutir impactos em modelos de regressão e PCA.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a Estrutura da Matriz de Correlação",
                                  "subSteps": [
                                    "Examine a diagonal principal, que sempre contém valores iguais a 1, representando a correlação perfeita de uma variável consigo mesma.",
                                    "Identifique os elementos off-diagonal, que variam de -1 a 1, indicando a força e direção da relação linear entre pares de variáveis.",
                                    "Note a simetria da matriz: o valor em (i,j) é igual ao em (j,i).",
                                    "Interprete o sinal: positivo para correlação direta, negativo para inversa, zero para ausência de relação linear.",
                                    "Visualize a matriz usando um heatmap para facilitar a identificação de padrões visuais."
                                  ],
                                  "verification": "Construa uma matriz de correlação 3x3 simples manualmente e explique cada elemento para um colega.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software como Python (pandas, seaborn) ou Excel",
                                    "Dataset de exemplo com 3-5 variáveis numéricas"
                                  ],
                                  "tips": "Sempre comece pela diagonal para confirmar a estrutura correta antes de analisar off-diagonais.",
                                  "learningObjective": "Reconhecer e descrever os componentes fundamentais de uma matriz de correlação.",
                                  "commonMistakes": [
                                    "Confundir correlação com causalidade",
                                    "Ignorar a simetria da matriz",
                                    "Interpretar valores próximos de zero como 'sem relação' sem contexto"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Avaliar Força e Direção das Correlações Bivariadas",
                                  "subSteps": [
                                    "Classifique a força: |r| < 0.3 (fraca), 0.3-0.7 (moderada), >0.7 (forte).",
                                    "Determine a direção: r > 0 (positiva), r < 0 (negativa).",
                                    "Considere o contexto do dataset para avaliar relevância prática, não apenas o valor absoluto.",
                                    "Calcule ou extraia valores de correlação Pearson para pares específicos usando código ou fórmula.",
                                    "Compare múltiplos pares para priorizar relações mais fortes."
                                  ],
                                  "verification": "Selecione 3 pares de variáveis de um dataset e classifique corretamente sua força e direção em um relatório curto.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código Python: df.corr() e sns.heatmap()",
                                    "Dataset bivariado como altura vs peso"
                                  ],
                                  "tips": "Use escalas padrão de força como guia, mas ajuste com base no domínio (ex: em finanças, 0.5 pode ser forte).",
                                  "learningObjective": "Quantificar e qualificar correlações lineares entre duas variáveis.",
                                  "commonMistakes": [
                                    "Sobreestimar força em amostras pequenas",
                                    "Ignorar outliers que distorcem r",
                                    "Confundir magnitude com significância estatística"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar Padrões Multivariados na Matriz",
                                  "subSteps": [
                                    "Procure clusters de alta correlação (blocos de valores >0.7) indicando grupos de variáveis relacionadas.",
                                    "Identifique variáveis isoladas (baixas correlações com todas as outras) como independentes.",
                                    "Detecte padrões de multicolinearidade: linhas/colunas com múltiplos altos |r|.",
                                    "Analise triângulos ou cadeias de correlações (ex: A-B forte, B-C forte, mas A-C fraca).",
                                    "Use dendrogramas ou clustering hierárquico para visualizar estruturas globais."
                                  ],
                                  "verification": "Descreva 2 padrões multivariados (ex: cluster, outlier) em uma matriz de 5x5 e justifique com valores específicos.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Python: seaborn.clustermap()",
                                    "Dataset multivariado como Boston Housing ou Iris"
                                  ],
                                  "tips": "Foque em blocos quadrados no heatmap para clusters rápidos.",
                                  "learningObjective": "Detectar e interpretar relações complexas entre múltiplas variáveis.",
                                  "commonMistakes": [
                                    "Focar apenas em pares mais altos sem ver o todo",
                                    "Ignorar correlações negativas em clusters",
                                    "Confundir correlação espúria com padrão real"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Discutir Impactos em Modelos de Regressão e PCA",
                                  "subSteps": [
                                    "Avalie multicolinearidade para regressão: altos |r| entre preditores inflacionam variâncias e reduzem interpretabilidade.",
                                    "Explique soluções para regressão: remoção de variáveis, ridge regression ou VIF >5-10.",
                                    "Para PCA, identifique como altas correlações justificam redução de dimensionalidade via componentes principais.",
                                    "Preveja loadings em PCA: variáveis altamente correlacionadas carregam em mesmos PCs.",
                                    "Discuta limitações: correlação assume linearidade, não captura não-linearidades."
                                  ],
                                  "verification": "Escreva um parágrafo explicando como uma correlação de 0.85 afeta um modelo de regressão linear múltipla.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Documentação scikit-learn para PCA e Ridge",
                                    "Exemplo de regressão com dataset correlacionado"
                                  ],
                                  "tips": "Sempre ligue de volta à matriz: 'Esta multicolinearidade aqui impacta assim'.",
                                  "learningObjective": "Aplicar interpretações da matriz a modelagem estatística avançada.",
                                  "commonMistakes": [
                                    "Assumir causalidade em regressão",
                                    "Subestimar efeitos em PCA para dados não-correlacionados",
                                    "Ignorar testes como VIF"
                                  ]
                                }
                              ],
                              "practicalExample": "No dataset Iris, interprete a matriz mostrando correlação forte positiva (0.87) entre comprimento e largura da pétala, indicando que flores maiores têm pétalas proporcionais; identifique cluster floral e discuta remoção de uma variável em regressão para prever espécies.",
                              "finalVerifications": [
                                "Explicar corretamente força e direção de 5 pares selecionados de uma matriz.",
                                "Identificar pelo menos um cluster multivariado e uma variável independente.",
                                "Discutir impacto de multicolinearidade em um modelo de regressão hipotético.",
                                "Gerar e interpretar um heatmap com código Python.",
                                "Prever estrutura de loadings em PCA baseado na matriz.",
                                "Listar limitações da correlação linear em um contexto real."
                              ],
                              "assessmentCriteria": [
                                "Precisão na classificação de força/direção (90%+ acertos).",
                                "Profundidade na detecção de padrões multivariados (mínimo 2 identificados).",
                                "Relevância das implicações para regressão/PCA (conexões lógicas e corretas).",
                                "Uso adequado de visualizações e código para suporte.",
                                "Clareza na comunicação escrita/oral de interpretações.",
                                "Consideração de limitações e contexto prático."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de significância para correlações (p-valores).",
                                "Machine Learning: Pré-processamento para evitar multicolinearidade em modelos.",
                                "Econometria: Análise de séries temporais e cointegração.",
                                "Bioinformática: Análise de genes correlacionados em expressão.",
                                "Finanças: Modelagem de risco via correlogramas de retornos."
                              ],
                              "realWorldApplication": "Em portfólios de investimento, interpretar matriz de correlação entre ativos para diversificar riscos, evitando combinações de alta correlação positiva que amplificam perdas em crises econômicas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.2.2.1"
                            ]
                          },
                          {
                            "id": "10.1.6.2.2.4",
                            "name": "Comparar matrizes de covariância e correlação",
                            "description": "Explicar diferenças (escala vs. padronização), quando usar cada uma em análise de dados de engenharia e relação com pressupostos de mínimos quadrados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Definições Fundamentais de Covariância e Correlação",
                                  "subSteps": [
                                    "Defina covariância como a medida de como duas variáveis variam juntas, incluindo fórmula: Cov(X,Y) = E[(X - μ_X)(Y - μ_Y)]",
                                    "Explique correlação como covariância padronizada: ρ = Cov(X,Y) / (σ_X σ_Y), variando de -1 a 1",
                                    "Discuta matrizes: covariância é n x n simétrica com variâncias na diagonal; correlação tem 1s na diagonal",
                                    "Identifique que covariância depende de unidades, enquanto correlação é unitless",
                                    "Calcule manualmente covariância e correlação para dois pares de dados simples (ex: X=[1,2,3], Y=[2,4,6])"
                                  ],
                                  "verification": "Resuma em um parágrafo as diferenças chave e forneça cálculos corretos para o exemplo dado",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Notebook para anotações",
                                    "Referência: Capítulo de Estatística Descritiva"
                                  ],
                                  "tips": [
                                    "Use dados centrados em média para visualizar melhor",
                                    "Lembre-se: sinal positivo indica covariância positiva"
                                  ],
                                  "learningObjective": "Compreender as fórmulas matemáticas e propriedades básicas das matrizes de covariância e correlação",
                                  "commonMistakes": [
                                    "Confundir covariância com correlação sem padronização",
                                    "Esquecer de centralizar dados antes do cálculo",
                                    "Ignorar que diagonal da covariância não é sempre 1"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular e Visualizar Matrizes de Covariância e Correlação",
                                  "subSteps": [
                                    "Carregue um dataset multivariado simples (ex: 3 variáveis: tensão, deformação, temperatura em testes de materiais)",
                                    "Calcule matriz de covariância usando fórmula ou software (média dos produtos desviados)",
                                    "Calcule matriz de correlação dividindo covariâncias pelas desvios-padrão",
                                    "Crie heatmaps para visualizar: note valores absolutos maiores na covariância devido a escalas",
                                    "Compare numericamente: extraia elementos off-diagonal e discuta discrepâncias"
                                  ],
                                  "verification": "Gere e compare as duas matrizes para o dataset, confirmando que correlação = cov / (sd_i * sd_j)",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python com NumPy/Pandas/Seaborn ou R",
                                    "Dataset exemplo: dados de engenharia (CSV com 50+ observações)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": [
                                    "Padronize dados antes para correlação direta",
                                    "Use corr() e cov() funções built-in para verificação rápida"
                                  ],
                                  "learningObjective": "Dominar o cálculo prático e visualização comparativa das matrizes",
                                  "commonMistakes": [
                                    "Usar dados não centrados levando a covariâncias incorretas",
                                    "Interpretar valores de covariância sem contexto de escala",
                                    "Confundir heatmap de cov com corr sem legendas claras"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Diferenças: Escala vs. Padronização e Contextos de Uso",
                                  "subSteps": [
                                    "Explique impacto da escala: variáveis em unidades diferentes (ex: metros vs. graus) distorcem covariância",
                                    "Discuta padronização na correlação: permite comparação entre variáveis heterogêneas",
                                    "Liste cenários de engenharia: use covariância para PCA em dados brutos; correlação para análise de dependências normalizadas",
                                    "Relacione com mínimos quadrados: homocedasticidade assume covariância constante; correlação detecta multicolinearidade",
                                    "Avalie trade-offs: covariância preserva magnitude, correlação ignora variância absoluta"
                                  ],
                                  "verification": "Escreva uma tabela comparativa com 5 diferenças e 3 exemplos de uso em engenharia",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Artigo sobre PCA e regressão linear",
                                    "Whiteboard ou papel para tabela",
                                    "Exemplos de datasets de engenharia"
                                  ],
                                  "tips": [
                                    "Pense em normalização Z-score como ponte entre cov e corr",
                                    "Sempre pergunte: 'As unidades importam aqui?'"
                                  ],
                                  "learningObjective": "Diferenciar conceitualmente e saber quando usar cada matriz em análises reais",
                                  "commonMistakes": [
                                    "Assumir correlação implica causalidade",
                                    "Usar correlação quando magnitudes absolutas são cruciais",
                                    "Ignorar violações de normalidade em pressupostos de LS"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Análise de Dados de Engenharia e Verificar Pressupostos",
                                  "subSteps": [
                                    "Selecione dataset de engenharia (ex: sensores em turbinas: vibração, temperatura, pressão)",
                                    "Compute ambas matrizes e identifique variáveis altamente correlacionadas (>0.8)",
                                    "Avalie multicolinearidade para regressão de mínimos quadrados: use correlação para screening",
                                    "Simule violação: escale uma variável e recompare matrizes para ver efeitos",
                                    "Conclua recomendação: cov para modelagem física, corr para screening inicial"
                                  ],
                                  "verification": "Produza relatório curto (1 página) recomendando uso baseado no dataset analisado",
                                  "estimatedTime": "70 minutos",
                                  "materials": [
                                    "Dataset real de Kaggle (ex: turbina ou falhas estruturais)",
                                    "Software estatístico (Python/R/MATLAB)",
                                    "Template de relatório"
                                  ],
                                  "tips": [
                                    "Teste VIF após correlação para multicolinearidade",
                                    "Documente todas transformações de escala"
                                  ],
                                  "learningObjective": "Integrar comparação de matrizes à análise prática em engenharia e mínimos quadrados",
                                  "commonMistakes": [
                                    "Overlook outliers inflando covariâncias",
                                    "Usar corr em dados não-lineares sem transformação",
                                    "Não checar normalidade antes de inferências"
                                  ]
                                }
                              ],
                              "practicalExample": "Em testes de fadiga de materiais de engenharia aeroespacial, calcule a matriz de covariância para variáveis brutas (cargas em Newtons, ciclos em milhares) para modelar variâncias absolutas em simulações FEM. Use a matriz de correlação para identificar redundâncias entre sensores de tensão e deformação, evitando multicolinearidade em regressões que preveem vida útil sob mínimos quadrados ordinários.",
                              "finalVerifications": [
                                "Calcule corretamente ambas matrizes para um dataset dado sem erros numéricos",
                                "Explique verbalmente 3 diferenças chave entre cov e corr em <2 minutos",
                                "Identifique corretamente quando usar cada uma em 2 cenários de engenharia",
                                "Relacione multicolinearidade detectada por corr aos pressupostos de OLS",
                                "Gere visualizações comparativas com interpretações precisas",
                                "Recomende uso apropriado em relatório com justificativa"
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos de matrizes (90%+ acurácia)",
                                "Compreensão conceitual: distinção clara de escala/padronização",
                                "Aplicação contextual: exemplos relevantes para engenharia",
                                "Análise crítica: ligação com pressupostos de mínimos quadrados",
                                "Clareza na comunicação: tabelas/visuais explicativos",
                                "Profundidade prática: detecção de issues como multicolinearidade"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em distribuições multivariadas (normalidade)",
                                "Machine Learning: Pré-processamento para PCA e feature selection",
                                "Engenharia Mecânica: Análise de vibrações e falhas preditivas",
                                "Programação Computacional: Implementação em NumPy/SciPy",
                                "Física Aplicada: Modelagem de sistemas dinâmicos correlacionados"
                              ],
                              "realWorldApplication": "Na indústria petrolífera, engenheiros comparam matrizes de covariância (para magnitudes em pressões de poços) e correlação (para padronizar sensores de fluxo e temperatura) para detectar multicolinearidade em modelos de regressão que otimizam extração sob mínimos quadrados, reduzindo erros em previsões de produção e prevenindo falhas catastróficas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.6.2.1.4",
                              "10.1.6.2.2.3"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.3",
                    "name": "Seleção de Componentes Principais",
                    "description": "Critérios para escolher o número de componentes, como variância explicada e scree plot.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.3.1",
                        "name": "Critério da Variância Explicada Cumulativa",
                        "description": "Método para selecionar o número de componentes principais com base na proporção da variância total dos dados explicada pelos componentes retidos, comumente visando um percentual cumulativo de 70-90%, aplicado em análises econométricas para redução dimensional em dados de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.1.1",
                            "name": "Calcular a variância explicada por componente",
                            "description": "Computar a variância explicada individual e cumulativa para cada componente principal a partir da matriz de autovalores, utilizando fórmulas como (λ_i / Σλ) * 100%, em contextos de regressão linear multivariada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Obter e Verificar a Matriz de Autovalores",
                                  "subSteps": [
                                    "Selecione um dataset multivariado padronizado adequado para PCA.",
                                    "Execute a Análise de Componentes Principais (PCA) usando software como Python (sklearn) ou R.",
                                    "Extraia a matriz de autovalores (λ1 ≥ λ2 ≥ ... ≥ λp) ordenados em ordem decrescente.",
                                    "Confirme que os autovalores são positivos e somam a variância total do dataset.",
                                    "Registre os autovalores em uma tabela ou array para cálculos subsequentes."
                                  ],
                                  "verification": "Verifique se os autovalores estão ordenados corretamente e somam a trace da matriz de covariância.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset de exemplo (ex: Iris ou synthético com 3 variáveis)",
                                    "Python com sklearn ou R com prcomp()",
                                    "Notebook Jupyter ou script R"
                                  ],
                                  "tips": [
                                    "Padronize os dados antes da PCA para evitar viés de escala.",
                                    "Use funções prontas como PCA() no sklearn para agilizar."
                                  ],
                                  "learningObjective": "Compreender a origem e propriedades dos autovalores na PCA.",
                                  "commonMistakes": [
                                    "Não padronizar dados antes da PCA",
                                    "Ordenar autovalores de forma crescente",
                                    "Ignorar autovalores negativos (inválidos em PCA cenralizada)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a Soma Total dos Autovalores (Σλ)",
                                  "subSteps": [
                                    "Liste todos os autovalores obtidos: λ1, λ2, ..., λp.",
                                    "Some todos os autovalores: Σλ = λ1 + λ2 + ... + λp.",
                                    "Verifique que Σλ equals a variância total (número de variáveis para dados padronizados).",
                                    "Registre o valor de Σλ com precisão decimal adequada (ex: 4 casas).",
                                    "Teste com um dataset pequeno para validar o cálculo manual."
                                  ],
                                  "verification": "Confirme que Σλ corresponde à dimensão total do dataset padronizado (p para p variáveis).",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Lista de autovalores do Step 1",
                                    "Calculadora ou código Python/R para soma"
                                  ],
                                  "tips": [
                                    "Automatize com np.sum(eigenvalues) no NumPy para precisão.",
                                    "Sempre use dados padronizados para Σλ = p."
                                  ],
                                  "learningObjective": "Dominar o cálculo da variância total a partir de autovalores.",
                                  "commonMistakes": [
                                    "Excluir autovalores pequenos",
                                    "Confundir com autovetores",
                                    "Erro aritmético em somas manuais"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular Variância Explicada Individual por Componente",
                                  "subSteps": [
                                    "Para cada componente i, aplique a fórmula: PE_i = (λ_i / Σλ) * 100%.",
                                    "Calcule PE_1, PE_2, ..., PE_p sequencialmente.",
                                    "Expresse resultados em porcentagem com 2 casas decimais.",
                                    "Crie uma tabela com PC_i, λ_i e PE_i.",
                                    "Valide que a soma das PE_i = 100%."
                                  ],
                                  "verification": "Soma das PE_i deve ser exatamente 100%; verifique cálculos cruzados.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Valores de Σλ do Step 2",
                                    "Planilha Excel ou Pandas DataFrame"
                                  ],
                                  "tips": [
                                    "Use loop em Python: pe_individual = (eigenvalues / total_var) * 100.",
                                    "Arredonde apenas no final para evitar erros de propagação."
                                  ],
                                  "learningObjective": "Aplicar corretamente a fórmula de proporção individual de variância.",
                                  "commonMistakes": [
                                    "Esquecer de dividir por Σλ",
                                    "Não multiplicar por 100 para %",
                                    "Usar λ_i absoluto sem normalizar"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular e Interpretar Variância Explicada Cumulativa",
                                  "subSteps": [
                                    "Para cada k, calcule PEC_k = (Σ_{i=1 to k} λ_i / Σλ) * 100%.",
                                    "Comece com PEC_1 = PE_1, PEC_2 = PE_1 + PE_2, etc.",
                                    "Gere uma tabela cumulativa e plote um scree plot ou gráfico de barras cumulativo.",
                                    "Interprete: identifique k onde PEC_k ≥ 80-90%.",
                                    "Documente decisões de seleção de componentes baseadas em PEC."
                                  ],
                                  "verification": "PEC_k deve ser não-decrescente e PEC_p = 100%; gráfico visual confirma.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "PE_i do Step 3",
                                    "Biblioteca matplotlib ou ggplot2 para plot"
                                  ],
                                  "tips": [
                                    "Use np.cumsum() no NumPy para cumulativa rápida.",
                                    "Critério comum: reter PCs até 85% cumulativo."
                                  ],
                                  "learningObjective": "Computar e usar variância cumulativa para seleção de componentes.",
                                  "commonMistakes": [
                                    "Calcular cumulativa como média em vez de soma",
                                    "Inverter ordem dos componentes",
                                    "Ignorar interpretação prática"
                                  ]
                                }
                              ],
                              "practicalExample": "Dataset com 3 variáveis (X1, X2, X3) padronizado; autovalores: λ1=2.5, λ2=1.2, λ3=0.3 (Σλ=4.0). PE1=(2.5/4)*100=62.5%, PE2=30%, PE3=7.5%. PEC1=62.5%, PEC2=92.5%, PEC3=100%. Retém 2 PCs para 92.5% variância.",
                              "finalVerifications": [
                                "Soma total Σλ calculada corretamente e equals variância total.",
                                "Todas PE_i somam 100% com precisão decimal.",
                                "PEC_k é não-decrescente e atinge 100% no final.",
                                "Tabela e gráfico de variância gerados sem erros.",
                                "Interpretação correta de quantos PCs reter (ex: ≥85%).",
                                "Cálculos validados manualmente em dataset pequeno."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nos cálculos de PE_i e PEC_k (erro <0.1%).",
                                "Correta normalização pela soma total Σλ.",
                                "Uso apropriado de ferramentas computacionais sem erros de código.",
                                "Interpretação contextual em regressão multivariada.",
                                "Visualizações claras e rotuladas corretamente.",
                                "Documentação completa de passos e fórmulas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Descritiva: Matriz de covariância e autovalores.",
                                "Programação: Implementação em Python (sklearn, NumPy) ou R.",
                                "Machine Learning: Redução de dimensionalidade pré-regressão.",
                                "Análise de Dados: Seleção de features em datasets high-dimensional.",
                                "Matemática Linear: Propriedades de matrizes simétricas."
                              ],
                              "realWorldApplication": "Em modelagem de risco financeiro, calcular variância explicada para selecionar componentes principais de retornos de ações, reduzindo dimensionalidade de 100+ variáveis para 5-10 PCs que capturam 90% da variância, melhorando eficiência de regressão linear multivariada."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.1.2",
                            "name": "Interpretar o percentual cumulativo de variância",
                            "description": "Analisar gráficos de variância cumulativa para determinar o número mínimo de componentes que capturem uma fração pré-definida da variância total, considerando trade-offs em modelos econométricos aplicados à engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de percentual cumulativo de variância em PCA",
                                  "subSteps": [
                                    "Revise os autovalores obtidos da decomposição PCA, que representam a variância explicada por cada componente principal.",
                                    "Calcule a variância explicada individual como autovalor / soma total de autovalores, expressa em porcentagem.",
                                    "Some as porcentagens individuais cumulativamente até o k-ésimo componente para obter o percentual cumulativo.",
                                    "Entenda que o percentual cumulativo indica quanta informação original dos dados é retida pelos primeiros k componentes.",
                                    "Pratique com um conjunto pequeno de dados (ex: 3 variáveis) para visualizar o cálculo manual."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o que significa '80% de variância cumulativa capturada por 3 componentes'.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Notebook Jupyter com NumPy",
                                    "Documentação PCA (sklearn)"
                                  ],
                                  "tips": "Normalize sempre a soma total de autovalores para 1 ou 100% para facilitar comparações.",
                                  "learningObjective": "Dominar o cálculo e interpretação matemática do percentual cumulativo de variância.",
                                  "commonMistakes": [
                                    "Confundir variância individual com cumulativa",
                                    "Esquecer de normalizar pela soma total de autovalores"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar e interpretar gráficos de variância cumulativa",
                                  "subSteps": [
                                    "Gere ou identifique um gráfico de variância cumulativa (scree plot cumulativo) com eixo X: número de componentes, eixo Y: % cumulativo.",
                                    "Observe a curva de crescimento: inicial rápida (altos autovalores) e posterior achatamento.",
                                    "Identifique pontos onde a curva atinge thresholds comuns como 70%, 85% ou 95%.",
                                    "Compare com scree plot não-cumulativo para validação cruzada da 'cotovelo'.",
                                    "Anotar valores exatos de % cumulativo para diferentes números de componentes."
                                  ],
                                  "verification": "Desenhe ou anote 3 pontos chave do gráfico e seus significados.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python (matplotlib, seaborn)",
                                    "Gráfico de exemplo de PCA",
                                    "Ferramenta online como PCA explorer"
                                  ],
                                  "tips": "Use zoom no gráfico para precisão em thresholds altos; plote múltiplas linhas para comparação.",
                                  "learningObjective": "Ler e extrair informações precisas de visualizações de variância cumulativa.",
                                  "commonMistakes": [
                                    "Ignorar a escala do eixo Y (deve ser 0-100%)",
                                    "Confundir com gráfico de variância individual (que cai para 0)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Determinar o número mínimo de componentes baseado em threshold pré-definido",
                                  "subSteps": [
                                    "Defina um threshold alvo (ex: 85% para equilíbrio em engenharia).",
                                    "Localize o menor k onde cumulativa >= threshold no gráfico.",
                                    "Valide com cálculo numérico: argmin(k) tal que sum(var[1:k]) / total >= 0.85.",
                                    "Teste sensibilidade variando threshold (70% vs 95%) e registre mudanças em k.",
                                    "Documente a escolha com justificativa quantitativa."
                                  ],
                                  "verification": "Forneça k e % exato para um gráfico dado, justificando o threshold.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código Python/sklearn para PCA",
                                    "Dataset multivariado (ex: Iris ou dados econômicos)"
                                  ],
                                  "tips": "Comece com threshold conservador (90%) e ajuste baseado no contexto.",
                                  "learningObjective": "Aplicar critérios quantitativos para seleção ótima de componentes.",
                                  "commonMistakes": [
                                    "Escolher k=1 sempre (alta variância inicial)",
                                    "Ignorar que k deve ser mínimo viável"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Considerar trade-offs em modelos econométricos aplicados à engenharia",
                                  "subSteps": [
                                    "Avalie trade-offs: menor k = menos dimensionalidade, mas possível perda de info; maior k = mais precisão, mas overfitting e custo computacional.",
                                    "Em contextos econométricos: priorize interpretabilidade para variáveis como PIB, inflação.",
                                    "Na engenharia: equilibre com restrições de sensores/hardware (ex: IoT com poucos canais).",
                                    "Simule cenários: reconstrua dados com k selecionado e meça erro de reconstrução (MSE).",
                                    "Redija relatório resumindo escolha de k com prós/contras."
                                  ],
                                  "verification": "Liste 3 trade-offs específicos para um caso de engenharia/economia.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Dataset real (ex: dados econômicos do World Bank)",
                                    "Ferramentas de simulação PCA"
                                  ],
                                  "tips": "Use matriz de correlação pós-PCA para checar multicolinearidade residual.",
                                  "learningObjective": "Integrar análise de variância com considerações práticas de modelagem.",
                                  "commonMistakes": [
                                    "Focar só em % alto ignorando custo computacional",
                                    "Não contextualizar para engenharia/economia"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um projeto de monitoramento de vibrações em turbinas eólicas (engenharia), aplique PCA a dados de 20 sensores. O gráfico mostra 85% de variância cumulativa com 5 componentes. Selecione k=5 para reduzir de 20 para 5 variáveis, mantendo precisão em previsões de falhas, evitando overfitting em modelos econométricos de custo-benefício.",
                              "finalVerifications": [
                                "Interprete corretamente um gráfico fornecido, identificando k para 90% cumulativo.",
                                "Calcule manualmente % cumulativo para autovalores dados.",
                                "Explique trade-offs de k=3 vs k=7 em contexto econométrico.",
                                "Gere e analise gráfico próprio de um dataset simples.",
                                "Compare escolhas de k com métodos alternativos (ex: Kaiser criterion).",
                                "Avalie impacto de k na reconstrução de dados (MSE < 10%)."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de % cumulativo (erro <1%).",
                                "Correta identificação de k mínimo para threshold dado.",
                                "Análise qualitativa de trade-offs contextualizada (engenharia/economia).",
                                "Qualidade visual e interpretativa do gráfico gerado.",
                                "Justificativa clara e quantitativa da escolha final de k.",
                                "Demonstração de verificação prática (ex: MSE baixo).",
                                "Uso adequado de terminologia PCA (autovalores, cumulativa)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de significância de autovalores (Bartlett).",
                                "Machine Learning: Redução de dimensionalidade pré-modelos (ex: regressão).",
                                "Engenharia: Otimização de sensores em sistemas IoT.",
                                "Econometria: Análise de séries multivariadas em previsões macroeconômicas.",
                                "Computação Científica: Implementação eficiente em Python/R."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, PCA com análise de variância cumulativa otimiza modelos de previsão de fadiga estrutural a partir de dados de sensores, reduzindo custos computacionais em simulações em tempo real e integrando com análises econométricas de manutenção preditiva."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.1.3",
                            "name": "Definir thresholds para retenção de componentes",
                            "description": "Estabelecer e justificar critérios como 80% de variância explicada cumulativa, adaptando ao contexto de grandes amostras em econometria e análise de dados de sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o cálculo da variância explicada cumulativa em PCA",
                                  "subSteps": [
                                    "Calcule os autovalores dos componentes principais a partir da matriz de covariância.",
                                    "Ordene os autovalores em ordem decrescente.",
                                    "Compute a proporção de variância explicada por cada componente: autovalor / soma total de autovalores.",
                                    "Acumule as proporções para obter a variância cumulativa.",
                                    "Plote o scree plot e o gráfico de variância cumulativa para visualização."
                                  ],
                                  "verification": "Verifique se a soma das variâncias cumulativas atinge 100% e se os gráficos mostram a acumulação correta.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (scikit-learn, matplotlib), dataset de exemplo como Iris ou Boston Housing; notebook Jupyter.",
                                  "tips": "Sempre normalize os dados antes do PCA para evitar viés de escala.",
                                  "learningObjective": "Dominar o cálculo preciso da variância explicada cumulativa como base para thresholds.",
                                  "commonMistakes": "Esquecer de ordenar autovalores ou não somar corretamente a variância total."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Estudar thresholds padrão e critérios de retenção",
                                  "subSteps": [
                                    "Revise guidelines comuns: 70-90% de variância cumulativa (ex: 80% como padrão Kaiser).",
                                    "Analise o critério de Kaiser (autovalores >1) e scree plot (cotovelo).",
                                    "Compare com outros métodos como variância explicada por componente individual.",
                                    "Documente prós e contras de cada threshold em contextos multivariados.",
                                    "Teste thresholds em um dataset pequeno para observar impacto na redução dimensional."
                                  ],
                                  "verification": "Crie uma tabela comparativa de thresholds com exemplos numéricos e justifique escolhas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Artigos acadêmicos (ex: Jolliffe's PCA book), R ou Python com pacotes prcomp/sklearn.",
                                  "tips": "Use 80% como ponto de partida, mas ajuste baseado no domínio.",
                                  "learningObjective": "Identificar e justificar thresholds padrão para retenção em PCA.",
                                  "commonMistakes": "Aplicar thresholds rígidos sem considerar o tamanho da amostra ou ruído nos dados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Adaptar thresholds para contextos de grandes amostras em econometria e sistemas de controle",
                                  "subSteps": [
                                    "Avalie impacto de grandes amostras: thresholds mais baixos (ex: 70-75%) devido a mais ruído e dimensionalidade alta.",
                                    "Em econometria, priorize variáveis econômicas chave retendo até 85% para evitar perda de interpretabilidade.",
                                    "Em sistemas de controle, adapte para estabilidade: threshold que mantém variância >80% sem overfit.",
                                    "Simule cenários com bootstrap para robustez do threshold em grandes datasets.",
                                    "Justifique adaptação com métricas como MSE de reconstrução ou cross-validação."
                                  ],
                                  "verification": "Gere relatórios com thresholds adaptados e comparações de performance em datasets simulados.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Datasets grandes (ex: Kaggle econometria ou time-series de controle), Python (pandas, sklearn).",
                                  "tips": "Use cross-validation para validar thresholds em subamostras.",
                                  "learningObjective": "Adaptar thresholds dinamicamente ao contexto específico de grandes dados.",
                                  "commonMistakes": "Ignorar multicolinearidade em econometria, levando a thresholds subótimos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Definir, implementar e validar o threshold final",
                                  "subSteps": [
                                    "Escolha threshold final (ex: 80% adaptado para 75% em grandes amostras).",
                                    "Implemente corte no PCA e reconstrua dados para verificação.",
                                    "Compare loadings e scores antes/depois do corte.",
                                    "Avalie com métricas: variância retida, tempo computacional e interpretabilidade.",
                                    "Documente justificativa contextual em relatório."
                                  ],
                                  "verification": "Confirme que o número de componentes retidos explica o threshold exato e melhora métricas downstream.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Código Python/R pronto, visualizações (biplots).",
                                  "tips": "Automatize com função que aceita threshold como parâmetro.",
                                  "learningObjective": "Implementar e validar um threshold personalizado de forma acionável.",
                                  "commonMistakes": "Retenção excessiva de componentes ruidosos, inflando dimensionalidade."
                                }
                              ],
                              "practicalExample": "Em um dataset econométrico de 10.000 observações de variáveis macroeconômicas (PIB, inflação, desemprego), compute PCA: autovalores mostram que 5 componentes explicam 82% da variância. Defina threshold de 80%, retendo 5 PCs, e use para prever recessões, reduzindo de 20 para 5 variáveis sem perda significativa.",
                              "finalVerifications": [
                                "Variância cumulativa atinge exatamente o threshold definido (ex: >=80%).",
                                "Número de componentes é mínimo possível sem perda >5% em reconstrução.",
                                "Scree plot confirma 'cotovelo' alinhado ao threshold.",
                                "Loadings dos componentes retidos são interpretáveis no contexto.",
                                "Teste de bootstrap confirma robustez em subamostras.",
                                "MSE de reconstrução é <10% do total."
                              ],
                              "assessmentCriteria": [
                                "Justificativa contextual clara e baseada em evidências (20%).",
                                "Cálculos precisos de variância cumulativa (25%).",
                                "Adaptação adequada a grandes amostras/econometria (20%).",
                                "Implementação prática com código reproduzível (20%).",
                                "Validação com múltiplas métricas (15%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em autovalores e testes de significância.",
                                "Machine Learning: Redução dimensional para modelos preditivos.",
                                "Economia: Análise de painéis em econometria multivariada.",
                                "Engenharia: Modelagem de sistemas de controle com PCA para estados observáveis."
                              ],
                              "realWorldApplication": "Em bancos centrais, define thresholds para PCA em dados macroeconômicos de alta dimensionalidade, permitindo forecasts eficientes de inflação; em indústrias de controle (ex: aviação), retém componentes para monitoramento de sistemas com milhares de sensores, otimizando detecção de falhas."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.3.2",
                        "name": "Scree Plot",
                        "description": "Gráfico que plota os autovalores em ordem decrescente para visualizar o 'cotovelo' (elbow), auxiliando na escolha intuitiva do número de componentes principais em análises multivariadas de dados econométricos em engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.2.1",
                            "name": "Construir um scree plot",
                            "description": "Gerar o gráfico de autovalores decrescentes utilizando ferramentas como R (prcomp) ou software econométrico, plotando λ_i versus i para identificação visual do ponto de inflexão.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o conjunto de dados e executar a Análise de Componentes Principais (PCA)",
                                  "subSteps": [
                                    "Carregue o dataset relevante em R usando read.csv() ou datasets built-in como iris.",
                                    "Selecione variáveis numéricas e remova quaisquer valores ausentes com na.omit().",
                                    "Padronize os dados usando scale() para garantir média zero e variância unitária.",
                                    "Execute prcomp() com os dados padronizados, especificando scale=FALSE já que padronizou manualmente.",
                                    "Inspecione o objeto PCA com summary() para confirmar execução bem-sucedida."
                                  ],
                                  "verification": "Verifique se summary(pca_object) mostra proporções de variância sem erros.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Pacotes: base R (sem necessidade de instalação adicional)"
                                  ],
                                  "tips": "Sempre padronize dados antes de PCA para evitar viés de escalas diferentes.",
                                  "learningObjective": "Compreender a preparação de dados para PCA e executar o cálculo de componentes principais.",
                                  "commonMistakes": [
                                    "Esquecer de padronizar dados levando a componentes distorcidos",
                                    "Incluir variáveis categóricas sem codificação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Extrair e ordenar os autovalores do modelo PCA",
                                  "subSteps": [
                                    "Acesse os autovalores com pca_object$sdev^2 para obter λ_i.",
                                    "Crie um vetor de autovalores: eigenvalues <- pca_object$sdev^2.",
                                    "Ordene os autovalores em ordem decrescente se necessário (prcomp já faz isso).",
                                    "Calcule a proporção cumulativa de variância com cumsum(eigenvalues)/sum(eigenvalues).",
                                    "Armazene o índice i como seq_along(eigenvalues) para o eixo x."
                                  ],
                                  "verification": "Execute print(eigenvalues) e confirme que são positivos e decrescentes.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Objeto PCA do Step 1",
                                    "R console"
                                  ],
                                  "tips": "Use sdev^2 pois prcomp retorna desvios padrão dos componentes.",
                                  "learningObjective": "Extrair autovalores corretamente para análise de variância explicada.",
                                  "commonMistakes": [
                                    "Confundir sdev com autovalores (use ^2)",
                                    "Não ordenar, distorcendo o plot"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Construir o scree plot utilizando ggplot2 ou base plot",
                                  "subSteps": [
                                    "Instale e carregue ggplot2 se necessário: install.packages('ggplot2'); library(ggplot2).",
                                    "Crie data frame: plot_data <- data.frame(index = 1:length(eigenvalues), eigenvalue = eigenvalues).",
                                    "Gere o plot: ggplot(plot_data, aes(x = index, y = eigenvalue)) + geom_line() + geom_point() + labs(title = 'Scree Plot', x = 'Componente Principal (i)', y = 'Autovalor (λ_i)') + theme_minimal().",
                                    "Alternativa base R: plot(1:length(eigenvalues), eigenvalues, type='b', xlab='i', ylab='λ_i', main='Scree Plot').",
                                    "Salve o plot com ggsave('scree_plot.png') ou png() para exportação."
                                  ],
                                  "verification": "O gráfico gerado mostra linha decrescente suave de λ_i vs i sem erros de plotting.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Pacote ggplot2",
                                    "Objeto eigenvalues do Step 2"
                                  ],
                                  "tips": "Use geom_point() + geom_line() para visual claro; adicione grid com theme_minimal().",
                                  "learningObjective": "Visualizar autovalores decrescentes para inspeção gráfica.",
                                  "commonMistakes": [
                                    "Eixos invertidos (i no x, λ_i no y)",
                                    "Escala log desnecessária obscurecendo inflexão"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Identificar e interpretar o ponto de inflexão no scree plot",
                                  "subSteps": [
                                    "Examine visualmente o plot procurando o 'cotovelo' onde a curva plana.",
                                    "Marque o ponto: adicione geom_vline(xintercept = k, color='red') onde k é o número estimado de componentes.",
                                    "Compare com critérios como Kaiser (λ_i > 1) ou proporção de variância (>80%).",
                                    "Anote o número de componentes retidos baseado na inflexão.",
                                    "Documente a interpretação em um relatório curto."
                                  ],
                                  "verification": "Identifique e justifique o número de componentes com base no plot.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Scree plot do Step 3",
                                    "Critérios de retenção (Kaiser, variância cumulativa)"
                                  ],
                                  "tips": "O ponto de inflexão é subjetivo; valide com scree.test() do pacote factorexR.",
                                  "learningObjective": "Interpretar scree plot para seleção ótima de componentes principais.",
                                  "commonMistakes": [
                                    "Escolher todos os componentes sem corte",
                                    "Ignorar padronização afetando autovalores"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset iris no R: data(iris); pca <- prcomp(iris[,1:4], scale=TRUE); eigenvalues <- pca$sdev^2; plot_data <- data.frame(i=1:4, lambda=eigenvalues); ggplot(plot_data, aes(i, lambda)) + geom_line() + geom_point(); o scree plot mostra inflexão em torno de 2 componentes, retendo 73% da variância.",
                              "finalVerifications": [
                                "Autovalores extraídos corretamente e decrescentes.",
                                "Scree plot plotado com eixos corretos (i vs λ_i).",
                                "Ponto de inflexão identificado visualmente.",
                                "Código R executável sem erros.",
                                "Interpretação inclui número de componentes recomendados.",
                                "Variância explicada calculada e reportada."
                              ],
                              "assessmentCriteria": [
                                "Precisão na execução de prcomp e extração de autovalores (40%).",
                                "Qualidade visual e legibilidade do scree plot (20%).",
                                "Correta identificação do ponto de inflexão com justificativa (20%).",
                                "Uso apropriado de padronização e verificações (10%).",
                                "Documentação clara do processo e interpretação (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Compreensão de variância e autovalores.",
                                "Programação: Manipulação de dados e visualização em R.",
                                "Visualização de Dados: Princípios de gráficos informativos.",
                                "Machine Learning: Redução de dimensionalidade pré-processamento."
                              ],
                              "realWorldApplication": "Em análise de risco financeiro, scree plots ajudam a selecionar componentes principais de retornos de ações para modelos preditivos compactos; em bioinformática, reduzem genes em estudos genômicos de alta dimensão."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.2.2",
                            "name": "Identificar o ponto de 'cotovelo' no scree plot",
                            "description": "Reconhecer subjetivamente o elbow onde a curva de autovalores se estabiliza, aplicando em conjuntos de dados de regressão com múltiplas variáveis em contextos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Gerar o Scree Plot a partir de um conjunto de dados multivariado",
                                  "subSteps": [
                                    "Carregue um conjunto de dados com múltiplas variáveis numéricas, como dados de sensores de engenharia (ex: temperatura, pressão, vibração).",
                                    "Padronize os dados (z-score) para garantir que variáveis com diferentes escalas não distorçam a análise.",
                                    "Aplique PCA usando uma biblioteca como scikit-learn em Python ou prcomp no R.",
                                    "Extraia os autovalores e plote-os em ordem decrescente contra o número de componentes principais.",
                                    "Adicione rótulos aos eixos (x: Componentes Principais, y: Autovalores) e uma linha de referência para visualização clara."
                                  ],
                                  "verification": "Confirme que o scree plot foi gerado corretamente exibindo uma curva decrescente suave sem erros de plotagem.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com scikit-learn e matplotlib",
                                    "Ou R com ggplot2",
                                    "Dataset de exemplo (ex: Iris ou dados de engenharia sintéticos)"
                                  ],
                                  "tips": "Sempre padronize os dados antes do PCA para evitar viés de escala; use log-scale no eixo y se autovalores variam muito.",
                                  "learningObjective": "Compreender e executar o processo de geração de scree plot para análise de componentes principais.",
                                  "commonMistakes": [
                                    "Esquecer de padronizar dados levando a autovalores distorcidos",
                                    "Plotar autovalores não ordenados",
                                    "Usar escala errada nos eixos"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar a forma e o declive da curva de autovalores",
                                  "subSteps": [
                                    "Observe o declive inicial íngreme da curva, onde os primeiros componentes capturam a maior variância.",
                                    "Identifique a transição para um declive mais suave, indicando componentes com variância residual.",
                                    "Marque visualmente pontos onde o declive muda significativamente (use zoom ou grid no plot).",
                                    "Calcule a proporção de variância explicada cumulativa para auxiliar a interpretação visual.",
                                    "Compare com critérios quantitativos como Kaiser (autovalor >1) para contexto subjetivo."
                                  ],
                                  "verification": "Descreva verbalmente ou anote as regiões de declive íngreme e suave no plot.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Scree plot gerado no Step 1",
                                    "Ferramentas de anotação em plots (ex: plt.axvline no matplotlib)"
                                  ],
                                  "tips": "Use múltiplas visualizações (linear e log-scale) para melhor percepção da mudança de declive.",
                                  "learningObjective": "Desenvolver habilidade em interpretar visualmente a estrutura de variância nos autovalores.",
                                  "commonMistakes": [
                                    "Confundir ruído com sinal ignorando o contexto do dataset",
                                    "Focar apenas nos primeiros autovalores sem ver o todo"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar subjetivamente o ponto de 'cotovelo' (elbow)",
                                  "subSteps": [
                                    "Imagine o plot como um braço: localize onde a curva 'dobra' como um cotovelo, estabilizando o declive.",
                                    "Teste traçando uma linha reta do primeiro ao último ponto e encontre a maior distância perpendicular à curva.",
                                    "Selecione o componente onde a redução de variância se torna marginal (ex: <5% adicional).",
                                    "Anotar o número do componente elbow e justificar com base na mudança de inclinação.",
                                    "Repita com subsets do data para validar consistência."
                                  ],
                                  "verification": "Apontar e justificar o ponto elbow em um scree plot anotado.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Scree plot analisado",
                                    "Ferramentas para medir distâncias (ex: cursor no plot interativo)"
                                  ],
                                  "tips": "Pratique com datasets conhecidos (ex: Iris tem elbow claro em PC2); subjetividade melhora com experiência.",
                                  "learningObjective": "Aplicar julgamento subjetivo para detectar o ponto de estabilização na curva de autovalores.",
                                  "commonMistakes": [
                                    "Escolher elbow muito cedo por viés de poucos componentes",
                                    "Ignorar contexto do domínio de engenharia"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e aplicar a seleção do elbow em PCA",
                                  "subSteps": [
                                    "Retreine PCA usando apenas componentes até o elbow e compare variância explicada (>80-90% ideal).",
                                    "Visualize scores dos componentes selecionados e verifique separação de clusters.",
                                    "Teste em regressão: use PCs selecionados como preditores e avalie RMSE ou R².",
                                    "Documente a escolha com scree plot anotado e métricas de performance.",
                                    "Compare com outros métodos (ex: parallel analysis) para robustez."
                                  ],
                                  "verification": "Demonstre melhoria na performance do modelo de regressão com PCs selecionados vs. todos.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Código de PCA e modelo de regressão",
                                    "Dataset de regressão multivariada"
                                  ],
                                  "tips": "Sempre valide subjetivo com métricas; em engenharia, priorize interpretabilidade.",
                                  "learningObjective": "Integrar identificação do elbow com aplicação prática em análise de dados.",
                                  "commonMistakes": [
                                    "Não validar com métricas levando a overfitting",
                                    "Selecionar mais PCs do que necessário"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de monitoramento de turbinas eólicas (variáveis: velocidade do vento, torque, vibração em 10 sensores), gere scree plot mostrando elbow em PC3 (capturando 85% variância). Use esses 3 PCs para prever falhas via regressão, reduzindo dimensionalidade de 10 para 3 variáveis.",
                              "finalVerifications": [
                                "Gera scree plot corretamente padronizado e anotado.",
                                "Identifica e justifica o elbow com mudança de declive clara.",
                                "Valida seleção com >80% variância explicada.",
                                "Aplica em regressão multivariada com ganho de performance mensurável.",
                                "Explica subjetivamente o raciocínio em termos de estabilização da curva.",
                                "Compara com método alternativo (ex: Kaiser criterion)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na geração e visualização do scree plot (sem erros técnicos).",
                                "Qualidade da justificativa subjetiva para o elbow (baseada em declive e contexto).",
                                "Robustez da validação (métricas de variância e performance do modelo).",
                                "Consistência em múltiplos datasets de engenharia.",
                                "Clareza na documentação e comunicação da escolha.",
                                "Integração com objetivos de redução dimensional em regressão."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Critérios de retenção de componentes (Kaiser, scree).",
                                "Machine Learning: Redução de dimensionalidade pré-processamento.",
                                "Engenharia: Análise de dados sensoriais multivariados para manutenção preditiva.",
                                "Programação: Implementação em Python/R para visualização de dados.",
                                "Visualização de Dados: Técnicas de plotting e interpretação gráfica."
                              ],
                              "realWorldApplication": "Em engenharia mecânica, identificar o elbow no scree plot de dados de vibração de máquinas permite selecionar PCs principais para modelos de detecção de falhas, reduzindo complexidade computacional e melhorando precisão em sistemas de monitoramento industrial em tempo real."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.2.3",
                            "name": "Combinar scree plot com outros critérios",
                            "description": "Integrar o scree plot com variância explicada para uma decisão robusta sobre o número de componentes, validando em modelos de análise fatorial ou PCA em séries temporais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Gerar e Interpretar o Scree Plot Inicial",
                                  "subSteps": [
                                    "Carregue o conjunto de dados de séries temporais multivariadas (ex: retornos de ações).",
                                    "Execute PCA ou análise fatorial para obter autovalores.",
                                    "Plote o scree plot (autovalores vs. número de componentes).",
                                    "Identifique o 'elbow' visual onde a curva decai abruptamente.",
                                    "Anote candidatos iniciais para número de componentes."
                                  ],
                                  "verification": "Scree plot gerado com elbow claro identificado e anotado.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (scikit-learn, matplotlib), Jupyter Notebook, dataset de séries temporais (ex: Yahoo Finance).",
                                  "tips": "Use escala logarítmica no eixo y para melhor visualização de elbows sutis.",
                                  "learningObjective": "Dominar a geração e interpretação visual do scree plot em PCA.",
                                  "commonMistakes": "Ignorar ruído em dados de séries temporais, confundindo com elbow verdadeiro."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Variância Explicada e Cumulativa",
                                  "subSteps": [
                                    "Calcule a proporção de variância explicada por cada componente (autovalor / soma total).",
                                    "Compute a variância cumulativa até cada componente.",
                                    "Plote variância cumulativa vs. número de componentes.",
                                    "Defina thresholds como 70-90% de variância retida.",
                                    "Compare com candidatos do scree plot."
                                  ],
                                  "verification": "Tabelas e plots de variância explicada e cumulativa gerados e thresholds aplicados.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python (numpy, pandas), código de PCA existente.",
                                  "tips": "Sempre normalize dados de séries temporais antes do PCA para evitar viés de escala.",
                                  "learningObjective": "Quantificar a contribuição de cada componente para a variância total.",
                                  "commonMistakes": "Usar variância absoluta em vez de proporcional, levando a decisões enviesadas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Critérios Adicionais de Seleção",
                                  "subSteps": [
                                    "Aplique critério de Kaiser (reter componentes com autovalor >1).",
                                    "Use critério de variância cumulativa (ex: >80%).",
                                    "Considere parallel analysis ou critério de broken stick para validação.",
                                    "Ajuste para autocorrelação em séries temporais (ex: teste de estacionariedade).",
                                    "Liste prós e contras de cada critério aplicado."
                                  ],
                                  "verification": "Relatório com resultados de pelo menos 3 critérios adicionais documentado.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Bibliotecas como factor_analyzer (Python), datasets com autocorrelação.",
                                  "tips": "Em séries temporais, priorize critérios robustos a dependências temporais como parallel analysis.",
                                  "learningObjective": "Aplicar múltiplos critérios quantitativos complementares ao scree plot.",
                                  "commonMistakes": "Aplicar Kaiser rigidamente sem contexto de dimensionalidade alta."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar Critérios e Decidir Número Ótimo de Componentes",
                                  "subSteps": [
                                    "Compare resultados: scree plot (visual), variância (quantitativa), outros critérios.",
                                    "Vote por consenso ou média ponderada (ex: peso maior para variância cumulativa).",
                                    "Teste sensibilidade removendo/adicionando um componente e comparando reconstrução.",
                                    "Valide em hold-out de séries temporais (ex: previsão MSE).",
                                    "Documente a decisão final com justificativa."
                                  ],
                                  "verification": "Decisão final justificada com tabela comparativa e teste de sensibilidade.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Código integrado de steps anteriores, métricas como MSE.",
                                  "tips": "Pondere critérios: 40% scree, 40% variância, 20% outros para equilíbrio.",
                                  "learningObjective": "Sintetizar múltiplos critérios em uma decisão robusta e validada.",
                                  "commonMistakes": "Escolher baseado em um critério isolado, ignorando inconsistências."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Interpretar em Contexto de Séries Temporais",
                                  "subSteps": [
                                    "Aplique PCA com número escolhido em dados de séries temporais.",
                                    "Reconstrua séries e avalie perda de informação (ex: correlograma residuals).",
                                    "Interprete loadings para componentes em termos temporais (ex: tendências sazonais).",
                                    "Compare performance em downstream task como forecasting.",
                                    "Ajuste se necessário e finalize relatório."
                                  ],
                                  "verification": "Modelo validado com métricas de reconstrução e interpretação documentada.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Bibliotecas de séries temporais (statsmodels), gráficos de residuals.",
                                  "tips": "Sempre cheque estacionariedade pós-PCA para evitar spurious components.",
                                  "learningObjective": "Adaptar seleção de componentes ao contexto específico de séries temporais.",
                                  "commonMistakes": "Não testar reconstrução, assumindo validade automática."
                                }
                              ],
                              "practicalExample": "Em dados de retornos diários de 10 ações (S&P500, 5 anos), gere scree plot mostrando elbow em 3 componentes; variância cumulativa atinge 85% em 4; Kaiser sugere 3; consenso: 3 componentes capturam tendências de mercado, validado por MSE baixo em previsão de 1 semana.",
                              "finalVerifications": [
                                "Scree plot e variância plots gerados corretamente.",
                                "Pelo menos 3 critérios adicionais aplicados com resultados tabulados.",
                                "Decisão consensual documentada com justificativa.",
                                "Validação em séries temporais com métricas quantitativas (MSE <5%).",
                                "Relatório completo com interpretações e sensibilidade.",
                                "Código reproduzível e livre de erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação do elbow e thresholds de variância (90%+ correção).",
                                "Integração coerente de múltiplos critérios (consenso lógico).",
                                "Adequação a séries temporais (consideração de autocorrelação).",
                                "Qualidade da validação (métricas < threshold definido).",
                                "Clareza do relatório e visualizações profissionais.",
                                "Eficiência temporal (dentro de 2 horas totais)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses para parallel analysis.",
                                "Machine Learning: Redução de dimensionalidade em forecasting.",
                                "Finanças: Análise de risco em portfólios multivariados.",
                                "Ciência de Dados: Pipelines de feature engineering."
                              ],
                              "realWorldApplication": "Em finanças, selecionar 4 componentes principais de retornos de 50 ativos para modelo de risco VaR, reduzindo dimensionalidade de 50 para 4 enquanto retém 88% variância, melhorando velocidade de previsão em tempo real."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.3.3",
                        "name": "Critério de Kaiser",
                        "description": "Regra heurística que retém componentes principais cujos autovalores sejam maiores que 1, garantindo que cada componente explique mais variância que uma variável original, útil em econometria aplicada à modelagem de sistemas dinâmicos.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.3.3.1",
                            "name": "Aplicar o critério de Kaiser-Guttman",
                            "description": "Contar o número de autovalores λ_i > 1 na matriz de correlação ou covariância, justificando sua aplicação em grandes amostras de dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar a matriz de correlação ou covariância dos dados",
                                  "subSteps": [
                                    "Colete um dataset multivariado de engenharia com pelo menos 5 variáveis (ex: tensão, deformação, temperatura, carga, umidade).",
                                    "Padronize os dados (z-score) para garantir que variáveis em escalas diferentes não distorçam a análise.",
                                    "Calcule a matriz de correlação (para variáveis padronizadas) ou covariância usando software como Python (numpy.corrcoef ou np.cov).",
                                    "Verifique a matriz para simetria e diagonal com valores esperados (1 para correlação).",
                                    "Salve a matriz em formato acessível para o próximo passo."
                                  ],
                                  "verification": "A matriz gerada é simétrica, com 1s na diagonal principal e valores entre -1 e 1 para correlação.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com bibliotecas numpy e pandas",
                                    "Dataset de exemplo (CSV com dados de engenharia)"
                                  ],
                                  "tips": "Use dados reais de sensores industriais para maior relevância; sempre padronize antes de correlação.",
                                  "learningObjective": "Compreender a importância da matriz de correlação/covariância na análise de componentes principais.",
                                  "commonMistakes": [
                                    "Esquecer de padronizar dados levando a matriz enviesada",
                                    "Confundir correlação com covariância em escalas diferentes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os autovalores da matriz preparada",
                                  "subSteps": [
                                    "Use função de autovalores (ex: np.linalg.eigvals em Python ou eig em MATLAB).",
                                    "Ordene os autovalores em ordem decrescente para facilitar a análise.",
                                    "Calcule a variância explicada por cada autovalor (λ_i / soma(λ)).",
                                    "Plote os autovalores em um scree plot para visualização inicial.",
                                    "Registre todos os autovalores com precisão de pelo menos 4 casas decimais."
                                  ],
                                  "verification": "Lista de autovalores ordenados corretamente, com scree plot mostrando queda gradual.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com numpy e matplotlib",
                                    "Matriz do Step 1"
                                  ],
                                  "tips": "Sempre ordene decrescente; verifique se soma dos autovalores equals ao traço da matriz.",
                                  "learningObjective": "Dominar o cálculo e interpretação inicial de autovalores em PCA.",
                                  "commonMistakes": [
                                    "Não ordenar autovalores",
                                    "Usar autovetores em vez de autovalores"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar o critério de Kaiser-Guttman",
                                  "subSteps": [
                                    "Identifique o limiar: autovalores λ_i > 1.",
                                    "Conte o número de autovalores que satisfazem λ_i > 1.",
                                    "Selecione esse número como o número de componentes principais a reter.",
                                    "Compare com scree plot para validação visual.",
                                    "Documente a contagem e os autovalores selecionados em uma tabela."
                                  ],
                                  "verification": "Número exato de componentes retidos baseado em contagem precisa de λ_i > 1.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Autovalores do Step 2",
                                    "Planilha ou notebook Jupyter"
                                  ],
                                  "tips": "O critério assume amostras grandes; ignore λ_i muito próximos de 1 sem rounding arbitrário.",
                                  "learningObjective": "Aplicar precisamente o critério Kaiser-Guttman para seleção de componentes.",
                                  "commonMistakes": [
                                    "Incluir λ_i = 1 exatamente",
                                    "Contar incorretamente devido a ordenação errada"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Justificar a aplicação em grandes amostras de dados de engenharia",
                                  "subSteps": [
                                    "Explique que o critério retém componentes que explicam mais variância que uma variável única (λ>1).",
                                    "Discuta limitações: funciona melhor em amostras >100 observações e variáveis correlacionadas moderadamente.",
                                    "Relacione a contextos de engenharia: redução de dimensionalidade em sensores IoT ou monitoramento estrutural.",
                                    "Compare com outros critérios (ex: scree) e defenda Kaiser-Guttman para objetividade.",
                                    "Escreva um parágrafo de justificativa com referências (Kaiser, 1960)."
                                  ],
                                  "verification": "Parágrafo escrito justificando uso, citando condições ideais e exemplos de engenharia.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Referências teóricas (artigo de Kaiser)",
                                    "Notebook com análise completa"
                                  ],
                                  "tips": "Enfatize 'grandes amostras' para evitar over-retention em datasets pequenos.",
                                  "learningObjective": "Justificar teoricamente o critério em aplicações práticas de engenharia.",
                                  "commonMistakes": [
                                    "Ignorar limitações como multicolinearidade perfeita",
                                    "Justificativa genérica sem contexto de engenharia"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de monitoramento de uma ponte (500 observações, 10 sensores: aceleração, vibração, temperatura, etc.), calcule a matriz de correlação, encontre autovalores [3.2, 1.8, 1.1, 0.9, ...], aplique Kaiser-Guttman para reter 3 componentes principais, reduzindo de 10 para 3 variáveis com 65% variância explicada.",
                              "finalVerifications": [
                                "Matriz de correlação/covariância calculada corretamente e verificada.",
                                "Autovalores ordenados e scree plot gerado.",
                                "Número de componentes retidos via Kaiser-Guttman documentado.",
                                "Justificativa escrita adaptada a grandes amostras de engenharia.",
                                "Análise completa reproduzível em código.",
                                "Comparação com scree plot confirma seleção."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de autovalores (erro <0.01).",
                                "Correta aplicação do limiar λ>1 sem ambiguidades.",
                                "Justificativa teórica clara e contextualizada (mín. 100 palavras).",
                                "Uso adequado de visualizações (scree plot).",
                                "Documentação completa com código e resultados.",
                                "Identificação de pelo menos 2 limitações do critério."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: ligação com testes de significância de variância.",
                                "Programação: implementação em Python/R para análise computacional.",
                                "Engenharia de Dados: redução de dimensionalidade em big data.",
                                "Machine Learning: pré-processamento para modelos de regressão.",
                                "Física/Mecânica: análise de sinais multivariados em estruturas."
                              ],
                              "realWorldApplication": "Em engenharia civil, aplica-se a dados de sensores em pontes ou turbinas eólicas para selecionar componentes principais, reduzindo ruído e custo computacional em monitoramento preditivo de falhas, comum em indústrias com milhares de medições diárias."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.3.3.2",
                            "name": "Comparar o critério de Kaiser com variância explicada",
                            "description": "Avaliar vantagens e limitações do critério de Kaiser versus métodos baseados em variância cumulativa, em cenários de multicolinearidade em regressões lineares.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Critério de Kaiser",
                                  "subSteps": [
                                    "Defina o Critério de Kaiser: retenção de componentes principais com autovalores maiores que 1.",
                                    "Explique a lógica: componentes com autovalor >1 explicam mais variância que uma variável original única.",
                                    "Calcule autovalores em um exemplo simples de PCA usando software.",
                                    "Interprete o scree plot associado para visualização.",
                                    "Discuta origens históricas de Kaiser (1960)."
                                  ],
                                  "verification": "Liste corretamente os autovalores retidos em um dataset de exemplo e justifique com scree plot.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python (scikit-learn), R (prcomp), dataset iris ou sintético"
                                  ],
                                  "tips": "Sempre compare autovalores com 1, não com variância percentual.",
                                  "learningObjective": "Identificar e aplicar o Critério de Kaiser para seleção inicial de componentes em PCA.",
                                  "commonMistakes": [
                                    "Ignorar autovalores próximos a 1",
                                    "Confundir com variância cumulativa",
                                    "Aplicar sem normalização de dados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Compreender o Método de Variância Explicada Cumulativa",
                                  "subSteps": [
                                    "Defina variância explicada: porcentagem de variância total capturada pelos componentes cumulativamente.",
                                    "Estabeleça thresholds comuns: 70-90% de variância cumulativa.",
                                    "Calcule variância percentual para cada componente: (autovalor / soma autovalores) * 100.",
                                    "Plote cumulativa e selecione o 'cotovelo' ou threshold fixo.",
                                    "Compare com Kaiser em um dataset pequeno."
                                  ],
                                  "verification": "Gere uma tabela de variância cumulativa e identifique o número de componentes para 80% de variância.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Jupyter Notebook, dataset com 5-10 variáveis"
                                  ],
                                  "tips": "Use thresholds adaptativos por contexto; 80% é padrão em exploratório.",
                                  "learningObjective": "Calcular e interpretar variância explicada cumulativa para decisões de retenção.",
                                  "commonMistakes": [
                                    "Parar cedo abaixo de 70%",
                                    "Confundir variância individual com cumulativa",
                                    "Ignorar custo computacional de mais componentes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar Vantagens e Limitações em Cenários Gerais",
                                  "subSteps": [
                                    "Liste vantagens de Kaiser: simples, objetivo, sem threshold arbitrário.",
                                    "Liste limitações de Kaiser: rígido em autovalores ~1, sensível a amostra.",
                                    "Vantagens de variância cumulativa: flexível, baseado em performance explicativa.",
                                    "Limitações: subjetivo (escolha de % ), pode reter componentes fracos.",
                                    "Crie tabela comparativa com exemplos numéricos."
                                  ],
                                  "verification": "Elabore uma tabela 2x2 com prós/contras de cada método, suportada por referências.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Planilha Excel/Google Sheets, artigos de Jolliffe ou Kaiser"
                                  ],
                                  "tips": "Teste sensibilidade variando tamanho da amostra.",
                                  "learningObjective": "Articular diferenças qualitativas e quantitativas entre os dois critérios.",
                                  "commonMistakes": [
                                    "Superestimar Kaiser em dados de alta dimensionalidade",
                                    "Ignorar contexto do problema",
                                    "Não considerar interpretabilidade"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar em Cenários de Multicolinearidade em Regressões Lineares",
                                  "subSteps": [
                                    "Gere dataset sintético com multicolinearidade (ex: variáveis correlacionadas >0.8).",
                                    "Aplique PCA pré-regressão e compare número de componentes por cada critério.",
                                    "Meça VIF pós-PCA para ambos e compare estabilidade do modelo de regressão.",
                                    "Simule cenários: Kaiser retém poucos vs. variância retém mais para melhor predição.",
                                    "Conclua recomendações: variância preferida em multicolinearidade severa."
                                  ],
                                  "verification": "Execute regressão em dataset multicolinear, reporte VIF e R² para ambos critérios.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python (statsmodels, sklearn), dataset Boston Housing modificado"
                                  ],
                                  "tips": "Verifique multicolinearidade pré-PCA com correlograma ou VIF.",
                                  "learningObjective": "Aplicar comparação em contexto prático de regressão com multicolinearidade.",
                                  "commonMistakes": [
                                    "Não normalizar dados antes PCA",
                                    "Usar PCA sem multicolinearidade real",
                                    "Ignorar overfitting com muitos componentes"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de previsão de preços de casas com variáveis multicolineares (ex: quartos, área útil, idade casa correlacionadas), aplique PCA. Critério de Kaiser retém 3 componentes (autovalores >1), mas variância cumulativa exige 5 para 85%. Regressão com Kaiser tem VIF alto residual; variância melhora R² em 15%.",
                              "finalVerifications": [
                                "Explicar por que Kaiser falha em autovalores próximos a 1.",
                                "Calcular corretamente variância cumulativa em dataset fornecido.",
                                "Identificar cenário onde variância é superior (multicolinearidade).",
                                "Listar 3 limitações de cada método.",
                                "Comparar resultados em regressão linear simulada.",
                                "Recomendar critério baseado em contexto dado."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e cálculo de ambos critérios (20%)",
                                "Profundidade na comparação de vantagens/limitações (25%)",
                                "Aplicação correta em multicolinearidade com evidências numéricas (25%)",
                                "Clareza na tabela comparativa e interpretação (15%)",
                                "Recomendações contextuais justificadas (15%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de significância de autovalores",
                                "Machine Learning: Redução de dimensionalidade em feature selection",
                                "Análise de Regressão: Mitigação de multicolinearidade via PCA",
                                "Computação Científica: Implementação eficiente em Python/R"
                              ],
                              "realWorldApplication": "Em finanças, para modelar risco de crédito com variáveis econômicas correlacionadas (PIB, inflação, juros), usar variância cumulativa em PCA pré-regressão evita multicolinearidade, melhorando previsões de default em 10-20% vs. modelo raw."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.4",
                    "name": "Análise Fatorial",
                    "description": "Técnica para extração de fatores latentes comuns subjacentes às variáveis observadas.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.4.1",
                        "name": "Fundamentos da Análise Fatorial",
                        "description": "Introdução aos conceitos básicos da análise fatorial, incluindo fatores latentes e o modelo matemático subjacente, no contexto de dados multivariados em econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.4.1.1",
                            "name": "Identificar fatores latentes",
                            "description": "Reconhecer e descrever fatores latentes como variáveis não observáveis que explicam correlações entre variáveis observadas em conjuntos de dados de engenharia, como em análises de sensores ou processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender Conceitos Fundamentais de Variáveis Observadas e Latentes",
                                  "subSteps": [
                                    "Defina variáveis observadas como dados mensuráveis diretamente, como leituras de sensores de temperatura e pressão.",
                                    "Defina variáveis latentes como constructs não observáveis que influenciam múltiplas variáveis observadas, como 'eficiência do processo' em uma linha de produção.",
                                    "Estude exemplos: em sensores industriais, vibração, ruído e temperatura podem ser influenciados por um fator latente 'desgaste da máquina'.",
                                    "Compare com modelos univariados: explique por que correlações entre observadas sugerem latentes.",
                                    "Crie um diagrama conceitual ligando observadas a latentes."
                                  ],
                                  "verification": "Crie um mapa conceitual com pelo menos 3 variáveis observadas ligadas a 1 fator latente e explique oralmente ou por escrito.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Papel e caneta ou software de diagramação como Draw.io",
                                    "Artigo introdutório sobre análise fatorial (ex: Wikipedia - Factor Analysis)"
                                  ],
                                  "tips": "Use analogias cotidianas, como 'personalidade' (latente) influenciando 'comportamentos observados'.",
                                  "learningObjective": "Diferenciar variáveis observadas de latentes e reconhecer sua relação em dados de engenharia.",
                                  "commonMistakes": [
                                    "Confundir latentes com ruído aleatório",
                                    "Ignorar que latentes explicam padrões compartilhados",
                                    "Assumir causalidade direta sem evidência"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Matriz de Correlação para Detectar Padrões",
                                  "subSteps": [
                                    "Calcule ou interprete a matriz de correlação de um dataset multivariado usando Python (pandas corr()) ou Excel.",
                                    "Identifique correlações altas (>0.7) entre variáveis observadas, indicando possível fator latente comum.",
                                    "Agrupe variáveis por padrões de correlação: ex., sensores de vibração e ruído correlacionados sugerem 'fator de manutenção'.",
                                    "Visualize com heatmap para destacar clusters.",
                                    "Questione: 'Quais constructs não observados poderiam explicar esses clusters?'"
                                  ],
                                  "verification": "Gere uma matriz de correlação de um dataset de sensores e anote 2-3 potenciais fatores latentes baseados em clusters.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com pandas e seaborn",
                                    "Dataset exemplo: dados de sensores industriais (ex: UCI Machine Learning Repository - Sensor dataset)"
                                  ],
                                  "tips": "Foquem em correlações moderadas a altas; ignore baixas como independentes.",
                                  "learningObjective": "Usar correlações para inferir a existência de fatores latentes subjacentes.",
                                  "commonMistakes": [
                                    "Interpretar toda correlação como latente",
                                    "Ignorar tamanho da amostra",
                                    "Confundir correlação com causalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Análise Fatorial Exploratória para Identificar Fatores",
                                  "subSteps": [
                                    "Execute análise fatorial em software (ex: factor_analyzer em Python ou R factanal()).",
                                    "Determine o número de fatores via scree plot ou critério de Kaiser (autovalores >1).",
                                    "Examine loadings fatoriais: variáveis com loadings >0.4 em um fator pertencem a ele.",
                                    "Rotacione fatores (varimax) para interpretabilidade clara.",
                                    "Nomeie fatores provisoriamente baseado em padrões de loading."
                                  ],
                                  "verification": "Produza um relatório com scree plot, loadings e nomes de 2-3 fatores de um dataset dado.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python: scikit-learn ou factor_analyzer",
                                    "R: psych package",
                                    "Dataset multivariado de processos industriais"
                                  ],
                                  "tips": "Comece com KMO test para verificar adequação (>0.6).",
                                  "learningObjective": "Executar análise fatorial para extrair e identificar fatores latentes.",
                                  "commonMistakes": [
                                    "Escolher número errado de fatores",
                                    "Ignorar communalities baixas (<0.4)",
                                    "Sobreinterpretar loadings fracos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Descrever e Interpretar Fatores Latentes em Contexto de Engenharia",
                                  "subSteps": [
                                    "Descreva cada fator: liste variáveis com alto loading e dê um nome descritivo (ex: 'Fator de Estresse Térmico').",
                                    "Explique como o fator explica correlações observadas nos dados de sensores.",
                                    "Valide com conhecimento de domínio: relacione a processos industriais reais.",
                                    "Discuta limitações: fatores são hipotéticos, requerem confirmação.",
                                    "Escreva um parágrafo resumindo o fator e sua utilidade preditiva."
                                  ],
                                  "verification": "Escreva descrições de 3 fatores identificados, ligando-os a correlações e aplicações industriais.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Relatório da Step 3",
                                    "Documentação de processos industriais (ex: manuais de sensores)"
                                  ],
                                  "tips": "Use linguagem não técnica para descrições acessíveis a engenheiros.",
                                  "learningObjective": "Articular o significado de fatores latentes de forma clara e contextualizada.",
                                  "commonMistakes": [
                                    "Nomes vagos ou genéricos",
                                    "Ignorar contexto de engenharia",
                                    "Confundir fator com variável observada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um conjunto de dados de sensores de uma planta química (temperatura, pressão, fluxo, vibração), a análise revela um fator latente 'Sobrecarga Operacional' com altos loadings em pressão e vibração, explicando suas correlações e prevendo falhas de manutenção.",
                              "finalVerifications": [
                                "Corretamente diferencia variáveis observadas de latentes em um exemplo dado.",
                                "Identifica clusters de correlação e infere fatores latentes plausíveis.",
                                "Executa análise fatorial e interpreta loadings corretamente.",
                                "Descreve fatores com nomes descritivos ligados ao domínio de engenharia.",
                                "Explica como fatores reduzem dimensionalidade em dados industriais.",
                                "Valida interpretação com testes de adequação (KMO, Bartlett)."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições claras sem confusões (30%)",
                                "Habilidade analítica: identificação correta de padrões em correlações e loadings (30%)",
                                "Interpretabilidade: descrições acionáveis e contextuais (20%)",
                                "Uso de ferramentas: execução correta de software sem erros (10%)",
                                "Criatividade em conexões: ligações relevantes a engenharia (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Modelos de regressão múltipla e PCA",
                                "Machine Learning: Redução de dimensionalidade e autoencoders",
                                "Engenharia Industrial: Monitoramento de condição e manutenção preditiva",
                                "Psicometria: Testes de inteligência (análoga a fatores em engenharia)"
                              ],
                              "realWorldApplication": "Em indústrias como manufatura ou óleo & gás, identificar fatores latentes em dados de sensores permite otimizar processos, prever falhas e reduzir custos, como detectar 'desgaste estrutural' antes de quebras caras."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.1.2",
                            "name": "Descrever o modelo matemático da análise fatorial",
                            "description": "Formular o modelo X = ΛF + ε, onde X são variáveis observadas, Λ matriz de cargas fatoriais, F fatores latentes e ε erros, explicando pressupostos como independência dos fatores e normalidade.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os Conceitos Fundamentais da Análise Fatorial",
                                  "subSteps": [
                                    "Defina variáveis observadas (X) como dados mensuráveis coletados empiricamente.",
                                    "Explique fatores latentes (F) como constructs não observáveis inferidos dos dados.",
                                    "Descreva erros (ε) como variância única e ruído não explicado pelos fatores.",
                                    "Diferencie cargas fatoriais (Λ) como pesos que conectam fatores a variáveis observadas.",
                                    "Revise a ideia de redução dimensional: múltiplas variáveis explicadas por poucos fatores."
                                  ],
                                  "verification": "Liste e defina corretamente os quatro componentes principais (X, Λ, F, ε) em um diagrama simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Livro de estatística multivariada (ex: 'Análise Multivariada de Dados' de Hair et al.), quadro branco ou software de desenho como Draw.io.",
                                  "tips": "Use analogias como 'fatores latentes são como ingredientes invisíveis em uma receita cujos efeitos vemos nos pratos observados'.",
                                  "learningObjective": "Identificar e definir os componentes básicos do modelo de análise fatorial.",
                                  "commonMistakes": "Confundir variáveis observadas com latentes ou ignorar que erros representam variância específica."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a Equação Geral do Modelo",
                                  "subSteps": [
                                    "Escreva a equação matricial: X = ΛF + ε.",
                                    "Especifique as dimensões: X (p x 1), Λ (p x m), F (m x 1), ε (p x 1), onde p > m.",
                                    "Interprete a equação: variáveis observadas são combinação linear de fatores mais erro.",
                                    "Desenhe um path diagram representando as relações.",
                                    "Pratique reescrevendo a equação para um caso com 3 variáveis e 2 fatores."
                                  ],
                                  "verification": "Escreva a equação corretamente e explique verbalmente o que cada termo representa.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Papel e caneta, ou Python/Jupyter com NumPy para matrizes simbólicas.",
                                  "tips": "Lembre-se: é um modelo de regressão múltipla onde regressores são não observados.",
                                  "learningObjective": "Formular e interpretar a equação matricial padrão da análise fatorial.",
                                  "commonMistakes": "Esquecer o termo de erro ou inverter as dimensões das matrizes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Detalhar a Matriz de Cargas Fatoriais (Λ)",
                                  "subSteps": [
                                    "Defina Λ como matriz de coeficientes de regressão padronizados entre fatores e variáveis.",
                                    "Explique interpretações: cargas > 0.7 indicam forte associação; sinal indica direção.",
                                    "Discuta rotação (varimax, obliqua) para melhorar interpretabilidade.",
                                    "Calcule um exemplo simples: Λ com valores hipotéticos para 4 variáveis e 2 fatores.",
                                    "Avalie communality: h² = soma das cargas ao quadrado por variável."
                                  ],
                                  "verification": "Construa uma matriz Λ 4x2 exemplo e calcule communalities para cada variável.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Calculadora ou Excel/Python para multiplicação matricial.",
                                  "tips": "Visualize Λ como 'setas' em um diagrama de fatores carregando nas variáveis.",
                                  "learningObjective": "Compreender e calcular o papel das cargas fatoriais no modelo.",
                                  "commonMistakes": "Interpretar cargas como correlações sem padronização ou ignorar rotação."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explicar Fatores Latentes (F) e Erros (ε)",
                                  "subSteps": [
                                    "Descreva F como vetor de fatores com média zero e variância unitária (padronizados).",
                                    "Explique covariância de F: diagonal para ortogonalidade em modelo ortogonal.",
                                    "Defina ε como independentes, com variância ψ (diagonal).",
                                    "Discuta E(F) = 0, Var(F) = I, Cov(F, ε) = 0.",
                                    "Compare modelos ortogonal vs. oblíquo."
                                  ],
                                  "verification": "Escreva as propriedades matemáticas de F e ε e prove independência.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Notas de aula sobre estatística matricial, software R com pacote psych.",
                                  "tips": "Pense em F como 'eixos principais' em uma nuvem de dados rotacionados.",
                                  "learningObjective": "Descrever propriedades estatísticas de fatores e erros.",
                                  "commonMistakes": "Assumir fatores com variância não unitária ou correlação com erros."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Descrever os Pressupostos do Modelo",
                                  "subSteps": [
                                    "Liste pressuposto 1: lineares relações (X linear em F).",
                                    "Pressuposto 2: normalidade multivariada das observadas (aproximação).",
                                    "Pressuposto 3: independência condicional dos erros.",
                                    "Pressuposto 4: fatores não correlacionados com erros; homogeneidade de variâncias.",
                                    "Pressuposto 5: adequação amostral (n > 10p) e KMO > 0.6.",
                                    "Discuta violações e remédios (ex: robustez a não-normalidade)."
                                  ],
                                  "verification": "Liste 5 pressupostos principais e dê um exemplo de violação para cada.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Artigo sobre pressupostos da AF (ex: de Costello & Osborne), simulador em R.",
                                  "tips": "Teste pressupostos em dados reais para fixar conceitos.",
                                  "learningObjective": "Identificar e explicar pressupostos críticos da análise fatorial.",
                                  "commonMistakes": "Omitir normalidade ou confundir com pressupostos de PCA."
                                }
                              ],
                              "practicalExample": "Em um questionário de personalidade com 10 itens (X), extraímos 3 fatores latentes (F: extroversão, neuroticismo, conscienciosidade) usando Λ com cargas como 0.8 para itens de extroversão no F1, resultando em X = ΛF + ε, onde ε captura respostas idiossincráticas.",
                              "finalVerifications": [
                                "Formula corretamente X = ΛF + ε com dimensões apropriadas.",
                                "Define e diferencia todos os componentes (X, Λ, F, ε).",
                                "Lista e explica pelo menos 4 pressupostos principais.",
                                "Calcula communalities de um exemplo simples.",
                                "Desenha um path diagram do modelo.",
                                "Discute implicações de violações de pressupostos."
                              ],
                              "assessmentCriteria": [
                                "Precisão na formulação matemática (equação e dimensões).",
                                "Completude na explicação de componentes e pressupostos.",
                                "Capacidade de interpretação prática (exemplos e analogias).",
                                "Correção em cálculos como communalities ou propriedades de variância.",
                                "Clareza na comunicação verbal/escrita do modelo.",
                                "Demonstração de entendimento de rotação e ortogonalidade."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: ligação com PCA e modelagem de equações estruturais.",
                                "Psicologia: aplicação em testes psicométricos e escalas de medida.",
                                "Ciência de Dados: redução dimensional em Machine Learning (pré-LDA).",
                                "Econometria: modelagem de fatores em séries temporais financeiras."
                              ],
                              "realWorldApplication": "Em pesquisas de satisfação do cliente, a análise fatorial reduz 20 variáveis de survey para 4 fatores latentes (qualidade, preço, serviço, lealdade), permitindo modelagem preditiva mais eficiente em marketing e análise de risco em bancos para detectar padrões latentes em portfólios de crédito."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.1.3",
                            "name": "Diferenciar análise fatorial de análise de componentes principais",
                            "description": "Comparar os objetivos, métodos de extração e interpretações, destacando que a análise fatorial modela erro único enquanto PCA maximiza variância total, com exemplos em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Objetivos Fundamentais de Cada Método",
                                  "subSteps": [
                                    "Leia definições: Análise Fatorial (AF) busca fatores latentes subjacentes que explicam correlações observadas, assumindo erro único comum.",
                                    "Leia definição de Análise de Componentes Principais (PCA): Reduz dimensionalidade maximizando variância explicada pelos componentes.",
                                    "Anote diferenças chave: AF é modelo inferencial (fatores causais), PCA é descritiva (transformação ortogonal).",
                                    "Crie um quadro comparativo com colunas para objetivos de AF e PCA.",
                                    "Pesquise referências como 'Applied Multivariate Statistical Analysis' de Johnson e Wichern para suporte teórico."
                                  ],
                                  "verification": "Quadro comparativo completo com pelo menos 3 diferenças nos objetivos, revisado por auto-perguntas.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Livro ou PDF de análise multivariada",
                                    "Papel ou ferramenta de notas como Notion/OneNote",
                                    "Acesso a artigos acadêmicos via Google Scholar"
                                  ],
                                  "tips": "Use analogias: AF como 'descobrir causas ocultas', PCA como 'comprimir imagem sem perda de variância principal'.",
                                  "learningObjective": "Identificar e articular os propósitos distintos de AF (modelagem latente) versus PCA (redução de dimensionalidade).",
                                  "commonMistakes": [
                                    "Confundir AF com clustering (AF é sobre fatores contínuos latentes)",
                                    "Ignorar que PCA não assume distribuição normal"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Comparar os Métodos de Extração",
                                  "subSteps": [
                                    "Estude extração em AF: Método dos componentes principais, máxima verossimilhança, etc., com rotação (varimax para interpretabilidade).",
                                    "Estude extração em PCA: Eigenvalores e autovetores da matriz de covariância, componentes ordenados por variância.",
                                    "Implemente em software: Use R (factanal() vs prcomp()) ou Python (factor_analyzer vs sklearn.decomposition.PCA) com dataset sintético.",
                                    "Compare outputs: AF dá loadings fatoriais, PCA dá scores de componentes.",
                                    "Calcule manualmente para matriz 3x3 pequena para visualizar diferenças."
                                  ],
                                  "verification": "Código executado gerando tabelas de loadings vs componentes, com interpretação escrita de 100 palavras.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Python/R instalado com bibliotecas (sklearn, factor_analyzer, factoextra)",
                                    "Dataset sintético de 10 variáveis",
                                    "Jupyter Notebook ou RStudio"
                                  ],
                                  "tips": "Comece com dados correlacionados para AF brilhar; normalize para PCA evitar viés de escala.",
                                  "learningObjective": "Executar e contrastar algoritmos de extração, destacando rotações em AF ausentes em PCA.",
                                  "commonMistakes": [
                                    "Não rotacionar fatores em AF, levando a interpretações ambíguas",
                                    "Usar PCA em dados não-lineares onde falha"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar Interpretações e Suposições Chave",
                                  "subSteps": [
                                    "Explique suposições AF: Erro único comum (unique variance por variável), fatores comuns explicam covariância.",
                                    "Explique PCA: Maximiza variância total, sem erro único modelado (toda variância é sinal).",
                                    "Discuta interpretações: AF para constructs psicológicos/engenharia, PCA para visualização/pre-processamento.",
                                    "Crie diagrama: Matriz de covariância → AF (fatores + erro único) vs PCA (componentes ortogonais).",
                                    "Avalie com teste de Kaiser-Meyer-Olkin (KMO) para adequação fatorial vs scree plot para PCA."
                                  ],
                                  "verification": "Diagrama desenhado e relatório de 150 palavras comparando suposições e interpretações.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Ferramenta de diagramação como Draw.io ou Lucidchart",
                                    "Calculadora ou Excel para KMO simples"
                                  ],
                                  "tips": "Lembre: AF responde 'por quê' correlacionado, PCA 'como resumir' dados.",
                                  "learningObjective": "Diferenciar modelagem de erro único em AF da maximização de variância em PCA nas interpretações.",
                                  "commonMistakes": [
                                    "Assumir AF e PCA intercambiáveis (AF requer amostra grande, >100 obs)",
                                    "Ignorar communalities em AF"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar e Sintetizar Diferenças com Exemplo em Engenharia",
                                  "subSteps": [
                                    "Carregue dataset de engenharia: Sensores de vibração em turbinas (10 variáveis como aceleração, temperatura).",
                                    "Execute AF e PCA: Compare % variância explicada, loadings vs componentes.",
                                    "Interprete: AF identifica fatores como 'desgaste mecânico', PCA comprime para monitoramento.",
                                    "Escreva síntese: Tabela final de prós/contras e quando usar cada.",
                                    "Teste sensibilidade: Altere dataset e re-execute para robustez."
                                  ],
                                  "verification": "Relatório final com códigos, tabelas e síntese de 200 palavras, auto-avaliado por checklist.",
                                  "estimatedTime": "75 minutos",
                                  "materials": [
                                    "Dataset público UCI/ML repo (e.g., turbofan engine degradation)",
                                    "Python/R scripts dos steps anteriores"
                                  ],
                                  "tips": "Escolha dataset com >5 variáveis correlacionadas para diferenças emergirem claramente.",
                                  "learningObjective": "Aplicar ambos métodos em dados reais de engenharia e sintetizar escolhas baseadas em objetivos.",
                                  "commonMistakes": [
                                    "Overfitting em AF sem validação cruzada",
                                    "Interpretar componentes PCA como causais"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de sensores de uma linha de produção de automóveis (10 variáveis: pressão, temperatura, vibração em 6 máquinas), aplique AF para identificar fatores latentes como 'falha térmica' (modelando erro de medição único) versus PCA para reduzir a 3 componentes principais capturando 85% variância para dashboard de monitoramento em tempo real.",
                              "finalVerifications": [
                                "Explicar verbalmente 5 diferenças chave sem consultar notas.",
                                "Escolher corretamente AF vs PCA para 3 cenários hipotéticos de engenharia.",
                                "Implementar ambos em novo dataset e interpretar resultados.",
                                "Identificar erro único em output de AF vs ausência em PCA.",
                                "Criar quadro comparativo de memória.",
                                "Passar quiz de 10 perguntas com >90% acerto."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção de objetivos (inferencial vs descritivo): 25%",
                                "Correta implementação e comparação de extração: 25%",
                                "Profundidade na análise de suposições (erro único vs variância): 20%",
                                "Qualidade da aplicação em exemplo de engenharia: 15%",
                                "Clareza na síntese e verificações finais: 15%"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de adequação (KMO, Bartlett) e inferência.",
                                "Machine Learning: PCA como pré-processamento para regressão/classificação.",
                                "Engenharia: Análise de falhas em sistemas multivariados (e.g., controle de qualidade).",
                                "Psicometria: AF em testes de construtos latentes adaptável a engenharia.",
                                "Visualização de Dados: Scree plots e biplots compartilhados."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, AF modela fatores latentes de degradação em motores (explicando ruído de sensores com erro único), enquanto PCA reduz dados de telemetria para detecção anômala em tempo real, otimizando manutenção preditiva e reduzindo downtime em 20%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.4.2",
                        "name": "Métodos de Extração de Fatores",
                        "description": "Técnicas estatísticas para estimar os fatores latentes a partir da matriz de correlações ou covariâncias, incluindo critérios para determinar o número de fatores.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.4.2.1",
                            "name": "Aplicar extração por autovalores e autovetores",
                            "description": "Utilizar decomposição em valores singulares ou autovalores da matriz de correlações para extrair fatores iniciais, interpretando o scree plot para retenção de fatores em dados multivariados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar a matriz de correlação dos dados multivariados",
                                  "subSteps": [
                                    "Carregar o conjunto de dados multivariado em um ambiente computacional.",
                                    "Padronizar as variáveis (z-score) para garantir correlação significativa.",
                                    "Calcular a matriz de correlação Pearson entre todas as variáveis.",
                                    "Verificar a matriz para valores ausentes ou não finitos e tratá-los.",
                                    "Salvar a matriz de correlação em formato utilizável para decomposição."
                                  ],
                                  "verification": "A matriz de correlação é simétrica, com diagonal principal igual a 1, e valores entre -1 e 1.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python com pandas e numpy; dataset de exemplo (ex: iris.csv)",
                                  "tips": "Use pd.corr() no pandas para rapidez; visualize com heatmap para inspeção inicial.",
                                  "learningObjective": "Compreender a importância da padronização e correlação na análise fatorial.",
                                  "commonMistakes": "Esquecer de padronizar variáveis com escalas diferentes, levando a correlações enviesadas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular autovalores e autovetores da matriz de correlação",
                                  "subSteps": [
                                    "Aplicar decomposição espectral (eigendecomposition) na matriz de correlação.",
                                    "Extrair os autovalores (λ) e autovetores correspondentes (v).",
                                    "Ordenar autovalores em ordem decrescente com autovetores associados.",
                                    "Verificar que a soma dos autovalores equals à trace da matriz (número de variáveis).",
                                    "Armazenar em estruturas separadas para análise subsequente."
                                  ],
                                  "verification": "Soma dos autovalores iguais à dimensão da matriz; autovetores ortonormais.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Python com numpy (np.linalg.eig); matriz de correlação salva",
                                  "tips": "Use np.linalg.eig() para cálculo direto; teste ortonormalidade com np.dot(v.T, v).",
                                  "learningObjective": "Dominar a decomposição em autovalores como base para extração de fatores.",
                                  "commonMistakes": "Não ordenar autovalores, resultando em interpretação incorreta da variância explicada."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Extrair fatores iniciais a partir dos autovetores",
                                  "subSteps": [
                                    "Definir fatores iniciais como autovetores escalados pela raiz quadrada dos autovalores.",
                                    "Calcular loadings fatoriais: √λ * v para os primeiros k fatores.",
                                    "Computar variância explicada por cada fator (λ_i / soma(λ)).",
                                    "Gerar scores fatoriais: X_padronizado * loadings.",
                                    "Salvar fatores iniciais não rotacionados para plotagem."
                                  ],
                                  "verification": "Variância cumulativa dos primeiros fatores > 60-70%; loadings normalizados.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Python com numpy; autovalores e autovetores do step anterior",
                                  "tips": "Multiplique autovetores por √λ para communalities adequadas; plote variância em barra.",
                                  "learningObjective": "Aplicar autovetores para representar fatores latentes nos dados.",
                                  "commonMistakes": "Confundir autovalores com variância percentual sem normalizar pela soma total."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir e interpretar o scree plot para retenção de fatores",
                                  "subSteps": [
                                    "Plotar autovalores em ordem decrescente (eixo y) vs. número do fator (eixo x).",
                                    "Identificar o 'cotovelo' (elbow) onde a curva se achata.",
                                    "Aplicar critérios como Kaiser (λ > 1) ou parallel analysis para validação.",
                                    "Decidir o número ótimo de fatores baseado no scree plot e critérios.",
                                    "Documentar a escolha com justificativa quantitativa e visual."
                                  ],
                                  "verification": "Scree plot gerado com cotovelo claro; número de fatores retidos justificado.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python com matplotlib ou seaborn; autovalores ordenados",
                                  "tips": "Use plt.plot(range(1, len(evals)+1), evals) com linha de referência λ=1; zoom no cotovelo.",
                                  "learningObjective": "Interpretar visual e quantitativamente a retenção de fatores relevantes.",
                                  "commonMistakes": "Retenção subjetiva sem critérios, levando a overfitting ou underfitting."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e resumir a extração de fatores",
                                  "subSteps": [
                                    "Calcular communalities (h² = soma loadings² por variável).",
                                    "Verificar variância total explicada pelos fatores retidos.",
                                    "Comparar com critérios alternativos (ex: SVD para robustez).",
                                    "Gerar relatório com scree plot, tabela de autovalores e loadings iniciais.",
                                    "Testar estabilidade com bootstrap se dados permitirem."
                                  ],
                                  "verification": "Communalities > 0.4 na maioria; variância > 50%; relatório completo.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Python completo (pandas, numpy, matplotlib); fatores extraídos",
                                  "tips": "Communalities baixas indicam variáveis ruins; use SVD com np.linalg.svd() como alternativa.",
                                  "learningObjective": "Avaliar qualidade da extração e preparar para rotação.",
                                  "commonMistakes": "Ignorar communalities baixas, invalidando a análise fatorial."
                                }
                              ],
                              "practicalExample": "Usando o dataset Iris (150 amostras, 4 variáveis: sepallength, sepalwidth, petallength, petalwidth), calcule a matriz de correlação, extraia autovalores/autovetores, gere scree plot mostrando 2 fatores principais (cotovelo em λ=2.3 e 1.7), retendo 2 fatores que explicam ~73% da variância, com loadings altos em petallength/petalwidth para fator 1 (tamanho pétala).",
                              "finalVerifications": [
                                "Matriz de correlação corretamente padronizada e simétrica.",
                                "Autovalores ordenados com soma igual à trace da matriz.",
                                "Scree plot identifica cotovelo claro com critérios Kaiser validados.",
                                "Fatores iniciais com loadings e communalities calculados.",
                                "Variância explicada > 60% pelos fatores retidos.",
                                "Relatório inclui plots e tabelas interpretáveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de autovalores/autovetores (erro < 1e-10).",
                                "Correta identificação do número de fatores via scree plot (acordo com critérios padrão).",
                                "Interpretação coerente de variância explicada e loadings.",
                                "Uso apropriado de padronização e verificações de qualidade.",
                                "Relatório claro com visualizações e justificativas.",
                                "Eficiência computacional sem erros em datasets médios."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência sobre variância em PCA e análise fatorial.",
                                "Machine Learning: Redução de dimensionalidade pré-processamento.",
                                "Ciência de Dados: Exploração multivariada em big data.",
                                "Psicologia: Modelagem de traços latentes em questionários."
                              ],
                              "realWorldApplication": "Em marketing, extrair fatores de preferências de consumidores de uma matriz de correlações de pesquisas para segmentação de mercado; em finanças, reduzir dimensionalidade de covariâncias de ativos para portfólios eficientes."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.2.2",
                            "name": "Implementar máxima verossimilhança",
                            "description": "Estimar fatores via método de máxima verossimilhança assumindo normalidade multivariada, comparando com mínimos quadrados e aplicando em software como R para dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Fundamentos Teóricos da Máxima Verossimilhança em Análise Fatorial",
                                  "subSteps": [
                                    "Estude a suposição de normalidade multivariada e a função de verossimilhança para matriz de covariância.",
                                    "Revise a equação de máxima verossimilhança para fatores latentes em análise fatorial.",
                                    "Compare conceitualmente ML com mínimos quadrados (ex.: PAF ou ULS), destacando vantagens em distribuições normais.",
                                    "Analise propriedades assintóticas como consistência e testes qui-quadrado.",
                                    "Resuma diferenças em estimativas de loadings e variâncias únicas."
                                  ],
                                  "verification": "Resuma em um parágrafo as diferenças chave entre ML e mínimos quadrados, citando fórmulas principais.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Livro 'Multivariate Analysis' de Mardia",
                                    "Artigo 'Factor Analysis by Maximum Likelihood' (Lawley & Maxwell)",
                                    "Notas de aula sobre normalidade multivariada"
                                  ],
                                  "tips": "Use diagramas de modelo fatorial para visualizar fatores latentes e observáveis.",
                                  "learningObjective": "Entender a base probabilística da ML e suas vantagens sobre métodos não-paramétricos.",
                                  "commonMistakes": [
                                    "Confundir ML com remoção de variância comum como em PCA",
                                    "Ignorar a necessidade de normalidade para validade assintótica"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar o Ambiente de Software e Conjunto de Dados",
                                  "subSteps": [
                                    "Instale e carregue pacotes R necessários: psych, corrplot, ggplot2.",
                                    "Carregue ou gere um dataset multivariado de engenharia (ex.: medidas de tensão, deformação, temperatura em testes de materiais).",
                                    "Verifique normalidade multivariada (Mardia's test) e transforme dados se necessário (ex.: log ou Box-Cox).",
                                    "Calcule matriz de correlação e teste KMO/Bartlett para adequação fatorial.",
                                    "Defina número de fatores via scree plot ou eigenvalues."
                                  ],
                                  "verification": "Execute script R que gera relatório de adequação de dados (KMO > 0.7, Bartlett p < 0.05).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R e RStudio",
                                    "Pacotes: psych, MVPnormtest",
                                    "Dataset exemplo: simular 200 amostras com 6 variáveis de engenharia"
                                  ],
                                  "tips": "Salve scripts em .Rmd para reprodutibilidade e versionamento com Git.",
                                  "learningObjective": "Preparar dados reais de engenharia para análise fatorial robusta.",
                                  "commonMistakes": [
                                    "Prosseguir sem testar normalidade, levando a estimativas enviesadas",
                                    "Usar amostras pequenas (<100), violando assunções"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar Estimativa por Máxima Verossimilhança em R",
                                  "subSteps": [
                                    "Execute fa(dataset, nfactors=2, fm='ml', rotate='varimax') no pacote psych.",
                                    "Extraia loadings, comunalidades, variâncias únicas e scores fatoriais.",
                                    "Teste significância com qui-quadrado e RMSEA.",
                                    "Gere plots de loadings e scree para visualização.",
                                    "Salve resultados em tabela formatada."
                                  ],
                                  "verification": "Obtenha modelo com qui-quadrado significativo mas RMSEA < 0.08, indicando bom ajuste.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "R script template para fa()",
                                    "Dataset preparado do Step 2"
                                  ],
                                  "tips": "Use covar=TRUE se dados forem covariâncias padronizadas.",
                                  "learningObjective": "Aplicar ML para extrair fatores de forma probabilística em software.",
                                  "commonMistakes": [
                                    "Especificar fm='ml' incorretamente como 'mlm'",
                                    "Interpretar loadings sem rotação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com Método de Mínimos Quadrados e Aplicar a Dados de Engenharia",
                                  "subSteps": [
                                    "Execute fa() com fm='pa' (Principal Axis) ou 'uls' para mínimos quadrados.",
                                    "Compare loadings, comunalidades e testes de ajuste lado a lado em tabela.",
                                    "Aplique ambos a dataset de engenharia (ex.: análise de falhas em componentes).",
                                    "Interprete diferenças: ML melhor em normalidade, LS mais robusto.",
                                    "Gere relatório com gráficos comparativos."
                                  ],
                                  "verification": "Tabela comparativa mostra convergência de loadings > 0.9 entre métodos.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Mesmo dataset",
                                    "Pacote psych para múltiplos fm"
                                  ],
                                  "tips": "Use psych::fa.diagram() para plots comparativos.",
                                  "learningObjective": "Avaliar robustez de ML vs. LS em contextos de engenharia.",
                                  "commonMistakes": [
                                    "Comparar com PCA em vez de PAF",
                                    "Ignorar amostragem Heywood (variâncias únicas negativas)"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar Resultados e Validar Aplicação",
                                  "subSteps": [
                                    "Calcule scores fatoriais e valide com regressão em variável externa.",
                                    "Avalie estabilidade com bootstrap (fa(bootstrap=TRUE)).",
                                    "Discuta implicações para engenharia (ex.: fatores de 'resistência' e 'degradação').",
                                    "Documente limitações (ex.: não-normalidade).",
                                    "Exporte relatório final em PDF/HTML."
                                  ],
                                  "verification": "Relatório final com interpretações coerentes e validação cruzada.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "knitr para relatórios",
                                    "Dataset validado"
                                  ],
                                  "tips": "Sempre reporte ICs de loadings via bootstrap.",
                                  "learningObjective": "Integrar análise fatorial ML em workflow de dados de engenharia.",
                                  "commonMistakes": [
                                    "Sobreinterpretar fatores sem validação externa",
                                    "Não reportar múltiplos ajustes"
                                  ]
                                }
                              ],
                              "practicalExample": "Em testes de fadiga de vigas de aço, use ML para extrair fatores 'resistência mecânica' (tensão, deformação) e 'condições ambientais' (temperatura, umidade) de 300 medições. Compare com PAF: ML fornece testes de ajuste probabilísticos, revelando que 70% da variância é explicada por 2 fatores, guiando otimização de design.",
                              "finalVerifications": [
                                "Script R executa sem erros e reproduz resultados consistentes.",
                                "Comparação ML vs. LS mostra diferenças <10% em loadings principais.",
                                "Qui-quadrado e RMSEA indicam ajuste adequado (p<0.05, RMSEA<0.08).",
                                "Interpretação dos fatores alinha com domínio de engenharia.",
                                "Bootstrap confirma estabilidade dos loadings.",
                                "Relatório inclui plots e tabelas profissionais."
                              ],
                              "assessmentCriteria": [
                                "Precisão teórica: explicação correta de ML sob normalidade (30%).",
                                "Implementação em R: código limpo e funcional (25%).",
                                "Comparação métodos: análise quantitativa e qualitativa (20%).",
                                "Interpretação aplicada: relevância para engenharia (15%).",
                                "Qualidade do relatório: clareza e visualizações (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses e intervalos de confiança.",
                                "Programação Computacional: manipulação de dados em R e visualização.",
                                "Engenharia de Materiais: análise multivariada de testes experimentais.",
                                "Machine Learning: extração de features latentes semelhantes a PCA/autoencoders.",
                                "Econometria: modelos de fatores em séries temporais."
                              ],
                              "realWorldApplication": "Na indústria aeroespacial, ML em análise fatorial otimiza sensores IoT para prever falhas em turbinas, integrando dados multivariados de vibração, temperatura e pressão, reduzindo downtime em 20% via fatores latentes identificados."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.2.3",
                            "name": "Determinar o número de fatores",
                            "description": "Aplicar critérios como Kaiser (autovalor >1), scree test e paralel analysis para decidir quantos fatores reter, validando em contextos de análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparação de Dados e Cálculo de Autovalores",
                                  "subSteps": [
                                    "Carregue um dataset multivariado adequado para análise fatorial (ex: medidas de sensores em engenharia).",
                                    "Verifique a adequação dos dados com testes KMO (>0.6) e Bartlett (p<0.05).",
                                    "Calcule a matriz de correlação.",
                                    "Extraia os autovalores usando PCA ou EFA em software como R (pacote psych) ou Python (factor_analyzer).",
                                    "Ordene os autovalores em ordem decrescente e calcule a variância explicada cumulativa."
                                  ],
                                  "verification": "Confirme que a soma dos autovalores equals o número de variáveis e % variância total é 100%.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Software R com pacotes psych e ggplot2 ou Python com pandas, numpy, factor_analyzer.",
                                    "Dataset exemplo (ex: dados de falhas em materiais de engenharia)."
                                  ],
                                  "tips": [
                                    "Padronize variáveis se escalas diferirem.",
                                    "Use correlation matrix em vez de covariance para datasets padronizados."
                                  ],
                                  "learningObjective": "Preparar dados e extrair autovalores para basear critérios de retenção de fatores.",
                                  "commonMistakes": [
                                    "Ignorar testes de adequação (KMO/Bartlett).",
                                    "Usar matriz de covariância sem padronização."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicação do Critério de Kaiser (Autovalor > 1)",
                                  "subSteps": [
                                    "Liste autovalores em ordem decrescente.",
                                    "Identifique e conte quantos autovalores são maiores que 1.",
                                    "Calcule a variância explicada pelos fatores retidos (>1).",
                                    "Registre o número sugerido pelo Kaiser e suas limitações (tendência a superestimar).",
                                    "Compare com variância cumulativa (ideal >50-70%)."
                                  ],
                                  "verification": "Número de fatores Kaiser documentado com lista de autovalores e % variância.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Planilha ou código R/Python para listar e filtrar autovalores.",
                                    "Gráfico de scree inicial."
                                  ],
                                  "tips": [
                                    "Ajuste para amostras pequenas (use >1.2-1.5).",
                                    "Combine sempre com outros critérios."
                                  ],
                                  "learningObjective": "Aplicar e interpretar o critério de Kaiser para sugestão inicial de fatores.",
                                  "commonMistakes": [
                                    "Retenção cega sem considerar tamanho da amostra.",
                                    "Ignorar que Kaiser superestima em >40 variáveis."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realização do Scree Test",
                                  "subSteps": [
                                    "Gere o scree plot: autovalor vs. número do componente/fator.",
                                    "Identifique visualmente o 'cotovelo' (ponto de inflexão onde autovalores caem abruptamente).",
                                    "Teste robustez girando o plot ou usando derivadas.",
                                    "Registre o número de fatores até o cotovelo e compare com Kaiser.",
                                    "Documente justificativa visual (ex: foto/anotação do plot)."
                                  ],
                                  "verification": "Scree plot gerado com cotovelo claramente marcado e número sugerido.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R com ggplot2 (plot() em prcomp) ou Python matplotlib/seaborn.",
                                    "Autovalores do Step 1."
                                  ],
                                  "tips": [
                                    "Use escala log para autovalores pequenos.",
                                    "Confirme cotovelo com múltiplos observadores."
                                  ],
                                  "learningObjective": "Construir e interpretar scree plot para determinação visual de fatores.",
                                  "commonMistakes": [
                                    "Escolha subjetiva sem justificativa.",
                                    "Confundir queda gradual com cotovelo."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Execução da Parallel Analysis",
                                  "subSteps": [
                                    "Gere 100-1000 matrizes de correlação aleatórias com mesmo n e p variáveis.",
                                    "Calcule autovalores médios para cada simulação paralela.",
                                    "Plote autovalores reais vs. médias paralelas (e desvios).",
                                    "Conte fatores onde autovalores reais > paralelos correspondentes.",
                                    "Registre o número sugerido pela parallel analysis."
                                  ],
                                  "verification": "Plot de parallel analysis com linha de corte e número de fatores final.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R pacote psych (fa.parallel()) ou Python com factor_analyzer.parallel().",
                                    "Computador com capacidade para simulações."
                                  ],
                                  "tips": [
                                    "Use 500+ simulações para precisão.",
                                    "Prefira percentile 95 para corte conservador."
                                  ],
                                  "learningObjective": "Realizar análise paralela para critério estatístico robusto de retenção.",
                                  "commonMistakes": [
                                    "Poucas simulações (baixa precisão).",
                                    "Comparar com mediana em vez de média/percentil."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integração de Critérios e Validação Final",
                                  "subSteps": [
                                    "Compare sugestões: Kaiser, scree, parallel analysis.",
                                    "Escolha número consensual (maioria ou médio ponderado).",
                                    "Valide com índices de fit (Tucker-Lewis, RMSEA) após rotação.",
                                    "Teste sensibilidade variando métodos de extração.",
                                    "Elabore relatório com justificativa e número final de fatores."
                                  ],
                                  "verification": "Relatório integrado justificando o número de fatores com evidências de múltiplos critérios.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Resultados dos steps anteriores.",
                                    "Software para EFA completa (psych::fa())."
                                  ],
                                  "tips": [
                                    "Priorize parallel analysis como mais robusta.",
                                    "Use cross-validation em subamostras."
                                  ],
                                  "learningObjective": "Integrar critérios para decisão robusta e validar em contexto de engenharia.",
                                  "commonMistakes": [
                                    "Decisão baseada em um único critério.",
                                    "Ignorar discrepâncias entre métodos."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia com 10 variáveis de sensores de vibração em turbinas (n=300), calcule autovalores: [3.2, 1.8, 1.1, 0.9, ...]. Kaiser sugere 3 fatores; scree cotovelo em 3; parallel analysis confirma 3 (reais > paralelos até 3). Retém 3 fatores representando modos de falha principais.",
                              "finalVerifications": [
                                "Autovalores calculados corretamente e plotados.",
                                "Número de fatores justificado por pelo menos 2 critérios.",
                                "Scree e parallel plots gerados e interpretados.",
                                "Relatório explica escolha em contexto de engenharia.",
                                "Validação com fit indices (ex: CFI >0.9).",
                                "Sensibilidade testada (variação <1 fator)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e listagem de autovalores (100% match).",
                                "Interpretação correta de cada critério (consistência com literatura).",
                                "Integração lógica de múltiplos métodos (consenso claro).",
                                "Qualidade visual dos plots (rótulos, escalas adequadas).",
                                "Justificativa contextualizada para engenharia (relevância prática).",
                                "Ausência de erros comuns (ex: superestimação Kaiser isolada)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial (testes de hipóteses como Bartlett).",
                                "Machine Learning (PCA e redução dimensional).",
                                "Engenharia de Dados (pré-processamento multivariado).",
                                "Pesquisa Operacional (otimização de modelos).",
                                "Análise de Dados Exploratória (visualizações como scree)."
                              ],
                              "realWorldApplication": "Na engenharia, determina fatores latentes em monitoramento de processos industriais, reduzindo dimensionalidade para detecção de falhas em manufatura, otimização de qualidade e previsão de manutenção preditiva, economizando recursos computacionais e melhorando decisões baseadas em dados."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.4.3",
                        "name": "Rotação e Interpretação de Fatores",
                        "description": "Processos para simplificar e interpretar a estrutura fatorial, incluindo rotações e cálculo de scores fatoriais, com foco em aplicações práticas.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.4.3.1",
                            "name": "Executar rotação ortogonal Varimax",
                            "description": "Aplicar rotação Varimax para maximizar cargas altas e minimizar baixas, melhorando interpretabilidade em fatores independentes, com exemplo em dados econômicos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e extrair fatores iniciais",
                                  "subSteps": [
                                    "Carregar dataset econômico de engenharia (ex: variáveis como PIB, investimento em infraestrutura, produção industrial, inflação e emprego)",
                                    "Padronizar os dados usando z-score para eliminar escalas diferentes",
                                    "Realizar Análise de Componentes Principais (PCA) ou Extração de Fatores para obter matriz de cargas iniciais",
                                    "Determinar o número de fatores usando critério de Kaiser (autovalores >1) ou scree plot",
                                    "Salvar a matriz de cargas fatoriais não rotacionadas"
                                  ],
                                  "verification": "Verificar se a matriz de cargas iniciais tem variância explicada >60% e autovalores >1 para fatores retidos",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python 3.x",
                                    "Bibliotecas: pandas, numpy, scikit-learn, factor_analyzer",
                                    "Dataset exemplo: dados econômicos fictícios ou do Kaggle"
                                  ],
                                  "tips": "Sempre padronize dados antes da análise para evitar viés de escala; use seed para reproducibilidade",
                                  "learningObjective": "Compreender preparação de dados multivariados para análise fatorial",
                                  "commonMistakes": [
                                    "Esquecer padronização levando a cargas distorcidas",
                                    "Selecionar número errado de fatores sem critério estatístico"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar rotação ortogonal Varimax",
                                  "subSteps": [
                                    "Importar função de rotação Varimax da biblioteca factor_analyzer ou implementar manualmente via otimização",
                                    "Aplicar rotação à matriz de cargas iniciais: loadings_rotated = varimax_rotation(loadings_initial)",
                                    "Calcular comunalidades pós-rotação (soma de quadrados das cargas por variável)",
                                    "Visualizar matriz de cargas rotacionadas em tabela e heatmap",
                                    "Comparar cargas pré e pós-rotação para observar maximização de altas e minimização de baixas"
                                  ],
                                  "verification": "Cargas fatoriais devem mostrar pelo menos 70% das variáveis com cargas >0.5 em um fator e <0.3 nos outros",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Biblioteca factor_analyzer ou código customizado para Varimax"
                                  ],
                                  "tips": "Use q= número de fatores; itere até convergência (geralmente <100 iterações)",
                                  "learningObjective": "Executar algoritmo Varimax para simplificar estrutura fatorial",
                                  "commonMistakes": [
                                    "Confundir rotação ortogonal com oblíqua (Varimax assume independência)",
                                    "Não verificar convergência do algoritmo"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar cargas rotacionadas e fatores",
                                  "subSteps": [
                                    "Identificar padrões: agrupar variáveis com cargas altas (>0.6) por fator",
                                    "Nomear fatores com base em interpretação temática (ex: Fator 1: Crescimento Econômico)",
                                    "Calcular escores fatoriais para cada observação",
                                    "Avaliar interpretabilidade: complexidade simples (média de cargas por variável ≈1)",
                                    "Gerar relatório com tabela de cargas e variância explicada por fator"
                                  ],
                                  "verification": "Cada fator deve ter pelo menos 3 variáveis com cargas salientes e interpretação coerente",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Matplotlib/Seaborn para visualizações",
                                    "Pandas para tabelas formatadas"
                                  ],
                                  "tips": "Cargas salientes: |λ| > 0.5; ignore cargas cruzadas baixas",
                                  "learningObjective": "Traduzir matriz numérica em insights interpretáveis",
                                  "commonMistakes": [
                                    "Nomear fatores sem suporte empírico",
                                    "Interpretar cargas baixas como significativas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e documentar resultados",
                                  "subSteps": [
                                    "Testar robustez com subamostras ou bootstrap",
                                    "Comparar com rotação não ortogonal (ex: Promax) para justificar Varimax",
                                    "Calcular Tucker’s congruence para estabilidade",
                                    "Exportar resultados em PDF/Excel com gráficos",
                                    "Discutir limitações (ex: assume fatores ortogonais)"
                                  ],
                                  "verification": "Congruência >0.9 e variância explicada similar à inicial",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Biblioteca pingouin para testes",
                                    "ReportLab ou pandas.to_latex para export"
                                  ],
                                  "tips": "Documente seed e parâmetros para reprodutibilidade",
                                  "learningObjective": "Garantir validade científica dos resultados fatoriais",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade residual",
                                    "Sobreinterpretar fatores com baixa variância"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia econômica com 100 regiões (variáveis: investimento em rodovias, produção de energia, taxa de desemprego, inflação industrial, PIB per capita), aplique Varimax após PCA: Fator 1 (Cargas altas em PIB e produção) interpretado como 'Desenvolvimento Industrial'; Fator 2 (Investimento e emprego) como 'Infraestrutura Humana'. Pós-rotação, cargas salientes aumentam de 0.45 para 0.72 em média.",
                              "finalVerifications": [
                                "Matriz de cargas mostra estrutura simples (cargas altas maximizadas >0.6, baixas <0.3)",
                                "Variância explicada por fatores é mantida ou aumentada pós-rotação",
                                "Fatores nomeados com interpretações coerentes baseadas em dados econômicos",
                                "Comunalidades >0.5 para maioria das variáveis",
                                "Gráficos de scree plot e heatmap confirmam melhor interpretabilidade",
                                "Escores fatoriais calculados e plotados sem erros"
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação do Varimax (convergência e cargas corretas: 30%)",
                                "Qualidade da interpretação fatorial (nomes e justificativas: 25%)",
                                "Uso correto de pré-processamento e validação (20%)",
                                "Visualizações claras e relatório completo (15%)",
                                "Eficiência temporal e código limpo (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Integra com testes de adequação KMO e Bartlett",
                                "Economia/Engenharia: Aplicação em modelagem de indicadores macroeconômicos",
                                "Programação: Uso de otimização numérica (gradient descent implícito)",
                                "Visualização de Dados: Heatmaps e biplots para comunicação de resultados"
                              ],
                              "realWorldApplication": "Em engenharia econômica, otimiza previsão de recessões rotacionando fatores de dados macro (PIB, emprego) para identificar drivers independentes como 'Inflação Estrutural' vs 'Crescimento', auxiliando governos em alocação de investimentos em infraestrutura sustentável."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.3.2",
                            "name": "Realizar rotação oblíqua",
                            "description": "Usar métodos como Promax ou Oblimin para permitir correlação entre fatores, interpretando a matriz de correlações de fatores em análises complexas de sistemas de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos de Rotação Oblíqua",
                                  "subSteps": [
                                    "Diferencie rotação ortogonal (varimax) de oblíqua (promax/oblimin), destacando que oblíqua permite correlações entre fatores.",
                                    "Estude a matriz de estrutura de fatores e a matriz de correlação de fatores (pattern e factor correlation matrices).",
                                    "Revise os pressupostos da análise fatorial exploratória (AFE) pré-rotação.",
                                    "Analise exemplos teóricos de quando usar rotação oblíqua em dados com fatores correlacionados.",
                                    "Identifique o parâmetro kappa no Promax ou o grau de oblíquidade no Oblimin."
                                  ],
                                  "verification": "Resuma em um parágrafo as diferenças entre rotações e justifique o uso de oblíqua com um exemplo hipotético.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro de texto sobre análise multivariada (ex: 'Análise Multivariada para as Ciências' de Hair et al.)",
                                    "Artigos sobre rotação de fatores (ex: Browne, 2001 sobre Promax)",
                                    "Notebook para anotações"
                                  ],
                                  "tips": "Use diagramas visuais para representar fatores ortogonais vs. oblíquos.",
                                  "learningObjective": "Explicar conceitualmente por que e quando aplicar rotação oblíqua em AFE.",
                                  "commonMistakes": [
                                    "Confundir rotação oblíqua com ortogonal",
                                    "Ignorar que oblíqua é para fatores teoricamente correlacionados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Dados e Selecionar Método de Rotação",
                                  "subSteps": [
                                    "Carregue o conjunto de dados de AFE prévia (fatores extraídos via máxima verossimilhança ou componentes principais).",
                                    "Verifique a solução ortogonal inicial e avalie o mapa de scree ou eigenvalues para confirmar número de fatores.",
                                    "Escolha o método: Oblimin para controle de oblíquidade (delta entre 0 e 1) ou Promax (kappa tipicamente 4).",
                                    "Defina parâmetros iniciais: número de fatores, grau de liberdade para testes de significância.",
                                    "Execute diagnóstico pré-rotação: teste de Bartlett e KMO para adequação dos dados."
                                  ],
                                  "verification": "Gere relatório confirmando KMO > 0.7 e escolha justificada do método (ex: Promax para robustez).",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software R (pacotes psych ou GPArotation)",
                                    "Python (factor_analyzer)",
                                    "Dataset de exemplo de engenharia (ex: dados de sensores multidimensionais)"
                                  ],
                                  "tips": "Comece com Oblimin se quiser controle fino; Promax é mais rápido para grandes datasets.",
                                  "learningObjective": "Preparar adequadamente dados para rotação oblíqua e selecionar método apropriado.",
                                  "commonMistakes": [
                                    "Usar rotação sem verificar adequação dos dados",
                                    "Escolher parâmetros sem justificativa teórica"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar a Rotação Oblíqua",
                                  "subSteps": [
                                    "Implemente a rotação no software: em R, fa.factor(..., rotate='oblimin') ou promax().",
                                    "Extraia matrizes chave: pattern matrix (loadings), factor correlations, e loadings de referência.",
                                    "Ajuste parâmetros iterativamente (ex: teste delta=0, 0.5, 1 no Oblimin) para simplicidade interpretativa.",
                                    "Compare soluções oblíqua vs. ortogonal usando coeficiente de congruência ou Tucker.",
                                    "Salve outputs: tabelas de loadings e matriz de correlações de fatores."
                                  ],
                                  "verification": "Produza tabelas de pattern matrix e factor correlations com loadings > 0.4 destacados.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ambiente RStudio ou Jupyter Notebook com bibliotecas instaladas",
                                    "Dataset real de sistemas de engenharia (ex: vibrações em estruturas)"
                                  ],
                                  "tips": "Use rotate='promax' para automação; visualize com fa.diagram() no psych.",
                                  "learningObjective": "Executar tecnicamente a rotação oblíqua e extrair matrizes essenciais.",
                                  "commonMistakes": [
                                    "Interpretar pattern matrix como loadings ortogonais",
                                    "Ignorar iterações para otimização"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Resultados e Matriz de Correlações",
                                  "subSteps": [
                                    "Analise pattern matrix: identifique loadings salientes (>0.4) e cross-loadings.",
                                    "Examine matriz de correlações de fatores: interprete correlações >0.3 como substantivas.",
                                    "Nomeie fatores baseados em conteúdo teórico e loadings.",
                                    "Avalie melhoria na interpretabilidade vs. solução ortogonal (ex: redução de Heywood cases).",
                                    "Discuta implicações para sistemas de engenharia: fatores correlacionados indicam interdependências."
                                  ],
                                  "verification": "Escreva relatório de 1 página nomeando fatores e justificando correlações observadas.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Templates de relatório de AFE",
                                    "Ferramentas de visualização (ggplot2 ou matplotlib)"
                                  ],
                                  "tips": "Priorize loadings primários; use regras de Thurstone para interpretação.",
                                  "learningObjective": "Interpretar corretamente matrizes de rotação oblíqua em contexto aplicado.",
                                  "commonMistakes": [
                                    "Sobreinterpretar correlações baixas",
                                    "Nomear fatores sem base teórica"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de monitoramento de engenharia civil, use dados de sensores (vibração, tensão, temperatura) para AFE. Aplique Promax para rotacionar 4 fatores, revelando 'Fator Estrutural' correlacionado com 'Fator Ambiental' (r=0.45), permitindo modelar interações em predições de falhas.",
                              "finalVerifications": [
                                "Matriz de correlações de fatores mostra valores coerentes com teoria (ex: r entre 0.2-0.7).",
                                "Pattern matrix tem pelo menos 70% de variância explicada com loadings salientes claros.",
                                "Relatório inclui comparação ortogonal vs. oblíqua com melhoria mensurável.",
                                "Fatores nomeados com justificativa baseada em loadings e contexto de engenharia.",
                                "Código reproduzível gera os mesmos resultados.",
                                "Nenhuma cross-loading problemática sem explicação."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: explicação correta de oblíqua vs. ortogonal (30%).",
                                "Execução técnica: código sem erros e parâmetros otimizados (25%).",
                                "Interpretação: análise profunda da matriz de correlações (25%).",
                                "Aplicação contextual: ligação com sistemas de engenharia (10%).",
                                "Relatório claro e visual (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de significância em correlações de fatores.",
                                "Machine Learning: similar a extração de features em PCA não-ortogonal.",
                                "Engenharia de Sistemas: modelagem de dependências em redes complexas.",
                                "Psicometria: interpretação de fatores em escalas multidimensionais.",
                                "Visualização de Dados: plotagem de biplots de fatores oblíquos."
                              ],
                              "realWorldApplication": "Em análises de sistemas de engenharia complexos, como monitoramento de turbinas eólicas, rotação oblíqua identifica fatores latentes correlacionados (ex: fadiga mecânica e condições climáticas), melhorando previsões de manutenção preditiva e otimizando designs robustos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.3.3",
                            "name": "Interpretar cargas fatoriais e communalities",
                            "description": "Analisar cargas fatoriais (>0.4 como significativas), communalities (variância explicada por fatores) e scores fatoriais para insights em dados multivariados de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de cargas fatoriais, communalities e scores fatoriais",
                                  "subSteps": [
                                    "Defina carga fatorial como a correlação entre uma variável original e um fator latente.",
                                    "Explique communality como a proporção de variância da variável explicada pelos fatores comuns.",
                                    "Descreva scores fatoriais como as projeções das observações nos fatores.",
                                    "Revise a estrutura da matriz de cargas fatoriais e seu papel na rotação (varimax ou oblimin).",
                                    "Identifique o limiar convencional de |carga| > 0.4 para significância."
                                  ],
                                  "verification": "Liste definições precisas e desenhe um exemplo simplificado de matriz de cargas 3x2.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Documentação de análise fatorial (R ou Python)",
                                    "Artigo introdutório sobre PCA vs. FA",
                                    "Notebook Jupyter vazio"
                                  ],
                                  "tips": "Use analogias: cargas como 'pesos' de ingredientes em uma receita de fatores.",
                                  "learningObjective": "Ao final, o aluno definirá e diferenciará cargas, communalities e scores com exemplos.",
                                  "commonMistakes": [
                                    "Confundir cargas com loadings de PCA (ignorar communalities)",
                                    "Ignorar o sinal das cargas (positivo/negativo indica direção)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Avaliar e interpretar cargas fatoriais significativas",
                                  "subSteps": [
                                    "Extraia a matriz de cargas rotacionada do output do software.",
                                    "Aplique o critério |carga| > 0.4 para marcar cargas significativas.",
                                    "Agrupe variáveis por fator com base em cargas altas (>0.4 em um fator, <0.3 em outros).",
                                    "Interprete o significado: nomeie fatores com base em variáveis dominantes.",
                                    "Considere supressão se cargas paradoxais aparecerem."
                                  ],
                                  "verification": "Anote cargas significativas e proponha nomes para 2 fatores em um dataset exemplo.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Software R (factanal) ou Python (factor_analyzer)",
                                    "Dataset multivariado industrial (ex: sensores de processo)"
                                  ],
                                  "tips": "Priorize cargas mais altas para nomeação; visualize com heatmap.",
                                  "learningObjective": "O aluno identificará e nomeará fatores corretamente em uma matriz real.",
                                  "commonMistakes": [
                                    "Sobrecarregar um fator com variáveis fracas",
                                    "Ignorar rotações oblíquas para correlações entre fatores"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar communalities para validar a qualidade da solução fatorial",
                                  "subSteps": [
                                    "Calcule communalities como soma dos quadrados das cargas por variável.",
                                    "Identifique variáveis com h² baixa (<0.4): considere remoção ou mais fatores.",
                                    "Compare communalities pré e pós-rotação para avaliar melhoria.",
                                    "Avalie variância total explicada (soma de communalities / n variáveis).",
                                    "Interprete: communalities altas indicam boa representabilidade."
                                  ],
                                  "verification": "Liste communalities do dataset e recomende ajustes se <50% explicada.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Mesmo dataset e software do step 2",
                                    "Tabela de communalities extraída"
                                  ],
                                  "tips": "h² próxima de 1 é ideal; valores <0.2 sinalizam problema.",
                                  "learningObjective": "O aluno avaliará a adequação da extração fatorial via communalities.",
                                  "commonMistakes": [
                                    "Confundir communality com variância total da variável",
                                    "Aceitar solução com communalities uniformemente baixas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar interpretações com scores fatoriais para insights industriais",
                                  "subSteps": [
                                    "Gere scores fatoriais usando regression ou Bartlett method.",
                                    "Plote scores fatoriais para visualizar clusters ou outliers em processos.",
                                    "Correlacione scores com variáveis originais para insights (ex: fator 1 alto = falha em sensor).",
                                    "Extraia insights multivariados: prediga problemas industriais via scores.",
                                    "Valide com métricas como Kaiser-Meyer-Olkin (KMO >0.6)."
                                  ],
                                  "verification": "Gere relatório com 3 insights baseados em scores e cargas de um caso industrial.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dataset real de processos industriais",
                                    "Bibliotecas: factor_analyzer (Python), psych (R)"
                                  ],
                                  "tips": "Use scores para monitoramento preditivo em tempo real.",
                                  "learningObjective": "O aluno aplicará cargas, communalities e scores para decisões industriais.",
                                  "commonMistakes": [
                                    "Interpretar scores sem contexto das cargas",
                                    "Ignorar multicolinearidade nas variáveis originais"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de cimento, analise dados de 10 sensores (temperatura, pressão, vibração etc.). Matriz de cargas revela Fator 1 ('Eficiência Térmica': cargas altas em temp forno >0.7, press >0.5; communalities >0.6). Scores altos em Fator 1 indicam lotes com alto consumo energético, permitindo otimização.",
                              "finalVerifications": [
                                "Explique por que |carga| >0.4 é significativa e dê contraexemplo.",
                                "Calcule communality manualmente para uma variável com cargas 0.6 e 0.3.",
                                "Interprete um score fatorial alto em contexto industrial.",
                                "Nomeie fatores de uma matriz exemplo com 4 variáveis e 2 fatores.",
                                "Avalie se KMO=0.75 e communalities médias=0.55 validam a solução.",
                                "Proponha insight de um plot de scores fatoriais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de cargas significativas (>90% corretas).",
                                "Interpretação coerente de fatores com variáveis dominantes.",
                                "Análise correta de communalities e recomendações de ajuste.",
                                "Insights acionáveis integrando scores e contexto industrial.",
                                "Uso adequado de critérios estatísticos (KMO, Bartlett).",
                                "Clareza em relatórios e visualizações."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de esfericidade e adequação amostral.",
                                "Engenharia de Processos: otimização multivariada em manufatura.",
                                "Química Industrial: análise de fatores em controle de qualidade.",
                                "Machine Learning: similaridade com redução de dimensionalidade (PCA).",
                                "Gestão de Dados: limpeza e pré-processamento multivariado."
                              ],
                              "realWorldApplication": "Em indústrias como petroquímica ou automotiva, interpretar cargas e communalities permite identificar padrões latentes em dados de sensores, prevendo falhas de equipamentos, otimizando processos e reduzindo custos operacionais em até 20% via monitoramento preditivo."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.4.3.4",
                            "name": "Aplicar análise fatorial em dados de engenharia",
                            "description": "Realizar análise fatorial completa em conjuntos de dados reais de engenharia, como monitoramento de equipamentos, usando R ou ferramentas similares, e validar resultados com bibliografia como Gujarati e Greene.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o Conjunto de Dados de Engenharia",
                                  "subSteps": [
                                    "Carregue o dataset real de engenharia (ex: dados de vibração, temperatura e pressão de equipamentos) em R usando read.csv() ou similar.",
                                    "Realize limpeza de dados: remova missing values com na.omit() ou imputação, e padronize variáveis com scale().",
                                    "Selecione variáveis relevantes baseadas em conhecimento de domínio de engenharia (ex: sensores correlacionados).",
                                    "Crie uma matriz de correlação para inspeção inicial com cor() ou corrplot.",
                                    "Salve uma cópia limpa do dataset para reproducibilidade."
                                  ],
                                  "verification": "Dataset limpo e padronizado sem NAs, com matriz de correlação visualizada e salva.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Pacotes: psych, corrplot",
                                    "Dataset CSV de monitoramento de equipamentos (ex: NASA Turbofan dataset)"
                                  ],
                                  "tips": "Sempre documente transformações em um script R para auditoria; use seed para reproducibilidade.",
                                  "learningObjective": "Dominar a preparação de dados multivariados reais de engenharia para análise fatorial.",
                                  "commonMistakes": [
                                    "Ignorar outliers que distorcem correlações",
                                    "Não padronizar variáveis com escalas diferentes",
                                    "Incluir variáveis categóricas sem codificação"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Avaliar Adequação dos Dados para Análise Fatorial",
                                  "subSteps": [
                                    "Instale e carregue pacotes necessários: library(psych).",
                                    "Calcule teste de Kaiser-Meyer-Olkin (KMO) com KMO(dataset).",
                                    "Realize teste de esfericidade de Bartlett com cortest.bartlett().",
                                    "Gere scree plot com fa.parallel() para estimar número de fatores.",
                                    "Interprete resultados: KMO > 0.6 e p-value Bartlett < 0.05 indicam adequação."
                                  ],
                                  "verification": "Relatório com KMO >= 0.6, Bartlett significativo e scree plot salvo.",
                                  "estimatedTime": "45 minutos - 1 hora",
                                  "materials": [
                                    "R com pacote psych",
                                    "Dataset preparado do Step 1"
                                  ],
                                  "tips": "Se KMO < 0.6, remova variáveis com communality baixa; visualize múltiplos plots para confirmação.",
                                  "learningObjective": "Avaliar se dados de engenharia atendem pré-requisitos estatísticos para análise fatorial.",
                                  "commonMistakes": [
                                    "Prosseguir com KMO baixo sem ajustes",
                                    "Ignorar multicolinearidade extrema",
                                    "Confundir parallel analysis com scree plot simples"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realizar Extração de Fatores",
                                  "subSteps": [
                                    "Execute análise fatorial principal com fa(dataset, nfactors=estimado, rotate='none').",
                                    "Escolha método de extração (ex: PAF ou ML) baseado em scree plot.",
                                    "Examine eigenvalues e variância explicada (>60% ideal).",
                                    "Gere loadings iniciais e communalities com print() e fa.diagram().",
                                    "Salve output em objeto para próximos passos."
                                  ],
                                  "verification": "Número de fatores extraídos com eigenvalues >1, variância explicada documentada.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R com psych",
                                    "Dataset validado"
                                  ],
                                  "tips": "Use fm='pa' para dados de engenharia com não-normalidade; compare múltiplos nfactors.",
                                  "learningObjective": "Extrair fatores latentes de dados multivariados de engenharia de forma robusta.",
                                  "commonMistakes": [
                                    "Sobrestimar nfactors ignorando elbow no scree plot",
                                    "Não reportar variância explicada",
                                    "Usar PCA em vez de FA para fatores latentes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Rotacionar e Interpretar Fatores",
                                  "subSteps": [
                                    "Aplique rotação varimax ou oblimin: fa(..., rotate='varimax').",
                                    "Identifique loadings > |0.4| e nomeie fatores baseado em domínio (ex: Fator 1: Vibração Estrutural).",
                                    "Crie scores de fatores com factor.scores().",
                                    "Valide interpretação com suppression e cross-loadings.",
                                    "Visualize com fa.diagram() rotacionado."
                                  ],
                                  "verification": "Fatores nomeados com loadings claros, sem cross-loadings significativos, diagramas salvos.",
                                  "estimatedTime": "1-1.5 horas",
                                  "materials": [
                                    "R psych",
                                    "Output do Step 3"
                                  ],
                                  "tips": "Prefira rotação oblíqua se correlação entre fatores >0.3; nomeie fatores com termos de engenharia.",
                                  "learningObjective": "Interpretar fatores rotacionados em contexto de engenharia.",
                                  "commonMistakes": [
                                    "Rotação inadequada para estrutura simples",
                                    "Nomear fatores sem domínio",
                                    "Ignorar communalities <0.4"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar Resultados e Reportar",
                                  "subSteps": [
                                    "Compare resultados com bibliografia (Gujarati Ch.18, Greene Ch.15) para critérios semelhantes.",
                                    "Calcule confiabilidade com alpha() nos scores de fatores.",
                                    "Teste robustez com bootstrap: fa.bootstrap().",
                                    "Gere relatório com loadings, scores e interpretações.",
                                    "Salve script completo e outputs para peer review."
                                  ],
                                  "verification": "Relatório validado contra referências, alpha >0.7, bootstrap consistente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livros: Gujarati 'Basic Econometrics', Greene 'Econometric Analysis'",
                                    "R psych"
                                  ],
                                  "tips": "Cite seções específicas da bibliografia; use knitr para relatório automatizado.",
                                  "learningObjective": "Validar análise fatorial com padrões acadêmicos e gerar relatório acionável.",
                                  "commonMistakes": [
                                    "Não validar communalities",
                                    "Ignorar validação cruzada",
                                    "Relatório sem contexto de engenharia"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dataset de monitoramento de turbinas (sensores: vibração, temperatura, rpm), extraia 3 fatores: 'Desgaste Estrutural' (vibração+pressão), 'Sobrecarga Térmica' (temperatura+rpm), 'Eficiência Operacional', reduzindo 10 variáveis para planejamento de manutenção preditiva.",
                              "finalVerifications": [
                                "KMO >= 0.6 e Bartlett significativo confirmados.",
                                "Variância explicada cumulativa >= 60%.",
                                "Todos fatores interpretados com loadings > |0.4| e communalities > 0.4.",
                                "Scores de fatores gerados e plotados.",
                                "Validação cruzada com bibliografia (Gujarati/Greene) documentada.",
                                "Script R reproduzível salvo."
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação e adequação dos dados (KMO, Bartlett).",
                                "Correta extração e rotação de fatores com justificativa.",
                                "Interpretação contextualizada para engenharia.",
                                "Validação robusta e comparação bibliográfica.",
                                "Relatório claro com visualizações e scores acionáveis.",
                                "Eficiência temporal e ausência de erros comuns."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Aplicada: Testes multivariados e validação.",
                                "Engenharia Mecânica: Monitoramento de condição de equipamentos.",
                                "Machine Learning: Redução de dimensionalidade pré-DIM.",
                                "Econometria: Modelos de Gujarati/Greene em dados industriais.",
                                "Gestão de Manutenção: Aplicações preditivas."
                              ],
                              "realWorldApplication": "Em indústrias de manufatura e energia, análise fatorial reduz dados de sensores IoT para identificar modos de falha em equipamentos, otimizando manutenção preditiva, reduzindo downtime em até 30% (ex: GE Predictive Maintenance)."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.5",
                    "name": "Cargas Fatoriais e Rotação",
                    "description": "Cálculo de cargas e aplicação de rotações (ex: Varimax) para melhorar interpretabilidade.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.5.1",
                        "name": "Cargas Fatoriais",
                        "description": "As cargas fatoriais são coeficientes que representam a correlação entre as variáveis originais observáveis e os fatores latentes identificados na análise fatorial. Elas permitem mapear como cada variável contribui para a definição de cada fator, facilitando a interpretação no contexto de econometria aplicada à engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.5.1.1",
                            "name": "Calcular cargas fatoriais",
                            "description": "Executar o cálculo das cargas fatoriais a partir da decomposição em autovalores e autovetores da matriz de correlação, utilizando fórmulas como Λ = V * √Λ (onde V são autovetores e Λ autovalores) ou funções em software como factanal() no R, considerando o número de fatores retidos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar a matriz de correlação",
                                  "subSteps": [
                                    "Colete os dados multivariados e verifique por valores ausentes ou outliers.",
                                    "Padronize as variáveis (z-score) para garantir que a matriz de correlação seja apropriada.",
                                    "Calcule a matriz de correlação R usando fórmula ou software.",
                                    "Inspecione a matriz para confirmar simetria e valores entre -1 e 1.",
                                    "Salve a matriz em formato utilizável (ex: CSV ou objeto em R)."
                                  ],
                                  "verification": "A matriz de correlação deve ser simétrica com diagonal igual a 1 e determinante positivo.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dataset com pelo menos 4 variáveis numéricas",
                                    "Software: R (cor() function) ou Python (pandas.corr())",
                                    "Calculadora matricial opcional"
                                  ],
                                  "tips": "Sempre use correlação de Pearson para dados contínuos; verifique multicolinearidade com valores >0.9.",
                                  "learningObjective": "Compreender o papel da matriz de correlação como base para análise fatorial.",
                                  "commonMistakes": [
                                    "Usar covariância em vez de correlação",
                                    "Ignorar padronização de variáveis",
                                    "Não tratar missing values"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar decomposição em autovalores e autovetores",
                                  "subSteps": [
                                    "Aplique eigen decomposição na matriz R: R = V Λ V^T, onde V são autovetores e Λ autovalores.",
                                    "Ordene autovalores em ordem decrescente.",
                                    "Use funções como eigen() no R ou np.linalg.eig() no Python.",
                                    "Verifique que V é ortogonal (V^T V = I).",
                                    "Extraia os autovalores e autovetores retidos."
                                  ],
                                  "verification": "Soma dos autovalores deve igualar o traço da matriz R; V deve satisfazer ortogonalidade.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Matriz de correlação do Step 1",
                                    "R: eigen() ou prcomp()",
                                    "Python: numpy.linalg.eig()"
                                  ],
                                  "tips": "Autovalores representam variância explicada; foque nos maiores para fatores principais.",
                                  "learningObjective": "Executar e interpretar decomposição espectral para extração de fatores.",
                                  "commonMistakes": [
                                    "Confundir autovalores com variância total",
                                    "Não ordenar autovalores",
                                    "Erro em transposição de V"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Determinar o número de fatores a reter",
                                  "subSteps": [
                                    "Aplique critérios como Kaiser (autovalores >1), scree plot ou parallel analysis.",
                                    "Plote scree plot: autovalores vs. número de fatores.",
                                    "Calcule variância explicada cumulativa (deve cobrir >60-70%).",
                                    "Decida o k (número de fatores) baseado nos critérios.",
                                    "Documente a justificativa para k escolhido."
                                  ],
                                  "verification": "Scree plot mostra 'cotovelo' claro; variância explicada é reportada corretamente.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Autovalores do Step 2",
                                    "R: plot() para scree ou nFactors() do pacote nFactors",
                                    "Gráficos em Python: matplotlib"
                                  ],
                                  "tips": "Combine múltiplos critérios para robustez; evite reter fatores com autovalor <0.7 em amostras pequenas.",
                                  "learningObjective": "Selecionar apropriadamente o número de fatores para evitar over/underfitting.",
                                  "commonMistakes": [
                                    "Retendo todos autovalores >0",
                                    "Ignorando tamanho da amostra",
                                    "Scree plot mal interpretado"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular as cargas fatoriais",
                                  "subSteps": [
                                    "Selecione os k primeiros autovetores V_k e autovalores Λ_k.",
                                    "Calcule cargas Λ = V_k * sqrt(Λ_k) (fórmula padrão para fatores principais).",
                                    "Use factanal() no R com método 'pa' ou 'ml' para automação.",
                                    "Arredonde cargas para 3 casas decimais e interprete magnitudes (>0.4 forte).",
                                    "Formate em tabela: variáveis x fatores."
                                  ],
                                  "verification": "Cargas devem satisfazer comunalidade h^2 = soma(Λ^2) <1 por variável; matriz Λ Λ^T ≈ R_k.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "V_k e Λ_k dos steps anteriores",
                                    "R: factanal(correlation=R, factors=k)",
                                    "Excel ou LaTeX para tabela"
                                  ],
                                  "tips": "Para reprodutibilidade, fixe seed em software; valide manualmente com fórmula para pequenos k.",
                                  "learningObjective": "Aplicar fórmula exata e software para obter cargas fatoriais precisas.",
                                  "commonMistakes": [
                                    "Usar Λ diretamente sem sqrt",
                                    "Incluir todos fatores em vez de k",
                                    "Erro no sinal dos autovetores"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e interpretar as cargas fatoriais",
                                  "subSteps": [
                                    "Calcule comunalidades e variância explicada por fator.",
                                    "Verifique reprodutibilidade com simulação ou bootstrap.",
                                    "Interprete: cargas altas agrupam variáveis em fatores.",
                                    "Compare com matriz R original (aproximação deve ser boa).",
                                    "Gere relatório com tabela de cargas e scree plot."
                                  ],
                                  "verification": "Comunalidades médias >0.5; erro de aproximação <10% da variância total.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Cargas do Step 4",
                                    "R: loadings() e print(factanal)",
                                    "Ferramentas de plot"
                                  ],
                                  "tips": "Cargas >|0.7| são substantivas; supressão de cargas pequenas (<0.3) melhora interpretabilidade.",
                                  "learningObjective": "Avaliar qualidade das cargas e extrair insights multivariados.",
                                  "commonMistakes": [
                                    "Interpretar cargas baixas como significativas",
                                    "Não calcular comunalidades",
                                    "Ignorar sinais das cargas"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere um dataset com 4 variáveis psicológicas (Ansiedade, Depressão, Bem-estar, Autoestima; n=200). Matriz R exemplo: [[1,.7,.5,-.6],[.7,1,.4,-.5],[.5,.4,1,-.7],[-.6,-.5,-.7,1]]. Eigen: λ=[2.8,1.2,0.9,0.1], retém k=2. Cargas: Fator1 (Ansiedade/Depressão: .85,.82), Fator2 (Bem-estar/Autoestima: .78,.75). Use R: factanal(R,2).",
                              "finalVerifications": [
                                "Calcular cargas corretamente para matriz 4x4 dada, com erro <0.01.",
                                "Explicar fórmula Λ = V √Λ e derivar para k=2.",
                                "Produzir scree plot e justificar k retido.",
                                "Interpretar cargas em contexto de dataset exemplo.",
                                "Validar comunalidades >0.4 em média.",
                                "Reproduzir via factanal() no R com output idêntico ao manual."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica das cargas e autovalores (100% match).",
                                "Correta seleção de k com justificativa baseada em critérios múltiplos.",
                                "Qualidade da interpretação (cargas agrupadas logicamente).",
                                "Uso correto de software com código comentado.",
                                "Relatório completo com tabelas, plots e validações.",
                                "Compreensão conceitual demonstrada em explicações."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Decomposição espectral e propriedades de matrizes.",
                                "Estatística: Análise de variância e testes de adequação fatorial (KMO).",
                                "Programação: Implementação em R/Python para automação.",
                                "Ciência de Dados: Redução de dimensionalidade em ML (PCA vs. FA).",
                                "Psicometria: Aplicação em testes psicológicos e validação de escalas."
                              ],
                              "realWorldApplication": "Em pesquisa de mercado, calcular cargas fatoriais identifica fatores latentes em surveys de satisfação do cliente (ex: agrupar 'preço' e 'qualidade' em fator 'valor'), permitindo segmentação e redução de variáveis para modelos preditivos em empresas como Nielsen ou Google Analytics."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.1.2",
                            "name": "Interpretar cargas fatoriais",
                            "description": "Analisar os valores das cargas para identificar padrões de carga alta (ex.: >0.5) em fatores específicos, associando variáveis econômicas ou de engenharia (como indicadores de produção ou sensores) a fatores interpretáveis como 'eficiência operacional' ou 'custo variável'.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar e compreender a matriz de cargas fatoriais",
                                  "subSteps": [
                                    "Examine a estrutura da matriz: linhas representam variáveis, colunas representam fatores.",
                                    "Identifique os valores de carga para cada variável em cada fator.",
                                    "Note os sinais das cargas (positivas ou negativas) e sua magnitude.",
                                    "Compare com o threshold comum de significância (ex.: |carga| > 0.5 para alta, 0.3-0.5 para moderada).",
                                    "Registre observações iniciais em um caderno ou planilha."
                                  ],
                                  "verification": "Confirme que pode descrever verbalmente ou por escrito a estrutura da matriz e thresholds usados.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Matriz de cargas fatoriais (ex.: saída de R ou Python como data frame)",
                                    "Planilha ou caderno para anotações"
                                  ],
                                  "tips": "Sempre use valores absolutos para magnitude, ignorando sinal inicialmente para agrupamento.",
                                  "learningObjective": "Compreender a representação matricial das cargas e critérios de significância.",
                                  "commonMistakes": [
                                    "Confundir linhas com colunas",
                                    "Ignorar sinais das cargas",
                                    "Usar threshold inadequado sem contexto"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar padrões de cargas altas",
                                  "subSteps": [
                                    "Selecione variáveis com |carga| > 0.5 em um fator específico.",
                                    "Destaque ou extraia subconjuntos de variáveis por fator.",
                                    "Agrupe variáveis com cargas altas no mesmo fator (ex.: Fator 1: variáveis A, B, C).",
                                    "Verifique cargas cruzadas baixas (<0.3) para confirmar especificidade.",
                                    "Crie uma tabela resumida de cargas principais por fator."
                                  ],
                                  "verification": "Produza uma tabela ou lista mostrando pelo menos 3 variáveis com cargas altas por fator principal.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Software de análise (R: factanal(), Python: factor_analyzer)",
                                    "Ferramenta de visualização como heatmap (ggplot ou seaborn)"
                                  ],
                                  "tips": "Use heatmaps para visualização intuitiva de padrões.",
                                  "learningObjective": "Detectar e isolar cargas significativas para revelar estrutura latente.",
                                  "commonMistakes": [
                                    "Incluir cargas baixas no agrupamento",
                                    "Ignorar cargas negativas como não significativas",
                                    "Não verificar especificidade (cargas altas em múltiplos fatores)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Associar variáveis a fatores interpretáveis",
                                  "subSteps": [
                                    "Liste as variáveis agrupadas por fator e descreva seu conteúdo (ex.: 'indicador de produção', 'sensor de temperatura').",
                                    "Busque temas comuns: econômicas (custo, receita) ou engenharia (eficiência, manutenção).",
                                    "Considere sinais: cargas positivas juntas indicam relação direta.",
                                    "Rascunhe nomes provisórios para fatores baseados no tema (ex.: 'Eficiência Operacional').",
                                    "Compare com contexto do domínio (ex.: produção industrial)."
                                  ],
                                  "verification": "Escreva associações claras para cada fator com 2-3 variáveis exemplares.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Descrições das variáveis originais",
                                    "Conhecimento de domínio (ex.: glossário econômico/engenharia)"
                                  ],
                                  "tips": "Pense em 'o que essas variáveis medem em comum?' para nomes intuitivos.",
                                  "learningObjective": "Mapear cargas estatísticas para conceitos de domínio reais.",
                                  "commonMistakes": [
                                    "Nomear fatores vagamente (ex.: 'Fator 1')",
                                    "Ignorar contexto disciplinar",
                                    "Forçar associações sem suporte de cargas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e refinar a interpretação dos fatores",
                                  "subSteps": [
                                    "Calcule variância explicada por fator para priorizar interpretações.",
                                    "Verifique consistência: cargas baixas em fatores não-associados.",
                                    "Teste nomes alternativos e selecione o mais parcimonioso.",
                                    "Documente a interpretação final em parágrafos curtos.",
                                    "Discuta potenciais vieses (ex.: multicolinearidade prévia)."
                                  ],
                                  "verification": "Produza um relatório de 1 página com nomes de fatores, variáveis associadas e justificativa.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Resultados de variância (eigenvalues)",
                                    "Template de relatório"
                                  ],
                                  "tips": "Use nomes descritivos mas concisos; valide com literatura similar.",
                                  "learningObjective": "Garantir robustez e comunicabilidade da interpretação.",
                                  "commonMistakes": [
                                    "Sobreinterpretar fatores com baixa variância",
                                    "Não considerar rotações prévias",
                                    "Fazer interpretações subjetivas sem dados"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de fábrica: variáveis como 'Produção_diária' (carga 0.78 no Fator 1), 'Eficiência_máquina' (0.72), 'Horas_trabalhadas' (0.65) → Fator 1: 'Eficiência Operacional'. 'Custo_matéria-prima' (0.81 no Fator 2), 'Gastos_energia' (0.69) → Fator 2: 'Custo Variável'. Sensores como 'Temperatura' (0.55 no Fator 1) reforçam eficiência.",
                              "finalVerifications": [
                                "Pode explicar verbalmente a interpretação de pelo menos 2 fatores de um exemplo dado.",
                                "Identifica corretamente todas cargas >0.5 em uma matriz fornecida.",
                                "Associa variáveis a fatores com justificativa baseada em domínio.",
                                "Nomeia fatores de forma interpretável e consistente.",
                                "Verifica especificidade (cargas cruzadas baixas).",
                                "Discute limitações da interpretação (ex.: threshold escolhido)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de cargas altas (>90% corretas).",
                                "Qualidade das associações variáveis-fatores (temáticas coerentes).",
                                "Criatividade e relevância nos nomes de fatores (alinhados ao domínio).",
                                "Uso correto de thresholds e verificações de especificidade.",
                                "Clareza e completude do relatório final.",
                                "Integração de variância explicada na priorização."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Integra com PCA e rotação de fatores.",
                                "Economia: Interpretação em análise de indicadores macroeconômicos.",
                                "Engenharia: Aplicação em monitoramento de sensores IoT.",
                                "Gestão: Redução dimensional para KPIs empresariais.",
                                "Ciência de Dados: Pré-processamento para ML supervisionado."
                              ],
                              "realWorldApplication": "Em empresas de manufatura, interpretar cargas fatoriais reduz dezenas de sensores/produção a 3-5 fatores acionáveis, como 'Eficiência' para otimizar linhas de produção ou 'Custo Variável' para controle orçamentário, economizando milhões em análises preditivas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.1.3",
                            "name": "Avaliar significância das cargas",
                            "description": "Verificar comunalidades (h² = soma das cargas ao quadrado por variável) para avaliar a proporção de variância explicada por variável, e aplicar critérios como cargas >0.4 para retenção, descartando variáveis com baixas contribuições em aplicações de análise de dados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Calcular as comunalidades (h²) para cada variável",
                                  "subSteps": [
                                    "Extraia a matriz de cargas fatoriais da saída do software de análise fatorial (ex: R ou Python).",
                                    "Para cada variável, some os quadrados das cargas em todos os fatores: h² = Σ (carga_{i,j}²) para j=1 até número de fatores.",
                                    "Calcule h² para todas as variáveis e registre os valores em uma tabela.",
                                    "Interprete h² como a proporção de variância explicada pelos fatores para aquela variável.",
                                    "Identifique variáveis com h² < 0.4 como potencialmente problemáticas."
                                  ],
                                  "verification": "Verifique se todos os h² somam corretamente aos quadrados das cargas e se os valores estão entre 0 e 1.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Matriz de cargas fatoriais, calculadora ou software (R: factanal(), Python: factor_analyzer), planilha Excel.",
                                  "tips": "Use funções prontas em software para automação, mas entenda a fórmula manualmente para validação.",
                                  "learningObjective": "Compreender e computar a comunalidade como medida de variância explicada por variável.",
                                  "commonMistakes": "Esquecer de elevar as cargas ao quadrado ou somar sobre todos os fatores."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Examinar as cargas fatoriais individuais por variável e fator",
                                  "subSteps": [
                                    "Liste as cargas absolutas para cada variável em cada fator, destacando as maiores.",
                                    "Classifique cargas como 'salientes' (>0.4 ou >0.5 dependendo do critério escolhido).",
                                    "Verifique cargas cruzadas (cross-loadings) onde uma variável carrega alto em múltiplos fatores.",
                                    "Calcule a carga máxima por variável e compare com thresholds.",
                                    "Anote padrões, como variáveis com cargas baixas em todos os fatores."
                                  ],
                                  "verification": "Confirme que cargas salientes são identificadas corretamente e cross-loadings destacadas.",
                                  "estimatedTime": "15 minutos",
                                  "materials": "Matriz de cargas, critérios de threshold (ex: tabela de referência Kaiser ou Hair et al.).",
                                  "tips": "Ordene a matriz por cargas decrescentes para visualização fácil.",
                                  "learningObjective": "Identificar cargas significativas e detectar problemas como cross-loadings.",
                                  "commonMistakes": "Ignorar o sinal das cargas (use valores absolutos para magnitude)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar critérios de significância para retenção de variáveis",
                                  "subSteps": [
                                    "Defina thresholds: h² > 0.4 e pelo menos uma carga >0.4 por variável.",
                                    "Marque variáveis para retenção (atendem critérios) ou descarte (h² baixa ou sem cargas salientes).",
                                    "Considere contexto: em engenharia, priorize variáveis com relevância prática.",
                                    "Justifique decisões com evidências numéricas (ex: h²=0.25 é baixa).",
                                    "Atualize a lista de variáveis selecionadas."
                                  ],
                                  "verification": "Crie uma tabela de decisão mostrando variável, h², carga max, status (reter/descartar).",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Tabela de critérios (ex: guidelines de análise fatorial), software para plotagem de heatmap.",
                                  "tips": "Use heatmaps para visualização intuitiva de cargas.",
                                  "learningObjective": "Aplicar regras quantitativas e qualitativas para seleção de variáveis.",
                                  "commonMistakes": "Aplicar thresholds rígidos sem contexto aplicado, descartando variáveis úteis."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e recomendar ações no modelo",
                                  "subSteps": [
                                    "Resuma proporção média de variância explicada (média h²).",
                                    "Discuta implicações: variáveis descartadas indicam ruído ou fatores inadequados.",
                                    "Sugira iterações: remover variáveis e refazer análise fatorial.",
                                    "Documente relatório com tabelas e justificativas.",
                                    "Valide com métricas globais como variância total explicada."
                                  ],
                                  "verification": "Relatório final inclui resumo, tabela de decisões e recomendações claras.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Relatório template, software para reanálise (R/Python).",
                                  "tips": "Sempre relacione decisões com objetivos da análise em engenharia.",
                                  "learningObjective": "Integrar avaliação de cargas em decisões de modelagem multivariada.",
                                  "commonMistakes": "Não considerar impacto no modelo global após remoções."
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia de qualidade do ar (variáveis: PM2.5, NO2, temperatura, umidade, vento), após extração de 3 fatores, calcule h² para PM2.5 = 0.65 (cargas: 0.7 no Fator1, 0.3 no F2), retenha; umidade h²=0.25 (cargas <0.3), descarte por baixa contribuição.",
                              "finalVerifications": [
                                "Todas comunalidades (h²) calculadas corretamente entre 0-1.",
                                "Variáveis com h² <0.4 ou sem cargas >0.4 identificadas para descarte.",
                                "Tabela de decisões completa com justificativas numéricas.",
                                "Sem cross-loadings não reportados.",
                                "Recomendações para reanálise se >20% variáveis descartadas.",
                                "Relatório relaciona resultados a variância total explicada."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de h² (erro <0.01).",
                                "Aplicação correta de thresholds (>0.4).",
                                "Detecção e discussão de cross-loadings.",
                                "Justificativas contextualizadas para engenharia.",
                                "Relatório claro e completo com tabelas/visuais.",
                                "Interpretação coerente com objetivos da análise."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Integra com testes de adequação fatorial (KMO, Bartlett).",
                                "Programação: Implementação em R (psych::fa) ou Python (factor_analyzer).",
                                "Engenharia: Otimização de sensores em monitoramento ambiental.",
                                "Machine Learning: Seleção de features em PCA/redução dimensional."
                              ],
                              "realWorldApplication": "Em engenharia de processos, avaliar cargas fatoriais otimiza modelos preditivos removendo variáveis com baixa variância explicada (ex: descartar sensores redundantes em fábricas, reduzindo custos de manutenção em 15-20%)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.5.2",
                        "name": "Rotação de Fatores",
                        "description": "A rotação de fatores é um procedimento para reorientar os eixos dos fatores latentes, melhorando a interpretabilidade ao maximizar cargas altas em poucos fatores e minimizando as demais, sem alterar a variância total explicada, com exemplos como Varimax em contextos econométricos.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.5.2.1",
                            "name": "Compreender a necessidade de rotação",
                            "description": "Explicar o problema da solução inicial não única e degenerada na análise fatorial, onde múltiplas rotações preservam autovalores, e como a rotação equilibra variância explicada versus simplicidade interpretativa em dados multivariados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Extração Inicial de Fatores na Análise Fatorial",
                                  "subSteps": [
                                    "Realize uma análise fatorial em um dataset multivariado simples (ex: medidas de componentes mecânicos).",
                                    "Extraia os autovalores e autovetores usando decomposição em autovalores.",
                                    "Calcule as cargas fatoriais iniciais (loadings) multiplicando autovetores por raiz quadrada dos autovalores.",
                                    "Plote as cargas fatoriais em um mapa de cargas para visualizar a estrutura inicial.",
                                    "Registre a variância total explicada pelos fatores."
                                  ],
                                  "verification": "Confirme que as cargas foram calculadas corretamente comparando com output de software (ex: fatoranal() no R ou FactorAnalysis no Python).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dataset CSV com 5-10 variáveis (ex: dimensões de peças de engenharia), Python (scikit-learn) ou R, Jupyter Notebook.",
                                  "tips": "Use datasets com correlações moderadas para evitar casos triviais.",
                                  "learningObjective": "Compreender como as cargas fatoriais iniciais são derivadas da decomposição espectral.",
                                  "commonMistakes": "Confundir autovalores com variância explicada sem normalizar; ignorar sinal dos autovetores."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Demonstrar Não-Unicidade e Degenerescência das Cargas Iniciais",
                                  "subSteps": [
                                    "Aplique uma matriz de rotação ortogonal arbitrária (ex: rotação de 45 graus) às cargas iniciais.",
                                    "Verifique que os autovalores permanecem inalterados após rotação.",
                                    "Calcule a variância explicada comum e mostre que ela é preservada.",
                                    "Compare visualmente as cargas rotacionadas vs. não-rotacionadas em gráficos.",
                                    "Explique matematicamente: Q^T * Lambda * Q = Lambda para Q ortogonal."
                                  ],
                                  "verification": "Autovalores antes e depois da rotação devem ser idênticos (tolerância 1e-10).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Mesmo dataset e software do Step 1, matriz de rotação numpy ou manual.",
                                  "tips": "Comece com uma rotação simples como matriz [[cosθ, -sinθ], [sinθ, cosθ]] para 2 fatores.",
                                  "learningObjective": "Identificar que rotações preservam propriedades matemáticas mas alteram interpretabilidade.",
                                  "commonMistakes": "Esquecer de verificar ortogonalidade da matriz Q (Q^T Q = I); assumir unicidade das cargas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Introduzir Métodos de Rotação e Critérios de Simplicidade",
                                  "subSteps": [
                                    "Implemente rotação varimax (ortogonal) para maximizar variância das cargas ao quadrado.",
                                    "Teste rotação obliqua (ex: promax) permitindo correlação entre fatores.",
                                    "Avalie simplicidade usando métricas como carga simples (hi-carregadas em um fator, zeros em outros).",
                                    "Compare variância explicada vs. interpretabilidade em tabelas de cargas.",
                                    "Escolha rotação baseada em contexto: varimax para fatores independentes."
                                  ],
                                  "verification": "Cargas rotacionadas devem ter pelo menos 70% das entradas com |loading| < 0.3 (simplicidade).",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Software com funções de rotação (fa() no R com rotate='varimax'; FactorAnalysis com rotation em Python).",
                                  "tips": "Use critério de Kaiser para decidir número de fatores antes da rotação.",
                                  "learningObjective": "Dominar rotações como ferramentas para equilibrar variância e interpretabilidade.",
                                  "commonMistakes": "Usar rotação obliqua sem evidência de correlação entre fatores; over-rotacionar levando a Heywood cases."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar Trade-off entre Variância e Interpretabilidade",
                                  "subSteps": [
                                    "Calcule variância explicada para cargas não-rotacionadas, varimax e obliqua.",
                                    "Interprete fatores em contexto de engenharia (ex: fator 1 = rigidez, fator 2 = durabilidade).",
                                    "Discuta quando priorizar variância (modelos preditivos) vs. simplicidade (relatórios).",
                                    "Gere relatório comparativo com tabelas e gráficos.",
                                    "Teste robustez com bootstrap de cargas."
                                  ],
                                  "verification": "Explique em 1 parágrafo por que rotação foi necessária no seu exemplo.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Gráficos matplotlib/seaborn, tabelas pandas.",
                                  "tips": "Documente decisões em um markdown notebook para clareza.",
                                  "learningObjective": "Aplicar julgamento profissional no trade-off de rotação em dados reais.",
                                  "commonMistakes": "Ignorar multicolinearidade inicial; superinterpretar cargas pequenas (<0.4)."
                                }
                              ],
                              "practicalExample": "Em um dataset de testes de fadiga de materiais de engenharia (10 variáveis como tensão, deformação, temperatura), as cargas iniciais mostram fatores 'espalhados'. Após varimax, Fator 1 carrega alto em tensão/deformação (interpretação: resistência mecânica), Fator 2 em temperatura/umidade (interpretação: condições ambientais), preservando 65% da variância mas ganhando interpretabilidade clara para otimização de design.",
                              "finalVerifications": [
                                "Explicar verbalmente por que cargas não são únicas.",
                                "Demonstrar rotação manual preservando autovalores.",
                                "Comparar cargas antes/depois em um dataset próprio.",
                                "Identificar trade-off em um exemplo dado.",
                                "Propor rotação adequada para um cenário de engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática na explicação de preservação de autovalores (90% correto).",
                                "Capacidade de gerar cargas rotacionadas válidas em software.",
                                "Clareza na distinção entre variância explicada e interpretabilidade.",
                                "Uso correto de métricas de simplicidade (ex: variância das cargas quadradas).",
                                "Aplicação contextualizada a dados multivariados de engenharia.",
                                "Identificação de erros comuns em rotações."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Ligação com PCA e decomposição espectral.",
                                "Machine Learning: Redução de dimensionalidade e feature extraction.",
                                "Engenharia Mecânica: Análise de falhas multivariadas em materiais.",
                                "Ciência de Dados: Pré-processamento para modelagem preditiva."
                              ],
                              "realWorldApplication": "Na indústria aeroespacial, rotação de fatores em dados de testes de vibração multivariados permite identificar padrões interpretáveis de falha (ex: fadiga vs. desalinhamento), otimizando manutenção preditiva e reduzindo custos em 20-30% ao equilibrar precisão estatística com insights acionáveis para engenheiros."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.2.2",
                            "name": "Aplicar rotação Varimax",
                            "description": "Implementar a rotação ortogonal Varimax, que maximiza a variância das cargas ao quadrado por coluna na matriz de cargas, utilizando funções como varimax() no R ou comandos equivalentes, e interpretar a matriz rotacionada para fatores mais puros em aplicações econométricas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar a matriz de cargas fatoriais",
                                  "subSteps": [
                                    "Carregue um dataset multivariado relevante, como indicadores econômicos (ex: PIB, inflação, desemprego) usando read.csv() no R.",
                                    "Execute Análise Fatorial ou PCA para obter a matriz de cargas iniciais não rotacionadas com fa() ou principal() do pacote psych.",
                                    "Verifique a estrutura da matriz de cargas: dimensões, valores absolutos e variância explicada total.",
                                    "Normalize as cargas se necessário (T ou Kaiser normalization) para preparar para rotação.",
                                    "Salve a matriz inicial em um objeto para comparação posterior."
                                  ],
                                  "verification": "Confirme que a matriz de cargas tem linhas (variáveis) e colunas (fatores) com valores entre -1 e 1, e imprima summary() sem erros.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Pacote psych: install.packages('psych')",
                                    "Dataset CSV com pelo menos 5 variáveis e 100 observações"
                                  ],
                                  "tips": "Use set.seed(123) para reprodutibilidade; visualize com plot() para inspeção inicial.",
                                  "learningObjective": "Compreender e preparar dados para rotação, garantindo qualidade da matriz de cargas.",
                                  "commonMistakes": [
                                    "Usar dados com multicolinearidade extrema sem pré-processamento",
                                    "Esquecer de centralizar/escalar variáveis antes da FA"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar a rotação Varimax no R",
                                  "subSteps": [
                                    "Carregue o pacote psych: library(psych).",
                                    "Aplique varimax() à matriz de cargas: rotated_loadings <- varimax(loadings_matrix, normalize = TRUE).",
                                    "Especifique parâmetros: normalize = TRUE para Kaiser, ou FALSE para raw; verifique ortogonalidade com rotated_loadings$orth.",
                                    "Extraia a matriz rotacionada: print(rotated_loadings$loadings).",
                                    "Calcule a variância das cargas ao quadrado por fator para confirmar maximização."
                                  ],
                                  "verification": "Execute rownames(rotated_loadings$loadings) e confirme que as colunas mostram variância maior que na matriz original.",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "R com psych",
                                    "Matriz de cargas do Step 1 salva como objeto"
                                  ],
                                  "tips": "Use ?varimax para opções; teste com matriz pequena primeiro para depuração.",
                                  "learningObjective": "Executar corretamente a função varimax() e entender seus parâmetros.",
                                  "commonMistakes": [
                                    "Passar matriz transposta",
                                    "Ignorar normalize, levando a rotações instáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar a matriz rotacionada",
                                  "subSteps": [
                                    "Identifique loadings altos (>0.4 ou 0.7) por coluna: fatores devem ter cargas dominantes em poucas variáveis.",
                                    "Nomeie os fatores com base em padrões: ex: Fator 1 = 'Crescimento Econômico' se PIB e emprego altos.",
                                    "Calcule communalities pós-rotação: sum(rotated_loadings$loadings^2) por linha.",
                                    "Compare variância explicada: sum of squared loadings por fator deve ser maximizada.",
                                    "Plote screeplot() ou fa.diagram() para visualização."
                                  ],
                                  "verification": "Escreva um parágrafo resumindo 2-3 fatores interpretáveis com loadings principais listados.",
                                  "estimatedTime": "25-35 minutos",
                                  "materials": [
                                    "Funções plot() e fa.diagram() do psych"
                                  ],
                                  "tips": "Use round(rotated_loadings$loadings, 3) para clareza; procure 'fatores puros' com <3 variáveis por fator.",
                                  "learningObjective": "Interpretar rotações para obter fatores simples e economicamente significativos.",
                                  "commonMistakes": [
                                    "Interpretar loadings baixos como significativos",
                                    "Não considerar sinais negativos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e aplicar em contexto econométrico",
                                  "subSteps": [
                                    "Compare pré e pós-rotação: loadings mais concentrados? Variância por fator maior?",
                                    "Teste robustez: rode com diferentes seeds ou subamostras.",
                                    "Integre em modelo econométrico: use scores fatoriais com factor.scores().",
                                    "Documente mudanças: tabela side-by-side das matrizes.",
                                    "Conclua com implicações para análise de risco ou previsão."
                                  ],
                                  "verification": "Gere relatório com tabelas comparativas mostrando melhoria em pureza de fatores.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Pacote knitr para tabelas",
                                    "Dados originais"
                                  ],
                                  "tips": "Salve output com write.csv(); use ggplot2 para gráficos comparativos.",
                                  "learningObjective": "Validar rotação e aplicá-la em cenários reais de econometria.",
                                  "commonMistakes": [
                                    "Não comparar com baseline",
                                    "Sobreinterpretar fatores sem validação cruzada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de indicadores econômicos brasileiros (PIB, inflação, taxa de juros, desemprego, exportações), execute FA para 4 fatores. Após Varimax, Fator 1 mostra loadings altos em PIB e exportações (0.85, 0.78), interpretado como 'Crescimento Externo', facilitando modelos de previsão mais simples.",
                              "finalVerifications": [
                                "Matriz rotacionada tem pelo menos 70% das cargas concentradas (>0.5) em uma coluna por variável.",
                                "Variância das cargas ao quadrado é maximizada por fator comparado à matriz original.",
                                "Fatores nomeados logicamente com interpretações econométricas coerentes.",
                                "Communalities médias aumentaram ou permaneceram estáveis.",
                                "Códigos R executam sem erros e são reprodutíveis.",
                                "Gráficos mostram fatores mais 'puros' visualmente."
                              ],
                              "assessmentCriteria": [
                                "Implementação correta de varimax() com parâmetros apropriados (100%).",
                                "Interpretação precisa de pelo menos 3 fatores com loadings e nomes (90%).",
                                "Comparação quantitativa pré/pós-rotação com métricas (85%).",
                                "Código limpo, comentado e documentado (80%).",
                                "Aplicação contextual em econometria com insights válidos (90%).",
                                "Tratamento de erros comuns e validação robusta (85%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de significância de loadings.",
                                "Programação em R: Manipulação de matrizes e pacotes especializados.",
                                "Econometria: Modelos de fatores em séries temporais.",
                                "Visualização de Dados: Plots de loadings e biplots.",
                                "Machine Learning: Redução de dimensionalidade comparável a PCA rotacionada."
                              ],
                              "realWorldApplication": "Em instituições financeiras, como bancos centrais, a rotação Varimax é usada para purificar fatores em análises de risco sistêmico, permitindo scores fatoriais mais interpretáveis em modelos de stress testing ou previsão de recessões econômicas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.5.2.3",
                            "name": "Comparar soluções rotacionadas",
                            "description": "Contrastar matrizes de cargas pré e pós-rotação, calculando métricas como a simplificação de Kaiser (proporção de cargas >0.5), e discutir quando optar por rotações oblíquas (ex.: Promax) se correlações entre fatores forem esperadas em dados de séries temporais ou controles.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar matrizes de cargas pré e pós-rotação",
                                  "subSteps": [
                                    "Carregue o dataset multivariado (ex.: dados de séries temporais com 10 variáveis).",
                                    "Execute análise fatorial exploratória (EFA) para obter matriz de cargas não rotacionada.",
                                    "Aplique rotação ortogonal (ex.: Varimax) para gerar matriz pós-rotação.",
                                    "Salve ambas as matrizes em formato tabular para comparação.",
                                    "Visualize as matrizes usando heatmaps para inspeção inicial."
                                  ],
                                  "verification": "Verifique se as matrizes têm dimensões idênticas e somas de quadrados iguais (propriedade de rotação).",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software R ou Python com pacotes psych/factor_analyzer",
                                    "Dataset de exemplo (ex.: dados de séries temporais do UCI ML Repository)"
                                  ],
                                  "tips": "Use funções prontas como fa() no psych para R ou FactorAnalyzer no Python para agilizar.",
                                  "learningObjective": "Compreender a estrutura inicial das matrizes de cargas e o impacto imediato da rotação.",
                                  "commonMistakes": [
                                    "Confundir cargas com comunalidades",
                                    "Não normalizar o dataset previamente",
                                    "Ignorar o número de fatores pré-definido"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular métricas de simplificação como critério de Kaiser",
                                  "subSteps": [
                                    "Defina o limiar de simplificação (tipicamente |carga| > 0.5).",
                                    "Conte o número de cargas acima do limiar na matriz pré-rotação.",
                                    "Repita a contagem na matriz pós-rotação.",
                                    "Calcule a proporção de Kaiser: (cargas salientes pós / total cargas) vs pré.",
                                    "Compare as proporções para quantificar a simplificação."
                                  ],
                                  "verification": "A proporção pós-rotação deve ser significativamente maior (ex.: >20% de aumento).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Planilha Excel ou script Python/R para contagem automatizada",
                                    "Matrizes geradas no Step 1"
                                  ],
                                  "tips": "Automatize com loop for ou apply() para eficiência em matrizes grandes.",
                                  "learningObjective": "Dominar o cálculo quantitativo da simplificação de Kaiser para avaliar rotações.",
                                  "commonMistakes": [
                                    "Usar limiar errado (ex.: 0.4 em vez de 0.5)",
                                    "Contar apenas cargas positivas",
                                    "Esquecer de dividir pelo total de elementos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Contrastar matrizes pré e pós-rotação qualitativamente",
                                  "subSteps": [
                                    "Identifique padrões de cargas difusas pré-rotação (múltiplas >0.3 por variável).",
                                    "Observe cargas salientes pós-rotação (uma dominante por variável/fator).",
                                    "Compare interpretabilidade: nomeie fatores pré vs pós.",
                                    "Plote side-by-side heatmaps ou barplots das cargas principais.",
                                    "Documente diferenças em um relatório tabular."
                                  ],
                                  "verification": "Fatores pós-rotação devem ter interpretações mais claras e únicas.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Bibliotecas de visualização: ggplot2 (R) ou seaborn (Python)",
                                    "Matrizes do Step 1"
                                  ],
                                  "tips": "Use cores divergentes em heatmaps para destacar saliências.",
                                  "learningObjective": "Desenvolver habilidade em interpretação visual e qualitativa de rotações.",
                                  "commonMistakes": [
                                    "Interpretar cargas pequenas como significativas",
                                    "Ignorar sinal das cargas",
                                    "Não considerar o contexto dos dados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Discutir rotações oblíquas vs ortogonais para dados correlacionados",
                                  "subSteps": [
                                    "Extraia matriz de correlação entre fatores da solução ortogonal.",
                                    "Se correlações >0.3, aplique rotação oblíqua (ex.: Promax).",
                                    "Compare métricas de Kaiser e interpretabilidade oblíqua vs ortogonal.",
                                    "Discuta cenários: séries temporais (fatores correlacionados por autocorrelação) ou controles (fatores dependentes).",
                                    "Conclua recomendação baseada em dados."
                                  ],
                                  "verification": "Justifique escolha de Promax com evidência de correlações fatoriais.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Pacotes promax() no psych (R) ou fa.rotation() no Python",
                                    "Matrizes anteriores"
                                  ],
                                  "tips": "Sempre teste correlações fatoriais primeiro para evitar ortogonal desnecessária.",
                                  "learningObjective": "Saber quando e por quê optar por rotações oblíquas em contextos reais.",
                                  "commonMistakes": [
                                    "Assumir independência de fatores sem checar correlações",
                                    "Usar Promax sem kappa otimizado",
                                    "Ignorar violações de suposições em séries temporais"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de séries temporais de vendas (variáveis: temperatura, feriados, marketing), execute EFA com 3 fatores. Pré-rotação: cargas difusas. Pós-Varimax: simplificação Kaiser de 35% para 72%. Correlações fatores=0.45 → aplique Promax para fatores 'clima-vendas' correlacionados.",
                              "finalVerifications": [
                                "Calcule corretamente Kaiser para pré/pós-rotação com >70% de simplificação.",
                                "Identifique pelo menos 3 diferenças interpretativas nas matrizes.",
                                "Justifique Promax com correlações fatoriais >0.3 dos dados.",
                                "Gere heatmaps comparativos sem erros de escala.",
                                "Explique aplicação em séries temporais ou controles.",
                                "Compare soluções em relatório de 1 página."
                              ],
                              "assessmentCriteria": [
                                "Precisão no cálculo de métricas Kaiser (erro <5%).",
                                "Qualidade da interpretação qualitativa (clareza de fatores).",
                                "Correta identificação de cenários para rotações oblíquas.",
                                "Visualizações profissionais e legíveis.",
                                "Relatório lógico com evidências quantitativas.",
                                "Consideração de contexto de dados (séries temporais/controles).",
                                "Ausência de erros comuns listados nos steps."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Avançada: Métricas de validação fatorial.",
                                "Programação Computacional: Scripts R/Python para EFA.",
                                "Ciência de Dados: Aplicação em séries temporais (ARIMA + FA).",
                                "Psicometria: Interpretação em questionários e controles experimentais.",
                                "Econometria: Fatores em modelos de previsão econômica."
                              ],
                              "realWorldApplication": "Em pesquisa de mercado, comparar rotações em dados de séries temporais de consumidor para identificar fatores latentes correlacionados (ex.: sazonalidade e promoção), otimizando estratégias de estoque e marketing com fatores mais simples e interpretáveis."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.6.6",
                    "name": "Aplicações em Engenharia",
                    "description": "Uso de PCA e análise fatorial em análise de dados econométricos aplicados à engenharia.",
                    "individualConcepts": [
                      {
                        "id": "10.1.6.6.1",
                        "name": "Análise de Componentes Principais (PCA)",
                        "description": "Método estatístico para redução de dimensionalidade em conjuntos de dados multivariados, aplicado à análise econométrica em engenharia, identificando componentes principais que explicam a variância máxima dos dados.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.6.1.1",
                            "name": "Compreender os princípios da PCA",
                            "description": "Explicar os fundamentos matemáticos da PCA, incluindo decomposição em valores singulares (SVD), variância explicada e escolha do número de componentes, no contexto de dados econométricos de engenharia como séries de sensores industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender os conceitos fundamentais da PCA",
                                  "subSteps": [
                                    "Definir PCA como uma técnica de redução de dimensionalidade que transforma variáveis correlacionadas em componentes principais ortogonais.",
                                    "Explicar a maximização da variância: o primeiro componente captura a maior variância dos dados.",
                                    "Discutir pré-requisitos: centralização e normalização dos dados para evitar viés de escala.",
                                    "Relacionar com dados econométricos de engenharia: redução de dimensionalidade em séries de sensores industriais com multicolinearidade.",
                                    "Visualizar geometricamente em 2D: rotação de eixos para alinhar com variância máxima."
                                  ],
                                  "verification": "Escrever um parágrafo explicando PCA e seus benefícios em dados de sensores, com diagrama simples.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Dataset toy de sensores (ex: UCI Machine Learning Repository)",
                                    "Vídeo introdutório sobre PCA (Khan Academy)"
                                  ],
                                  "tips": "Comece com visualizações 2D para ganhar intuição antes da matemática.",
                                  "learningObjective": "Compreender o propósito da PCA como técnica de redução de dimensionalidade preservando variância.",
                                  "commonMistakes": [
                                    "Esquecer de centralizar os dados antes da aplicação",
                                    "Confundir componentes principais com variáveis originais"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar a matriz de covariância e autovalores",
                                  "subSteps": [
                                    "Calcular a matriz de covariância a partir de dados centralizados: cov(X) = (1/n) X^T X.",
                                    "Explicar autovalores e autovetores: autovetores definem direções dos componentes, autovalores a variância.",
                                    "Ordenar autovalores decrescentemente para priorizar componentes.",
                                    "Implementar em Python com NumPy: np.cov() e np.linalg.eig().",
                                    "Aplicar a um dataset de sensores: identificar correlações entre variáveis como temperatura e vibração."
                                  ],
                                  "verification": "Computar manualmente a matriz de covariância para um dataset 3x3 e listar autovalores ordenados.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com NumPy e Matplotlib",
                                    "Dataset de sensores industriais (ex: NASA Turbofan)",
                                    "Calculadora matricial online"
                                  ],
                                  "tips": "Use heatmaps para visualizar a matriz de covariância e identificar padrões.",
                                  "learningObjective": "Dominar o cálculo e interpretação da matriz de covariância como base da PCA.",
                                  "commonMistakes": [
                                    "Usar correlação em vez de covariância sem normalizar",
                                    "Interpretar autovetores sem normalizá-los"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Compreender a Decomposição em Valores Singulares (SVD)",
                                  "subSteps": [
                                    "Definir SVD: X = U Σ V^T, onde U e V são ortogonais, Σ diagonal com valores singulares.",
                                    "Relacionar SVD com PCA: componentes principais são colunas de V, variâncias são quadrados dos valores singulares.",
                                    "Comparar SVD vs. eigen-decomposição: SVD mais estável numericamente para dados não quadrados.",
                                    "Implementar SVD em Python: np.linalg.svd() e extrair componentes.",
                                    "Aplicar a séries de sensores: decompor matriz de dados temporais para extrair padrões latentes."
                                  ],
                                  "verification": "Executar SVD em um dataset pequeno e verificar que os primeiros componentes maximizam variância.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Python com NumPy/SciPy",
                                    "Documentação SVD NumPy",
                                    "Exemplo de código GitHub sobre PCA via SVD"
                                  ],
                                  "tips": "Lembre-se: SVD é preferível para grandes datasets por eficiência computacional.",
                                  "learningObjective": "Entender SVD como base algébrica robusta para PCA em dados reais.",
                                  "commonMistakes": [
                                    "Confundir U e V na interpretação",
                                    "Ignorar que SVD requer dados centralizados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar variância explicada e escolher número de componentes",
                                  "subSteps": [
                                    "Calcular variância explicada: (autovalor_i / soma_autovalores) * 100%.",
                                    "Criar scree plot: autovalores vs. índice para 'cotovelo'.",
                                    "Usar critérios cumulativos: reter k componentes até 80-95% de variância.",
                                    "Aplicar a dados de sensores industriais: selecionar componentes para monitoramento econométrico.",
                                    "Validar com biplot: projeção de variáveis e observações."
                                  ],
                                  "verification": "Gerar scree plot para dataset de sensores e justificar escolha de 3 componentes.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com Matplotlib/Seaborn",
                                    "Scikit-learn para PCA pipeline",
                                    "Dataset real de sensores IoT"
                                  ],
                                  "tips": "Combine scree plot com variância cumulativa para decisão robusta.",
                                  "learningObjective": "Saber quantificar e selecionar componentes baseados em variância preservada.",
                                  "commonMistakes": [
                                    "Escolher componentes pelo 'cotovelo' subjetivo sem métrica cumulativa",
                                    "Retenção excessiva levando a overfitting"
                                  ]
                                }
                              ],
                              "practicalExample": "Carregue um dataset de sensores industriais (ex: vibração, temperatura, pressão de 100 turbinas). Centralize, aplique SVD via scikit-learn PCA(n_components=3), plote scree plot mostrando 85% variância explicada, e interprete o primeiro componente como 'modo de falha geral'.",
                              "finalVerifications": [
                                "Explicar verbalmente a relação entre SVD e autovalores de covariância.",
                                "Calcular manualmente variância explicada para um toy dataset 2D.",
                                "Implementar PCA via SVD em Python e reproduzir resultados com eigen-decomposição.",
                                "Interpretar scree plot de um dataset real de sensores e propor número de componentes.",
                                "Discutir limitações da PCA em dados não lineares.",
                                "Relacionar componentes extraídos a variáveis econômicas em séries industriais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na explicação matemática de SVD e variância (90% correto).",
                                "Correta implementação e interpretação de código Python (sem erros).",
                                "Justificativa fundamentada para escolha de componentes (baseada em métricas).",
                                "Integração contextual com dados de sensores industriais.",
                                "Clareza em visualizações como scree plot e biplot.",
                                "Identificação de pelo menos 3 erros comuns evitados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência multivariada e testes de multicolinearidade.",
                                "Machine Learning: Pré-processamento para modelos como regressão ou clustering.",
                                "Engenharia Industrial: Análise de séries temporais para manutenção preditiva.",
                                "Econometria: Modelagem de fatores latentes em dados macroeconômicos.",
                                "Visualização de Dados: Criação de biplots e heatmaps."
                              ],
                              "realWorldApplication": "Na engenharia industrial, PCA é aplicada em séries de sensores IoT para detectar anomalias em equipamentos (ex: turbinas eólicas), reduzindo dimensionalidade de centenas de variáveis para poucos componentes, permitindo monitoramento em tempo real, previsão de falhas e otimização econômica de manutenção."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.6.1.2",
                            "name": "Aplicar PCA em dados econométricos",
                            "description": "Implementar PCA utilizando ferramentas como R (pacote prcomp), padronizando dados e selecionando componentes para análise de regressão linear em grandes amostras de dados de engenharia, como custos de produção e variáveis econômicas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e carregar os dados econométricos",
                                  "subSteps": [
                                    "Identifique e baixe um dataset relevante, como dados de custos de produção (ex: dataset 'production_costs.csv' com variáveis como custo_mao_obra, custo_materiais, PIB_regional, inflacao)",
                                    "Carregue o dataset no R usando read.csv() ou readr::read_csv()",
                                    "Explore os dados com summary(), str() e visualize com ggplot2 para identificar missing values e outliers",
                                    "Trate missing values com imputação média ou remoção, e remova variáveis não numéricas ou irrelevantes",
                                    "Defina a matriz de dados para PCA, selecionando apenas variáveis contínuas multivariadas"
                                  ],
                                  "verification": "Execute summary() e cor() para confirmar que os dados estão limpos, numéricos e com correlações visíveis",
                                  "estimatedTime": "45 minutos",
                                  "materials": "R/RStudio, dataset CSV de custos de produção (ex: simular com 1000+ observações), pacotes: readr, dplyr, ggplot2",
                                  "tips": "Sempre salve uma cópia original dos dados com data <- read.csv('file.csv')",
                                  "learningObjective": "Preparar dados econométricos limpos e prontos para análise multivariada",
                                  "commonMistakes": "Ignorar outliers que distorcem a variância; não tratar missing values antes da padronização"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Padronizar os dados para PCA",
                                  "subSteps": [
                                    "Verifique escalas das variáveis com summary() para confirmar necessidade de padronização",
                                    "Use scale() função para centralizar e escalar: data_scaled <- scale(data_numeric)",
                                    "Confirme padronização com apply(data_scaled, 2, mean) ≈ 0 e apply(data_scaled, 2, sd) ≈ 1",
                                    "Crie um boxplot ou histograma das variáveis padronizadas para visual inspeção",
                                    "Salve a média e desvio padrão originais para possível reversão futura"
                                  ],
                                  "verification": "Médias das colunas padronizadas próximas de 0 e desvios padrão de 1",
                                  "estimatedTime": "30 minutos",
                                  "materials": "R com base + pacotes base::scale(), ggplot2 para plots",
                                  "tips": "PCA é sensível a escalas; padronize SEMPRE em dados econométricos com unidades diferentes",
                                  "learningObjective": "Garantir que todas variáveis contribuam igualmente na extração de componentes",
                                  "commonMistakes": "Esquecer de padronizar, levando componentes dominados por variáveis de alta escala como custos absolutos"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar PCA com prcomp e analisar resultados iniciais",
                                  "subSteps": [
                                    "Instale/carregue pacote stats: library(stats)",
                                    "Execute pca_model <- prcomp(data_scaled, center = FALSE, scale = FALSE) pois já padronizado",
                                    "Gere scree plot: plot(pca_model, type='l') e biplot(pca_model)",
                                    "Extraia summary(pca_model) para ver proporção de variância explicada por componente",
                                    "Calcule cumulativa variância: cumsum(pca_model$sdev^2 / sum(pca_model$sdev^2)) * 100"
                                  ],
                                  "verification": "Scree plot mostra 'cotovelo' e summary indica >70% variância em primeiros 3-5 componentes",
                                  "estimatedTime": "40 minutos",
                                  "materials": "R com stats (base), opcional factoextra para plots avançados",
                                  "tips": "Use center=FALSE se já scale() foi usado para evitar dupla centralização",
                                  "learningObjective": "Implementar PCA corretamente e interpretar variância explicada",
                                  "commonMistakes": "Usar princomp() em vez de prcomp() (prcomp é mais eficiente para grandes datasets)"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Selecionar componentes e integrá-los à regressão linear",
                                  "subSteps": [
                                    "Escolha k componentes baseado em scree plot e >80% variância cumulativa",
                                    "Extraia scores: pc_scores <- pca_model$x[,1:k]",
                                    "Prepare modelo de regressão: lm_model <- lm(custo_producao ~ pc_scores, data = dataset_completo)",
                                    "Analise summary(lm_model) para significância (p-values <0.05) e R² ajustado",
                                    "Valide com cross-validation usando caret::train() ou manual split"
                                  ],
                                  "verification": "Modelo LM mostra componentes significativos e R² > baseline sem PCA",
                                  "estimatedTime": "50 minutos",
                                  "materials": "R com stats, pacotes: caret para CV opcional",
                                  "tips": "Selecione k onde elbow ocorre; teste múltiplos k para otimizar",
                                  "learningObjective": "Aplicar componentes selecionados para reduzir dimensionalidade em regressão econométrica",
                                  "commonMistakes": "Selecionar muitos componentes, negando redução de dimensionalidade; multicolinearidade nos scores"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar loadings e validar o modelo final",
                                  "subSteps": [
                                    "Examine loadings: pca_model$rotation para ver contribuições de variáveis originais",
                                    "Interprete PC1/PC2 como combinações econômicas (ex: PC1 = fator custo geral)",
                                    "Compare regressão com PCA vs. original com VIF() para multicolinearidade",
                                    "Gere plots de scores PC vs. variável target e resíduos do LM",
                                    "Documente insights: 'PC1 explica 45% variância em custos econômicos'"
                                  ],
                                  "verification": "Loadings mostram interpretações econômicas coerentes e VIF <5 nos PCs",
                                  "estimatedTime": "35 minutos",
                                  "materials": "R base + car::vif() do pacote car",
                                  "tips": "Loadings ajudam a nomear componentes (ex: 'fator eficiência produtiva')",
                                  "learningObjective": "Interpretar e validar PCA no contexto econométrico",
                                  "commonMistakes": "Ignorar rotações (loadings) levando a interpretações errôneas"
                                }
                              ],
                              "practicalExample": "Usando dataset de 2000 firmas de manufatura com variáveis: custo_mao_obra, custo_energia, custo_materiais, PIB, inflacao_anual, taxa_juros. Após PCA, PC1 captura 'fator custo operacional' (alta loading em custos), PC2 'fator macroeconômico'. Regressão LM(PC1+PC2 ~ lucro) atinge R²=0.78 vs. 0.62 original, reduzindo multicolinearidade.",
                              "finalVerifications": [
                                "Scree plot e variância cumulativa >80% com k<=5 componentes",
                                "Padronização confirmada (médias=0, sd=1)",
                                "Regressão LM com p-values<0.05 para componentes e R² melhorado",
                                "Biplot mostra separação clara de clusters econômicos",
                                "VIF<10 confirma ausência de multicolinearidade nos PCs",
                                "Interpretação de loadings alinhada com teoria econômica"
                              ],
                              "assessmentCriteria": [
                                "Correta padronização e execução de prcomp (20%)",
                                "Seleção justificada de componentes baseada em critérios (25%)",
                                "Integração bem-sucedida em LM com melhoria em R²/VIF (25%)",
                                "Interpretação precisa de loadings e variância (15%)",
                                "Código limpo, comentado e reproduzível (10%)",
                                "Validação com plots e métricas (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Redução de dimensionalidade em modelos de painel",
                                "Engenharia de Produção: Otimização de custos multivariados",
                                "Estatística: Inferência em grandes amostras (>1000 obs)",
                                "Machine Learning: Pré-processamento para regressão em datasets high-dim"
                              ],
                              "realWorldApplication": "Em indústrias de manufatura, PCA em dados de custos e variáveis macroeconômicas permite prever aumentos de produção com menos multicolinearidade, auxiliando decisões de investimento (ex: empresas como Petrobras usam para análise de CAPEX em óleo&gás)."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.6.1.3",
                            "name": "Interpretar resultados de PCA",
                            "description": "Analisar loadings, scores e biplots para identificar padrões em dados multivariados, relacionando com pressupostos de regressão linear e inferência em contextos de engenharia econômica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Analisar Loadings dos Componentes Principais",
                                  "subSteps": [
                                    "Carregue os resultados de PCA de um dataset multivariado usando bibliotecas como scikit-learn ou R.",
                                    "Identifique os loadings para cada variável nos primeiros 2-3 componentes principais (PCs).",
                                    "Classifique variáveis com |loading| > 0.5 como dominantes para cada PC.",
                                    "Calcule a variância explicada por cada PC e some para os principais.",
                                    "Documente padrões: variáveis positivamente/negativamente correlacionadas."
                                  ],
                                  "verification": "Gere um relatório resumindo os loadings dominantes e sua interpretação em termos de padrões de correlação entre variáveis.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python (scikit-learn, pandas, matplotlib)",
                                    "Dataset exemplo de variáveis econômicas (ex: custos de projetos de engenharia)"
                                  ],
                                  "tips": "Foquem nos PCs que explicam >70% da variância total para priorizar interpretações relevantes.",
                                  "learningObjective": "Compreender como loadings revelam contribuições relativas de variáveis para componentes e identificam padrões multivariados.",
                                  "commonMistakes": [
                                    "Ignorar o sinal dos loadings (positivo vs. negativo)",
                                    "Interpretar loadings isolados sem contexto de variância explicada",
                                    "Confundir loadings com scores"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar Scores das Observações",
                                  "subSteps": [
                                    "Extraia os scores para as observações nos PCs principais.",
                                    "Plote scores em scatterplots para PC1 vs PC2, colorindo por grupos conhecidos (ex: tipos de projetos).",
                                    "Identifique outliers ou clusters nos scores que indicam observações atípicas ou semelhantes.",
                                    "Calcule distâncias euclidianas entre scores para quantificar similaridades.",
                                    "Relacione scores com variáveis originais para validar agrupamentos."
                                  ],
                                  "verification": "Crie um gráfico de scores com anotações explicando 2-3 clusters ou outliers identificados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python (matplotlib, seaborn)",
                                    "Resultados de PCA do Step 1"
                                  ],
                                  "tips": "Use escalas padronizadas para scores para facilitar comparações entre PCs.",
                                  "learningObjective": "Interpretar scores como projeções das observações, identificando padrões de similaridade e outliers em dados multivariados.",
                                  "commonMistakes": [
                                    "Interpretar scores como valores absolutos sem normalização",
                                    "Ignorar variância explicada ao priorizar PCs menores",
                                    "Confundir scores com loadings"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Examinar Biplots para Visualização Conjunta",
                                  "subSteps": [
                                    "Gere um biplot combinando scores (setas para observações) e loadings (vetores para variáveis).",
                                    "Analise ângulos entre vetores de variáveis: ângulos agudos indicam correlação positiva.",
                                    "Identifique variáveis opostas (180°) como anticorrelationadas.",
                                    "Sobreponha scores de observações para ver como elas se alinham com vetores.",
                                    "Interprete comprimentos de vetores como importância relativa das variáveis."
                                  ],
                                  "verification": "Produza um biplot anotado explicando pelo menos 3 relações chave entre variáveis e observações.",
                                  "estimatedTime": "1-1.5 horas",
                                  "materials": [
                                    "Python (scikit-learn plot_components)",
                                    "Resultados dos Steps 1-2"
                                  ],
                                  "tips": "Ajuste o scaling do biplot para equilibrar visibilidade de scores e loadings.",
                                  "learningObjective": "Usar biplots para visualizar simultaneamente relações entre observações e variáveis nos componentes principais.",
                                  "commonMistakes": [
                                    "Ignorar a direção das setas nos biplots",
                                    "Sobrecarregar o biplot com todos os PCs",
                                    "Interpretar comprimento sem contexto de variância"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relacionar Interpretações PCA com Pressupostos de Regressão Linear e Inferência em Engenharia Econômica",
                                  "subSteps": [
                                    "Verifique multicolinearidade: variáveis com loadings altos no mesmo PC indicam correlação.",
                                    "Use PCs como preditores em regressão para mitigar multicolinearidade.",
                                    "Avalie pressupostos de regressão (linearidade, homocedasticidade) nos scores.",
                                    "Aplique inferência: teste significância de loadings via bootstrap.",
                                    "Contextualize em engenharia econômica: identifique drivers de custo (ex: materiais vs. mão de obra)."
                                  ],
                                  "verification": "Escreva um parágrafo integrando achados PCA a um modelo de regressão linear para previsão de custos econômicos.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "statsmodels ou lm em R",
                                    "Dataset com variável resposta econômica (ex: custo total de projeto)"
                                  ],
                                  "tips": "Sempre valide PCA com VIF em regressão original para confirmar redução de multicolinearidade.",
                                  "learningObjective": "Conectar resultados PCA a validação de pressupostos de regressão e inferência prática em contextos econômicos de engenharia.",
                                  "commonMistakes": [
                                    "Assumir causalidade de correlações em loadings",
                                    "Ignorar perda de interpretabilidade ao usar PCs em regressão",
                                    "Não testar significância estatística"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de 100 projetos de engenharia civil com variáveis como custo de materiais, mão de obra, localização e inflação, aplique PCA. Loadings mostram que PC1 é dominado por materiais e mão de obra (alta correlação), scores revelam clusters de projetos urbanos vs rurais, biplot confirma oposição entre localização e inflação, e isso valida remoção de multicolinearidade para regressão de custo total.",
                              "finalVerifications": [
                                "Explicar verbalmente o significado de um loading de 0.8 em PC1.",
                                "Identificar corretamente 2 outliers em um gráfico de scores fornecido.",
                                "Interpretar um biplot destacando 3 relações chave.",
                                "Relacionar achados PCA a um pressuposto violado de regressão linear (ex: multicolinearidade).",
                                "Aplicar inferência básica (ex: intervalo de confiança para variância explicada).",
                                "Gerar relatório integrando todos os elementos para um dataset real."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de padrões em loadings, scores e biplots (80%+ acurácia).",
                                "Correta relação com pressupostos de regressão (multicolinearidade, linearidade).",
                                "Qualidade visual e anotação de gráficos (clareza, legibilidade).",
                                "Profundidade da inferência estatística em contextos econômicos.",
                                "Capacidade de integrar interpretações em relatório coeso.",
                                "Tempo de execução dentro dos estimados com resultados acionáveis."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de significância em loadings e variância.",
                                "Machine Learning: Redução de dimensionalidade para modelos preditivos.",
                                "Economia de Engenharia: Análise de drivers de custo e risco.",
                                "Visualização de Dados: Técnicas de plotting para insights multivariados.",
                                "Regressão Linear: Mitigação de violações de pressupostos via PCA."
                              ],
                              "realWorldApplication": "Na engenharia econômica, PCA em dados de custos de projetos de infraestrutura identifica fatores principais de variância (ex: dominância de flutuações de commodities), reduz multicolinearidade para modelos de regressão mais robustos, permitindo inferências confiáveis sobre orçamentos e alocação de recursos em cenários de alta dimensionalidade."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.6.2",
                        "name": "Análise Fatorial",
                        "description": "Técnica para identificar fatores latentes subjacentes a variáveis observadas, usada em análise econométrica aplicada à engenharia para modelagem de relações não observáveis em dados complexos.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.6.2.1",
                            "name": "Entender os modelos de análise fatorial",
                            "description": "Descrever modelos fatorial exploratório e confirmatório, incluindo rotação varimax e critérios de Kaiser para retenção de fatores, adaptados a dados econométricos de engenharia como indicadores de desempenho de sistemas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais da Análise Fatorial",
                                  "subSteps": [
                                    "Defina análise fatorial como uma técnica multivariada que identifica fatores latentes subjacentes a variáveis observadas.",
                                    "Estude o modelo matemático básico: X = ΛF + ε, onde X são variáveis observadas, Λ é a matriz de cargas fatoriais, F são os fatores comuns e ε é o erro único.",
                                    "Diferencie fatores comuns de variáveis únicas e entenda a comunalidade (h²).",
                                    "Revise pressupostos: multicolinearidade moderada, adequação de amostra (KMO > 0.6) e teste de esfericidade de Bartlett.",
                                    "Explore adaptações para dados econométricos de engenharia, como indicadores de desempenho (ex.: eficiência energética, custo operacional)."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o modelo matemático e seus componentes para um colega.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Livro 'Análise Multivariada' de Hair et al.",
                                    "Tutorial online sobre análise fatorial (Khan Academy ou YouTube)",
                                    "Software R com pacote psych ou Python com factor_analyzer"
                                  ],
                                  "tips": "Comece com exemplos visuais de gráficos de cargas fatoriais para intuitar os conceitos.",
                                  "learningObjective": "Identificar e descrever os componentes básicos do modelo de análise fatorial adaptado a contextos de engenharia.",
                                  "commonMistakes": [
                                    "Confundir fatores comuns com componentes principais; ignorar pressupostos como normalidade multivariada."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Dominar a Análise Fatorial Exploratória (EFA) com Rotação Varimax e Critério de Kaiser",
                                  "subSteps": [
                                    "Aprenda extração de fatores via máxima verossimilhança ou componentes principais.",
                                    "Implemente rotação ortogonal Varimax para maximizar variância explicada por fator e simplificar interpretação.",
                                    "Aplique critério de Kaiser (autovalores > 1) para retenção de fatores; compare com scree plot e paralel analysis.",
                                    "Interprete cargas fatoriais (> 0.4) e suprima cargas cruzadas.",
                                    "Teste em dataset econométrico: simule indicadores de desempenho de sistemas (ex.: tempo de inatividade, consumo de energia)."
                                  ],
                                  "verification": "Execute EFA em um dataset de amostra e interprete os autovalores e cargas fatoriais.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Dataset exemplo de indicadores de engenharia (Kaggle ou UCI ML Repository)",
                                    "R script para EFA com factanal() e varimax()",
                                    "Python com sklearn.decomposition.FactorAnalysis"
                                  ],
                                  "tips": "Sempre padronize variáveis antes da análise para evitar viés de escala.",
                                  "learningObjective": "Executar e interpretar EFA usando rotação Varimax e critério de Kaiser em dados de engenharia.",
                                  "commonMistakes": [
                                    "Retenção excessiva de fatores sem validação múltipla; interpretação de cargas baixas como significativas."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar a Análise Fatorial Confirmatória (CFA)",
                                  "subSteps": [
                                    "Entenda CFA como teste de hipótese sobre estrutura fatorial pré-especificada usando modelagem de equações estruturais (SEM).",
                                    "Defina modelo: especifique cargas fixas/livres, correlações entre fatores e erros.",
                                    "Avalie ajuste: χ², CFI (>0.95), RMSEA (<0.06), SRMR (<0.08).",
                                    "Compare EFA vs. CFA em termos de exploração vs. confirmação.",
                                    "Adapte a indicadores econométricos: confirme fatores como 'eficiência operacional' em sistemas de engenharia."
                                  ],
                                  "verification": "Construa um modelo CFA simples em software e avalie índices de ajuste.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Software lavaan no R ou semopy no Python",
                                    "Tutorial CFA de Byrne 'Structural Equation Modeling'",
                                    "Dataset validado para CFA"
                                  ],
                                  "tips": "Use modificação de índices com cautela para evitar overfitting.",
                                  "learningObjective": "Construir e avaliar modelos CFA para validar estruturas fatoriais em contextos econométricos.",
                                  "commonMistakes": [
                                    "Ignorar violações de normalidade; aceitar ajuste pobre baseado apenas em χ²."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Modelos Fatoriais a Dados Econométricos de Engenharia",
                                  "subSteps": [
                                    "Selecione dataset real: indicadores de desempenho de sistemas (ex.: KPIs de plantas industriais).",
                                    "Realize EFA para explorar, refine com Varimax/Kaiser, confirme via CFA.",
                                    "Valide robustez: análise de sensibilidade, bootstrap para intervalos de confiança.",
                                    "Interprete resultados: nomeie fatores e relacione a aplicações de engenharia.",
                                    "Documente relatório com gráficos (biplot, scree plot)."
                                  ],
                                  "verification": "Produza um relatório de 1 página resumindo análise em dataset próprio.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": [
                                    "Dataset público de engenharia (ex.: turbinas ou redes elétricas)",
                                    "Jupyter Notebook para integração EFA/CFA",
                                    "Ferramentas de visualização: ggplot2 ou matplotlib"
                                  ],
                                  "tips": "Integre domínio de engenharia para nomear fatores de forma significativa.",
                                  "learningObjective": "Aplicar integralmente EFA e CFA a dados reais de engenharia econométrica.",
                                  "commonMistakes": [
                                    "Amostra insuficiente (<10:1 variáveis); generalização sem validação cruzada."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de 20 indicadores de desempenho de uma usina eólica (ex.: produção de energia, manutenção, custos), aplique EFA para extrair 3 fatores (Eficiência, Confiabilidade, Custo) via Varimax (autovalores >1 Kaiser), confirme via CFA com CFI=0.97, identificando 'Eficiência' como fator latente chave para otimização.",
                              "finalVerifications": [
                                "Descreva a diferença entre EFA e CFA com exemplos.",
                                "Explique rotação Varimax e critério de Kaiser em termos matemáticos simples.",
                                "Interprete um scree plot e matriz de cargas fatoriais de um exemplo.",
                                "Liste 3 índices de ajuste para CFA e seus thresholds.",
                                "Aplique conceitos a um dataset econométrico de engenharia fornecido.",
                                "Crie um modelo fatorial hipotético para indicadores de sistemas."
                              ],
                              "assessmentCriteria": [
                                "Precisão na descrição de modelos EFA/CFA (90% acurácia).",
                                "Correta aplicação de rotação Varimax e Kaiser (autovalores interpretados).",
                                "Interpretação válida de cargas e fatores em contexto de engenharia.",
                                "Uso adequado de índices de ajuste CFA (CFI, RMSEA citados corretamente).",
                                "Relatório prático com visualizações claras e conclusões acionáveis.",
                                "Adaptação explícita a dados econométricos de engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Avançada: Integra com PCA e SEM.",
                                "Engenharia de Sistemas: Redução de dimensionalidade em monitoramento IoT.",
                                "Econometria: Análise de painéis e variáveis latentes em finanças de projetos.",
                                "Ciência de Dados: Pré-processamento para ML em big data de engenharia.",
                                "Gestão de Projetos: KPIs fatoriais para avaliação de desempenho."
                              ],
                              "realWorldApplication": "Em engenharia, análise fatorial reduz dezenas de indicadores de desempenho de sistemas complexos (ex.: aviões, redes elétricas) a poucos fatores latentes, facilitando monitoramento preditivo, otimização de custos e tomada de decisões baseadas em dados econométricos para manutenção preventiva."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.6.2.2",
                            "name": "Realizar análise fatorial em software",
                            "description": "Executar análise fatorial com R (pacote factanal), testando adequação de amostra (KMO) e esfericidade de Bartlett, em conjuntos de dados de engenharia com múltiplas variáveis econômicas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente R e preparar conjunto de dados",
                                  "subSteps": [
                                    "Instalar e carregar pacotes necessários: psych, FactoMineR e ggplot2.",
                                    "Importar dataset de engenharia com variáveis econômicas (ex: custos de materiais, mão de obra, energia para 10 projetos).",
                                    "Explorar dados: summary(), str() e detectar missing values com is.na().",
                                    "Padronizar variáveis com scale() para análise fatorial.",
                                    "Verificar correlações iniciais com cor() ou corrplot."
                                  ],
                                  "verification": "Dataset carregado e padronizado sem erros; matriz de correlação visualizada corretamente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Dataset CSV com variáveis econômicas (ex: engineering_econ_data.csv)",
                                    "Pacotes: psych, FactoMineR, ggplot2"
                                  ],
                                  "tips": "Sempre use set.seed() para reprodutibilidade em simulações.",
                                  "learningObjective": "Preparar dados adequadamente para análise multivariada em R.",
                                  "commonMistakes": [
                                    "Ignorar missing values",
                                    "Não padronizar variáveis",
                                    "Usar dataset com poucas observações"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Testar adequação da amostra (KMO e teste de Bartlett)",
                                  "subSteps": [
                                    "Calcular MSA (Measure of Sampling Adequacy) com KMO() do pacote psych.",
                                    "Executar teste de esfericidade de Bartlett com cortest.bartlett().",
                                    "Interpretar resultados: KMO > 0.6 e p-value Bartlett < 0.05 indicam adequação.",
                                    "Identificar variáveis com MSA individual baixo (< 0.5) e considerar remoção.",
                                    "Documentar resultados em um relatório inicial."
                                  ],
                                  "verification": "Relatório gerado mostrando KMO >= 0.6 e Bartlett significativo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Pacote psych carregado",
                                    "Dataset padronizado do Step 1"
                                  ],
                                  "tips": "KMO entre 0.5-0.6 é marginal; refine dados se necessário.",
                                  "learningObjective": "Avaliar premissas estatísticas para validade da análise fatorial.",
                                  "commonMistakes": [
                                    "Confundir KMO com outros índices",
                                    "Ignorar MSA individual de variáveis",
                                    "Não interpretar p-value corretamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar análise fatorial com factanal()",
                                  "subSteps": [
                                    "Executar factanal(data, factors=2, rotation='varimax') ajustando número de fatores via scree plot ou eigenvalues >1.",
                                    "Extrair loadings com $loadings e communalities com $communality.",
                                    "Determinar número ótimo de fatores usando fa.parallel() do psych.",
                                    "Rotacionar fatores (varimax ou oblimin) para interpretabilidade.",
                                    "Calcular scores fatoriais com lm() ou factor.scores()."
                                  ],
                                  "verification": "Modelo factanal executado sem erros; loadings impressos e rotacionados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Dataset validado do Step 2",
                                    "Pacotes psych e base R"
                                  ],
                                  "tips": "Comece com 2-3 fatores e refine baseado em eigenvalues.",
                                  "learningObjective": "Realizar extração e rotação de fatores em R.",
                                  "commonMistakes": [
                                    "Escolher fatores demais/poucos",
                                    "Esquecer rotação",
                                    "Interpretar loadings sem rotação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar, visualizar e validar resultados",
                                  "subSteps": [
                                    "Plotar scree plot com fa.diagram() ou ggplot para eigenvalues.",
                                    "Interpretar loadings: valores >0.4 indicam carga significativa em fatores.",
                                    "Calcular variância explicada com $var$values.",
                                    "Validar com reliability(alfa de Cronbach por fator) e plot de communalities.",
                                    "Gerar relatório final com tabelas e gráficos."
                                  ],
                                  "verification": "Relatório completo com interpretações, plots e métricas de validade.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Resultados do Step 3",
                                    "Pacotes ggplot2 e psych"
                                  ],
                                  "tips": "Nomeie fatores baseado em loadings (ex: Fator1=Custo Operacional).",
                                  "learningObjective": "Interpretar e comunicar resultados de análise fatorial.",
                                  "commonMistakes": [
                                    "Sobresimplificar interpretações",
                                    "Ignorar communalities baixas",
                                    "Não reportar % variância explicada"
                                  ]
                                }
                              ],
                              "practicalExample": "Analisar dataset de 50 projetos de engenharia civil com 8 variáveis econômicas (custo mão de obra, materiais, energia, etc.). Após KMO=0.78 e Bartlett p<0.001, extrair 3 fatores explicando 65% variância: Fator1=Custos Fixos, Fator2=Variáveis Operacionais, Fator3=Eficiência Energética. Usar scores para clustering de projetos.",
                              "finalVerifications": [
                                "KMO e Bartlett confirmam adequação da amostra.",
                                "Análise factanal executa sem erros com rotação adequada.",
                                "Loadings interpretados corretamente com >60% variância explicada.",
                                "Relatório inclui plots, tabelas e conclusões acionáveis.",
                                "Scores fatoriais calculados e aplicados em exemplo prático.",
                                "Comunalidades >0.5 para maioria das variáveis."
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação e validação de dados (20%)",
                                "Correta execução e interpretação de testes de adequação (25%)",
                                "Qualidade da análise factanal e rotação (25%)",
                                "Profundidade de interpretação e visualizações (20%)",
                                "Relatório claro e completo (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e inferência multivariada.",
                                "Engenharia Econômica: Redução de dimensionalidade em dados de custos.",
                                "Programação: Manipulação de dados em R e visualização.",
                                "Gestão de Projetos: Clustering de projetos por perfis econômicos.",
                                "Machine Learning: Pré-processamento para PCA ou clustering."
                              ],
                              "realWorldApplication": "Em engenharia, usar análise fatorial para reduzir variáveis econômicas em dashboards de custo de projetos, identificando padrões como 'projetos de alto custo energético' para otimização orçamentária e tomada de decisões em licitações."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.6.2.3",
                            "name": "Aplicar fatores em regressão",
                            "description": "Integrar fatores extraídos em modelos de regressão linear ou métodos generalizados de momentos, avaliando propriedades estatísticas dos estimadores em aplicações de engenharia como otimização de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados e fatores extraídos da análise fatorial",
                                  "subSteps": [
                                    "Carregar o dataset original com variáveis observadas",
                                    "Extrair ou carregar os fatores scores da análise fatorial prévia",
                                    "Verificar communalities e loadings para selecionar fatores relevantes",
                                    "Padronizar variáveis e fatores para evitar escalas diferentes",
                                    "Tratar valores ausentes e outliers nos dados"
                                  ],
                                  "verification": "Dataset preparado com fatores integrados, sem erros de shape ou NaN, verificado via summary statistics",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com pandas, numpy e factor_analyzer",
                                    "Dataset de exemplo de engenharia (ex: sensores industriais)"
                                  ],
                                  "tips": [
                                    "Verifique multicolinearidade entre fatores usando VIF antes de prosseguir",
                                    "Salve os fatores como novas colunas no dataframe"
                                  ],
                                  "learningObjective": "Preparar dados limpos e fatores prontos para inclusão em modelos de regressão",
                                  "commonMistakes": [
                                    "Não normalizar fatores levando a bias nos coeficientes",
                                    "Ignorar fatores com baixa communality"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar o modelo de regressão linear ou GMM",
                                  "subSteps": [
                                    "Definir a variável dependente (ex: performance do processo)",
                                    "Selecionar fatores como preditores independentes",
                                    "Especificar equação do modelo: Y = β0 + β1*F1 + ... + ε",
                                    "Para GMM, definir instrumentos e momento conditions",
                                    "Implementar em código usando statsmodels ou similar"
                                  ],
                                  "verification": "Modelo especificado corretamente, equação impressa e sintaxe validada sem erros",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com statsmodels, linearmodels",
                                    "Documentação de GMM"
                                  ],
                                  "tips": [
                                    "Comece com OLS simples antes de GMM para baseline",
                                    "Inclua intercepto sempre"
                                  ],
                                  "learningObjective": "Construir especificação teórica e prática do modelo incorporando fatores",
                                  "commonMistakes": [
                                    "Omitir variáveis de controle",
                                    "Confundir fatores com variáveis originais"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimar o modelo e obter estimadores",
                                  "subSteps": [
                                    "Ajustar o modelo de regressão linear via OLS",
                                    "Se necessário, estimar via GMM com instrumentos válidos",
                                    "Extrair coeficientes, erros padrão e p-values",
                                    "Verificar convergência e condições de momentos",
                                    "Calcular intervalos de confiança para estimadores"
                                  ],
                                  "verification": "Modelo ajustado com summary() mostrando coeficientes significativos e sem warnings",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Bibliotecas: statsmodels.sm.OLS e IV2SLS",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": [
                                    "Use robust standard errors para heteroscedasticidade comum em dados de engenharia",
                                    "Teste endogeneidade antes de GMM"
                                  ],
                                  "learningObjective": "Executar estimação eficiente e obter propriedades dos estimadores",
                                  "commonMistakes": [
                                    "Não testar instrumentos fracos em GMM",
                                    "Interpretar p-values sem múltiplos testes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar propriedades estatísticas e validar o modelo",
                                  "subSteps": [
                                    "Analisar resíduos: normalidade (QQ-plot), homoscedasticidade (Breusch-Pagan)",
                                    "Calcular R², R² ajustado e F-statistic",
                                    "Testar multicolinearidade (VIF) e autocorrelação",
                                    "Realizar validação cruzada com dados de teste",
                                    "Interpretar impacto dos fatores na variável dependente"
                                  ],
                                  "verification": "Relatório de diagnósticos com todos testes aprovados (p > 0.05 onde aplicável)",
                                  "estimatedTime": "1 hora e 30 minutos",
                                  "materials": [
                                    "statsmodels diagnostics",
                                    "Matplotlib/Seaborn para plots"
                                  ],
                                  "tips": [
                                    "Plots visuais são essenciais para resíduos",
                                    "Compare OLS vs GMM via testes de Hausman"
                                  ],
                                  "learningObjective": "Avaliar robustez e validade estatística dos estimadores em contexto",
                                  "commonMistakes": [
                                    "Ignorar resíduos não-normais",
                                    "Sobreajuste por muitos fatores"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar resultados em otimização de processos de engenharia",
                                  "subSteps": [
                                    "Interpretar coeficientes dos fatores economicamente",
                                    "Simular cenários de otimização baseados nos estimadores",
                                    "Prever outcomes para novos dados",
                                    "Recomendar ações baseadas em significância",
                                    "Documentar relatório com visualizações"
                                  ],
                                  "verification": "Previsões precisas em hold-out set e relatório gerado",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Excel ou Python para simulações",
                                    "Templates de relatório"
                                  ],
                                  "tips": [
                                    "Foco em fatores com maior β para priorizar otimizações",
                                    "Sensibilidade analysis para robustez"
                                  ],
                                  "learningObjective": "Traduzir resultados estatísticos em decisões práticas de engenharia",
                                  "commonMistakes": [
                                    "Generalizar sem contexto domínio",
                                    "Ignorar incertezas nos CIs"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma linha de produção de turbinas eólicas, extraia fatores de análise fatorial de sensores de vibração, temperatura e pressão. Integre-os em regressão linear contra tempo até falha, estimando via OLS/GMM para identificar fatores preditivos e otimizar manutenção preventiva.",
                              "finalVerifications": [
                                "Modelo converge com R² > 0.7 e resíduos normais",
                                "Fatores significativos (p < 0.05) com VIF < 5",
                                "Previsões em teste com MAE < 10% do mean",
                                "Testes de diagnósticos (Hausman, J-stat) aprovados",
                                "Relatório com interpretação aplicada gerado",
                                "Simulação de otimização reduzindo custo em 15%"
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação e integração de fatores (30%)",
                                "Correção na estimação e escolha de método (25%)",
                                "Qualidade dos diagnósticos estatísticos (20%)",
                                "Interpretação e aplicação prática (15%)",
                                "Clareza do código e documentação (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Propriedades de estimadores e testes de hipóteses",
                                "Engenharia de Processos: Otimização e controle de qualidade",
                                "Programação Científica: Manipulação de dados em Python/R",
                                "Machine Learning: Redução de dimensionalidade e previsão",
                                "Econometria: Modelos com endogeneidade via GMM"
                              ],
                              "realWorldApplication": "Otimização de processos industriais, como previsão de falhas em manufatura, alocação de recursos em engenharia química e melhoria de eficiência energética em plantas de produção, reduzindo custos e downtime."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.6.2.4",
                            "name": "Validar e interpretar fatores",
                            "description": "Realizar testes de confiabilidade (alfa de Cronbach) e validar fatores com dados de validação cruzada, interpretando no contexto de análise multivariada para engenharia econômica.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e calcular Alfa de Cronbach para confiabilidade",
                                  "subSteps": [
                                    "Carregar o dataset multivariado relevante para engenharia econômica (ex: variáveis de custo, risco, retorno).",
                                    "Verificar pressupostos: normalidade, ausência de multicolinearidade via correlações e VIF.",
                                    "Calcular Alfa de Cronbach usando biblioteca apropriada (ex: pingouin em Python ou psych em R).",
                                    "Interpretar valores: >0.7 aceitável, >0.8 bom, <0.6 problemático.",
                                    "Identificar itens com baixa correlação item-total e considerar remoção."
                                  ],
                                  "verification": "Alfa de Cronbach calculado e reportado com intervalo de confiança; itens problemáticos listados.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (pandas, pingouin, scipy) ou R (psych package); dataset de exemplo com 10+ variáveis econômicas.",
                                  "tips": "Use alpha if item deleted para diagnosticar itens fracos antes de remover.",
                                  "learningObjective": "Compreender e aplicar teste de confiabilidade interna para escalas em análise multivariada.",
                                  "commonMistakes": "Ignorar violações de pressupostos como normalidade; interpretar alfa alto como validade sem testes adicionais."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar Análise Fatorial e Extrair Fatores",
                                  "subSteps": [
                                    "Selecionar método de extração (ex: PCA ou PAF) e rotação (varimax para ortogonalidade).",
                                    "Determinar número de fatores via scree plot, KMO (>0.6) e Bartlett's test (p<0.05).",
                                    "Extrair loadings fatoriais e supressão (<0.3).",
                                    "Calcular communalities (>0.4 indica boa explicação).",
                                    "Nomear fatores provisoriamente baseado em loadings >0.4."
                                  ],
                                  "verification": "Matriz de loadings gerada; KMO e Bartlett reportados; scree plot visualizado.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python (factor_analyzer) ou R (factanal); mesmo dataset limpo pós-Cronbach.",
                                  "tips": "Prefira rotação oblíqua (promax) se correlações entre fatores esperadas em contextos econômicos.",
                                  "learningObjective": "Executar extração fatorial robusta e avaliar adequação dos dados.",
                                  "commonMistakes": "Escolher número errado de fatores sem múltiplos critérios; ignorar communalities baixas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Validar Fatores com Cross-Validation",
                                  "subSteps": [
                                    "Dividir dataset em treino (70%) e teste (30%) ou usar k-fold (k=5-10).",
                                    "Treinar modelo fatorial no treino e prever no teste.",
                                    "Comparar loadings Tuckey congruence coefficient (>0.85 boa similaridade) ou RMSEA (<0.08).",
                                    "Avaliar estabilidade via bootstrap (1000 resamples) para CIs de loadings.",
                                    "Testar diferenças significativas com Hotelling's T² se aplicável."
                                  ],
                                  "verification": "Coeficientes de congruência >0.85; métricas de fit como RMSEA reportadas para holdout.",
                                  "estimatedTime": "75 minutos",
                                  "materials": "Python (scikit-learn para CV, factor_analyzer) ou R (CFA com lavaan); dataset dividido.",
                                  "tips": "Use stratified k-fold para balancear variáveis econômicas raras como riscos altos.",
                                  "learningObjective": "Aplicar validação cruzada para confirmar generalização dos fatores extraídos.",
                                  "commonMistakes": "Overfitting sem holdout; usar CV simples em dados desbalanceados."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar Fatores no Contexto de Engenharia Econômica",
                                  "subSteps": [
                                    "Mapear fatores a constructs econômicos (ex: Fator 1 = 'Risco Financeiro' baseado em loadings de custo/volatilidade).",
                                    "Calcular scores fatoriais e correlacionar com outcomes (ex: NPV de projetos).",
                                    "Discutir implicações: fatores estáveis preveem viabilidade econômica?",
                                    "Reportar limitações: tamanho amostra, causalidade não inferida.",
                                    "Sugerir melhorias: itens adicionais para refinar fatores."
                                  ],
                                  "verification": "Relatório escrito com nomes de fatores, scores e ligações contextuais; correlações significativas (p<0.05).",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Ferramentas de plotting (matplotlib/seaborn ou ggplot); relatório template em Jupyter/Markdown.",
                                  "tips": "Use pattern matrix para interpretações claras; valide nomes com literatura econômica.",
                                  "learningObjective": "Traduzir resultados fatoriais em insights acionáveis para decisões de engenharia.",
                                  "commonMistakes": "Sobrenomear fatores sem suporte empírico; ignorar direção dos loadings negativos."
                                }
                              ],
                              "practicalExample": "Em um dataset de 500 projetos de infraestrutura, valide fatores como 'Custo Eficiência' (loadings altos em CAPEX, OPEX) e 'Risco Ambiental'. Calcule Cronbach's alpha=0.82, confirme via 5-fold CV (congruência=0.91), interprete como preditor de ROI >15%.",
                              "finalVerifications": [
                                "Cronbach's alpha >0.7 para todos fatores.",
                                "KMO >0.6 e Bartlett p<0.05.",
                                "Cross-validation congruence >0.85.",
                                "Communalities médias >0.5.",
                                "Loadings principais >0.4 sem cross-loadings >0.3.",
                                "Interpretação alinhada com contexto econômico (ex: fatores predizem NPV)."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos (alfa, loadings, CV metrics) - 30%.",
                                "Qualidade da validação (múltiplos métodos usados) - 25%.",
                                "Profundidade da interpretação contextual - 20%.",
                                "Relato claro com visuals e limitações - 15%.",
                                "Tratamento de erros comuns e pressupostos - 10%."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses em Bartlett/KMO.",
                                "Engenharia Econômica: Aplicação de fatores em modelos de decisão (NPV, BCR).",
                                "Machine Learning: Validação cruzada similar a feature selection.",
                                "Psicometria: Confiabilidade alfa aplicada a constructs econômicos."
                              ],
                              "realWorldApplication": "Em consultorias de engenharia, validar fatores de risco em portfólios de projetos para otimizar alocação de capital, reduzindo perdas em 20% via identificação de clusters instáveis de variáveis econômicas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.6.6.3",
                        "name": "Aplicações em Engenharia",
                        "description": "Integração de PCA e análise fatorial em problemas reais de engenharia, como análise de dados de sistemas de controle e séries temporais econométricas, com referência a métodos de mínimos quadrados e ARIMA.",
                        "specificSkills": [
                          {
                            "id": "10.1.6.6.3.1",
                            "name": "Aplicar PCA e fatorial em sistemas de controle",
                            "description": "Usar PCA para redução de ruído em dados de sensores de sistemas dinâmicos (ex.: diagramas de Bode), integrando com modelagem econométrica para previsão de custos operacionais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coleta e Exploração Inicial de Dados de Sensores",
                                  "subSteps": [
                                    "Coletar dados multivariados de sensores em sistemas dinâmicos, como acelerômetros e giroscópios em um drone ou motor industrial.",
                                    "Realizar estatísticas descritivas: média, variância, correlações e visualizações (scatter plots, heatmaps).",
                                    "Identificar ruído e outliers usando boxplots e testes estatísticos (e.g., Z-score).",
                                    "Normalizar os dados (z-score ou min-max) para preparar para PCA.",
                                    "Documentar características do sistema dinâmico, incluindo equações de estado."
                                  ],
                                  "verification": "Dados explorados mostram correlações altas (>0.7) e ruído quantificado (e.g., 20% de variância atribuída a ruído).",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python com pandas, numpy, matplotlib/seaborn",
                                    "Dataset de sensores reais ou simulado (e.g., de Kaggle)"
                                  ],
                                  "tips": "Sempre plote os dados brutos primeiro para visualizar padrões dinâmicos.",
                                  "learningObjective": "Compreender a estrutura de dados ruidosos em sistemas de controle e prepará-los adequadamente.",
                                  "commonMistakes": [
                                    "Ignorar normalização, levando a componentes distorcidos",
                                    "Não detectar outliers, poluindo a análise"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicação de PCA para Redução de Ruído e Dimensionalidade",
                                  "subSteps": [
                                    "Implementar PCA usando scikit-learn: fit_transform nos dados normalizados.",
                                    "Selecionar número de componentes principais via scree plot ou critério de Kaiser (eigenvalues >1).",
                                    "Projetar dados no espaço reduzido e reconstruir para filtrar ruído (inverso PCA).",
                                    "Avaliar variância explicada cumulativa (alvo: >85-95%).",
                                    "Visualizar componentes principais em relação a diagramas de Bode iniciais."
                                  ],
                                  "verification": "Variância explicada >90% com redução de dimensionalidade de 50% ou mais.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Scikit-learn (PCA module)",
                                    "Jupyter Notebook para visualizações"
                                  ],
                                  "tips": "Use cross-validation para robustez em dados dinâmicos.",
                                  "learningObjective": "Dominar PCA como ferramenta de redução de ruído em sinais de sensores dinâmicos.",
                                  "commonMistakes": [
                                    "Escolher poucos componentes, perdendo informação",
                                    "Não validar variância explicada"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Realização de Análise Fatorial nos Componentes Principais",
                                  "subSteps": [
                                    "Aplicar Análise Fatorial (FA) nos scores de PCA usando Maximum Likelihood ou Principal Axis.",
                                    "Determinar número de fatores via eigenvalues e scree plot.",
                                    "Rotacionar fatores (Varimax) para interpretabilidade.",
                                    "Interpretar loadings: mapear fatores a variáveis físicas (e.g., fator 1 = vibração).",
                                    "Calcular scores fatoriais para cada observação."
                                  ],
                                  "verification": "Fatores interpretáveis com loadings >0.6 e comunalidades >0.5.",
                                  "estimatedTime": "1.5-2 horas",
                                  "materials": [
                                    "Scikit-learn (FactorAnalysis) ou factor_analyzer library"
                                  ],
                                  "tips": "Integre conhecimento de domínio para nomear fatores.",
                                  "learningObjective": "Extrair fatores latentes de dados reduzidos para modelagem de sistemas de controle.",
                                  "commonMistakes": [
                                    "Não rotacionar, resultando em fatores ambíguos",
                                    "Sobre-extração de fatores"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integração com Modelagem Econométrica e Previsão de Custos",
                                  "subSteps": [
                                    "Construir modelo econométrico (e.g., ARIMA ou VAR) usando scores fatoriais como preditores.",
                                    "Incorporar respostas de frequência via diagramas de Bode dos fatores (FFT nos scores).",
                                    "Treinar modelo para prever custos operacionais (e.g., manutenção baseada em degradação).",
                                    "Validar com métricas (MAE, RMSE) e análise de resíduos.",
                                    "Gerar previsões e simular cenários de controle."
                                  ],
                                  "verification": "Modelo prevê custos com RMSE <10% em conjunto de teste.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Statsmodels para ARIMA/VAR",
                                    "Control library para Bode plots"
                                  ],
                                  "tips": "Use lags baseados em dinâmica do sistema (e.g., ordem do Bode).",
                                  "learningObjective": "Integrar análise multivariada com econometria para aplicações em engenharia de controle.",
                                  "commonMistakes": [
                                    "Ignorar autocorrelação nos resíduos",
                                    "Não alinhar escalas de tempo"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validação Final e Interpretação em Sistemas de Controle",
                                  "subSteps": [
                                    "Comparar dados originais vs. reconstruídos (erro de reconstrução <5%).",
                                    "Analisar estabilidade via Bode plots dos fatores filtrados.",
                                    "Simular feedback de controle usando fatores para otimização.",
                                    "Documentar pipeline completo e sensibilidade a hiperparâmetros.",
                                    "Preparar relatório com insights acionáveis."
                                  ],
                                  "verification": "Pipeline end-to-end reduz ruído efetivamente e previsões precisas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Matplotlib para plots de Bode",
                                    "Relatório template"
                                  ],
                                  "tips": "Teste com dados out-of-sample para generalização.",
                                  "learningObjective": "Validar e interpretar resultados holisticamente em contextos reais de controle.",
                                  "commonMistakes": [
                                    "Sobreajuste no modelo econométrico",
                                    "Ignorar incertezas em previsões"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de turbina eólica, dados de sensores (vibração, temperatura, velocidade) com ruído são processados: PCA reduz de 20 para 5 componentes (95% variância), FA extrai 3 fatores (desgaste, turbulência, falha elétrica), integrados em VAR para prever custos de manutenção via Bode plots mostrando picos de ressonância preditivos.",
                              "finalVerifications": [
                                "PCA captura >90% variância com redução dimensional efetiva.",
                                "Fatores da FA são interpretáveis e comunalidades >0.6.",
                                "Modelo econométrico tem resíduos estacionários (ADF test p<0.05).",
                                "Bode plots filtrados mostram atenuação de ruído >20dB.",
                                "Previsões de custos alinhadas com dados históricos (erro <15%).",
                                "Pipeline reproduzível em novo dataset."
                              ],
                              "assessmentCriteria": [
                                "Precisão da redução de ruído (MSE reconstruído < original).",
                                "Interpretabilidade dos fatores (loadings claros e nomeados).",
                                "Desempenho preditivo (R² >0.8 em custos).",
                                "Robustez a variações de dados (CV score estável).",
                                "Integração correta com diagramas de Bode.",
                                "Documentação completa do processo."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Métodos multivariados e testes de hipóteses.",
                                "Engenharia de Controle: Análise de frequência e estabilidade.",
                                "Economia: Modelagem econométrica e previsão de séries temporais.",
                                "Machine Learning: Redução dimensional e feature engineering.",
                                "Física: Dinâmica de sistemas e sinais ruidosos."
                              ],
                              "realWorldApplication": "Manutenção preditiva em indústrias (e.g., aeroespacial, automotiva), reduzindo custos operacionais em 20-30% ao prever falhas em sistemas de controle via sensores limpos, como em fábricas inteligentes ou veículos autônomos."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.6.6.3.2",
                            "name": "Analisar dados econométricos multivariados",
                            "description": "Combinar PCA/fatorial com regressão em grandes amostras e cointegração para análise de eficiência em processos de engenharia, testando hipóteses e selecionando modelos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coleta e Preparação de Dados Multivariados",
                                  "subSteps": [
                                    "Identificar e coletar dados de grandes amostras relevantes para eficiência em processos de engenharia (ex.: sensores IoT, logs de produção).",
                                    "Limpar dados: tratar missing values, outliers e multicolinearidade inicial usando testes como VIF.",
                                    "Normalizar/escalar dados para adequação a PCA e regressão (z-score ou min-max).",
                                    "Explorar correlações iniciais com heatmap e matriz de correlação.",
                                    "Dividir dados em treino/teste (80/20) para validação cruzada."
                                  ],
                                  "verification": "Dataset limpo salvo em formato CSV/Parquet com relatório de summary statistics sem erros de NaN ou inf.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Software R/Python (pandas, numpy, scikit-learn)",
                                    "Dados de exemplo de processos industriais (Kaggle ou simulados)",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Use pipelines automatizados no Python para reproducibilidade; sempre documente transformações.",
                                  "learningObjective": "Preparar dados econométricos robustos para análises multivariadas sem viés.",
                                  "commonMistakes": [
                                    "Ignorar multicolinearidade levando a instabilidade",
                                    "Não normalizar causando dominância de escalas",
                                    "Subamostragem inadequada distorcendo representatividade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicação de PCA ou Análise Fatorial para Redução Dimensional",
                                  "subSteps": [
                                    "Selecionar método: PCA para variância máxima ou Fatorial para fatores latentes baseados em teoria de eficiência.",
                                    "Calcular componentes/fatores com bibliotecas (sklearn.decomposition.PCA ou factanal no R).",
                                    "Determinar número de componentes via scree plot, Kaiser criterion (eigen >1) e variância explicada (>70%).",
                                    "Rotacionar componentes (varimax) para interpretabilidade.",
                                    "Projetar dados originais nos novos componentes e validar com biplot."
                                  ],
                                  "verification": "Scree plot gerado mostrando cumulativa variância >75%; componentes nomeados com loadings >0.7.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Bibliotecas: scikit-learn (PCA), factor_analyzer (Python), ou factoextra (R)",
                                    "Dados preparados do Step 1"
                                  ],
                                  "tips": "Priorize interpretabilidade sobre variância pura; valide com cross-loadings baixos.",
                                  "learningObjective": "Reduzir dimensionalidade preservando informação essencial para modelagem posterior.",
                                  "commonMistakes": [
                                    "Escolher demais componentes inflando ruído",
                                    "Não rotacionar obscurecendo interpretações",
                                    "Ignorar pressupostos de normalidade nos resíduos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Modelagem de Regressão Multivariada com Dados Reduzidos",
                                  "subSteps": [
                                    "Especificar modelo: regressão OLS/MLE com componentes PCA como preditores e eficiência (ex.: OEE) como dependente.",
                                    "Ajustar modelo com statsmodels (Python) ou lm() (R), incluindo termos de interação se necessário.",
                                    "Diagnosticar resíduos: testes de normalidade (Shapiro), homocedasticidade (Breusch-Pagan) e autocorrelação (Durbin-Watson).",
                                    "Corrigir violações (ex.: robust SE ou transformações).",
                                    "Interpretar coeficientes padronizados e R² ajustado."
                                  ],
                                  "verification": "Modelo ajustado com p-values <0.05 para preditores chave e R² >0.6; plots de resíduos normais.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "statsmodels, lmtest (R)",
                                    "Dados reduzidos do Step 2"
                                  ],
                                  "tips": "Use stepwise selection para variáveis; sempre cheque multicolinearidade pós-PCA.",
                                  "learningObjective": "Construir modelos regressivos estáveis para prever eficiência em processos.",
                                  "commonMistakes": [
                                    "Overfitting sem validação cruzada",
                                    "Ignorar heterocedasticidade invalidando inferências",
                                    "Má interpretação de coeficientes não padronizados"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Teste de Cointegração para Relações de Longo Prazo",
                                  "subSteps": [
                                    "Testar estacionariedade unitária (ADF/KPSS) em séries temporais multivariadas.",
                                    "Aplicar teste Johansen para cointegração (trace/max eigenvalue) com lags via AIC/BIC.",
                                    "Estimar vetor de cointegração e ECM (Error Correction Model) se cointegradas.",
                                    "Interpretar ajuste de erro e velocidades de correção.",
                                    "Integrar resultados com regressão para análise dinâmica de eficiência."
                                  ],
                                  "verification": "Matriz de cointegração com estatísticas Johansen significativas (p<0.05); ECM com half-life < período relevante.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Bibliotecas: arch (Python), urca (R)",
                                    "Séries temporais dos dados originais"
                                  ],
                                  "tips": "Confirme ordem de integração I(1); use VECM se múltiplas relações.",
                                  "learningObjective": "Detectar e modelar equilíbrios de longo prazo em dados econométricos de engenharia.",
                                  "commonMistakes": [
                                    "Testar cointegração sem estacionariedade",
                                    "Escolha errada de lags inflando testes",
                                    "Confundir cointegração com correlação espúria"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Teste de Hipóteses, Seleção de Modelo e Análise de Eficiência",
                                  "subSteps": [
                                    "Formular hipóteses (ex.: H0: componentes não afetam eficiência).",
                                    "Realizar testes F/Wald/LRT e seleções (AIC/BIC, LASSO para robustez).",
                                    "Avaliar eficiência via scores de frontier (DEA integrada se aplicável).",
                                    "Simular cenários e prever impactos em processos de engenharia.",
                                    "Gerar relatório com visualizações (coefplots, forecasts)."
                                  ],
                                  "verification": "Modelo final selecionado com menor AIC; todas hipóteses testadas com conclusões claras.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Bibliotecas: AICc (seleção), matplotlib/seaborn para plots",
                                    "Modelos dos steps anteriores"
                                  ],
                                  "tips": "Compare múltiplos modelos com tabela de critérios; foque em parcimônia.",
                                  "learningObjective": "Validar e selecionar o melhor modelo para insights acionáveis em eficiência.",
                                  "commonMistakes": [
                                    "Testes múltiplos sem correção Bonferroni",
                                    "Seleção por R² alto ignorando overfitting",
                                    "Falta de interpretação contextual para engenharia"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de automóveis, analise dados de 10.000 ciclos de produção (variáveis: tempo máquina, energia, defeitos, throughput). Use PCA para reduzir 20 sensores a 5 componentes, regresse contra OEE, teste cointegração entre throughput e energia para detectar desvios de longo prazo, e selecione modelo confirmando hipótese de ineficiência por sobrecarga energética.",
                              "finalVerifications": [
                                "Variância explicada por PCA/fatorial >75%.",
                                "Regressão com R² ajustado >0.65 e resíduos normais.",
                                "Teste Johansen confirma cointegração com p<0.05.",
                                "Modelo selecionado via AIC/BIC com previsões validadas em hold-out.",
                                "Relatório interpreta eficiência com recomendações práticas.",
                                "Simulações mostram redução de 10-20% em ineficiências."
                              ],
                              "assessmentCriteria": [
                                "Precisão estatística: todos testes com p-values apropriados e diagnósticos passados.",
                                "Robustez: modelo estável em validação cruzada e sensibilidade.",
                                "Interpretabilidade: componentes e coeficientes ligados a conceitos de engenharia.",
                                "Eficiência computacional: execução em <10h para grandes amostras.",
                                "Reprodutibilidade: código versionado com seeds e dados mock.",
                                "Impacto prático: insights quantificáveis para otimização de processos."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Processos: Otimização lean e Six Sigma.",
                                "Economia: Análise de eficiência produtiva e frontier analysis.",
                                "Machine Learning: Redução dimensional e feature engineering.",
                                "Programação Estatística: R/Python para econometria.",
                                "Gestão Industrial: KPIs de performance e previsão de falhas."
                              ],
                              "realWorldApplication": "Otimizações em indústrias como manufatura, energia e logística, onde grandes datasets de sensores revelam ineficiências ocultas, permitindo reduções de custo (ex.: 15% em energia via ajustes baseados em cointegração) e manutenção preditiva em linhas de produção."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              },
              {
                "id": "10.1.7",
                "name": "Aplicações em Análise de Dados em Engenharia",
                "description": "Foca na aplicação prática dos métodos em análise de dados no contexto de engenharia.",
                "totalSkills": 48,
                "atomicTopics": [
                  {
                    "id": "10.1.7.1",
                    "name": "Regressão Linear em Engenharia",
                    "description": "Aplicação prática de regressão linear e mínimos quadrados ordinários para modelagem de processos de engenharia.",
                    "individualConcepts": [
                      {
                        "id": "10.1.7.1.1",
                        "name": "Modelo de Regressão Linear",
                        "description": "Formulação matemática do modelo de regressão linear simples e múltipla, adaptado à modelagem de processos de engenharia, como previsão de desempenho de materiais ou eficiência de sistemas.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.1.1.1",
                            "name": "Especificar modelo de regressão linear para problemas de engenharia",
                            "description": "Identificar variável dependente (ex.: taxa de falha em um processo) e independentes (ex.: temperatura, pressão), escrevendo a equação Y = β0 + β1X1 + ... + ε, com interpretação contextual em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o problema de engenharia e coletar dados iniciais",
                                  "subSteps": [
                                    "Analise o contexto do problema de engenharia, como otimização de processos ou previsão de falhas.",
                                    "Identifique o fenômeno principal a ser modelado (ex.: taxa de falha, eficiência energética).",
                                    "Reúna dados históricos disponíveis, incluindo medições de fatores ambientais ou operacionais.",
                                    "Liste potenciais variáveis influenciadoras baseadas em conhecimento de domínio de engenharia.",
                                    "Documente suposições iniciais sobre relações lineares entre variáveis."
                                  ],
                                  "verification": "Crie um diagrama conceitual do problema com variáveis anotadas e valide com um colega ou supervisor.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Papel e caneta ou software de diagramação (ex.: Draw.io)",
                                    "Dados históricos do processo (planilhas Excel ou CSV)"
                                  ],
                                  "tips": "Comece pelo 'porquê' do problema: o que se quer prever e por quê?",
                                  "learningObjective": "Ao final, o aluno compreenderá o escopo do problema e identificará fontes de dados relevantes.",
                                  "commonMistakes": [
                                    "Ignorar variáveis qualitativas que podem ser quantificadas",
                                    "Não considerar o domínio físico do problema"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar variável dependente (Y) e independentes (X1, X2, ...)",
                                  "subSteps": [
                                    "Defina claramente a variável dependente Y como o resultado a ser previsto (ex.: taxa de falha em %).",
                                    "Selecione variáveis independentes Xi com base em causalidade física (ex.: temperatura, pressão).",
                                    "Justifique a escolha com evidências teóricas ou empíricas de engenharia.",
                                    "Verifique multicolinearidade inicial entre Xs usando gráficos de dispersão.",
                                    "Limite a 2-4 Xs iniciais para simplicidade no modelo linear."
                                  ],
                                  "verification": "Escreva uma tabela com Y, Xs, justificativa e unidade de medida para cada.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Planilha Excel ou Python (pandas para gráficos)",
                                    "Literatura técnica de engenharia"
                                  ],
                                  "tips": "Pergunte: 'Esta variável afeta diretamente o resultado?' para priorizar Xs relevantes.",
                                  "learningObjective": "Ao final, o aluno selecionará corretamente Y e Xs com justificativa contextual.",
                                  "commonMistakes": [
                                    "Confundir causa e efeito (ex.: tratar falha como Xi)",
                                    "Incluir variáveis irrelevantes sem justificativa"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Especificar a equação do modelo de regressão linear",
                                  "subSteps": [
                                    "Escreva a forma geral: Y = β0 + β1X1 + β2X2 + ... + βkXk + ε.",
                                    "Atribua símbolos específicos: ex.: TaxaFalha = β0 + β1Temperatura + β2Pressao + ε.",
                                    "Defina o significado de cada βi (coeficiente de inclinação) e β0 (intercepto).",
                                    "Inclua o termo de erro ε para representar variabilidade não explicada.",
                                    "Teste a equação com dados fictícios para validar sintaxe."
                                  ],
                                  "verification": "Escreva a equação completa em LaTeX ou texto e simule valores para βs.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Editor de texto ou Jupyter Notebook",
                                    "Calculadora"
                                  ],
                                  "tips": "Use notação consistente: Y maiúsculo para dependente, X minúsculo para independentes.",
                                  "learningObjective": "Ao final, o aluno formulará a equação precisa do modelo.",
                                  "commonMistakes": [
                                    "Esquecer o termo de erro ε",
                                    "Usar notação incorreta para coeficientes"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar o modelo no contexto de engenharia",
                                  "subSteps": [
                                    "Explique β0: valor basal de Y quando todas Xs=0 (verificar viabilidade física).",
                                    "Interprete β1, β2 etc.: mudança em Y por unidade de mudança em Xi, ceteris paribus.",
                                    "Discuta implicações práticas: ex.: 'a cada 10°C, taxa de falha aumenta 2%'.",
                                    "Avalie limitações: linearidade assumida, intervalo de validade das Xs.",
                                    "Proponha próximos passos: ajuste e validação com dados reais."
                                  ],
                                  "verification": "Redija um parágrafo de interpretação com exemplos numéricos hipotéticos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Exemplos de relatórios de engenharia",
                                    "Software de regressão (ex.: scikit-learn)"
                                  ],
                                  "tips": "Sempre relacione βs a unidades físicas para relevância em engenharia.",
                                  "learningObjective": "Ao final, o aluno interpretará coeficientes com significado prático.",
                                  "commonMistakes": [
                                    "Interpretar β fora do contexto físico",
                                    "Ignorar que β mede efeito marginal"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma usina hidrelétrica, especifique o modelo para prever a eficiência η de uma turbina: η = β0 + β1Vazão + β2Rotação + ε, onde η é a eficiência (%), Vazão em m³/s e Rotação em RPM. Interpretação: β1 indica como a vazão afeta a eficiência.",
                              "finalVerifications": [
                                "Identifica corretamente Y e pelo menos 2 Xs relevantes para um problema dado.",
                                "Escreve a equação completa com termo de erro.",
                                "Fornece interpretação física de todos os βs.",
                                "Justifica escolhas com contexto de engenharia.",
                                "Reconhece limitações do modelo linear.",
                                "Propõe verificação com dados reais."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de variáveis (30%)",
                                "Correção da equação matemática (25%)",
                                "Qualidade da interpretação contextual (20%)",
                                "Justificativas baseadas em engenharia (15%)",
                                "Clareza e completude da documentação (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Conceitos de inferência e testes de significância.",
                                "Programação: Implementação em Python/R para ajuste do modelo.",
                                "Engenharia Mecânica: Aplicações em otimização de processos industriais.",
                                "Física: Relações causais baseadas em leis fundamentais.",
                                "Gestão de Projetos: Integração em análises de risco e manutenção preditiva."
                              ],
                              "realWorldApplication": "Em indústrias petroquímicas, especificar modelos para prever desgaste de equipamentos baseado em variáveis operacionais, permitindo manutenção preditiva e redução de downtime em até 20%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.1.1.2",
                            "name": "Interpretar coeficientes de regressão",
                            "description": "Explicar o significado de βj como variação na resposta para unidade de mudança em Xj, ceteris paribus, com exemplos como impacto da carga em deformação estrutural.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar o modelo de regressão linear e identificar coeficientes",
                                  "subSteps": [
                                    "Escreva a equação geral do modelo de regressão linear: Y = β₀ + β₁X₁ + β₂X₂ + ... + βⱼXⱼ + ε.",
                                    "Identifique β₀ como o intercepto (valor esperado de Y quando todas X=0).",
                                    "Destaque os coeficientes βⱼ como os parâmetros de inclinação para cada preditor Xⱼ.",
                                    "Discuta o papel do erro ε na equação.",
                                    "Visualize graficamente um modelo simples univariado para fixar a ideia."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o que cada βⱼ representa na equação, usando um exemplo simples.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Papel e caneta ou editor de texto",
                                    "Gráfico de regressão linear de exemplo (de um livro ou online)"
                                  ],
                                  "tips": "Comece com um modelo univariado (uma X) para simplificar antes de múltiplas variáveis.",
                                  "learningObjective": "Compreender a estrutura matemática do modelo e localizar os coeficientes βⱼ.",
                                  "commonMistakes": [
                                    "Confundir βⱼ com a média de Xⱼ",
                                    "Ignorar o termo de erro ε",
                                    "Pensar que β₀ é sempre zero"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar o significado individual de um coeficiente βⱼ",
                                  "subSteps": [
                                    "Defina βⱼ como a variação esperada na variável resposta Y para uma mudança de uma unidade em Xⱼ.",
                                    "Calcule um exemplo numérico: se β₁ = 2.5, uma unidade extra em X₁ aumenta Y em 2.5 unidades.",
                                    "Considere as unidades: verifique se as unidades de βⱼ fazem sentido (ex: mm/kN).",
                                    "Diferencie de correlação: βⱼ mede efeito médio, não força da relação.",
                                    "Pratique com 2-3 coeficientes fictícios, escrevendo interpretações em linguagem natural."
                                  ],
                                  "verification": "Escreva 3 interpretações corretas de βⱼ hipotéticos, incluindo unidades e direção do efeito.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Calculadora",
                                    "Tabela de coeficientes de exemplo de regressão"
                                  ],
                                  "tips": "Sempre inclua 'aumento/diminuição' baseado no sinal de βⱼ (positivo/negativo).",
                                  "learningObjective": "Traduzir valores numéricos de βⱼ em declarações interpretativas claras.",
                                  "commonMistakes": [
                                    "Interpretar βⱼ como mudança total em Y, não marginal",
                                    "Ignorar o sinal do coeficiente",
                                    "Confundir com percentual de mudança"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Incorporar o conceito de 'ceteris paribus' na interpretação",
                                  "subSteps": [
                                    "Explique 'ceteris paribus' como 'mantendo todas as outras variáveis constantes'.",
                                    "Ilustre com um modelo bivariado: mudança em X₁ com X₂ fixo.",
                                    "Simule numericamente: calcule Y para Xⱼ=0 e Xⱼ=1, fixando outras X.",
                                    "Discuta por que isso é crucial em modelos multivariados (controle de confundidores).",
                                    "Compare interpretações com e sem ceteris paribus para um exemplo."
                                  ],
                                  "verification": "Descreva como βⱼ muda se ignorarmos ceteris paribus, usando um contraexemplo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Software como Excel, R ou Python com dataset bivariado",
                                    "Dataset exemplo com 2 preditores"
                                  ],
                                  "tips": "Use tabelas para mostrar valores de Y fixando variáveis para visualizar o isolamento.",
                                  "learningObjective": "Aplicar ceteris paribus para interpretações precisas e evitar vieses.",
                                  "commonMistakes": [
                                    "Assumir que βⱼ captura efeito total sem controle",
                                    "Confundir com causalidade absoluta",
                                    "Esquecer interações entre variáveis"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Praticar interpretação com exemplos reais em engenharia",
                                  "subSteps": [
                                    "Carregue um dataset de engenharia (ex: carga vs. deformação em vigas).",
                                    "Ajuste o modelo de regressão e extraia coeficientes βⱼ.",
                                    "Interprete cada βⱼ com ceteris paribus, focando em impacto prático.",
                                    "Valide com predições: preveja Y para cenários específicos.",
                                    "Documente em um relatório curto com gráficos de resíduos para confiança."
                                  ],
                                  "verification": "Gere um relatório de 1 página interpretando todos βⱼ de um modelo ajustado.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Software R/Python/Jupyter",
                                    "Dataset público de regressão em engenharia (ex: de Kaggle)"
                                  ],
                                  "tips": "Verifique significância estatística (p-value < 0.05) antes de interpretar.",
                                  "learningObjective": "Integrar interpretação em contextos aplicados, preparando para análise real.",
                                  "commonMistakes": [
                                    "Interpretar coeficientes não-significativos como definitivos",
                                    "Ignorar suposições da regressão (linearidade, etc.)",
                                    "Generalizar demais sem contexto"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão para deformação estrutural em vigas de concreto: Deformação (mm) = 0.1 + 0.05 * Carga (kN) + 0.02 * Comprimento (m) + ε. O β_carga = 0.05 significa que, ceteris paribus (comprimento fixo), cada kN adicional de carga aumenta a deformação em 0.05 mm, ajudando engenheiros a prever limites de segurança.",
                              "finalVerifications": [
                                "Explique βⱼ em palavras simples para um não-especialista.",
                                "Calcule e interprete a mudança em Y para ΔXⱼ=1, fixando outras variáveis.",
                                "Identifique cenários onde ceteris paribus não se aplica (ex: multicolinearidade).",
                                "Ajuste um modelo simples e interprete todos coeficientes corretamente.",
                                "Discuta limitações da interpretação (correlação vs. causalidade).",
                                "Preveja Y para um novo conjunto de X e justifique com βⱼ."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição de βⱼ como mudança marginal (90% correto).",
                                "Uso consistente de ceteris paribus em todas interpretações.",
                                "Inclusão de unidades e sinal do efeito em exemplos.",
                                "Aplicação correta em datasets reais sem erros de software.",
                                "Clareza e concisão na linguagem interpretativa.",
                                "Reconhecimento de suposições e limitações do modelo."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de significância e intervalos de confiança para βⱼ.",
                                "Engenharia Civil/Mecânica: Aplicações em análise estrutural e otimização.",
                                "Programação: Uso de bibliotecas como scikit-learn (Python) ou lm() (R).",
                                "Econometria: Interpretações semelhantes em modelos de demanda.",
                                "Machine Learning: Feature importance em regressão como precursor."
                              ],
                              "realWorldApplication": "Engenheiros usam isso para quantificar como variáveis como carga, temperatura ou material afetam desempenho estrutural, prevendo falhas em pontes ou edifícios; em manufatura, otimiza processos prevendo defeitos baseados em parâmetros de produção."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.1.1.3",
                            "name": "Formular hipóteses em modelagem de engenharia",
                            "description": "Definir hipóteses nulas e alternativas para relevância de preditoras em contextos como otimização de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Identificar o contexto de engenharia e preditores relevantes",
                                  "subSteps": [
                                    "Analise o problema de otimização industrial, como eficiência de produção.",
                                    "Liste os preditores potenciais (ex.: temperatura, pressão, tempo de ciclo).",
                                    "Defina a variável resposta (ex.: taxa de defeitos).",
                                    "Colete dados iniciais ou descreva o dataset.",
                                    "Documente premissas do modelo de regressão linear."
                                  ],
                                  "verification": "Lista de preditores e variável resposta documentada com justificativa contextual.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dataset de processos industriais (ex.: CSV com dados de fábrica), planilha ou notebook Jupyter.",
                                  "tips": "Priorize preditores com base em conhecimento de domínio da engenharia.",
                                  "learningObjective": "Compreender a relação entre preditores e o problema de engenharia.",
                                  "commonMistakes": "Ignorar correlações entre preditores ou escolher variáveis irrelevantes."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Formular a hipótese nula (H0)",
                                  "subSteps": [
                                    "Estabeleça H0: o coeficiente do preditor é igual a zero (β = 0).",
                                    "Explique que isso significa que o preditor não tem relevância estatística.",
                                    "Adapte ao contexto: 'A temperatura não afeta a taxa de defeitos'.",
                                    "Escreva a notação matemática formal: H0: β_i = 0.",
                                    "Verifique consistência com o modelo de regressão linear."
                                  ],
                                  "verification": "H0 escrita em linguagem natural e matemática, ligada ao preditor específico.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Folha de papel ou editor de texto, referências de estatística básica.",
                                  "tips": "Sempre use linguagem clara para engenheiros não-estatísticos.",
                                  "learningObjective": "Definir corretamente a ausência de efeito do preditor.",
                                  "commonMistakes": "Confundir H0 com igualdade a um valor diferente de zero."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Formular a hipótese alternativa (H1)",
                                  "subSteps": [
                                    "Defina H1: o coeficiente do preditor é diferente de zero (β ≠ 0).",
                                    "Especifique direção se aplicável (ex.: β > 0 para efeito positivo).",
                                    "Contextualize: 'A temperatura afeta significativamente a taxa de defeitos'.",
                                    "Escreva a notação: H1: β_i ≠ 0 (ou unilateral).",
                                    "Justifique com base em teoria de engenharia ou dados preliminares."
                                  ],
                                  "verification": "H1 contrastante com H0, com justificativa contextual e notação correta.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Mesmo do step anterior, gráficos exploratórios de dados.",
                                  "tips": "Considere testes unilaterais em contextos de otimização direcionada.",
                                  "learningObjective": "Articular o efeito esperado do preditor.",
                                  "commonMistakes": "Fazer H1 idêntica ou redundante à H0."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e documentar as hipóteses para teste",
                                  "subSteps": [
                                    "Revise H0 e H1 quanto a clareza, correção e relevância.",
                                    "Defina nível de significância (α = 0.05) e tipo de teste (t-test).",
                                    "Prepare script para teste futuro em software.",
                                    "Discuta implicações de rejeitar/aceitar H0 no processo industrial.",
                                    "Registre em relatório com diagrama de modelo."
                                  ],
                                  "verification": "Documento completo com H0, H1, α e plano de teste pronto.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python/R com bibliotecas statsmodels ou lmtest, template de relatório.",
                                  "tips": "Use visualizações para ilustrar hipóteses.",
                                  "learningObjective": "Integrar hipóteses ao fluxo completo de modelagem.",
                                  "commonMistakes": "Esquecer de especificar o nível de significância."
                                }
                              ],
                              "practicalExample": "Em uma fábrica de automóveis, para otimizar o tempo de soldagem (resposta), teste se a pressão do soldador (preditor) é relevante: H0: β_pressão = 0 (não afeta tempo); H1: β_pressão ≠ 0 (afeta, permitindo ajuste para reduzir tempo em 10%).",
                              "finalVerifications": [
                                "H0 e H1 estão matematicamente corretas e contrastantes.",
                                "Hipóteses são específicas ao preditor e contexto de engenharia.",
                                "Nível de significância e tipo de teste definidos.",
                                "Justificativas baseadas em domínio industrial fornecidas.",
                                "Preparação para teste estatístico (p-value) explícita.",
                                "Implicações práticas para otimização documentadas."
                              ],
                              "assessmentCriteria": [
                                "Clareza e precisão na redação das hipóteses (linguagem e matemática).",
                                "Relevância contextual à engenharia e preditores escolhidos.",
                                "Consistência estatística com regressão linear.",
                                "Profundidade de justificativa e implicações.",
                                "Completude da documentação e plano de teste.",
                                "Ausência de erros comuns como confusão entre H0/H1."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e p-values.",
                                "Engenharia Industrial: Otimização de processos e DOE.",
                                "Programação: Implementação em Python/R para regressão.",
                                "Matemática: Álgebra linear em modelos de regressão."
                              ],
                              "realWorldApplication": "Em indústrias como manufatura ou óleo/gás, formular hipóteses permite testar se variáveis como temperatura ou velocidade impactam eficiência, guiando otimizações que reduzem custos em milhões anualmente."
                            },
                            "estimatedTime": "0.5 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.1.2",
                        "name": "Método dos Mínimos Quadrados Ordinários (MQO)",
                        "description": "Princípios do MQO para estimação de parâmetros, minimizando a soma dos quadrados dos resíduos, com aplicação prática em dados de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.1.2.1",
                            "name": "Calcular estimadores MQO em regressão simples",
                            "description": "Derivar e computar β0 e β1 manualmente para dados de engenharia, como relação entre tensão e deformação em testes mecânicos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e organizar o conjunto de dados",
                                  "subSteps": [
                                    "Selecione um conjunto de dados relevante de engenharia, como deformação (x) e tensão (y) de testes mecânicos.",
                                    "Liste os pares (x_i, y_i) em uma tabela organizada.",
                                    "Verifique a ausência de valores ausentes ou outliers iniciais.",
                                    "Defina n como o número de observações.",
                                    "Registre unidades (ex: x em m/m, y em MPa)."
                                  ],
                                  "verification": "Tabela de dados completa e organizada em planilha ou papel, com n definido.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Planilha Excel ou papel e lápis",
                                    "Dados de exemplo: x = [0, 0.001, 0.002, 0.003, 0.004], y = [0, 52, 105, 152, 205]"
                                  ],
                                  "tips": "Use dados lineares reais para melhor compreensão; comece com n=5 para simplicidade.",
                                  "learningObjective": "Organizar dados experimentais de forma estruturada para análise MQO.",
                                  "commonMistakes": [
                                    "Ignorar unidades inconsistentes",
                                    "Confundir variáveis independentes (x) e dependentes (y)",
                                    "Incluir dados não lineares sem justificativa"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular as somas estatísticas básicas",
                                  "subSteps": [
                                    "Calcule sum(x) somando todos os x_i.",
                                    "Calcule sum(y) somando todos os y_i.",
                                    "Calcule sum(xy) multiplicando cada par x_i * y_i e somando.",
                                    "Calcule sum(x²) elevando cada x_i ao quadrado e somando.",
                                    "Confirme n e todas as somas com uma segunda verificação aritmética."
                                  ],
                                  "verification": "Todas as quatro somas (Σx, Σy, Σxy, Σx²) calculadas corretamente e documentadas.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Calculadora ou Excel para somas",
                                    "Tabela de dados do Step 1"
                                  ],
                                  "tips": "Use fórmulas no Excel como =SOMA() e =SOMARPRODUTO() para agilizar.",
                                  "learningObjective": "Dominar o cálculo preciso de estatísticos descritivos necessários para MQO.",
                                  "commonMistakes": [
                                    "Erros de arredondamento precoce",
                                    "Confundir sum(xy) com sum(x)*sum(y)",
                                    "Esquecer de calcular sum(x²)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Derivar e calcular o estimador β1 (inclinação)",
                                  "subSteps": [
                                    "Lembre a fórmula: β1 = [n * Σ(xy) - Σx * Σy] / [n * Σ(x²) - (Σx)²].",
                                    "Calcule o numerador: n * Σ(xy) - Σx * Σy.",
                                    "Calcule o denominador: n * Σ(x²) - (Σx)².",
                                    "Divida numerador por denominador para obter β1.",
                                    "Arredonde β1 para 4 casas decimais e anote o significado físico (ex: módulo de elasticidade)."
                                  ],
                                  "verification": "β1 calculado corretamente (ex: 51000 para dados exemplo) com passos intermediários mostrados.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Fórmula anotada",
                                    "Resultados das somas do Step 2",
                                    "Calculadora"
                                  ],
                                  "tips": "Verifique se denominador > 0 (evita divisão por zero em dados colineares).",
                                  "learningObjective": "Aplicar a fórmula de MQO para β1 e entender sua derivação intuitiva (covariância/variância).",
                                  "commonMistakes": [
                                    "Inverter numerador e denominador",
                                    "Usar médias em vez de somas",
                                    "Arredondar demais nos intermediários"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Calcular o estimador β0 (intercepto)",
                                  "subSteps": [
                                    "Lembre a fórmula: β0 = [Σy - β1 * Σx] / n.",
                                    "Multiplique β1 por Σx.",
                                    "Subtraia esse valor de Σy.",
                                    "Divida pelo n para obter β0.",
                                    "Interprete β0 (ex: tensão inicial sem deformação)."
                                  ],
                                  "verification": "β0 calculado corretamente (ex: ≈0 para dados exemplo) com equação da reta y = β0 + β1 x.",
                                  "estimatedTime": "10 minutos",
                                  "materials": [
                                    "Resultados de β1 e somas anteriores",
                                    "Calculadora"
                                  ],
                                  "tips": "β0 pode ser zero em cenários físicos como lei de Hooke (σ = E ε).",
                                  "learningObjective": "Completar o modelo de regressão simples com o intercepto usando MQO.",
                                  "commonMistakes": [
                                    "Esquecer de dividir por n",
                                    "Usar β0 em vez de média de y",
                                    "Ignorar sinal de β1"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Verificar e interpretar os resultados",
                                  "subSteps": [
                                    "Calcule y_pred para cada x_i e compare com y_i reais.",
                                    "Compute SQE = Σ(y_i - y_pred_i)² (deve ser mínimo).",
                                    "Plote os pontos e a reta ajustada manualmente ou no Excel.",
                                    "Discuta limitações (ex: linearidade assumida).",
                                    "Salve o modelo para uso futuro."
                                  ],
                                  "verification": "Gráfico com reta ajustada e SQE baixo; interpretação escrita.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Excel ou papel para plot",
                                    "Valores de β0 e β1"
                                  ],
                                  "tips": "Use scatter plot no Excel para visualização rápida.",
                                  "learningObjective": "Validar o ajuste MQO e conectar com aplicações em engenharia.",
                                  "commonMistakes": [
                                    "Não verificar resíduos",
                                    "Assumir causalidade sem análise",
                                    "Ignorar suposições MQO (linearidade, homocedasticidade)"
                                  ]
                                }
                              ],
                              "practicalExample": "Dados de teste mecânico: deformação x = [0, 0.001, 0.002, 0.003, 0.004] (m/m), tensão y = [0, 52, 105, 152, 205] (MPa). Somatórios: Σx=0.01, Σy=514, Σxy=1.538, Σx²=0.00003, n=5. β1 = [5*1.538 - 0.01*514] / [5*0.00003 - 0.0001] = 2.55 / 0.00005 = 51000. β0 = [514 - 51000*0.01]/5 ≈ 0. Equação: y = 51000 x (módulo elástico ≈51 GPa).",
                              "finalVerifications": [
                                "Todas somas calculadas com precisão <0.1% de erro.",
                                "β1 e β0 coincidem com cálculo manual/verificação Excel.",
                                "Resíduos (y - y_pred) próximos de zero e sem padrão.",
                                "Gráfico mostra bom ajuste linear (R² >0.99 calculável).",
                                "Interpretação física correta (ex: rigidez material).",
                                "Fórmulas MQO recitadas corretamente."
                              ],
                              "assessmentCriteria": [
                                "Precisão aritmética nos cálculos (erro <1%).",
                                "Completude de todos substeps em cada step.",
                                "Demonstração de entendimento das fórmulas MQO.",
                                "Qualidade da verificação e plotagem.",
                                "Interpretação contextual em engenharia.",
                                "Identificação de pelo menos 2 suposições MQO."
                              ],
                              "crossCurricularConnections": [
                                "Física: Lei de Hooke (σ = E ε) e mecânica dos materiais.",
                                "Estatística: Covariância, variância e propriedades dos estimadores MQO.",
                                "Programação: Implementar em Python (numpy.polyfit) ou R.",
                                "Engenharia: Análise de fadiga e dimensionamento estrutural.",
                                "Matemática: Álgebra matricial para generalização múltipla."
                              ],
                              "realWorldApplication": "Em testes de tração de materiais, usa-se MQO para estimar módulo de Young (E=β1) a partir de curvas tensão-deformação, permitindo prever deformações sob cargas em pontes, aviões ou implantes médicos, otimizando designs e evitando falhas."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.7.1.2.2",
                            "name": "Implementar MQO em software como R",
                            "description": "Usar função lm() no R para ajustar modelo a dados reais de processos de engenharia, gerando sumário com coeficientes e estatísticas de ajuste.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente R e carregar dados reais de engenharia",
                                  "subSteps": [
                                    "Instalar e abrir RStudio ou console R",
                                    "Instalar pacotes essenciais: install.packages(c('ggplot2', 'dplyr'))",
                                    "Baixar ou criar dataset CSV com dados de processos de engenharia (ex: força de tração vs. corrente e voltagem em solda)",
                                    "Definir diretório de trabalho com setwd() e carregar dados com read.csv()",
                                    "Executar head() e str() para inspecionar estrutura dos dados"
                                  ],
                                  "verification": "Dataset carregado corretamente, visível com head(data) sem erros de encoding ou missing values iniciais",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "R/RStudio instalado",
                                    "Dataset CSV de exemplo (força_tração.csv com colunas: forca, corrente, voltagem)"
                                  ],
                                  "tips": "Use read.csv(file, stringsAsFactors = FALSE) para evitar problemas com fatores; verifique dimensões com dim(data)",
                                  "learningObjective": "Preparar ambiente computacional pronto para modelagem estatística com dados reais",
                                  "commonMistakes": [
                                    "Caminho de arquivo incorreto levando a erro 'file not found'",
                                    "Não instalar pacotes antes de library()",
                                    "Ignorar NAs nos dados"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explorar e preparar dados para ajuste do modelo MQO",
                                  "subSteps": [
                                    "Verificar missing values com summary() e is.na()",
                                    "Tratar outliers com boxplot() e remover ou imputar se necessário",
                                    "Criar data frame limpo com dplyr::filter() ou na.omit()",
                                    "Visualizar relações com plot(forca ~ corrente, data=data) e ggplot2 para scatterplots",
                                    "Verificar multicolinearidade básica com cor() ou pairs()"
                                  ],
                                  "verification": "Dados limpos sem NAs, gráficos mostram relações lineares aparentes sem outliers extremos",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Pacotes ggplot2 e dplyr carregados",
                                    "Dataset preparado do step 1"
                                  ],
                                  "tips": "Sempre salve versão limpa: data_clean <- data; use theme_minimal() em ggplots para clareza",
                                  "learningObjective": "Identificar e corrigir problemas nos dados para garantir validade do modelo MQO",
                                  "commonMistakes": [
                                    "Não tratar NAs causando NA nos coeficientes",
                                    "Ignorar não-linearidades evidentes nos plots",
                                    "Sobrepor variáveis correlacionadas sem checagem"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar modelo MQO usando função lm()",
                                  "subSteps": [
                                    "Especificar fórmula: lm(forca ~ corrente + voltagem, data = data_clean)",
                                    "Atribuir a um objeto: model_mqo <- lm(formula)",
                                    "Executar summary(model_mqo) para obter coeficientes, R-quadrado e estatísticas",
                                    "Verificar resíduos com plot(model_mqo) para homocedasticidade",
                                    "Testar significância com anova(model_mqo)"
                                  ],
                                  "verification": "Objeto model_mqo criado, summary() exibe tabela com coeficientes, p-values e R-squared > 0.7 idealmente",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Dados limpos do step 2",
                                    "R base (função lm() )"
                                  ],
                                  "tips": "Use nomes descritivos para objetos; capture summary em objeto: sum_model <- summary(model_mqo)",
                                  "learningObjective": "Implementar regressão linear ordinária via MQO e gerar métricas de ajuste iniciais",
                                  "commonMistakes": [
                                    "Fórmula errada como lm(forca == corrente)",
                                    "Não especificar data= causando erro de ambiente",
                                    "Confundir lm() com glm()"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e validar ajuste do modelo",
                                  "subSteps": [
                                    "Analisar coeficientes: interpretar beta0 (intercepto), beta1/beta2 (slopes) e significância (p < 0.05)",
                                    "Avaliar R-quadrado e Adjusted R-quadrado para qualidade de ajuste",
                                    "Diagnosticar resíduos: plot(residuals(model_mqo)) e qqnorm() para normalidade",
                                    "Prever novos valores com predict(model_mqo, newdata)",
                                    "Comparar com dados reais via RMSE: sqrt(mean(residuals(model_mqo)^2))"
                                  ],
                                  "verification": "Relatório escrito com interpretações: 'Coeficiente de corrente: X unidades por ampère, significativo'",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Modelo ajustado do step 3"
                                  ],
                                  "tips": "Documente em Markdown no RStudio; use confint(model_mqo) para intervalos de confiança",
                                  "learningObjective": "Extrair insights acionáveis de MQO e validar premissas da regressão linear",
                                  "commonMistakes": [
                                    "Interpretar p-value como probabilidade do modelo ser falso",
                                    "Ignorar resíduos não-normais",
                                    "R-quadrado alto mas multicolinearidade"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um processo de solda industrial, use dados reais (forca_tração.csv: 100 observações de força (kN), corrente (A), voltagem (V)). Código: library(dplyr); data <- read.csv('forca_tração.csv'); data_clean <- na.omit(data); model <- lm(forca ~ corrente + voltagem, data_clean); summary(model) resulta em Coef. corrente: 0.45 (p<0.001), voltagem: 1.2 (p=0.03), R²=0.82, permitindo prever força ótima para automação.",
                              "finalVerifications": [
                                "Executa lm() e summary() sem erros em dataset novo",
                                "Interpreta corretamente todos coeficientes e p-values",
                                "Gera plots de diagnóstico mostrando resíduos aleatórios",
                                "Calcula R-quadrado e explica seu significado no contexto de engenharia",
                                "Faz predições precisas com RMSE < 10% do range dos dados",
                                "Identifica e corrige pelo menos um problema comum nos dados"
                              ],
                              "assessmentCriteria": [
                                "Código funcional e reproduzível (25%)",
                                "Interpretação precisa de sumário MQO (30%)",
                                "Qualidade de preparação e exploração de dados (20%)",
                                "Validação de premissas (resíduos, normalidade) (15%)",
                                "Relatório com insights práticos para engenharia (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses e intervalos de confiança",
                                "Programação Computacional: Manipulação de dataframes em R com dplyr",
                                "Engenharia de Processos: Otimização preditiva em manufatura",
                                "Visualização de Dados: Gráficos diagnósticos com ggplot2",
                                "Matemática Aplicada: Derivação de MQO via minimização de soma quadrados"
                              ],
                              "realWorldApplication": "Na engenharia mecânica, implementar MQO em R para modelar eficiência energética de turbinas (potência vs. rotação e temperatura), permitindo otimizar operações industriais, reduzir custos em 15-20% e prever falhas preventivamente em fábricas como siderúrgicas ou petroquímicas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.1.1.1"
                            ]
                          },
                          {
                            "id": "10.1.7.1.2.3",
                            "name": "Avaliar qualidade de ajuste com R²",
                            "description": "Calcular e interpretar R² e R² ajustado para medir proporção de variância explicada em modelos de engenharia, como previsão de consumo energético.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de R² e Variância Explicada",
                                  "subSteps": [
                                    "Defina R² como o coeficiente de determinação, que mede a proporção da variância total da variável dependente explicada pelo modelo de regressão.",
                                    "Explique SST (Soma Total de Quadrados) como a variância total dos dados observados em relação à média.",
                                    "Descreva SSR (Soma de Quadrados da Regressão) como a variância explicada pelo modelo.",
                                    "Defina SSE (Soma de Erros Quadrados) como a variância residual não explicada.",
                                    "Discuta limitações do R², como aumento automático com mais preditores, justificando o R² ajustado."
                                  ],
                                  "verification": "Escreva definições precisas de R², SST, SSR e SSE em suas próprias palavras e forneça a fórmula básica R² = 1 - (SSE/SST).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Papel e caneta para anotações",
                                    "Notebook com Python e bibliotecas NumPy/Pandas",
                                    "Artigo introdutório sobre regressão linear (ex: de Khan Academy)"
                                  ],
                                  "tips": "Visualize com um gráfico de dispersão: pontos próximos à linha de regressão indicam alto R².",
                                  "learningObjective": "Entender o significado estatístico de R² como métrica de ajuste do modelo.",
                                  "commonMistakes": [
                                    "Confundir R² com correlação ao quadrado (válido apenas para regressão simples)",
                                    "Ignorar que R² não implica causalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular Componentes de Variância (SST, SSR, SSE)",
                                  "subSteps": [
                                    "Colete ou gere um dataset simples de engenharia, como consumo energético (y) vs. temperatura (x).",
                                    "Calcule a média da variável dependente (ȳ).",
                                    "Compute SST = Σ(y_i - ȳ)² para todos os dados.",
                                    "Calcule valores preditos ẏ_i = b0 + b1*x_i usando coeficientes de MQO.",
                                    "Compute SSR = Σ(ẏ_i - ȳ)² e SSE = Σ(y_i - ẏ_i)²."
                                  ],
                                  "verification": "Verifique se SST = SSR + SSE (decomposição exata) com cálculos manuais em um dataset de 10 pontos.",
                                  "estimatedTime": "60 minutos",
                                  "materials": [
                                    "Planilha Excel ou Google Sheets",
                                    "Python com NumPy para validação",
                                    "Dataset exemplo: consumo energético (disponível em repositórios Kaggle)"
                                  ],
                                  "tips": "Use funções prontas como np.sum((y - y.mean())**2) no Python para checar cálculos manuais.",
                                  "learningObjective": "Dominar o cálculo dos componentes de variância para qualquer dataset de regressão.",
                                  "commonMistakes": [
                                    "Erros aritméticos em somas de quadrados",
                                    "Usar valores absolutos em vez de quadrados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e Comparar R² e R² Ajustado",
                                  "subSteps": [
                                    "Calcule R² = SSR / SST ou equivalentemente 1 - (SSE / SST).",
                                    "Calcule R² ajustado = 1 - [(1 - R²)(n - 1)/(n - k - 1)], onde n é o número de observações e k o número de preditores.",
                                    "Implemente em código: use statsmodels ou sklearn para obter valores automáticos e compare com manuais.",
                                    "Teste com datasets crescentes em preditores para observar penalização no R² ajustado.",
                                    "Registre valores para interpretação subsequente."
                                  ],
                                  "verification": "Produza um relatório com R² e R² ajustado para dois modelos (simples vs. múltiplo) e confirme consistência com bibliotecas.",
                                  "estimatedTime": "50 minutos",
                                  "materials": [
                                    "Python/Jupyter Notebook com statsmodels e scikit-learn",
                                    "Dataset de consumo energético com múltiplas variáveis (ex: temperatura, umidade)"
                                  ],
                                  "tips": "Sempre prefira R² ajustado para modelos com mais de um preditor para evitar overfitting.",
                                  "learningObjective": "Aplicar fórmulas exatas de R² e R² ajustado em contextos computacionais.",
                                  "commonMistakes": [
                                    "Esquecer de subtrair 1 no denominador do R² ajustado",
                                    "Aplicar R² ajustado incorretamente em regressão simples (k=1)"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar R² no Contexto de Engenharia e Avaliar Qualidade de Ajuste",
                                  "subSteps": [
                                    "Interprete faixas: R² > 0.9 excelente, 0.7-0.9 bom, <0.5 pobre para previsão energética.",
                                    "Compare R² vs. R² ajustado: queda significativa indica overfitting.",
                                    "Avalie se o modelo explica variância relevante para engenharia (ex: >80% para consumo energético confiável).",
                                    "Discuta thresholds contextuais: mais rigoroso em aplicações críticas como energia.",
                                    "Gere relatório com conclusões acionáveis."
                                  ],
                                  "verification": "Escreva uma interpretação de 200 palavras para um R²=0.85 e R² adj=0.82 em previsão de consumo, justificando viabilidade.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Gráficos de resíduos e predicted vs actual no Matplotlib",
                                    "Referências de benchmarks em engenharia (ex: artigos IEEE)"
                                  ],
                                  "tips": "Combine com gráficos de resíduos: R² alto mas resíduos padrões indicam problemas.",
                                  "learningObjective": "Interpretar R² de forma contextualizada para decisões de engenharia.",
                                  "commonMistakes": [
                                    "Interpretar R² como 'precisão absoluta'",
                                    "Ignorar domínio específico ao julgar valores"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um modelo de regressão linear simples para prever consumo energético diário (kWh) baseado na temperatura média (°C) de uma planta industrial: dados de 50 dias mostram R² = 0.78 (78% da variância explicada) e R² ajustado = 0.77. Isso indica bom ajuste, mas adicionar umidade eleva R² para 0.85 (ajustado 0.82), melhorando previsões para otimização de cargas.",
                              "finalVerifications": [
                                "Calcule corretamente R² e R² ajustado para um dataset fornecido sem erros aritméticos.",
                                "Explique a diferença entre R² e R² ajustado com exemplo numérico.",
                                "Interprete um R²=0.65 como inadequado para previsão energética crítica.",
                                "Verifique decomposição SST = SSR + SSE em código e manualmente.",
                                "Identifique overfitting quando R² > R² ajustado em >0.05."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de SST/SSR/SSE (erro <1%).",
                                "Correta aplicação da fórmula de R² ajustado considerando n e k.",
                                "Interpretação contextualizada com thresholds de engenharia.",
                                "Uso de ferramentas computacionais com validação manual.",
                                "Relatório claro com gráficos e conclusões acionáveis.",
                                "Identificação de limitações e sugestões de melhoria."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Ligação com testes F e ANOVA para significância do modelo.",
                                "Programação: Implementação em Python/R para automação em pipelines de dados.",
                                "Engenharia Elétrica: Aplicação direta em modelagem de cargas energéticas e otimização.",
                                "Física: Relação com leis de conservação em simulações preditivas."
                              ],
                              "realWorldApplication": "Em engenharia, R² avalia modelos de previsão de consumo energético para balanceamento de redes elétricas, reduzindo custos em 10-20% via otimização de picos, como em usinas solares onde temperatura explica 75-85% da variância na produção."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.1.2.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.1.3",
                        "name": "Pressupostos, Propriedades e Inferência",
                        "description": "Pressupostos clássicos da regressão linear, propriedades dos estimadores MQO (não viesados, consistentes, eficientes) e técnicas de inferência para validação em aplicações de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.1.3.1",
                            "name": "Verificar pressupostos da regressão linear",
                            "description": "Diagnosticar linearidade, independência dos erros, homocedasticidade, normalidade e ausência de multicolinearidade usando gráficos residuais e testes em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e ajustar modelo de regressão linear",
                                  "subSteps": [
                                    "Carregar dataset de engenharia (ex: dados de tensão vs. deformação em materiais)",
                                    "Explorar dados com summary statistics e gráficos iniciais (scatter plot de variáveis preditoras vs. resposta)",
                                    "Ajustar modelo de regressão linear usando statsmodels em Python",
                                    "Extrair resíduos padronizados e valores preditos",
                                    "Salvar resíduos para análises subsequentes"
                                  ],
                                  "verification": "Modelo ajustado com summary() mostrando coeficientes e R-squared; resíduos extraídos e plotados basicamente",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python (pandas, statsmodels, matplotlib), dataset de engenharia (ex: CSV com medições de materiais)",
                                  "tips": "Use OLS de statsmodels para obter p-values e resíduos automaticamente",
                                  "learningObjective": "Dominar ajuste de modelo e extração de resíduos para diagnósticos",
                                  "commonMistakes": "Esquecer de padronizar variáveis ou usar dados com missing values sem tratamento"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Verificar linearidade e padrões nos resíduos",
                                  "subSteps": [
                                    "Criar scatter plot de resíduos vs. valores preditos",
                                    "Criar Q-Q plot para resíduos padronizados",
                                    "Adicionar linha de tendência ao scatter plot para detectar curvatura",
                                    "Inspecionar visualmente por padrões não-lineares ou funis",
                                    "Documentar observações qualitativas"
                                  ],
                                  "verification": "Gráficos gerados sem padrões evidentes de não-linearidade (resíduos aleatórios em torno de zero)",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (seaborn, matplotlib, scipy.stats para Q-Q)",
                                  "tips": "Use seaborn.residplot() para gráficos rápidos e informativos",
                                  "learningObjective": "Interpretar gráficos residuais para diagnosticar linearidade",
                                  "commonMistakes": "Confundir dispersão aleatória com violações leves; ignorar outliers"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diagnosticar independência, homocedasticidade e normalidade",
                                  "subSteps": [
                                    "Plotar resíduos ordenados por tempo/ordem de coleta para independência (ACF plot)",
                                    "Testar homocedasticidade com Breusch-Pagan test",
                                    "Testar normalidade com Shapiro-Wilk ou Kolmogorov-Smirnov",
                                    "Visualizar histograma e Q-Q plot detalhado dos resíduos",
                                    "Interpretar p-values (p > 0.05 indica pressuposto ok)"
                                  ],
                                  "verification": "Testes estatísticos com p-values reportados e gráficos sem autocorrelação ou variância heterogênea",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python (statsmodels.stats.diagnostic, scipy.stats)",
                                  "tips": "Combine testes visuais e formais; log-transform se heteroscedasticidade detectada",
                                  "learningObjective": "Aplicar testes formais para independência, homocedasticidade e normalidade",
                                  "commonMistakes": "Usar testes inadequados para amostras grandes (Shapiro-Wilk falha em n>5000)"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar ausência de multicolinearidade",
                                  "subSteps": [
                                    "Calcular Variance Inflation Factor (VIF) para cada preditora",
                                    "Criar tabela de correlação entre preditoras",
                                    "Identificar variáveis com VIF > 5 ou 10 como problemáticas",
                                    "Visualizar heatmap de correlação",
                                    "Sugerir remoção ou combinação de variáveis multicolineares"
                                  ],
                                  "verification": "Todos VIF < 5; heatmap sem correlações > 0.8",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (statsmodels.stats.outliers_influence, seaborn.heatmap)",
                                  "tips": "VIF = 1/(1-R²); priorize remoção da variável com menor impacto no modelo",
                                  "learningObjective": "Quantificar e mitigar multicolinearidade em modelos multivariados",
                                  "commonMistakes": "Ignorar multicolinearidade em preditoras altamente correlacionadas como temperatura e pressão"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Sintetizar diagnóstico e propor correções",
                                  "subSteps": [
                                    "Compilar relatório com todos gráficos e testes",
                                    "Listar pressupostos violados e razões",
                                    "Propor soluções (transformações, remoção de variáveis, modelos alternativos)",
                                    "Reajustar modelo se necessário e reavaliar",
                                    "Documentar conclusões finais"
                                  ],
                                  "verification": "Relatório completo com recomendações acionáveis e modelo validado",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Jupyter Notebook para relatório integrado",
                                  "tips": "Use markdown em notebook para relatório profissional",
                                  "learningObjective": "Integrar diagnósticos em workflow de modelagem robusto",
                                  "commonMistakes": "Não propor correções específicas ou ignorar violações menores"
                                }
                              ],
                              "practicalExample": "Em um dataset de testes de fadiga em vigas de aço (variáveis: ciclos de carga, tensão máxima, espessura; resposta: vida útil), ajuste regressão linear, gere resíduos e detecte heteroscedasticidade via Breusch-Pagan (p=0.01), corrigindo com log-transform da resposta.",
                              "finalVerifications": [
                                "Resíduos vs. preditos mostram dispersão aleatória sem padrões",
                                "VIF de todas preditoras < 5",
                                "p-value Breusch-Pagan > 0.05 para homocedasticidade",
                                "Shapiro-Wilk p-value > 0.05 para normalidade",
                                "ACF plot sem autocorrelação significativa",
                                "Q-Q plot alinhado com linha reta",
                                "Relatório sintetiza todas violações e correções"
                              ],
                              "assessmentCriteria": [
                                "Correta geração e interpretação de todos gráficos residuais (30%)",
                                "Aplicação precisa de testes estatísticos com thresholds adequados (25%)",
                                "Diagnóstico preciso de violações específicas (20%)",
                                "Propostas de correção lógicas e testadas (15%)",
                                "Relatório claro e completo (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses e p-values",
                                "Programação Computacional: Manipulação de dados em Python/R",
                                "Engenharia Mecânica: Modelagem preditiva em materiais",
                                "Visualização de Dados: Gráficos diagnósticos com seaborn/matplotlib",
                                "Machine Learning: Pré-requisitos para modelos avançados"
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, verificar pressupostos em regressão para prever desgaste de turbinas garante modelos confiáveis para manutenção preditiva, evitando falhas catastróficas e otimizando custos operacionais."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.1.2.2"
                            ]
                          },
                          {
                            "id": "10.1.7.1.3.2",
                            "name": "Realizar testes de hipótese e intervalos de confiança",
                            "description": "Aplicar teste t para significância de coeficientes, teste F para modelo global, e construir ICs para βj em contextos como análise de confiabilidade de sistemas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o modelo de regressão linear e estimar parâmetros",
                                  "subSteps": [
                                    "Carregar o dataset com variáveis dependente (ex: log(tempo de falha)) e independentes (ex: tensão, temperatura).",
                                    "Verificar pressupostos básicos (linearidade, normalidade dos resíduos, homocedasticidade) usando gráficos QQ e resíduos vs fitted.",
                                    "Ajustar o modelo de regressão linear usando biblioteca como statsmodels em Python.",
                                    "Extrair coeficientes βj, erros padrão, valores t e p-values iniciais.",
                                    "Salvar o summary do modelo para referência."
                                  ],
                                  "verification": "Summary do modelo mostra coeficientes estimados e erros padrão sem erros de ajuste.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python com statsmodels e pandas; dataset exemplo de confiabilidade (ex: simulated failure times).",
                                  "tips": "Sempre padronize variáveis para facilitar interpretação de magnitudes.",
                                  "learningObjective": "Entender como estimar parâmetros βj corretamente para inferência posterior.",
                                  "commonMistakes": "Ignorar verificação de pressupostos, levando a testes inválidos; usar dados não limpos."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar teste t para significância de coeficientes individuais",
                                  "subSteps": [
                                    "Identificar H0: βj = 0 vs H1: βj ≠ 0 para cada coeficiente j.",
                                    "Calcular estatística t = βj_hat / SE(βj_hat) do summary do modelo.",
                                    "Obter p-value associado e comparar com nível de significância α (ex: 0.05).",
                                    "Rejeitar H0 se p-value < α e registrar decisão para cada βj.",
                                    "Documentar interpretação: 'β1 é significativo, tensão afeta tempo de falha'."
                                  ],
                                  "verification": "Tabela com t-stats, p-values e decisões de rejeição para todos βj.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Output do modelo statsmodels; calculadora ou código para t-distribution.",
                                  "tips": "Use one-tailed test apenas se justificado pela teoria; prefira two-tailed.",
                                  "learningObjective": "Aplicar teste t para testar hipótese nula de irrelevância de preditor.",
                                  "commonMistakes": "Confundir t-stat com p-value; ignorar múltiplos testes sem correção."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar teste F para significância global do modelo",
                                  "subSteps": [
                                    "Formular H0: todos βj = 0 (modelo nulo intercept-only) vs H1: pelo menos um βj ≠ 0.",
                                    "Calcular F-stat = (SSR_restrito - SSR_completo)/q / (SST - SSR_completo)/(n-k-1) ou usar summary.",
                                    "Obter p-value do teste F e comparar com α.",
                                    "Rejeitar H0 se p-value < α, confirmando utilidade do modelo.",
                                    "Comparar R² ajustado para suporte adicional."
                                  ],
                                  "verification": "p-value F < 0.05 e interpretação escrita: 'Modelo global significativo'.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Summary do modelo; fórmula F ou função anova_lm em R/Python.",
                                  "tips": "F-test é robusto; sempre reporte graus de liberdade.",
                                  "learningObjective": "Avaliar se o modelo como um todo explica variância na resposta.",
                                  "commonMistakes": "Usar F-test para preditores individuais em vez de t-test."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir e interpretar intervalos de confiança para βj",
                                  "subSteps": [
                                    "Calcular IC 95% para βj: βj_hat ± t_{α/2, df} * SE(βj_hat).",
                                    "Usar conf_int() no statsmodels para automação.",
                                    "Verificar se IC exclui 0: se sim, βj significativo no nível 95%.",
                                    "Interpretar amplitude: precisão da estimativa (estreito = dados informativos).",
                                    "Relacionar com contexto: 'IC para β_tensao: [0.2, 0.8], tensão aumenta falhas'."
                                  ],
                                  "verification": "Tabela de ICs para cada βj com interpretação contextual.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Tabela t crítica; statsmodels conf_int(); dataset.",
                                  "tips": "Aumente confiança (ex: 99%) para ICs mais conservadores em engenharia.",
                                  "learningObjective": "Construir ICs e usá-los para inferência sem p-values.",
                                  "commonMistakes": "Usar Z em vez de t para amostras pequenas; inverter limites do IC."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Integrar resultados e validar no contexto de engenharia",
                                  "subSteps": [
                                    "Compilar tabela unificada: t-tests, F-test, ICs.",
                                    "Interpretar coletivamente: quais preditores guiam decisões de design.",
                                    "Simular cenários: predizer confiabilidade sob condições extremas.",
                                    "Verificar robustez com bootstrap se necessário.",
                                    "Recomendar ações: 'Reduzir tensão para melhorar MTBF baseado em β1 significativo'."
                                  ],
                                  "verification": "Relatório final com conclusões acionáveis e visualizações (ex: plot ICs).",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Gráficos (matplotlib); relatório template.",
                                  "tips": "Sempre contextualize: ligue stats a impacto em sistemas reais.",
                                  "learningObjective": "Sintetizar inferência para aplicações em análise de confiabilidade.",
                                  "commonMistakes": "Sobre-generalizar sem considerar limitações do modelo."
                                }
                              ],
                              "practicalExample": "Em análise de confiabilidade de turbinas, modelo: log(MTBF) = β0 + β1*Tensão + β2*Temperatura + ε. Dataset de 50 testes. Teste t: β1 p=0.01 (significativo), β2 p=0.20. F-test p<0.001 (global ok). IC β1 95%: [0.15, 0.45] (exclui 0). Conclusão: Tensão crítica para design.",
                              "finalVerifications": [
                                "Todos p-values t e F corretamente calculados e interpretados.",
                                "ICs construídos sem conter 0 para coeficientes significativos.",
                                "Pressupostos do modelo verificados antes dos testes.",
                                "Interpretação alinhada ao contexto de engenharia de confiabilidade.",
                                "Tabela summary completa e sem erros numéricos.",
                                "Recomendações práticas derivadas dos resultados."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de t, F e ICs (erro <5%).",
                                "Correta formulação e rejeição de hipóteses.",
                                "Interpretação qualitativa e quantitativa adequada.",
                                "Verificação de pressupostos e discussão de limitações.",
                                "Clareza na documentação e visualizações.",
                                "Aplicação contextual em confiabilidade de sistemas."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Fundamentos de testes paramétricos.",
                                "Programação Computacional: Uso de statsmodels/scikit-learn em Python.",
                                "Engenharia de Confiabilidade: Modelagem de falhas (Weibull via regressão).",
                                "Machine Learning: Inferência em modelos lineares como base para regressão logística.",
                                "Análise de Dados: Visualização de resíduos e diagnósticos."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, usar testes t/F e ICs em regressão para identificar fatores (ex: vibração, material) que reduzem tempo até falha, otimizando design de componentes para MTBF > 10.000 horas, reduzindo custos de manutenção em 20%."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.1.2.1"
                            ]
                          },
                          {
                            "id": "10.1.7.1.3.3",
                            "name": "Aplicar regressão em modelagem prática de engenharia",
                            "description": "Desenvolver e validar modelo para prever saída de processo (ex.: rendimento químico vs. variáveis operacionais), usando MQO e inferência, com referência a bibliografia como Gujarati.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coleta e Preparação de Dados",
                                  "subSteps": [
                                    "Identificar variáveis dependente (ex.: rendimento químico) e independentes (ex.: temperatura, pressão, concentração).",
                                    "Coletar dataset real ou simulado com pelo menos 30 observações.",
                                    "Limpar dados: tratar missing values, outliers e escalar variáveis se necessário.",
                                    "Explorar dados com estatísticas descritivas e gráficos (scatter plots, histogramas).",
                                    "Dividir dataset em treino (70%) e teste (30%)."
                                  ],
                                  "verification": "Dataset limpo e dividido, com relatório de exploração salvo (ex.: Jupyter notebook).",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Python com bibliotecas pandas, numpy, matplotlib e seaborn.",
                                    "Dataset exemplo de processo químico (ex.: de repositórios Kaggle).",
                                    "Livro Gujarati (capítulos iniciais sobre dados)."
                                  ],
                                  "tips": "Sempre visualize os dados antes de modelar para detectar padrões ou anomalias.",
                                  "learningObjective": "Compreender a importância da qualidade dos dados na regressão linear.",
                                  "commonMistakes": [
                                    "Ignorar outliers sem justificativa.",
                                    "Não verificar multicolinearidade inicial.",
                                    "Usar dataset muito pequeno."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificação e Ajuste do Modelo por MQO",
                                  "subSteps": [
                                    "Definir equação do modelo: Y = β0 + β1 X1 + β2 X2 + ... + ε.",
                                    "Implementar MQO usando statsmodels ou scikit-learn.",
                                    "Ajustar o modelo no conjunto de treino e obter coeficientes β.",
                                    "Calcular métricas iniciais: R², R² ajustado.",
                                    "Interpretar sinais e magnitudes dos coeficientes."
                                  ],
                                  "verification": "Modelo ajustado com summary() exibindo coeficientes e R² > 0.7.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Python com statsmodels ou sklearn.",
                                    "Jupyter notebook para código reproduzível."
                                  ],
                                  "tips": "Inclua intercepto (β0) e teste modelos simples vs. múltiplos.",
                                  "learningObjective": "Dominar o método dos Mínimos Quadrados Ordinários (MQO).",
                                  "commonMistakes": [
                                    "Omitir variáveis relevantes (omissão bias).",
                                    "Interpretar coeficientes sem contexto de unidades.",
                                    "Confundir R² com causalidade."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificação de Pressupostos da Regressão Linear",
                                  "subSteps": [
                                    "Testar linearidade: residual plots e teste RESET.",
                                    "Verificar independência: Durbin-Watson para autocorrelação.",
                                    "Testar homocedasticidade: Breusch-Pagan ou White test.",
                                    "Normalidade dos resíduos: Q-Q plot e Shapiro-Wilk.",
                                    "Multicolinearidade: VIF (Variance Inflation Factor) < 5."
                                  ],
                                  "verification": "Relatório de diagnósticos com todos pressupostos satisfeitos ou correções aplicadas.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Bibliotecas statsmodels (para testes) e scipy.",
                                    "Referência Gujarati capítulos 10-12 sobre pressupostos."
                                  ],
                                  "tips": "Se pressuposto violado, considere transformações (log) ou modelo robusto.",
                                  "learningObjective": "Avaliar validade do modelo via pressupostos clássicos.",
                                  "commonMistakes": [
                                    "Ignorar violações e prosseguir.",
                                    "Confundir heterocedasticidade com não-linearidade.",
                                    "VIF alto sem remover variáveis."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Inferência Estatística e Validação",
                                  "subSteps": [
                                    "Calcular intervalos de confiança e testes t para coeficientes.",
                                    "Teste F global para significância do modelo.",
                                    "Validar no conjunto de teste: RMSE, MAE, previsão plots.",
                                    "Análise de resíduos: padronizados e studentized.",
                                    "Comparar com baseline (média simples)."
                                  ],
                                  "verification": "p-valores < 0.05 para coeficientes chave e RMSE teste < RMSE treino.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "Statsmodels para inferência.",
                                    "Gujarati capítulos sobre testes de hipóteses."
                                  ],
                                  "tips": "Use nível de significância 5% e interprete economicamente.",
                                  "learningObjective": "Realizar inferência e validar generalização do modelo.",
                                  "commonMistakes": [
                                    "Overfitting por não usar conjunto de teste.",
                                    "Ignorar significância estatística.",
                                    "Confundir correlação com causalidade."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretação, Aplicação e Relatório",
                                  "subSteps": [
                                    "Interpretar modelo: impacto de cada variável no rendimento.",
                                    "Fazer previsões para cenários novos.",
                                    "Documentar limitações e sugestões de melhoria.",
                                    "Gerar relatório com gráficos e tabela de resultados.",
                                    "Referenciar Gujarati para validação teórica."
                                  ],
                                  "verification": "Relatório final com modelo interpretado e previsões precisas.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Ferramentas de visualização: matplotlib, seaborn.",
                                    "Template de relatório LaTeX ou Markdown."
                                  ],
                                  "tips": "Enfatize implicações práticas para engenharia.",
                                  "learningObjective": "Aplicar o modelo em contexto de engenharia prática.",
                                  "commonMistakes": [
                                    "Não discutir limitações.",
                                    "Relatório sem visualizações.",
                                    "Ignorar referências bibliográficas."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um reator químico, preveja o rendimento de etanol (Y) baseado em temperatura (T °C), pressão (P bar) e concentração de catalisador (C %): Y = β0 + β1 T + β2 P + β3 C + ε. Use dataset de 50 runs, ajuste via MQO em Python, valide pressupostos e infira que +10°C aumenta rendimento em 5% (p<0.01).",
                              "finalVerifications": [
                                "R² ajustado > 0.75 e teste F significativo (p<0.05).",
                                "Todos pressupostos verificados e satisfeitos.",
                                "Previsões no teste com RMSE < 10% do desvio padrão de Y.",
                                "Coeficientes interpretados com intervalos de confiança.",
                                "Relatório completo com código reproduzível.",
                                "Referências a Gujarati incluídas."
                              ],
                              "assessmentCriteria": [
                                "Precisão do modelo (R², RMSE baixo).",
                                "Correta verificação e correção de pressupostos.",
                                "Inferência estatística rigorosa (testes t/F).",
                                "Interpretação contextual em engenharia.",
                                "Código limpo e documentado.",
                                "Relatório claro com visualizações."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia Química: modelagem de processos industriais.",
                                "Estatística: inferência e testes de hipóteses.",
                                "Programação: Python para análise de dados.",
                                "Otimização: uso em controle de processos.",
                                "Machine Learning: base para modelos avançados."
                              ],
                              "realWorldApplication": "Otimização de reatores em indústrias petroquímicas, prevendo rendimento para ajustar variáveis operacionais, reduzindo custos energéticos em até 15% e minimizando desperdícios, como em refinarias da Petrobras."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.1.3.1",
                              "10.1.7.1.3.2"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.7.2",
                    "name": "Análise de Séries Temporais com ARIMA",
                    "description": "Uso de modelos ARIMA para previsão e análise de dados temporais em sistemas dinâmicos de engenharia.",
                    "individualConcepts": [
                      {
                        "id": "10.1.7.2.1",
                        "name": "Fundamentos de Séries Temporais",
                        "description": "Conceitos básicos de séries temporais, incluindo estacionariedade, autocorrelação e diferenciação, essenciais para preparar dados em sistemas dinâmicos de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.2.1.1",
                            "name": "Identificar estacionariedade em séries temporais",
                            "description": "Avaliar se uma série temporal é estacionária utilizando testes como Dickey-Fuller e gráficos de autocorrelação, aplicando diferenciação quando necessário para dados de sistemas dinâmicos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o Conceito de Estacionariedade e Visualizar a Série Temporal",
                                  "subSteps": [
                                    "Defina estacionariedade: média, variância e covariância constantes ao longo do tempo.",
                                    "Carregue um conjunto de dados de série temporal usando Python (pandas).",
                                    "Plote a série temporal, histograma e QQ-plot para inspeção visual.",
                                    "Calcule e plote estatísticas descritivas em janelas deslizantes.",
                                    "Identifique sinais visuais de não-estacionariedade (tendências, sazonalidade)."
                                  ],
                                  "verification": "Gráficos gerados mostram ausência ou presença clara de tendências/sazonalidade; estatísticas deslizantes variam ou são constantes.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python (pandas, matplotlib, seaborn)",
                                    "Dataset exemplo: AirPassengers ou dados de temperatura"
                                  ],
                                  "tips": "Use log-transformação inicial para estabilizar variância em séries com heteroscedasticidade.",
                                  "learningObjective": "Reconhecer visualmente propriedades de estacionariedade em séries temporais.",
                                  "commonMistakes": [
                                    "Ignorar sazonalidade confundindo com tendência",
                                    "Não normalizar escala nos gráficos deslizantes"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar Gráficos de Autocorrelação (ACF) e Autocorrelação Parcial (PACF)",
                                  "subSteps": [
                                    "Gere gráficos ACF e PACF usando statsmodels.tsa.stattools.",
                                    "Interprete ACF: decaimento lento indica não-estacionariedade.",
                                    "Interprete PACF: picos significativos além do lag 1 sugerem dependência.",
                                    "Compare ACF/PACF antes e após remoção de tendência (detrending).",
                                    "Documente lags onde correlações excedem bandas de confiança."
                                  ],
                                  "verification": "ACF decai rapidamente para estacionária; relatório escrito com interpretação dos lags principais.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Biblioteca statsmodels",
                                    "Jupyter Notebook para visualizações interativas"
                                  ],
                                  "tips": "Ajuste o número de lags para 2*n/(fs) onde fs é frequência de amostragem.",
                                  "learningObjective": "Usar ACF/PACF para diagnosticar não-estacionariedade.",
                                  "commonMistakes": [
                                    "Confundir bandas de confiança com ruído",
                                    "Não diferenciar ACF de PACF na interpretação"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar o Teste de Dickey-Fuller Aumentado (ADF)",
                                  "subSteps": [
                                    "Instale e importe statsmodels.tsa.stattools.adfuller.",
                                    "Execute adfuller() na série original, registrando estatística do teste, p-value e valores críticos.",
                                    "Interprete: p-value > 0.05 rejeita estacionariedade nula? Hipótese nula é não-estacionária.",
                                    "Teste resíduos de regressão para confirmar ausência de autocorrelação.",
                                    "Gere relatório com todos os outputs do teste."
                                  ],
                                  "verification": "p-value < 0.05 confirma estacionariedade; código executado sem erros.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels",
                                    "Dataset não-estacionário para prática"
                                  ],
                                  "tips": "Inclua 'autolag'='AIC' para seleção automática de lags no ADF.",
                                  "learningObjective": "Executar e interpretar teste estatístico formal de estacionariedade.",
                                  "commonMistakes": [
                                    "Confundir hipótese nula (não-estacionária) com alternativa",
                                    "Ignorar estatística vs. p-value"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar Diferenciação e Retestar Estacionariedade",
                                  "subSteps": [
                                    "Aplique diff() no pandas para primeira diferenciação se não estacionária.",
                                    "Repita visualizações (gráficos, ACF/PACF) e teste ADF na série diferenciada.",
                                    "Determine ordem de diferenciação (1 ou 2) até p-value < 0.05.",
                                    "Plote série original vs. diferenciada para validação.",
                                    "Salve modelo de série estacionária final."
                                  ],
                                  "verification": "Série diferenciada passa em ADF e ACF decai rapidamente.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "pandas para diff()",
                                    "Gráficos comparativos"
                                  ],
                                  "tips": "Evite sobrediferenciação: over-differencing causa invertibilidade issues em ARIMA.",
                                  "learningObjective": "Transformar séries não-estacionárias em estacionárias via diferenciação.",
                                  "commonMistakes": [
                                    "Diferenciar excessivamente sem reteste",
                                    "Não plotar após diff para confirmação visual"
                                  ]
                                }
                              ],
                              "practicalExample": "Carregue o dataset AirPassengers (passageiros aéreos mensais). Plote a série (tendência crescente), ACF (decaimento lento), execute ADF (p>0.05). Aplique diff(1), reteste: ADF p<0.05, ACF decai rápido. Conclua: não-estacionária original, estacionária após 1ª diff.",
                              "finalVerifications": [
                                "Pode gerar e interpretar ACF/PACF corretamente.",
                                "Executa ADF test com interpretação precisa de p-value.",
                                "Aplica diferenciação e confirma estacionariedade via múltiplos métodos.",
                                "Documenta relatório com gráficos e resultados numéricos.",
                                "Identifica corretamente ordem de diferenciação em dataset real.",
                                "Diferencia visual vs. estatístico para diagnóstico."
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de p-value ADF (80%+ acerto).",
                                "Qualidade dos gráficos ACF/PACF com lags corretos.",
                                "Correta identificação de não-estacionariedade em 90% dos casos.",
                                "Eficiência na diferenciação (mínima ordem necessária).",
                                "Relatório completo com verificações visuais e estatísticas.",
                                "Ausência de erros comuns como sobrediferenciação."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipótese e autocorrelação.",
                                "Machine Learning: Pré-processamento para modelos de forecasting.",
                                "Engenharia: Análise de sinais dinâmicos e controle.",
                                "Economia/Finanças: Modelagem de séries financeiras voláteis.",
                                "Ciência de Dados: Integração com ARIMA/SARIMA."
                              ],
                              "realWorldApplication": "Em engenharia, detectar estacionariedade em sensores IoT para previsão de falhas em sistemas dinâmicos; em finanças, estabilizar retornos de ações para modelos ARIMA de trading algorítmico."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.2.1.2",
                            "name": "Calcular funções de autocorrelação (ACF e PACF)",
                            "description": "Computar e interpretar as funções de autocorrelação (ACF) e autocorrelação parcial (PACF) para analisar dependências temporais em dados de engenharia, como sinais de sensores.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o Ambiente de Computação e os Dados de Série Temporal",
                                  "subSteps": [
                                    "Instale as bibliotecas necessárias: pandas, statsmodels e matplotlib via pip.",
                                    "Carregue um dataset de série temporal de sensores (ex: vibration_data.csv com colunas 'timestamp' e 'value').",
                                    "Converta a coluna de timestamp para datetime e defina como índice.",
                                    "Visualize os dados iniciais com plot da série temporal e estatísticas descritivas (média, variância).",
                                    "Verifique e trate valores ausentes ou outliers básicos."
                                  ],
                                  "verification": "Confirme que o plot da série temporal é exibido corretamente e os dados estão indexados por tempo sem erros.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python 3.x",
                                    "Jupyter Notebook ou Google Colab",
                                    "Bibliotecas: pandas, statsmodels, matplotlib",
                                    "Dataset de exemplo: vibration_data.csv"
                                  ],
                                  "tips": "Use pd.read_csv com parse_dates para timestamps automáticos. Sempre plote os dados primeiro para inspeção visual.",
                                  "learningObjective": "Configurar ambiente e preparar dados limpos para análise de autocorrelação.",
                                  "commonMistakes": [
                                    "Esquecer de definir índice temporal",
                                    "Ignorar valores ausentes",
                                    "Não visualizar dados iniciais"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Computar e Visualizar a Função de Autocorrelação (ACF)",
                                  "subSteps": [
                                    "Importe as funções from statsmodels.graphics.tsaplots import plot_acf.",
                                    "Execute plot_acf(dados['value'], lags=40) para gerar o gráfico ACF.",
                                    "Adicione limites de confiança (alpha=0.05) e salve o plot.",
                                    "Analise as barras que excedem as bandas de confiança azul.",
                                    "Registre os lags significativos (ex: lag 1, 12)."
                                  ],
                                  "verification": "O gráfico ACF mostra barras dentro/fora das bandas de confiança e lags identificados corretamente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Bibliotecas já instaladas",
                                    "Jupyter Notebook",
                                    "Dataset preparado"
                                  ],
                                  "tips": "Escolha lags baseado no período esperado (ex: 40 para dados diários). Use plt.show() para exibir.",
                                  "learningObjective": "Calcular ACF para medir correlações em diferentes lags temporais.",
                                  "commonMistakes": [
                                    "Usar lags insuficientes",
                                    "Ignorar bandas de confiança",
                                    "Confundir ACF com PACF"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Computar e Visualizar a Função de Autocorrelação Parcial (PACF)",
                                  "subSteps": [
                                    "Importe from statsmodels.graphics.tsaplots import plot_pacf.",
                                    "Execute plot_pacf(dados['value'], lags=40) para gerar o gráfico PACF.",
                                    "Configure alpha=0.05 para bandas de confiança e exiba o plot.",
                                    "Identifique lags onde barras cortam as bandas de confiança.",
                                    "Compare com ACF anotando diferenças nos lags significativos."
                                  ],
                                  "verification": "Gráfico PACF gerado com lags significativos anotados e comparado ao ACF.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Bibliotecas já instaladas",
                                    "Jupyter Notebook",
                                    "Dataset preparado"
                                  ],
                                  "tips": "PACF remove efeitos de lags intermediários; foque em 'cortes' limpos para ordem AR.",
                                  "learningObjective": "Calcular PACF para isolar correlações diretas em lags específicos.",
                                  "commonMistakes": [
                                    "Confundir interpretação de PACF com ACF",
                                    "Lags inconsistentes entre plots",
                                    "Não comparar os dois gráficos"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar ACF e PACF para Análise de Dependências Temporais",
                                  "subSteps": [
                                    "Compare ACF e PACF: decay lento em ACF sugere MA; cortes em PACF sugerem AR.",
                                    "Identifique padrões para modelo ARIMA (ex: ACF decay + PACF spike = AR(p)).",
                                    "Teste estacionariedade com ADF test se necessário (from statsmodels.tsa.stattools import adfuller).",
                                    "Documente insights: lags dominantes e implicações para engenharia.",
                                    "Gere relatório com plots e conclusões."
                                  ],
                                  "verification": "Relatório escrito explica lags, sugere modelo ARIMA e liga a contexto de sensores.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Bibliotecas já instaladas",
                                    "Jupyter Notebook",
                                    "Plots gerados"
                                  ],
                                  "tips": "Use Ljung-Box test para resíduos futuros. Considere sazonalidade em dados de sensores.",
                                  "learningObjective": "Interpretar ACF/PACF para identificar estrutura temporal e guiar modelagem.",
                                  "commonMistakes": [
                                    "Interpretar sem contexto de confiança",
                                    "Ignorar não-estacionariedade",
                                    "Sugestões erradas de ordem ARIMA"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sensor de vibração de turbina eólica (dados horários por 1 ano), compute ACF/PACF. ACF mostra decay exponencial após lag 1 (sugere AR(1)), PACF corta após lag 1, confirmando AR(1) para prever vibrações e detectar falhas precoces.",
                              "finalVerifications": [
                                "Plots de ACF e PACF gerados corretamente com lags=40 e bandas de confiança.",
                                "Lags significativos identificados e anotados em ambos os gráficos.",
                                "Diferenças entre ACF e PACF explicadas verbalmente ou por escrito.",
                                "Sugestão válida de ordem ARIMA baseada nos plots.",
                                "Teste de estacionariedade aplicado se decay lento observado.",
                                "Relatório liga resultados a aplicação em sensores de engenharia."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos ACF/PACF (plots idênticos ao esperado).",
                                "Correta identificação de lags significativos (>95% confiança).",
                                "Interpretação coerente com teoria ARIMA (AR/MA patterns).",
                                "Clareza no relatório e conexões com dados reais de engenharia.",
                                "Eficiência no código (sem erros, bem comentado).",
                                "Tratamento adequado de dados (limpeza, indexação temporal)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de significância e inferência.",
                                "Programação: Manipulação de dados em Python/pandas.",
                                "Engenharia de Sinais: Análise de dependências em sensores.",
                                "Machine Learning: Pré-processamento para modelos de previsão.",
                                "Física: Modelagem de sinais temporais em sistemas dinâmicos."
                              ],
                              "realWorldApplication": "Na engenharia, ACF e PACF analisam sinais de sensores em monitoramento de equipamentos (ex: detecção de vibrações anormais em pontes ou turbinas), permitindo manutenção preditiva, otimização de processos industriais e previsão de falhas em sistemas IoT."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.1.1"
                            ]
                          },
                          {
                            "id": "10.1.7.2.1.3",
                            "name": "Aplicar transformações para estacionariedade",
                            "description": "Realizar diferenciação, logaritmização ou sazonalização em séries temporais não estacionárias oriundas de processos de engenharia para torná-las adequadas a modelos ARIMA.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Avaliar estacionariedade da série temporal original",
                                  "subSteps": [
                                    "Carregar a série temporal de um processo de engenharia (ex: medições de vibração de uma turbina)",
                                    "Visualizar a série com gráficos de linha, histograma e ACF/PACF",
                                    "Realizar testes estatísticos como Augmented Dickey-Fuller (ADF) e Kwiatkowski-Phillips-Schmidt-Shin (KPSS)",
                                    "Analisar tendências, sazonalidade e variância não constante",
                                    "Documentar evidências de não-estacionariedade"
                                  ],
                                  "verification": "Gráficos mostram tendência/sazonalidade e p-value ADF > 0.05 (não rejeita H0 de raiz unitária)",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python (pandas, matplotlib, statsmodels)",
                                    "Dataset de série temporal (ex: CSV de sensores industriais)"
                                  ],
                                  "tips": "Use log escala no gráfico para detectar variância heteroscédastica; compare ACF lenta decay para confirmação",
                                  "learningObjective": "Identificar padrões de não-estacionariedade visual e estatisticamente",
                                  "commonMistakes": [
                                    "Ignorar sazonalidade visual",
                                    "Confundir p-values de ADF e KPSS",
                                    "Não plotar múltiplas visualizações"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Selecionar e aplicar transformações iniciais",
                                  "subSteps": [
                                    "Escolher transformação baseada na análise: logaritmo para variância crescente, diferenciação para tendência, sazonal para periodicidade",
                                    "Implementar logaritmização: y_log = log(y + c) onde c evita log(0)",
                                    "Aplicar diferenciação de ordem 1: diff1 = y.diff(1).dropna()",
                                    "Para sazonal: diff_saz = y.diff(12).dropna() se sazonalidade anual",
                                    "Combinar transformações se necessário (ex: log + diff)"
                                  ],
                                  "verification": "Código executado sem erros e nova série gerada com comprimento esperado",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Bibliotecas: numpy, statsmodels.tsa.stattools"
                                  ],
                                  "tips": "Sempre adicione pequena constante (1e-6) no log para valores próximos de zero; teste ordens baixas primeiro",
                                  "learningObjective": "Selecionar e codificar transformações adequadas ao tipo de não-estacionariedade",
                                  "commonMistakes": [
                                    "Diferenciar demais causando sobrediferenciação",
                                    "Esquecer dropna() após diff",
                                    "Aplicar log em séries com zeros/negativos sem ajuste"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificar estacionariedade da série transformada",
                                  "subSteps": [
                                    "Plotar gráficos da série transformada (linha, ACF/PACF, boxplots por lags)",
                                    "Executar testes ADF e KPSS na transformada",
                                    "Comparar com critérios: ADF p-value < 0.05 e KPSS p-value > 0.05",
                                    "Analisar resíduos para autocorrelação restante",
                                    "Documentar melhorias (ex: remoção de tendência)"
                                  ],
                                  "verification": "ADF rejeita H0 (p<0.05) e KPSS aceita H0 (p>0.05); ACF corta rapidamente",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.tsa.stattools.adfuller",
                                    "statsmodels.tsa.stattools.kpss"
                                  ],
                                  "tips": "Use qqplot para normalidade; se falhar, aumente ordem de diferenciação gradualmente",
                                  "learningObjective": "Validar efetividade das transformações com testes e visualizações",
                                  "commonMistakes": [
                                    "Não testar múltiplas transformações",
                                    "Ignorar discrepâncias entre testes",
                                    "Sobrepor gráficos sem legendas claras"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Iterar transformações e preparar para ARIMA",
                                  "subSteps": [
                                    "Se não estacionária, aplicar diferenciação adicional ou sazonal composta (ex: diff(1).diff(12))",
                                    "Reverificar com testes e gráficos após iterações",
                                    "Estimar parâmetros d (ordem de diferenciação) para ARIMA baseado nos testes",
                                    "Salvar série transformada e relatório de transformações aplicadas",
                                    "Testar estabilidade com Ljung-Box para autocorrelação nos resíduos"
                                  ],
                                  "verification": "Série final estacionária e pronta para modelagem ARIMA (d definido)",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.tsa.stattools.acf",
                                    "Relatório em Markdown/PDF"
                                  ],
                                  "tips": "Mantenha registro de todas iterações em um log; evite d>2 para evitar perda de interpretabilidade",
                                  "learningObjective": "Otimizar transformações iterativamente para adequação a ARIMA",
                                  "commonMistakes": [
                                    "Parar em primeira transformação sem verificação",
                                    "Diferenciação excessiva removendo sinal útil",
                                    "Não documentar sequência de transformações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma planta química, dados de pressão de um reator mostram tendência crescente e variância heteroscédastica. Aplique log(pressao + 1) seguido de diferenciação de ordem 1. Verifique com ADF (p=0.01) e plote ACF cortando em lag 2, preparando para ARIMA(1,1,1).",
                              "finalVerifications": [
                                "Teste ADF confirma estacionariedade (p-value < 0.05)",
                                "Teste KPSS confirma ausência de tendência (p-value > 0.05)",
                                "ACF/PACF da transformada mostram decaimento rápido sem sazonalidade residual",
                                "Variância constante em boxplots por lags",
                                "Ljung-Box rejeita autocorrelação significativa nos resíduos",
                                "Gráficos comparativos original vs transformada mostram remoção de não-estacionariedade"
                              ],
                              "assessmentCriteria": [
                                "Correta identificação de tipo de não-estacionariedade (tendência/variância/sazonal)",
                                "Aplicação precisa de transformações com código limpo e sem erros",
                                "Validação estatística rigorosa com múltiplos testes",
                                "Iteração lógica até convergência para estacionariedade",
                                "Documentação clara de passos e decisões",
                                "Preparação adequada para ARIMA (definição de d)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses unit root (ADF/KPSS)",
                                "Programação: Manipulação de dados em Python/R (pandas, dplyr)",
                                "Engenharia de Processos: Análise de sensores em tempo real",
                                "Machine Learning: Pré-processamento para modelos de previsão"
                              ],
                              "realWorldApplication": "Em manutenção preditiva de turbinas eólicas, transformar séries de vibração não estacionárias permite modelar ARIMA para prever falhas, reduzindo downtime em 20% e custos de manutenção."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.1.1"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.2.2",
                        "name": "Componentes do Modelo ARIMA",
                        "description": "Estrutura do modelo ARIMA(p,d,q), abrangendo partes autoregressiva (AR), integrada (I) e média móvel (MA), com ênfase em modelagem de dados temporais dinâmicos.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.2.2.1",
                            "name": "Especificar ordens p, d e q do modelo ARIMA",
                            "description": "Determinar as ordens autoregressiva (p), de integração (d) e média móvel (q) com base em gráficos ACF/PACF e critérios como AIC/BIC para séries de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Verificar estacionariedade da série temporal e determinar a ordem de integração (d)",
                                  "subSteps": [
                                    "Carregue os dados da série temporal em um ambiente como Python (statsmodels) ou R.",
                                    "Plote o gráfico da série original e realize o teste de Dickey-Fuller Aumentado (ADF) para verificar estacionariedade.",
                                    "Aplique diferenciação de primeira ordem (diff) se p-valor > 0.05 e repita o teste ADF.",
                                    "Continue diferenciando até que o teste ADF indique estacionariedade (p-valor < 0.05) e registre o número de diferenças como d.",
                                    "Plote os gráficos das séries diferenciadas para visual confirmação de estacionariedade."
                                  ],
                                  "verification": "O teste ADF na série diferenciada d vezes apresenta p-valor < 0.05 e os gráficos mostram ausência de tendência ou variância crescente.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python com bibliotecas statsmodels, pandas, matplotlib",
                                    "Jupyter Notebook",
                                    "Dataset de série temporal (ex: dados de sensores de engenharia)"
                                  ],
                                  "tips": "Sempre visualize os gráficos antes e após diferenciação; evite overdifferencing que pode induzir autocorrelação negativa.",
                                  "learningObjective": "Compreender e aplicar testes de estacionariedade para determinar a ordem d necessária para tornar a série estacionária.",
                                  "commonMistakes": [
                                    "Não plotar gráficos visuais além do teste estatístico",
                                    "Diferenciar excessivamente sem validação",
                                    "Ignorar possíveis componentes sazonais"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar e interpretar os gráficos de autocorrelação (ACF) e autocorrelação parcial (PACF)",
                                  "subSteps": [
                                    "Com a série estacionária (após d diferenças), gere o gráfico ACF usando função acf() ou plot_acf().",
                                    "Gere o gráfico PACF usando pacf() ou plot_pacf().",
                                    "Identifique lags significativos no ACF: barras acima da linha de confiança indicam autocorrelações relevantes.",
                                    "Identifique lags significativos no PACF: decay exponencial ou sinusoidal sugere ordem p.",
                                    "Anote os primeiros lags significativos em cada gráfico (ex: corte abrupto após lag k)."
                                  ],
                                  "verification": "Gráficos ACF e PACF gerados corretamente com lags significativos anotados e interpretados verbalmente.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python statsmodels.tsa.stattools",
                                    "R forecast package",
                                    "Série temporal estacionária preparada"
                                  ],
                                  "tips": "Use confiança de 95% para significância; foque nos primeiros 10-20 lags para séries curtas.",
                                  "learningObjective": "Interpretar padrões em ACF e PACF para identificar dependências temporais na série estacionária.",
                                  "commonMistakes": [
                                    "Confundir ACF com PACF",
                                    "Ignorar a linha de confiança azul",
                                    "Considerar lags insignificantes como relevantes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Propor ordens candidatas para p (autoregressiva) e q (média móvel) baseadas em ACF/PACF",
                                  "subSteps": [
                                    "Para ordem p: número de lags significativos no PACF antes do corte para zero (ex: PACF significativo até lag 2 → p=2).",
                                    "Para ordem q: número de lags significativos no ACF antes do corte para zero (ex: ACF significativo até lag 1 → q=1).",
                                    "Considere padrões alternativos: decay exponencial em ACF sugere MA(q), sinusoidal em ambos sugere ARMA.",
                                    "Liste 3-5 combinações candidatas de (p,q) baseadas nos gráficos (ex: (1,1), (2,0), (0,2)).",
                                    "Documente a justificativa para cada candidato com referência aos lags observados."
                                  ],
                                  "verification": "Lista de combinações (p,q) candidatas com justificativas baseadas em padrões ACF/PACF.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Gráficos ACF/PACF do passo anterior",
                                    "Folha de papel ou notebook para anotar candidatos"
                                  ],
                                  "tips": "Comece com modelos simples (baixos p+q); padrões mistos podem requerer ARMA(p,q).",
                                  "learningObjective": "Mapear interpretações de ACF/PACF diretamente para ordens p e q em modelos ARIMA.",
                                  "commonMistakes": [
                                    "Atribuir p baseado em ACF em vez de PACF",
                                    "Escolher ordens muito altas sem evidência",
                                    "Ignorar combinações híbridas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Ajustar modelos ARIMA(p,d,q) candidatos e selecionar o melhor usando critérios AIC/BIC",
                                  "subSteps": [
                                    "Ajuste os modelos ARIMA(p,d,q) para cada combinação candidata usando função ARIMA().",
                                    "Calcule AIC e BIC para cada modelo ajustado.",
                                    "Selecione o modelo com o menor AIC/BIC; compare resíduos para ausência de autocorrelação (Ljung-Box test).",
                                    "Plote resíduos e verifique normalidade/ausência de padrão.",
                                    "Confirme o modelo final com previsão de curto prazo e comparação com dados reais."
                                  ],
                                  "verification": "Modelo selecionado com AIC/BIC mais baixo, resíduos brancos (p-valor Ljung-Box >0.05).",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python statsmodels.tsa.arima.model.ARIMA",
                                    "R arima()",
                                    "Combinações candidatas"
                                  ],
                                  "tips": "Prefira BIC para parcimônia; sempre valide resíduos antes de finalizar.",
                                  "learningObjective": "Usar critérios informativos para refinar e validar a especificação do modelo ARIMA.",
                                  "commonMistakes": [
                                    "Não verificar resíduos",
                                    "Escolher apenas por AIC sem BIC",
                                    "Overfitting com p+q alto"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados de vibração de uma turbina eólica (série temporal diária de 500 observações). Após plotar, teste ADF indica d=1. ACF mostra decay lento até lag 1 (q=1), PACF corta após lag 2 (p=2). Ajuste ARIMA(2,1,1): AIC=1450, BIC=1460 (melhor que (1,1,1) com AIC=1480). Resíduos confirmam adequação para previsão de falhas.",
                              "finalVerifications": [
                                "Explica corretamente a diferença entre ACF e PACF na determinação de p e q.",
                                "Determina d=1 para uma série com tendência linear via ADF e plots.",
                                "Lista pelo menos 3 combinações candidatas com justificativa.",
                                "Seleciona modelo com menor AIC/BIC e valida resíduos.",
                                "Aplica o processo completo em um dataset novo com >80% acurácia.",
                                "Identifica overdifferencing em uma série já estacionária."
                              ],
                              "assessmentCriteria": [
                                "Precisão na determinação de d via testes e visualização (30%).",
                                "Interpretação correta de padrões ACF/PACF para p/q (25%).",
                                "Geração de combinações candidatas relevantes (15%).",
                                "Seleção rigorosa via AIC/BIC e validação de resíduos (20%).",
                                "Documentação clara e justificativas lógicas (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipóteses (ADF, Ljung-Box).",
                                "Programação Computacional: Python/R para análise de séries temporais.",
                                "Engenharia de Controle: Previsão em sistemas dinâmicos.",
                                "Machine Learning: Modelos de forecasting como baseline para redes neurais.",
                                "Análise de Dados Exploratória: Visualização gráfica de padrões temporais."
                              ],
                              "realWorldApplication": "Em engenharia, especificar p,d,q ARIMA permite prever demanda de energia em redes elétricas, detectar anomalias em sensores de monitoramento estrutural ou otimizar manutenção preditiva em equipamentos industriais baseados em séries de vibração ou temperatura, reduzindo custos e downtime."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.1.2",
                              "10.1.7.2.1.3"
                            ]
                          },
                          {
                            "id": "10.1.7.2.2.2",
                            "name": "Implementar modelo AR(p)",
                            "description": "Construir e interpretar um modelo autoregressivo puro AR(p) para capturar dependências passadas em dados temporais de sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e Explorar os Dados Temporais",
                                  "subSteps": [
                                    "Carregar o conjunto de dados temporais usando pandas em Python.",
                                    "Verificar a estrutura dos dados: índice temporal, valores ausentes e tipo de dados.",
                                    "Visualizar a série temporal com plots de linha e histograma para identificar padrões.",
                                    "Calcular estatísticas descritivas básicas (média, variância, autocorrelação inicial).",
                                    "Dividir os dados em treino e teste (ex: 80/20)."
                                  ],
                                  "verification": "Dados carregados corretamente, plots gerados sem erros e divisão realizada.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com pandas, matplotlib, numpy",
                                    "Conjunto de dados temporais (ex: AirPassengers ou dados de carga industrial)"
                                  ],
                                  "tips": "Sempre defina o índice como DatetimeIndex para facilitar operações temporais.",
                                  "learningObjective": "Entender a estrutura de dados temporais e prepará-los para modelagem AR(p).",
                                  "commonMistakes": [
                                    "Ignorar valores ausentes",
                                    "Não converter índice para datetime",
                                    "Usar divisão aleatória em vez de sequencial"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Testar Estacionariedade da Série",
                                  "subSteps": [
                                    "Realizar teste de Dickey-Fuller Aumentado (ADF) usando statsmodels.",
                                    "Visualizar decomposição da série (trend, seasonal, residual) com seasonal_decompose.",
                                    "Aplicar diferenciação se necessário e retestar estacionariedade.",
                                    "Confirmar que a série é estacionária (p-value < 0.05 no ADF).",
                                    "Documentar o número de diferenciações requeridas (para AR(p) puro, idealmente 0)."
                                  ],
                                  "verification": "Teste ADF passa com p-value < 0.05 e resíduos sem trend claro nos plots.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels.tsa.stattools.adfuller",
                                    "statsmodels.tsa.seasonal.seasonal_decompose"
                                  ],
                                  "tips": "Use log-transformação se variância aumentar com o tempo antes de testar.",
                                  "learningObjective": "Garantir que os pressupostos de estacionariedade para AR(p) sejam atendidos.",
                                  "commonMistakes": [
                                    "Não testar múltiplas lags no ADF",
                                    "Ignorar sazonalidade",
                                    "Diferenciar excessivamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar a Ordem p do Modelo AR",
                                  "subSteps": [
                                    "Calcular e plotar Função de Autocorrelação (ACF) até lag 20.",
                                    "Calcular e plotar Função de Autocorrelação Parcial (PACF) até lag 20.",
                                    "Identificar p como o lag onde PACF corta para zero (significância 95%).",
                                    "Usar critério de informação AIC/BIC para confirmar ordens candidatas.",
                                    "Selecionar a ordem p ótima baseada em cortes significativos."
                                  ],
                                  "verification": "Plots de ACF/PACF gerados e ordem p justificada com evidências visuais e AIC.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.graphics.tsaplots.plot_acf",
                                    "statsmodels.graphics.tsaplots.plot_pacf"
                                  ],
                                  "tips": "PACF é mais confiável para AR(p); procure decays exponenciais em ACF.",
                                  "learningObjective": "Selecionar empiricamente a ordem p usando ferramentas gráficas e informacionais.",
                                  "commonMistakes": [
                                    "Confundir ACF com PACF",
                                    "Escolher p muito alto sem penalidade AIC",
                                    "Ignorar significância das barras"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Ajustar e Estimar o Modelo AR(p)",
                                  "subSteps": [
                                    "Instanciar o modelo ARIMA(p,0,0) usando statsmodels.tsa.arima.model.ARIMA.",
                                    "Ajustar o modelo aos dados de treino com método de máxima verossimilhança.",
                                    "Examinar coeficientes φ1 a φp e seu p-values (todos < 0.05 idealmente).",
                                    "Gerar previsões in-sample e out-of-sample no conjunto de teste.",
                                    "Calcular métricas de ajuste como RMSE e R²."
                                  ],
                                  "verification": "Modelo ajustado sem erros, coeficientes significativos e RMSE baixo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels.tsa.arima.model.ARIMA",
                                    "Dados de treino/teste preparados"
                                  ],
                                  "tips": "Use order=(p,0,0) para AR(p) puro; especifique trend='c' para constante.",
                                  "learningObjective": "Implementar e estimar parâmetros de um modelo AR(p) em software.",
                                  "commonMistakes": [
                                    "Incluir MA ou integração desnecessárias",
                                    "Não checar multicolinearidade em lags altos",
                                    "Esquecer de fit()"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Diagnosticar, Interpretar e Aplicar o Modelo",
                                  "subSteps": [
                                    "Analisar resíduos: plot Q-Q, teste Ljung-Box para white noise.",
                                    "Verificar normalidade dos resíduos com teste Jarque-Bera.",
                                    "Interpretar coeficientes: φi indica impacto do lag i.",
                                    "Gerar previsões de h-steps ahead e intervalos de confiança.",
                                    "Comparar com baseline (média ou naive forecast)."
                                  ],
                                  "verification": "Resíduos passam em testes de white noise e normalidade; previsões coerentes.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.stats.diagnostic",
                                    "model.resid.plot()"
                                  ],
                                  "tips": "Resíduos devem se comportar como ruído branco: sem autocorrelação.",
                                  "learningObjective": "Validar o modelo e interpretar suas implicações em sistemas de controle.",
                                  "commonMistakes": [
                                    "Aceitar resíduos autocorrelacionados",
                                    "Ignorar intervalos de confiança",
                                    "Superinterpretar coeficientes insignificantes"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados históricos de carga elétrica em um sistema de controle industrial (ex: dataset de consumo de energia), implemente um AR(2) para prever a carga futura baseada em dependências das últimas 2 observações, ajudando a otimizar alocação de recursos.",
                              "finalVerifications": [
                                "Série estacionária confirmada por ADF (p<0.05).",
                                "Ordem p selecionada com PACF cortando em lag p.",
                                "Todos coeficientes φi significativos (p<0.05).",
                                "Resíduos são white noise (Ljung-Box p>0.05).",
                                "Previsões out-of-sample com RMSE < baseline.",
                                "Modelo interpretado corretamente em contexto de controle."
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação e teste de estacionariedade (30%).",
                                "Correta identificação de p via ACF/PACF/AIC (25%).",
                                "Ajuste e diagnóstico do modelo sem erros (20%).",
                                "Interpretação clara dos coeficientes e resíduos (15%).",
                                "Previsões e métricas comparativas válidas (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em parâmetros e testes de hipóteses.",
                                "Programação: Manipulação de dados com Python/pandas/statsmodels.",
                                "Engenharia de Controle: Modelagem dinâmica de sistemas.",
                                "Machine Learning: Séries temporais como base para redes recorrentes.",
                                "Econometria: Aplicações em previsão financeira."
                              ],
                              "realWorldApplication": "Em sistemas de controle de processos industriais, modelos AR(p) capturam dependências temporais em variáveis como temperatura ou fluxo, permitindo previsões para manutenção preditiva e controle adaptativo em tempo real."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.1.3"
                            ]
                          },
                          {
                            "id": "10.1.7.2.2.3",
                            "name": "Implementar modelo MA(q)",
                            "description": "Desenvolver um modelo de média móvel MA(q) para modelar erros correlacionados em resíduos de séries temporais de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados da série temporal para modelagem MA(q)",
                                  "subSteps": [
                                    "Carregue os dados da série temporal usando pandas (ex: dados de resíduos de um processo industrial).",
                                    "Verifique e trate valores ausentes ou outliers usando interpolação ou remoção.",
                                    "Teste estacionariedade dos resíduos com teste ADF (Augmented Dickey-Fuller).",
                                    "Diferencie a série se necessário para torná-la estacionária.",
                                    "Plote a série temporal e ACF inicial para visualizar correlações."
                                  ],
                                  "verification": "Série é estacionária (p-value ADF < 0.05) e plot da ACF mostra decaimento lento indicando correlação nos erros.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python 3.x",
                                    "Bibliotecas: pandas, numpy, statsmodels, matplotlib"
                                  ],
                                  "tips": "Sempre padronize os dados antes de modelar para melhorar convergência.",
                                  "learningObjective": "Preparar dados estacionários prontos para modelagem MA(q).",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade levando a modelos inválidos.",
                                    "Não tratar outliers distorcendo a ACF."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificar a ordem q do modelo MA usando função de autocorrelação (ACF)",
                                  "subSteps": [
                                    "Calcule e plote a ACF dos resíduos até lag 20-30.",
                                    "Identifique lags significativos onde ACF corta zero (decaimento exponencial ou sinusoidal).",
                                    "Defina q como o lag onde ACF se torna insignificante (ex: q=2 se ACF significativo até lag 2).",
                                    "Compare com PACF para confirmar ausência de AR.",
                                    "Documente a escolha de q com justificativa baseada no plot."
                                  ],
                                  "verification": "Plot ACF mostra q lags significativos e escolha de q é justificada por critérios como Ljung-Box.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python: statsmodels.tsa.stattools.acf e plot_acf",
                                    "Jupyter Notebook para visualização"
                                  ],
                                  "tips": "Use limite de confiança de 95% na ACF para determinar significância.",
                                  "learningObjective": "Selecionar ordem q apropriada baseada em evidências empíricas da ACF.",
                                  "commonMistakes": [
                                    "Escolher q muito alto causando overfitting.",
                                    "Confundir ACF com PACF."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar o modelo MA(q) aos resíduos",
                                  "subSteps": [
                                    "Importe ARIMA de statsmodels e defina modelo como SMA(q,0) ou ARIMA(0,q,0).",
                                    "Ajuste o modelo com fit() usando método de máxima verossimilhança.",
                                    "Examine coeficientes e intervalos de confiança (todos significativos).",
                                    "Calcule AIC/BIC para comparar com outros q.",
                                    "Salve o modelo ajustado."
                                  ],
                                  "verification": "Modelo convergeu sem warnings, coeficientes significativos (p<0.05), AIC baixo.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels.tsa.arima.model.ARIMA",
                                    "Dados preparados do step 1"
                                  ],
                                  "tips": "Use start_params para inicialização se convergência falhar.",
                                  "learningObjective": "Implementar e ajustar modelo MA(q) com parâmetros ótimos.",
                                  "commonMistakes": [
                                    "Não verificar significância de coeficientes.",
                                    "Ignorar warnings de não-convergência."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Diagnosticar e validar o modelo MA(q)",
                                  "subSteps": [
                                    "Extraia resíduos do modelo ajustado.",
                                    "Plote resíduos: QQ-plot, histograma e ACF dos resíduos.",
                                    "Teste Ljung-Box para autocorrelação nos resíduos (p>0.05 indica bom ajuste).",
                                    "Verifique normalidade com Jarque-Bera.",
                                    "Compare previsões in-sample com dados reais via RMSE."
                                  ],
                                  "verification": "Resíduos são white noise: ACF insignificante, Ljung-Box p>0.05, normalidade OK.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels diagnostics: plot_diagnostics()",
                                    "scipy.stats para testes"
                                  ],
                                  "tips": "Se diagnóstico falhar, aumente q ou revise preparação de dados.",
                                  "learningObjective": "Validar que o modelo MA(q) captura correlações nos erros.",
                                  "commonMistakes": [
                                    "Aceitar resíduos correlacionados.",
                                    "Não testar normalidade."
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar o modelo para previsão e interpretação",
                                  "subSteps": [
                                    "Gere previsões out-of-sample com forecast(steps=n).",
                                    "Calcule intervalos de confiança das previsões.",
                                    "Interprete coeficientes MA: sinal indica direção da correlação nos erros.",
                                    "Compare performance com baseline (média simples) usando MAE/RMSE.",
                                    "Documente relatório com plots e métricas."
                                  ],
                                  "verification": "Previsões precisas (RMSE < baseline), relatório completo.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Modelo ajustado",
                                    "matplotlib para plots de previsão"
                                  ],
                                  "tips": "Use dynamic=False para previsões condicionais estáveis.",
                                  "learningObjective": "Usar modelo MA(q) para previsões práticas em processos industriais.",
                                  "commonMistakes": [
                                    "Interpretar coeficientes sem contexto.",
                                    "Ignorar intervalos de confiança largos."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de cimento, resíduos de temperatura do forno mostram correlação (ACF sig até lag 2). Implemente MA(2): carregue dados diários, confirme estacionariedade, ajuste modelo (coef MA1=-0.4, MA2=0.3), valide resíduos white noise, preveja próximos 7 dias reduzindo variância de erro em 25%.",
                              "finalVerifications": [
                                "Modelo MA(q) ajustado converge e captura correlações nos resíduos.",
                                "Resíduos são white noise (ACF insignificante, Ljung-Box p>0.05).",
                                "Coeficientes significativos e ordem q justificada por ACF.",
                                "Previsões com IC razoáveis e melhor que baseline.",
                                "Relatório inclui plots, métricas (AIC, RMSE) e interpretação.",
                                "Código reproduzível sem erros."
                              ],
                              "assessmentCriteria": [
                                "Precisão na identificação de q via ACF (80% match com expert).",
                                "Qualidade do ajuste: AIC < threshold, resíduos independentes.",
                                "Validação completa com pelo menos 3 diagnósticos estatísticos.",
                                "Interpretação correta de coeficientes e aplicações.",
                                "Código limpo, comentado e eficiente (<5s execução).",
                                "Relatório profissional com visualizações claras."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses (ADF, Ljung-Box).",
                                "Programação: Manipulação de dados em Python/pandas.",
                                "Engenharia Industrial: Controle de processos e previsão de falhas.",
                                "Matemática: Séries temporais e processos estocásticos.",
                                "Machine Learning: Modelos univariados vs. redes neurais."
                              ],
                              "realWorldApplication": "Em processos industriais como monitoramento de temperatura em fornos ou pressão em tubulações, o MA(q) modela erros correlacionados nos resíduos de ARIMA, melhorando previsões de manutenção preditiva e reduzindo downtime em 15-20%."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.1.2"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.2.3",
                        "name": "Estimação, Diagnóstico e Previsão com ARIMA",
                        "description": "Processo de estimação por máxima verossimilhança, validação do modelo e geração de previsões para análise preditiva em sistemas dinâmicos de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.2.3.1",
                            "name": "Estimar parâmetros do modelo ARIMA",
                            "description": "Utilizar métodos de máxima verossimilhança ou mínimos quadrados para estimar coeficientes de um modelo ARIMA, avaliando significância estatística em contextos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os dados da série temporal para estimação ARIMA",
                                  "subSteps": [
                                    "Carregue o conjunto de dados de série temporal usando pandas.",
                                    "Verifique e trate valores ausentes ou outliers.",
                                    "Aplique diferenciação (d) se necessário para estacionariedade, usando testes como ADF.",
                                    "Divida os dados em treino e teste.",
                                    "Visualize a série com plots ACF/PACF para confirmar ordens preliminares."
                                  ],
                                  "verification": "Confirme que os dados estão estacionários (p-value ADF < 0.05) e plots ACF/PACF mostram decaimento rápido.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python com pandas, statsmodels, matplotlib",
                                    "Dataset de série temporal (ex: dados de consumo de energia)"
                                  ],
                                  "tips": "Sempre padronize a escala dos dados para melhorar convergência numérica.",
                                  "learningObjective": "Preparar dados limpos e estacionários prontos para modelagem ARIMA.",
                                  "commonMistakes": [
                                    "Ignorar não-estacionariedade levando a estimações enviesadas",
                                    "Não tratar missing values",
                                    "Usar dados não diferenciados adequadamente"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Especificar e inicializar o modelo ARIMA(p,d,q)",
                                  "subSteps": [
                                    "Defina as ordens p (autoregressivo), d (diferenciação) e q (média móvel) baseadas em ACF/PACF.",
                                    "Instancie o modelo ARIMA usando statsmodels.tsa.arima.model.ARIMA.",
                                    "Configure método de estimação: 'css-mle' para máxima verossimilhança condicional ou 'statespace' para MLE completo.",
                                    "Defina parâmetros iniciais se necessário para evitar falhas de convergência.",
                                    "Compile o modelo com enforce_stationarity=False se aplicável."
                                  ],
                                  "verification": "Modelo instanciado sem erros e ordens p,d,q justificadas por análise gráfica.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Biblioteca statsmodels",
                                    "Jupyter Notebook para experimentação"
                                  ],
                                  "tips": "Comece com modelos simples (p+q <=2) para testes iniciais.",
                                  "learningObjective": "Selecionar e configurar corretamente as ordens e método de estimação ARIMA.",
                                  "commonMistakes": [
                                    "Escolher ordens muito altas causando overfitting",
                                    "Não especificar método de estimação levando a defaults inadequados",
                                    "Ignorar warnings de convergência"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimar os coeficientes usando máxima verossimilhança ou mínimos quadrados",
                                  "subSteps": [
                                    "Ajuste o modelo chamando .fit() com method='css-mle' ou 'statespace'.",
                                    "Monitore iterações e verifique log-likelihood para convergência.",
                                    "Extraia coeficientes AR (phi), MA (theta) e variância de erro.",
                                    "Compare com mínimos quadrados condicionais se aplicável para validação.",
                                    "Salve o modelo ajustado para uso posterior."
                                  ],
                                  "verification": "Modelo ajustado com status 'converged' e valores de coeficientes finitos.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "statsmodels ARIMA",
                                    "Dados preparados do Step 1"
                                  ],
                                  "tips": "Aumente maxiter=1000 se houver falhas de convergência.",
                                  "learningObjective": "Aplicar métodos de estimação MLE/OLS para obter coeficientes ARIMA confiáveis.",
                                  "commonMistakes": [
                                    "Não verificar convergência resultando em NaNs",
                                    "Confundir MLE com OLS sem contexto",
                                    "Ignorar variância de erro na interpretação"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar significância estatística dos parâmetros estimados",
                                  "subSteps": [
                                    "Extraia summary() do modelo para t-statistics e p-values.",
                                    "Teste hipótese nula (coef=0) com p-value < 0.05 para significância.",
                                    "Calcule intervalos de confiança (95%) para cada coeficiente.",
                                    "Analise resíduos para autocorrelação (Ljung-Box test).",
                                    "Interprete resultados no contexto de engenharia (ex: impacto em previsões)."
                                  ],
                                  "verification": "Todos coeficientes significativos têm p-value < 0.05 e resíduos sem autocorrelação (p > 0.05 Ljung-Box).",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "statsmodels summary e diagnostics",
                                    "Gráficos de resíduos"
                                  ],
                                  "tips": "Use plot_diagnostics() para visualização rápida de resíduos.",
                                  "learningObjective": "Avaliar robustez estatística dos parâmetros ARIMA em aplicações reais.",
                                  "commonMistakes": [
                                    "Interpretar p-values sem múltiplos testes",
                                    "Ignorar resíduos correlacionados invalidando estimação",
                                    "Confundir significância com magnitude prática"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e refinar a estimação do modelo",
                                  "subSteps": [
                                    "Compare AIC/BIC com modelos alternativos para seleção.",
                                    "Gere previsões out-of-sample e calcule RMSE/MAE.",
                                    "Ajuste hiperparâmetros se p-values ruins (ex: mudar solver).",
                                    "Documente coeficientes e significância em relatório.",
                                    "Salve modelo para deployment em engenharia."
                                  ],
                                  "verification": "Modelo com AIC mínimo e previsões precisas (RMSE < threshold de benchmark).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Teste set de dados",
                                    "Métricas de erro como mean_squared_error"
                                  ],
                                  "tips": "Use auto_arima de pmdarima para benchmark rápido.",
                                  "learningObjective": "Refinar e validar estimação ARIMA para uso confiável.",
                                  "commonMistakes": [
                                    "Overfitting por não usar validação cruzada temporal",
                                    "Ignorar critérios de informação",
                                    "Não documentar decisões de refinamento"
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia elétrica, estime parâmetros ARIMA(1,1,1) para dados de consumo de energia horário de uma usina. Use MLE para obter phi=0.65 (p=0.02), theta=-0.45 (p=0.01), prevendo picos de demanda com RMSE=15kW.",
                              "finalVerifications": [
                                "Coeficientes estimados com p-values <0.05 em summary().",
                                "Resíduos independentes e normais (testes Ljung-Box e Jarque-Bera).",
                                "Modelo converge sem warnings e AIC otimizado.",
                                "Previsões out-of-sample com erro <10% do desvio padrão.",
                                "Relatório documenta método, resultados e interpretações.",
                                "Código reproduzível gera mesmos coeficientes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na estimação (coeficientes próximos a verdadeiros valores simulados).",
                                "Correta avaliação de significância (interpretação de p-values e CIs).",
                                "Qualidade de diagnóstico de resíduos (sem padrões).",
                                "Eficiência computacional (convergência em <50 iterações).",
                                "Aplicação contextual em engenharia (relevância prática).",
                                "Documentação clara de steps e decisões."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipótese e máxima verossimilhança.",
                                "Programação: Manipulação de dados com Python/pandas.",
                                "Engenharia: Modelagem preditiva para sistemas dinâmicos.",
                                "Matemática: Equações diferenciais e processos estocásticos.",
                                "Machine Learning: Comparação com modelos como LSTM."
                              ],
                              "realWorldApplication": "Em manutenção preditiva de turbinas eólicas, ARIMA estima parâmetros de vibrações para prever falhas, reduzindo downtime em 20% e custos de manutenção em engenharia industrial."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.2.1"
                            ]
                          },
                          {
                            "id": "10.1.7.2.3.2",
                            "name": "Diagnosticar adequação do modelo",
                            "description": "Realizar testes de resíduos (Ljung-Box), análise de normalidade e gráficos de resíduos para validar um modelo ARIMA ajustado a dados temporais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Obter e visualizar resíduos do modelo ARIMA ajustado",
                                  "subSteps": [
                                    "Ajuste o modelo ARIMA aos dados temporais usando statsmodels.tsa.arima.model.ARIMA.",
                                    "Extraia os resíduos com model_fit.residuais.",
                                    "Plote os resíduos no tempo usando matplotlib para identificar padrões.",
                                    "Gere um gráfico ACF (Autocorrelation Function) dos resíduos.",
                                    "Salve os gráficos para análise posterior."
                                  ],
                                  "verification": "Verifique se os resíduos estão centralizados em zero sem padrões óbvios nos plots.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python (statsmodels, matplotlib, pandas)",
                                  "tips": "Padronize os dados antes para evitar problemas de escala.",
                                  "learningObjective": "Compreender como extrair e visualizar resíduos para inspeção inicial.",
                                  "commonMistakes": "Esquecer de diferenciar a série se não estacionária; ignorar outiliers nos plots."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar teste de normalidade dos resíduos",
                                  "subSteps": [
                                    "Importe scipy.stats para testes como Shapiro-Wilk ou Kolmogorov-Smirnov.",
                                    "Aplique stats.shapiro(residuos) ou stats.normaltest(residuos).",
                                    "Gere um QQ-plot com statsmodels.qqplot(residuos).",
                                    "Interprete o p-value: >0.05 indica normalidade.",
                                    "Registre o estatístico e p-value em um relatório."
                                  ],
                                  "verification": "p-value > 0.05 e QQ-plot alinhado na reta diagonal.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Python (scipy.stats, statsmodels.graphics)",
                                  "tips": "Use amostras menores se n>5000 para Shapiro-Wilk, pois é sensível a grandes amostras.",
                                  "learningObjective": "Avaliar se resíduos seguem distribuição normal, pressuposto chave do ARIMA.",
                                  "commonMistakes": "Aplicar teste em resíduos não estacionários; confundir p-value com significância."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar teste Ljung-Box para autocorrelação serial",
                                  "subSteps": [
                                    "Use statsmodels.stats.diagnostic.acorr_ljungbox(residuos, lags=10).",
                                    "Especifique lags baseado no tamanho da amostra (ex: min(10, n/5)).",
                                    "Analise p-values para lags individuais e conjunto.",
                                    "Plote o Ljung-Box statistic vs lags.",
                                    "Conclua: p-value >0.05 para todos lags indica ausência de autocorrelação."
                                  ],
                                  "verification": "Tabela Ljung-Box mostra p-values >0.05 para lags relevantes.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Python (statsmodels.stats.diagnostic)",
                                  "tips": "Teste múltiplos lags para detectar autocorrelação em diferentes escalas.",
                                  "learningObjective": "Verificar independência dos resíduos, essencial para validade do modelo.",
                                  "commonMistakes": "Usar poucos lags; interpretar lb_stat como p-value."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar diagnósticos e concluir adequação do modelo",
                                  "subSteps": [
                                    "Compile resultados: normalidade OK? Autocorrelação ausente? Plots limpos?",
                                    "Verifique homocedasticidade com plot de resíduos vs fitted values.",
                                    "Se falhas, sugira ajustes (ex: mais AR/MA terms).",
                                    "Gere relatório com conclusões e gráficos.",
                                    "Salve modelo como adequado ou proponha refit."
                                  ],
                                  "verification": "Relatório escrito justifica adequação com evidências quantitativas e visuais.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Python (matplotlib para plots adicionais), Jupyter Notebook",
                                  "tips": "Use thresholds consistentes (alpha=0.05) para todos testes.",
                                  "learningObjective": "Sintetizar diagnósticos para decisão sobre modelo.",
                                  "commonMistakes": "Ignorar falhas menores; não documentar trade-offs."
                                }
                              ],
                              "practicalExample": "Usando dados de passageiros aéreos (AirPassengers dataset do R ou statsmodels), ajuste ARIMA(2,1,2), extraia resíduos, plote ACF/QQ, aplique Shapiro e Ljung-Box (lags=12). Conclusão: resíduos normais e sem autocorrelação, modelo adequado para previsão mensal.",
                              "finalVerifications": [
                                "Resíduos plotados mostram média zero e variância constante.",
                                "QQ-plot e teste de normalidade confirmam distribuição normal (p>0.05).",
                                "Ljung-Box rejeita autocorrelação para lags 1-10 (p>0.05).",
                                "Não há padrões nos gráficos de resíduos vs tempo ou fitted.",
                                "Relatório resume todos testes com valores exatos.",
                                "Modelo pode prosseguir para previsão sem ajustes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na extração e plotting de resíduos (20%).",
                                "Correta aplicação e interpretação de testes estatísticos (30%).",
                                "Qualidade visual e análise de gráficos (20%).",
                                "Conclusão lógica com evidências (20%).",
                                "Documentação completa e código reproduzível (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de hipóteses e distribuições.",
                                "Programação: Manipulação de dados em Python/statsmodels.",
                                "Engenharia: Modelagem preditiva em sistemas dinâmicos.",
                                "Análise de Dados: Validação de modelos em ML."
                              ],
                              "realWorldApplication": "Em engenharia, diagnosticar ARIMA para prever falhas em sensores IoT ou demanda energética, garantindo previsões confiáveis que evitam custos operacionais altos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.2.1",
                              "10.1.7.2.3.1"
                            ]
                          },
                          {
                            "id": "10.1.7.2.3.3",
                            "name": "Gerar previsões e intervalos de confiança",
                            "description": "Produzir previsões pontuais e intervalos de confiança com modelos ARIMA para prever comportamentos futuros em sistemas dinâmicos, como controle de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar o modelo ARIMA ajustado e definir o horizonte de previsão",
                                  "subSteps": [
                                    "Carregue o modelo ARIMA previamente ajustado usando statsmodels.tsa.arima.model.ARIMA.",
                                    "Defina o número de períodos a prever (h steps ahead) com base no contexto do problema.",
                                    "Verifique a estacionariedade residual do modelo com testes como Ljung-Box.",
                                    "Extraia os resíduos e confirme que não há autocorrelação significativa.",
                                    "Salve configurações em um dicionário para reproducibilidade."
                                  ],
                                  "verification": "Execute modelo.summary() e confirme ausência de padrões nos resíduos plotados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Python com statsmodels, pandas, matplotlib; dataset de série temporal ajustado.",
                                  "tips": "Use h=10-20 para testes iniciais para evitar sobrecarga computacional.",
                                  "learningObjective": "Entender como preparar um modelo ARIMA para geração de previsões confiáveis.",
                                  "commonMistakes": "Ignorar diagnóstico de resíduos, levando a previsões enviesadas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar previsões pontuais (point forecasts)",
                                  "subSteps": [
                                    "Use o método forecast(h=n) no modelo ajustado para obter previsões pontuais.",
                                    "Converta o resultado em um DataFrame com índices de tempo correspondentes.",
                                    "Plote as previsões sobrepostas à série histórica para inspeção visual.",
                                    "Calcule métricas iniciais como MAE em dados de validação, se disponível.",
                                    "Armazene previsões em variável para uso posterior."
                                  ],
                                  "verification": "Previsões geradas sem erros e plotadas corretamente alinhadas com dados históricos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Jupyter Notebook; biblioteca statsmodels e matplotlib.",
                                  "tips": "Sempre especifique o índice de tempo correto para alinhamento futuro.",
                                  "learningObjective": "Dominar a geração de previsões pontuais com ARIMA.",
                                  "commonMistakes": "Esquecer de estender o índice de tempo, causando desalinhamento."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular e extrair intervalos de confiança",
                                  "subSteps": [
                                    "Use forecast(h=n, alpha=0.05) para obter intervalos de 95% de confiança por padrão.",
                                    "Extraia limites inferior e superior em colunas separadas do DataFrame.",
                                    "Ajuste níveis de confiança (ex: alpha=0.1 para 90%) conforme necessidade.",
                                    "Plote faixas de confiança sombreadas junto às previsões pontuais.",
                                    "Verifique se os intervalos se alargam com o horizonte, como esperado."
                                  ],
                                  "verification": "Intervalos calculados e plotados, com largura crescente ao longo do tempo.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "statsmodels; seaborn para plots avançados.",
                                  "tips": "Use alpha menor para intervalos mais conservadores em aplicações críticas.",
                                  "learningObjective": "Aprender a quantificar incerteza em previsões ARIMA.",
                                  "commonMistakes": "Confundir alpha com nível de confiança (alpha=0.05 é 95%)."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar, validar e relatar previsões com intervalos",
                                  "subSteps": [
                                    "Compare previsões com dados hold-out se disponíveis, calculando cobertura de intervalos.",
                                    "Interprete: 'Previsão de 100±15 unidades com 95% confiança'.",
                                    "Gere relatório com tabela de previsões, intervalos e visualizações.",
                                    "Discuta implicações para sistemas dinâmicos, como limites de controle.",
                                    "Salve resultados em CSV ou PDF para compartilhamento."
                                  ],
                                  "verification": "Relatório gerado com interpretações corretas e cobertura de intervalos ~95%.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "pandas para export; matplotlib/seaborn para figs finais.",
                                  "tips": "Calcule cobertura empírica: % de pontos reais dentro dos intervalos.",
                                  "learningObjective": "Aplicar previsões e intervalos em contextos de engenharia.",
                                  "commonMistakes": "Superestimar precisão ignorando alargamento dos intervalos."
                                }
                              ],
                              "practicalExample": "Em uma usina de controle de processos, use ARIMA para prever a demanda de energia nos próximos 7 dias. Modelo ajustado em dados históricos de consumo: previsão pontual dia 1=150MW, intervalo 95% [140-160]MW, auxiliando no planejamento de geração.",
                              "finalVerifications": [
                                "Previsões pontuais geradas sem erros para h=10 períodos.",
                                "Intervalos de confiança plotados corretamente com alpha=0.05.",
                                "Cobertura empírica dos intervalos próxima a 95% em dados de teste.",
                                "Visualizações incluem histórico, previsões e faixas de confiança.",
                                "Relatório interpretativo salvo e compreensível.",
                                "Resíduos confirmados sem autocorrelação via Ljung-Box (p>0.05)."
                              ],
                              "assessmentCriteria": [
                                "Precisão na configuração e geração de previsões pontuais (30%).",
                                "Correta implementação e interpretação de intervalos de confiança (25%).",
                                "Qualidade das visualizações e validações (20%).",
                                "Relatório claro com interpretações práticas (15%).",
                                "Tratamento de erros comuns e dicas aplicadas (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Conceitos de incerteza e distribuições normais aproximadas.",
                                "Engenharia de Controle: Aplicação em sistemas dinâmicos e feedback.",
                                "Programação: Manipulação de dados com pandas e modelagem em statsmodels.",
                                "Análise de Dados: Integração com machine learning para ensembles."
                              ],
                              "realWorldApplication": "Em engenharia de processos, prever fluxos de produção em fábricas para otimizar estoque e evitar downtime; em finanças, forecast de séries temporais de preços para gerenciamento de risco."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.3.1",
                              "10.1.7.2.3.2"
                            ]
                          },
                          {
                            "id": "10.1.7.2.3.4",
                            "name": "Aplicar ARIMA em casos de engenharia",
                            "description": "Implementar análise ARIMA em dados reais de sistemas de controle contínuos/discretos, integrando com conceitos de estabilidade e realimentação para previsão de ruído e desempenho.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Coleta e Preparação de Dados de Séries Temporais de Engenharia",
                                  "subSteps": [
                                    "Identifique e carregue dados reais de sistemas de controle (ex: medições de ruído em um controlador PID discreto usando sensores).",
                                    "Realize testes de estacionariedade (ADF test) e aplique diferenciação se necessário para tornar a série estacionária.",
                                    "Trate valores ausentes, outliers e ruído utilizando decomposição sazonal ou filtros de suavização.",
                                    "Divida os dados em conjuntos de treino e teste (80/20).",
                                    "Visualize a série temporal com plots de autocorrelação (ACF) e autocorrelação parcial (PACF)."
                                  ],
                                  "verification": "Confirme estacionariedade com p-value < 0.05 no teste ADF e plots ACF/PACF decaindo rapidamente.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "Python com bibliotecas pandas, numpy, statsmodels, matplotlib",
                                    "Dataset real de engenharia (ex: dados de vibração de motor do UCI ML Repository)"
                                  ],
                                  "tips": "Sempre plote os dados primeiro para entender padrões; use log-transformação para variância não constante.",
                                  "learningObjective": "Preparar dados de séries temporais de engenharia para modelagem ARIMA, garantindo estacionariedade.",
                                  "commonMistakes": [
                                    "Ignorar sazonalidade levando a diferenciações excessivas",
                                    "Não tratar outliers causando viés no modelo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Identificação e Seleção dos Parâmetros do Modelo ARIMA",
                                  "subSteps": [
                                    "Analise gráficos ACF e PACF para estimar ordens p (AR), d (diferenciação) e q (MA).",
                                    "Use critério de informação (AIC/BIC) para testar múltiplas combinações de (p,d,q).",
                                    "Incorpore componentes de estabilidade do sistema de controle (ex: polos do controlador) na escolha de d.",
                                    "Ajuste um modelo ARIMA provisional usando statsmodels.tsa.arima.model.ARIMA.",
                                    "Compare modelos iniciais com validação cruzada temporal."
                                  ],
                                  "verification": "Modelo selecionado tem o menor AIC/BIC e resíduos brancos (Ljung-Box test p>0.05).",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "Biblioteca statsmodels para ARIMA e auto_arima do pmdarima"
                                  ],
                                  "tips": "Comece com ordens baixas (p,q <=2); auto_arima acelera mas valide manualmente.",
                                  "learningObjective": "Selecionar parâmetros ARIMA otimizados integrando análise gráfica e critérios estatísticos.",
                                  "commonMistakes": [
                                    "Sobreajuste com p/d/q altos",
                                    "Confundir spikes em ACF com sazonalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Estimação, Diagnóstico e Integração com Conceitos de Controle",
                                  "subSteps": [
                                    "Estime coeficientes do modelo ARIMA usando máxima verossimilhança.",
                                    "Diagnostique resíduos: teste normalidade (Jarque-Bera), homocedasticidade e independência.",
                                    "Integre com realimentação: simule impacto de previsões na estabilidade do laço de controle (ex: análise de Nyquist).",
                                    "Ajuste hiperparâmetros se resíduos não forem brancos.",
                                    "Gere intervalos de confiança para previsões."
                                  ],
                                  "verification": "Resíduos passam em testes diagnósticos (p>0.05) e Q-Q plot linear.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": [
                                    "statsmodels para diagnostics",
                                    "control library para simulação de sistemas"
                                  ],
                                  "tips": "Use plot_diagnostics() do statsmodels para visualização rápida; integre previsões como entrada de referência no controlador.",
                                  "learningObjective": "Diagnosticar modelo ARIMA e integrá-lo com análise de estabilidade e realimentação em engenharia.",
                                  "commonMistakes": [
                                    "Não verificar heterocedasticidade levando a previsões enviesadas",
                                    "Ignorar integração com controle"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Previsão, Validação e Aplicação em Cenários de Engenharia",
                                  "subSteps": [
                                    "Gere previsões de h-steps ahead para ruído/desempenho no conjunto de teste.",
                                    "Calcule métricas de erro (MAE, RMSE, MAPE) e compare com baselines (média móvel).",
                                    "Simule aplicação: use previsões para ajustar ganhos de realimentação e prever desempenho.",
                                    "Valide estabilidade pós-previsão via margens de ganho/fase.",
                                    "Documente relatório com plots de previsão vs real."
                                  ],
                                  "verification": "RMSE < 10% do desvio padrão dos dados e estabilidade confirmada (ganho >6dB, fase >45°).",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Datasets de teste",
                                    "Ferramentas de simulação como MATLAB/Simulink ou Python control"
                                  ],
                                  "tips": "Use forecast intervals para robustez; teste sensibilidade a parâmetros de controle.",
                                  "learningObjective": "Aplicar previsões ARIMA em contextos de engenharia de controle com validação completa.",
                                  "commonMistakes": [
                                    "Avaliar em treino só (overfitting)",
                                    "Não considerar horizonte de previsão finito"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de controle discreto de temperatura de um forno industrial, use dados históricos de ruído térmico (amostrados a 1Hz) para ajustar ARIMA(2,1,1), prever flutuações nos próximos 50 passos e otimizar ganhos PID para manter estabilidade com erro de rastreamento <2°C.",
                              "finalVerifications": [
                                "Modelo ARIMA ajustado prevê ruído com RMSE <5% nos dados de teste.",
                                "Resíduos são estacionários, normais e independentes (testes estatísticos aprovados).",
                                "Previsões integradas melhoram estabilidade do sistema (margens de ganho/fase adequadas).",
                                "Código reproduzível gera plots de previsão vs. observado.",
                                "Relatório documenta escolhas de parâmetros e impactos em desempenho de controle.",
                                "Simulação end-to-end mostra redução de variância em 20% com realimentação baseada em ARIMA."
                              ],
                              "assessmentCriteria": [
                                "Precisão da preparação de dados (estacionariedade confirmada: 25%)",
                                "Adequação da seleção de parâmetros ARIMA (AIC baixo e diagnósticos: 25%)",
                                "Qualidade de integração com controle/estabilidade (simulações válidas: 20%)",
                                "Métricas de previsão e validação (RMSE/MAPE: 15%)",
                                "Documentação e código limpo (reprodutível: 15%)"
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Controle: Estabilidade e realimentação via polos/zero.",
                                "Estatística: Testes de hipóteses e inferência em séries temporais.",
                                "Programação: Manipulação de dados em Python/R e visualização.",
                                "Machine Learning: Modelos univariados vs. redes neurais para séries temporais.",
                                "Física/Mecânica: Modelagem de ruído em sistemas dinâmicos."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, prever vibrações em turbinas de aviões para manutenção preditiva; em automotiva, forecast de ruído de motor para otimizar controle de emissões, reduzindo downtime em 15-30% em plantas industriais."
                            },
                            "estimatedTime": "3 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.2.3.3"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.7.3",
                    "name": "Análise de Componentes Principais (PCA)",
                    "description": "Técnica de redução de dimensionalidade aplicada a dados multivariados de sensores e medições em engenharia.",
                    "individualConcepts": [
                      {
                        "id": "10.1.7.3.1",
                        "name": "Fundamentos da Análise de Componentes Principais (PCA)",
                        "description": "Conceitos básicos da PCA como técnica de redução de dimensionalidade que transforma dados multivariados em componentes ortogonais, preservando a máxima variância, aplicada a dados de sensores e medições em engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.3.1.1",
                            "name": "Identificar problemas de alta dimensionalidade em dados multivariados",
                            "description": "Reconhecer desafios como a maldição da dimensionalidade em conjuntos de dados de sensores industriais, como vibrações ou temperaturas múltiplas, e justificar a necessidade de redução dimensional para análise eficiente.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender o conceito de dimensionalidade em dados multivariados",
                                  "subSteps": [
                                    "Defina dimensionalidade como o número de variáveis ou features em um conjunto de dados.",
                                    "Diferencie dados univariados, bivariados e multivariados com exemplos simples.",
                                    "Calcule a dimensionalidade de um dataset exemplo com 50 sensores de temperatura.",
                                    "Visualize dimensionalidade baixa vs. alta usando gráficos 2D e 3D.",
                                    "Discuta o volume do espaço de features em alta dimensionalidade."
                                  ],
                                  "verification": "Crie um diagrama ilustrando um dataset de 10 dimensões e explique seu volume exponencial.",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Notebook Jupyter ou Google Colab",
                                    "Biblioteca Matplotlib para visualizações",
                                    "Dataset exemplo com 5-10 features"
                                  ],
                                  "tips": "Use analogias como 'aumentar cômodos em uma casa' para visualizar o crescimento exponencial.",
                                  "learningObjective": "Explicar dimensionalidade e calcular para dados multivariados.",
                                  "commonMistakes": [
                                    "Confundir dimensionalidade com tamanho do dataset",
                                    "Ignorar o impacto exponencial no volume do espaço"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Reconhecer a maldição da dimensionalidade",
                                  "subSteps": [
                                    "Descreva a maldição da dimensionalidade como o crescimento exponencial da distância entre pontos.",
                                    "Liste problemas: esparsidade de dados, overfitting em modelos, custo computacional alto.",
                                    "Calcule o volume de uma hiperesfera unitária em dimensões crescentes (ex: d=1 a d=100).",
                                    "Simule esparsidade gerando pontos aleatórios em espaços de 2D, 10D e 50D.",
                                    "Compare distâncias médias entre pontos em diferentes dimensões."
                                  ],
                                  "verification": "Gere um gráfico mostrando distâncias médias crescendo com dimensões e interprete.",
                                  "estimatedTime": "30-45 minutos",
                                  "materials": [
                                    "Python com NumPy e SciPy",
                                    "Código para simulação de hiperesferas",
                                    "Gráficos interativos com Plotly"
                                  ],
                                  "tips": "Normalize dados antes de calcular distâncias para evitar viés de escala.",
                                  "learningObjective": "Identificar e quantificar impactos da maldição da dimensionalidade.",
                                  "commonMistakes": [
                                    "Subestimar esparsidade em dimensões médias (acima de 10)",
                                    "Confundir com multicolinearidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar alta dimensionalidade em dados de sensores industriais",
                                  "subSteps": [
                                    "Carregue um dataset real de sensores (ex: vibrações de turbinas com 100 canais).",
                                    "Analise estatísticas: número de features, correlações, missing values.",
                                    "Plote matriz de correlação e heatmap para visualizar redundâncias.",
                                    "Calcule métricas como razão sinal-ruído e variância explicada por feature.",
                                    "Detecte sinais de maldição: distâncias euclidianas saturando ou dados esparsos."
                                  ],
                                  "verification": "Produza um relatório resumindo 5 evidências de alta dimensionalidade no dataset.",
                                  "estimatedTime": "40-60 minutos",
                                  "materials": [
                                    "Dataset NASA Turbofan ou UCI Sensor Dataset",
                                    "Pandas e Seaborn para análise",
                                    "Jupyter Notebook"
                                  ],
                                  "tips": "Filtre outliers antes da análise para resultados mais limpos.",
                                  "learningObjective": "Aplicar diagnóstico de dimensionalidade em dados industriais reais.",
                                  "commonMistakes": [
                                    "Ignorar features correlacionadas como indício de redução possível",
                                    "Usar visualizações inadequadas para >3D"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Justificar a necessidade de redução dimensional",
                                  "subSteps": [
                                    "Explique benefícios: redução de ruído, aceleração computacional, melhor generalização.",
                                    "Compare performance de modelo (ex: KNN) antes/depois de redução simulada.",
                                    "Discuta técnicas como PCA, t-SNE para mitigação em sensores.",
                                    "Quantifique ganhos: tempo de treinamento, acurácia em validação cruzada.",
                                    "Escreva uma justificativa formal para um caso de manutenção preditiva."
                                  ],
                                  "verification": "Redija um parágrafo justificando PCA para o dataset analisado, com métricas.",
                                  "estimatedTime": "25-40 minutos",
                                  "materials": [
                                    "Scikit-learn para PCA demo",
                                    "Dataset do Step 3",
                                    "Métricas de modelo como accuracy_score"
                                  ],
                                  "tips": "Sempre valide redução com cross-validation para evitar perda de informação.",
                                  "learningObjective": "Argumentar racionalmente pela redução dimensional com evidências.",
                                  "commonMistakes": [
                                    "Recomendar redução sem verificar variância preservada",
                                    "Ignorar custo-benefício computacional"
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de turbinas eólicas, dados de 200 sensores de vibração (200 dimensões) mostram esparsidade: distâncias entre amostras saturam em 50D, correlações >0.9 em 60% das features. Redução via PCA para 10 componentes preserva 95% variância, reduzindo tempo de análise de horas para minutos e melhorando detecção de falhas em 20%.",
                              "finalVerifications": [
                                "Explique maldição da dimensionalidade com fórmula de volume hiperesférico.",
                                "Identifique 3 problemas em um dataset de 100 features de sensores.",
                                "Justifique redução dimensional com pelo menos 2 métricas quantitativas.",
                                "Gere visualização de esparsidade em 2D vs. 50D.",
                                "Compare performance de modelo pré/pós-redução.",
                                "Redija relatório de 200 palavras sobre um caso industrial."
                              ],
                              "assessmentCriteria": [
                                "Precisão na definição e cálculo de dimensionalidade (20%)",
                                "Identificação correta de sintomas da maldição (25%)",
                                "Análise relevante de datasets industriais (20%)",
                                "Justificativa lógica e evidenciada (20%)",
                                "Uso adequado de ferramentas e visualizações (10%)",
                                "Clareza na comunicação de resultados (5%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Análise de variância e correlação",
                                "Machine Learning: Overfitting e regularização",
                                "Engenharia Industrial: Manutenção preditiva com IoT",
                                "Computação Científica: Otimização numérica em alta dimensão",
                                "Visualização de Dados: Técnicas para dados multidimensionais"
                              ],
                              "realWorldApplication": "Na indústria 4.0, engenheiros usam essa habilidade para processar dados de milhares de sensores em linhas de produção, reduzindo dimensionalidade antes de modelos de IA para prever falhas em equipamentos, economizando milhões em downtime e otimizando operações em tempo real."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.3.1.2",
                            "name": "Explicar os objetivos e princípios da PCA",
                            "description": "Descrever como a PCA maximiza a variância explicada por componentes principais ortogonais, diferenciando-a de técnicas como análise fatorial, com foco em aplicações econométricas e de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Objetivos Principais da PCA",
                                  "subSteps": [
                                    "Defina PCA como uma técnica de redução de dimensionalidade não supervisionada.",
                                    "Identifique objetivos chave: maximizar variância explicada, remover redundâncias e facilitar visualização de dados.",
                                    "Discuta como PCA transforma dados originais em um novo espaço de menor dimensão preservando informação.",
                                    "Explore cenários onde PCA é útil, como datasets de alta dimensionalidade em engenharia.",
                                    "Revise exemplos iniciais de problemas que PCA resolve, como multicolinearidade."
                                  ],
                                  "verification": "Liste e explique pelo menos três objetivos principais da PCA com exemplos breves.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Notebook para anotações",
                                    "Vídeo introdutório sobre PCA (ex: Khan Academy)",
                                    "Artigo 'A Tutorial on Principal Component Analysis' de Shlens"
                                  ],
                                  "tips": [
                                    "Use analogias como 'comprimir uma imagem sem perda visível' para fixar conceitos.",
                                    "Desenhe um fluxograma simples dos objetivos."
                                  ],
                                  "learningObjective": "Identificar e articular os objetivos fundamentais da PCA em contextos de análise de dados.",
                                  "commonMistakes": [
                                    "Confundir PCA com clustering (PCA é para redução linear, não agrupamento).",
                                    "Ignorar que PCA é não supervisionada e não usa rótulos."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Explicar os Princípios Matemáticos da PCA: Variância e Ortogonalidade",
                                  "subSteps": [
                                    "Revise conceitos de covariância e matriz de covariância para dados multivariados.",
                                    "Explique que componentes principais são autovetores da matriz de covariância, ordenados por autovalores (variância).",
                                    "Descreva ortogonalidade: componentes principais são vetores ortogonais que capturam variância máxima sequencialmente.",
                                    "Demonstre matematicamente como o primeiro PC maximiza variância projetada, e os subsequentes maximizam variância residual.",
                                    "Calcule um exemplo simples com 2D para ilustrar rotação e escalonamento."
                                  ],
                                  "verification": "Derive ou explique a fórmula de maximização de variância para o primeiro componente principal.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Python com NumPy/SciPy para matriz de covariância",
                                    "Folha de cálculo ou papel para cálculo manual 2D",
                                    "Tutorial interativo de PCA no scikit-learn"
                                  ],
                                  "tips": [
                                    "Visualize com gráficos de dispersão antes/depois da PCA para intuição geométrica.",
                                    "Comece com dados centrados (média zero)."
                                  ],
                                  "learningObjective": "Dominar os princípios matemáticos de maximização de variância e ortogonalidade na PCA.",
                                  "commonMistakes": [
                                    "Esquecer de centralizar dados antes do cálculo.",
                                    "Confundir autovalores com variância total em vez de por componente."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Diferenciar PCA de Técnicas Relacionadas como Análise Fatorial",
                                  "subSteps": [
                                    "Compare PCA (baseada em variância total) vs. Análise Fatorial (baseada em variância comum).",
                                    "Explique que PCA usa matriz de covariância, enquanto FA modela fatores latentes com erros únicos.",
                                    "Discuta rotações: PCA tem rotações únicas por variância decrescente; FA permite rotações interpretáveis (varimax).",
                                    "Identifique quando usar cada: PCA para redução dim em engenharia; FA para modelagem psicológica/econômica.",
                                    "Forneça tabela comparativa de suposições, outputs e aplicações."
                                  ],
                                  "verification": "Crie uma tabela comparando 4 diferenças chave entre PCA e Análise Fatorial.",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Tabela comparativa em documento ou Excel",
                                    "Leitura: 'PCA vs Factor Analysis' de Jolliffe",
                                    "Exemplos de datasets para ambos"
                                  ],
                                  "tips": [
                                    "Use mnemônicos: PCA = 'Principal' variância total; FA = 'Fatores' comuns.",
                                    "Teste com software para ver diferenças em loadings."
                                  ],
                                  "learningObjective": "Diferenciar precisamente PCA de análise fatorial em termos teóricos e práticos.",
                                  "commonMistakes": [
                                    "Achar que ambas são idênticas (PCA não assume estrutura fatorial).",
                                    "Ignorar que FA é paramétrica e PCA exploratória."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Explorar Aplicações em Econometria e Engenharia",
                                  "subSteps": [
                                    "Em econometria: reduza multicolinearidade em regressões com muitos preditores econômicos.",
                                    "Em engenharia: aplique em análise de sinais para monitoramento de falhas (ex: vibrações).",
                                    "Discuta scree plot e critério de Kaiser para selecionar número de componentes.",
                                    "Integre com foco em variância explicada cumulativa (>80-90%).",
                                    "Planeje um mini-projeto: aplique PCA a dataset real e interprete componentes."
                                  ],
                                  "verification": "Descreva uma aplicação específica em econometria ou engenharia com passos de implementação.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Dataset exemplo: Boston Housing ou sensores IoT",
                                    "Python/Jupyter com scikit-learn",
                                    "Gráficos de biplot para interpretação"
                                  ],
                                  "tips": [
                                    "Sempre reporte % variância explicada por componente.",
                                    "Interprete componentes via loadings altos."
                                  ],
                                  "learningObjective": "Aplicar conceitos de PCA a domínios específicos como econometria e engenharia.",
                                  "commonMistakes": [
                                    "Selecionar todos componentes (use elbow method).",
                                    "Interpretar componentes sem contexto de variáveis originais."
                                  ]
                                }
                              ],
                              "practicalExample": "Em engenharia mecânica, aplique PCA a dados de 50 sensores de vibração em uma turbina (100 features). Reduza para 4 componentes principais que explicam 95% da variância, identificando padrões de falha sem ruído, permitindo manutenção preditiva.",
                              "finalVerifications": [
                                "Explicar verbalmente como PCA maximiza variância com ortogonalidade.",
                                "Diferenciar PCA de análise fatorial em 3 pontos chave.",
                                "Interpretar um scree plot de exemplo.",
                                "Calcular % variância explicada cumulativa para um caso simples.",
                                "Propor uma aplicação em econometria ou engenharia.",
                                "Criar diagrama conceitual dos passos da PCA."
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: uso correto de termos como 'autovetores' e 'variância explicada' (30%).",
                                "Profundidade matemática: demonstração de princípios de maximização (25%).",
                                "Diferenciação clara: distinção precisa de análise fatorial (20%).",
                                "Aplicações relevantes: exemplos contextualizados em econometria/engenharia (15%).",
                                "Clareza e estrutura: explicação lógica e visual (10%)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Matriz de covariância e autovalores.",
                                "Machine Learning: Pré-processamento para modelos supervisionados.",
                                "Econometria: Tratamento de multicolinearidade em modelos econômicos.",
                                "Engenharia: Análise de sinais e controle de sistemas.",
                                "Visualização de Dados: Gráficos biplot e scree plots."
                              ],
                              "realWorldApplication": "Na econometria, bancos usam PCA para extrair fatores de risco de portfólios de ações correlacionadas, reduzindo dimensionalidade de milhares de ativos para 5-10 componentes principais, melhorando previsões de VaR (Value at Risk). Em engenharia aeroespacial, a NASA aplica PCA para comprimir dados de telemetria de satélites, detectando anomalias em tempo real."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "beginner",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.3.1.3",
                            "name": "Diferenciar variáveis originais de componentes principais",
                            "description": "Comparar as variáveis originais correlacionadas (ex.: medições de sensores) com os componentes principais não correlacionados, destacando a rotação ortogonal e perda mínima de informação.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender as Variáveis Originais e Sua Correlação",
                                  "subSteps": [
                                    "Identifique variáveis originais em um dataset, como medições de sensores (ex.: temperatura, umidade, pressão).",
                                    "Calcule a matriz de correlação para visualizar dependências lineares entre variáveis.",
                                    "Interprete coeficientes de correlação: valores próximos de 1 ou -1 indicam alta correlação.",
                                    "Discuta impactos da multicolinearidade em análises, como instabilidade em regressões.",
                                    "Visualize correlações com heatmap usando bibliotecas como Seaborn."
                                  ],
                                  "verification": "Construa e interprete uma matriz de correlação para um dataset de sensores e explique pelo menos duas correlações fortes.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dataset de sensores (ex.: CSV com medições ambientais), Python com Pandas e Seaborn, Jupyter Notebook.",
                                  "tips": "Comece com datasets pequenos (10-20 variáveis) para facilitar a visualização.",
                                  "learningObjective": "Reconhecer padrões de correlação em variáveis originais e suas implicações.",
                                  "commonMistakes": "Confundir correlação com causalidade; ignorar correlações negativas."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir os Componentes Principais e Suas Propriedades",
                                  "subSteps": [
                                    "Defina componentes principais (PCs) como combinações lineares ortogonais das variáveis originais.",
                                    "Explique que PCs são não correlacionados e ordenados por variância decrescente.",
                                    "Calcule os primeiros PCs manualmente para um dataset 2D simples.",
                                    "Compare variância explicada: PCs capturam máxima variância sem correlação.",
                                    "Visualize PCs em um scatter plot para observar separação ortogonal."
                                  ],
                                  "verification": "Gere os dois primeiros PCs para um dataset bivariado e confirme ausência de correlação entre eles (coeficiente ~0).",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python com Scikit-learn (PCA module), dataset bivariado simples, gráficos Matplotlib.",
                                  "tips": "Use `PCA(n_components=2).fit_transform()` para automação inicial, mas entenda a fórmula manualmente.",
                                  "learningObjective": "Diferenciar PCs de variáveis originais pela ortogonalidade e ordenação por variância.",
                                  "commonMistakes": "Assumir que PCs são as variáveis originais escaladas; ignorar ordenação por variância."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Explorar a Rotação Ortogonal no PCA",
                                  "subSteps": [
                                    "Descreva a matriz de loadings como vetores que rotacionam o espaço das variáveis originais.",
                                    "Ilustre geometricamente: eixos originais correlacionados vs. eixos PCs ortogonais.",
                                    "Calcule loadings para um exemplo e interprete contribuições de variáveis originais em cada PC.",
                                    "Demonstre rotação com animação ou plot de setas em um plano 2D.",
                                    "Verifique ortogonalidade: produto interno dos vetores de loading deve ser zero."
                                  ],
                                  "verification": "Plote loadings para um dataset e confirme ortogonalidade multiplicando matriz de loadings transposta por ela mesma (deve ser identidade).",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Python com Scikit-learn e Matplotlib para plots de loadings, dataset 2D-3D.",
                                  "tips": "Pense na rotação como alinhar eixos com direções de máxima variância.",
                                  "learningObjective": "Entender como a rotação ortogonal decorrela as componentes.",
                                  "commonMistakes": "Confundir rotação com escalonamento; não verificar ortogonalidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Analisar a Perda Mínima de Informação e Comparação Final",
                                  "subSteps": [
                                    "Calcule variância explicada cumulativa e scree plot para quantificar preservação de informação.",
                                    "Compare reconstrução: variáveis originais vs. projeção reversa dos PCs.",
                                    "Explique perda mínima: soma das variâncias dos PCs discarded é mínima para dada dimensionalidade.",
                                    "Compare qualitativamente: originais (correlacionadas, redundantes) vs. PCs (independentes, compactas).",
                                    "Aplique em dataset real e discuta trade-off dimensionalidade vs. informação."
                                  ],
                                  "verification": "Gere scree plot e reconstrua 90% da variância com mínimo PCs; compare erro de reconstrução.",
                                  "estimatedTime": "55 minutos",
                                  "materials": "Scikit-learn PCA, dataset de sensores multidimensional, métricas como MSE para reconstrução.",
                                  "tips": "Use `explained_variance_ratio_` para priorizar PCs com >80% cumulativo.",
                                  "learningObjective": "Quantificar e comparar preservação de informação entre originais e PCs.",
                                  "commonMistakes": "Subestimar perda em PCs de baixa variância; ignorar normalização prévia."
                                }
                              ],
                              "practicalExample": "Em um dataset de sensores IoT (temperatura, umidade, pressão, CO2), variáveis originais mostram correlação alta (ex.: temp e umidade r=0.85). Após PCA, PC1 (variância 65%) captura tendência climática geral (ortogonal a PC2, r=0), permitindo análise compacta com perda mínima (95% variância em 2 PCs vs. 4 originais).",
                              "finalVerifications": [
                                "Explique verbalmente a diferença entre variáveis originais correlacionadas e PCs não correlacionados.",
                                "Gere matriz de correlação zero para PCs em um dataset teste.",
                                "Interprete loadings de um PC e sua rotação ortogonal.",
                                "Calcule e justifique número de PCs para preservar 90% variância.",
                                "Reconstrua dataset original dos PCs e meça erro <5%.",
                                "Discuta perda de informação em termos de variância descartada."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção: correlação vs. ortogonalidade (30%)",
                                "Compreensão quantitativa: cálculos de variância e loadings corretos (25%)",
                                "Visualizações claras: heatmaps, scree plots, loadings plots (20%)",
                                "Explicação da rotação e perda mínima sem erros conceituais (15%)",
                                "Aplicação prática em exemplo real com interpretação (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Matriz de covariância e autovalores.",
                                "Machine Learning: Redução de dimensionalidade para clustering/classificação.",
                                "Engenharia: Análise de sinais em sensores e compressão de dados.",
                                "Física: Transformadas ortogonais em mecânica quântica."
                              ],
                              "realWorldApplication": "Em monitoramento ambiental com sensores IoT, PCA diferencia variáveis correlacionadas (ex.: temp/umidade) de PCs independentes para detectar anomalias em tempo real, reduzindo ruído e bandwidth em redes sem perda significativa de informação crítica."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.3.2",
                        "name": "Procedimento Computacional da PCA",
                        "description": "Passos matemáticos e algorítmicos para computar a PCA, incluindo padronização, matriz de covariância, autovalores e autovetores, com ênfase em métodos de mínimos quadrados e propriedades estatísticas.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.3.2.1",
                            "name": "Calcular a matriz de covariância e correlação de dados padronizados",
                            "description": "Padronizar dados multivariados de sensores (subtrair média e dividir pelo desvio padrão) e computar a matriz de covariância, considerando pressupostos de regressão linear relaxados para grandes amostras.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e Padronizar os Dados Multivariados",
                                  "subSteps": [
                                    "Carregue o conjunto de dados multivariados de sensores (ex.: temperatura, umidade, pressão) em uma matriz X de dimensão n x p, onde n é o número de observações e p o número de variáveis.",
                                    "Calcule a média μ_j e o desvio padrão σ_j para cada variável j = 1 a p.",
                                    "Padronize cada observação: Z_{i,j} = (X_{i,j} - μ_j) / σ_j, resultando na matriz Z de dados centralizados e escalados.",
                                    "Verifique se as colunas de Z têm média zero e variância unitária.",
                                    "Trate valores ausentes ou outliers, se necessário, usando imputação ou remoção."
                                  ],
                                  "verification": "Confirme que mean(Z, axis=0) ≈ [0,0,...,0] e std(Z, axis=0) ≈ [1,1,...,1] com tolerância 1e-6.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Python com NumPy e Pandas",
                                    "Dataset exemplo de sensores (CSV com 1000+ amostras)"
                                  ],
                                  "tips": "Use np.mean() e np.std(ddof=0) para estatísticas populacionais em grandes amostras.",
                                  "learningObjective": "Dominar a padronização z-score para tornar variáveis comparáveis em escala.",
                                  "commonMistakes": [
                                    "Usar desvio padrão amostral (ddof=1) em vez de populacional para PCA",
                                    "Esquecer de padronizar todas as variáveis",
                                    "Ignorar verificação de médias e desvios pós-padronização"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular a Matriz de Covariância dos Dados Padronizados",
                                  "subSteps": [
                                    "Lembre a fórmula: Σ = (1/n) * Z^T * Z, onde Z é a matriz padronizada centrada.",
                                    "Implemente computacionalmente usando multiplicação de matrizes ou função built-in como np.cov(Z.T, rowvar=False, bias=True).",
                                    "Verifique propriedades: Σ deve ser simétrica positiva semi-definida com diagonal ≈1 (variâncias unitárias).",
                                    "Calcule para subconjuntos de dados para validar consistência em grandes amostras.",
                                    "Documente os valores off-diagonal como medidas de covariância linear."
                                  ],
                                  "verification": "A matriz Σ deve ser simétrica (Σ == Σ.T) e ter trace(Σ) ≈ p (soma de variâncias unitárias).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python com NumPy",
                                    "Matriz Z do Step 1"
                                  ],
                                  "tips": "Para grandes n, use bias=True em np.cov para estimativa não-viésada em PCA.",
                                  "learningObjective": "Computar corretamente a matriz de covariância empírica para dados padronizados.",
                                  "commonMistakes": [
                                    "Usar (1/(n-1)) em vez de (1/n) para grandes amostras",
                                    "Confundir rowvar em np.cov",
                                    "Não transpor Z adequadamente"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular a Matriz de Correlação a partir da Covariância Padronizada",
                                  "subSteps": [
                                    "Note que para dados padronizados, a matriz de correlação R = Σ (pois variâncias são 1).",
                                    "Confirme: R_{j,k} = Σ_{j,k} / (σ_j * σ_k), mas σ_j=1, então R=Σ.",
                                    "Implemente usando np.corrcoef(Z.T) ou diretamente Σ do Step 2.",
                                    "Visualize com heatmap para inspecionar correlações fortes (>0.7 ou <-0.7).",
                                    "Compare R com Σ para validar identidade em dados padronizados."
                                  ],
                                  "verification": "R deve ser simétrica com diagonal de 1s e valores entre -1 e 1.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com NumPy e Matplotlib/Seaborn para visualização",
                                    "Matriz Σ do Step 2"
                                  ],
                                  "tips": "Use corr=True em np.cov para correlação diretamente, mas entenda a relação.",
                                  "learningObjective": "Entender e computar a relação entre covariância e correlação em dados escalados.",
                                  "commonMistakes": [
                                    "Recalcular desvios pós-padronização levando a erros",
                                    "Confundir correlação de Pearson com covariância bruta",
                                    "Ignorar sinal de correlações negativas"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar Resultados Considerando Pressupostos Relaxados para Grandes Amostras",
                                  "subSteps": [
                                    "Verifique pressupostos de PCA: linearidade (correlações altas indicam), normalidade aproximada (QQ-plots), homocedasticidade relaxada para n grande.",
                                    "Teste multicolinearidade via det(Σ) baixo ou eigenvalues próximos de zero.",
                                    "Avalie robustez: recalcule com bootstrap (100 reamostras) para intervalos de confiança.",
                                    "Interprete: identifique pares de variáveis altamente correlacionadas para redução dimensional.",
                                    "Documente limitações: pressupostos relaxados OK para n>>p em regressão/PCA."
                                  ],
                                  "verification": "Relatório com testes (ex.: |det(Σ)| > 1e-10, correlações consistentes no bootstrap).",
                                  "estimatedTime": "35 minutos",
                                  "materials": [
                                    "Python com SciPy para testes estatísticos",
                                    "Matrizes Σ e R anteriores"
                                  ],
                                  "tips": "Para n grande, CLT relaxa normalidade; foque em linearidade via scatterplots.",
                                  "learningObjective": "Aplicar validação crítica considerando violações menores em grandes datasets.",
                                  "commonMistakes": [
                                    "Exigir normalidade estrita ignorando n grande",
                                    "Não checar simetria ou positividade",
                                    "Sobreporpretação de correlações baixas"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere dados de sensores IoT em uma fábrica: 5000 amostras de temperatura (T), vibração (V) e pressão (P). Padronize Z, compute Σ (ex.: cov(T,V)=0.75), R=Σ, valide com bootstrap mostrando IC 95% estável, revelando alta correlação T-V para PCA em detecção de falhas.",
                              "finalVerifications": [
                                "Matriz Z padronizada com médias zero e variâncias unitárias.",
                                "Matriz Σ simétrica, diagonal≈1, off-diagonais coerentes com dados.",
                                "Matriz R idêntica a Σ com bounds [-1,1].",
                                "Validação bootstrap com variância <5% nos elementos principais.",
                                "Interpretação correta de pelo menos 3 pares correlacionados.",
                                "Relatório documentando pressupostos relaxados para n>1000."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica: erros <1e-6 em médias/desvios e matrizes.",
                                "Implementação correta de fórmulas vs. funções built-in.",
                                "Validação robusta com testes estatísticos e visualizações.",
                                "Compreensão conceitual: explicar relação covariância-correlação-padronização.",
                                "Eficiência computacional para datasets grandes (n=10k).",
                                "Relatório claro com interpretações e limitações."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência via bootstrap e CLT para grandes amostras.",
                                "Programação: NumPy/SciPy para álgebra linear eficiente.",
                                "Engenharia: Análise de sensores para manutenção preditiva.",
                                "Machine Learning: Pré-processamento para PCA e redução dimensional.",
                                "Matemática: Propriedades de matrizes simétricas positivas semi-definidas."
                              ],
                              "realWorldApplication": "Em engenharia de manufatura, padronizar e calcular covariância/correlação de dados de sensores vibracionais permite PCA para detectar anomalias em máquinas, reduzindo downtime em 20-30% via monitoramento preditivo em indústrias como automotiva e óleo&gás."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.1.1"
                            ]
                          },
                          {
                            "id": "10.1.7.3.2.2",
                            "name": "Extrair autovalores e autovetores da matriz de covariância",
                            "description": "Resolver o problema de autovalores para decompor a matriz de covariância, ordenando componentes por variância decrescente, e relacionar com maximização de verossimilhança em contextos econométricos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar a matriz de covariância e configurar o ambiente computacional",
                                  "subSteps": [
                                    "Carregue a biblioteca NumPy no Python com import numpy as np.",
                                    "Defina ou carregue os dados padronizados (centrado e escalado) de um conjunto de dados econométrico, como retornos de ações.",
                                    "Calcule a matriz de covariância usando np.cov() ou np.dot() para garantir precisão numérica.",
                                    "Verifique as dimensões e propriedades da matriz (simétrica e positiva semi-definida).",
                                    "Armazene a matriz em uma variável chamada cov_matrix."
                                  ],
                                  "verification": "Execute print(cov_matrix.shape) e print(np.allclose(cov_matrix, cov_matrix.T)) para confirmar simetria e dimensões corretas.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com NumPy instalado",
                                    "Jupyter Notebook ou IDE como VS Code",
                                    "Dataset exemplo: retornos de ações (ex: Yahoo Finance via pandas_datareader)"
                                  ],
                                  "tips": "Use dados reais de séries temporais econômicas para maior relevância; sempre padronize antes para evitar viés de escala.",
                                  "learningObjective": "Configurar corretamente o ambiente e preparar a entrada para o cálculo de autovalores.",
                                  "commonMistakes": [
                                    "Esquecer de centralizar os dados antes da covariância",
                                    "Usar correlação em vez de covariância",
                                    "Ignorar verificação de simetria"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular autovalores e autovetores usando decomposição eig",
                                  "subSteps": [
                                    "Aplique np.linalg.eig(cov_matrix) para obter autovalores (eigenvalues) e autovetores (eigenvectors).",
                                    "Desempacote os resultados: eigenvalues, eigenvectors = np.linalg.eig(cov_matrix).",
                                    "Verifique que os autovetores formam uma matriz ortogonal com np.allclose(np.dot(eigenvectors.T, eigenvectors), np.eye(len(eigenvalues))).",
                                    "Identifique autovalores reais e positivos, comuns em matrizes de covariância.",
                                    "Armazene em variáveis separadas para manipulação posterior."
                                  ],
                                  "verification": "Confirme ortogonalidade dos autovetores e que a reconstrução da matriz original é aproximada: np.allclose(np.dot(eigenvectors, np.dot(np.diag(eigenvalues), eigenvectors.T)), cov_matrix).",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Código Python do Step 1",
                                    "Documentação NumPy linalg.eig"
                                  ],
                                  "tips": "Para matrizes grandes, considere métodos iterativos como power iteration para eficiência; use precisão de ponto flutuante dupla.",
                                  "learningObjective": "Executar o cálculo numérico preciso de autovalores e autovetores.",
                                  "commonMistakes": [
                                    "Confundir autovalores com autovetores",
                                    "Não verificar ortogonalidade",
                                    "Ignorar autovalores complexos (raros em covariância)"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ordenar autovalores e autovetores por variância decrescente",
                                  "subSteps": [
                                    "Crie índices de ordenação: idx = np.argsort(eigenvalues)[::-1].",
                                    "Ordene autovalores: sorted_eigenvalues = eigenvalues[idx].",
                                    "Ordene autovetores correspondentes: sorted_eigenvectors = eigenvectors[:, idx].",
                                    "Calcule a variância explicada percentual: explained_var = (sorted_eigenvalues / np.sum(sorted_eigenvalues)) * 100.",
                                    "Visualize com matplotlib: plot das variâncias cumulativas."
                                  ],
                                  "verification": "Verifique que sorted_eigenvalues[0] é o maior e explained_var soma a 100%.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Código dos Steps anteriores",
                                    "Matplotlib para visualização"
                                  ],
                                  "tips": "Mantenha correspondência exata entre autovalores e autovetores durante a ordenação para evitar mismatches.",
                                  "learningObjective": "Ordenar componentes principais corretamente para priorizar variância máxima.",
                                  "commonMistakes": [
                                    "Ordenar apenas autovalores sem autovetores",
                                    "Erro em argsort reverso",
                                    "Não normalizar variância percentual"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e relacionar com maximização de verossimilhança em econometria",
                                  "subSteps": [
                                    "Explique que autovetores ordenados são componentes principais maximizando variância projetada.",
                                    "Relacione com PCA: projeção Y = X * sorted_eigenvectors[:, :k] para k componentes.",
                                    "Conecte à verossimilhança: em modelos gaussianos multivariados, PCA aproxima máxima verossimilhança reduzindo dimensionalidade.",
                                    "Aplique em exemplo econométrico: reduza dimensionalidade de fatores macroeconômicos.",
                                    "Documente insights: quantos componentes capturam 95% da variância."
                                  ],
                                  "verification": "Gere projeções e confirme redução de dimensionalidade sem perda significativa de variância.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código completo",
                                    "Teoria PCA de Bishop ou Jolliffe"
                                  ],
                                  "tips": "Em econometria, use para evitar multicolinearidade em regressões; teste com scree plot.",
                                  "learningObjective": "Conectar computação a teoria estatística e aplicações econométricas.",
                                  "commonMistakes": [
                                    "Ignorar sinal dos autovetores (sinal ambíguo)",
                                    "Confundir variância total com explicada",
                                    "Não relacionar a verossimilhança gaussiana"
                                  ]
                                }
                              ],
                              "practicalExample": "Considere retornos diários de 5 ações (AAPL, MSFT, GOOG, TSLA, AMZN) de 2023. Após padronização, calcule covariância 5x5. Extraia autovalores [2.1, 1.3, 0.8, 0.4, 0.1] e ordene para identificar o primeiro PC capturando 58% da variância, útil para portfólio diversificado em finanças.",
                              "finalVerifications": [
                                "Matriz reconstruída a partir de autovalores/autovetores coincide com covariância original (erro < 1e-10).",
                                "Autovetores são ortonormais (produto escalar identidade).",
                                "Variâncias percentuais somam 100% e decrescem monotonicamente.",
                                "Projeção nos top-2 PCs preserva >80% variância em dataset exemplo.",
                                "Interpretação correta: maximização de variância relaciona-se a verossimilhança em modelos gaussianos.",
                                "Código reproduzível sem erros numéricos."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica no cálculo eig (tolerância 1e-12).",
                                "Correta ordenação e cálculo de variância explicada.",
                                "Verificações de ortogonalidade e reconstrução implementadas.",
                                "Interpretação teórica precisa no contexto PCA/econometria.",
                                "Eficiência computacional para matrizes até 100x100.",
                                "Clareza no código com comentários e visualizações."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Distribuições multivariadas gaussianas e máxima verossimilhança.",
                                "Programação: Algoritmos numéricos em Python/NumPy e otimização.",
                                "Econometria: Redução de dimensionalidade em modelos de séries temporais e finanças.",
                                "Machine Learning: Pré-processamento para regressão e clustering.",
                                "Física: Oscilações e decomposição espectral em sistemas dinâmicos."
                              ],
                              "realWorldApplication": "Em análise de risco financeiro, extrair autovetores da covariância de ativos permite construir portfólios ótimos (Markowitz), reduzindo dimensionalidade de centenas de ativos para 5-10 fatores principais, maximizando retorno ajustado ao risco via PCA."
                            },
                            "estimatedTime": "2.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.2.1"
                            ]
                          },
                          {
                            "id": "10.1.7.3.2.3",
                            "name": "Projetar dados nos componentes principais",
                            "description": "Multiplicar os dados padronizados pelos autovetores para obter scores dos componentes principais, verificando propriedades estatísticas como não correlação e variância explicada.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar os Dados Padronizados e a Matriz de Autovetores",
                                  "subSteps": [
                                    "Carregue o dataset e selecione as features numéricas.",
                                    "Padronize os dados subtraindo a média e dividindo pelo desvio padrão para cada feature.",
                                    "Confirme que os dados padronizados têm média zero e variância unitária.",
                                    "Obtenha a matriz de autovetores dos componentes principais a partir da decomposição da matriz de covariância.",
                                    "Verifique que os autovetores são ortonormais (produto escalar entre colunas é identidade)."
                                  ],
                                  "verification": "Execute np.mean(X_std, axis=0) == 0 e np.var(X_std, axis=0) == 1; np.dot(eigenvectors.T, eigenvectors) ≈ identidade.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python com NumPy e Pandas",
                                    "Dataset de exemplo (ex: Iris)"
                                  ],
                                  "tips": "Sempre verifique as dimensões das matrizes antes de prosseguir: X_std deve ser (n_samples, n_features), eigenvectors (n_features, n_components).",
                                  "learningObjective": "Entender a preparação correta dos insumos para garantir projeções válidas em PCA.",
                                  "commonMistakes": [
                                    "Esquecer de padronizar os dados, levando a componentes enviesados; confundir autovalores com autovetores."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar a Projeção dos Dados nos Componentes Principais",
                                  "subSteps": [
                                    "Defina o número de componentes principais desejados (k ≤ n_features).",
                                    "Selecione as k primeiras colunas da matriz de autovetores (ordenados por autovalores decrescentes).",
                                    "Compute os scores multiplicando X_std pela matriz de autovetores: scores = X_std @ eigenvectors_k.",
                                    "Armazene os scores em uma nova matriz ou DataFrame.",
                                    "Visualize os scores iniciais para inspeção rápida (ex: scatter plot dos primeiros dois PCs)."
                                  ],
                                  "verification": "Scores deve ter shape (n_samples, k); verifique se não há NaNs ou infs com np.isnan(scores).any().",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Python com NumPy",
                                    "Biblioteca Matplotlib para visualização opcional"
                                  ],
                                  "tips": "Use @ para multiplicação matricial eficiente em NumPy; ordene autovetores por autovalores descendentes.",
                                  "learningObjective": "Dominar a multiplicação matricial para obter representações nos componentes principais.",
                                  "commonMistakes": [
                                    "Multiplicar na ordem errada (eigenvectors @ X_std em vez de X_std @ eigenvectors); selecionar componentes não ordenados."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Verificar a Variância Explicada pelos Componentes",
                                  "subSteps": [
                                    "Calcule a variância explicada por cada PC: var_explained = np.var(scores, axis=0).",
                                    "Compute a proporção de variância: prop_var = var_explained / np.sum(var_explained_original).",
                                    "Calcule a variância cumulativa: cum_var = np.cumsum(prop_var).",
                                    "Plote um scree plot ou bar chart da variância explicada.",
                                    "Confirme que a soma das proporções é próxima de 1 para todos os PCs."
                                  ],
                                  "verification": "Soma de prop_var ≈ 1; pelo menos 80-95% da variância cumulativa nos primeiros k PCs.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Python com NumPy e Matplotlib"
                                  ],
                                  "tips": "Normalize pela variância total dos dados padronizados para proporções precisas.",
                                  "learningObjective": "Avaliar quão bem os componentes capturam a variabilidade dos dados originais.",
                                  "commonMistakes": [
                                    "Usar variância dos dados originais sem padronização; ignorar ordenação dos autovalores."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Verificar a Não Correlação entre os Componentes Principais",
                                  "subSteps": [
                                    "Compute a matriz de correlação dos scores: corr_matrix = np.corrcoef(scores.T).",
                                    "Verifique que a diagonal é 1 e off-diagonal é próxima de 0 (ortogonalidade).",
                                    "Calcule os autovalores da matriz de covariância dos scores para confirmar identidade.",
                                    "Teste estatisticamente com correlações de Pearson entre pares de PCs.",
                                    "Documente qualquer desvio mínimo devido a precisão numérica."
                                  ],
                                  "verification": "np.allclose(corr_matrix, np.eye(k), atol=1e-6) deve ser True.",
                                  "estimatedTime": "15 minutos",
                                  "materials": [
                                    "Python com NumPy e SciPy"
                                  ],
                                  "tips": "Use np.allclose() para tolerância numérica em vez de == exato.",
                                  "learningObjective": "Confirmar as propriedades ortogonais dos componentes principais.",
                                  "commonMistakes": [
                                    "Confundir correlação com covariância; não transpor corretamente para corrcoef."
                                  ]
                                }
                              ],
                              "practicalExample": "No dataset Iris (150 amostras, 4 features), padronize X para X_std. Compute autovetores da covariância, selecione top 2. Projeje: pc_scores = X_std @ eigenvectors[:, :2]. Plote PC1 vs PC2 para ver separação de espécies. Verifique: var PC1+PC2 ≈ 95%, corr(PC1,PC2) ≈ 0.",
                              "finalVerifications": [
                                "Scores têm dimensões corretas (n_samples x k_components).",
                                "Variância explicada cumulativa ≥ 85% para k selecionado.",
                                "Matriz de correlação dos scores é identidade (off-diagonais < 1e-6).",
                                "Ausência de valores NaN ou infinitos nos scores.",
                                "Visualização dos PCs mostra estrutura de dados preservada.",
                                "Reconstrução aproximada: X_recon = pc_scores @ eigenvectors_k.T + mean_original tem erro baixo."
                              ],
                              "assessmentCriteria": [
                                "Correta preparação e padronização dos dados (média=0, var=1).",
                                "Multiplicação matricial precisa sem erros de shape.",
                                "Cálculo exato de variância explicada e cumulativa.",
                                "Verificação rigorosa de ortogonalidade/não correlação.",
                                "Interpretação clara das propriedades estatísticas.",
                                "Código reproduzível e eficiente."
                              ],
                              "crossCurricularConnections": [
                                "Álgebra Linear: Decomposição em autovetores e multiplicação matricial.",
                                "Estatística: Análise de variância e correlação.",
                                "Machine Learning: Redução de dimensionalidade para pré-processamento.",
                                "Engenharia de Dados: Compressão e visualização de datasets multivariados."
                              ],
                              "realWorldApplication": "Em análise de imagens médicas, projetar voxels de scans MRI nos PCs para reduzir dimensionalidade de milhares de features para 10-50, permitindo detecção rápida de tumores enquanto preserva 95% da variância, usado em sistemas de IA para diagnóstico."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.2.2"
                            ]
                          },
                          {
                            "id": "10.1.7.3.2.4",
                            "name": "Selecionar o número de componentes principais",
                            "description": "Usar critérios como scree plot, proporção de variância explicada (ex.: >80%) ou teste de Kaiser para decidir quantos componentes reter em dados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Calcular e visualizar o scree plot",
                                  "subSteps": [
                                    "Carregue o dataset de engenharia padronizado (ex.: dados de sensores).",
                                    "Execute a decomposição PCA para obter os eigenvalues ordenados.",
                                    "Plote os eigenvalues em um gráfico de linha (scree plot) com índice do componente no eixo x.",
                                    "Identifique visualmente o 'cotovelo' onde a curva de eigenvalues achata.",
                                    "Anote o número aproximado de componentes antes do cotovelo."
                                  ],
                                  "verification": "Scree plot gerado com eigenvalues decrescentes e cotovelo marcado claramente.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Python (scikit-learn, matplotlib)",
                                    "Jupyter Notebook",
                                    "Dataset de exemplo com pelo menos 10 features"
                                  ],
                                  "tips": "Use escala logarítmica no eixo y se os eigenvalues variarem muito em magnitude.",
                                  "learningObjective": "Dominar a visualização gráfica para identificar o ponto de inflexão na retenção de componentes.",
                                  "commonMistakes": [
                                    "Ignorar padronização dos dados antes da PCA",
                                    "Plotar variância percentual em vez de eigenvalues absolutos",
                                    "Não ordenar eigenvalues"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar a proporção de variância explicada cumulativa",
                                  "subSteps": [
                                    "Calcule a variância explicada por cada componente (eigenvalue / soma total de eigenvalues).",
                                    "Compute a variância cumulativa somando as proporções sequencialmente.",
                                    "Defina um threshold prático, como 80-90% de variância total explicada.",
                                    "Identifique o menor k tal que a variância cumulativa >= threshold.",
                                    "Plote a curva cumulativa para visualização."
                                  ],
                                  "verification": "Tabela ou gráfico mostrando variância cumulativa atingindo o threshold com k componentes específicos.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Python (numpy, pandas para cálculos)",
                                    "Gráficos com matplotlib ou seaborn"
                                  ],
                                  "tips": "Escolha threshold baseado no contexto: 80% para engenharia geral, 95% para precisão alta.",
                                  "learningObjective": "Aprender a quantificar a perda de informação ao truncar componentes.",
                                  "commonMistakes": [
                                    "Confundir variância individual com cumulativa",
                                    "Usar soma de eigenvalues não normalizada",
                                    "Definir threshold muito baixo ignorando ruído"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar o critério de Kaiser e integrar decisões",
                                  "subSteps": [
                                    "Liste componentes com eigenvalue > 1 (regra de Kaiser).",
                                    "Compare resultados do scree plot, variância cumulativa e Kaiser.",
                                    "Resolva discrepâncias priorizando contexto de engenharia (ex.: ruído em dados sensoriais).",
                                    "Documente a escolha final de k com justificativa baseada em múltiplos critérios.",
                                    "Valide projetando dados em k componentes e verificando perda de variância."
                                  ],
                                  "verification": "Relatório escrito justificando k final com evidências de pelo menos dois critérios.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Código Python para critérios",
                                    "Template de relatório em Markdown"
                                  ],
                                  "tips": "Em dados de alta dimensionalidade, Kaiser pode superestimar; pondere com scree plot.",
                                  "learningObjective": "Integrar heurísticas múltiplas para uma decisão robusta e contextualizada.",
                                  "commonMistakes": [
                                    "Aplicar Kaiser cegamente sem contexto",
                                    "Ignorar outliers afetando eigenvalues",
                                    "Não documentar trade-offs"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar e refinar a seleção",
                                  "subSteps": [
                                    "Projete o dataset original nos k componentes selecionados.",
                                    "Compare reconstrução com dados originais (ex.: MSE ou correlação).",
                                    "Teste estabilidade com subamostras do dataset.",
                                    "Ajuste k se validação indicar perda excessiva de informação.",
                                    "Salve configuração final (k, critérios usados)."
                                  ],
                                  "verification": "Métricas de validação (ex.: variância retida >80%, MSE baixo) e gráfico de reconstrução.",
                                  "estimatedTime": "25 minutos",
                                  "materials": [
                                    "Scikit-learn para projeção e métricas",
                                    "Dataset de validação"
                                  ],
                                  "tips": "Use cross-validation para robustez em datasets pequenos.",
                                  "learningObjective": "Garantir que a seleção de k seja validada empiricamente.",
                                  "commonMistakes": [
                                    "Pular validação pós-seleção",
                                    "Usar todo dataset para fitting sem hold-out",
                                    "Interpretar MSE sem contexto de escala"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de vibrações de uma turbina eólica (15 sensores: aceleração, temperatura, etc.), compute PCA: scree plot sugere cotovelo em k=5; variância cumulativa atinge 85% em k=6; Kaiser indica k=7. Decida k=6 priorizando variância explicada para modelagem preditiva de falhas.",
                              "finalVerifications": [
                                "Scree plot identifica cotovelo consistente.",
                                "Variância cumulativa >=80% com k mínimo.",
                                "Eigenvalues >1 listados corretamente via Kaiser.",
                                "Justificativa escrita integra múltiplos critérios.",
                                "Projeção em k componentes preserva estrutura principal dos dados.",
                                "Métricas de reconstrução confirmam perda aceitável."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de eigenvalues e variâncias (100% correto).",
                                "Interpretação visual correta do scree plot e cumulativa.",
                                "Aplicação heurística de Kaiser com limitações discutidas.",
                                "Decisão de k justificada e contextualizada para engenharia.",
                                "Validação empírica com métricas quantitativas.",
                                "Código limpo, reproduzível e comentado."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência baseada em testes de significância de eigenvalues.",
                                "Machine Learning: Pré-processamento para feature selection e redução dimensional.",
                                "Engenharia Mecânica: Análise de sinais multivariados em monitoramento estrutural.",
                                "Visualização de Dados: Gráficos interpretativos para tomada de decisão.",
                                "Computação Científica: Otimização numérica em decomposições matriciais."
                              ],
                              "realWorldApplication": "Na indústria de óleo e gás, selecionar componentes principais de dados sísmicos reduz dimensionalidade de milhares de features para modelos de detecção de fraturas, economizando tempo computacional e melhorando precisão em prospecção."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.2.3"
                            ]
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.3.3",
                        "name": "Aplicações da PCA em Análise de Dados em Engenharia",
                        "description": "Implementação e interpretação da PCA em contextos de engenharia, como análise de sensores em sistemas de controle, redução de ruído e integração com modelos ARIMA ou controladores PID.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.3.3.1",
                            "name": "Aplicar PCA em dados reais de sensores multivariados",
                            "description": "Implementar PCA em software como R (usando prcomp) para dados de medições de engenharia, como sinais de sensores em sistemas dinâmicos, filtrando ruído de medida.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar e Carregar Dados de Sensores Multivariados",
                                  "subSteps": [
                                    "Obter ou baixar um dataset real de sensores (ex: CSV com medições de vibração, temperatura, pressão de um sistema dinâmico)",
                                    "Instalar pacotes R necessários: install.packages(c('tidyverse', 'corrplot'))",
                                    "Carregar bibliotecas: library(tidyverse); library(corrplot)",
                                    "Ler dados: dados <- read_csv('sensores.csv')",
                                    "Inspecionar: glimpse(dados); summary(dados); identificar missing values e outliers"
                                  ],
                                  "verification": "Dados carregados sem erros, glimpse() e summary() exibem estrutura e estatísticas corretas, sem NAs inesperados.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R e RStudio instalados",
                                    "Dataset CSV de sensores multivariados (ex: 1000+ observações, 5-10 variáveis)",
                                    "Internet para instalação de pacotes"
                                  ],
                                  "tips": "Defina o diretório de trabalho com setwd() para evitar erros de caminho; use readr::read_csv para robustez.",
                                  "learningObjective": "Carregar e realizar inspeção inicial de dados multivariados de sensores no R.",
                                  "commonMistakes": [
                                    "Esquecer de instalar pacotes antes de carregar",
                                    "Caminho incorreto no read_csv levando a erro de arquivo não encontrado",
                                    "Ignorar verificação de tipos de dados (ex: fatores vs numéricos)"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Pré-processar os Dados para PCA",
                                  "subSteps": [
                                    "Tratar missing values: dados <- drop_na(dados) ou imputar com mean()",
                                    "Escolher variáveis numéricas: data_pca <- dados %>% select(where(is.numeric))",
                                    "Verificar e remover variáveis constantes: data_pca <- data_pca %>% select(where(~ sd(.x) > 0))",
                                    "Normalizar dados: data_scaled <- scale(data_pca, center = TRUE, scale = TRUE)",
                                    "Visualizar correlações: corrplot(cor(data_scaled))"
                                  ],
                                  "verification": "Matriz data_scaled sem NAs, escalada (médias zero, desvios 1), correlogram mostra multicolinearidade.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "RStudio com pacotes tidyverse e corrplot",
                                    "Dataset pré-carregado do Step 1"
                                  ],
                                  "tips": "Sempre escale dados para PCA, pois variáveis em escalas diferentes distorcem loadings; use pipe %>% para legibilidade.",
                                  "learningObjective": "Preparar dados multivariados adequados para aplicação de PCA, lidando com pré-requisitos.",
                                  "commonMistakes": [
                                    "Não escalar dados, levando a dominância de variáveis com maior escala",
                                    "Remover linhas com NAs sem justificativa, perdendo dados úteis",
                                    "Incluir variáveis categóricas sem codificação"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar PCA com prcomp()",
                                  "subSteps": [
                                    "Executar PCA: pca <- prcomp(data_scaled, center = FALSE, scale = FALSE)",
                                    "Inspecionar resultados: summary(pca); str(pca)",
                                    "Extrair componentes: scores <- pca$x; loadings <- pca$rotation",
                                    "Calcular variância explicada: pca.var <- pca$sdev^2 / sum(pca$sdev^2) * 100",
                                    "Verificar cumulativa: cumsum(pca.var)"
                                  ],
                                  "verification": "Objeto 'pca' criado, summary(pca) mostra proporção de variância por PC, sem erros de convergência.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "R com dados escalados do Step 2"
                                  ],
                                  "tips": "Use center=FALSE e scale=FALSE após pré-escala manual; capture output com capture.output(summary(pca)).",
                                  "learningObjective": "Implementar corretamente o algoritmo PCA em R usando prcomp em dados reais.",
                                  "commonMistakes": [
                                    "Esquecer scale=TRUE se não pré-escalado",
                                    "Confundir prcomp com princomp (este último é legado)",
                                    "Não verificar se matriz é numérica"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar e Visualizar Resultados do PCA",
                                  "subSteps": [
                                    "Plotar scree plot: plot(pca, type = 'l', main = 'Scree Plot')",
                                    "Gerar biplot: biplot(pca, main = 'Biplot PCA Sensores')",
                                    "Analisar loadings: print(round(loadings, 3)); identificar variáveis dominantes por PC",
                                    "Determinar PCs úteis: k <- which(cumsum(pca.var) > 80)[1]",
                                    "Plotar scores: ggplot(data.frame(scores[,1:2]), aes(PC1, PC2)) + geom_point()"
                                  ],
                                  "verification": "Plots gerados (scree, biplot, scores), loadings interpretados, número de PCs definido com >80% variância.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacotes ggplot2 e factoextra opcionais para plots avançados",
                                    "Objeto pca do Step 3"
                                  ],
                                  "tips": "Use factoextra::fviz_eig(pca) para plots elegantes; foque em PCs que explicam ruído vs sinal.",
                                  "learningObjective": "Interpretar loadings, scores e variância para entender estrutura dos dados de sensores.",
                                  "commonMistakes": [
                                    "Interpretar loadings sem considerar sinal (positivo/negativo)",
                                    "Escolher PCs baseado só em elbow sem métrica cumulativa",
                                    "Plots ilegíveis por falta de labels"
                                  ]
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Aplicar PCA para Filtrar Ruído em Sinais de Sensores",
                                  "subSteps": [
                                    "Reconstruir com top PCs: recon <- scores[,1:k] %*% t(loadings[,1:k])",
                                    "Adicionar de volta médias: recon_original_scale <- scale(recon, center = -attr(data_scaled, 'scaled:center'), scale = 1/attr(data_scaled, 'scaled:scale'))",
                                    "Comparar: plot(data_pca[1:100,1], type='l'); lines(recon_original_scale[1:100,1], col='red')",
                                    "Calcular erro: mse <- mean((data_pca - recon_original_scale)^2)",
                                    "Avaliar redução de ruído: comparar variância residual"
                                  ],
                                  "verification": "Dados reconstruídos mostram MSE baixo, plots evidenciam ruído filtrado (sinais mais suaves).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Objetos pca, data_scaled dos steps anteriores"
                                  ],
                                  "tips": "Escolha k baseado em interpretação; valide com cross-validation para robustez.",
                                  "learningObjective": "Usar PCA para redução dimensional e filtragem de ruído em dados de engenharia reais.",
                                  "commonMistakes": [
                                    "Esquecer de desescalar para escala original",
                                    "Usar todos PCs, anulando filtragem",
                                    "MSE calculado em dados escalados"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de sensores de um turbofan (ex: NASA CMAPSS), com variáveis como vibração axial, temperatura de rolamento, pressão de óleo (1000 amostras x 8 vars). Aplique PCA para reduzir a 3 PCs, reconstrua e filtre ruído de medição, revelando padrões de desgaste real vs flutuações aleatórias.",
                              "finalVerifications": [
                                "PCA executado com prcomp sem erros em dataset >500 observações multivariado.",
                                "Variância cumulativa de top 3 PCs >80%, com loadings coerentes para sensores (ex: vibração alta em PC1).",
                                "Biplot e scree plot gerados e interpretados corretamente.",
                                "Reconstrução com top PCs reduz MSE em >30% vs original, plots mostram ruído filtrado.",
                                "Relatório escrito com conclusões sobre filtragem de ruído em sistemas dinâmicos.",
                                "Código reproduzível salvo em script R."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação prcomp e pré-processamento (sem erros comuns).",
                                "Qualidade das visualizações e interpretação de loadings/variância.",
                                "Eficácia da filtragem: MSE reduzido e validação visual.",
                                "Escolha justificada de número de PCs (>80% variância, elbow).",
                                "Relatório claro com código, plots e análise de ruído filtrado.",
                                "Eficiência temporal: conclusão em <6 horas totais.",
                                "Robustez: teste com subset de dados."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Análise Multivariada e Inferência",
                                "Engenharia de Controle: Processamento de Sinais e Sensores",
                                "Machine Learning: Redução de Dimensionalidade e Feature Extraction",
                                "Física Aplicada: Dinâmica de Sistemas e Medições Experimentais",
                                "Computação Científica: Programação em R para Dados Grandes"
                              ],
                              "realWorldApplication": "Na indústria 4.0, PCA em dados de sensores IoT (ex: vibração em turbinas eólicas) filtra ruído de medição para detecção precoce de falhas, reduzindo downtime em 20-30% e custos de manutenção preditiva em fábricas inteligentes."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.2.4"
                            ]
                          },
                          {
                            "id": "10.1.7.3.3.2",
                            "name": "Interpretar loadings e scores dos componentes",
                            "description": "Analisar loadings para identificar contribuições de variáveis originais nos componentes e scores para detecção de padrões ou anomalias em processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de loadings e scores em PCA",
                                  "subSteps": [
                                    "Revise a definição de loadings como os coeficientes que representam a contribuição de cada variável original para os componentes principais.",
                                    "Estude scores como as projeções das observações originais no espaço dos componentes principais.",
                                    "Identifique a relação matemática: scores = dados originais × matriz de loadings.",
                                    "Explore visualizações típicas, como heatmaps para loadings e scatter plots para scores.",
                                    "Diferencie loadings (importância de variáveis) de scores (posição das amostras)."
                                  ],
                                  "verification": "Explique em suas palavras a diferença entre loadings e scores, com um diagrama simples.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação de PCA (scikit-learn ou similar), notebook Jupyter com exemplos básicos de PCA.",
                                  "tips": "Use analogias: loadings são 'receitas' dos componentes; scores são 'ingredientes prontos' das observações.",
                                  "learningObjective": "Dominar as definições e relações matemáticas de loadings e scores.",
                                  "commonMistakes": "Confundir loadings com pesos de features em outros modelos ou ignorar a normalização dos dados."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar loadings para identificar contribuições de variáveis",
                                  "subSteps": [
                                    "Calcule e extraia a matriz de loadings de um modelo PCA ajustado.",
                                    "Visualize loadings com barplots ou heatmaps, focando nos valores absolutos maiores que 0.3-0.5.",
                                    "Interprete loadings altos: variáveis com forte contribuição positiva/negativa para o componente.",
                                    "Agrupe variáveis por componentes: identifique padrões como clusters de sensores relacionados.",
                                    "Compare loadings entre componentes para priorizar os mais explicativos da variância."
                                  ],
                                  "verification": "Gere um heatmap de loadings e liste as top-3 variáveis por componente com justificativa.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Python com pandas, matplotlib/seaborn, scikit-learn; dataset industrial de sensores (ex: UCI datasets).",
                                  "tips": "Sempre use loadings absolutos para contribuição; normalize variáveis antes do PCA.",
                                  "learningObjective": "Extrair e interpretar contribuições variáveis-componentes para insights de engenharia.",
                                  "commonMistakes": "Ignorar componentes com baixa variância explicada."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Interpretar scores para detecção de padrões e anomalias",
                                  "subSteps": [
                                    "Extraia scores dos componentes principais do modelo PCA.",
                                    "Plote scores em scatter plots bi-dimensionais (PC1 vs PC2) coloridos por classes ou tempo.",
                                    "Identifique clusters: padrões normais em grupos apertados; anomalias como outliers distantes.",
                                    "Calcule distâncias Mahalanobis ou use thresholds (ex: 3 desvios) para flagar anomalias.",
                                    "Correlacione scores com metadados industriais, como turnos ou máquinas."
                                  ],
                                  "verification": "Identifique e justifique 2-3 anomalias em um plot de scores com evidências.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Mesmo ambiente Python; dataset com labels de falhas (ex: dados de vibracão de máquinas).",
                                  "tips": "Foque nos primeiros 2-3 PCs que capturam >80% variância para visualizações claras.",
                                  "learningObjective": "Usar scores para visualizar e detectar desvios em processos industriais.",
                                  "commonMistakes": "Sobrepor anomalias sem validar com dados originais; ignorar multicolinearidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Integrar interpretações de loadings e scores para análise completa",
                                  "subSteps": [
                                    "Combine insights: para uma anomalia em scores, cheque loadings para variáveis causais.",
                                    "Gere relatório: 'Amostra X é outlier em PC1 devido a alta contribuição de variável Y (loading=0.8)'.",
                                    "Valide com reconstrução: compare dados originais vs reconstruídos via PCA.",
                                    "Simule cenários industriais: prediga falhas baseadas em thresholds de scores/loadings.",
                                    "Documente limitações: PCA assume linearidade; sugira próximos passos como clustering."
                                  ],
                                  "verification": "Produza um relatório de 1 página integrando loadings e scores de um dataset exemplo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Notebook Jupyter para relatório; ferramentas de export PDF.",
                                  "tips": "Use biplots para visualizar loadings e scores juntos em um gráfico.",
                                  "learningObjective": "Realizar análise holística para decisões em engenharia.",
                                  "commonMistakes": "Interpretar isoladamente sem integração; generalizar de poucos componentes."
                                }
                              ],
                              "practicalExample": "Em uma fábrica de manufatura, aplique PCA a dados de 10 sensores (temperatura, pressão, vibração). Loadings revelam que PC1 é dominado por sensores térmicos (loadings >0.7). Scores mostram uma amostra outlier em PC1-PC2, indicando falha de refrigeração – confirmado por inspeção física.",
                              "finalVerifications": [
                                "Explique corretamente loadings vs scores em um quiz de 5 perguntas.",
                                "Gere plots de loadings e scores para um dataset novo sem erros.",
                                "Identifique corretamente 80% das anomalias simuladas em scores.",
                                "Integre análises em um relatório coerente.",
                                "Discuta limitações da PCA em contexto industrial.",
                                "Aplique biplot para visualização conjunta."
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de loadings (contribuições >0.5 corretas: 30%)",
                                "Detecção precisa de anomalias em scores (acurácia >85%: 25%)",
                                "Qualidade de visualizações e relatórios (clareza e labels: 20%)",
                                "Integração loadings-scores (insights acionáveis: 15%)",
                                "Uso correto de ferramentas e validações (sem erros: 10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Correlação e variância explicada.",
                                "Engenharia de Processos: Monitoramento e controle de qualidade (SPC).",
                                "Machine Learning: Redução de dimensionalidade e detecção de outliers.",
                                "Visualização de Dados: Heatmaps, scatter plots e biplots."
                              ],
                              "realWorldApplication": "Em indústrias como óleo&gás ou automotiva, interpretar loadings identifica sensores redundantes ou críticos; scores detectam falhas em tempo real, reduzindo downtime em 20-30% via manutenção preditiva."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.3.1"
                            ]
                          },
                          {
                            "id": "10.1.7.3.3.3",
                            "name": "Avaliar e validar a redução dimensional",
                            "description": "Calcular percentual de variância explicada cumulativa, biplot e comparar com métodos alternativos como regressão em grandes amostras ou análise fatorial.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Calcular o percentual de variância explicada cumulativa",
                                  "subSteps": [
                                    "Carregar o dataset e preparar os dados (padronização/normalização).",
                                    "Aplicar PCA usando biblioteca como scikit-learn para extrair componentes principais.",
                                    "Calcular a variância explicada por cada componente (explained_variance_ratio_).",
                                    "Computar a variância cumulativa somando os valores sequencialmente.",
                                    "Plotar scree plot para visualizar a variância cumulativa."
                                  ],
                                  "verification": "Verificar se a soma da variância cumulativa para todos os componentes é aproximadamente 100%.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (scikit-learn, matplotlib, pandas), dataset de exemplo (ex: dados de sensores de engenharia).",
                                  "tips": "Sempre padronize os dados antes do PCA para evitar viés de escala.",
                                  "learningObjective": "Compreender e calcular quanto da variância original é preservada pelos componentes principais.",
                                  "commonMistakes": "Esquecer de padronizar dados, levando a componentes dominados por variáveis de maior escala."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Gerar e interpretar biplot para visualização da redução",
                                  "subSteps": [
                                    "Extrair loadings (vetores de carregamento) e scores dos componentes principais.",
                                    "Criar biplot plotando scores das observações e setas para variáveis nos dois primeiros componentes.",
                                    "Interpretar ângulos entre setas (correlações positivas/negativas) e distâncias (importância).",
                                    "Analisar agrupamentos de observações e contribuições das variáveis.",
                                    "Anotar insights qualitativos sobre a estrutura dimensional reduzida."
                                  ],
                                  "verification": "Biplot gerado mostra setas coerentes com correlações conhecidas no dataset.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Python (scikit-learn, matplotlib ou seaborn), mesmo dataset do Step 1.",
                                  "tips": "Use PCA com n_components=2 para biplot simples; escalone loadings para melhor visualização.",
                                  "learningObjective": "Visualizar e interpretar relações entre variáveis e observações na espaço reduzido.",
                                  "commonMistakes": "Interpretar incorretamente ângulos (ângulo <90° indica correlação positiva)."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar PCA com métodos alternativos: Regressão em grandes amostras",
                                  "subSteps": [
                                    "Preparar dataset para regressão (dividir em treino/teste, selecionar features).",
                                    "Treinar modelo de regressão linear múltipla e calcular R² ou MSE.",
                                    "Aplicar PCA para reduzir features e treinar regressão no espaço reduzido.",
                                    "Comparar métricas de performance (R², MSE) entre PCA+regressão e regressão full.",
                                    "Avaliar perda de performance devido à redução dimensional."
                                  ],
                                  "verification": "Métricas de PCA+regressão estão próximas (ex: perda <10%) das full features.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Python (scikit-learn para PCA e LinearRegression, train_test_split).",
                                  "tips": "Use cross-validation para robustez na comparação de performance.",
                                  "learningObjective": "Avaliar se a redução dimensional mantém performance preditiva comparada a regressão completa.",
                                  "commonMistakes": "Não usar validação cruzada, levando a overfitting em comparações."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar com Análise Fatorial e validar redução dimensional",
                                  "subSteps": [
                                    "Aplicar Análise Fatorial (FA) no dataset (ex: usando FactorAnalyzer).",
                                    "Calcular communalities e comparar variância explicada com PCA.",
                                    "Realizar teste de adequação (KMO, Bartlett) para validar FA vs PCA.",
                                    "Comparar biplots ou loadings entre PCA e FA.",
                                    "Concluir validação: escolher método baseado em variância, interpretabilidade e performance."
                                  ],
                                  "verification": "Relatório comparativo mostra prós/contras e justificativa para PCA ou alternativo.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (factor_analyzer library, scikit-learn).",
                                  "tips": "PCA é para variância máxima; FA assume fatores latentes subjacentes.",
                                  "learningObjective": "Diferenciar PCA de FA e validar redução via comparações empíricas.",
                                  "commonMistakes": "Confundir PCA (não gera fatores latentes) com FA."
                                }
                              ],
                              "practicalExample": "Em um dataset de sensores de vibração em turbinas (1000 amostras, 20 sensores), aplicar PCA para reduzir a 3 componentes (85% variância), gerar biplot mostrando agrupamentos de falhas, comparar R² de regressão de vida útil (0.92 full vs 0.89 PCA) e communalities em FA (média 0.78).",
                              "finalVerifications": [
                                "Variância cumulativa ≥80% com ≤50% das dimensões originais.",
                                "Biplot revela padrões interpretáveis (agrupamentos, correlações).",
                                "Perda de performance em regressão <10% após redução.",
                                "KMO >0.6 confirma adequação para FA como alternativa.",
                                "Relatório escrito justifica escolha do método.",
                                "Reprodutibilidade: código roda sem erros em dataset similar."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de variância (erro <1%).",
                                "Interpretação correta de biplot (correlações identificadas).",
                                "Comparação quantitativa robusta (métricas + testes estatísticos).",
                                "Clareza no relatório de validação (prós/contras).",
                                "Eficiência: redução mantém >85% variância com performance similar.",
                                "Uso adequado de ferramentas (código limpo, comentado)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Testes de adequação (KMO, Bartlett).",
                                "Machine Learning: Redução dimensional em pipelines preditivos.",
                                "Engenharia: Análise de dados multivariados em monitoramento de equipamentos.",
                                "Visualização de Dados: Interpretação de scree plots e biplots."
                              ],
                              "realWorldApplication": "Em engenharia de manutenção preditiva, validar PCA para comprimir dados de sensores IoT, permitindo detecção de falhas em tempo real com menor custo computacional, comparando com regressão para previsão de tempo até falha em turbinas eólicas."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.3.2"
                            ]
                          },
                          {
                            "id": "10.1.7.3.3.4",
                            "name": "Integrar PCA com análises econométricas e de controle",
                            "description": "Combinar PCA com modelos ARIMA para séries temporais de sensores ou com estabilidade em sistemas de controle, usando inferência e testes de hipótese nos componentes reduzidos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparação de Dados e Aplicação Inicial de PCA",
                                  "subSteps": [
                                    "Colete e pré-processe dados multivariados de séries temporais de sensores ou sistemas de controle.",
                                    "Padronize os dados (normalização z-score) para garantir escalas comparáveis.",
                                    "Aplique PCA usando decomposição de autovalores para extrair componentes principais.",
                                    "Selecione o número de componentes baseado em variância explicada (>80-90%).",
                                    "Visualize os loadings e scores dos componentes principais."
                                  ],
                                  "verification": "Verifique se a variância cumulativa dos componentes selecionados excede 85% e plote o scree plot.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Python (scikit-learn, pandas, numpy, matplotlib), dataset de sensores (ex: UCI ML repository).",
                                  "tips": "Sempre verifique multicolinearidade antes de PCA com correlograma.",
                                  "learningObjective": "Dominar a preparação e aplicação de PCA em dados de alta dimensionalidade.",
                                  "commonMistakes": "Esquecer normalização, levando a componentes dominados por variáveis de maior escala."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Integração de PCA com Modelos ARIMA para Séries Temporais",
                                  "subSteps": [
                                    "Transforme os scores dos componentes principais em séries temporais estacionárias (teste ADF).",
                                    "Ajuste parâmetros ARIMA (p,d,q) para cada componente relevante usando ACF/PACF.",
                                    "Ajuste modelos ARIMA individuais nos componentes reduzidos.",
                                    "Combine previsões dos componentes via reconstrução linear.",
                                    "Valide o modelo com resíduos brancos (teste Ljung-Box)."
                                  ],
                                  "verification": "Confirme estacionariedade pós-diferenciação e ausência de autocorrelação nos resíduos.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "Python (statsmodels, pmdarima), dados pré-processados do Step 1.",
                                  "tips": "Use auto_arima para otimização inicial de parâmetros e evite overfitting.",
                                  "learningObjective": "Aprender a forecasting em dimensões reduzidas para eficiência computacional.",
                                  "commonMistakes": "Aplicar ARIMA diretamente em dados não estacionários, causando forecasts enviesados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Integração de PCA com Análise de Estabilidade em Sistemas de Controle",
                                  "subSteps": [
                                    "Modele o sistema de controle usando componentes PCA como entradas/estados.",
                                    "Construa matrizes A, B, C do modelo state-space com componentes reduzidos.",
                                    "Analise estabilidade via autovalores da matriz A (todos dentro do círculo unitário).",
                                    "Implemente controle LQR ou PID nos componentes para estabilização.",
                                    "Simule respostas ao degrau e avalie overshoot/settling time."
                                  ],
                                  "verification": "Todos autovalores têm módulo <1 e simulações mostram convergência estável.",
                                  "estimatedTime": "3-4 horas",
                                  "materials": "Python (control, scipy), modelo state-space dos dados PCA.",
                                  "tips": "Priorize componentes que capturam variância dinâmica do sistema.",
                                  "learningObjective": "Integrar redução dimensional com teoria de controle para sistemas complexos.",
                                  "commonMistakes": "Ignorar modos instáveis nos componentes descartados, comprometendo estabilidade."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Inferência Estatística e Testes de Hipótese nos Componentes Reduzidos",
                                  "subSteps": [
                                    "Defina hipóteses nulas/alternativas para loadings ou scores (ex: H0: loading=0).",
                                    "Aplique testes t ou F nos coeficientes dos componentes.",
                                    "Corrija múltiplos testes com Bonferroni ou FDR.",
                                    "Construa intervalos de confiança bootstrap para previsões ARIMA/controle.",
                                    "Interprete significância econômica/engenharia dos componentes."
                                  ],
                                  "verification": "p-valores ajustados <0.05 para componentes relevantes e CIs não sobrepostos com zero.",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Python (scipy.stats, statsmodels), resultados dos steps anteriores.",
                                  "tips": "Use bootstrap para robustez em amostras pequenas.",
                                  "learningObjective": "Realizar inferência válida em espaço reduzido para decisões baseadas em evidência.",
                                  "commonMistakes": "Não corrigir por múltiplos testes, inflando falsos positivos."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validação Integrada e Aplicação Final",
                                  "subSteps": [
                                    "Reconstrua dados originais dos componentes e compare com originais (MSE baixo).",
                                    "Avalie performance conjunta: forecast ARIMA + estabilidade controle.",
                                    "Realize cross-validation temporal para robustez.",
                                    "Documente pipeline completo em notebook Jupyter.",
                                    "Teste sensibilidade a hiperparâmetros de PCA/ARIMA."
                                  ],
                                  "verification": "MSE de reconstrução <5% e CV scores consistentes.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Todos materiais anteriores + Jupyter Notebook.",
                                  "tips": "Automatize pipeline com funções modulares para reprodutibilidade.",
                                  "learningObjective": "Validar e integrar o framework PCA-econometria-controle holisticamente.",
                                  "commonMistakes": "Sobreajuste ao validar apenas in-sample."
                                }
                              ],
                              "practicalExample": "Em uma fábrica de automóveis, use PCA para reduzir dados de 50 sensores de vibração (séries temporais), aplique ARIMA nos componentes para prever desgaste, integre com controle PID para estabilizar linhas de montagem, e teste hipóteses sobre componentes preditivos de falhas.",
                              "finalVerifications": [
                                "Variância explicada por PCA >85%.",
                                "Modelos ARIMA com resíduos estacionários (ADF p<0.05).",
                                "Sistema de controle estável (autovalores |λ|<1).",
                                "Testes de hipótese significativos pós-correção (FDR<0.1).",
                                "Reconstrução fiel dos dados originais (MSE<0.05).",
                                "Forecasts precisos em hold-out set (MAE<10% do range)."
                              ],
                              "assessmentCriteria": [
                                "Precisão da redução dimensional (variância capturada).",
                                "Convergência e estacionariedade dos modelos ARIMA.",
                                "Estabilidade demonstrada em simulações de controle.",
                                "Validade estatística dos testes de inferência.",
                                "Integração seamless entre PCA, ARIMA e controle.",
                                "Eficiência computacional (redução >50% em tempo).",
                                "Interpretação prática dos resultados."
                              ],
                              "crossCurricularConnections": [
                                "Econometria: Modelos de séries temporais (ARIMA/SARIMA).",
                                "Engenharia de Controle: State-space e LQR/PID.",
                                "Estatística: Inferência multivariada e testes múltiplos.",
                                "Machine Learning: Redução dimensional e feature engineering.",
                                "Engenharia Industrial: Manutenção preditiva com IoT."
                              ],
                              "realWorldApplication": "Monitoramento preditivo em indústrias 4.0, como previsão de falhas em turbinas eólicas (PCA+ARIMA para vento/sensores, controle para estabilidade rotórica), reduzindo downtime em 30% e custos de manutenção."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": [
                              "10.1.7.3.3.3"
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.7.4",
                    "name": "Análise Fatorial em Dados de Engenharia",
                    "description": "Identificação de fatores latentes e estrutura subjacente em conjuntos de dados complexos de engenharia.",
                    "individualConcepts": [
                      {
                        "id": "10.1.7.4.1",
                        "name": "Modelo de Análise Fatorial",
                        "description": "Compreensão do modelo matemático da análise fatorial, incluindo fatores latentes, variáveis observadas e estrutura de covariância em conjuntos de dados complexos de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.4.1.1",
                            "name": "Identificar componentes do modelo fatorial",
                            "description": "Diferenciar entre fatores comuns latentes, variância única e variância de erro no modelo X = ΛF + ψ + ε, aplicando-o a dados de engenharia como sensores ou medições estruturais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a estrutura geral do modelo fatorial",
                                  "subSteps": [
                                    "Revise a equação do modelo fatorial: X = ΛF + ψ + ε, onde X são as variáveis observadas.",
                                    "Identifique X como o vetor de observações (ex.: dados de sensores).",
                                    "Explique o papel de cada termo na decomposição da variância total.",
                                    "Desenhe um diagrama path do modelo mostrando relações entre componentes.",
                                    "Compare com modelo de regressão múltipla para destacar diferenças."
                                  ],
                                  "verification": "Desenhe e rotule corretamente o diagrama do modelo fatorial, explicando verbalmente cada componente.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Papel e caneta ou software de diagramação (Draw.io), slides ou vídeo introdutório sobre análise fatorial.",
                                  "tips": "Use cores diferentes para cada componente no diagrama para visualização clara.",
                                  "learningObjective": "Entender a equação matricial do modelo fatorial e sua interpretação geométrica.",
                                  "commonMistakes": "Confundir ψ com ε; assumir que todos os fatores são observáveis."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Diferenciar fatores comuns latentes (ΛF)",
                                  "subSteps": [
                                    "Defina F como fatores comuns latentes não observáveis que explicam covariância compartilhada.",
                                    "Explique Λ como a matriz de cargas fatoriais que mapeia fatores para variáveis observadas.",
                                    "Calcule ΛF para um exemplo simples com 2 fatores e 3 variáveis.",
                                    "Interprete cargas fatoriais altas (>0.7) como forte associação.",
                                    "Discuta rotação de fatores (varimax) para interpretabilidade."
                                  ],
                                  "verification": "Compute ΛF manualmente para um dataset toy de 3x2 e interprete os resultados.",
                                  "estimatedTime": "60 minutos",
                                  "materials": "Calculadora ou Python (NumPy), dataset exemplo com correlação matriz.",
                                  "tips": "Comece com fatores ortogonais para simplificar cálculos iniciais.",
                                  "learningObjective": "Distinguir e calcular a contribuição dos fatores comuns para X.",
                                  "commonMistakes": "Interpretar cargas como coeficientes de regressão diretos; ignorar communality (h² = ΛΛ')."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar variância única (ψ) e variância de erro (ε)",
                                  "subSteps": [
                                    "Defina ψ como variância única (especificidade): variância não compartilhada entre variáveis.",
                                    "Defina ε como variância de erro de medição aleatória.",
                                    "Calcule communality h² = 1 - ψ para cada variável.",
                                    "Compare ψ e ε em termos de confiabilidade: ψ reflete traços únicos, ε é ruído.",
                                    "Estime ψ e ε usando diagonal da matriz de covariâncias residuais."
                                  ],
                                  "verification": "Para um exemplo, calcule h², ψ e ε, e explique por que ψ > 0 indica variância não-fatorial.",
                                  "estimatedTime": "50 minutos",
                                  "materials": "Planilha Excel ou R/Python script para decomposição de variância.",
                                  "tips": "Lembre-se: variância total = communality + ψ + ε.",
                                  "learningObjective": "Diferenciar precisamente ψ (traço único) de ε (erro) e computar suas proporções.",
                                  "commonMistakes": "Tratar ψ como erro total; subestimar impacto de ε em dados ruidosos de sensores."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar o modelo a dados de engenharia",
                                  "subSteps": [
                                    "Carregue dados reais de sensores (ex.: vibrações em ponte com 5 sensores).",
                                    "Ajuste modelo fatorial usando software (faça EFA ou CFA).",
                                    "Identifique fatores latentes (ex.: modo1, modo2), ψ (sensores únicos) e ε (ruído).",
                                    "Interprete resultados: fatores para padrões globais, ψ para falhas locais.",
                                    "Valide com plot de cargas e resíduos."
                                  ],
                                  "verification": "Gere relatório com decomposição X = ΛF + ψ + ε para dataset de engenharia.",
                                  "estimatedTime": "90 minutos",
                                  "materials": "Dataset de sensores (Kaggle ou simulado), Python (factor_analyzer) ou R (psych package).",
                                  "tips": "Use dados com pelo menos 100 observações para estabilidade.",
                                  "learningObjective": "Aplicar identificação de componentes em contexto prático de engenharia.",
                                  "commonMistakes": "Sobre-fatorar (muitos F); ignorar suposições de normalidade em ε."
                                }
                              ],
                              "practicalExample": "Em dados de 5 sensores de vibração em uma viga estrutural (100 medições), identifique F1 como 'vibração global' (Λ altas em todos sensores), ψ alto no sensor 3 (falha local), e ε como ruído ambiental. Decomponha matriz de covariâncias para confirmar.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças entre ΛF, ψ e ε com 100% acurácia.",
                                "Calcular corretamente h² para todas variáveis em dataset exemplo.",
                                "Desenhar diagrama path sem erros.",
                                "Aplicar modelo a dados novos e rotular componentes.",
                                "Identificar quando ψ indica necessidade de variável adicional.",
                                "Validar resíduos como ~N(0,ε) via QQ-plot."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção conceitual (fatores comuns vs. únicos vs. erro): 30%.",
                                "Cálculos matriciais corretos: 25%.",
                                "Interpretação em contexto de engenharia: 20%.",
                                "Uso adequado de software e validação: 15%.",
                                "Clareza em relatórios/diagramas: 10%."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Modelos lineares generalizados e PCA.",
                                "Engenharia Civil/Mecânica: Análise modal e monitoramento SHM.",
                                "Machine Learning: Redução de dimensionalidade e autoencoders.",
                                "Psicometria: Validação de escalas adaptada a sensores."
                              ],
                              "realWorldApplication": "Em engenharia estrutural, decompor sinais de sensores IoT para detectar modos de vibração latentes (F), falhas sensor-specific (ψ) e ruído (ε), permitindo manutenção preditiva em pontes ou turbinas eólicas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.4.1.2",
                            "name": "Comparar Análise Fatorial com Análise de Componentes Principais",
                            "description": "Explicar as diferenças entre Análise Fatorial (fatores latentes) e ACP (componentes observados), destacando quando usar cada uma em dados multivariados de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos da Análise de Componentes Principais (PCA)",
                                  "subSteps": [
                                    "Defina PCA como técnica de redução de dimensionalidade que cria componentes lineares a partir de variáveis observadas.",
                                    "Explique o objetivo principal: maximizar a variância explicada pelos componentes.",
                                    "Descreva o processo matemático: padronização, matriz de covariância, autovalores e autovetores.",
                                    "Implemente PCA em Python usando scikit-learn em um dataset simples de engenharia (ex: medidas de sensores).",
                                    "Interprete os loadings e scores dos componentes principais."
                                  ],
                                  "verification": "Execute código PCA e gere gráfico de variância explicada; confirme que os primeiros componentes capturam >80% da variância.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com scikit-learn, pandas, matplotlib",
                                    "Dataset exemplo: Iris ou sensores industriais"
                                  ],
                                  "tips": "Sempre padronize os dados antes da PCA para evitar viés de escala.",
                                  "learningObjective": "Compreender PCA como método observacional focado em variância total.",
                                  "commonMistakes": [
                                    "Não padronizar variáveis",
                                    "Interpretar componentes como fatores causais",
                                    "Ignorar autovalores próximos a zero"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Revisar Fundamentos da Análise Fatorial (FA)",
                                  "subSteps": [
                                    "Defina FA como modelo que infere fatores latentes não observados a partir de variáveis manifestas com erro de medição.",
                                    "Explique o modelo matemático: X = ΛF + ε, onde Λ são loadings fatoriais e ε é erro único.",
                                    "Descreva métodos de estimação: máxima verossimilhança ou principal axis factoring.",
                                    "Implemente FA em Python usando factor_analyzer em um dataset com estrutura latente simulada.",
                                    "Interprete communalities, loadings e fatores rotacionados (varimax)."
                                  ],
                                  "verification": "Gere relatório de FA mostrando communalities >0.5 para a maioria das variáveis e loadings significativos.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Python com factor_analyzer, pandas",
                                    "Dataset: simule dados com fatores latentes ou use dados psicológicos adaptados"
                                  ],
                                  "tips": "Use rotação ortogonal para interpretabilidade clara dos fatores.",
                                  "learningObjective": "Compreender FA como modelo causal de fatores subjacentes.",
                                  "commonMistakes": [
                                    "Confundir communalities com variância explicada em PCA",
                                    "Não testar adequação de amostra (KMO >0.6)",
                                    "Sobreinterpretar fatores sem rotação"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Identificar e Comparar Diferenças Chave entre PCA e FA",
                                  "subSteps": [
                                    "Compare objetivos: PCA (redução de dados) vs FA (descoberta de estrutura latente).",
                                    "Liste diferenças matemáticas: PCA usa variância total; FA usa variância comum e assume erro único.",
                                    "Discuta outputs: componentes (PCA, ortogonais) vs fatores (FA, podem ser rotacionados).",
                                    "Crie tabela comparativa com colunas: suposições, rotações, interpretações.",
                                    "Aplique ambos em mesmo dataset multivariado de engenharia e compare resultados."
                                  ],
                                  "verification": "Produza tabela comparativa e gráficos lado a lado mostrando divergências nos loadings.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Excel ou Jupyter para tabelas",
                                    "Mesmo dataset dos steps anteriores"
                                  ],
                                  "tips": "Lembre: PCA é extração; FA é modelagem com ruído.",
                                  "learningObjective": "Discernir premissas e outputs distintos de cada método.",
                                  "commonMistakes": [
                                    "Tratar PCA e FA como sinônimos",
                                    "Ignorar que PCA não modela erro de medição",
                                    "Não comparar em dados reais"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Determinar Quando Usar Cada Método em Dados Multivariados de Engenharia",
                                  "subSteps": [
                                    "Liste cenários para PCA: compressão de dados, visualização (ex: monitoramento de sensores).",
                                    "Liste cenários para FA: identificar constructs latentes (ex: fatores de falha em máquinas).",
                                    "Avalie critérios de escolha: tamanho da amostra, presença de erro de medição, interpretabilidade.",
                                    "Aplique decisão em case de engenharia: dados de vibração de turbinas.",
                                    "Documente trade-offs: PCA mais robusta, FA mais teórica."
                                  ],
                                  "verification": "Crie fluxograma de decisão e aplique a um dataset, justificando escolha.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Dataset de engenharia: vibrações ou qualidade de processo",
                                    "Ferramentas de diagrama: draw.io"
                                  ],
                                  "tips": "Prefira PCA para dados exploratórios grandes; FA para validação de teorias.",
                                  "learningObjective": "Selecionar método apropriado baseado em contexto de engenharia.",
                                  "commonMistakes": [
                                    "Usar FA em amostras pequenas (<100)",
                                    "Escolher sem considerar suposições estatísticas",
                                    "Ignorar validação cruzada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de sensores de uma linha de produção (temperatura, pressão, vibração), use PCA para reduzir dimensionalidade e detectar outliers; use FA para extrair fatores latentes como 'estresse térmico' e 'desgaste mecânico', explicando variabilidade subjacente.",
                              "finalVerifications": [
                                "Explique verbalmente 5 diferenças chave entre PCA e FA.",
                                "Implemente ambos em um dataset e compare variância explicada vs communalities.",
                                "Crie fluxograma de decisão para escolha do método.",
                                "Identifique erro comum em relatório de análise multivariada.",
                                "Aplique a um case de engenharia e justifique escolha."
                              ],
                              "assessmentCriteria": [
                                "Precisão na distinção de premissas matemáticas (30%)",
                                "Correta implementação e interpretação em código (25%)",
                                "Tabela comparativa clara e completa (20%)",
                                "Justificativa contextual para engenharia (15%)",
                                "Ausência de confusões comuns (10%)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: testes de adequação (KMO, Bartlett)",
                                "Machine Learning: PCA como pré-processamento para regressão",
                                "Engenharia de Dados: redução em IoT e sensores",
                                "Psicometria: origens da FA adaptadas a engenharia"
                              ],
                              "realWorldApplication": "Na manutenção preditiva de turbinas eólicas, PCA reduz dados de sensores para monitoramento em tempo real; FA identifica fatores latentes de falha (ex: fadiga vs corrosão), otimizando intervenções e reduzindo downtime em 20%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.4.1.3",
                            "name": "Verificar pressupostos do modelo fatorial",
                            "description": "Avaliar pressupostos como normalidade multivariada, adequação de amostra (KMO) e teste de esfericidade de Bartlett em datasets de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o dataset e identificar pressupostos chave",
                                  "subSteps": [
                                    "Carregue o dataset de engenharia (ex: propriedades mecânicas de materiais) em R ou Python usando bibliotecas como read.csv() ou pandas.read_csv().",
                                    "Realize limpeza de dados: remova missing values, outliers via boxplots e padronize variáveis com scale() ou StandardScaler.",
                                    "Liste os pressupostos principais: normalidade multivariada, KMO > 0.6 e Bartlett p < 0.05.",
                                    "Verifique dimensionalidade inicial com summary() ou describe().",
                                    "Documente o tamanho da amostra (n > 100 recomendado para análise fatorial)."
                                  ],
                                  "verification": "Dataset limpo e padronizado salvo; lista de pressupostos documentada em relatório.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "RStudio ou Jupyter Notebook",
                                    "Pacotes: psych (R), factor_analyzer (Python)",
                                    "Dataset exemplo: propriedades de ligas metálicas"
                                  ],
                                  "tips": [
                                    "Sempre padronize antes de testes; use cor() para matriz de correlações iniciais."
                                  ],
                                  "learningObjective": "Entender e preparar dados adequadamente para testes de pressupostos em análise fatorial.",
                                  "commonMistakes": [
                                    "Ignorar outliers que distorcem normalidade",
                                    "Usar dataset sem pelo menos 5-10 observações por variável"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Testar normalidade multivariada",
                                  "subSteps": [
                                    "Instale e carregue pacotes: psych::mshapiro.test() em R ou scipy.stats em Python para aproximações.",
                                    "Aplique teste de Mardia: psych::mardia() em R para skewness e kurtosis multivariados.",
                                    "Calcule estatísticas: skewness < 0.5 e kurtosis < 1 por variável como regra heurística se teste exato falhar.",
                                    "Visualize com Q-Q plots multivariados ou pairs.panels() para inspeção gráfica.",
                                    "Registre p-value: rejeitar H0 (normalidade) se p < 0.05."
                                  ],
                                  "verification": "Relatório com p-values de Mardia e gráficos salvos; decisão sobre normalidade registrada.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Pacotes R: psych, MVN; Python: pingouin",
                                    "Gráficos: ggplot2 ou matplotlib"
                                  ],
                                  "tips": [
                                    "Para amostras grandes, use bootstrapping se teste exato for sensível; priorize heurísticas em engenharia."
                                  ],
                                  "learningObjective": "Avaliar e interpretar testes de normalidade multivariada em contextos de engenharia.",
                                  "commonMistakes": [
                                    "Confundir univariada com multivariada",
                                    "Ignorar violações leves em datasets reais de engenharia"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular KMO e teste de esfericidade de Bartlett",
                                  "subSteps": [
                                    "Carregue função KMO: psych::KMO() em R ou factor_analyzer.KMO().",
                                    "Execute KMO na matriz de correlações: valores > 0.6 (aceitável), > 0.8 (meritorio).",
                                    "Aplique Bartlett: psych::cortest.bartlett() ; p-value < 0.05 indica adequação para fatorial.",
                                    "Gere MSA (Measure of Sampling Adequacy) por variável; remova < 0.5.",
                                    "Salve tabela com KMO global, por item e p-Bartlett."
                                  ],
                                  "verification": "Tabela de KMO e Bartlett com interpretações; variáveis problemáticas identificadas.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Pacotes R: psych; Python: factor_analyzer",
                                    "Matriz de correlações pré-computada"
                                  ],
                                  "tips": [
                                    "KMO é mais robusto que Bartlett em engenharia; itere removendo itens baixos."
                                  ],
                                  "learningObjective": "Executar e interpretar adequadamente KMO e Bartlett para validar estrutura fatorial.",
                                  "commonMistakes": [
                                    "Interpretar KMO baixo como falha total sem remoção iterativa",
                                    "Usar covariâncias em vez de correlações"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados integrados e decidir viabilidade",
                                  "subSteps": [
                                    "Compile todos resultados: normalidade OK?, KMO > 0.6?, Bartlett significativo?.",
                                    "Se violações: aplique transformações (log, Box-Cox) ou considere EFA robusta (ex: fatorial com mínimos quadrados).",
                                    "Defina critérios de corte: prosseguir se 2/3 pressupostos atendidos em dados de engenharia.",
                                    "Gere relatório final com tabelas, gráficos e recomendação (prossiga ou ajuste dataset).",
                                    "Salve script reproduzível para auditoria."
                                  ],
                                  "verification": "Relatório integrado com decisão clara (viável/não viável) e justificativa.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "R Markdown ou Jupyter para relatório",
                                    "Scripts anteriores"
                                  ],
                                  "tips": [
                                    "Em engenharia, priorize KMO sobre normalidade estrita devido a dados reais não-normais."
                                  ],
                                  "learningObjective": "Integrar verificações de pressupostos para decisões informadas em análise fatorial.",
                                  "commonMistakes": [
                                    "Prosseguir apesar de KMO < 0.5",
                                    "Não documentar trade-offs em violações"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de propriedades mecânicas de 150 amostras de ligas de alumínio (resistência à tração, alongamento, dureza), carregue em R, padronize, teste Mardia (p=0.03, violação leve), KMO=0.72 (aceitável), Bartlett p<0.001. Remova 2 variáveis com MSA<0.5, reteste: prossiga para EFA.",
                              "finalVerifications": [
                                "Relatório completo com p-values de Mardia, KMO global/itens e Bartlett gerado.",
                                "Gráficos de Q-Q e matriz de MSA visualizados corretamente.",
                                "Decisão de viabilidade justificada com critérios quantitativos.",
                                "Script reproduzível executa sem erros em dataset teste.",
                                "Transformações aplicadas se necessário, com antes/depois comparados.",
                                "Documentação cobre contexto de engenharia (ex: implicações para modelagem de falhas)."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos: KMO e p-values corretos (±0.01).",
                                "Interpretação adequada: thresholds aplicados corretamente (KMO>0.6, etc.).",
                                "Tratamento de violações: remoção iterativa ou transformações lógicas.",
                                "Qualidade do relatório: claro, com tabelas/gráficos e recomendações.",
                                "Eficiência temporal: completado em <5 horas com resultados válidos.",
                                "Conhecimento conceitual: explica diferenças entre pressupostos em 1 parágrafo."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses e significância.",
                                "Programação Computacional: manipulação de dados em R/Python.",
                                "Engenharia de Materiais: aplicação em análise de propriedades multivariadas.",
                                "Machine Learning: pré-requisito para redução de dimensionalidade.",
                                "Qualidade e Controle Estatístico: validação de modelos em processos industriais."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, verificar pressupostos em dados de fadiga de componentes garante que análise fatorial identifique fatores latentes (ex: microestrutura, carregamento) para prever falhas, otimizando design e manutenção preditiva."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.4.2",
                        "name": "Métodos de Estimação e Inferência",
                        "description": "Técnicas para estimar parâmetros da análise fatorial, incluindo máxima verossimilhança e métodos generalizados de momentos, com inferência estatística.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.4.2.1",
                            "name": "Aplicar estimação por máxima verossimilhança",
                            "description": "Implementar o método de máxima verossimilhança para estimar matriz de loadings Λ e variâncias únicas ψ em dados de engenharia, usando software como R.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender a formulação teórica da máxima verossimilhança em análise fatorial",
                                  "subSteps": [
                                    "Revise a função de verossimilhança para modelo de análise fatorial: L(Λ, ψ | dados) = produto de densidades multivariadas normais.",
                                    "Entenda os parâmetros: matriz de loadings Λ (fatores comuns) e matriz diagonal ψ (variâncias únicas).",
                                    "Estude a equação de covariância: Σ = ΛΛ' + ψ.",
                                    "Aprenda sobre restrições de identificação: fixar loadings ou variâncias para rotatividade.",
                                    "Discuta suposições: normalidade multivariada e independência condicional."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito a derivada da log-verossimilhança e como maximizá-la.",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Livro 'An Introduction to the Theory of Numbers' ou notas de aula sobre FA",
                                    "Artigo seminal de Lawley e Maxwell sobre ML em FA"
                                  ],
                                  "tips": "Use diagramas path para visualizar o modelo Σ = ΛΛ' + ψ.",
                                  "learningObjective": "Formular matematicamente o problema de estimação ML em FA.",
                                  "commonMistakes": [
                                    "Confundir variâncias únicas ψ com erros residuais",
                                    "Ignorar problemas de identificação do modelo"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar e explorar dados de engenharia para análise fatorial",
                                  "subSteps": [
                                    "Carregue dados em R: ex., medidas de sensores (vibração, tensão, temperatura de uma estrutura).",
                                    "Verifique normalidade multivariada com Q-Q plots e teste de Mardia.",
                                    "Padronize variáveis: scale() para média 0 e variância 1.",
                                    "Calcule matriz de correlações e realize teste KMO (>0.6) e Bartlett.",
                                    "Determine número de fatores via scree plot ou eigenvalues >1."
                                  ],
                                  "verification": "Gere relatório com KMO >0.7 e Bartlett p<0.05.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "R e RStudio",
                                    "Pacote psych: install.packages('psych')",
                                    "Dataset exemplo: dados simulados de engenharia com 10 variáveis observáveis"
                                  ],
                                  "tips": "Use corPlot() do psych para visualizar correlações.",
                                  "learningObjective": "Preparar dados adequados para ML-FA, garantindo suposições.",
                                  "commonMistakes": [
                                    "Prosseguir com KMO <0.5",
                                    "Não tratar outliers que violam normalidade"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar estimação por máxima verossimilhança em R",
                                  "subSteps": [
                                    "Use factanal(dados, factors=k, method='ML') para ajustar o modelo.",
                                    "Extraia loadings: loadings <- loadings(fit_model).",
                                    "Obtenha ψ: fit_model$uniqueness.",
                                    "Verifique convergência: sem warnings e hessiana positiva.",
                                    "Ajuste rotações se necessário: varimax() nos loadings."
                                  ],
                                  "verification": "Execute factanal() e confirme loadings e ψ extraídos corretamente.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "R com base stats (factanal built-in)",
                                    "Pacotes: psych para fa() alternativa"
                                  ],
                                  "tips": "Comece com factors=2-3; aumente se chi-square p>0.05.",
                                  "learningObjective": "Codificar e executar estimação ML para Λ e ψ.",
                                  "commonMistakes": [
                                    "Especificar factors excessivos levando a Heywood cases (ψ<0)",
                                    "Ignorar warnings de não-convergência"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Avaliar e interpretar os resultados da estimação",
                                  "subSteps": [
                                    "Calcule índices de ajuste: chi-square, RMSEA, TLI via fa() do psych.",
                                    "Interprete loadings: |λ| >0.4 significativo; supressão <0.1.",
                                    "Analise communalities: h² = 1 - ψ.",
                                    "Realize testes de significância nos loadings.",
                                    "Gere scores fatoriais: factor.scores() para predições."
                                  ],
                                  "verification": "Produza tabela de loadings com asteriscos para significância e relatório de fit.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Pacote psych para fa.parallel() e fit indices"
                                  ],
                                  "tips": "Use print(fit, cutoff=0.3, sort=TRUE) para loadings limpos.",
                                  "learningObjective": "Diagnosticar qualidade da estimação e extrair insights.",
                                  "commonMistakes": [
                                    "Interpretar loadings pequenos como significativos",
                                    "Não reportar índices de ajuste"
                                  ]
                                }
                              ],
                              "practicalExample": "Em dados de monitoramento de uma ponte (vibrações em 8 sensores, tensão, deformação), aplique factanal() com 3 fatores para estimar Λ (fatores: 'modo flexural', 'torsional', 'global') e ψ (ruído sensor-specific), identificando padrões de desgaste estrutural.",
                              "finalVerifications": [
                                "Modelo convergeu sem Heywood cases (todas ψ >0).",
                                "Índices de ajuste: chi-square/df <3, RMSEA <0.08.",
                                "Loadings primários >0.5, cross-loadings <0.3.",
                                "KMO >0.8 e communalities médias >0.6.",
                                "Scores fatoriais gerados e plotados coherentemente.",
                                "Reprodutibilidade: seed set e resultados idênticos em re-run."
                              ],
                              "assessmentCriteria": [
                                "Precisão numérica: Λ e ψ coincidem com valores conhecidos em simulações (±0.01).",
                                "Eficiência computacional: convergência em <100 iterações.",
                                "Interpretação correta: fatores nomeados logicamente para contexto de engenharia.",
                                "Robustez: modelo estável a remoção de 10% dados.",
                                "Relatório completo: inclui código R, outputs e discussão.",
                                "Uso apropriado de rotações e testes de significância."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses em loadings.",
                                "Programação Computacional: otimização numérica em R.",
                                "Engenharia de Dados: pré-processamento de sensores IoT.",
                                "Machine Learning: relação com PCA e modelos latentes.",
                                "Cálculo Numérico: algoritmos de maximização (BFGS em factanal)."
                              ],
                              "realWorldApplication": "Em manutenção preditiva de turbinas eólicas, estimação ML de fatores latentes em dados de vibração permite detectar modos de falha precocemente, otimizando agendamentos de inspeção e reduzindo downtime em 20-30%."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.4.2.2",
                            "name": "Realizar testes de significância em fatores",
                            "description": "Executar testes de hipótese para determinar o número de fatores significativos, utilizando critérios como eigenvalues >1 e scree plot em contextos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e realizar extração inicial de fatores",
                                  "subSteps": [
                                    "Colete e limpe o conjunto de dados de engenharia (ex: dados de sensores).",
                                    "Padronize as variáveis para remover escalas diferentes.",
                                    "Execute análise fatorial ou PCA para extrair componentes iniciais usando software como R ou Python.",
                                    "Calcule a matriz de correlação ou covariância.",
                                    "Obtenha os eigenvalues iniciais para todos os componentes."
                                  ],
                                  "verification": "Verifique se a matriz de correlação tem KMO > 0.6 e Bartlett's test é significativo (p < 0.05).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Software R/Python (pacotes psych ou factoextra), dataset de exemplo em CSV.",
                                  "tips": "Sempre padronize dados antes para evitar viés de escala.",
                                  "learningObjective": "Entender preparação de dados para análise fatorial.",
                                  "commonMistakes": "Ignorar outliers ou não testar adequação amostral (KMO/Bartlett)."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular e visualizar eigenvalues com scree plot",
                                  "subSteps": [
                                    "Extraia eigenvalues ordenados decrescentemente da análise.",
                                    "Crie o scree plot plotando eigenvalues contra número de fatores.",
                                    "Identifique o 'elbow' visual no gráfico onde a curva achata.",
                                    "Salve o plot e anote os valores de eigenvalues principais.",
                                    "Compare com linha de referência (ex: valor médio aleatório)."
                                  ],
                                  "verification": "Scree plot gerado corretamente com elbow visível em pelo menos 3-5 fatores.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "R (ggplot2 ou base plot), Python (matplotlib/seaborn), eigenvalues do Step 1.",
                                  "tips": "Use log scale se necessário para melhor visualização do elbow.",
                                  "learningObjective": "Dominar visualização gráfica para inspeção de fatores.",
                                  "commonMistakes": "Interpretar elbow subjetivamente sem comparar com critérios numéricos."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar critérios de significância como eigenvalue >1",
                                  "subSteps": [
                                    "Aplique critério de Kaiser: conte fatores com eigenvalue >1.",
                                    "Realize análise paralela (parallel analysis) simulando dados aleatórios.",
                                    "Compare eigenvalues reais com percentiles de simulação (ex: 95%).",
                                    "Determine número de fatores significativos baseado nos critérios.",
                                    "Documente decisão com tabela de eigenvalues e critérios."
                                  ],
                                  "verification": "Tabela mostra número exato de fatores com lambda >1 e comparação paralela.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Pacotes R (nFactors), Python (factor_analyzer), dados do Step 1.",
                                  "tips": "Use análise paralela para robustez além de Kaiser.",
                                  "learningObjective": "Aplicar múltiplos testes estatísticos para significância.",
                                  "commonMistakes": "Confiar só em eigenvalue >1 sem contexto amostral."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e validar número de fatores",
                                  "subSteps": [
                                    "Interprete o número de fatores em contexto de engenharia.",
                                    "Execute rotação (varimax) nos fatores selecionados e examine loadings.",
                                    "Valide com communalities >0.4 para a maioria das variáveis.",
                                    "Teste estabilidade com bootstrap se possível.",
                                    "Escreva relatório com número de fatores e justificativa."
                                  ],
                                  "verification": "Relatório final cita número de fatores, critérios usados e loadings principais.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Software anterior, template de relatório.",
                                  "tips": "Priorize fatores com loadings >0.4 e sem cross-loadings altos.",
                                  "learningObjective": "Integrar testes em interpretação prática.",
                                  "commonMistakes": "Selecionar muitos fatores ignorando overfit."
                                }
                              ],
                              "practicalExample": "Em dados de vibração de uma turbina eólica (10 sensores), aplique testes: eigenvalues mostram 3 >1, scree plot com elbow em 3, análise paralela confirma 3 fatores significativos representando modos de falha (rolamento, lâmina, eixo).",
                              "finalVerifications": [
                                "Scree plot exibe elbow claro alinhado com critérios numéricos.",
                                "Número de fatores com eigenvalue >1 é consistente com análise paralela.",
                                "KMO >0.6 e Bartlett p<0.05 confirmam adequação.",
                                "Communalities médias >0.5 indicam boa explicação de variância.",
                                "Loadings primários >0.4 sem cross-loadings >0.3.",
                                "Relatório documenta todos critérios e decisão final."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de eigenvalues e scree plot (sem erros numéricos).",
                                "Correta aplicação e interpretação de critérios (Kaiser + visual).",
                                "Uso adequado de análise paralela ou bootstrap para validação.",
                                "Interpretação contextualizada para engenharia.",
                                "Relatório claro com visualizações e tabelas.",
                                "Tempo de execução dentro do estimado com qualidade."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Testes de hipótese e simulações.",
                                "Programação Computacional: R/Python para análise multivariada.",
                                "Engenharia de Manutenção: Aplicação em dados de sensores industriais.",
                                "Visualização de Dados: Criação e interpretação de scree plots."
                              ],
                              "realWorldApplication": "Em engenharia, usado para reduzir dimensionalidade em monitoramento de equipamentos (ex: identificar fatores latentes de desgaste em aviões ou fábricas), otimizando modelos preditivos e reduzindo custos de manutenção."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.4.2.3",
                            "name": "Usar métodos alternativos de estimação",
                            "description": "Comparar mínimos quadrados ordinários e métodos generalizados de momentos para estimação em grandes amostras de dados de engenharia com pressupostos relaxados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos dos Mínimos Quadrados Ordinários (OLS)",
                                  "subSteps": [
                                    "Relembrar a formulação do OLS: minimizar a soma dos quadrados dos resíduos.",
                                    "Estudar propriedades assintóticas do OLS em grandes amostras: consistência e eficiência sob pressupostos clássicos.",
                                    "Analisar violações comuns de pressupostos (heterocedasticidade, autocorrelação) em dados de engenharia.",
                                    "Implementar OLS simples em Python ou R com dados simulados de engenharia.",
                                    "Calcular estatísticas de eficiência para grandes amostras."
                                  ],
                                  "verification": "Gerar relatório com saída do OLS mostrando coeficientes, erros padrão e testes de pressupostos.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Python/R com bibliotecas statsmodels/sklearn; dados simulados de regressão linear.",
                                  "tips": "Use dados com N>1000 para simular grandes amostras e observar convergência.",
                                  "learningObjective": "Compreender limitações do OLS quando pressupostos são relaxados.",
                                  "commonMistakes": "Ignorar testes de pressupostos como Breusch-Pagan para heterocedasticidade."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Introduzir Métodos Generalizados de Momentos (GMM)",
                                  "subSteps": [
                                    "Estudar a base teórica do GMM: condições de momento e função objetivo.",
                                    "Diferenciar GMM de 1 passo e 2 passos, focando em eficiência assintótica.",
                                    "Explorar instrumentos válidos para dados de engenharia com endogeneidade.",
                                    "Implementar GMM básico em Python (statsmodels) ou R (gmm package).",
                                    "Simular dados com violações de pressupostos OLS para testar GMM."
                                  ],
                                  "verification": "Executar código GMM e comparar matriz de covariância com OLS.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Python/R com statsmodels/gmm; tutoriais Hansen (1982) sobre GMM.",
                                  "tips": "Comece com condições de momento lineares para simplicidade antes de não-lineares.",
                                  "learningObjective": "Dominar formulação e estimação GMM para pressupostos relaxados.",
                                  "commonMistakes": "Escolher instrumentos fracos; verificar com teste de Sargan-Hansen."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Comparar OLS e GMM em Grandes Amostras",
                                  "subSteps": [
                                    "Comparar propriedades: consistência, eficiência e robustez a misspecificação.",
                                    "Analisar desempenho em simulações Monte Carlo com N grande e pressupostos violados.",
                                    "Calcular métricas como viés, MSE e cobertura de intervalos de confiança.",
                                    "Visualizar diferenças com gráficos de distribuições de estimadores.",
                                    "Discutir trade-offs: simplicidade OLS vs. flexibilidade GMM."
                                  ],
                                  "verification": "Criar tabela comparativa de resultados de simulações com estatísticas descritivas.",
                                  "estimatedTime": "4 horas",
                                  "materials": "Jupyter Notebook; bibliotecas numpy/pandas/matplotlib para simulações.",
                                  "tips": "Use seeds fixos para reprodutibilidade em Monte Carlo.",
                                  "learningObjective": "Identificar cenários onde GMM supera OLS em dados de engenharia.",
                                  "commonMistakes": "Não considerar custo computacional de GMM em amostras muito grandes."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar em Dados Reais de Engenharia",
                                  "subSteps": [
                                    "Selecionar dataset real (ex: sensores de vibração ou falhas estruturais).",
                                    "Estimar modelo com OLS e GMM, ajustando para heterocedasticidade.",
                                    "Testar inferência: estatísticas t, J-test para GMM.",
                                    "Interpretar diferenças nos coeficientes e significância.",
                                    "Documentar relatório com recomendações de método."
                                  ],
                                  "verification": "Produzir relatório final com códigos, outputs e conclusões comparativas.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Datasets UCI/ML (ex: Concrete Compressive Strength); software estatístico.",
                                  "tips": "Padronize variáveis para facilitar comparação de magnitudes.",
                                  "learningObjective": "Aplicar comparação prática e decidir método baseado em dados.",
                                  "commonMistakes": "Sobreajustar instrumentos levando a estimadores inconsistentes."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e Refinar Conhecimento",
                                  "subSteps": [
                                    "Revisar literatura chave (Newey-West para robustez).",
                                    "Realizar auto-avaliação com exercícios de estimação.",
                                    "Explorar extensões como GMM contínuo-updating.",
                                    "Discutir limitações em contextos de engenharia específicos.",
                                    "Preparar resumo para apresentação."
                                  ],
                                  "verification": "Completar quiz ou auto-teste com 90% acerto em conceitos chave.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Artigos acadêmicos; Khan Academy/YouTube tutoriais avançados.",
                                  "tips": "Ensine o conceito a outra pessoa para reforçar aprendizado.",
                                  "learningObjective": "Sintetizar comparação e aplicações futuras.",
                                  "commonMistakes": "Confundir eficiência assintótica com finita-amostra."
                                }
                              ],
                              "practicalExample": "Em dados de sensores de uma turbina eólica (N=5000 observações), estime o impacto de temperatura na vibração usando OLS (assume homocedasticidade) vs. GMM com instrumentos para endogeneidade, mostrando GMM reduzindo viés em 20% sob heterocedasticidade.",
                              "finalVerifications": [
                                "Explicar verbalmente diferenças em propriedades assintóticas.",
                                "Executar código comparativo sem erros em novo dataset.",
                                "Identificar violações de pressupostos em dados reais.",
                                "Calcular corretamente teste J de sobre-identificação.",
                                "Recomendar método baseado em análise de eficiência.",
                                "Visualizar comparações com gráficos apropriados."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação de OLS e GMM (códigos funcionais).",
                                "Correta identificação de violações de pressupostos.",
                                "Análise quantitativa robusta (MSE, cobertura IC).",
                                "Interpretação contextual em engenharia.",
                                "Relatório claro e bem estruturado.",
                                "Criatividade em escolha de instrumentos."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência assintótica e testes de hipóteses.",
                                "Engenharia: Análise de dados de sensores e monitoramento estrutural.",
                                "Programação: Otimização numérica em Python/R.",
                                "Econometria: Modelos com endogeneidade aplicados a engenharia."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, usar GMM para estimar parâmetros de fadiga de materiais em grandes datasets de testes, onde OLS falha devido a heterocedasticidade, melhorando previsões de manutenção preditiva e reduzindo downtime em 15%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.4.3",
                        "name": "Interpretação e Rotação de Fatores",
                        "description": "Técnicas para rotacionar e interpretar fatores, facilitando a identificação de estrutura subjacente em dados complexos de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.4.3.1",
                            "name": "Aplicar rotação ortogonal e oblíqua",
                            "description": "Executar rotação Varimax (ortogonal) e Promax (oblíqua) para simplificar loadings e interpretar fatores em datasets de engenharia como falhas em sistemas.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar o dataset e extrair fatores iniciais para rotação",
                                  "subSteps": [
                                    "Carregue o dataset de falhas em sistemas de engenharia (ex: variáveis como vibração, temperatura, pressão).",
                                    "Padronize as variáveis e verifique premissas da análise fatorial (KMO > 0.6, Bartlett sphericity p < 0.05).",
                                    "Execute extração de fatores iniciais usando PCA ou PAF com 3-5 fatores.",
                                    "Salve a matriz de loadings não rotacionados para baseline.",
                                    "Visualize scree plot e communalities para confirmar número de fatores."
                                  ],
                                  "verification": "Matriz de loadings iniciais gerada e premissas validadas; KMO e teste de Bartlett confirmados em output.",
                                  "estimatedTime": "1-2 horas",
                                  "materials": [
                                    "Python 3.x",
                                    "Bibliotecas: pandas, factor_analyzer, matplotlib",
                                    "Dataset CSV de falhas em sistemas (ex: 1000 amostras, 10 variáveis)"
                                  ],
                                  "tips": "Use padronização z-score para evitar bias de escala; comece com 3 fatores para datasets de engenharia.",
                                  "learningObjective": "Preparar dados adequadamente para garantir validade da rotação de fatores.",
                                  "commonMistakes": [
                                    "Ignorar padronização, levando a loadings distorcidos",
                                    "Escolher número errado de fatores sem scree plot",
                                    "Não verificar premissas KMO/Bartlett"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar rotação ortogonal Varimax",
                                  "subSteps": [
                                    "Configure o modelo de análise fatorial com rotação='varimax'.",
                                    "Execute a rotação e extraia a nova matriz de loadings.",
                                    "Calcule percentual de variância explicada pós-rotação.",
                                    "Gere plot de loadings rotacionados (heatmap ou biplot).",
                                    "Identifique loadings > |0.4| como significativos."
                                  ],
                                  "verification": "Matriz de loadings Varimax gerada com valores simplificados (muitos zeros ou baixos); variância total preservada.",
                                  "estimatedTime": "45 minutos - 1 hora",
                                  "materials": [
                                    "Jupyter Notebook",
                                    "factor_analyzer library (fa = FactorAnalyzer(n_factors=3, rotation='varimax'))"
                                  ],
                                  "tips": "Varimax maximiza a variância dos loadings ao quadrado; ideal para fatores independentes em falhas mecânicas.",
                                  "learningObjective": "Executar rotação ortogonal para simplificar estrutura de fatores mantendo ortogonalidade.",
                                  "commonMistakes": [
                                    "Confundir com rotação oblíqua (Varimax assume independência)",
                                    "Não threshold loadings adequadamente",
                                    "Ignorar perda de interpretabilidade em fatores correlacionados"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Implementar rotação oblíqua Promax",
                                  "subSteps": [
                                    "Configure rotação oblíqua com método='promax' e kappa=4 (padrão).",
                                    "Execute a rotação e extraia matriz de loadings padrão e pattern matrix.",
                                    "Calcule matriz de correlações entre fatores (phi matrix).",
                                    "Compare loadings com Varimax usando critério de simplicidade (ex: Cattell's s-index).",
                                    "Visualize correlações fatoriais em heatmap."
                                  ],
                                  "verification": "Pattern matrix gerada com loadings simples e phi matrix mostrando correlações reais (ex: 0.2-0.5 entre fatores).",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Python factor_analyzer (rotation='promax')",
                                    "NumPy para matrizes phi"
                                  ],
                                  "tips": "Promax é Varimax + suavização oblíqua; use kappa=4 para equilíbrio em dados de engenharia.",
                                  "learningObjective": "Aplicar rotação oblíqua para capturar correlações reais entre fatores em sistemas complexos.",
                                  "commonMistakes": [
                                    "Usar kappa muito alto (>10) causando over-rotation",
                                    "Confundir loadings com pattern matrix",
                                    "Assumir independência quando phi > 0.3"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar, comparar rotações e validar resultados",
                                  "subSteps": [
                                    "Compare simplicidade: conte zeros em loadings (>50% ideal).",
                                    "Interprete fatores: nomeie baseado em loadings altos (ex: Fator1=Vibração/Temp).",
                                    "Avalie communalities e variância explicada (deve >60%).",
                                    "Escolha rotação: Varimax se fatores independentes, Promax se correlacionados.",
                                    "Gere relatório com scores fatoriais para predição de falhas."
                                  ],
                                  "verification": "Relatório com interpretação coerente, escolha justificada e scores fatoriais computados.",
                                  "estimatedTime": "1-1.5 horas",
                                  "materials": [
                                    "Seaborn para heatmaps",
                                    "Pandas para resumo de loadings"
                                  ],
                                  "tips": "Priorize Promax em engenharia onde falhas são interdependentes; valide com cross-validation.",
                                  "learningObjective": "Interpretar rotações para extrair insights acionáveis de dados de engenharia.",
                                  "commonMistakes": [
                                    "Sobreinterpretar loadings baixos (<0.3)",
                                    "Não comparar rotações",
                                    "Ignorar communalities baixas (<0.4)"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de sensores de uma turbina eólica (vibração, temperatura, rpm, pressão; 5000 observações), aplique Varimax para isolar 'Fator Mecânico' independente e Promax para revelar correlação com 'Fator Térmico' (phi=0.45), simplificando predição de falhas.",
                              "finalVerifications": [
                                "Loadings simplificados: >60% com |loading| < 0.3 ou > 0.7.",
                                "Variância explicada total similar pré/pós-rotação (>70%).",
                                "Correlações fatoriais lógicas (phi < 0.8 para Promax).",
                                "Interpretação nomeada para cada fator com ≥3 variáveis fortes.",
                                "Scores fatoriais gerados e plotados contra falhas reais.",
                                "Código reproduzível sem erros em novo dataset."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação: código executa sem erros e produz matrizes corretas.",
                                "Simplicidade alcançada: redução significativa em loadings ambíguos.",
                                "Interpretação qualitativa: fatores nomeados com justificativa baseada em domínio de engenharia.",
                                "Comparação robusta: escolha de rotação justificada por métricas (ex: s-index).",
                                "Eficiência computacional: tempo <5s para 1000 amostras.",
                                "Relatório claro: visualizações e conclusões acionáveis."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Multivariada: ligação com PCA e componentes principais.",
                                "Machine Learning: redução de dimensionalidade para modelos preditivos.",
                                "Engenharia de Manutenção: aplicação em detecção de falhas preditivas.",
                                "Visualização de Dados: heatmaps e biplots para comunicação.",
                                "Programação Científica: uso de APIs como scikit-learn/factor_analyzer."
                              ],
                              "realWorldApplication": "Em indústrias como óleo & gás ou aeroespacial, rotações Varimax/Promax simplificam análise de dados de sensores para identificar padrões de falha (ex: rotores), reduzindo downtime em 20-30% via manutenção preditiva otimizada."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.4.3.2",
                            "name": "Interpretar loadings e scores fatoriais",
                            "description": "Analisar loadings fatoriais (>0.4 como significativos) e calcular scores fatoriais para resumir dados multivariados em engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os conceitos fundamentais de loadings e scores fatoriais",
                                  "subSteps": [
                                    "Defina loadings fatoriais como as correlações entre variáveis originais e fatores latentes.",
                                    "Explique scores fatoriais como as pontuações projetadas de cada observação nos fatores.",
                                    "Revise a matriz de loadings obtida de software como R (factanal) ou Python (factor_analyzer).",
                                    "Identifique o threshold comum de >0.4 para loadings significativos em contextos de engenharia.",
                                    "Diferencie loadings de comunalidades e variância explicada."
                                  ],
                                  "verification": "Explique verbalmente ou por escrito o significado de um loading de 0.6 em um fator, citando o threshold.",
                                  "estimatedTime": "20 minutos",
                                  "materials": [
                                    "Documentação de análise fatorial (R ou Python)",
                                    "Artigo introdutório sobre análise fatorial"
                                  ],
                                  "tips": "Use diagramas path para visualizar relações variável-fator.",
                                  "learningObjective": "Entender os conceitos teóricos de loadings e scores para basear interpretações subsequentes.",
                                  "commonMistakes": [
                                    "Confundir loadings com coeficientes de regressão",
                                    "Ignorar o sinal dos loadings (positivo/negativo)",
                                    "Aplicar thresholds arbitrários sem justificativa"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Analisar e interpretar a matriz de loadings fatoriais",
                                  "subSteps": [
                                    "Extraia a matriz de loadings rotacionada (ex: varimax) do output da análise.",
                                    "Identifique loadings absolutos >0.4 como significativos e marque-os.",
                                    "Agrupe variáveis por padrões de loading alto em fatores específicos (cross-loadings <0.3).",
                                    "Calcule a variância explicada por fator somando quadrados dos loadings.",
                                    "Interprete semanticamente: nomeie fatores baseados em variáveis com loadings altos."
                                  ],
                                  "verification": "Crie um mapa mental ou tabela resumindo quais variáveis carregam em quais fatores, justificando com valores numéricos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Dataset multivariado de engenharia (ex: propriedades de materiais)",
                                    "Software R/Python com factanal ou factor_analyzer"
                                  ],
                                  "tips": "Priorize rotação ortogonal para interpretabilidade em engenharia.",
                                  "learningObjective": "Capacitar a identificar e interpretar padrões significativos na matriz de loadings.",
                                  "commonMistakes": [
                                    "Interpretar loadings baixos como irrelevantes sem threshold",
                                    "Ignorar cross-loadings que indicam ambiguidade",
                                    "Nomear fatores sem base nas variáveis dominantes"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Calcular scores fatoriais a partir dos loadings",
                                  "subSteps": [
                                    "Escolha método de scoring: regressão (Bartlett) ou Thompson para scores não correlacionados.",
                                    "Use fórmula: score = (loadings * inv(covariância)) * dados padronizados.",
                                    "Implemente em software: R (predict(princomp)) ou Python (factor_analyzer.get_scores()).",
                                    "Padronize variáveis antes (z-scores) para escalas comparáveis.",
                                    "Valide scores checando média zero e variância unitária aproximada."
                                  ],
                                  "verification": "Calcule manualmente scores para 3 observações de um dataset pequeno e compare com software.",
                                  "estimatedTime": "40 minutos",
                                  "materials": [
                                    "Código R/Python pronto para scoring",
                                    "Dataset pequeno com 10 observações e 5 variáveis"
                                  ],
                                  "tips": "Use dados padronizados para evitar viés de escala em engenharia.",
                                  "learningObjective": "Dominar o cálculo prático de scores fatoriais para resumir dados.",
                                  "commonMistakes": [
                                    "Esquecer padronização levando a scores enviesados",
                                    "Usar loadings não rotacionados",
                                    "Confundir scores com eigenvectors de PCA"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar scores fatoriais no contexto de engenharia",
                                  "subSteps": [
                                    "Analise distribuição dos scores (boxplot, histograma) por fator.",
                                    "Identifique outliers: scores >2 ou <-2 desvios padrão.",
                                    "Relacione scores altos/baixos às interpretações de fatores (ex: score alto em 'força' indica material robusto).",
                                    "Crie scores compostos se múltiplos fatores relevantes.",
                                    "Valide com métricas: correlação scores vs. variáveis originais."
                                  ],
                                  "verification": "Gere relatório de 1 página interpretando scores de um dataset, ligando a aplicações reais.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Gráficos gerados (ggplot2 ou matplotlib)",
                                    "Relatório template"
                                  ],
                                  "tips": "Visualize scores em scatterplots para padrões multivariados.",
                                  "learningObjective": "Aplicar interpretações de scores para insights acionáveis em dados de engenharia.",
                                  "commonMistakes": [
                                    "Interpretar scores isolados sem contexto de loadings",
                                    "Ignorar outliers que indicam falhas de dados",
                                    "Sobre-generalizar sem validação cruzada"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um dataset de engenharia mecânica com variáveis como resistência à tração, ductilidade, dureza e peso de ligas metálicas (n=50 amostras), a análise fatorial revela Fator1 'Resistência Mecânica' (loadings: tração=0.85, dureza=0.72) e Fator2 'Leveza' (peso=-0.78). Scores fatoriais identificam amostras com alta Resistência Mecânica (score>1.5) ideais para estruturas aeroespaciais.",
                              "finalVerifications": [
                                "Identificar corretamente todos loadings >0.4 em uma matriz fornecida.",
                                "Calcular scores fatoriais para uma amostra de 5 observações com precisão >95%.",
                                "Nomear fatores com base em padrões de loadings e justificar.",
                                "Interpretar 3 scores extremos ligando ao contexto de engenharia.",
                                "Explicar impacto de rotação na interpretabilidade dos loadings.",
                                "Validar scores checando variância explicada total >60%."
                              ],
                              "assessmentCriteria": [
                                "Precisão na detecção de loadings significativos (threshold >0.4).",
                                "Correção matemática nos cálculos de scores fatoriais.",
                                "Profundidade na interpretação semântica de fatores e scores.",
                                "Uso adequado de visualizações para validação.",
                                "Identificação e discussão de erros comuns evitados.",
                                "Aplicação contextualizada a problemas de engenharia."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de significância de loadings.",
                                "Machine Learning: similaridade com componentes principais em PCA.",
                                "Engenharia de Materiais: redução dimensional em testes multivariados.",
                                "Análise de Dados em Engenharia Civil: monitoramento estrutural.",
                                "Econometria: modelagem de fatores latentes em séries temporais."
                              ],
                              "realWorldApplication": "Na indústria de manufatura, interpretar loadings e scores fatoriais resume medições de sensores (vibração, temperatura, pressão) em fatores como 'Desgaste' e 'Eficiência', permitindo manutenção preditiva e otimização de processos, reduzindo downtime em 20-30%."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.4.4",
                        "name": "Aplicações em Dados de Engenharia",
                        "description": "Implementação prática da análise fatorial em contextos de engenharia, integrando com econometria e análise de dados complexos.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.4.4.1",
                            "name": "Implementar análise fatorial em R para dados de engenharia",
                            "description": "Usar pacotes como psych ou factanal no R para analisar dados reais de engenharia, como monitoramento de estruturas ou otimização de processos.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Configurar ambiente R e preparar dataset de engenharia",
                                  "subSteps": [
                                    "Instalar e carregar pacotes essenciais: install.packages(c('psych', 'factanal', 'corrplot', 'ggplot2')); library(psych); library(corrplot)",
                                    "Obter dataset real de engenharia (ex: dados de sensores de vibração ou deformação de estruturas do UCI Repository ou Kaggle)",
                                    "Carregar dados com read.csv() ou read_excel() e inspecionar com str(), summary(), head()",
                                    "Tratar valores ausentes usando na.omit() ou imputação com mean() por coluna",
                                    "Padronizar variáveis com scale() para análise fatorial"
                                  ],
                                  "verification": "Dataset limpo carregado sem erros, matriz de correlação gerada com cor() e visualizada com corrplot()",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "RStudio ou R console",
                                    "Pacotes: psych, corrplot, ggplot2",
                                    "Dataset exemplo: 'bridge_sensor_data.csv'"
                                  ],
                                  "tips": "Sempre verifique dimensões com dim() após limpeza para garantir pelo menos 5-10 observações por variável",
                                  "learningObjective": "Configurar ambiente R e preparar dados de engenharia adequados para análise fatorial",
                                  "commonMistakes": [
                                    "Esquecer de instalar pacotes antes de library()",
                                    "Não tratar outliers que distorcem correlações",
                                    "Usar dados não numéricos sem conversão"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Realizar análise exploratória e teste de adequação",
                                  "subSteps": [
                                    "Calcular matriz de correlação com cor(data_scaled)",
                                    "Executar teste KMO com KMO(data_scaled) e Bartlett com cortest.bartlett(cor_matrix)",
                                    "Gerar scree plot com fa.parallel(data_scaled) do psych para estimar número de fatores",
                                    "Verificar communalities esperadas e decidir número de fatores (ex: >0.7 cumulativo)",
                                    "Documentar resultados em um relatório inicial com print()"
                                  ],
                                  "verification": "KMO > 0.6, p-value Bartlett < 0.05, e scree plot salvo como PNG",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Pacotes psych carregados",
                                    "Dataset escalonado do step 1"
                                  ],
                                  "tips": "Se KMO < 0.6, remova variáveis com baixa correlação (<0.3) e reteste",
                                  "learningObjective": "Avaliar adequação dos dados para análise fatorial usando métricas estatísticas padrão",
                                  "commonMistakes": [
                                    "Ignorar teste Bartlett e assumir adequação",
                                    "Escolher fatores baseado só em elbow sem parallel analysis",
                                    "Não escalonar dados numéricos"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar análise fatorial com factanal ou fa()",
                                  "subSteps": [
                                    "Rodar análise com fa(data_scaled, nfactors=3, rotate='varimax') ou factanal(data_scaled, factors=3, rotation='varimax')",
                                    "Extrair loadings com fa_object$loadings e communalities com fa_object$communality",
                                    "Rotacionar fatores para interpretabilidade (varimax ou oblimin se correlacionados)",
                                    "Calcular scores fatoriais com factor.scores(fa_object)",
                                    "Salvar resultados em objetos para plots: loadings_matrix <- fa_object$loadings"
                                  ],
                                  "verification": "Modelo converge sem warnings, loadings > 0.4 em pelo menos um fator por variável",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "Funções fa() ou factanal()",
                                    "Dados adequados do step 2"
                                  ],
                                  "tips": "Comece com nfactors conservador (2-4) e ajuste baseado em scree; use rotate='varimax' para ortogonalidade",
                                  "learningObjective": "Implementar e extrair componentes da análise fatorial em R para dados multivariados",
                                  "commonMistakes": [
                                    "Não especificar rotation levando a loadings confusos",
                                    "nfactors muito alto causando overfitting",
                                    "Ignorar convergence warnings"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados, visualizar e validar",
                                  "subSteps": [
                                    "Plotar loadings com fa.diagram(fa_object) ou biplot()",
                                    "Interpretar fatores: nomear baseado em loadings altas (ex: Fator1='Estresse Estrutural')",
                                    "Validar com reliability(fa_object) e plot de scores com ggplot(scores)",
                                    "Comparar com dados originais: correlação entre scores e variáveis",
                                    "Gerar relatório com loadings table e conclusões em Markdown ou PDF"
                                  ],
                                  "verification": "Fatores nomeados com interpretações lógicas, plots salvos, e communalities > 0.5 média",
                                  "estimatedTime": "1 hora",
                                  "materials": [
                                    "ggplot2 para visualizações avançadas",
                                    "Resultados do step 3"
                                  ],
                                  "tips": "Loadings > |0.5| são significativos; valide com cross-validation se dataset grande",
                                  "learningObjective": "Interpretar e comunicar resultados de análise fatorial aplicados a engenharia",
                                  "commonMistakes": [
                                    "Sobrenomear fatores sem base em domínio",
                                    "Não plotar para visual inspeção",
                                    "Ignorar communalities baixas indicando variáveis ruins"
                                  ]
                                }
                              ],
                              "practicalExample": "Usando dados de sensores de uma ponte (10 variáveis: deformações, acelerações em pontos A-G), execute análise fatorial para extrair 3 fatores: 'Vibração Global', 'Deformação Local Norte' e 'Estresse Térmico', reduzindo de 10 para 3 variáveis para modelagem preditiva de falhas.",
                              "finalVerifications": [
                                "Código R completo executa end-to-end sem erros em dataset de engenharia real",
                                "KMO >= 0.7 e Bartlett significativo confirmam adequação",
                                "Loadings matriz mostra estrutura clara com >70% variância explicada",
                                "Fatores interpretados com nomes de domínio de engenharia",
                                "Scores fatoriais gerados e plotados corretamente",
                                "Relatório gerado com plots e tabela de loadings"
                              ],
                              "assessmentCriteria": [
                                "Precisão na preparação e adequação dos dados (KMO, Bartlett)",
                                "Correta implementação de fa() ou factanal() com rotação apropriada",
                                "Qualidade da interpretação de loadings e nomeação de fatores",
                                "Efetividade das visualizações (scree, loadings plot)",
                                "Aplicação prática ao contexto de engenharia (ex: otimização)",
                                "Ausência de erros comuns e documentação clara"
                              ],
                              "crossCurricularConnections": [
                                "Estatística: testes multivariados e redução dimensional",
                                "Programação: scripting avançado em R e manipulação de dados",
                                "Engenharia Civil/Mecânica: análise de monitoramento estrutural",
                                "Machine Learning: pré-processamento para PCA/FA em modelos preditivos",
                                "Gestão de Projetos: otimização de processos industriais"
                              ],
                              "realWorldApplication": "Na engenharia, análise fatorial identifica padrões latentes em dados de sensores para manutenção preditiva de pontes/aviões, otimiza processos fabris reduzindo variáveis em controles de qualidade, e melhora modelos de simulação finita reduzindo dimensionalidade de datasets massivos."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.4.4.2",
                            "name": "Integrar com regressão e séries temporais",
                            "description": "Combinar fatores extraídos com modelos de regressão linear ou ARIMA para previsão em aplicações de engenharia, relaxando pressupostos quando necessário.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar fatores extraídos e dados target para integração",
                                  "subSteps": [
                                    "Selecionar fatores relevantes da análise fatorial com base em cargas fatoriais elevadas",
                                    "Calcular scores fatoriais usando regressão ou método de Bartlett",
                                    "Preparar a variável target (ex: série temporal de falhas ou consumo)",
                                    "Tratar missing values e outliers nos fatores e target",
                                    "Dividir dados em conjuntos de treino, validação e teste"
                                  ],
                                  "verification": "Dataset integrado pronto com fatores como preditores e target alinhado, sem NaNs ou discrepâncias",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Python (pandas, numpy, factor_analyzer), Jupyter Notebook, dataset de engenharia",
                                  "tips": "Use scores fatoriais em vez de variáveis originais para reduzir dimensionalidade",
                                  "learningObjective": "Dominar a preparação de outputs fatoriais para uso em predição",
                                  "commonMistakes": "Não alinhar temporalmente fatores e target em séries temporais"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Implementar regressão linear com fatores como preditores",
                                  "subSteps": [
                                    "Ajustar modelo de regressão linear: target ~ fatores",
                                    "Verificar pressupostos (linearidade, homocedasticidade, normalidade de resíduos)",
                                    "Interpretar coeficientes e significância dos fatores",
                                    "Realizar diagnósticos com plots (QQ, residuals vs fitted)",
                                    "Prever no conjunto de teste e calcular métricas (R², RMSE)"
                                  ],
                                  "verification": "Modelo ajustado com R² > 0.7 e resíduos aleatórios",
                                  "estimatedTime": "3 horas",
                                  "materials": "Python (statsmodels, scikit-learn), matplotlib/seaborn",
                                  "tips": "Inclua intercepto e use VIF para detectar multicolinearidade",
                                  "learningObjective": "Aplicar regressão linear multivariada com fatores latentes",
                                  "commonMistakes": "Ignorar multicolinearidade entre fatores levando a coeficientes instáveis"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Integrar fatores em modelos ARIMA para séries temporais",
                                  "subSteps": [
                                    "Testar estacionariedade da série target (ADF test)",
                                    "Ajustar ARIMA puro e depois híbrido (fatores como exógenas em ARIMAX)",
                                    "Selecionar parâmetros p,d,q via ACF/PACF ou auto_arima",
                                    "Incorporar scores fatoriais como variáveis exógenas",
                                    "Gerar forecasts com intervalos de confiança"
                                  ],
                                  "verification": "Modelo ARIMAX com AIC menor que ARIMA puro e forecasts plausíveis",
                                  "estimatedTime": "4 horas",
                                  "materials": "Python (pmdarima, statsmodels.tsa), dataset temporal",
                                  "tips": "Diferencie a série se não estacionária antes de adicionar exógenas",
                                  "learningObjective": "Construir modelos híbridos fator-ARIMA para predição temporal",
                                  "commonMistakes": "Adicionar exógenas sem testar estacionariedade da target"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Relaxar pressupostos e realizar ajustes robustos",
                                  "subSteps": [
                                    "Identificar violações (heterocedasticidade, não-normalidade)",
                                    "Aplicar regressão robusta (Huber, quantile) ou transformações (log, Box-Cox)",
                                    "Para ARIMA, usar SARIMAX se sazonalidade detectada",
                                    "Testar alternativas como regressão ridge se multicolinearidade persiste",
                                    "Comparar modelos com validação cruzada temporal"
                                  ],
                                  "verification": "Modelo ajustado com resíduos melhorados (Shapiro-Wilk p>0.05)",
                                  "estimatedTime": "2-3 horas",
                                  "materials": "Python (sklearn robust, scipy stats), cross_validation tools",
                                  "tips": "Priorize validação out-of-sample para séries temporais",
                                  "learningObjective": "Adaptar modelos relaxando pressupostos clássicos em contextos reais",
                                  "commonMistakes": "Forçar pressupostos rígidos ignorando dados de engenharia ruidosos"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar, interpretar e aplicar previsões",
                                  "subSteps": [
                                    "Calcular métricas finais (MAE, MAPE, MASE para temporais)",
                                    "Interpretar contribuição dos fatores nas previsões",
                                    "Visualizar forecasts vs reais com bandas de confiança",
                                    "Simular cenários (what-if com variação de fatores)",
                                    "Documentar pipeline completo para reprodutibilidade"
                                  ],
                                  "verification": "Relatório com métricas, plots e interpretações coerentes",
                                  "estimatedTime": "2 horas",
                                  "materials": "Python (plotly, matplotlib), relatório template",
                                  "tips": "Use MASE para comparar com benchmark ingênuo em séries",
                                  "learningObjective": "Avaliar integralmente modelos híbridos e extrair insights",
                                  "commonMistakes": "Superestimar performance por overfitting no treino"
                                }
                              ],
                              "practicalExample": "Em dados de sensores de uma turbina eólica (vibração, temperatura, carga), extraia fatores (desgaste, fadiga). Use-os como exógenas em ARIMAX para prever tempo até falha, relaxando normalidade com regressão robusta, alcançando MAPE de 15%.",
                              "finalVerifications": [
                                "Pipeline roda end-to-end sem erros",
                                "Previsões superam baselines (média, ARIMA puro) em 20%",
                                "Interpretação dos fatores alinha com domínio de engenharia",
                                "Resíduos passam testes de diagnóstico",
                                "Forecasts têm bandas de confiança realistas",
                                "Modelo é robusto a 10% de ruído adicionado"
                              ],
                              "assessmentCriteria": [
                                "Precisão preditiva (RMSE/MAPE < benchmark)",
                                "Correta integração de fatores (contribuição >30% na variância explicada)",
                                "Relaxamento adequado de pressupostos (resíduos iid)",
                                "Qualidade de código e documentação",
                                "Interpretação contextual em engenharia",
                                "Eficiência computacional (tempo <10min para fit)"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial (testes de pressupostos)",
                                "Engenharia de Dados (pipelines ETL)",
                                "Machine Learning (modelos híbridos)",
                                "Análise de Sistemas Dinâmicos (previsão temporal)"
                              ],
                              "realWorldApplication": "Manutenção preditiva em plantas industriais, prevendo falhas em equipamentos via fatores de sensores IoT integrados a ARIMAX, otimizando downtime e custos em 25%."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "id": "10.1.7.5",
                    "name": "Inferência e Testes de Hipóteses em Modelos",
                    "description": "Validação estatística de modelos econométricos aplicados a dados de engenharia, incluindo pressupostos e seleção de modelos.",
                    "individualConcepts": [
                      {
                        "id": "10.1.7.5.1",
                        "name": "Pressupostos da Regressão Linear",
                        "description": "Identificação e validação dos pressupostos fundamentais para a aplicação do método de Mínimos Quadrados Ordinários (MQO) em modelos econométricos aplicados a dados de engenharia, como linearidade, homocedasticidade e independência dos erros.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.5.1.1",
                            "name": "Listar os pressupostos do modelo de regressão linear clássica",
                            "description": "Descrever os quatro pressupostos principais do MQO: linearidade nos parâmetros, exogeneidade estrita, homocedasticidade e normalidade dos erros, com exemplos em contextos de engenharia como modelagem de eficiência energética.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Entender o modelo de regressão linear clássica e a importância dos pressupostos",
                                  "subSteps": [
                                    "Revise a equação do modelo de regressão linear: Y = β₀ + β₁X₁ + ... + βₖXₖ + ε",
                                    "Explique por que os pressupostos são necessários para as propriedades do estimador MQO (não viesado, eficiente, etc.)",
                                    "Identifique os quatro pressupostos principais do MQO clássico",
                                    "Discuta violações comuns e consequências (ex.: viés, ineficiência)",
                                    "Anote definições iniciais em um caderno"
                                  ],
                                  "verification": "Escreva um resumo de 100 palavras explicando o modelo e a necessidade dos pressupostos, sem erros conceituais",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Caderno ou editor de texto",
                                    "Livro de econometria ou estatística (ex.: Wooldridge)",
                                    "Notebook com Python/R para visualização opcional"
                                  ],
                                  "tips": "Comece com a equação para ancorar o aprendizado; use analogias como 'regras do jogo' para inferências válidas",
                                  "learningObjective": "Compreender o framework teórico da regressão linear e o papel dos pressupostos para inferências estatísticas confiáveis",
                                  "commonMistakes": "Confundir pressupostos com propriedades do estimador; ignorar que são condições para teoremas assintóticos"
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Pressuposto 1: Linearidade nos parâmetros",
                                  "subSteps": [
                                    "Defina formalmente: E(Y|X) = β₀ + β₁X₁ + ... + βₖXₖ",
                                    "Explique que é uma suposição sobre a estrutura condicional da média",
                                    "Dê exemplo em engenharia: modelagem de eficiência energética onde consumo (Y) é linear em temperatura (X)",
                                    "Discuta teste: plotar resíduos vs. preditos para checar linearidade",
                                    "Pratique reescrevendo o pressuposto em notação matemática"
                                  ],
                                  "verification": "Descreva o pressuposto e forneça um exemplo engenheiro sem usar termos errados como 'linearidade nos dados'",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Gráfico de resíduos (software como Python matplotlib ou R ggplot)",
                                    "Dataset exemplo de eficiência energética (ex.: Kaggle)"
                                  ],
                                  "tips": "Lembre: linearidade é nos parâmetros β, não nos dados X ou Y; teste com gráficos de resíduos",
                                  "learningObjective": "Dominar a definição precisa e implicações do primeiro pressuposto com aplicação prática",
                                  "commonMistakes": "Pensar que requer linearidade em X ou Y; confundir com multicolinearidade"
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Pressuposto 2: Exogeneidade estrita (E(ε|X)=0)",
                                  "subSteps": [
                                    "Defina: Cov(X, ε) = 0 para todos os regressores, ou E(ε|X) = 0",
                                    "Explique implicações: garante não viesado do MQO",
                                    "Exemplo em engenharia: em eficiência energética, temperatura (X) não correlacionada com erro de medição (ε)",
                                    "Discuta violações: endogeneidade por variáveis omitidas ou causalidade reversa",
                                    "Simule em código: gere dados com e sem exogeneidade e compare β estimados"
                                  ],
                                  "verification": "Explique com equação e exemplo por que violação causa viés, corretamente",
                                  "estimatedTime": "20-30 minutos",
                                  "materials": [
                                    "Python/R com bibliotecas statsmodels ou lmtest",
                                    "Dataset sintético gerado"
                                  ],
                                  "tips": "Use 'não correlação entre X e erro' como mnemônico; teste com correlação de resíduos e X",
                                  "learningObjective": "Entender exogeneidade como ausência de correlação e suas consequências para consistência",
                                  "commonMistakes": "Confundir com causalidade; achar que basta ortogonalidade nos dados amostrais"
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Pressuposto 3: Homocedasticidade (Var(ε|X) = σ² constante)",
                                  "subSteps": [
                                    "Defina: variância condicional dos erros constante",
                                    "Explique impacto em violações: erros padrão incorretos, testes inválidos",
                                    "Exemplo: eficiência energética onde variância de erros não varia com nível de isolamento (X)",
                                    "Testes: Breusch-Pagan ou White; plote resíduos vs. fitted",
                                    "Pratique interpretando output de teste de heteroscedasticidade"
                                  ],
                                  "verification": "Descreva teste visual e formal, identificando heteroscedasticidade em gráfico hipotético",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Software estatístico com teste BP (Python: statsmodels, R: lmtest)",
                                    "Gráficos de resíduos"
                                  ],
                                  "tips": "Procure padrões em funil nos resíduos vs. fitted; corrija com erros padrão robustos se violado",
                                  "learningObjective": "Identificar e testar homocedasticidade para inferências válidas sobre significância",
                                  "commonMistakes": "Confundir com normalidade; ignorar que MQO ainda não viesado"
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Pressuposto 4: Normalidade dos erros (ε ~ N(0, σ²))",
                                  "subSteps": [
                                    "Defina: erros condicionalmente normais para testes t/F exatos em amostras pequenas",
                                    "Explique que é para distribuição exata, não assintótica",
                                    "Exemplo: em eficiência energética, erros de medição sensores seguem normal",
                                    "Testes: Shapiro-Wilk, Q-Q plot, histogram de resíduos",
                                    "Discuta robustez: ok para grandes amostras pelo TLMC",
                                    "Integre todos pressupostos em checklist"
                                  ],
                                  "verification": "Liste teste e interpretação para normalidade, com exemplo",
                                  "estimatedTime": "15-25 minutos",
                                  "materials": [
                                    "Python scipy.stats.normaltest ou R shapiro.test",
                                    "Q-Q plots"
                                  ],
                                  "tips": "Normalidade é frágil; priorize para n<30; use bootstrap para grandes n",
                                  "learningObjective": "Compreender normalidade para testes paramétricos e alternativas",
                                  "commonMistakes": "Achar essencial para MQO não viesado; confundir com homocedasticidade"
                                }
                              ],
                              "practicalExample": "Em modelagem de eficiência energética: Y=consumo kWh, X1=temperatura externa, X2=isolamento. Verifique linearidade plotando Y vs X; exogeneidade com correlação X-resíduos=0; homocedasticidade sem funil em resíduos vs fitted; normalidade via Q-Q plot dos resíduos. Se violado, ajuste modelo ou use robusto.",
                              "finalVerifications": [
                                "Liste corretamente os 4 pressupostos com abreviações padrão (LIN, EXO, HOMO, NORM)",
                                "Explique cada um com equação matemática precisa",
                                "Forneça exemplo engenheiro para cada sem erros",
                                "Descreva pelo menos um teste diagnóstico por pressuposto",
                                "Crie checklist para verificação em dataset real",
                                "Discuta consequências de violações em inferências"
                              ],
                              "assessmentCriteria": [
                                "Precisão conceitual: definições exatas sem confusões comuns",
                                "Profundidade: inclusão de notação matemática e testes",
                                "Aplicação contextual: exemplos relevantes a engenharia energética",
                                "Completude: cobertura de todos os 4 pressupostos",
                                "Clareza: explicações concisas e acionáveis",
                                "Crítica: menção a robustez e alternativas"
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: testes de hipóteses e intervalos",
                                "Engenharia (Energética/Mecânica): modelagem preditiva",
                                "Programação Computacional: Python/R para diagnósticos (statsmodels, ggplot)",
                                "Econometria: extensões para painel e IV",
                                "Machine Learning: diagnóstico em regressão vs. black-box models"
                              ],
                              "realWorldApplication": "Na engenharia, verificar pressupostos em regressão para eficiência energética garante predições confiáveis de consumo, otimização de isolantes e políticas sustentáveis, evitando decisões baseadas em modelos inválidos que superestimam impactos."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.5.1.2",
                            "name": "Verificar violações de pressupostos",
                            "description": "Aplicar testes diagnósticos como Ramsey RESET para linearidade, Breusch-Pagan para heteroscedasticidade e Durbin-Watson para autocorrelação, utilizando dados de engenharia simulados ou reais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e ajustar modelo de regressão linear",
                                  "subSteps": [
                                    "Carregar dados de engenharia (ex: tensão vs. carga em testes de materiais) usando pandas.",
                                    "Explorar dados com summary statistics e plots (scatterplot, histogram).",
                                    "Ajustar modelo OLS com statsmodels: sm.OLS(y, X).fit().",
                                    "Verificar resíduos: model.resid.",
                                    "Salvar modelo para testes subsequentes."
                                  ],
                                  "verification": "Modelo ajustado com summary() mostrando coeficientes e R-squared; resíduos plotados sem padrões óbvios iniciais.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Python (pandas, statsmodels, matplotlib), dataset de engenharia (ex: CSV com colunas 'carga', 'tensao').",
                                  "tips": "Padronize variáveis independentes para melhor interpretação nos testes.",
                                  "learningObjective": "Entender preparação de dados para diagnósticos de regressão.",
                                  "commonMistakes": "Ignorar multicolinearidade inicial ou usar dados não estacionários."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Aplicar teste Ramsey RESET para linearidade",
                                  "subSteps": [
                                    "Importar linear_reset de statsmodels.stats.diagnostic.",
                                    "Executar: lbvalue, pvalue, _ = linear_reset(model, power=2).",
                                    "Interpretar p-value: se >0.05, não rejeitar linearidade.",
                                    "Plotar resíduos vs. fitted values para visual confirmação.",
                                    "Documentar resultado em relatório."
                                  ],
                                  "verification": "P-value calculado e interpretado corretamente; plot sem padrões curvos.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "statsmodels.stats.diagnostic.linear_reset, notebook Jupyter.",
                                  "tips": "Teste múltiplos powers (2-4) se suspeita forte de não-linearidade.",
                                  "learningObjective": "Diagnosticar violações de linearidade funcional.",
                                  "commonMistakes": "Confundir RESET com testes de normalidade; ignorar powers adequados."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar teste Breusch-Pagan para heteroscedasticidade",
                                  "subSteps": [
                                    "Importar het_breuschpagan de statsmodels.stats.diagnostic.",
                                    "Executar: lm, lmpval, _, _ = het_breuschpagan(model.resid, model.model.exog).",
                                    "Interpretar LM statistic e p-value: p>0.05 indica homoscedasticidade.",
                                    "Plotar resíduos quadrados vs. fitted para visual.",
                                    "Registrar se violado e sugerir correção (ex: robust SE)."
                                  ],
                                  "verification": "P-value e LM statistic reportados; plot sem funil.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "statsmodels.stats.diagnostic.het_breuschpagan.",
                                  "tips": "Use White test se suspeita de heteroscedasticidade não-linear.",
                                  "learningObjective": "Detectar variância não constante nos resíduos.",
                                  "commonMistakes": "Testar em resíduos não padronizados; ignorar exog variáveis."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar teste Durbin-Watson para autocorrelação",
                                  "subSteps": [
                                    "Calcular: from statsmodels.stats.diagnostic import durbin_watson; dw = durbin_watson(model.resid).",
                                    "Interpretar: DW ~2 indica ausência; <1.5 ou >2.5 sugere autocorrelação.",
                                    "Plotar ACF de resíduos para confirmação visual.",
                                    "Se violado, considerar ARIMA ou Newey-West SE.",
                                    "Compilar todos resultados em tabela."
                                  ],
                                  "verification": "DW statistic entre 1.5-2.5 ou corretamente flagged; ACF sem picos significativos.",
                                  "estimatedTime": "25 minutos",
                                  "materials": "statsmodels.stats.diagnostic.durbin_watson, statsmodels.tsa.stattools.acf.",
                                  "tips": "Útil para séries temporais em engenharia; teste lags múltiplos se necessário.",
                                  "learningObjective": "Identificar dependência serial nos resíduos.",
                                  "commonMistakes": "Aplicar em dados não ordenados; confundir com estacionariedade."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar resultados e propor correções",
                                  "subSteps": [
                                    "Resumir violações em tabela: teste, p-value, conclusão.",
                                    "Priorizar correções: transformações para linearidade, robust SE para heteroscedasticidade.",
                                    "Reajustar modelo se necessário e retestar.",
                                    "Gerar relatório com plots e recomendações.",
                                    "Discutir impacto em inferências de engenharia."
                                  ],
                                  "verification": "Relatório completo com tabela, plots e plano de ação.",
                                  "estimatedTime": "40 minutos",
                                  "materials": "Jupyter notebook, pandas para tabelas.",
                                  "tips": "Sempre reteste após correções para convergência.",
                                  "learningObjective": "Sintetizar diagnósticos e remediar modelos.",
                                  "commonMistakes": "Ignorar violações múltiplas; superestimar robustez sem reteste."
                                }
                              ],
                              "practicalExample": "Em dados simulados de testes de fadiga em vigas de aço (colunas: ciclos_de_carga, tensao_maxima, deformacao), ajuste regressão deformacao ~ ciclos + tensao. Aplique testes: RESET detecta não-linearidade (p=0.01), Breusch-Pagan OK (p=0.23), DW=1.2 indica autocorrelação devido a ordem temporal.",
                              "finalVerifications": [
                                "Executa todos os testes sem erros de código.",
                                "Interpreta p-values corretamente para cada teste.",
                                "Identifica violações em dataset de exemplo.",
                                "Propõe correções apropriadas.",
                                "Gera plots diagnósticos claros.",
                                "Compila relatório coeso."
                              ],
                              "assessmentCriteria": [
                                "Precisão na implementação dos testes (100% match com statsmodels outputs).",
                                "Correta interpretação estatística (p-values thresholds).",
                                "Qualidade visual dos plots (legíveis, informativos).",
                                "Lógica nas correções propostas.",
                                "Completude do relatório (tabelas + texto).",
                                "Eficiência temporal (dentro de 2.5h total)."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Hipóteses nulas/alternativas.",
                                "Programação Computacional: Python/statsmodels para análise.",
                                "Engenharia Mecânica: Modelagem preditiva de falhas materiais.",
                                "Análise de Séries Temporais: Extensão para autocorrelação.",
                                "Machine Learning: Diagnósticos em modelos lineares."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial, verificar pressupostos em regressões de fadiga de turbinas garante predições confiáveis de vida útil, evitando falhas catastróficas e otimizando manutenção preditiva."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.5.1.3",
                            "name": "Analisar propriedades estatísticas dos estimadores MQO",
                            "description": "Explicar propriedades como não-viés, consistência, eficiência e asymptoticidade sob pressupostos satisfeitos, com demonstrações matemáticas e aplicações em regressões de desempenho de sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar os pressupostos fundamentais da regressão linear MQO",
                                  "subSteps": [
                                    "Liste os pressupostos clássicos de Gauss-Markov: linearidade nos parâmetros, exogeneidade estrita (E[u|X]=0), homocedasticidade e ausência de autocorrelação (Var(u|X)=σ²I).",
                                    "Explique o pressuposto adicional de normalidade dos erros para inferência exata.",
                                    "Discuta violações comuns e suas implicações nas propriedades dos estimadores.",
                                    "Derive brevemente a fórmula do estimador MQO: β̂ = (X'X)⁻¹X'y.",
                                    "Verifique os pressupostos com resíduos em um exemplo simples."
                                  ],
                                  "verification": "Capacidade de listar e justificar todos os pressupostos com exemplos de violações.",
                                  "estimatedTime": "1.5 horas",
                                  "materials": [
                                    "Notas de econometria ou livro 'Introdução à Econometria' de Wooldridge",
                                    "Software R ou Python (statsmodels ou lmtest)"
                                  ],
                                  "tips": [
                                    "Use mnemônicos para lembrar os pressupostos: LINE (Linearity, Independence, No multicollinearity, Exogeneity).",
                                    "Sempre verifique multicolinearidade perfeita como barreira inicial."
                                  ],
                                  "learningObjective": "Compreender os pressupostos necessários para validar as propriedades estatísticas dos estimadores MQO.",
                                  "commonMistakes": [
                                    "Confundir exogeneidade com independência dos erros.",
                                    "Ignorar multicolinearidade na matriz X'X.",
                                    "Esquecer que normalidade é para testes exatos, não para consistência."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Demonstrar a propriedade de não-viés do estimador MQO",
                                  "subSteps": [
                                    "Prove matematicamente: E[β̂] = β sob o pressuposto de exogeneidade estrita.",
                                    "Derive E[β̂] = (X'X)⁻¹X'E[XY] = (X'X)⁻¹X'Xβ = β.",
                                    "Simule em software um modelo com erros centrados em zero e verifique o viés médio.",
                                    "Analise o impacto de endogeneidade (E[u|X]≠0) causando viés.",
                                    "Calcule o viés em um exemplo numérico simples com n=100 observações."
                                  ],
                                  "verification": "Derivação correta da expectativa e simulação mostrando viés próximo a zero.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Lápis e papel para derivações",
                                    "Python com NumPy e statsmodels para simulação"
                                  ],
                                  "tips": [
                                    "Parta da decomposição y = Xβ + u para facilitar a prova.",
                                    "Use sementes fixas em simulações para reprodutibilidade."
                                  ],
                                  "learningObjective": "Provar e verificar empiricamente a não-viés do MQO sob pressupostos.",
                                  "commonMistakes": [
                                    "Esquecer de condicionar em X na expectativa.",
                                    "Confundir viés com variância na simulação finita."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Analisar consistência, eficiência e propriedades assintóticas",
                                  "subSteps": [
                                    "Explique consistência: plim β̂ = β quando n→∞, requerendo ergodicidade e pressupostos fracos.",
                                    "Demonstre eficiência pelo teorema de Gauss-Markov: MQO é BLUE (Best Linear Unbiased Estimator).",
                                    "Derive a variância: Var(β̂) = σ² (X'X)⁻¹ e prove menor variância.",
                                    "Discuta normalidade assintótica: √n (β̂ - β) ~ N(0, σ² plim (X'X/n)⁻¹).",
                                    "Simule convergência com amostras crescentes (n=50, 500, 5000)."
                                  ],
                                  "verification": "Gráficos de simulação mostrando convergência e derivação da matriz de variância.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "Software R (lm e ggplot2) ou Python (seaborn para plots)",
                                    "Tabela assintótica de propriedades"
                                  ],
                                  "tips": [
                                    "Use teorema do limite probabilístico para consistência.",
                                    "Compare variâncias com estimadores rivais como médias simples."
                                  ],
                                  "learningObjective": "Dominar as propriedades de consistência, eficiência e comportamento assintótico do MQO.",
                                  "commonMistakes": [
                                    "Confundir consistência (plim) com não-viés (E).",
                                    "Ignorar que eficiência requer homocedasticidade."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Aplicar as propriedades em regressões de desempenho de sistemas de controle",
                                  "subSteps": [
                                    "Colete ou simule dados de desempenho: e.g., eficiência de um controlador PID vs variáveis de entrada.",
                                    "Estime modelo MQO e teste pressupostos (resíduos, VIF para multicolinearidade).",
                                    "Verifique não-viés e consistência via bootstrap ou simulações Monte Carlo.",
                                    "Interprete coeficientes à luz das propriedades: confiança em eficiência para predições.",
                                    "Discuta aplicações: otimização de sistemas de controle industrial."
                                  ],
                                  "verification": "Relatório com modelo estimado, testes de pressupostos e análise de propriedades.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Dataset simulado de sistemas de controle (e.g., temperatura vs setpoint)",
                                    "Python scikit-learn ou MATLAB para regressão"
                                  ],
                                  "tips": [
                                    "Use dados reais de sensores IoT se possível.",
                                    "Sempre reporte intervalos de confiança assintóticos."
                                  ],
                                  "learningObjective": "Aplicar análise de propriedades MQO em contexto de engenharia de controle.",
                                  "commonMistakes": [
                                    "Violações de pressupostos em dados de tempo (autocorrelação).",
                                    "Interpretar causalidade sem exogeneidade."
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de temperatura de um forno industrial, regresse a eficiência energética (Y) contra setpoint (X1), carga térmica (X2) e ruído ambiental (X3). Estime MQO, verifique pressupostos, prove não-viés via E[erros]=0 e eficiência pela menor variância dos coeficientes, simulando 1000 replicatas para mostrar convergência assintótica.",
                              "finalVerifications": [
                                "Listar e justificar os 4 pressupostos Gauss-Markov.",
                                "Derivar E[β̂]=β e Var(β̂).",
                                "Simular consistência com n→∞.",
                                "Explicar por que MQO é BLUE.",
                                "Aplicar em dataset de engenharia e interpretar propriedades.",
                                "Identificar violações e correções (e.g., robust SE)."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas derivações (80% corretas).",
                                "Correta interpretação de simulações e gráficos.",
                                "Profundidade na análise de pressupostos e violações.",
                                "Relevância da aplicação em sistemas de controle.",
                                "Clareza na explicação de propriedades assintóticas.",
                                "Uso adequado de software e verificações empíricas."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade e Estatística: Distribuições assintóticas e teoremas limites.",
                                "Engenharia de Controle: Modelagem de sistemas dinâmicos via regressão.",
                                "Machine Learning: Comparação com regressão ridge/lasso sob violações.",
                                "Economia/Econometria: Inferência causal em painéis.",
                                "Computação Científica: Otimização numérica de quadrados mínimos."
                              ],
                              "realWorldApplication": "Em engenharia de controle, analisa-se regressões MQO para avaliar desempenho de controladores em usinas (e.g., prever consumo energético), garantindo previsões não-viesadas e eficientes para otimização em tempo real, reduzindo custos operacionais em indústrias como óleo&gás ou automotiva."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.5.2",
                        "name": "Inferência Estatística em Modelos",
                        "description": "Desenvolvimento de intervalos de confiança e análise de significância para parâmetros em modelos de regressão, considerando distribuições assintóticas e aplicações em validação de modelos econométricos para engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.5.2.1",
                            "name": "Construir intervalos de confiança para coeficientes",
                            "description": "Calcular intervalos de confiança usando a distribuição t de Student ou normal assintótica, interpretando-os no contexto de previsões de falhas em sistemas dinâmicos de engenharia.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Ajustar o modelo de regressão e obter estimativas dos coeficientes",
                                  "subSteps": [
                                    "Colete e prepare os dados de falhas em sistemas dinâmicos (ex.: tempo até falha vs. variáveis como vibração e temperatura).",
                                    "Ajuste o modelo de regressão linear múltipla usando software estatístico.",
                                    "Extraia as estimativas dos coeficientes (β̂) do modelo ajustado."
                                  ],
                                  "verification": "Confira se o modelo foi ajustado corretamente comparando resíduos com resíduos teóricos (QQ-plot).",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Dados de exemplo em CSV, software R ou Python (bibliotecas statsmodels ou lm em R).",
                                  "tips": "Sempre centre as variáveis preditoras para melhorar a interpretabilidade.",
                                  "learningObjective": "Compreender como obter estimativas pontuais dos coeficientes em um modelo de regressão.",
                                  "commonMistakes": "Ignorar multicolinearidade entre preditores, levando a coeficientes instáveis."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Calcular os erros padrão dos coeficientes",
                                  "subSteps": [
                                    "Calcule a variância dos resíduos (σ²) a partir do modelo ajustado.",
                                    "Construa a matriz de covariância dos estimadores (X'X)^{-1}.",
                                    "Extraia os erros padrão (SE(β̂)) como raiz quadrada da diagonal dessa matriz multiplicada por σ²."
                                  ],
                                  "verification": "Verifique se os SE(β̂) são consistentes com saídas do software (ex.: summary() em R).",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Software estatístico com funções de regressão, calculadora matricial opcional.",
                                  "tips": "Use funções prontas como vcov() em R para automatizar o cálculo.",
                                  "learningObjective": "Dominar o cálculo da incerteza associada aos estimadores de coeficientes.",
                                  "commonMistakes": "Confundir variância dos resíduos com variância dos coeficientes."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Selecionar a distribuição e determinar os quantis críticos",
                                  "subSteps": [
                                    "Avalie o tamanho da amostra (n) e graus de liberdade (gl = n - p - 1).",
                                    "Escolha distribuição t de Student se n pequeno (<30) ou normal assintótica se n grande.",
                                    "Obtenha o quantil crítico (t* ou z*) para o nível de confiança desejado (ex.: 95%)."
                                  ],
                                  "verification": "Confira graus de liberdade e quantil com tabelas ou funções como qt() em R.",
                                  "estimatedTime": "20 minutos",
                                  "materials": "Tabelas de distribuição t e normal, software com funções qnorm() e qt().",
                                  "tips": "Para aproximação assintótica, use z* = 1.96 para 95% de confiança.",
                                  "learningObjective": "Saber quando usar t vs. normal e calcular quantis apropriados.",
                                  "commonMistakes": "Usar distribuição normal para amostras pequenas, subestimando incerteza."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Construir os intervalos de confiança",
                                  "subSteps": [
                                    "Calcule o limite inferior: β̂ - t* * SE(β̂).",
                                    "Calcule o limite superior: β̂ + t* * SE(β̂).",
                                    "Repita para todos os coeficientes relevantes do modelo."
                                  ],
                                  "verification": "Compare com intervalos fornecidos pelo software (confint() em R).",
                                  "estimatedTime": "25 minutos",
                                  "materials": "Resultados dos passos anteriores, calculadora.",
                                  "tips": "Automatize com funções prontas para evitar erros aritméticos.",
                                  "learningObjective": "Executar o cálculo fórmulo dos intervalos de confiança.",
                                  "commonMistakes": "Inverter os sinais nos limites, criando intervalos inválidos."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Interpretar os intervalos no contexto de previsões de falhas",
                                  "subSteps": [
                                    "Analise se o IC inclui zero (insignificância prática).",
                                    "Discuta implicações para previsões de falhas (ex.: amplitude indica confiabilidade).",
                                    "Relacione com engenharia: incerteza em coeficientes afeta alertas de manutenção."
                                  ],
                                  "verification": "Escreva um parágrafo de interpretação coerente com o contexto.",
                                  "estimatedTime": "35 minutos",
                                  "materials": "Relatório ou documento para escrita, gráficos do modelo.",
                                  "tips": "Use visualizações como plot de coeficientes com barras de erro.",
                                  "learningObjective": "Interpretar ICs probabilisticamente em aplicações de engenharia.",
                                  "commonMistakes": "Interpretar IC como probabilidade de que o verdadeiro β esteja no intervalo."
                                }
                              ],
                              "practicalExample": "Em um sistema dinâmico de uma turbina eólica, ajuste um modelo linear: TempoFalha ~ Vibração + Temperatura. Para o coeficiente de Vibração (β̂ = -0.5, SE = 0.12, gl=28, 95% confiança), usando t*, IC = [-0.5 ± 2.05*0.12] = [-0.74, -0.26]. Interprete: com 95% confiança, cada unidade de vibração aumenta o risco de falha em 0.26 a 0.74 unidades de tempo.",
                              "finalVerifications": [
                                "Os intervalos foram calculados corretamente para todos coeficientes principais?",
                                "A escolha da distribuição (t ou normal) foi justificada pelo tamanho da amostra?",
                                "A interpretação considera o contexto de previsões de falhas em engenharia?",
                                "Os ICs são simétricos em torno de β̂ e não incluem valores irrelevantes (ex.: zero para efeitos esperados)?",
                                "Gráficos ou tabelas foram gerados para visualização?",
                                "Cálculos manuais coincidem com saídas de software?"
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de SE(β̂) e quantis críticos (erro <1%).",
                                "Correta seleção e justificativa da distribuição apropriada.",
                                "Intervalos construídos matematicamente corretos e reportados adequadamente.",
                                "Interpretação contextualizada com aplicações em sistemas dinâmicos.",
                                "Uso adequado de software e verificação cruzada de resultados.",
                                "Clareza na comunicação dos resultados via tabelas/gráficos."
                              ],
                              "crossCurricularConnections": [
                                "Probabilidade e Estatística: Fundamentos de distribuições t e normal.",
                                "Engenharia Mecânica: Análise de confiabilidade e manutenção preditiva.",
                                "Programação Computacional: Uso de R/Python para modelagem estatística.",
                                "Análise de Sistemas Dinâmicos: Modelagem de falhas em processos contínuos."
                              ],
                              "realWorldApplication": "Em engenharia aeroespacial ou de energia, intervalos de confiança para coeficientes em modelos de previsão de falhas permitem quantificar incertezas em tempos de vida útil de componentes, suportando decisões de inspeção preventiva e otimizando custos de manutenção em sistemas como aviões ou turbinas."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.5.2.2",
                            "name": "Realizar inferência sobre previsões do modelo",
                            "description": "Derivar variâncias de previsões pontuais e médias, aplicando em cenários de engenharia como otimização de controladores PID com dados observados.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Inferência em Modelos de Regressão",
                                  "subSteps": [
                                    "Estude previsões pontuais (valores individuais previstos) e médias previstas (média condicional).",
                                    "Revise fórmulas de variância em regressão linear: σ²(ŷ₀) = σ² [1 + x₀(XᵀX)⁻¹x₀ᵀ] para previsão pontual.",
                                    "Entenda variância da média prevista: σ²(ȳ̂₀) = σ² x₀(XᵀX)⁻¹x₀ᵀ.",
                                    "Pratique com exemplos simples em software estatístico.",
                                    "Identifique diferenças entre variância de previsão pontual e média."
                                  ],
                                  "verification": "Resolva 3 exercícios manuais e verifique com software (ex: R ou Python) se os resultados coincidem.",
                                  "estimatedTime": "2 horas",
                                  "materials": "Livro de regressão (ex: Montgomery), Python com statsmodels, planilha Excel.",
                                  "tips": "Use matrizes para visualização; desenhe diagramas de leverage.",
                                  "learningObjective": "Compreender as fórmulas matemáticas de variâncias em inferência de modelos.",
                                  "commonMistakes": "Confundir variância de resíduo com variância de previsão; ignorar o termo '1' na previsão pontual."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Derivar e Calcular Variâncias de Previsões",
                                  "subSteps": [
                                    "Colete ou gere dados de exemplo (ex: 20 observações lineares com ruído).",
                                    "Ajuste modelo de regressão linear usando mínimos quadrados.",
                                    "Calcule manualmente a matriz (XᵀX)⁻¹.",
                                    "Compute variância para uma nova previsão pontual e para média em um ponto x₀ específico.",
                                    "Construa intervalos de confiança usando distribuição t de Student."
                                  ],
                                  "verification": "Compare cálculos manuais com output de função predict() em statsmodels ou lm() no R.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Python (numpy, statsmodels), R, calculadora matricial online.",
                                  "tips": "Padronize variáveis para facilitar interpretação numérica.",
                                  "learningObjective": "Aplicar fórmulas para derivar variâncias numericamente em dados simulados.",
                                  "commonMistakes": "Esquecer de estimar σ² dos resíduos; usar distribuição normal em vez de t para amostras pequenas."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Aplicar Inferência em Cenário de Engenharia: Controlador PID",
                                  "subSteps": [
                                    "Obtenha dados observados de um sistema PID (ex: resposta de temperatura a setpoint).",
                                    "Modele a relação setpoint vs. erro observado com regressão linear múltipla (ganhos Kp, Ki, Kd como preditores).",
                                    "Derive variâncias das previsões de erro para novos setpoints.",
                                    "Analise como variância afeta estabilidade do controlador.",
                                    "Simule cenários com diferentes níveis de ruído nos dados."
                                  ],
                                  "verification": "Gere gráficos de intervalos de confiança sobrepostas às observações reais.",
                                  "estimatedTime": "4 horas",
                                  "materials": "Dados simulados PID (Python control library), Jupyter Notebook.",
                                  "tips": "Use simulação Monte Carlo para validar variâncias.",
                                  "learningObjective": "Integrar inferência estatística em modelagem de controladores PID.",
                                  "commonMistakes": "Não considerar multicolinearidade entre ganhos PID; superestimar precisão em dados ruidosos."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Otimizar Controlador PID Usando Inferências",
                                  "subSteps": [
                                    "Defina objetivo: minimizar variância de previsão de erro em operação nominal.",
                                    "Use intervalos de confiança para selecionar ganhos PID ótimos.",
                                    "Aplique teste de hipóteses para comparar modelos (ex: F-test em subconjuntos de preditores).",
                                    "Itere otimizações com gradiente descendente considerando variâncias.",
                                    "Valide com simulação em tempo real ou dados de validação."
                                  ],
                                  "verification": "Demonstre redução de 20% na variância média de previsão pós-otimização.",
                                  "estimatedTime": "3 horas",
                                  "materials": "Python (scipy.optimize, control), dados de validação PID.",
                                  "tips": "Priorize ganhos com intervalos de confiança estreitos.",
                                  "learningObjective": "Otimizar parâmetros de engenharia via inferência estatística.",
                                  "commonMistakes": "Ignorar viés de seleção ao testar múltiplos modelos; otimizar apenas ponto único."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Avaliar e Refinar o Processo de Inferência",
                                  "subSteps": [
                                    "Realize análise de resíduos para checar premissas (normalidade, homocedasticidade).",
                                    "Ajuste modelo se necessário (ex: regressão robusta).",
                                    "Documente pipeline completo em relatório.",
                                    "Teste sensibilidade a outliers em dados PID.",
                                    "Compare com métodos bayesianos para insights adicionais."
                                  ],
                                  "verification": "Produza relatório com Q-Q plots e métricas de cobertura de IC (95% taxa).",
                                  "estimatedTime": "2 horas",
                                  "materials": "Python (seaborn para plots), LaTeX ou Markdown para relatório.",
                                  "tips": "Automatize com funções reutilizáveis.",
                                  "learningObjective": "Garantir robustez da inferência em aplicações reais.",
                                  "commonMistakes": "Não diagnosticar violações de premissas; superconfiança em IC sem validação."
                                }
                              ],
                              "practicalExample": "Em um forno industrial, dados observados de temperatura (setpoint, ganhos PID) são modelados. Calcule variância da previsão de erro para setpoint=200°C, otimizando Kp para minimizar variância, resultando em controle mais estável.",
                              "finalVerifications": [
                                "Calcula corretamente variância de previsão pontual e média para x₀ dado.",
                                "Constrói intervalos de confiança válidos (cobertura ~95%).",
                                "Aplica inferência para otimizar ganhos PID com redução mensurável de variância.",
                                "Identifica e corrige violações de premissas do modelo.",
                                "Gera gráficos interpretáveis de incertezas em previsões.",
                                "Documenta pipeline com código reproduzível."
                              ],
                              "assessmentCriteria": [
                                "Precisão matemática nas derivações de variância (erro <1%).",
                                "Correta implementação em software com validação cruzada.",
                                "Relevância da aplicação PID à otimização real.",
                                "Profundidade na análise de diagnósticos (resíduos, leverage).",
                                "Criatividade em conexões com cenários de engenharia.",
                                "Clareza na comunicação de resultados e incertezas."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Controle: Otimização PID diretamente aplicada.",
                                "Programação Computacional: Uso de statsmodels/control em Python.",
                                "Estatística Avançada: Extensão a modelos generalizados lineares.",
                                "Física Aplicada: Dinâmica de sistemas com ruído observacional."
                              ],
                              "realWorldApplication": "Otimização de controladores PID em indústrias como manufatura automotiva ou aeroespacial, onde previsões incertas de desempenho podem levar a falhas; inferência reduz risco ajustando ganhos com base em variâncias observadas, economizando tempo de tuning manual."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      },
                      {
                        "id": "10.1.7.5.3",
                        "name": "Testes de Hipóteses e Seleção de Modelos",
                        "description": "Execução de testes estatísticos para validação de hipóteses e escolha de modelos adequados, incluindo critérios de informação e testes F, com foco em aplicações econométricas para análise de dados de engenharia.",
                        "specificSkills": [
                          {
                            "id": "10.1.7.5.3.1",
                            "name": "Aplicar testes t e F em regressão",
                            "description": "Executar testes de significância individual (t) e conjunta (F) para coeficientes, rejeitando ou não a nulidade com p-valores, em exemplos de regressão de eficiência de processos industriais.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Preparar dados e ajustar o modelo de regressão linear",
                                  "subSteps": [
                                    "Coletar ou carregar o dataset de eficiência de processos industriais (ex: eficiência Y vs. variáveis X1=temperatura, X2=pressão, X3=velocidade).",
                                    "Explorar os dados: calcular estatísticas descritivas, verificar multicolinearidade e outliers.",
                                    "Ajustar o modelo de regressão linear usando software como R (lm()) ou Python (statsmodels).",
                                    "Obter o summary do modelo com coeficientes, erros padrão e p-valores iniciais.",
                                    "Verificar premissas do modelo: linearidade, homocedasticidade e normalidade dos resíduos."
                                  ],
                                  "verification": "Modelo ajustado com summary exibido, premissas verificadas sem violações graves.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Dataset exemplo (CSV com dados industriais)",
                                    "R ou Python com bibliotecas (statsmodels, pandas, matplotlib)"
                                  ],
                                  "tips": "Sempre centre as variáveis se houver intercepto; use plot de resíduos para diagnósticos rápidos.",
                                  "learningObjective": "Configurar e validar um modelo de regressão pronto para testes de hipóteses.",
                                  "commonMistakes": [
                                    "Ignorar outliers que distorcem coeficientes.",
                                    "Não verificar multicolinearidade (VIF > 5).",
                                    "Esquecer de padronizar variáveis em escalas diferentes."
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Executar teste t para significância individual dos coeficientes",
                                  "subSteps": [
                                    "Formular hipóteses nula (H0: βj = 0) e alternativa (Ha: βj ≠ 0) para cada coeficiente.",
                                    "Calcular estatística t = βj / SE(βj) e p-valor do summary do modelo.",
                                    "Comparar p-valor com nível de significância α (ex: 0.05); rejeitar H0 se p < α.",
                                    "Interpretar: coeficiente significativo indica impacto individual da variável.",
                                    "Documentar resultados em tabela com t, p-valor e decisão."
                                  ],
                                  "verification": "Tabela com testes t para todos coeficientes, com decisões de rejeição corretas.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Output do summary do modelo",
                                    "Tabela Excel ou Markdown para registrar"
                                  ],
                                  "tips": "Use testes bilaterais por padrão; confie nos p-valores ajustados se múltiplos testes.",
                                  "learningObjective": "Aplicar teste t para avaliar relevância individual de preditores.",
                                  "commonMistakes": [
                                    "Confundir t com F (t é individual).",
                                    "Interpretar magnitude de t sem p-valor.",
                                    "Usar α errado (ex: 0.1 em vez de 0.05)."
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Executar teste F para significância conjunta dos coeficientes",
                                  "subSteps": [
                                    "Formular H0: todos βj = 0 (modelo nulo vs. completo).",
                                    "Calcular F = (SSR_restrito - SSR_completo)/q / (SST - SSR_completo)/(n-k-1), ou usar anova() em R.",
                                    "Obter p-valor do teste F do summary ou função específica.",
                                    "Rejeitar H0 se p < α, indicando que o modelo explica variância significativa.",
                                    "Comparar com teste t: F global, t individuais."
                                  ],
                                  "verification": "Estatística F, p-valor e decisão de significância global documentados.",
                                  "estimatedTime": "30 minutos",
                                  "materials": [
                                    "Funções anova() em R ou statsmodels em Python",
                                    "Summary do modelo"
                                  ],
                                  "tips": "F sempre ≥ máximo t²; use para validar modelo antes de t individuais.",
                                  "learningObjective": "Avaliar se o modelo como um todo é útil via teste F conjunto.",
                                  "commonMistakes": [
                                    "Confundir F com teste de variância total.",
                                    "Ignorar graus de liberdade no cálculo manual.",
                                    "Não testar modelo restrito (apenas intercepto)."
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Interpretar resultados e tomar decisões baseadas em testes",
                                  "subSteps": [
                                    "Resumir: quais variáveis são significativas (t e F)?",
                                    "Discutir implicações para eficiência industrial (ex: remover variáveis não significativas).",
                                    "Calcular intervalos de confiança para coeficientes significativos.",
                                    "Gerar relatório com gráficos (coeficientes com barras de erro, resíduos).",
                                    "Propor próximos passos: refinar modelo ou aplicar em produção."
                                  ],
                                  "verification": "Relatório completo com interpretações, decisões e visualizações.",
                                  "estimatedTime": "45 minutos",
                                  "materials": [
                                    "Gráficos em ggplot2 ou seaborn",
                                    "Template de relatório Jupyter Notebook"
                                  ],
                                  "tips": "Sempre contextualize p-valores com tamanho da amostra; evite caça ao p-valor.",
                                  "learningObjective": "Integrar testes t/F em decisões práticas de modelagem.",
                                  "commonMistakes": [
                                    "Rejeitar modelo só por F não significativo.",
                                    "Ignorar significância prática vs. estatística.",
                                    "Não reportar ICs junto com p-valores."
                                  ]
                                }
                              ],
                              "practicalExample": "Em uma fábrica de cimento, modele eficiência energética (Y, kWh/ton) regredida sobre temperatura do forno (X1, °C), taxa de alimentação (X2, ton/h) e umidade (X3, %). Ajuste lm(Y ~ X1 + X2 + X3), teste t para cada (ex: p_X1=0.02 → significativo), F global p=0.001 → modelo útil. Conclusão: temperatura impacta individualmente; otimizar para reduzir 10% energia.",
                              "finalVerifications": [
                                "Modelo ajustado corretamente com summary completo.",
                                "Testes t individuais com p-valores e decisões precisas.",
                                "Teste F conjunto executado e interpretado.",
                                "Relatório com implicações industriais claras.",
                                "Gráficos de diagnóstico sem erros graves.",
                                "Intervalos de confiança calculados para coeficientes chave."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de t e F (erro <5%).",
                                "Formulação correta de hipóteses nulas/alternativas.",
                                "Interpretação coerente de p-valores e decisões.",
                                "Validação de premissas do modelo (resíduos, etc.).",
                                "Relatório claro e acionável com exemplos reais.",
                                "Uso adequado de software e visualizações.",
                                "Ausência de erros comuns como confusão t/F."
                              ],
                              "crossCurricularConnections": [
                                "Estatística Inferencial: Distribuições t e F.",
                                "Engenharia Industrial: Otimização de processos.",
                                "Programação: Manipulação de dados em R/Python.",
                                "Econometria: Modelos lineares em análise de custos.",
                                "Machine Learning: Seleção de features via testes."
                              ],
                              "realWorldApplication": "Em indústrias como manufatura e química, testes t/F em regressões identificam variáveis chave para eficiência (ex: reduzir desperdício em 15% otimizando temperatura em fornos), suportando decisões de engenharia baseadas em dados para Lean Manufacturing e Indústria 4.0."
                            },
                            "estimatedTime": "1.5 horas",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.5.3.2",
                            "name": "Utilizar critérios de seleção de modelos",
                            "description": "Comparar modelos usando AIC, BIC e teste de Chow, selecionando o mais parcimonioso para dados de engenharia, como modelagem de séries temporais em sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Compreender os Conceitos Fundamentais de AIC, BIC e Teste de Chow",
                                  "subSteps": [
                                    "Estude a fórmula do AIC: AIC = -2*log(L) + 2*k, onde L é a verossimilhança e k o número de parâmetros.",
                                    "Analise o BIC: BIC = -2*log(L) + k*log(n), destacando a penalização maior para amostras pequenas.",
                                    "Revise o teste de Chow para quebras estruturais: Hipótese nula de estabilidade vs. alternativa de mudança em um ponto.",
                                    "Compare penalizações: AIC favorece complexidade, BIC parcimônia.",
                                    "Leia documentação de bibliotecas como statsmodels para implementação."
                                  ],
                                  "verification": "Explique em suas palavras as diferenças entre AIC e BIC, e quando usar Chow.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Documentação statsmodels/sklearn; notebook Jupyter; artigos introdutórios sobre critérios de informação.",
                                  "tips": "Use analogias: AIC como 'bom e barato', BIC como 'econômico rigoroso'.",
                                  "learningObjective": "Dominar definições matemáticas e intuitivas dos critérios para seleção informada.",
                                  "commonMistakes": "Confundir log-verossimilhança com RSS; ignorar tamanho da amostra no BIC."
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Preparar Dados de Séries Temporais de Engenharia",
                                  "subSteps": [
                                    "Colete ou gere dados simulados de série temporal, ex: sinal de controle de um motor (velocidade vs. tempo).",
                                    "Realize pré-processamento: remoção de missing values, stationarity test (ADF).",
                                    "Divida dados em segmentos para teste de Chow (pré e pós-quebra suspeita).",
                                    "Visualize séries com plots: autocorrelação, PACF para identificar lags.",
                                    "Defina modelos candidatos: ARIMA(p,d,q) com diferentes ordens."
                                  ],
                                  "verification": "Confirme stationarity via teste ADF e gere plots ACF/PACF limpos.",
                                  "estimatedTime": "1 hora",
                                  "materials": "Python com pandas, statsmodels.tsa; dados simulados de sistemas de controle.",
                                  "tips": "Simule ruído realista com AR(1) para dados de engenharia.",
                                  "learningObjective": "Preparar dados adequados para modelagem de séries temporais em contextos de controle.",
                                  "commonMistakes": "Não testar stationarity; usar dados não estacionários sem diferenciação."
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Ajustar Modelos Candidatos e Calcular Critérios",
                                  "subSteps": [
                                    "Ajuste 3-5 modelos ARIMA variando p,q (ex: ARIMA(1,1,1), (2,1,1)).",
                                    "Extraia AIC e BIC diretamente das saídas do modelo (model.aic, model.bic).",
                                    "Implemente teste de Chow manualmente ou via statsmodels: defina ponto de quebra e compute F-statistic.",
                                    "Registre valores em tabela: modelo, AIC, BIC, p-value Chow.",
                                    "Verifique resíduos: plots QQ e Ljung-Box para independência."
                                  ],
                                  "verification": "Tabela completa com AIC/BIC/Chow para todos modelos, sem erros de convergência.",
                                  "estimatedTime": "1 hora 30 minutos",
                                  "materials": "statsmodels.tsa.arima.model; scipy.stats para Chow.",
                                  "tips": "Comece com ordens baixas para evitar overfitting inicial.",
                                  "learningObjective": "Aplicar computacionalmente os critérios em múltiplos modelos.",
                                  "commonMistakes": "Ignorar warnings de não-convergência; mal definir breakpoint no Chow."
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Comparar Critérios e Selecionar o Modelo Mais Parcimonioso",
                                  "subSteps": [
                                    "Classifique modelos por AIC (menor melhor), depois BIC para tie-break.",
                                    "Interprete Chow: rejeite H0 se p<0.05, indicando necessidade de modelo segmentado.",
                                    "Selecione modelo com menor BIC entre os com AIC similar, priorizando parcimônia.",
                                    "Compare forecasts out-of-sample para validação extra.",
                                    "Documente justificativa: 'Modelo X escolhido por BIC=XX e Chow não significativo'."
                                  ],
                                  "verification": "Relatório escrito justificando seleção com valores numéricos.",
                                  "estimatedTime": "45 minutos",
                                  "materials": "Excel ou pandas para tabela comparativa; matplotlib para forecast plots.",
                                  "tips": "BIC para engenharia onde parcimônia evita overfitting em controle.",
                                  "learningObjective": "Integrar critérios para decisão robusta em cenários de engenharia.",
                                  "commonMistakes": "Selecionar por AIC só, ignorando BIC; não considerar Chow para séries com quebras."
                                },
                                {
                                  "stepNumber": 5,
                                  "title": "Validar e Aplicar o Modelo Selecionado",
                                  "subSteps": [
                                    "Avalie in-sample fit: R² ajustado, resíduos brancos.",
                                    "Teste out-of-sample: holdout set com MAPE/RMSE.",
                                    "Simule aplicação em controle: use modelo para prever setpoint em sistema.",
                                    "Sensibilidade: varie breakpoint no Chow e reavalie.",
                                    "Registre lições para iterações futuras."
                                  ],
                                  "verification": "Forecasts precisos (MAPE<10%) e resíduos independentes.",
                                  "estimatedTime": "30 minutos",
                                  "materials": "Dados holdout; métricas de forecast (mean_absolute_percentage_error).",
                                  "tips": "Sempre valide out-of-sample para credibilidade em engenharia.",
                                  "learningObjective": "Garantir robustez da seleção em aplicações reais de controle.",
                                  "commonMistakes": "Overfit in-sample sem validação externa."
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de temperatura de um forno industrial, ajuste ARIMA(1,1,0), ARIMA(2,1,1) e ARIMA(1,1,1) a dados de temperatura horária. Calcule AIC=125.3 (AR1), BIC=130.1; AIC=122.5 (AR2), BIC=132.0; AIC=124.0 (AR11), BIC=131.5. Teste Chow no dia da manutenção (breakpoint=50): p=0.12 (não rejeita). Selecione ARIMA(1,1,0) por menor BIC, prevendo desvios para ajuste PID.",
                              "finalVerifications": [
                                "Calcula corretamente AIC/BIC para 3 modelos diferentes.",
                                "Implementa e interpreta teste de Chow com p-value apropriado.",
                                "Seleciona modelo parcimonioso justificando com valores numéricos.",
                                "Valida com resíduos e forecast out-of-sample.",
                                "Aplica a um dataset de engenharia realista.",
                                "Documenta processo em relatório claro."
                              ],
                              "assessmentCriteria": [
                                "Precisão nos cálculos de AIC/BIC (erro <1%).",
                                "Correta implementação e interpretação do teste de Chow.",
                                "Seleção coerente priorizando parcimônia (BIC sobre AIC).",
                                "Qualidade de validação (resíduos independentes, bom forecast).",
                                "Clareza na justificativa e visualizações.",
                                "Aplicação contextualizada a séries temporais de controle."
                              ],
                              "crossCurricularConnections": [
                                "Estatística: Inferência em modelos lineares.",
                                "Engenharia de Controle: Modelagem preditiva para PID tuning.",
                                "Machine Learning: Seleção de hiperparâmetros em time series.",
                                "Econometria: Detecção de quebras estruturais."
                              ],
                              "realWorldApplication": "Em sistemas de controle industrial, como monitoramento de turbinas eólicas, selecione ARIMA parcimonioso via BIC para prever vibrações, otimizando manutenção preditiva e reduzindo downtime em 20%."
                            },
                            "estimatedTime": "2 horas",
                            "difficulty": "advanced",
                            "status": "not_started",
                            "prerequisites": []
                          },
                          {
                            "id": "10.1.7.5.3.3",
                            "name": "Interpretar resultados de testes em contextos de engenharia",
                            "description": "Analisar outputs de software (R ou similar) para validar modelos econométricos aplicados a dados de engenharia, relacionando com estabilidade e requisitos de sistemas de controle.",
                            "atomicExpansion": {
                              "steps": [
                                {
                                  "stepNumber": 1,
                                  "title": "Revisar Fundamentos de Testes de Hipóteses em Modelos Econométricos",
                                  "subSteps": [
                                    "Estude testes comuns: normalidade (Jarque-Bera), autocorrelação (Durbin-Watson), heteroscedasticidade (Breusch-Pagan), multicolinearidade (VIF) e especificação (Ramsey RESET).",
                                    "Entenda hipóteses nula e alternativa para cada teste, incluindo estatísticas chave e valores críticos.",
                                    "Revise p-values, intervalos de confiança e como rejeitar/aceitar H0.",
                                    "Pratique com fórmulas básicas e exemplos teóricos de regressão linear.",
                                    "Anote thresholds típicos (ex: p < 0.05 para rejeição)."
                                  ],
                                  "verification": "Crie um resumo de 1 página listando 5 testes com suas hipóteses e interpretações; revise com um colega ou tutor.",
                                  "estimatedTime": "2 horas",
                                  "materials": [
                                    "Livro 'Introdução à Econometria' (Wooldridge), slides de aula sobre testes, calculadora ou planilha Excel para simulações"
                                  ],
                                  "tips": "Foquem em visualizar distribuições (QQ-plots) para intuição; use tabelas de decisão para p-values.",
                                  "learningObjective": "Compreender o propósito e interpretação estatística de testes diagnósticos em modelos econométricos.",
                                  "commonMistakes": [
                                    "Confundir p-value com probabilidade de H1 ser verdadeira",
                                    "Ignorar tamanho da amostra em testes",
                                    "Não considerar múltiplos testes e ajuste de significância"
                                  ]
                                },
                                {
                                  "stepNumber": 2,
                                  "title": "Interpretar Outputs de Software como R para Testes de Modelos",
                                  "subSteps": [
                                    "Instale e configure R/RStudio com pacotes: lmtest, tseries, car.",
                                    "Execute comandos para testes em um modelo de regressão simples (lm()).",
                                    "Analise saídas: identifique seções como 'Residuals', 'Coefficients' e outputs de testes específicos (ex: dwtest(), bptest()).",
                                    "Pratique decodificando: 'p-value < 2.2e-16' significa rejeição forte; DW ~2 indica sem autocorrelação.",
                                    "Gere relatórios com stargazer ou broom para sumarizar resultados."
                                  ],
                                  "verification": "Rode um script R em dataset padrão (mtcars) e produza um relatório interpretando 4 testes; valide com summary() outputs.",
                                  "estimatedTime": "3 horas",
                                  "materials": [
                                    "R/RStudio instalado",
                                    "Datasets de exemplo (mtcars, AirPassengers)",
                                    "Tutoriais R: lmtest vignette"
                                  ],
                                  "tips": "Sempre cheque assumptions lineares primeiro; use plot(residuals) para visualizações intuitivas.",
                                  "learningObjective": "Ler e extrair insights acionáveis de outputs de software para validação de modelos.",
                                  "commonMistakes": [
                                    "Interpretar coeficientes sem testes de significância",
                                    "Ignorar warnings de convergência",
                                    "Confundir estatística teste com p-value"
                                  ]
                                },
                                {
                                  "stepNumber": 3,
                                  "title": "Relacionar Resultados de Testes com Contextos de Engenharia",
                                  "subSteps": [
                                    "Estude dados de engenharia: séries temporais de sistemas de controle (ex: resposta de um PID controller).",
                                    "Mapeie violações econométricas para problemas de engenharia: autocorrelação → instabilidade dinâmica; heteroscedasticidade → variação não-linear em ruído.",
                                    "Aplique modelos econométricos (ARIMA, VAR) a dados de sensores/atuadores.",
                                    "Interprete: baixa normalidade → modelo não captura não-linearidades do sistema; alto VIF → variáveis redundantes em design de controle.",
                                    "Simule cenários: ajuste requisitos de estabilidade (ganho, fase) baseado em testes."
                                  ],
                                  "verification": "Analise um dataset de engenharia (ex: dados de temperatura de motor) e escreva 300 palavras ligando 3 falhas de teste a impactos em controle.",
                                  "estimatedTime": "4 horas",
                                  "materials": [
                                    "Datasets: UCI ML repo (engine datasets), MATLAB/Simulink export to CSV",
                                    "R pacotes: forecast, vars"
                                  ],
                                  "tips": "Pense em termos de Bode plots ou root locus para analogias; priorize testes relevantes para tempo real.",
                                  "learningObjective": "Conectar diagnósticos econométricos a requisitos funcionais de sistemas de engenharia.",
                                  "commonMistakes": [
                                    "Aplicar testes sem contexto domain-specific",
                                    "Ignorar lag structures em dados de controle",
                                    "Sobre-generalizar de dados econômicos para engenharia"
                                  ]
                                },
                                {
                                  "stepNumber": 4,
                                  "title": "Validar Modelos e Tomar Decisões de Seleção",
                                  "subSteps": [
                                    "Compare modelos via AIC/BIC pós-testes diagnósticos.",
                                    "Decida ações: reespecificar modelo, transformar variáveis ou rejeitar se múltiplas falhas.",
                                    "Documente trade-offs: precisão vs. estabilidade em contextos de controle.",
                                    "Teste robustez com bootstrap ou cross-validation.",
                                    "Gere recomendação final: 'Modelo válido para previsão de falhas com 95% confiança'."
                                  ],
                                  "verification": "Selecione o melhor modelo de 3 opções em um dataset engenharia e justifique com tabela de testes/AIC.",
                                  "estimatedTime": "2.5 horas",
                                  "materials": [
                                    "R scripts dos steps anteriores",
                                    "Ferramentas: AIC() function, ggplot2 para plots comparativos"
                                  ],
                                  "tips": "Use information criteria como tie-breaker; sempre valide out-of-sample.",
                                  "learningObjective": "Integrar interpretações para seleção e validação final de modelos em aplicações reais.",
                                  "commonMistakes": [
                                    "Escolher por fit seul sem diagnósticos",
                                    "Ignorar custo computacional em sistemas embarcados",
                                    "Não reportar incertezas"
                                  ]
                                }
                              ],
                              "practicalExample": "Em um sistema de controle de drone, use R para ajustar ARIMA a dados de aceleração do motor. Testes revelam autocorrelação (DW=1.2, p<0.01), indicando modelo inadequado para estabilidade; reespecifique com lags, validando para requisitos de hover preciso.",
                              "finalVerifications": [
                                "Explicar corretamente 5 testes diagnósticos e suas implicações em engenharia.",
                                "Interpretar output R completo de um modelo, identificando todas as falhas.",
                                "Relacionar uma violação (ex: heteroscedasticidade) a falha em sistema de controle.",
                                "Selecionar modelo ótimo justificando com critérios quantitativos.",
                                "Produzir relatório com visualizações e recomendações acionáveis.",
                                "Simular correção de modelo e verificar melhorias nos testes."
                              ],
                              "assessmentCriteria": [
                                "Precisão na interpretação de p-values e estatísticas (90% acerto).",
                                "Profundidade na conexão com estabilidade/requisitos de engenharia.",
                                "Qualidade dos sub-passos executados e verificações autônomas.",
                                "Clareza no relatório final com exemplos concretos.",
                                "Criatividade em tips e avoidance de common mistakes.",
                                "Eficiência temporal (dentro de estimados)."
                              ],
                              "crossCurricularConnections": [
                                "Engenharia de Controle: Estabilidade via Nyquist vs. testes de resíduos.",
                                "Programação: Manipulação de dados em R/Python para automação.",
                                "Estatística: Inferência bayesiana como extensão.",
                                "Física/Mecânica: Modelagem dinâmica de sistemas reais."
                              ],
                              "realWorldApplication": "Em indústrias como aeroespacial ou automotiva, validar modelos preditivos para detecção precoce de falhas em controladores PID, otimizando manutenção preditiva e garantindo conformidade com normas de segurança (ex: ISO 26262)."
                            },
                            "estimatedTime": "1 hora",
                            "difficulty": "intermediate",
                            "status": "not_started",
                            "prerequisites": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            ],
            "totalSkills": 331
          }
        ],
        "totalSkills": 331
      }
    ]
  }
}